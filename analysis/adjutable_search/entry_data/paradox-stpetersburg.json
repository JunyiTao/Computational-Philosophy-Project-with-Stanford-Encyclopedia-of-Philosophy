{
    "url": "paradox-stpetersburg",
    "title": "The St. Petersburg Paradox",
    "authorship": {
        "year": "Copyright \u00a9 2023",
        "author_text": "Martin Peterson\n<martinpeterson@tamu.edu>",
        "author_links": [
            {
                "http://www.martinpeterson.org": "Martin Peterson"
            },
            {
                "mailto:martinpeterson%40tamu%2eedu": "martinpeterson@tamu.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2023</a> by\n\n<br/>\n<a href=\"http://www.martinpeterson.org\" target=\"other\">Martin Peterson</a>\n&lt;<a href=\"mailto:martinpeterson%40tamu%2eedu\"><em>martinpeterson<abbr title=\" at \">@</abbr>tamu<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Tue Jul 30, 2019",
        "substantive revision Tue Aug 1, 2023"
    ],
    "preamble": "\n\nThe St. Petersburg paradox was introduced by Nicolaus Bernoulli in\n1713. It continues to be a reliable source for new puzzles and\ninsights in decision theory.\n\nThe standard version of the St. Petersburg paradox is derived from the\nSt. Petersburg game, which is played as follows: A fair coin is\nflipped until it comes up heads the first time. At that point the\nplayer wins \\(\\$2^n,\\) where n is the number of times the coin\nwas flipped. How much should one be willing to pay for playing this\ngame? Decision theorists advise us to apply the principle of\nmaximizing expected value. According to this principle, the value of\nan uncertain prospect is the sum total obtained by multiplying the\nvalue of each possible outcome with its probability and then adding up\nall the terms (see the entry on\n normative theories of rational choice: expected utility).\n In the St. Petersburg game the monetary values of the outcomes and\ntheir probabilities are easy to determine. If the coin lands heads on\nthe first flip you win $2, if it lands heads on the second flip you\nwin $4, and if this happens on the third flip you win $8, and so on.\nThe probabilities of the outcomes are \\(\\frac{1}{2}\\),\n\\(\\frac{1}{4}\\), \\(\\frac{1}{8}\\),\u2026. Therefore, the expected\nmonetary value of the St. Petersburg game is \n\\[\\begin{align}\n\\frac{1}{2}\\cdot 2 + \\frac{1}{4}\\cdot 4 + \\frac{1}{8}\\cdot 8 + \\cdots &= 1+1+1+ \\cdots \\\\\n&= \\sum_{n=1}^{\\infty} \\left(\\frac{1}{2}\\right)^n \\cdot 2^n \\\\\n&= \\infty.\n\\end{align}\\]\n\n\n(Some would say that the sum approaches infinity, not that it\nis infinite. We will discuss this distinction in\n Section 2.)\n\nThe \u201cparadox\u201d consists in the fact that our best theory of\nrational choice seems to entail that it would be rational to pay\nany finite fee for a single opportunity to play the St.\nPetersburg game, even though it is almost certain that the player will\nwin a very modest amount. The probability is \\(\\frac{1}{2}\\) that the\nplayer wins no more than $2, and \\(\\frac{3}{4}\\) that he or she wins\nno more than $4.\n\nIn a strict logical sense, the St. Petersburg paradox is not a paradox\nbecause no formal contradiction is derived. However, to claim that a\nrational agent should pay millions, or even billions, for playing this\ngame seems absurd. So it seems that we, at the very least, have a\ncounterexample to the principle of maximizing expected value. If\nrationality forces us to liquidate all our assets for a single\nopportunity to play the St. Petersburg game, then it seems unappealing\nto be rational.\n",
    "toc": [
        {
            "#HistStPetePara": "1. The History of the St. Petersburg Paradox"
        },
        {
            "#ModeStPetePara": "2. The Modern St. Petersburg Paradox"
        },
        {
            "#UnreAssu": "3. Unrealistic Assumptions?"
        },
        {
            "#BounUtilFunc": "4. A Bounded Utility Function?"
        },
        {
            "#IgnoSmalProb": "5. Ignore Small Probabilities?"
        },
        {
            "#RelaExpeUtilTheo": "6. Relative Expected Utility Theory"
        },
        {
            "#PasaGame": "7. The Pasadena Game"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. The History of the St. Petersburg Paradox\n\nThe St. Petersburg paradox is named after one of the leading\nscientific journals of the eighteenth century, Commentarii\nAcademiae Scientiarum Imperialis Petropolitanae [Papers of\nthe Imperial Academy of Sciences in Petersburg], in which Daniel\nBernoulli (1700\u20131782) published a paper entitled \u201cSpecimen\nTheoriae Novae de Mensura Sortis\u201d [\u201cExposition of a New\nTheory on the Measurement of Risk\u201d] in 1738. Daniel Bernoulli\nhad learned about the problem from his cousin Nicolaus I\n(1687\u20131759), who proposed an early but unnecessarily complex\nversion of the paradox in a letter to Pierre R\u00e9mond de Montmort\non 9 September 1713 (for this and related letters see J. Bernoulli\n1975). Nicolaus asked de Montmort to imagine an example in which an\nordinary dice is rolled until a 6 comes up:\n\n\n[W]hat is the expectation of B \u2026 if A promises to\nB to give him some coins in this progression 1, 2, 4, 8, 16\netc. or 1, 3, 9, 27 etc. or 1, 4, 9, 16, 25 etc. or 1, 8, 27, 64\ninstead of 1, 2, 3, 4, 5 etc. as beforehand. Although for the most\npart these problems are not difficult, you will find however something\nmost curious. (N. Bernoulli to Montmort, 9 September 1713)\n\n\nIt seems that Montmort did not immediately get Nicolaus\u2019 point.\nMontmort responded that these problems \n\n\nhave no difficulty, the only concern is to find the sum of the series\nof which the numerators being in the progression of squares, cubes,\netc. the denominators are in geometric progression. (Montmort to N.\nBernoulli, 15 November 1713) \n\n\nHowever, he never performed any calculations. If he had, he would have\ndiscovered that the expected value of the first series (1, 2, 4, 8,\n16, etc.) is: \n\\[\n\\sum_{n=1}^{\\infty} \\frac{5^{n-1}}{6^n}\\cdot 2^{n-1}.\n\\]\n\n\nFor this series it holds that \n\\[\n\\lim_{n\\to\\infty} \\left|\\frac{a_{n+1}}{a_n}\\right| \\gt 1,\n\\]\n\n\nso by applying the ratio test it is easy to verify that the series is\ndivergent. (This test was discovered by d\u2019Alembert in 1768, so\nit might be unfair to criticize Montmort for not seeing this.)\nHowever, the mathematical argument presented by Nicolaus himself was\nalso a bit sketchy and would not impress contemporary mathematicians.\nThe good news is that his conclusion was correct:\n\n\nit would follow thence that B must give to A an infinite sum\nand even more than infinity (if it is permitted to speak thus) in\norder that he be able to make the advantage to give him some coins in\nthis progression 1, 2, 4, 8, 16 etc. (N. Bernoulli to Montmort, 20\nFebruary 1714)\n\n\nThe next important contribution to the debate was made by\nCram\u00e9r in 1728. He read about Nicolaus\u2019 original problem\nin a book published by Montmort and proposed a simpler and more\nelegant formulation in a letter to Nicolaus:\n\n\nIn order to render the case more simple I will suppose that A\nthrow in the air a piece of money, B undertakes to give him a\ncoin, if the side of Heads falls on the first toss, 2, if it is only\nthe second, 4, if it is the 3rd toss, 8, if it is the 4th toss, etc.\nThe paradox consists in this that the calculation gives for the\nequivalent that A must give to B an infinite sum, which\nwould seem absurd. (Cram\u00e9r to N. Bernoulli, 21 May 1728)\n\n\nIn the very same letter, Cram\u00e9r proposed a solution that\nrevolutionized the emerging field of decision theory. Cram\u00e9r\npointed out that it is not the expected monetary value that\nshould guide the choices of a rational agent, but rather the\n\u201cusage\u201d that \u201cmen of good sense\u201d can make of\nmoney. According to Cram\u00e9r, twenty million is not worth more\nthan ten million, because ten million is enough for satisfying all\ndesires an agent may reasonably have:\n\n\nmathematicians value money in proportion to its quantity, and men of\ngood sense in proportion to the usage that they may make of it. That\nwhich renders the mathematical expectation infinite, is the prodigious\nsum that I am able to receive, if the side of Heads falls only very\nlate, the 100th or 1000th toss. Now this sum, if I reason as a\nsensible man, is not more for me, does not make more pleasure for me,\ndoes not engage me more to accept the game, than if it would be only\n10 or 20 million coins. (21 May 1728)\n\n\nThe point made by Cram\u00e9r in this passage can be generalized.\nSuppose that the upper boundary of an outcome\u2019s value is\n\\(2^m.\\) If so, that outcome will be obtained if the coin lands heads\non the mth flip. This means that the expected value\nof all the infinitely many possible outcomes in which the\ncoin is flipped more than m times will be finite: It is \\(2^m\\)\ntimes the probability that this happens, so it cannot exceed \\(2^m\\).\nTo this we have to add the aggregated value of the first m\npossible outcomes, which is obviously finite. Because the sum of any\ntwo finite numbers is finite, the expected value of\nCram\u00e9r\u2019s version of the St. Petersburg game is\nfinite.\n\nCram\u00e9r was aware that it would be controversial to claim that\nthere exists an upper boundary beyond which additional riches do not\nmatter at all. However, he pointed out that his solution\nworks even if he the value of money is strictly increasing but the\nrelative increase gets smaller and smaller (21 May 1728): \n\n\nIf one wishes to suppose that the moral value of goods was as the\nsquare root of the mathematical quantities \u2026 my moral\nexpectation will be \n\\[\n\\frac{1}{2} \\cdot \\sqrt{1} + \\frac{1}{4} \\cdot \\sqrt{2} + \\frac{1}{8} \\cdot \\sqrt{4} + \\frac{1}{16} \\cdot \\sqrt{8} \\ldots \n  \\]\n\n\n\nThis is the first clear statement of what contemporary decision\ntheorists and economists refer to as decreasing marginal utility: The\nadditional utility of more money is never zero, but the richer you\nare, the less you gain by increasing your wealth further.\nCram\u00e9r correctly calculated the expected utility (\u201cmoral\nvalue\u201d) of the St. Petersburg game to be about 2.9 units for an\nagent whose utility of money is given by the root function.\n\nDaniel Bernoulli proposed a very similar idea in his famous 1738\narticle mentioned at the beginning of this section. Daniel argued that\nthe agent\u2019s utility of wealth equals the logarithm of the\nmonetary amount, which entails that improbable but large monetary\nprizes will contribute less to the expected utility of the game than\nmore probable but smaller monetary amounts. As his article was about\nto be published, Daniel\u2019s brother Nicolaus mentioned to him that\nCram\u00e9r had proposed a very similar idea in 1728 (in the letter\nquoted above). In the final version of the text, Daniel openly\nacknowledged this: \n\n\nIndeed I have found [Cram\u00e9r\u2019s] theory so similar to mine\nthat it seems miraculous that we independently reached such close\nagreement on this sort of subject. (Daniel Bernoulli 1738 [1954:\n33])\n\n2. The Modern St. Petersburg Paradox\n\nCram\u00e9r\u2019s remark about the agent\u2019s decreasing\nmarginal utility of money solves the original version of the St.\nPetersburg paradox. However, modern decision theorists agree that this\nsolution is too narrow. The paradox can be restored by increasing the\nvalues of the outcomes up to the point at which the agent is fully\ncompensated for her decreasing marginal utility of money (see Menger\n1934 [1979]). The version of the St. Petersburg paradox discussed in\nthe modern literature can thus be formulated as follows:\n\n\nA fair coin is flipped until it comes up heads. At that point the\nplayer wins a prize worth \\(2^n\\) units of utility on the\nplayer\u2019s personal utility scale, where n is the number of\ntimes the coin was flipped.\n\n\nNote that the expected utility of this gamble is infinite even if the\nagent\u2019s marginal utility of money is decreasing. We can leave it\nopen exactly what the prizes consists of. It need not be money.\n\nIt is worth stressing that none of the prizes in the St. Petersburg\ngame have infinite value. No matter how many times the coin is\nflipped, the player will always win some finite amount of\nutility. The expected utility of the St. Petersburg game\nis not finite, but the actual outcome will always be finite.\nIt would thus be a mistake to dismiss the paradox by arguing that no\nactual prizes can have infinite utility. No actual infinities are\nrequired for constructing the paradox, only potential ones. (For a\ndiscussion of the distinction between actual and potential infinities,\nsee Linnebo and Shapiro 2019.) In discussions of the St. Petersburg\nparadox it is often helpful to interpret the term \u201cinfinite\nutility\u201d as \u201cnot finite\u201d but leave it to\nphilosophers of mathematics to determine whether it is or\nmerely approaches infinity.\n\nSome authors have discussed exactly what is problematic with the claim\nthat the expected utility of the modified St. Petersburg game is\ninfinite (read: not finite). Is it merely the fact that the fair price\nof the wager is \u201ctoo high\u201d, or is there something else\nthat prompts the worry? James M. Joyce notes that \n\n\na wager of infinite utility will be strictly preferred to any\nof its payoffs since the latter are all finite. This is absurd given\nthat we are confining our attention to bettors who value wagers only\nas means to the end of increasing their fortune. (Joyce 1999: 37)\n\n\nJoyce\u2019s point seems to be that an agent who pays the fair price\nof the wager will know for sure that she will actually be\nworse off after she has paid the fee. However, this seems to\npresuppose that actual infinities do exist. If only potential\ninfinities exist, then the player cannot \u201cpay\u201d an infinite\nfee for playing the game. If so, we could perhaps interpret Joyce as\nreminding us that no matter what finite amount the player actually\nwins, the expected utility will always be higher, meaning that it\nwould have been rational to pay even more. Russell and Isaacs\n(2021:179) offer a slightly different analysis. Their point is that\n\u201chowever much the St. Petersburg gamble is worth, no particular\noutcome could be worth exactly that much\u201d. This is\nbecause the St. Petersburg gamble is worth more than any finite\noutcome, but less than something worth infinitely much.\n\n\nIs the St. Petersburg gamble perhaps worth something like an infinite\namount of money? No. The St. Petersburg gamble is sure to pay only a\nfinite amount of money. Suppose there is something which is worth\nmore than each finite amount of money\u2013such as an\ninfinite amount of money (whatever that might come to), or a priceless\nartwork, or true love. If [the agent] has something like that, then\nthe prospect of keeping it (with certainty) will dominate\ngiving it up in exchange for the St. Petersburg gamble; thus the St.\nPetersburg gamble is not worth so much. Of course, nothing is worth\nmore than each finite amount of money, yet not worth more\nthan every finite amount of money. So the conclusion of [the\nagent\u2019s] reasoning is that nothing she could bid\u2013monetary\nor otherwise\u2013would be the right price. (Russell and Isaacs\n2021:179)\n\n\nDecisions theorists wish to clarify a means-ends notion of\nrationality, according to which it is rational to do whatever is the\nbest means to one\u2019s end. The player thus knows that paying more\nthan what one actually wins cannot be the best means to the\nend of maximizing utility. But always being forced to pay too little\nis also problematic, because then the seller would \u201cpay\u201d\ntoo much (that is, receive too little). So at least one agent will be\nirrational and pay too much unless we can establish a fair price of\nthe gamble. This observation enables us to strengthen the original\n\u201cparadox\u201d (in which no formal contradiction is derived)\ninto a stronger version consisting of three incompatible claims:\n\n The amount of utility it is rational to pay for\nplaying (or selling the right to play) the St. Petersburg game is\nhigher than every finite amount of utility.\n The buyer knows that the actual amount of utility he\nor she will actually receive is finite.\n It is not rational to knowingly pay more for\nsomething than one will receive.\n\n\nMany discussions of the St. Petersburg paradox have focused on\n (1).\n As we will see in the next couple of sections, many scholars argue\nthat the value of the St. Petersburg game is, for one reason or\nanother, finite. A rare exception is H\u00e1jek and Nover. They\noffer the following argument for accepting\n (1):\n\n\nThe St Petersburg game can be regarded as the limit of a sequence of\ntruncated St Petersburg games, with successively higher finite\ntruncation points\u2014for example, the game is called off if heads\nis not reached by the tenth toss; by the eleventh toss; by the\ntwelveth toss;\u2026. If we accept dominance reasoning, these\nsuccessive truncations can guide our assessment of the St Petersburg\ngame\u2019s value: it is bounded below by each of their values, these\nbounds monotonically increasing. Thus we have a principled reason for\naccepting that it is worth paying any finite amount to play the St\nPetersburg game. (H\u00e1jek and Nover 2006: 706)\n\n\nAlthough they do not explicitly say so, H\u00e1jek and Nover would\nprobably reject\n (3).\n The least controversial claim is perhaps (2). It is, of course,\nlogically possible that the coin keeps landing tails\nevery time it is flipped, even though an infinite sequence of\ntails has probability 0. (For a discussion of this possibility, see\nWilliamson 2007.) Some events that have probability 0 do actually\noccur, and in uncountable probability spaces it is impossible that all\noutcomes have a probability greater than 0. Even so, if the coin keeps\nlanding tails every time it is flipped, the agent wins 0\nunits of utility. So\n (2)\n would still hold true.\n3. Unrealistic Assumptions?\n\nSome authors claim that the St. Petersburg game should be dismissed\nbecause it rests on assumptions that can never be fulfilled. For\ninstance, Jeffrey (1983: 154) argues that \u201canyone who offers to\nlet the agent play the St. Petersburg gamble is a liar, for he is\npretending to have an indefinitely large bank\u201d. Similar\nobjections were raised in the eighteenth century by Buffon and\nFontaine (see Dutka 1988).\n\nHowever, it is not clear why Jeffrey\u2019s point about real-world\nconstraints would be relevant. What is wrong with evaluating a highly\nidealized game we have little reason to believe we will ever get to\nplay? H\u00e1jek and Smithson (2012) point out that the St\nPetersburg paradox is contagious in the following sense: As\nlong as you assign some nonzero probability to the hypothesis that the\nbank\u2019s promise is credible, the expected utility will be\ninfinite no matter how low your credence in the hypothesis is. Any\nnonzero probability times infinity equals infinity, so any option in\nwhich you get to play the St. Petersburg game with a nonzero\nprobability has infinite expected utility.\n\nIt is also worth keeping in mind that the St. Petersburg game may not\nbe as unrealistic as Jeffrey claims. The fact that the bank does not\nhave an indefinite amount of money (or other assets) available\nbefore the coin is flipped should not be a problem. All that\nmatters is that the bank can make a credible promise to the\nplayer that the correct amount will be made available within a\nreasonable period of time after the flipping has been completed. How\nmuch money the bank has in the vault when the player plays the game is\nirrelevant. This is important because, as noted in section 2, the\namount the player actually wins will always be finite. We can thus\nimagine that the game works as follows: We first flip the coin, and\nonce we know what finite amount the bank owes the player, the CEO will\nsee to it that the bank raises enough money.\n\nIf this does not convince the player, we can imagine that the central\nbank issues a blank check in which the player gets to fill in the\ncorrect amount once the coin has been flipped. Because the check is\nissued by the central bank it cannot bounce. New money is\nautomatically created as checks issued by the central bank are\nintroduced in the economy. Jeffrey dismisses this version of the St.\nPetersburg game with the following argument:\n\n\n[Imagine that] Treasury department delivers to the winner a crisp new\nbillion billion dollar bill. Due to the resulting inflation, the\nmarginal desirabilities of such high payoffs would presumably be low\nenough to make the prospect of playing the game have finite expected\n[utility]. (Jeffrey 1983: 155)\n\n\nJeffrey is probably right that \u201ca crisp new billion billion\ndollar bill\u201d would trigger some inflation, but this seems to be\nsomething we could take into account as we construct the game. All\nthat matters is that the utilities in the payoff scheme are\nlinear.\n\nReaders who feel unconvinced by this argument may wish to imagine a\nversion of the St. Petersburg game in which the player is hooked up to\nNozick\u2019s Experience Machine (see section 2.3 in the entry on\n hedonism).\n By construction, this machine can produce any pleasurable experience\nthe agent wishes. So once the coin has been flipped n times,\nthe Experience Machine will generate a pleasurable experience worth\n\\(2^n\\) units of utility on the player\u2019s personal utility scale.\nAumann (1977) notes without explicitly mention the Experience Machine\nthat:\n\n\nThe payoffs need not be expressible in terms of a fixed finite number\nof commodities, or in terms of commodities at all [\u2026] the\nlottery ticket [\u2026] might be some kind of open-ended activity --\none that could lead to sensations that he has not heretofore\nexperienced. Examples might be religious, aesthetic, or emotional\nexperiences, like entering a monastery, climbing a mountain, or\nengaging in research with possibly spectacular results. (Aumann 1977:\n444)\n\n\nA possible example of the type of experience that Aumann has in mind\ncould be the number of days spent in Heaven. It is not clear why time\nspent in Heaven must have diminishing marginal utility. \n\nAnother type of practical worry concerns the temporal dimension of the\nSt. Petersburg game. Brito (1975) claims that the coin flipping may\nsimply take too long time. If each flip takes n seconds, we\nmust make sure it would be possible to flip it sufficiently\nmany times before the player dies. Obviously, if there exists an upper\nlimit to how many times the coin can be flipped the expected utility\nwould be finite too.\n\nA straightforward response to this worry is to imagine that the\nflipping took place yesterday and was recorded on video. The first\nflip occurred at 11 p.m. sharp, the second flip \\(\\frac{60}{2}\\)\nminutes later, the third \\(\\frac{60}{4}\\) minutes after the second,\nand so on. The video has not yet been made available to anyone, but as\nsoon as the player has paid the fee for playing the game the video\nwill be placed in the public domain. Note that the coin could in\nprinciple have been flipped infinitely many times within a single\nhour. (This is an example of a \u201csupertask\u201d; see the entry\non\n supertasks.)\n\nIt is true that this random experiment requires the coin to be flipped\nfaster and faster. At some point we would have to spin the coin faster\nthan the speed of light. This is not logically impossible\nalthough this assumption violates a contingent law of nature. If you\nfind this problematic, we can instead imagine that someone throws a\ndart on the real line between 0 and 1. The probability that the dart\nhits the first half of the interval, \\(\\left[0, \\frac{1}{2}\\right),\\)\nis \\(\\frac{1}{2}.\\) And the probability that the dart hits the next\nquarter, \\(\\left[\\frac{1}{2}, \\frac{3}{4}\\right),\\) is\n\\(\\frac{1}{4}\\), and so on. If \u201ccoin flips\u201d are generated\nin this manner the random experiment will be over in no time at all.\nTo steer clear of the worry that no real-world dart is infinitely\nsharp we can define the point at which the dart hits the real line as\nfollows: Let a be the area of the dart. The point at which the\ndart hits the interval [0,1] is defined such that half of the area of\na is to the right of some vertical line through a and\nthe other half to the left the vertical line. The point at which the\nvertical line crosses the interval [0,1] is the outcome of the random\nexperiment.\n\nIn the contemporary literature on the St. Petersburg paradox practical\nworries are often ignored, either because it is possible to imagine\nscenarios in which they do not arise, or because highly idealized\ndecision problems with unbounded utilities and infinite state spaces\nare deemed to be interesting in their own right.\n4. A Bounded Utility Function?\n\nArrow (1970: 92) suggests that the utility function of a rational\nagent should be \u201ctaken to be a bounded function.\u2026 since\nsuch an assumption is needed to avoid [the St. Petersburg]\nparadox\u201d. Basset (1987) makes a similar point; see also\nSamuelson (1977) and McClennen (1994).\n\nArrow\u2019s point is that utilities must be bounded to avoid the St.\nPetersburg paradox and that traditional axiomatic accounts of the\nexpected utility principle guarantee this to be the case. The\nwell-known axiomatizations proposed by Ramsey (1926), von Neumann and\nMorgenstern (1947), and Savage (1954) do, for instance, all entail\nthat the decision maker\u2019s utility function is bounded. (See\n section 2.3 in the entry on decision theory\n for an overview of von Neumann and Morgenstern\u2019s\naxiomatization.)\n\nIf the utility function is bounded, then the expected utility of the\nSt. Petersburg game will of course be finite. But why do the axioms of\nexpected utility theory guarantee that the utility function is\nbounded? The crucial assumption is that rationally permissible\npreferences over lotteries are continuous. To explain the\nsignificance of this axiom it is helpful to introduce some symbols.\nLet \\(\\{pA, (1-p)B\\}\\) be the lottery that results in A with\nprobability p and B with probability \\(1-p\\). The\nexpression \\(A\\preceq B\\) means that the agent considers B to\nbe at least as good as A, i.e., weakly prefers B to\nA. Moreover, \\(A\\sim B\\) means that A and B are\nequi-preferred, and \\(A\\prec B\\) means that B is preferred to\nA. Consider:\n\n\nThe Continuity Axiom: Suppose \\(A \\preceq B\\preceq C\\).\nThen there is a probability \\(p\\in [0,1]\\) such that \\(\\{pA,\n(1-p)C\\}\\sim B\\).\n\n\n\nTo explain why this axiom entails that no object can have infinite\nvalue, suppose for reductio that A is a prize check\nworth $1, B is a check worth $2, and C is a prize to\nwhich the agent assigns infinite utility. The decision maker\u2019s\npreference is \\(A\\prec B\\prec C\\), but there is no probability\np such that \\(\\{pA, (1-p)C\\sim B\\). Whenever p is\nnonzero the decision maker will strictly prefer \\(\\{pA, (1-p)C\\}\\) to\nB, and if p is 0 the decision maker will strictly prefer\nB. So because no object (lottery or outcome) can have infinite\nvalue, and a utility function is defined by the utilities it assigns\nto those objects (lotteries or outcomes), the utility function has to\nbe bounded.\n\nDoes this solve the St. Petersburg paradox? The answer depends on\nwhether we think a rational agent offered to play the St. Petersburg\ngame has any reason to accept the continuity axiom. A possible view is\nthat anyone who is offered to play the St. Petersburg game has reason\nto reject the continuity axiom. Because the St. Petersburg game has\ninfinite utility, the agent has no reason to evaluate lotteries in the\nmanner stipulated by this axiom. As explained in Section 3, we can\nimagine unboundedly valuable payoffs.\n\nSome might object that the continuity axiom, as well as the other\naxioms proposed by von Neumann and Morgenstern (and Ramsey and\nSavage), are essential for defining utility in a\nmathematically precise manner. It would therefore be\nmeaningless to talk about utility if we reject the continuity\naxiom. This axiom is part of what it means to say that something has a\nhigher utility than something else. A good response could be to\ndevelop a theory of utility in which preferences over lotteries are\nnot used for defining the meaning of the concept; see Luce (1959) for\nan early example of such a theory. Another response could be to\ndevelop a theory of utility in which the continuity axiom is\nexplicitly rejected; see Skala (1975).\n5. Ignore Small Probabilities?\n\nBuffon argued in 1777 that a rational decision maker should disregard\nthe possibility of winning lots of money in the St. Petersburg game\nbecause the probability of doing so is very low. According to Buffon,\nsome sufficiently improbable outcomes are \u201cmorally\nimpossible\u201d and should therefore be ignored. From a technical\npoint of view, this solution is very simple: The St. Petersburg\nparadox arises because the decision maker is willing to aggregate\ninfinitely many extremely valuable but highly improbable outcomes, so\nif we restrict the set of \u201cpossible\u201d outcomes by excluding\nsufficiently improbable ones the expected utility will, of course, be\nfinite.\n\nBut why should small probabilities be ignored? And how do we\ndraw the line between small probabilities that are beyond concern and\nothers that are not? Dutka summarizes Buffon\u2019s lengthy answer as\nfollows:\n\n\nTo arrive at a suitable threshold value, [Buffon] notes that a\nfifty-six year old man, believing his health to be good, would\ndisregard the probability that he would die within twenty-four hours,\nalthough mortality tables indicate that the odds against his dying in\nthis period are only 10189 to 1. Buffon thus takes a probability of\n1/10,000 or less for an event as a probability which may be\ndisregarded. (Dutka 1988: 33)\n\n\nIs this a convincing argument? According to Buffon, we ought\nto ignore some small probabilities because people like him\n(56-year-old males) do in fact ignore them. Buffon can thus\nbe accused of attempting to derive an \u201cought\u201d from an\n\u201cis\u201d. To avoid Hume\u2019s no-ought-from-an-is objection,\nBuffon would have to add a premise to the effect that people\u2019s\neveryday reactions to risk are always rational. But why should we\naccept such a premise?\n\nAnother objection is that if we ignore small probabilities, then we\nwill sometimes have to ignore all possible outcomes of an\nevent. Consider the following example: A regular deck of cards has 52\ncards, so it can be arranged in exactly 52! different ways. The\nprobability of any given arrangement is thus about 1 in \\(8 \\cdot\n10^{67}\\). This is a very small probability. (If one were to add six\ncards to the deck, then the number of possible orderings would exceed\nthe number of atoms in the known, observable universe.) However, every\ntime we shuffle a deck of cards, we know that exactly one of the\npossible outcomes will materialize, so why should we ignore\nall such very improbable outcomes?\n\nNicholas J. J. Smith (2014) defends a modern version of Buffon\u2019s\nsolution. He bases his argument on the following principle:\n\n\nRationally negligible probabilities (RNP): For any\nlottery featuring in any decision problem faced by any agent, there is\nan \\(\\epsilon > 0\\) such that the agent need not consider outcomes\nof that lottery of probability less than \\(\\epsilon\\) incoming to a\nfully rational decision. (Smith 2014: 472)\n\n\n\nSmith points out that the order of the quantifiers in RNP is crucial.\nThe claim is that for every lottery there exists some probability\nthreshold \\(\\epsilon\\) below which all probabilities should be\nignored, but it would be a mistake to think that one and the same\n\\(\\epsilon\\) is applicable to every lottery. This is important because\notherwise we could argue that RNP allows us to combine thousands or\nmillions of separate events with a probability of less than\n\\(\\epsilon.\\) It would obviously make little sense to ignore, say,\nhalf a million one-in-a-million events. By keeping in mind that that\nthe appropriate \\(\\epsilon\\) may vary from case to case this worry can\nbe dismissed.\n\nSmith also points out that if we ignore probabilities less than\n\\(\\epsilon,\\) then we have to increase some other probabilities to\nensure that all probabilities sum up to one, as required by the\nprobability axioms (see\n section 1 in the entry on interpretations of probability).\n Smith proposes a principle for doing this in a systematic manner.\n\nHowever, why should we accept RNP? What is the\nargument for accepting this controversial principle apart\nfrom the fact that it would solve the St. Petersburg paradox?\nSmith\u2019s argument goes as follows:\n\n\nInfinite precision cannot be required: rather, in any given context,\nthere must be some finite tolerance\u2014some positive threshold such\nthat ignoring all outcomes whose probabilities lie below this\nthreshold counts as satisfying the norm\u2026. There is a norm of\ndecision theory which says to ignore outcomes whose probability is\nzero. Because this norm mentions a specific probability value (zero),\nit is the kind of norm where it makes sense to impose a tolerance:\nzero plus or minus \\(\\epsilon\\) (which becomes zero plus \\(\\epsilon,\\)\ngiven that probabilities are all between 0 and 1)\u2026 the idea\nbehind (RNP) is that in any actual context in which a decision is to\nbe made, one never needs to be infinitely precise in this\nway\u2014that it never matters. There is (for each decision problem,\neach lottery therein, and each agent) some threshold such that the\nagent would not be irrational if she simply ignored outcomes whose\nprobabilities lie below that threshold. (Smith 2014:\n472\u2013474)\n\n\nSuppose we accept the claim that infinite precision is not\nrequired in decision theory. This would entail, per\nSmith\u2019s argument, that it is rationally permissible to\nignore probabilities smaller than \\(\\epsilon\\). However, to ensure\nthat the decision maker never pays a fortune for playing the St.\nPetersburg game it seems that Smith would have to defend the stronger\nclaim that decision makers are rationally required to ignore\nsmall probabilities, i.e., that it is not permissible to not ignore\nthem. Decision makers who find themselves in agreement with\nSmith\u2019s view run a risk of paying a very large amount for\nplaying the St. Petersburg game without doing anything deemed to be\nirrational by RNP. This point is important because it is arguably more\ndifficult to show that decision makers are rationally\nrequired to avoid \u201cinfinite precision\u201d in decisions\nin which this is an attainable and fully realistic goal, such as the\nSt. Petersburg game. For a critique of RNP and a discussion of some\nrelated issues, see H\u00e1jek (2014).\n\nAnother objection to RNP has been proposed by Yoaav Isaacs (2016). He\nshows that RNP together with an additional principle endorsed by Smith\n(Weak Consistency) entail that the decision maker will sometimes take\narbitrarily much risk for arbitrarily little reward.\n\nLara Buchak (2013) proposes what is arguably a more elegant version of\nthis solution. Her suggestion is that we should assign exponentially\nless weight to small probabilities as we calculate an\noption\u2019s value. A possible weighting function r discussed\nby Buchak is \\(r(p) = p^2.\\) Her proposal is, thus, that if the\nprobability is \\(\\frac{1}{8}\\) that you win $8 in addition to what you\nalready have, and your utility of money increases linearly, then\ninstead of multiplying your gain in utility by \\(\\frac{1}{8},\\) you\nshould multiply it by \\((\\frac{1}{8})^2 =\\frac{1}{64}.\\) Moreover, if\nthe probability is \\(\\frac{1}{16}\\) that you win $16 in addition to\nwhat you already have, you should multiply your gain by\n\\(\\frac{1}{256},\\) and so on. This means that small probabilities\ncontribute very little to the risk-weighted expected\nutility.\n\nBuchak\u2019s proposal vaguely resembles the familiar idea that our\nmarginal utility of money is decreasing. As stressed by Cram\u00e9r\nand Daniel Bernoulli, more money is always better than less, but the\nutility gained from each extra dollar is decreasing. According to\nBuchak, the weight we should assign to an outcome\u2019s probability\nis also nonlinear: Small probabilities matter less the smaller they\nare, and their relative importance decrease exponentially:\n\n\nThe intuition behind the diminishing marginal utility analysis of risk\naversion was that adding money to an outcome is of less value the more\nmoney the outcome already contains. The intuition behind the present\nanalysis of risk aversion is that adding probability to an outcome is\nof more value the more likely that outcome already is to obtain.\n(Buchak 2014: 1099.)\n\n\nBuchak notes that this move does not by itself solve the St.\nPetersburg paradox. For reasons that are similar to those Menger (1934\n[1979]) mentions in his comment on Bernoulli\u2019s solution, the\nparadox can be reintroduced by adjusting the outcomes such that the\nsum increases linearly (for details, see Buchak 2013: 73\u201374).\nBuchak is, for this reason, also committed to RNP, i.e., the\ncontroversial assumption that there will be some probability so small\nthat it does not make any difference to the overall value of the\ngamble.\n\nAnother worry is that because Buchak rejects the principle of\nmaximizing expected utility and replaces it with the principle of\nrisk-weighted maximizing expected utility, many of the stock\nobjections decision theorists have raised against violations of the\nexpected utility principle can be raised against her principle as\nwell. For instance, if you accept the principle of risk-weighted\nmaximizing expected utility, you have to reject the independence\naxiom. This entails that you can be exploited in some cleverly\ndesigned pragmatic argument. See Briggs (2015) for a discussion of\nsome objections to Buchak\u2019s theory.\n6. Relative Expected Utility Theory\n\nIn the Petrograd game introduced by Colyvan (2008) the player wins $1\nmore than in the St. Petersburg game regardless of how many times the\ncoin is flipped. So instead of winning 2 utility units if the coin\nlands heads on the first toss, the player wins 3; and so on. See\n Table 1.\n\nTable 1\n\nProbability\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{8}\\)\n\u2026 \n\nSt. Petersburg\n2\n4\n8\n\u2026 \n\nPetrograd\n\\(2+1\\)\n\\(4+1\\)\n\\(8+1\\)\n\u2026 \n\n\nIt seems obvious that the Petrograd game is worth more than the St.\nPetersburg game. However, it is not easy to explain why. Both games\nhave infinite expected utility, so the expected utility principle\ngives the wrong answer. It is not true that the Petrograd game is\nworth more than the St. Petersburg game because its expected utility\nis higher; the two games have exactly the same expected utility. This\nshows that the expected utility principle is not universally\napplicable to all risky choices, which is an interesting observation\nin its own right.\n\nIs the Petrograd game worth more than the St. Petersburg game because\nthe outcomes of the Petrograd game dominate those of the St.\nPetersburg game? In this context, dominance means that the player will\nalways win $1 more regardless of which state of the world turns out to\nbe the true state, that is, regardless of how many times the coin is\nflipped. The problem is that it is easy to imagine versions of the\nPetrograd game to which the dominance principle would not be\napplicable. Imagine, for instance, a version of the Petrograd game\nthat is exactly like the one in\n Table 1\n except that for some very improbable outcome (say, if the coin lands\nheads for the first time on the 100th flip) the player wins\n1 unit less than in the St. Petersburg game. This game, the\nPetrogradskij game, does not dominate the St. Petersburg game.\nHowever, since it is almost certain that the player will be better off\nby playing the Petrogradskij game a plausible decision theory should\nbe able to explain why the Petrogradskij game is worth more than the\nSt. Petersburg game.\n\nColyvan claims that we can solve this puzzle by introducing a new\nversion of expected utility theory called Relative Expected Utility\nTheory (REUT). According to REUT we should calculate the difference in\nexpected utility between the two options for each possible outcome.\nFormally, the relative expected utility (\\(\\reu\\)) of act \\(A_k\\) over\n\\(A_l\\) is \n\\[\n\\reu(A_k,A_l) = \\sum_{i=1}^n p_i(u_{ki} - u_{li}).\n\\]\n\n\nAccording to Colyvan, it is rational to choose \\(A_k\\) over \\(A_l\\) if\nand only if \\(\\reu(A_k,A_l) \\gt 0\\).\n\nColyvan\u2019s REUT neatly explains why the Petrograd game is worth\nmore than the St. Petersburg game because the relative expected\nutility is 1. REUT also explains why the Petrogradskij game is worth\nmore than the St. Petersburg game: the difference in expected utility\nis \\(1 - (\\frac{1}{2})^{100}\\) which is > 0.\n\nHowever, Peterson (2013) notes that REUT cannot explain why the\nLeningradskij game is worth more than the Leningrad\ngame (see\n Table 2).\n The Leningradskij game is the version of the Petrograd game in which\nthe player in addition to receiving a finite number of units of\nutility also gets to play the St. Petersburg game (SP) if the coin\nlands heads up in the second round. In the Leningrad game the player\ngets to play the St. Petersburg game (SP) if the coin lands heads up\nin the third round.\n\nTable 2\n\nProbability\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{16}\\)\n\u2026 \n\nLeningrad\n2\n4\n\\(8+\\textrm{SP}\\)\n16\n\u2026 \n\nLeningradskij\n2\n\\(4+\\textrm{SP}\\)\n8\n16\n\u2026\n\n\nIt is obvious that the Leningradskij game is worth more than the\nLeningrad game because the probability that the player gets to play SP\nas a bonus (which has infinite expected utility) is higher. However,\nREUT cannot explain why. The difference in expected utility for the\nstate that occurs with probability \\(\\frac{1}{4}\\) in\n Table 2\n is \\(-\\infty\\) and it is \\(+\\infty\\) for the state that occurs with\nprobability \\(\\frac{1}{8}.\\) Therefore, because \\(p \\cdot \\infty =\n\\infty\\) for all positive probabilities \\(p\\), and \u201c\\(\\infty -\n\\infty\\)\u201d is undefined in standard analysis, REUT cannot be\napplied to these games.\n\nBartha (2007) and (2016) proposes a more complex version of relative\nexpected utility theory. In Bartha\u2019s theory, the utility of an\noutcome x is compared to the utility of some alternative\noutcome y and a basepoint z, which can be chosen\narbitrarily as long as x and y are at least as preferred\nas z. The relative utility of x vis-\u00e0-vis\ny and the base-point z is then defined as the ratio\nbetween u(x) \u2013 u(z) and the\ndenominator u(y) \u2013 u(z); the\nlatter is a \u201cmeasuring stick\u201d to which\nu(x) \u2013 u(z) is compared. So\nif u(x) = 10, u(y) = 20 and\nu(z)= 0, then the relative utility of x\nvis-\u00e0-vis y and the base-point z is\nU(x, y; z) = 0.5.\n\nBartha\u2019s suggestion is to ask the agent to compare the St.\nPetersburg game to a lottery between two other games. If, for\ninstance, Petrograd+ is the game in which the player always\nwins 2 units more than in the St. Petersburg game regardless of how\nmany times the coin is tossed, then the player could compare the\nPetrograd game to a lottery between Petrograd+ and the St.\nPetersburg game. By determining for what probabilities p a\nlottery in which one plays Petrograd+ with probability\np and the St. Petersburg game with probability \\(1-p\\) is\nbetter than playing the Petrograd game for sure one can establish a\nmeasure of the relative value of Petrograd as compared to\nPetrograd+ or St. Petersburg. (For details, see Sect. 5 in\nBartha 2016. See also Colyvan and H\u00e1jek\u2019s 2016 discussion\nof Bartha\u2019s theory.) \n\nAn odd feature of Bartha\u2019s theory is that two lotteries can have\nthe same relative utility even if one is strictly\npreferred to the other; see Bartha (2011: 34\u201335). This indicates\nthat the relative utilities assigned to lotteries in Bartha\u2019s\ntheory are not always choice-guiding. \n\nLet us also mention another, quite simple variation of the original\nSt. Petersburg game, which is played as follows (see Peterson 2015:\n87): A manipulated coin lands heads up with probability 0.4 and the\nplayer wins a prize worth \\(2^n\\) units of utility, where n is\nthe number of times the coin was tossed. This game, the Moscow game,\nis more likely to yield a long sequence of flips and is therefore\nworth more than the St. Petersburg game, but the expected utility of\nboth games is the same, because both games have infinite expected\nutility. It might be tempting to say that the Moscow game is more\nattractive because the Moscow game stochastically dominates\nthe St. Petersburg game. (That one game stochastically dominates\nanother game means that for every possible outcome, the first game has\nat least as high a probability of yielding a prize worth at least\nu units of utility as the second game; and for some u,\nthe first game yields u with a higher probability than the\nsecond.) However, the stochastic dominance principle is inapplicable\nto games in which there is a small risk that the player wins a prize\nworth slightly less than in the other game. We can, for instance,\nimagine that if the coin lands heads on the 100th flip the\nMoscow game pays one unit less than the St. Petersburg game; in this\nscenario neither game stochastically dominates the other. Despite\nthis, it still seems reasonable to insist that the game that is almost\ncertain to yield a better outcome (in the sense explained above) is\nworth more. The challenge is to explain why in a robust and\nnon-arbitrary way.\n7. The Pasadena Game\n\nThe Pasadena paradox introduced by Nover and H\u00e1jek (2004) is\ninspired by the St. Petersburg game, but the pay-off schedule is\ndifferent. As usual, a fair coin is flipped n times until it\ncomes up heads for the first time. If n is odd the player wins\n\\((2^n)/n\\) units of utility; however, if n is even the player\nhas to pay \\((2^n)/n\\) units. How much should one be willing\nto pay for playing this game?\n\nIf we sum up the terms in the temporal order in which the outcomes\noccur and calculate expected utility in the usual manner we find that\nthe Pasadena game is worth:\n\n\n\\[\\begin{align}\n\\frac{1}{2}\\cdot\\frac{2}{1} - \\frac{1}{4}\\cdot\\frac{4}{2} + \\frac{1}{8}\\cdot\\frac{8}{3}\n &- \\frac{1}{16}\\cdot\\frac{16}{4} + \\frac{1}{32}\\cdot\\frac{16}{5} - \\cdots  \\\\\n &= 1 - \\frac{1}{2} + \\frac{1}{3} - \\frac{1}{4} + \\frac{1}{5} - \\cdots \\\\\n &= \\sum_n \\frac{(-1)^{n-1}}{n}\n\\end{align}\\]\n \n\nThis infinite sum converges to ln 2 (about 0.69 units of\nutility). However, Nover and H\u00e1jek point out that we would\nobtain a very different result if we were to rearrange the order in\nwhich the very same numbers are summed up. Here is one of many\npossible examples of this mathematical fact: \n\\[\\begin{align}\n1 - \\frac{1}{2} - \\frac{1}{4} + \\frac{1}{3} - \\frac{1}{6} - \\frac{1}{8}\n  + \\frac{1}{5} - \\frac{1}{10} &- \\frac{1}{12} + \\frac{1}{7} - \\frac{1}{14}\n  - \\frac{1}{16} \\cdots \\\\\n &= \\frac{1}{2}(\\ln 2).\n\\end{align}\\]\n\n\nThis is, of course, not news to mathematicians. The infinite sum\nproduced by the Pasadena game is known as the alternating harmonic\nseries, which is a conditionally convergent series. (A\nseries \\(a_n\\) is conditionally convergent if \\(\\sum_{j=1}^{\\infty}\na_n\\) converges but \\(\\sum_{j=1}^{\\infty} \\lvert a_n\\rvert\\)\ndiverges.) Because of a theorem known as the Riemann rearrangement\ntheorem, we know that if an infinite series is conditionally\nconvergent, then its terms can always be rearranged such the sum\nconverges to any finite number, or to \\(+\\infty\\) or to\n\\(-\\infty\\).\n\nNover and H\u00e1jek\u2019s point is that it seems\narbitrary to sum up the terms in the Pasadena game in the\ntemporal order produced by the coin flips. To see why, it is helpful\nto imagine a slightly modified version of the game. In their original\npaper, Nover and H\u00e1jek ask us to imagine that:\n\n\nWe toss a fair coin until it lands heads for the first time. We have\nwritten on consecutive cards your pay-off for each possible outcome.\nThe cards read as follows: (Top card) If the first =heads is on toss\n#1, we pay you $2. [\u2026] By accident, we drop the cards, and\nafter picking them up and stacking them on the table, we find that\nthey have been rearranged. No matter, you say\u2014obviously the game\nhas not changed, since the pay-off schedule remains the same. The\ngame, after all, is correctly and completely specified by the\nconditionals written on the cards, and we have merely changed the\norder in which the conditions are presented. (Nover and H\u00e1jek\n2004: 237\u2013239)\n\n\nUnder the circumstances described here, we seem to have no\nreason to prefer any particular order in which to sum up the terms of\nthe infinite series. So is the expected value of Pasadena game \\(\\ln\n2\\) or \\(\\frac{1}{2}(\\ln 2)\\) or \\(\\frac{1}{3}\\) or \\(-\\infty\\) or\n345.68? All these suggestions seem equally arbitrary. Moreover, the\nsame holds true for the Altadena game, in which every payoff is\nincreased by one dollar. The Altadena game is clearly better than then\nPasadena game, but advocates of expected utility theory seem unable to\nexplain why.\n\nThe literature on the Pasadena game is extensive. See, e.g.,\nH\u00e1jek and Nover (2006), Fine (2008), Smith (2014), and Bartha\n(2016). A particularly influential solution is due to Easwaran (2008).\nHe introduces a distinction between a strong and a weak version of the\nexpected utility principle, inspired by the well-known distinction\nbetween the strong and weak versions of the law of large numbers.\nAccording to the strong law of large numbers, the average utility of a\ngame converges to its expected utility with probability one as the\nnumber of iterations goes to infinity. The weak law of large numbers\nholds that for a sufficiently large set of trials the probability can\nbe made arbitrarily small that that the average utility will not\ndiffer from the expected utility by more than some small pre-specified\namount. So according to the weak expected utility principle, \n\n\nby fixing in advance a high enough number of n plays, the\naverage payoff per play can be almost guaranteed to be arbitrarily\nclose to ln 2, \n\n\nwhile the strong version of the principle entails that \n\n\nif one player keeps getting to decide whether to play again or quit,\nthen she can almost certainly guarantee as much profit as she wants,\nregardless of the (constant) price per play. (Easwaran 2008: 635) \n\n\nEaswaran\u2019s view is that the weak expected utility principle\nshould guide the agent\u2019s choice and that the fair price to pay\nis ln 2.\n\nHowever, Easwaran\u2019s solution cannot be generalized to other\ngames with slightly different payoff schemes. Bartha (2016: 805)\ndescribes a version of the Pasadena game that has no expected value.\nIn this game, the Arroyo game, the player wins \\(-1^{n+1}(n+1)\\) with\nprobability \\(p_n = \\frac{1}/{(n+1)}\\). If we calculate the expected\nutility in the order in which the outcomes are produced, we get the\nsame result as for the Pasadena game: \\(1 - \\frac{1}{2} + \\frac{1}{3}\n- \\frac{1}{4} \\cdots\\) For reasons explained (and proved) by Bartha,\nthe Arroyo game has no weak expected utility.\n\nIt is also worth keeping in mind that Pasadena-like scenarios can\narise in non-probabilistic contexts (see Peterson 2013). Imagine, for\ninstance, an infinite population in which the utility of individual\nnumber j is \\(\\frac{(-1)^{j-1}}{j}\\). What is the total utility\nof this population? Or imagine that you are the proud owner of a\nJackson Pollock painting. An art dealer tells you the overall\naesthetic value of the painting is the sum of some of its\nparts. You number the points in the painting with arbitrary\nnumbers 1, 2, 3, \u2026 (perhaps by writing down the numbers on\ncards and then dropping all cards on the floor); the aesthetic value\nof each point j is \\(\\frac{(-1)^{j-1}}{j}\\). What is the total\naesthetic value of the painting? These examples are non-probabilistic\nversions of the Pasadena problem, to which the expected utility\nprinciple is inapplicable. There is no uncertainty about any state of\nnature; the decision maker knows for sure what the world is like. This\nmeans that Easwaran\u2019s distinction between weak and strong\nexpectations is not applicable.\n\nAlthough some of these problems may appear to be somewhat esoteric, we\ncannot dismiss them. All Pasadena-like problems are vulnerable to the\nsame contagion problem as the St Petersburg game (see\n section 2).\n H\u00e1jek and Smithson offer the following colorful\nillustration:\n\n\nYou can choose between pizza and Chinese for dinner. Each\noption\u2019s desirability depends on how you weigh probabilistically\nvarious scenarios (burnt pizza, perfectly cooked pizza,\u2026\nover-spiced Chinese, perfectly spiced Chinese\u2026) and the\nutilities you accord them. Let us stipulate that neither choice\ndominates the other, yet it should be utterly straightforward for you\nto make a choice. But it is not if the expectations of pizza and\nChinese are contaminated by even a miniscule [sic] assignment of\ncredence to the Pasadena game. If the door is opened to it just a\ncrack, it kicks the door down and swamps all expected utility\ncalculations. You cannot even choose between pizza and Chinese.\n(H\u00e1jek and Smithson 2012: 42, emph. added.)\n\n\nColyvan (2006) suggests that we should bite the bullet on the Pasadena\ngame and accept that it has no expected utility. The\ncontagion problem shows that if we were to do so, we would have to\nadmit that the principle of maximizing expected utility would be\napplicable to nearly no decisions. Moreover, because the\ncontagion problem is equally applicable to all games discussed in this\nentry (St. Petersburg, Pasadena, Arroyo, etc.) it seems that all these\nproblems may require a unified solution.\n\nFor hundreds of years, decision theorists have agreed that rational\nagents should maximize expected utility. The discussion has mostly\nbeen focused on how to interpret this principle, especially for\nchoices in which the causal structure of the world is unusual.\nHowever, until recently no one has seriously questioned that the\nprinciple of maximizing expected utility is the right principle to\napply. The rich and growing literature on the many puzzles inspired by\nthe St. Petersburg paradox indicate that this might have been a\nmistake. Perhaps the principle of maximizing expected utility should\nbe replaced by some entirely different principle?\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Alexander, J. M., 2011, \u201cExpectations and\nChoiceworthiness\u201d, <em>Mind</em>, 120(479): 803\u2013817.\ndoi:10.1093/mind/fzr049",
                "Arrow, Kenneth J., 1970, <em>Essays in the Theory of\nRisk-Bearing</em>, Amsterdam: North-Holland.",
                "Aumann, Robert J., 1977, \u201cThe St. Petersburg Paradox: A\nDiscussion of Some Recent Comments\u201d, <em>Journal of Economic\nTheory</em>, 14(2): 443\u2013445.\ndoi:10.1016/0022-0531(77)90143-0",
                "Bartha, Paul, 2007, \u201cTaking Stock of Infinite Value:\nPascal\u2019s Wager and Relative Utilities\u201d, <em>Synthese</em>,\n154(1): 5\u201352.",
                "Bartha, Paul, Barker, John and H\u00e1jek, Alan, 2014,\n\u201cSatan, Saint Peter and Saint Petersburg: Decision Theory and\nDiscontinuity at Infinity\u201d, <em>Synthese</em>, 191(4):\n629\u2013660.",
                "Bartha, Paul F. A., 2016, \u201cMaking Do Without\nExpectations\u201d, <em>Mind</em>, 125(499): 799\u2013827.\ndoi:10.1093/mind/fzv152",
                "Bassett, Gilbert W., 1987, \u201cThe St. Petersburg Paradox and\nBounded Utility\u201d, <em>History of Political Economy</em>, 19(4):\n517\u2013523. doi:10.1215/00182702-19-4-517",
                "Bernoulli, Daniel, 1738 [1954], \u201cSpecimen Theoriae Novae de\nMensura Sortis\u201d, <em>Commentarii Academiae Scientiarum\nImperialis Petropolitanae</em>, 5: 175\u2013192. English translation,\n1954, \u201cExposition of a New Theory on the Measurement of\nRisk\u201d, <em>Econometrica</em>, 22(1): 23\u201336.\ndoi:10.2307/1909829",
                "Bernoulli, Jakob, 1975, <em>Die Werke von Jakob Bernoulli</em>,\nBand III, Basel: Birkh\u00e4user. A translation from this by Richard\nJ. Pulskamp of\n <a href=\"https://web.archive.org/web/20200725100737/http://cerebro.xu.edu/math/Sources/NBernoulli/correspondence_petersburg_game.pdf\" target=\"other\">Nicolas Bernoulli\u2019s letters concerning the St. Petersburg Game is available online</a>.",
                "Briggs, Rachael, 2015, \u201cCosts of Abandoning the Sure-Thing\nPrinciple\u201d, <em>Canadian Journal of Philosophy</em>,\n45(5\u20136): 827\u2013840. doi:10.1080/00455091.2015.1122387",
                "Brito, D.L, 1975, \u201cBecker\u2019s Theory of the Allocation\nof Time and the St. Petersburg Paradox\u201d, <em>Journal of Economic\nTheory</em>, 10(1): 123\u2013126.\ndoi:10.1016/0022-0531(75)90067-8",
                "Buchak, Lara, 2013, <em>Risk and Rationality</em>, New York:\nOxford University Press.\ndoi:10.1093/acprof:oso/9780199672165.001.0001",
                "\u2013\u2013\u2013, 2014, \u201cRisk and Tradeoffs\u201d,\n<em>Erkenntnis</em>, 79(S6): 1091\u20131117.\ndoi:10.1007/s10670-013-9542-4",
                "Buffon, G. L. L., 1777, \u201cEssai\nd\u2019Arithmd\u00e9\u00e9tique Motale\u201d, in\n<em>Suppl\u00e9ments \u00e0 l\u2019Histoire Naturelle</em>.\nReprinted in <em>Oeuvres Philosophiques de Buffon</em>, Paris,\n1954.",
                "Chalmers, David J., 2002, \u201cThe St. Petersburg Two-Envelope\nParadox\u201d, <em>Analysis</em>, 62(2): 155\u2013157.\ndoi:10.1093/analys/62.2.155",
                "Chen, Eddy Keming and Daniel Rubio, forthcoming, \u201cSurreal\nDecisions\u201d, <em>Philosophy and Phenomenological Research</em>,\nFirst online: 5 June 2018. doi:10.1111/phpr.12510",
                "Colyvan, Mark, 2006, \u201cNo Expectations\u201d, <em>Mind</em>,\n115(459): 695\u2013702. doi:10.1093/mind/fzl695",
                "\u2013\u2013\u2013, 2008, \u201cRelative Expectation\nTheory\u201d:, <em>Journal of Philosophy</em>, 105(1): 37\u201344.\ndoi:10.5840/jphil200810519",
                "Colyvan, Mark and Alan H\u00e1jek, 2016, \u201cMaking Ado\nWithout Expectations\u201d:, <em>Mind</em>, 125(499): 829\u2013857.\ndoi:10.1093/mind/fzv160",
                "Cowen, Tyler and Jack High, 1988, \u201cTime, Bounded Utility,\nand the St. Petersburg Paradox\u201d, <em>Theory and Decision</em>,\n25(3): 219\u2013223. doi:10.1007/BF00133163",
                "Dutka, Jacques, 1988, \u201cOn the St. Petersburg Paradox\u201d,\n<em>Archive for History of Exact Sciences</em>, 39(1): 13\u201339.\ndoi:10.1007/BF00329984",
                "Easwaran, Kenny, 2008, \u201cStrong and Weak Expectations\u201d,\n<em>Mind</em>, 117(467): 633\u2013641. doi:10.1093/mind/fzn053",
                "Fine, Terrence L., 2008, \u201cEvaluating the Pasadena, Altadena,\nand St Petersburg Gambles\u201d, <em>Mind</em>, 117(467):\n613\u2013632. doi:10.1093/mind/fzn037",
                "H\u00e1jek, Alan, 2014, \u201cUnexpected Expectations\u201d,\n<em>Mind</em>, 123(490): 533\u2013567. doi:10.1093/mind/fzu076",
                "H\u00e1jek, Alan and Harris Nover, 2006, \u201cPerplexing\nExpectations\u201d, <em>Mind</em>, 115(459): 703\u2013720.\ndoi:10.1093/mind/fzl703",
                "\u2013\u2013\u2013, 2008, \u201cComplex Expectations\u201d,\n<em>Mind</em>, 117(467): 643\u2013664. doi:10.1093/mind/fzn086",
                "H\u00e1jek, Alan and Michael Smithson, 2012, \u201cRationality\nand Indeterminate Probabilities\u201d, <em>Synthese</em>, 187(1):\n33\u201348. doi:10.1007/s11229-011-0033-3",
                "Isaacs, Yoaav, 2016, \u201cProbabilities Cannot Be Rationally\nNeglected\u201d, <em>Mind</em>, 125(499): 759\u2013762.\ndoi:10.1093/mind/fzv151",
                "Jeffrey, Richard C., 1983, <em>The Logic of Decision</em>, 2nd\nedition, Chicago: University of Chicago Press.",
                "Jordan, Jeff, 1994, \u201cThe St. Petersburg Paradox and\nPascal\u2019s Wager\u201d, <em>Philosophia</em>, 23(1\u20134):\n207\u2013222. doi:10.1007/BF02379856",
                "Joyce, James M., 1999, <em>The Foundations of Causal Decision\nTheory</em>, Cambridge: Cambridge University Press.",
                "Lauwers, Luc and Peter Vallentyne, 2016, \u201cDecision Theory\nwithout Finite Standard Expected Value\u201d, <em>Economics and\nPhilosophy</em>, 32(3): 383\u2013407.\ndoi:10.1017/S0266267115000334",
                "Linnebo, \u00d8ystein and Stewart Shapiro, 2019, \u201cActual\nand Potential Infinity: Actual and Potential Infinity\u201d,\n<em>No\u00fbs</em>, 53(1): 160\u2013191. doi:10.1111/nous.12208",
                "Luce, R. Duncan, 1959, \u201cOn the Possible Psychophysical\nLaws\u201d, <em>Psychological Review</em>, 66(2): 81\u201395.\ndoi:10.1037/h0043178",
                "McClennen, Edward F., 1994, \u201cPascal\u2019s Wager and Finite\nDecision Theory\u201d, in <em>Gambling on God: Essays on\nPascal\u2019s Wager</em>, Jeff Jordan (ed.), Boston: Rowman &amp;\nLittlefield, 115\u2013138.",
                "McCutcheon, Randall G., 2021, \u201cHow to co-exist with\nnonexistent expectations\u201d, <em>Synthese</em>, 198(3):\n2783\u20132799.",
                "Menger, Karl, 1934 [1979], \u201cDas Unsicherheitsmoment in der\nWertlehre: Betrachtungen im Anschlu\u00df an das sogenannte\nPetersburger Spiel\u201d, <em>Zeitschrift f\u00fcr\nNational\u00f6konomie</em>, 5(4): 459\u2013485. Translated, 1979, as\n\u201cThe Role of Uncertainty in Economics\u201d, in Menger\u2019s\n<em>Selected Papers in Logic and Foundations, Didactics,\nEconomics</em>, Dordrecht: Springer Netherlands, 259\u2013278.\ndoi:10.1007/BF01311578 (de) doi:10.1007/978-94-009-9347-1_25 (en)\n",
                "Nover, Harris and Alan H\u00e1jek, 2004, \u201cVexing\nExpectations\u201d, <em>Mind</em>, 113(450): 237\u2013249.\ndoi:10.1093/mind/113.450.237",
                "Peterson, Martin, 2011, \u201cA New Twist to the St. Petersburg\nParadox\u201d:, <em>Journal of Philosophy</em>, 108(12):\n697\u2013699. doi:10.5840/jphil20111081239",
                "\u2013\u2013\u2013, 2013, \u201cA Generalization of the\nPasadena Puzzle: A Generalization of the Pasadena Puzzle\u201d,\n<em>Dialectica</em>, 67(4): 597\u2013603.\ndoi:10.1111/1746-8361.12046",
                "\u2013\u2013\u2013, 2009 [2017], <em>An Introduction to\nDecision Theory</em>, Cambridge: Cambridge University Press; second\nedition 2017. doi:10.1017/CBO9780511800917\ndoi:10.1017/9781316585061",
                "\u2013\u2013\u2013, 2019, \u201cInterval Values and Rational\nChoice\u201d, <em>Economics and Philosophy</em>, 35(1):\n159\u2013166. doi:10.1017/S0266267118000147",
                "Ramsey, Frank Plumpton, 1926 [1931], \u201cTruth and\nProbability\u201d, printed in <em>The Foundations of Mathematics and\nOther Logical Essays</em>, R. B. Braithwaite (ed.), London: Kegan\nPaul, Trench, Trubner &amp; Co., 156\u2013198. Reprinted in\n<em>Philosophy of Probability: Contemporary Readings</em>, Antony\nEagle (ed.), New York: Routledge, 2011: 52\u201394.\n [<a href=\"https://econpapers.repec.org/bookchap/hayhetcha/ramsey1926.htm\" target=\"other\">Ramsey 1926 [1931] available online</a>]",
                "Russell, Jeffrey Sanford and Isaacs, Yoaav, 2021, \u201cInfinite\nProspects\u201d, <em>Philosophy and Phenomenological Research</em>,\n103(1): 178\u2013198.",
                "Samuelson, Paul A., 1977, \u201cSt. Petersburg Paradoxes:\nDefanged, Dissected, and Historically Described\u201d, <em>Journal of\nEconomic Literature</em>, 15(1): 24\u201355.",
                "Savage, Leonard J., 1954, <em>The Foundations of Statistics</em>,\n(Wiley Publications in Statistics), New York: Wiley. Second edition,\nCourier Corporation, 1974.",
                "Skala, Heinz J., 1975, <em>Non-Archimedean Utility Theory</em>,\nDordrecht: D. Reidel.",
                "Smith, Nicholas J. J., 2014, \u201cIs Evaluative Compositionality\na Requirement of Rationality?\u201d, <em>Mind</em>, 123(490):\n457\u2013502. doi:10.1093/mind/fzu072",
                "von Neumann, John and Oskar Morgenstern, 1947, <em>Theory of Games\nand Economic Behavior</em>, second revised edtion, Princeton, NJ:\nPrinceton University Press.",
                "Weirich, Paul, 1984, \u201cThe St. Petersburg Gamble and\nRisk\u201d, <em>Theory and Decision</em>, 17(2): 193\u2013202.\ndoi:10.1007/BF00160983",
                "Williamson, Timothy, 2007, \u201cHow Probable Is an Infinite\nSequence of Heads?\u201d, <em>Analysis</em>, 67(295): 173\u2013180.\ndoi:10.1111/j.1467-8284.2007.00671.x"
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Alexander, J. M., 2011, \u201cExpectations and\nChoiceworthiness\u201d, <em>Mind</em>, 120(479): 803\u2013817.\ndoi:10.1093/mind/fzr049</li>\n<li>Arrow, Kenneth J., 1970, <em>Essays in the Theory of\nRisk-Bearing</em>, Amsterdam: North-Holland.</li>\n<li>Aumann, Robert J., 1977, \u201cThe St. Petersburg Paradox: A\nDiscussion of Some Recent Comments\u201d, <em>Journal of Economic\nTheory</em>, 14(2): 443\u2013445.\ndoi:10.1016/0022-0531(77)90143-0</li>\n<li>Bartha, Paul, 2007, \u201cTaking Stock of Infinite Value:\nPascal\u2019s Wager and Relative Utilities\u201d, <em>Synthese</em>,\n154(1): 5\u201352.</li>\n<li>Bartha, Paul, Barker, John and H\u00e1jek, Alan, 2014,\n\u201cSatan, Saint Peter and Saint Petersburg: Decision Theory and\nDiscontinuity at Infinity\u201d, <em>Synthese</em>, 191(4):\n629\u2013660.</li>\n<li>Bartha, Paul F. A., 2016, \u201cMaking Do Without\nExpectations\u201d, <em>Mind</em>, 125(499): 799\u2013827.\ndoi:10.1093/mind/fzv152</li>\n<li>Bassett, Gilbert W., 1987, \u201cThe St. Petersburg Paradox and\nBounded Utility\u201d, <em>History of Political Economy</em>, 19(4):\n517\u2013523. doi:10.1215/00182702-19-4-517</li>\n<li>Bernoulli, Daniel, 1738 [1954], \u201cSpecimen Theoriae Novae de\nMensura Sortis\u201d, <em>Commentarii Academiae Scientiarum\nImperialis Petropolitanae</em>, 5: 175\u2013192. English translation,\n1954, \u201cExposition of a New Theory on the Measurement of\nRisk\u201d, <em>Econometrica</em>, 22(1): 23\u201336.\ndoi:10.2307/1909829</li>\n<li>Bernoulli, Jakob, 1975, <em>Die Werke von Jakob Bernoulli</em>,\nBand III, Basel: Birkh\u00e4user. A translation from this by Richard\nJ. Pulskamp of\n <a href=\"https://web.archive.org/web/20200725100737/http://cerebro.xu.edu/math/Sources/NBernoulli/correspondence_petersburg_game.pdf\" target=\"other\">Nicolas Bernoulli\u2019s letters concerning the St. Petersburg Game is available online</a>.</li>\n<li>Briggs, Rachael, 2015, \u201cCosts of Abandoning the Sure-Thing\nPrinciple\u201d, <em>Canadian Journal of Philosophy</em>,\n45(5\u20136): 827\u2013840. doi:10.1080/00455091.2015.1122387</li>\n<li>Brito, D.L, 1975, \u201cBecker\u2019s Theory of the Allocation\nof Time and the St. Petersburg Paradox\u201d, <em>Journal of Economic\nTheory</em>, 10(1): 123\u2013126.\ndoi:10.1016/0022-0531(75)90067-8</li>\n<li>Buchak, Lara, 2013, <em>Risk and Rationality</em>, New York:\nOxford University Press.\ndoi:10.1093/acprof:oso/9780199672165.001.0001</li>\n<li>\u2013\u2013\u2013, 2014, \u201cRisk and Tradeoffs\u201d,\n<em>Erkenntnis</em>, 79(S6): 1091\u20131117.\ndoi:10.1007/s10670-013-9542-4</li>\n<li>Buffon, G. L. L., 1777, \u201cEssai\nd\u2019Arithmd\u00e9\u00e9tique Motale\u201d, in\n<em>Suppl\u00e9ments \u00e0 l\u2019Histoire Naturelle</em>.\nReprinted in <em>Oeuvres Philosophiques de Buffon</em>, Paris,\n1954.</li>\n<li>Chalmers, David J., 2002, \u201cThe St. Petersburg Two-Envelope\nParadox\u201d, <em>Analysis</em>, 62(2): 155\u2013157.\ndoi:10.1093/analys/62.2.155</li>\n<li>Chen, Eddy Keming and Daniel Rubio, forthcoming, \u201cSurreal\nDecisions\u201d, <em>Philosophy and Phenomenological Research</em>,\nFirst online: 5 June 2018. doi:10.1111/phpr.12510</li>\n<li>Colyvan, Mark, 2006, \u201cNo Expectations\u201d, <em>Mind</em>,\n115(459): 695\u2013702. doi:10.1093/mind/fzl695</li>\n<li>\u2013\u2013\u2013, 2008, \u201cRelative Expectation\nTheory\u201d:, <em>Journal of Philosophy</em>, 105(1): 37\u201344.\ndoi:10.5840/jphil200810519</li>\n<li>Colyvan, Mark and Alan H\u00e1jek, 2016, \u201cMaking Ado\nWithout Expectations\u201d:, <em>Mind</em>, 125(499): 829\u2013857.\ndoi:10.1093/mind/fzv160</li>\n<li>Cowen, Tyler and Jack High, 1988, \u201cTime, Bounded Utility,\nand the St. Petersburg Paradox\u201d, <em>Theory and Decision</em>,\n25(3): 219\u2013223. doi:10.1007/BF00133163</li>\n<li>Dutka, Jacques, 1988, \u201cOn the St. Petersburg Paradox\u201d,\n<em>Archive for History of Exact Sciences</em>, 39(1): 13\u201339.\ndoi:10.1007/BF00329984</li>\n<li>Easwaran, Kenny, 2008, \u201cStrong and Weak Expectations\u201d,\n<em>Mind</em>, 117(467): 633\u2013641. doi:10.1093/mind/fzn053</li>\n<li>Fine, Terrence L., 2008, \u201cEvaluating the Pasadena, Altadena,\nand St Petersburg Gambles\u201d, <em>Mind</em>, 117(467):\n613\u2013632. doi:10.1093/mind/fzn037</li>\n<li>H\u00e1jek, Alan, 2014, \u201cUnexpected Expectations\u201d,\n<em>Mind</em>, 123(490): 533\u2013567. doi:10.1093/mind/fzu076</li>\n<li>H\u00e1jek, Alan and Harris Nover, 2006, \u201cPerplexing\nExpectations\u201d, <em>Mind</em>, 115(459): 703\u2013720.\ndoi:10.1093/mind/fzl703</li>\n<li>\u2013\u2013\u2013, 2008, \u201cComplex Expectations\u201d,\n<em>Mind</em>, 117(467): 643\u2013664. doi:10.1093/mind/fzn086</li>\n<li>H\u00e1jek, Alan and Michael Smithson, 2012, \u201cRationality\nand Indeterminate Probabilities\u201d, <em>Synthese</em>, 187(1):\n33\u201348. doi:10.1007/s11229-011-0033-3</li>\n<li>Isaacs, Yoaav, 2016, \u201cProbabilities Cannot Be Rationally\nNeglected\u201d, <em>Mind</em>, 125(499): 759\u2013762.\ndoi:10.1093/mind/fzv151</li>\n<li>Jeffrey, Richard C., 1983, <em>The Logic of Decision</em>, 2nd\nedition, Chicago: University of Chicago Press.</li>\n<li>Jordan, Jeff, 1994, \u201cThe St. Petersburg Paradox and\nPascal\u2019s Wager\u201d, <em>Philosophia</em>, 23(1\u20134):\n207\u2013222. doi:10.1007/BF02379856</li>\n<li>Joyce, James M., 1999, <em>The Foundations of Causal Decision\nTheory</em>, Cambridge: Cambridge University Press.</li>\n<li>Lauwers, Luc and Peter Vallentyne, 2016, \u201cDecision Theory\nwithout Finite Standard Expected Value\u201d, <em>Economics and\nPhilosophy</em>, 32(3): 383\u2013407.\ndoi:10.1017/S0266267115000334</li>\n<li>Linnebo, \u00d8ystein and Stewart Shapiro, 2019, \u201cActual\nand Potential Infinity: Actual and Potential Infinity\u201d,\n<em>No\u00fbs</em>, 53(1): 160\u2013191. doi:10.1111/nous.12208</li>\n<li>Luce, R. Duncan, 1959, \u201cOn the Possible Psychophysical\nLaws\u201d, <em>Psychological Review</em>, 66(2): 81\u201395.\ndoi:10.1037/h0043178</li>\n<li>McClennen, Edward F., 1994, \u201cPascal\u2019s Wager and Finite\nDecision Theory\u201d, in <em>Gambling on God: Essays on\nPascal\u2019s Wager</em>, Jeff Jordan (ed.), Boston: Rowman &amp;\nLittlefield, 115\u2013138.</li>\n<li>McCutcheon, Randall G., 2021, \u201cHow to co-exist with\nnonexistent expectations\u201d, <em>Synthese</em>, 198(3):\n2783\u20132799.</li>\n<li>Menger, Karl, 1934 [1979], \u201cDas Unsicherheitsmoment in der\nWertlehre: Betrachtungen im Anschlu\u00df an das sogenannte\nPetersburger Spiel\u201d, <em>Zeitschrift f\u00fcr\nNational\u00f6konomie</em>, 5(4): 459\u2013485. Translated, 1979, as\n\u201cThe Role of Uncertainty in Economics\u201d, in Menger\u2019s\n<em>Selected Papers in Logic and Foundations, Didactics,\nEconomics</em>, Dordrecht: Springer Netherlands, 259\u2013278.\ndoi:10.1007/BF01311578 (de) doi:10.1007/978-94-009-9347-1_25 (en)\n</li>\n<li>Nover, Harris and Alan H\u00e1jek, 2004, \u201cVexing\nExpectations\u201d, <em>Mind</em>, 113(450): 237\u2013249.\ndoi:10.1093/mind/113.450.237</li>\n<li>Peterson, Martin, 2011, \u201cA New Twist to the St. Petersburg\nParadox\u201d:, <em>Journal of Philosophy</em>, 108(12):\n697\u2013699. doi:10.5840/jphil20111081239</li>\n<li>\u2013\u2013\u2013, 2013, \u201cA Generalization of the\nPasadena Puzzle: A Generalization of the Pasadena Puzzle\u201d,\n<em>Dialectica</em>, 67(4): 597\u2013603.\ndoi:10.1111/1746-8361.12046</li>\n<li>\u2013\u2013\u2013, 2009 [2017], <em>An Introduction to\nDecision Theory</em>, Cambridge: Cambridge University Press; second\nedition 2017. doi:10.1017/CBO9780511800917\ndoi:10.1017/9781316585061</li>\n<li>\u2013\u2013\u2013, 2019, \u201cInterval Values and Rational\nChoice\u201d, <em>Economics and Philosophy</em>, 35(1):\n159\u2013166. doi:10.1017/S0266267118000147</li>\n<li>Ramsey, Frank Plumpton, 1926 [1931], \u201cTruth and\nProbability\u201d, printed in <em>The Foundations of Mathematics and\nOther Logical Essays</em>, R. B. Braithwaite (ed.), London: Kegan\nPaul, Trench, Trubner &amp; Co., 156\u2013198. Reprinted in\n<em>Philosophy of Probability: Contemporary Readings</em>, Antony\nEagle (ed.), New York: Routledge, 2011: 52\u201394.\n [<a href=\"https://econpapers.repec.org/bookchap/hayhetcha/ramsey1926.htm\" target=\"other\">Ramsey 1926 [1931] available online</a>]</li>\n<li>Russell, Jeffrey Sanford and Isaacs, Yoaav, 2021, \u201cInfinite\nProspects\u201d, <em>Philosophy and Phenomenological Research</em>,\n103(1): 178\u2013198.</li>\n<li>Samuelson, Paul A., 1977, \u201cSt. Petersburg Paradoxes:\nDefanged, Dissected, and Historically Described\u201d, <em>Journal of\nEconomic Literature</em>, 15(1): 24\u201355.</li>\n<li>Savage, Leonard J., 1954, <em>The Foundations of Statistics</em>,\n(Wiley Publications in Statistics), New York: Wiley. Second edition,\nCourier Corporation, 1974.</li>\n<li>Skala, Heinz J., 1975, <em>Non-Archimedean Utility Theory</em>,\nDordrecht: D. Reidel.</li>\n<li>Smith, Nicholas J. J., 2014, \u201cIs Evaluative Compositionality\na Requirement of Rationality?\u201d, <em>Mind</em>, 123(490):\n457\u2013502. doi:10.1093/mind/fzu072</li>\n<li>von Neumann, John and Oskar Morgenstern, 1947, <em>Theory of Games\nand Economic Behavior</em>, second revised edtion, Princeton, NJ:\nPrinceton University Press.</li>\n<li>Weirich, Paul, 1984, \u201cThe St. Petersburg Gamble and\nRisk\u201d, <em>Theory and Decision</em>, 17(2): 193\u2013202.\ndoi:10.1007/BF00160983</li>\n<li>Williamson, Timothy, 2007, \u201cHow Probable Is an Infinite\nSequence of Heads?\u201d, <em>Analysis</em>, 67(295): 173\u2013180.\ndoi:10.1111/j.1467-8284.2007.00671.x</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "decision theory",
            "hedonism",
            "infinity",
            "Pascal\u2019s wager",
            "probability, interpretations of",
            "rational choice, normative: expected utility",
            "space and time: supertasks",
            "statistics, philosophy of"
        ],
        "entry_link": [
            {
                "../decision-theory/": "decision theory"
            },
            {
                "../hedonism/": "hedonism"
            },
            {
                "../infinity/": "infinity"
            },
            {
                "../pascal-wager/": "Pascal\u2019s wager"
            },
            {
                "../probability-interpret/": "probability, interpretations of"
            },
            {
                "../rationality-normative-utility/": "rational choice, normative: expected utility"
            },
            {
                "../spacetime-supertasks/": "space and time: supertasks"
            },
            {
                "../statistics/": "statistics, philosophy of"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=paradox-stpetersburg\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/paradox-stpetersburg/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=paradox-stpetersburg&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/paradox-stpetersburg/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=paradox-stpetersburg": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/paradox-stpetersburg/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=paradox-stpetersburg&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/paradox-stpetersburg/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [],
        "listed_links": []
    }
}