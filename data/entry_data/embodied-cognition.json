{
    "url": "embodied-cognition",
    "title": "Embodied Cognition",
    "authorship": {
        "year": "Copyright \u00a9 2021",
        "author_text": "Lawrence Shapiro\n<lshapiro@wisc.edu>\nShannon Spaulding\n<shannon.spaulding@okstate.edu>",
        "author_links": [
            {
                "mailto:lshapiro%40wisc%2eedu": "lshapiro@wisc.edu"
            },
            {
                "mailto:shannon%2espaulding%40okstate%2eedu": "shannon.spaulding@okstate.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2021</a> by\n\n<br/>\nLawrence Shapiro\n&lt;<a href=\"mailto:lshapiro%40wisc%2eedu\"><em>lshapiro<abbr title=\" at \">@</abbr>wisc<abbr title=\" dot \">.</abbr>edu</em></a>&gt;<br/>\nShannon Spaulding\n&lt;<a href=\"mailto:shannon%2espaulding%40okstate%2eedu\"><em>shannon<abbr title=\" dot \">.</abbr>spaulding<abbr title=\" at \">@</abbr>okstate<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Fri Jun 25, 2021"
    ],
    "preamble": "\n\n\nEmbodied Cognition is a wide-ranging research program drawing from\nand inspiring work in psychology, neuroscience, ethology, philosophy,\nlinguistics, robotics, and artificial intelligence. Whereas traditional\ncognitive science also encompasses these disciplines, it finds common\npurpose in a conception of mind wedded to computationalism: mental\nprocesses are computational processes; the brain, qua\ncomputer, is the seat of cognition. In contrast, embodied cognition\nvariously rejects or reformulates the computational commitments of\ncognitive science, emphasizing the significance of an agent\u2019s\nphysical body in cognitive abilities. Unifying investigators of\nembodied cognition is the idea that the body or the body\u2019s\ninteractions with the environment constitute or contribute to cognition\nin ways that require a new framework for its investigation. Mental\nprocesses are not, or not only, computational processes. The brain is\nnot a computer, or not the seat of cognition.\n\n\nOnce a fringe movement, embodied cognition now enjoys a fair amount of\nprominence. Unlike, say, ecological psychology, which has faced an\nuphill battle for mainstream acceptance, embodied cognition has gained\na substantial following. The appointment of researchers who take an\nembodied perspective to cognition would, today, raise few eyebrows.\nEmbodied cognition has been the subject of numerous articles in\npopular outlets. Moreover, there is not an area of cognitive\nscience\u2014perception, language, learning, memory, categorization,\nproblem solving, emotion, social cognition\u2014that has not received\nan embodied \u201cmake-over.\u201d\n\n\nNone of this is to say, of course, that embodied cognition does not\nface hard questions, or has escaped harsh criticism. The numerous and\nsometimes incompatible claims it makes about the body\u2019s role in\ncognition and the myriad methods it employs for understanding this role\nmake it ripe for philosophical reflection. Critics charge embodied\ncognition with embracing a depleted conception of cognition, or with\nnot offering a genuine replacement to computational cognitive science,\nor with claiming that bodies play a constitutive role in cognition when\nin fact their role is merely causal. Proponents have responded to all\nof these objections. A welcome byproduct of these debates is a new\nperspective on some old philosophical questions concerning what minds\nare, what concepts are, and how to understand the nature and\nsignificance of representation.\n",
    "toc": [
        {
            "#FoilInspForEmboCogn": "1. The Foils and Inspirations for Embodied Cognition"
        },
        {
            "#EcolPsyc": "1.1 Ecological Psychology"
        },
        {
            "#Conn": "1.2 Connectionism"
        },
        {
            "#Phen": "1.3 Phenomenology"
        },
        {
            "#EmboCognThemClosRela": "2. Embodied Cognition: Themes and Close Relations"
        },
        {
            "#ThreThemEmboCogn": "2.1 Three Themes of Embodied Cognition"
        },
        {
            "#EmbeCogn": "2.2 Embedded Cognition"
        },
        {
            "#ExteCogn": "2.3 Extended Cognition"
        },
        {
            "#EnacCogn": "2.4 Enactive Cognition"
        },
        {
            "#Conc": "3. Conceptualization"
        },
        {
            "#MetaBasiConc": "3.1 Metaphor and Basic Concepts"
        },
        {
            "#EmboConc": "3.2 Embodied Concepts"
        },
        {
            "#Repl": "4. Replacement"
        },
        {
            "#Robo": "4.1 Robotics"
        },
        {
            "#DynaSystApprCogn": "4.2 Dynamical Systems Approaches to Cognition"
        },
        {
            "#Cons": "5. Constitution"
        },
        {
            "#ConsThroCoup": "5.1 Constitution Through Coupling"
        },
        {
            "#ConsThroPariWideComp": "5.2 Constitution Through Parity and Wide Computationalism"
        },
        {
            "#ReacEmboCogn": "6. The Reach of Embodied Cognition"
        },
        {
            "#SociCogn": "6.1 Social Cognition"
        },
        {
            "#MoraCogn": "6.2 Moral Cognition"
        },
        {
            "#Conc_1": "7. Conclusion"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. The Foils and Inspirations for Embodied Cognition\n\n\nThe ontological and methodological commitments of traditional\ncomputational cognitive science, which have been in play since at\nleast the mid-Twentieth Century, are by now well understood. Early or\ninfluential applications of computationalism to cognition include\ntheories of language acquisition (Chomsky 1959), attention (Broadbent\n1958), problem solving (Newell, Shaw, and Simon 1958), attention, memory (Sternberg 1969), and perception (Marr 1982).\nCommon to all computationally-oriented research is the idea that\ncognition involves a step-wise series of events, beginning with the\ntransduction of stimulus energy into a symbolic expression, followed\nby transformations of this expression according to various rules, the\nresult of which is a particular output\u2014a grammatical linguistic\nutterance, isolation of one stream of words from another, a solution\nto a logic problem, the identification of a stimulus as being among a\nset of memorized stimuli, or a 3-D perception of the world\n\n\nThe symbolic expressions over which cognitive processes operate, as\nwell as the rules according to which these operations proceed, appear\nas representational states internal to the cognizing agent. They are\nindividuated in terms of what they are about (phonemes, light\nintensity, edges, shapes, etc.). All of this cognitive activity takes\nplace in the agent\u2019s nervous system. It is in virtue of the\nactivation of the nervous system that stimuli become encoded into a\n\u201cmentalese\u201d language of thought, akin to the programming\nlanguages found in ordinary computers; similarly, the rules dictating\nthe manipulation of symbols in the language of thought are like the\ninstructions that a C.P.U. executes in the course of carrying out a\ntask. Rather than running spread sheets or displaying Tetris pieces,\nthe computational brain produces language, or perceives the world, or\nretrieves items from memory. The methods of computational cognitive\nscience reflect these ontological commitments. Experiments are designed\nto reveal the content of representational states or to uncover the\nsteps by which mental algorithms transform input into output.\n\n\nSo pervasive has this computational conception of cognition been over\nthe past decades that many cognitive scientists would be happy to\nidentify cognition with computation, giving little thought to the\npossibility of alternatives. Certainly the great strides toward\nunderstanding cognition that the advent of computationalism has made\npossible invites the idea that computational cognitive science, if not\nthe only game in town, is likely the best. However, ecological\npsychology, which J.J. Gibson (1966; 1979) began to develop around the\ntime that computationalism came to dominate psychological practice,\nrejected nearly every plank of the information processing model of\ncognition that computational cognitive science epitomizes. More\nrecently, connectionist cognitive science has challenged the symbolist\ncommitments of computationalism even while conceding a role for\ncomputational processes. Both ecological psychology and connectionist\npsychology have played significant roles in the rise of embodied\ncognition and so a brief discussion of their points of influence is\nnecessary to understand the \u201cembodied turn.\u201d Likewise,\nsome embodied cognition researchers draw on a very different source\nfor inspiration\u2014the phenomenological tradition with special\nattention to Merleau-Ponty\u2019s contributions. The next three\nsubsections examine these various strands of influence.\n1.1 Ecological Psychology\n\n\nA primary disagreement between computational and ecological\npsychologists concerns the nature of the stimuli to which organisms\nare exposed. Computationalists largely regard these stimuli as, in\nChomsky\u2019s terminology, impoverished (Chomsky 1980). The\nlinguistic utterances to which an infant comes in contact do not, on\ntheir own, contain sufficient information to indicate the grammar of a\nlanguage. Similarly, the visual information present in the light that\nstimulates an organism\u2019s retina does not, on its own, specify\nthe layout of surfaces in the organism\u2019s environment. Visual\nperception faces an \u201cinverse optics\u201d problem. For any\npattern of light on a retina, there exists an infinite number of\npossible distal surfaces capable of producing that pattern. The visual\nsystem thus seems to confront an impossible task\u2014while it is\npossible to calculate the pattern of light a reflecting surface will\nproduce on the retina, the inverse of this problem appears to be\nunsolvable, and yet visual systems solve it all the time and,\nphenomenologically speaking, immediately.\n\n\nComputationalists regard the inescapable poverty of stimuli as\nplacing on cognitive systems a need to draw inferences. Just as\nbackground knowledge allows you to infer from the footprints in the\nsnow that a deer has passed by, cognitive systems, according to\ncomputationalists, rely on sub-conscious background knowledge to infer\nwhat the world is like given the partial clues the stimuli offer. The\nperception of an object\u2019s size, for instance, would, according to\nthe computationalist, be inferred on the basis of the size of the\nretinal image of the object together with knowledge of the\nobject\u2019s distance from the viewer. Perception of an\nobject\u2019s shape, similarly, is inferred from the shape of the\nretinal image along with knowledge of the object\u2019s orientation\nrelative to the viewer.\n\n\nEcological psychologists, on the other hand, deny that organisms\nencounter impoverished stimuli (Michaels and Palatinus 2014). Such a\nview, they believe, falsely identifies whole sensory systems with\ntheir parts\u2014with eyes, or with retinal images, or with brain\nactivity. Visual perceptual processes, for instance, are not exclusive\nto the eye or even the brain, but involve the whole organism as it\nmoves about its environment. The motions of an organism create an\never-changing pattern of stimulation in which invariant features\nsurface. The detection of these invariants, according to the\necological psychologist, provides all the information necessary for\nperception. Perception of an object\u2019s shape, for instance,\nbecomes apparent as a result of detecting the kinds of transformations\nin the stimulus pattern that occur when approaching or moving around\nthe object. The edges of a square, for instance, will create patterns\nof light quite different from those that a diamond would reflect as\none moves toward or around a square, thus eliminating the need for\nrule-guided inferences, drawing upon background knowledge, to\ndistinguish the square from a diamond. Insights like these have\nencouraged embodied cognition proponents to seek explanations of\ncognition that minimize or disavow entirely the role of inference and,\nhence, the need for computation. Just as perception, according to the\necological psychologist, is an extended process involving whole\norganisms in motion through their environments, the same may well be\ntrue for many other cognitive achievements.\n1.2 Connectionism\n\n\nConnectionist systems offer a means of computation that, in many\ncases, eschews the symbolist commitments of computational cognitive\nscience. In contrast to the computer that operates on symbols on the\nbasis of internally stored rules, a connectionist system consists in\nnetworks of nodes that excite or inhibit each other\u2019s activity\naccording to weighted connections between them. Different stimuli will\naffect input nodes differently, causing distinct patterns of\nactivation in deeper layers of nodes depending on the values of\nactivation that the input nodes send upstream. The result of this\nactivity will reveal itself in the activation values of a final layer\nof nodes\u2014the output nodes.\n\n\nConnectionist networks thus compute\u2014they transform input\nactivation values into output activation values\u2014but the\nimputation of symbolic structures within this computational process,\nas well as explicit rules by which a C.P.U. executes operations upon\nthese symbols, appears unfounded. As Hatfield (1991) describes\nconnectionist networks, they are non-cognitive, in the sense\nthat their operation involves none of the trappings of cognition upon\nwhich computationalists insist, and yet still computational, insofar\nas stimulation of their input nodes creates patterns of activation\nthat lead to particular activation values in output nodes. For more on\n connectionism generally, see the entry on \n connectionism.\n \n\n\nMany embodied cognition researchers saw in connectionist networks a\nnew way to conceptualize cognition and, accordingly, to explain\ncognitive processes. Non-symbolic explanations of cognition, despite\nthe \u201conly game in town\u201d mantra of computationalists (Fodor\n1987), might be possible after all. Adding momentum to the\nconnectionist challenge was the realization that the mathematics of\ndynamical systems theory could often illuminate the unfolding patterns\nof activity in connectionist networks and could as well be extended to\ninclude within its explanatory scope the body-environment interactions\nbetween which connectionist networks reside. Consequently, some\nembodied cognition researchers have argued that dynamical systems\ntheory offers the best framework from which to\nunderstand cognition.\n1.3. Phenomenology\n\n\nAnother source of inspiration for embodied cognition is the\nphenomenological tradition. Phenomenology investigates the nature and\nstructure of our conscious, lived experiences. Although the subject of\nphenomenological analyses can vary widely from perception to\nimagination, emotion, willing, and intentional physical movements, all\nphenomenological analyses aim to elucidate the intentional structure\nof consciousness. They do so by analyzing our conscious experiences in\nterms of temporal, spatial, attentional, kinesthetic, social, and self\nawareness. In contrast to computational accounts of the mind that\nmodel consciousness in terms of input, processing, and output,\nphenomenological accounts ground consciousness in a host of rich and\nvaried attentional experiences, which with practice can be described\nand analyzed. For more on phenomenology, see\n see the entry on \n phenomenology.\n \n\n\nSome variations of embodied cognition are inspired by the works of\nphenomenologists like Martin Heidegger (1975), Edmund Husserl (1929),\nand Maurice Merleau-Ponty (1962) who emphasize the physical embodiment\nof our conscious cognitive experiences. These thinkers analyze the\nvarious ways in which our bodies shape our thoughts and how we\nexperience our conscious activities. Some even argue that\nconsciousness is constituted by embodiment. Merleau-Ponty,\nfor example, argues that consciousness itself is embodied:\n\n\n\nInsofar as, when I reflect on the essence of subjectivity, I find it\nbound up with that of the body and that of the world, this is because\nmy existence as subjectivity [= consciousness] is merely one with my\nexistence as a body and with the existence of the world, and because\nthe subject that I am, when taken concretely, is inseparable from this\nbody and this world (Merleau-Ponty 1962, p. 408).\n\n\n\nThis phenomenological influence can be seen clearly in embodied\ncognition analyses of the relation between mind and body. These\nanalyses reject the idea that mentality is fundamentally different and\nseparate from physicality and the corollary idea that others\u2019\nmentality is somehow hidden from view. Inspired by Husserl and other\nphenomenologists, embodied cognition proponents argue that\nCartesian-style analyses of the mind and the body fundamentally\nmisconstrue cognition (Gallagher and Zahavi, 2008). Cognition is not\npurely or even typically an intellectual, solipsistic introspection in\nthe way Descartes\u2019 Meditations suggest. Rather, cognition is\nphysically interactive, embedded in physical contexts, and manifested\nin physical bodies. Even contemporary philosophers and cognitive\nscientists who reject mind-body dualism may fall into the trap of\nintuitively regarding mental and physical as distinct and thereby\naccept the idea that we must infer the existence and nature of other\nminds from indirect cues. From the perspective that phenomenologists\nfavor, however, all cognition is embodied and interactive and embedded\nin dynamically changing environments. Attention to the way in which our\nown conscious experiences are structured by our bodies and environments\nreveals that there is no substantial distinction between mind and body.\nThe embodiment of cognition makes our own and others\u2019 minds just\nas observable as any other feature of the world. In other words,\nphenomenological analysis of our conscious experiences reveals the\nMind-Body Problem and Problem of Other Minds to be merely illusory\nproblems. This phenomenological analysis of the relation between mind\nand body and our relation to other minds deeply influenced proponents\nof embodied cognition such as Shaun Gallagher (2005), Dan Zahavi\n(2005), and Evan Thompson (2010).\n2. Embodied Cognition: Themes and Close Relations\n\n\nUnlike computational cognitive science, the commitments of which can\nbe readily identified, embodied cognition is better characterized as a\nresearch program with no clear defining features other than the tenet\nthat computational cognitive science has failed to appreciate the\nbody\u2019s significance in cognitive processing and to do so requires\na dramatic re-conceptualization of the nature of cognition and how it\nmust be investigated. Different researchers view the body\u2019s\nsignificance for cognition as entailing different consequences for the\nsubject matter and practice of cognitive science. Nevertheless, through\nthis very broad diversity of views it is possible to extract three\nmajor themes around which discussion of embodied cognition can be\norganized (see Shapiro 2012; 2019a).\n2.1 Three Themes of Embodied Cognition\n\n\nThe three themes of embodiment around which most of the following\ndiscussion will be organized are as follows.\n\nConceptualization: The properties of an\norganism\u2019s body limit or constrain the concepts an organism can\nacquire. That is, the concepts by which an organism understands its\nenvironment depend on the nature of its body in such a way that\ndifferently embodied organisms would understand their environments\ndifferently.\n\nReplacement: The array of computationally-inspired\nconcepts, including symbol, representation, and\ninference, on which traditional cognitive science has drawn\nmust be abandoned in favor of others that are better-suited to the\ninvestigation of bodily-informed cognitive systems.\n\nConstitution: The body (and, perhaps, parts of the\nworld) does more than merely contribute causally to cognitive\nprocesses: it plays a constitutive role in cognition, literally as a\npart of a cognitive system. Thus, cognitive systems consist in more\nthan just the nervous system and sensory organs.\n\n\nThe theses above are not intended to be individually\nexclusive\u2014embodied cognition research might show tendencies\ntoward more than one at a time. Similarly, descriptions of embodied\ncognition might be organized around a larger number of narrower themes\n(M. Wilson 2002); however, efforts to broaden the themes, thereby\nreducing their number, risks generalizing the description of embodied\ncognition to the extent that its purported novelty is jeopardized.\n\n\nBefore examining how these themes receive expression, it is worth\npausing to compare embodied cognition to some closely related research\nareas. Sometimes embodied cognition is distinguished from\nembedded cognition, as well as extended cognition and\nenactive cognition. However, despite the distinctions between\nthe four \u201cEs\u201d\u2014embodied, embedded, enactive, and\nextended\u2014it is not uncommon to use the label\n\u201cembodied\u201d to include any or all of these\n\u201cEs\u201d. The E-fields share the view, after all, that the\nbrain-centrism of traditional cognitive science, as well as its\ndependence on the computer for inspiration, stands in the way of a\ncorrect understanding of cognition.\n2.2 Embedded Cognition\n\n\nEmbedded cognition assumes that cognitive tasks\u2014dividing a\nnumber into fractions, navigating a large ship, retrieving the correct\nbook from a shelf\u2014require some quantity of cognitive effort.\nThe cognitive \u201cload\u201d that a task requires can be reduced\nwhen the agent embeds herself within an appropriately designed\nphysical or social environment. For instance, Martin and Schwartz\n(2005) found that children are more successful at calculating \u00bc\nof 8 when allowed to manipulate pie pieces than if only viewing the\npieces. The cognitive load required to navigate a large Navy vessel\nexceeds the capacity of any single individual, but can be distributed\nacross a number of specialists, each with his or her own particular\ntask (Hutchins 1996). Arranging books on a shelf alphabetically makes\nsearching for a particular title much easier than it would be if the\nbooks were simply set randomly upon the shelf. In all of these cases,\nthe cognitive capacities of an individual are enhanced when provided\nwith the opportunity to interact with features of a suitably organized\nphysical or social environment.\n2.3 Extended Cognition\n\n\nClose kin to embedded cognition, extended cognition moves from the\nclaim that cognition is embedded to claim additionally that the\nenvironmental and social resources that enhance the cognitive\ncapacities of an agent are in fact constituents of a larger\ncognitive system, rather than merely useful tools for a cognitive\nsystem that retains its traditional location wholly within an\nagent\u2019s nervous system (Clark and Chalmers 1998; Menary 2008).\nSome interpret the thesis of extended cognition to mean that cognition\nactually takes place outside the nervous system\u2014within the\nextra-cranial resources involved in the cognitive task (Adams and\nAizawa 2001; 2008; 2009; 2010). Others interpret the thesis more\nmodestly, as claiming that parts of an agent\u2019s environment or\nbody should be construed as parts of a cognitive system, even if\ncognition does not take place within these parts, thus extending\ncognitive systems beyond the agent\u2019s nervous system (Clark and\nChalmers 1998; Wilson 1994; Wilson and Clark 2001).\n2.4 Enactive Cognition\n\n\nEnactivism is the view that cognition emerges from or is constituted\nby sensorimotor activity. Currently, there are three distinct strands\nof enactivism (Ward, Silverman, and Villalobos 2017). Autopoietic\nEnactivism conceives of cognition in terms of the biodynamics of living\nsystems (Varela, Thompson, and Rosch 2017; Di Paolo 2005). Just as a\nbacterium is created and maintained by processes that span the organism\nand environment, so too is cognition generated and specified through\noperation of sensorimotor processes that crisscross the brain, body,\nand world. On this version of enactivism, there is no bright line\nbetween mental processes and non-mental biological processes. The\nformer simply are an enriched version of the latter. Sensorimotor\nEnactivism is another strand of enactivism that focuses on explaining\nthe intentionality and phenomenology of perceptual experiences in\nparticular (O'Regan and No\u00eb 2001; No\u00eb 2004). This view holds\nthat perception consists in active exploration of the environment,\nwhich establishes patterns of dependence between our movements, sensory\nstates, and the world. Perceivers need not build and manipulate\ninternal models of the external world. Instead, they need only\nskillfully exploit sensorimotor dependences that their exploratory\nactivities reveal. Finally, Radical Enactivism aims to replace all\nrepresentational explanations of cognition with embodied, interactive\nexplanations (Hutto and Myin 2013; Chemero 2011). The primary tactic\nguiding Radical Enactivism is to deconstruct and eliminate the notion\nof mental content in cognitive science. This tactic manifests in\ncritiques of attempts to naturalize intentionality, redescribing\ncognitive processes studied in mainstream cognitive science, and\nchallenging concepts employed even by closely related views, such as\nAutopoietic Enactivism\u2019s notion of sensemaking (Chemero 2016).\nThese three strands of enactivism vary in their target explanations and\nmethodology, however they share the commitment to the idea that\ncognition emerges from sensorimotor activity.\n3. Conceptualization\n\n\nReturning now to the three themes around which this discussion of\nembodied cognition is organized, the first is Conceptualization.\nAccording to Conceptualization, the concepts by which organisms\nrecognize and categorize objects in the world, reason and draw\ninferences, and communicate with each other, are heavily\nbody-dependent. The morphological properties of an agent\u2019s body\nwill constrain and inform the meaning of its concepts. The claim that\nconcepts are embodied in this way has been defended via quite distinct\nroutes.\n3.1 Metaphor and Basic Concepts\n\n\nLakoff and Johnson (1980; 1999) offered an early and influential\ndefense of Conceptualization. Their argument begins with the plausible\npremise that human beings rely extensively upon metaphorical reasoning\nwhen learning or developing an understanding of unfamiliar concepts.\nImagine, for instance, trying to explain to a child the meaning of\nelection. Drawing a connection between election and a\nconcept the child already understands, like foot race, makes\nthe job easier. The \u201celections are races\u201d metaphor provides\na kind of scaffolding for introducing and explaining the content of the\nelection concept. Candidates are like runners hoping\nto win the race. They will adopt various strategies.\nThey must be careful not to start too fast or they might\nburn out before reaching the finish line. It\u2019s about\nendurance through the long stretch\u2014more a\nmarathon than a sprint. Some will play\ndirty, trying to trip others up, knocking them off their\nstride. There will be sore losers but also\ngraceful winners. Appeal to the content of a familiar\nconcept\u2014foot race\u2014provides the child with a\nframework or stance for learning the unfamiliar\nconcept\u2014election.\n\n\nThe next step toward the embodiment of concepts proceeds with the\nobservation that, through pain of regress, not all concepts can be\nacquired through metaphorical scaffolding. There must be a class of\nbasic concepts that (if not innate) we learn some other way.\nLakoff and Johnson argue that these basic concepts derive from the\nkinds of \u201cdirect physical experience\u201d (1980: 57) that come\nfrom moving a human body through the environment. The concept\nup, for instance, is basic, emerging from possession of a body\nthat stands erect, so that \u201c[a]lmost every movement we make\ninvolves a motor program that either changes our up-down orientation,\nmaintains it, presupposes it, or takes it into account in some\nway\u201d (1980, 56). Lakoff and Johnson offer a similar account for\nhow human beings come to possess concepts like front,\nback, pushing, pulling, and so on.\n\n\nBasic concepts reflect the idiosyncrasies of particular kinds of\nbodies. Insofar as less-basic concepts depend upon metaphorical\nextensions of these most basic concepts, they will in turn reflect the\nidiosyncrasies of particular kinds of bodies. All concepts, Lakoff and\nJohnson appear to believe, are \u201cstamped\u201d with the\nbody\u2019s imprint as the characteristics of the body \u201ctrickle\nup\u201d into more abstract concepts. They thus arrive at\nConceptualization: \u201cthe peculiar nature of our bodies shapes our\nvery possibilities for conceptualization and categorization\u201d\n(1999, 19). Insofar as this is true, one should expect that\ndifferently-bodied organisms, equipped with a different class of basic\nconcepts, would conceptualize and categorize their worlds in nonhuman\nways.\n\n\nAlthough Lakoff and Johnson see Conceptualization as incompatible with\ncomputational cognitive science, their grounds for doing so are\ntenuous. Metaphorical reasoning consists in applying aspects of one\nconcept\u2019s content to that of another. Because such reasoning is\nexplicitly about content, and because computationalism is a theory\nabout how to process mental states in virtue of their content, Lakoff\nand Johnson\u2019s antagonism toward computationalism seems\nunwarranted. Additionally, their case for Conceptualization remains\nlargely a priori. They claim that organisms morphologically\ndistinct from human beings\u2014spherical in shape, say\u2014would\nbe unable to develop some human concepts (1980, 57), but with no such\nbeings available to test, this assertion is entirely speculative.\n3.2 Embodied Concepts\n\n\nA far more developed and empirically grounded case for\nConceptualization comes from psychological and neurological studies\nthat show a connection between a subject\u2019s use of a concept and\nactivity in the subject\u2019s sensorimotor systems. Arising from\nthese studies is a view of concepts as containing within their content\nfacts about the sensorimotor particularities of their possessors.\nBecause these particularities reflect the properties of an\norganism\u2019s body\u2014how, for instance, it moves its limbs when\ninteracting with the world\u2014the content of its concepts too will\nbe constrained and informed by the nature of its body.\n\n\nCentral to the idea that concepts are embodied is the description of\nsuch concepts as modal. This label is intended to make stark\nthe anti-computationalism that proponents of embodied concepts\nendorse. Symbols in a computer\u2014strings of 1s and 0s\u2014are\namodal, in the sense that their relationship to their\ncontents is arbitrary. Words too are amodal symbols. The symbol\n\u2018lake\u2019 means lake, but not in virtue of any\nresemblance or nomological connection it bears towards lakes. There is\nno reason that \u2018lake\u2019, rather than some other symbol,\nshould mean lake\u2014as is obvious when thinking about\nwords that mean lake in non-English languages. All mental\nsymbols, from the perspective of computational cognitive science, are\namodal in this sense.\n\n\nModal symbols, on the other hand, retain information about the\nsources of their origin. They are not just symbols, but, in\nBarsalou\u2019s (1999; Barsalou et al. 2003) terminology,\nperceptual symbols. Thoughts about a lake, for instance,\nconsist in activation of the sensorimotor areas of the brain that had\nbeen activated during previous encounters with actual lakes. A\nlake thought re-activates areas of visual cortex that respond\nto visual information corresponding to lakes; areas of auditory cortex\nthat respond to auditory information corresponding to lakes; areas of\nmotor cortex that correspond to actions typically associated with lakes\n(although this activation is suppressed so that it does not lead to\nactual motion), and so on. The result is a lake concept that\nreflects the kinds of sensory and motor activities that are unique to\nhuman bodies and sensory systems. Lake means something like\n\u201cthing that looks like this, sounds like this,\nsmells like this, allows me to swim within it like\nthis\u201d. Moreover, because how things look and sound\ndepend on the properties of sensory systems, and because the\ninteractions something affords depends on the properties of motor\nsystems, concepts will be body-specific.\n\n\nMuch of the evidence for the modality of concepts arises from\ndemonstrations of an orientation-dependent spatial compatibility\neffect (OSC) (Symes, Ellis, and Tucker 2007). Tucker and Ellis\n(1998), for instance, asked subjects to judge whether a given object,\ne.g., a pan, was right-side-up or upside down. The object was oriented\neither rightwards or leftwards. So, for instance, the pan\u2019s\nhandle extended toward the right or left. Subjects would indicate\nwhether the object was right-side-up or upside down by pressing a\nbutton to their right with their right index finger or to their left\nwith their left index finger. Subjects\u2019 reaction times were\nshorter when using a right finger to indicate a response when the\nobject was oriented to the right than when oriented toward the left,\nand, mutatis mutandis, for left-finger responses when the\nobject was oriented to the left. Despite the fact that subjects were\nnot asked to consider horizontal orientation of the stimulus object,\nthis orientation influenced response times (for related work on the\nOSC, see Tucker and Ellis 2001; 2004).\n\n\nRelatedly, Glenberg and Kaschak (2002) showed an action-sentence\ncompatibility effect (ASC) Subjects were asked to judge the\nsensibility of sentences like \u201copen the drawer\u201d or\n\u201cclose the drawer.\u201d Sentences of the first kind suggested\nactions that would require a motion of the hand toward the body and\nsentences of the second kind suggested actions with motions away from\nthe body. Subjects would indicate the sensibility of the sentence by\npressing a button that required a hand motion either away from the body\nor toward the body. Glenberg and Kaschak found that reaction times were\nshorter when the response motion was compatible with the motion\nsuggested by the action sentences.\n\n\nBoth the OSC and ASC effects have been taken to show that concepts\nare modal. Thoughts about pans, for instance, activate areas in motor\ncortex that would be activated when actually manipulating a pan.\nSubjects are slower to respond to a leftward oriented pan with their\nright finger, because seeing the pan\u2019s orientation activates\nmotor areas in the brain associated with grasping the pan with the left\nhand, priming a left finger response while inhibiting a right finger\nresponse. Similarly, the meaning of words like \u201copen\u201d and\n\u201cclose\u201d include in their content the kinds of motor\nactivity that would be involved in opening or closing motions. The\nmeaning of object concepts thus contain information about how objects\nmight be manipulated by bodies like ours; action concepts\nconsist, in part, of information about how bodies like ours\nmove.\n\n\nFurther evidence for the claim that concepts are packed with\nsensorimotor information comes from Edmiston and Lupyan (2017), who\nasked subjects questions that required for their answers either\n\u201cencyclopedic\u201d knowledge\u2014\u201cDoes a swan lay\neggs?\u201d\u2014or visual knowledge\u2014\u201cDoes a swan have a\nbeak?\u201d. Interestingly, they found that visual interference\nduring the task would diminish performance on questions requiring\nvisual knowledge but not encyclopedic knowledge. They took this as\nevidence for the embodiment of concepts insofar as the effect of\nvisual interference would be expected if concepts were modal\u2014if,\nin this case, they involved the activation of vision centers in the\nbrain\u2014but not if concepts were amodal symbols, divorced from\ntheir sensorimotor origins.\n\n\nA final source of evidence for embodied concepts comes from\nneurological investigations that reveal activation in the sensorimotor\nareas of the brain associated with particular actions. Reading a word\nlike \u2018kick\u2019 or \u2018punch\u2019 causes activity in\nmotor areas of the brain associated with kicking and punching\n(Pulverm\u00fcller 2005). Stimulation of these areas by transcranial\nmagnetic stimulation can affect comprehension of such words\n(Pulverm\u00fcller 2005; Buccino et al. 2005). Again, results like\nthese are precisely what an embodied theory of concepts would predict\nbut would be unexpected on standard computational amodal theories of\nconcepts. If the concept kick includes in its content motions\ndistinctive of a human leg, as determined by activity in the motor\ncortex, then, as Conceptualization entails, it shows the imprint of a\nspecific sort of embodiment.\n\n\nCritics of embodied concepts have issued a number of challenges.\nMost basically, one might question whether empirical studies like those\njust mentioned are targeting concepts at all. Why think, for instance,\nthat the meaning of the concept pan includes information about\nhow pans must be grasped; and that the meaning of open\nincludes information about how an arm should move? Claims like these\nseem inattentive to a distinction between a concept and a\nconception (Rey 1983; 1985; Shapiro 2019a). The meaning of the\nconcept bachelor, for instance, is unmarried male.\nBut apart from this concept is a conception of a bachelor,\nwhere a conception involves something like typical or representative\nfeatures. A bachelor conception might include things like being a\nlothario, or being young, or participating in bro-culture. These\nconcepts are associated with the concept bachelor,\nbut not actually part of the meaning of the concept. Similarly, that\npans might be grasped so, or opening involves moving\nan arm like so, might not be part of the meaning of the\nconcepts pan and open, but instead features of\none\u2019s conception of pans and one\u2019s conception of how to\nopen things.\n\n\nJust as defenders of embodied concepts might not be investigating\nconcepts after all, but instead only conceptions\u2014only features\nassociated with concepts\u2014it may be that the motor\nactivity that accompanies thoughts about concepts does not contribute\nto the meaning of a concept but is instead only associated with the\nconcept. The psychologists Mahon and Caramazza (2008) argue for this\nway of interpreting the neurological studies taken to support of\nembodied concepts. The finding that exposure to the word\n\u2018kick\u2019 causes activity in the motor areas of the brain\nresponsible for kicking does not show that kick is a modal\nconcept. Mahon and Caramazza suggest that linguistic processing of a\nword might create a cascade of activity that flows to areas of the\nbrain that are associated with the meaning of the word. A\nthought about kick is associated with thoughts about moving\none\u2019s leg, which in turn causes activity in the motor system,\nbut there is no motivation for regarding this activity as part of the\nkick concept\u2014no motivation for seeing it as evidence\nfor the modality of the concept (Mahon 2015). Thinking about a kick\ncauses one to think about moving one\u2019s leg, which causes\nactivity in motor cortex, but the meaning of kick is\nindependent of such activity.\n\n\nFinally, even granting the modality of concepts like pan\nand kick, one might question whether all concepts\nare embodied, as some embodied cognition researchers suggest (Barsalou\n1999). Of special concern are abstract concepts like\ndemocracy, justice, and morality (Dove 2009;\n2016). Unlike pan, the meaning of which might involve\ninformation from sensory and motor systems, what sensory and motor\nactivity might be included in the meaning of justice? Barsalou\n(2008) and Barsalou and Wiemer-Hastings (2005) offer an account of how\nabstract concepts might be analyzed in modal terms, but debate over the\nissue is far from settled.\n4. Replacement\n\n\nMany who take an embodied perspective on cognition believe that the\ncommitments of traditional cognitive science must be jettisoned and\nreplaced with something else. No more computation, no more\nrepresentation, no more manipulation of symbols. Researchers who\npromote the complete replacement of traditional cognitive science tend\nto show the influence of ecological psychology. Less radical are\narguments for abandoning some elements of traditional cognitive\nscience, for instance the idea that cognition is a product of\nrule-guided inference, while retaining others, e.g., the idea that\ncognition still involves representational states. This position has\nroots in the connectionist alternative to computationalism discussed\nin \u00a71.2. Support for Replacement arrives from several\ndirections.\n4.1 Robotics\n\n\nEarly ventures in robotics took on board the idea that cognition is\ncomputation over symbolic representations. The robot Shakey\n(1966\u20131972) for instance, created at the Artificial Intelligence\nLaboratory at what was then the Stanford Research Institute, was\nprogrammed to navigate through a room, avoiding or pushing blocks of\nvarious shapes and colors. Guiding Shakey\u2019s behavior was a\nprogram, called STRIPS, which operated on symbolically encoded images\nof the blocks, combining them with stored descriptions of\nShakey\u2019s world. As the roboticist Brooks characterizes\nShakey\u2019s architecture, it cycles through iterations of\nsense-model-plan-act sequences (Brooks 1991a). A camera senses the\nenvironment, a computer builds a symbolic model of the environment\nfrom the camera images, the STRIPS program combines the model with\nstored symbolic descriptions of the environment, creating plans for a\ncourse of action. Shakey\u2019s progress was slow\u2014some tasks\nwould take days to complete\u2014and heavily dependent on an\nenvironment carefully structured to make images easier to process.\n\n\nBrooks\u2019s approach to robotics disavows the computational\nprinciples on which Shakey was designed, embracing instead a\nGibsonian-inspired architecture. The result has been robots that\nexhibit far more versatility than Shakey ever displayed\u2014robots\nthat can roam cluttered environments, avoiding obstacles, setting goals\nfor themselves, collecting soda cans for recycling, and more.\nBrooks\u2019s \u201cCreatures\u201d run on what he calls a\nsubsumption architecture. Rather than cycling through\nsense-model-plan-act sequences, Creatures contain arrays of sensors\nthat are connected directly to behavior-generating mechanisms. For\ninstance, the sensors on Brooks\u2019s robot Allen were connected\ndirectly to three different kinds of behavior-generators: Avoid,\nWander, and Explore. When sensors detected an object in Allen\u2019s\npath, the Avoid mechanism would cause Allen to stop its forward\nmotion, turn, and then proceed. The Wander generator would simply send\nAllen along a random heading, while the Explore generator would steer\nAllen toward a selected target. The three kinds of activity\nlayers as Brooks called them, continually compete with each\nother. For instance, if Allen were Wandering and came across an\nobstacle, Avoid would step in and prevent Allen from a\ncollision. Explore could inhibit Wander\u2019s activation in order to\nkeep Allen on course toward a target. From the competitive\ninteractions of the three layers emerged unexpectedly flexible and\nseemingly goal-oriented behavior.\n\n\nAccording to Brooks, his Creatures have no need for representations.\nImplementing an idea from ecological psychology, Brooks says that the\nactivity layers in his robots connect \u201cperception to action\ndirectly\u201d (1991b, 144). A robot designed in this way need not\nrepresent the world because it is able to \u201cuse the world as its\nown model\u201d (1991b, 139). The robot\u2019s behavior evolves\nthrough a continuous loop: the body moves, which changes the\nstimulation its sensors receive, which directly causes new movement,\nand so on. Because nothing stands \u201cin between\u201d the sensory\nsignals and the robot\u2019s behavior, there is no need for something\nthat plays the standard intermediating role of a representational\nstate. The robot does not require, for instance, a model of its\nenvironment in order to navigate through hallways. The move-sense loop\ndoes its job without one.\n\n\nDespite the success of Brooks\u2019s robots in comparison to their\ncomputational ancestors, and the impact Brooks\u2019s ideas have had\non industry (e.g., Roomba vacuum cleaners), whether Brooks\u2019s\ninsights pave the way for a radical, representation-free, cognitive\nscience, as some enactivists like Chemero (2009) and Hutto and Myin\n(2013) believe, is far from certain. A first question concerns whether\nthe behavior of Brooks\u2019s Creatures really proceeds without the\nbenefit of representational states. The sensors with which the\nCreatures are equipped, after all, send signals to the various\nactivity layers so that the layers can respond to objects in the\nenvironment. Moreover, the various layers communicate with each other\nin order to modulate each other\u2019s activities. They are, in\neffect, signaling each other with messages that seem to have a\nsemantics: \u201cgo ahead,\u201d or \u201cstop!\u201d.\n\n\nSkeptics about representation, such as Chemero (2009) and Hutto and\nMyin (2013) focus on the continuous contact that Brooks\u2019s\nCreatures bear to their environments as a reason to deny a role for\nrepresentation. Because a Creature is in constant contact with the\nworld, it does not need to represent the world. But constant contact\ndoes not always obviate a need for representation. Consider, for\ninstance, that an organism might be in constant contact with many\nfeatures of its environment\u2014sunlight, humidity, oxygen, the\ngravitational pull of the moon, and so on. Yet, surely it will be\nsensitive to only some of these features\u2014only some of these\nfeatures will shape the organism\u2019s behavior. A natural way to\ndescribe how some features make a difference to an organism while\nothers do not might appeal to representation\u2014an organism\ndetects some features, represents them, and not others.\nWhether detection of this sort must involve representation will depend\non the theory of representation that one adopts. One might therefore\nsee the success of Brooks\u2019s challenge to representation, and the\nenactivists\u2019 embrace of the challenge, as hostage to a theory of\nrepresentation, the details of which will no doubt themselves be\ncontroversial.\n\n\nAnother response to Brooks\u2019s work doubts whether something like\nthe subsumption architecture, even granting that it makes no use of\nrepresentations, can \u201cscale up\u201d\u2014can produce the more\nadvanced sorts of behavior that cognitive scientists typically\ninvestigate (Shapiro 2007). Matthen (2014) argues that once we move\njust a little beyond the capabilities of Brooks\u2019s Creatures,\nexplanations of behavior will require an appeal to\nrepresentations. For instance, imagine an organism that knows how to\nmove from point A to point B, and from point A to point\nC, and on the basis of this knowledge, \u201cfigures out\u201d\nhow to move from point B to point C (Matthen 2014). It would\nseem that such an organism must possess a representation of the\nrelations between points A, B, and C for such a\ncalculation to be possible.\n\n\nClark and Toribio (1994) describe some cognitive tasks as\n\u201crepresentation-hungry.\u201d Examples include imagining or\nthinking about non-existent entities (e.g., unicorns) or\ncounterfactual states of affairs (what would happen if I sawed through\nthe tree in this direction?). Of necessity, an organism cannot be in\nconstant contact with non-existents. That human beings so readily and\noften entertain such thoughts poses a difficulty for enactivists like\nChemero and Hutto and Myin who see in Brooks\u2019s \u201cworld as\nits own model\u201d slogan a foundation for all or most\ncognition. Because the world contains no unicorns, using the world as\na model cannot explain thoughts about unicorns.\n4.2 Dynamical Systems Approaches to Cognition\n\n\nAround the turn of the century, some cognitive scientists (Beer 2000;\n2003; Kelso 1995; Thelen and Smith 1993; Thelen et al. 2001) and\nphilosophers (Van Gelder 1995; 1998) began to advocate for dynamical\nsystems approaches cognition. Van Gelder (1995; 1998) argued that the\ncomputer, as the defining metaphor for cognitive systems, should be\nreplaced with something more like the Watt\u2019s centrifugal\ngovernor. A centrifugal governor regulates the speed of a steam engine\nby modulating the opening of a steam valve. As the valve opens, a\nspindle to which flyballs are connected spins faster, causing the\nflyballs to rise, which then cause the steam valve to close,\ndecreasing the speed at which the spindle spins, causing the flyballs\nto drop, thus opening the steam valve, and so on. Whereas a\ncomputational solution to maintaining engine speed might represent the\nengine\u2019s current speed, compare it to a representation of the\nengine\u2019s desired speed, and then calculate and correct for the\ndifference, the centrifugal governor does its job without having to\nrepresent or calculate anything (although some have argued that\nrepresentations are indeed present in the governor: Bechtel 1998;\nPrinz and Barsalou 2000).\n\n\nThe centrifugal governor is an example of a dynamical system. Typical\nof dynamical systems is behavior that changes continuously through\ntime\u2014the height of the flyballs, the speed of the spindle, and\nthe size of the steam valve opening all change continuously through\ntime, and the rate of change in each effects the rate of change of the\nothers. Dynamical systems theory provides the mathematical\napparatus\u2014differential and difference equations\u2014to model\ndynamical systems. It is to these equations that dynamical\ncognitive science looks for explanations of cognition.\n\n\nAmong the most-cited examples of a dynamical explanation of cognition\nis the Haken-Kelso-Bunz (HKB) model of coordination dynamics (Haken,\nKelso, and Bunz 1985; Kelso 1995). This model, consisting of a single\ndifferential equation, captures the dynamics of coordinated finger\nwagging. Subjects are asked to wag their right and left index fingers\neither in-phase, where each finger moves toward and away from each\nother, or out-of-phase, like windshield wipers. As the rate of finger\nwagging increases, out-of-phase motion will \u201cflip\u201d to\nin-phase motion, but motion that starts in-phase will remain\nin-phase. In dynamical terms, the coordination of finger wagging has\ntwo attractors, or regions of stability, at slower speeds\n(in-phase and out-of-phase) but only one attractor at a higher speed\n(in-phase). The HKB model makes a number of predictions borne out by\nobservation, for instance that there are only two stable wagging\npatterns at lower speeds, that erratic fluctuations in coordination\nwill occur near the critical threshold at which out-of-phase wagging\ntransforms to in-phase, and that deviations from out-of-phase wagging\nwill take longer to correct near the speed of transformation to\nin-phase (see Chemero 2001 discussion).\n\n\nOther influential examples of dynamical explanations of cognition have\nfocused on the coordination of infants\u2019 legs for stepping\nbehavior (Thelen and Smith 1993), perseverative reaching behavior in\ninfants (Thelen et al. 2001), and categorization in a simulated agent\n(Beer 2003). Authors of these studies have been explicit in their\nbelief that traditional cognitive science should be replaced with the\ncommitments of dynamical cognitive science. Among these commitments is\na rejection of representation as a necessary component of cognition as\nwell as a view of cognition as \u201cunfolding\u201d from the\ncontinuous interactions between an organism\u2019s brain, body, and\nenvironment rather than as emerging from discrete, rule-guided,\nalgorithmic steps. This latter commitment returns us to the theme of\nembodiment. As Thelen et al. explain:\n\n\n\nTo say that cognition is embodied means that it arises from bodily\ninteractions with the world. From this point of view, cognition\ndepends on the kinds of experiences that come from having a body with\nparticular perceptual and motor capabilities that are inseparably\nlinked and that together form the matrix within which reasoning,\nmemory, emotion, language, and all other aspects of mental life are\nmeshed\u201d (2001, 1).\n\n\n\nOf course, computational cognitive scientists can accept as well that\ncognition \u201carises from bodily interactions with the\nworld,\u201d in the sense that the inputs to cognitive processes\noften arise from bodily interactions with the world. Thelen et\nal. (2001) must then mean something more than that. Presumably, the\nidea is that the body is like a component in a centrifugal governor,\nand cognition arises from the continuous interactions between the\nbody, the brain, and the world. Spivey, another prominent dynamical\ncognitive scientist, puts matters like this: \u201cFor the new\npsychology on the horizon, perhaps we are ready to discard the\nmetaphor of the mind as computer\u2026and replace it with a\ntreatment of the mind as a natural continuous event\u201d (2007, 29),\nmuch as, presumably, how the regulation of a steam engine\u2019s\nspeed is the result of the continuous interactions of the components\nof a centrifugal governor.\n\n\nOne challenge facing dynamical approaches to cognition echoes that\nconfronting roboticists like Brooks. Just as the principles underlying\nthe subsumption architecture may not scale-up in ways that can explain\nmore advanced cognitive capacities, so too one might wonder whether\ndynamical approaches to such capacities will succeed. Perhaps finger\nwagging and infant stepping behavior are not instances of cognition in\nthe first place, or are so only in an attenuated sense (Shapiro 2007;\n2013), in which case any lessons learned from their investigation have\nlittle relevance to cognitive science.\n\n\nOr perhaps as dynamical cognitive scientists examine more explicitly\ncognitive phenomena, they will find themselves in need of tools\nassociated with standard cognitive science. Spivey, a pioneer of\ndynamical systems approaches, is on friendly terms with the idea of\nrepresentations. Dietrich and Markman (2001) have argued that even\nbehavior like coordinated finger wagging depends on representation,\nalthough perhaps not a conception of representation as\n\u201cthick\u201d as one usually attributed to\ncomputationalism. Once again, it is evident that resolving some of the\ncontroversy surrounding the Replacement thesis hinges on the theory of\nrepresentation that one adopts.\n\n\nAnother criticism of dynamical cognitive science questions whether the\ndifferential equations that are offered as explanations of cognitive\nphenomena are genuinely explanatory. Chemero (2001) and Beer (2003)\ninsist that they are. The equations can be used to\npredict the behavior of organisms as well as to address\ncounterfactuals about behavior (how would the organism have\nbehaved if such and such had occurred?)\u2014both hallmarks of\nexplanation. Dietrich and Markman (2001), on the other hand, argue that\nthe equations offer only descriptions of phenomena rather than\nexplaining them (see also Eliasmith 1996; van Leeuwen 2005). Spivey,\ndespite his devotion to dynamical cognitive science, shares this view.\nDynamical systems theory, he thinks, does not explain cognition. Its\nutility consists in \u201cmodeling how the mind works\u201d\n(2007, 33, his emphasis). He continues:\n\n\n\nThe emergence of mind takes place in the medium of patterns of\nactivation across neuronal cell assemblies in conjunction with the\ninteraction of their attached sensors (eyes, ears, etc.) and effectors\n(hands, speech apparatus, etc.) with the environment in which they are\nembedded. Make no mistake about it, that is the stuff of\nwhich human minds are made: brains, bodies, and\nenvironments. Trajectories through high-dimensional state spaces are\nmerely convenient ways for scientists to describe, visualize, and\nmodel what is going on in those brains, bodies, and\nenvironments\u201d (2007, 33, his emphasis).\n\n\n\nHowever, as Zednik (2011) has noted (see also Clark 1997 and Bechtel\n1998), the differential equations on which dynamical explanations\ndepend contain terms that permit interpretation. This is what turns a\npiece of pure mathematics into applied mathematics, which routinely is\nunderstood as describing causal processes (Sauer 2010). As an instance\nof applied (rather than pure) mathematics, The Lotka Volterra\nequations, for instance, do indeed explain the dynamics of\npredator-prey populations when their terms are taken to refer to\npredation rate and reproductive rate. The equations\nreveal how predation affects the size of the prey population,\nand how depletion in the prey population affects the size of\nthe predator population, and how reproduction restores the\nprey population. So, Spivey may be right that the \u201cstuff\u201d\nof minds consists in brains, bodies, and environments, but this does\nnot preclude the differential equations that describe these\ninteractions from being explanatory. They are\nexplanatory because they describe how brains, bodies, and\nenvironments interact and the consequences ensuing from these\ninteractions.\n5. Constitution\n\n\nBaking powder is a constituent of a scone, and its presence causes the\nscone to rise when baked. A hot oven is also a cause of the\nscone\u2019s rising, but it is not a constituent of the scone. You\neat baking powder when you eat a scone, but you do not eat a hot oven.\nAccording to computational cognitive science, the constituents of a\ncognitive system are brain processes, where these processes are\nperforming computations. The causes of cognition will be whatever\ncauses these brain processes\u2014stimulation to the body from the\nenvironment, for instance. Many embodied cognition theorists believe\nthat this account of the constituents of cognition is incorrect. The\nconstituents of a cognitive system extend beyond the brain, to include\nthe body and the environment. A difficulty for this view is justifying\nthe claim that the body and world are better construed as constituents\nof cognition rather than causes. Why are they more like baking powder\nthan a hot oven?\n5.1 Constitution Through Coupling\n\n\nThe previous discussion of dynamic cognitive science serves also to\nillustrate the Constitution theme. As the quotation above from Spivey\nindicated, dynamically-oriented cognitive scientists regard cognition\nto be the product of interactions between brain, body, and world. The\ncontinuous interactions between these things, Chemero writes, explains\nwhy \u201cdynamically-minded cognitive scientists do not assume that\nan animal must represent the world to interact with it. Instead, they\nthink of the animal and the relevant parts of the environment as\ntogether comprising a single, coupled system\u201d (2001, 142).\nChemero continues this idea: \u201cIt is only for convenience (and\nfrom habit) that we think of the organism and environment as separate;\nin fact, they are best thought of as comprising just one\nsystem\u2026the animal and environment are not separate to begin\nwith\u201d (2001, 142).\n\n\nChemero\u2019s description of the animal and environment as coupled\nis ubiquitous in dynamical cognitive science. Coupling is a technical\nnotion. The behaviors of objects are coupled when the differential\nequations that describe the behavior of one contains a term that\nrefers to the behavior of the other. The equations that apply to the\ncentrifugal governor, for instance, contain terms referring to the\nheight of the flyballs and the size of the steam valve opening. The\nLotka Volterra equations contain terms that refer to the number of\npredators and the number of prey. The co-occurrence of terms in the\nequations that describe a dynamical system shows that the behavior of\nthe objects to which they refer are co-dependent. They are thus\nusefully construed as constituents of a single system\u2014a system\nheld together by the interactions of parts whose relationships are\ncaptured in coupled differential equations.\n\n\nIn addition to the technical sense of coupling, philosophers often\nappeal to a looser sense when defending Constitution. Clark, for\ninstance, discusses the process of writing. When writing, \u201c[i]t\nis not always that fully formed thoughts get committed to paper.\nRather, the paper provides a medium in which, this time via some kind\nof coupled neural-scribbling-reading unfolding, we are enabled to\nexplore ways of thinking that might otherwise be unavailable to\nus\u201d (2008, 126). Clark\u2019s idea is that the cognitive system\nthat produces writing extends beyond a subject\u2019s brain, to\ninclude among its constituents the paper on which words are written.\nThe paper and the acts of reading and writing are literally parts of\nthe cognitive process, no less than neural processes, because of the\ncontinuous interactions between all of these things. If it were\npossible to provide differential equations that describe the\nproduction of writing, they would include terms referring to the\nbehaviors of each of these things. Thus, the reasoning that brings us\nto the conclusion that the components of a centrifugal governor are\nconstituents of a single system, and that predator and prey are\nconstituents of single system, leads also to the conclusion that the\nconstituents of many cognitive systems will include parts of the body\nand world.\n\n\nThe coupling concept underlies some arguments for extended\ncognition. When brain processes are coupled to processes in the\nbody or world, either in the technical sense deriving from dyamical\nsystems theory or in the less strict sense involving loops of\ndependency, the resulting \u201cbrain+\u201d is itself a single\ncognitive system. It is a cognitive system that extends beyond the\nhead because the constituents of the system are not brain-bound.\n\n\nAdams and Aizawa (2008; 2009; 2010) have objected to coupling-inspired\ndefenses of Constitution, and hence the idea of extended cognition, on\nthe grounds that they commit a\ncoupling-constitution fallacy: \u201cThe pattern of\nreasoning here involves moving from the observation that process X\nis in some way causally connected (coupled) to a process Y of type\nj to the conclusion that X is part of the process of type\nj\u201d (2009, 81). They argue that this reasoning leads to\nabsurd results. For instance, \u201c[i]t is the interaction of the\nspinning bowling ball with the surface of the alley that leads to all\nthe pins falling. Still, the process of the ball\u2019s spinning does\nnot extend into the surface of the alley or the pins (2009,\n83). Similarly, Adams and Aizawa would claim, the process of cognition\ndoes not extend into the paper and scribblings involved in\nwriting.\n\n\nThis response is unlikely to impress supporters of coupling arguments\nfor Constitution. Firstly, coupling arguments require that process\nX be more than simply causally connected to process Y of type\nj for X to be part of the j process. Suppose that process\nY of type j is the production of a written paragraph on a\npiece of paper. Let X be the sound of the pencil as it leaves\ngraphite on the surface of the paper. The sound is causally connected\nto the production of writing, but defenders of Constitution need not\nregard it as a constituent in the system of that results in the\nwritten paragraph. The sound does not contribute to the\n\u201cloop\u201d\u2014neural events, scribbling, reading\u2014from\nwhich the paragraph emerges. So, not just any causal connections\nsuffice for constituency in a process.\n\n\nSecond, Clark and other defenders of Constitution would not claim that\nthe writing process itself occurs in the constituents of the\ncognitive system that produces writing. Certainly the bowling\nball\u2019s spinning does not extend into the floor of the alley, and\nof course the writing process does not extend into a piece of paper.\nBut the Constitution thesis is not committed to such claims (Shapiro\n2019a). Just as one can say that a neuron is a constituent of a brain\neven if cognition does not take place in a neuron, it might make sense\nto say that the floor of the alley is a constituent in a system that\nresults in the ball\u2019s spinning even if spinning does not take\nplace in the floor, and the paper is a constituent in a system that\nproduces writing even if the writing process does not take place\nin the paper. Such conclusions, even if ultimately\nunwarranted, do not fail for the reasons Adams and Aizawa muster.\n5.2 Constitution Through Parity and Wide Computationalism\n\n\nApart from coupling arguments, some philosophers, e.g., Clark and\nChalmers (1998) and Clark (2008), have defended the idea that\ncognitive systems include constituents outside the brain by appeal to\na\nparity principle, whereas Wilson (2004) invokes the idea of\nwide computationalism. The arguments are similar, both seeking\nto reveal how a functionalist commitment to mental states or processes\nlicenses the possibility of cognitive processes that extend beyond the\nbrain.\n\n\nThe parity principle says \u201c[i]f, as we confront some task, a\npart of the world functions as a process which, were it done in the\nhead, we would have no hesitation in recognizing as part of the\ncognitive process, then that part of the world is\u2026part of the\ncognitive process\u201d (Clark 2008, 222). As illustration, Clark and\nChalmers (1998) compare the occurrent beliefs of Otto, who is\nafflicted with Alzheimer\u2019s disease, to those of Inga, who has a\nnormal biological brain. Otto keeps a notebook containing information\nof the sort that would be stored in the hippocampus of a normally\nfunctioning brain. When Inga wants to visit MoMA, she pulls from her\nbiological memory the information that MoMA is on 53rd\nSt. which prompts her to take a subway to the destination. When Otto\nhas the same desire, he consults his notebook in which is written\n\u201cMoMA is on 53rd St.\u201d, which in turn induces\nhis trip to that location. By stipulation, the representation of\nMoMA\u2019s location in Otto\u2019s notebook plays an identical\nfunctional role to the representation in Inga\u2019s brain. Hence, by\nthe parity principle, the notebook entry is a memory\u2014an\noccurrent belief about the location of MoMA. The notebook is thus home\nto constituents of many of Otto\u2019s cognitive processes.\n\n\nIn a similar vein, Wilson (2004) discusses a person who wishes to\nsolve a multiplication problem involving two large\nnumbers. Calculating the product \u201cin the head\u201d is a\npossibility, but solving the problem with the aid of pencil and paper\nwould be much easier. In the latter case, Wilson claims that the brain\n\u201coffloads\u201d onto the paper some of the work that it would\notherwise have to do on its own. Crucial to Wilson\u2019s argument is\nthe idea that solving the multiplication problem is a computational\nprocess and that computational processes are not confined to\nparticular spatial regions. When the multiplication problem is solved\n\u201cin the head\u201d the computational processes occur within the\nbrain alone. But some of the steps in the computation could as well\ntake place outside the head, on a piece of paper, in which case a\ncomputational process might partly occur outside the head. There is,\nthen, a parity in the two processes, whether the particular\ncomputations are internal or external to the agent. To the extent that\nthis is plausible, one can find additional support for\nConstitution.\n\n\nMost criticism of extended cognition has been aimed at Clark and\nChalmers\u2019s original proposal, although because Wilson\u2019s\nposition is similar, it is as much victim to these criticisms insofar\nas they succeed. Among the most vocal critics are Adams and Aizawa\n(2001; 2008; 2009; 2010), who argue that extended cognitive systems\nlike those involving Otto and his notebook or a person doing\nmultiplication with a paper and pencil, cannot actually be cognitive\nbecause they fail to satisfy two \u201cmarks\u201d of the cognitive.\nThe first mark is that \u201ccognitive states must involve intrinsic,\nnon-derived content\u201d (Adams and Aizawa 2001, 48). The second is\nthat cognitive systems must display processes of sufficient uniformity\nto fall within the domain of a single science (Adams and Aizawa\n2010).\n\n\nThe intrinsic content criterion assumes a distinction between content\nthat is derived from human thought, as the content of the word\n\u2018martini\u2019 is derived from thoughts about martinis, and\ncontent that arises \u201con its own\u201d without having to depend\non some other contentful state for its origin. The thought\nmartini, for instance, presumably does not (or need not)\nderive from other contentful states but arises from some naturalistic\nprocess involving relationships between brain states and martinis\n(relationships that it is the business of a naturalistic theory of\ncontent to specify). Words, maps, signs, and so on possess derived,\nnon-intrinsic content whereas thoughts have intrinsic, non-derived,\noriginal content. Granting this distinction and its importance\nfor identifying genuinely cognitive states and processes, Adams and\nAizawa dismiss the plausibility of extended cognition on the grounds\nthat things like notebook entries and numerals written on paper do not\nhave intrinsic content.\n\n\nClark (2010) responds to this objection, in part pressing Adams and\nAizawa to clarify how much intrinsic content must be present in a\nsystem for the system to qualify as cognitive. After all, brains, if\nanything, are cognitive systems but not all activity occurring in a\nbrain involves states or processes with intrinsic\ncontent. Accordingly, Clark wonders, why should the fact that some\nelements of the Otto+ notebook system, because they lack\nintrinsic content, preclude the system from counting as cognitive?\n\n\nAdams and Adams propose in response that \u201cif you have a process\nthat involves no intrinsic content, then the condition rules that the\nprocess is non-cognitive (2010, 70). However, this response leaves\nopen whether Otto+ notebook constitutes a cognitive system. Because\nOtto\u2019s brain does indeed contain states and processes that\n\u201cinvolve\u201d intrinsic content\u2014states and processes by\nwhich the notebook entries are read and understood and used to guide\nbehavior\u2014Clark can readily accept Adams and Aizawa\u2019s\nstipulation. Some of the Otto+ notebook system involves intrinsic\ncontent, some does not, and the cognitive system as a whole\nincorporates both these elements.\n\n\nThe second mark of the mental that Adams and Aizawa take to preclude\nsystems like Otto+ notebook from counting as cognitive raises issues\nconcerning the identification of scientific domains. If one supposes,\nreasonably enough, that the objects, processes, properties, etc. that\nfall into the domain of a particular science do so in virtue of sharing\nparticular features, then one should expect the same for the domain of\ncognitive science. The parts, properties, and activities taking place\nin brains do seem to share important features, features that explain\nhow it is possible to identify brains in newly discovered species, how\nthey differ from igneous rocks, and so on. But now suppose that\ncognitive systems can be extended in ways that Clark, Chalmers and\nWilson have argued. Such systems would now contain constituents that\ncould not possibly fit into the domain of a single science. Extended\nsystems might include notebooks, or pencil and paper, or tools of just\nabout any sort. \u201c[F]or this reason,\u201d Adams and Aizawa\nargue, \u201ca would-be brain-tool science would have to cover more\nthan just a multiplicity of causal processes. It would have to cover a\ngenuine motley\u201d (2010, 76).\n\n\nRupert (2004) shares a similar concern, noting that the processes by\nwhich Otto and Inga locate MoMA differ so considerably that it makes\nno sense to treat them as of a kind\u2014as within the domain of a\nsingle science. Additionally, Rupert argues, there is no good reason\nto regard the various implements that combine with brain activity to\nbe constituents of a cognitive system rather than simply tools that\ncognitive systems use to ease the processing they require to complete\nsome task. Instead of insisting that cognitive systems extend, Rupert\nasks, why not regard them as seeking ways to embed themselves among\ntools that make their jobs easier? An axe does not become part of a\nperson when she uses it to chop down a tree, why does a notebook\nbecome part of cognitive system when a brain uses it to locate MoMA? A\nsensible conservatism, Rupert thinks, speaks in favor of seeing\ncognitive systems as embedded in environments that allow ready use of\ntools to reduce their workloads, rather than as constituted, in part,\nby such tools. The hypothesis that cognitive systems use tools\n\u201cis significantly less radical\u201d (2004, 7) than the\nhypothesis that tools are constituents of cognitive systems and would\nseem to provide adequate explanations for all the phenomena that\ninitially motivated the idea of extended cognition.\n\n\nFrom Clark\u2019s perspective, however, there is nothing motley, as\nAdams and Aizawa claim, about the brain+ tool systems that he\nbelieves constitute a legitimate kind for scientific\ninvestigation. Moreover, the processes by which Otto and Inga locate\nMoMA are not, as Rupert insists, vastly different. Once one steps back\nform the physical particularities of the constituents of extended\ncognitive systems and focuses just on the functional, computational,\nroles they play, such systems are identical, or very similar, to\nwholly brain-bound cognitive systems.\n\n\nSimilarly, Clark would deny Rupert\u2019s claim that the hypothesis\nof embedded cognition can equally well save the phenomena that the\nhypothesis of extended cognition was intended to capture and do so\nwhile requiring less revision of existing ideas about how cognitive\nsystems operate. A brain, Clark claims, is \u201c\u2019cognitively\nimpartial\u2019: It does not care how and where key operations are\nperformed\u201d (2008, 136). Rupert\u2019s conservatism in fact\nreflects a misunderstanding\u2014it conceives of brains as having the\nfunction of cognizing, which is true in a sense, but more accurate\nwould be a description of the brain\u2019s function as directing the\nconstruction of cognizing systems\u2014some (many?) of which include\nconstituents outside the brain proper (see also Wilson and Clark\n2009).\n\n\nFinally, Shapiro (2019b; 2019c) has suggested that the parity and\nwide-computationalist defenses of Constitution do not sit well with\nother commitments of embodied cognition. As mentioned, such defenses\nrest on a functionalist theory of cognition (for more on\n functionalism, see the entry on\n functionalism).\n Functionalism may well justify the claim that states and processes\noutside the brain can be identical to states and processes internal to\na brain (can stand in a relation of parity towards them), which in\nturn grounds the possibility that cognitive systems can contain\nnon-neural constituents. But, Shapiro argues, this strategy for\ndefending extended cognition seems contrary to the central theme of\nembodied cognition. Motivating the embodied turn in cognitive science\nis the idea that bodies are somehow essential to cognition. But the\nparity and wide-computational arguments for extended cognition entail\njust the opposite\u2014important for cognition are computational\nprocesses, and because computational processes are \u201chardware\nneutral\u201d, one need not consider the specifics of bodies in order\nto describe them. Thus, it appears, arguments in favor of extended\ncognition succeed to the extent that bodies, qua bodies, do\nnot matter to cognition.\n6. The Reach of Embodied Cognition\n\n\nIn addition to the usual cognitive terrain\u2014language, perception,\nmemory, categorization\u2014that embodied cognition encompasses,\nresearchers have recruited the concepts and methods of embodied\ncognition for the purpose of investigating other psychological\ndomains. In particular, embodied cognition finds application in the\nfields of social cognition and moral cognition.\n6.1 Social Cognition\n\n\nSocial cognition is the ability to understand and interact with other\nagents. A wide variety of cognitive capacities are involved in social\ncognition, such as attention, memory, affective cognition, and\nmetacognition (Fiske and Taylor 2013). Traditionally, however, the\nphilosophical discussion of social cognition has narrowly conceived of\nit in terms of mentalizing (also called theory of mind or\nmindreading). Mentalizing refers to the attribution of mental\nstates, often restricted to propositional attitudes, and typically for\nthe purpose of explaining and predicting others\u2019 behavior. Thus,\nalthough social cognition is enabled by and involves numerous and\ndiverse cognitive processes, many philosophers have tended to think of\nit simply as involving the attribution of propositional attitudes in\norder to predict and explain behavior. For canonical expressions of\nthis view of social cognition, see Davies and Stone (1995a) and\n(1995b). More recently, philosophers have begun to conceive of social\ncognition more broadly. See Andrews, Spaulding, and Westra (2020) for\na survey of Pluralistic Folk Psychology.\n\n\nEmbodied cognition theorists have rejected this narrow construal of\nsocial cognition. Though they do not deny that neurotypical adult\nhumans have the capacity to attribute beliefs and desires and to\nexplain and predict behavior, they argue that this is a specialized\nand rarely used skill in our ordinary social interactions (Gallagher\n2020; Gallagher 2008; Hutto and Ratcliffe 2007). Most social\ninteractions require only basic underlying social cognitive capacities\nthat are known as primary and secondary intersubjectivity (Trevarthen\n1979).\n\n\nPrimary intersubjectivity is the pre-theoretical, non-conceptual,\nembodied understanding of others that underlies and supports the\nhigher-level cognitive skills involved in mentalizing. It is\n\u201cthe innate or early developing capacity to interact with others\nmanifested at the level of perceptual experience\u2014we see or more\ngenerally perceive in the other person\u2019s bodily movements,\nfacial gestures, eye direction, and so on, what they intend and what\nthey feel\u201d (Gallagher 2005, 204). Primary intersubjectivity is\npresent from birth, but it continues to serve as the basis for our\nsocial cognition in adulthood. It manifests as the capacity for facial\nimitation, the capacity to detect and track eye movement, detect\nintentional behavior, and \u201cread\u201d emotions from actions and\nexpressive movements of others. Primary intersubjectivity consists in\ninformational sensitivity and appropriate responsiveness to specific\nfeatures of one\u2019s environment. It does not, embodied cognition\ntheorists argue, involve representing and theorizing about those\nfeatures. It simply requires certain practical abilities that have\nbeen shaped by selective pressures, e.g., sensitivity to certain\nbodily cues and facial expressions.\n\n\nAround one year of age, neurotypical children develop the capacity for\nsecondary intersubjectivity. This development enables a subject to\nmove from one-on-one, immediate intersubjectivity to shared attention.\nAt this stage, children learn to follow gazes, point, and communicate\nwith others about objects of shared attention. According to embodied\ncognition, the cognitive skills acquired through secondary\nintersubjectivity are not rich, meta-cognitive representations about\nother minds. Rather, children learn practical skills when getting\nothers to attend to an object and when learning to attend to objects\nothers are attending to. This allows for a richer understanding of\nother agents, but it is still meant to be a behavioral, embodied\nunderstanding rather than a representation of others\u2019\npropositional attitudes (Gallagher 2005, 207).\n\n\nAlthough primary and secondary intersubjectivity are described in\ndevelopmental terms, according to embodied cognition these\nintersubjective practices constitute our primary mode of social\ncognition even as adults (Fuchs 2012; Gallagher 2008). For example,\nHutto claims, \u201cOur primary worldly engagements are\nnonrepresentational and do not take the form of intellectual\nactivity\u201d (2008, 51). One can see in Hutto\u2019s description\nof social cognition a tendency toward the Replacement theme insofar as\nhe seeks to minimize or reject completely a role for representation in\nthe human capacity for understanding others\u2019\nbehavior. Mentalizing, it is argued, is a late developing, rarely\nused, specialized skill.  Primary and secondary intersubjectivity are\nfundamental insofar as they are sufficient for navigating most typical\nsocial interactions and insofar as they enable the development of\nhigher-level social cognition, like mentalizing. Although, see\nSpaulding (2010) for a critique of these arguments.\n\n\nMirror neurons may be an important mechanism of social cognition on\nthis kind of view. Mirror neurons are neurons that activate both\nendogenously in producing a behavior and exogenously in observing that\nvery same behavior. For instance, neurons in the premotor cortex and\ninferior parietal lobule activate when a subject uses, say, a\nwhole-handed grasp to pick up a bottle. These very same neurons\nselectively activate when a subject observes a target using a\nwhole-handed grasp to pick up an object. Neuroscientists have\ndiscovered similar patterns of activation in neurons in various parts\nof the brain, leading to the proposal that there are mirror neuron\nsystems for action, fear, anger, pain, disgust, etc. Though the\ninterpretation of these findings is subject to a great deal of\ncontroversy (Hickok 2009), many theorists propose that mirror neurons\nare a basic mechanism of social cognition (Gallese 2009; Goldman 2009;\nGoldman and de Vignemont 2009; Iacoboni 2009). The rationale is that\nmirror neurons explain how a subject understands a target\u2019s\nmental states without needing complicated, high-level inferences about\nbehavior and mental states. In observation mode, the subject\u2019s\nbrain activates as if the subject is doing, feeling, or experiencing\nwhat the target is doing, feeling, or experiencing. Thus, the\nobservation of the target\u2019s behavior is automatically meaningful\nto the subject. Mirror neurons are a possible mechanism for embodied\nsocial cognition. If the findings and interpretations are upheld, they\nsubstantiate the claim that we can understand and interact with others\nwithout engaging in mentalizing. For a survey of the reasons to be\ncautious about these interpretations of mirror neurons, see Spaulding\n(2011; 2013).\n6.2 Moral Cognition\n\n\nEmbodied moral cognition takes moral sentimentalism as a starting\n point. \n Moral sentimentalism\n is the view\nthat our emotions and desires are, in some way, fundamental to\nmorality, moral knowledge, and moral judgments. A particular version\nof moral sentimentalism holds that emotions, moral attitudes, and\nmoral judgments are generated by our \u201cgut reactions,\u201d and\nany moral reasoning that occurs is typically post-hoc rationalization\nof those gut reactions (Haidt 2001; Nichols 2004; Prinz\n2004). Embodied moral cognition takes inspiration from this kind of\nmoral sentimentalism. It holds that many of our moral judgments stem\nfrom our embodied, affective states rather than abstract\nreasoning.\n\n\nVarious sources of empirical evidence support this kind of view.\nConsider, for example, pathological cases, such as psychopaths or\nindividuals with damage to the ventromedial prefrontal cortex (vmPFC).\nSuch individuals are impaired in making moral judgments. Psychopaths\nfeel little compunction about behaving immorally and sometimes have a\nhard time differentiating moral from conventional norms (Hare 1999).\nIndividuals with damage to the vmPFC retain knowledge of abstract\nmoral principles but struggle in making specific, everyday moral\ndecisions (Damasio 1994). In both cases, individuals lack the\nphysiological responses that accompany neurotypical moral\ndecision-making. Lacking these \u201csomatic markers\u201d that\nguide moral judgments, these individuals behave in impulsive, selfish,\nand immoral ways (Damasio 1994). Embodied cognition would predict this\nconnection between physiological responses (like increased heartrate\nand palm sweating) and moral decision-making.\n\n\nPsychologists and neuroscientists have observed the influence of\nembodied cues on moral judgments in neurotypical individuals, as well.\nFor instance, experimentally manipulated perception of one\u2019s\nheartrate seems to influence one\u2019s moral judgments, with\nperceptions of faster heartrates leading to feelings of higher moral\ndistress and more just moral judgments (Gu, Zhong, and Page-Gould\n2013). Relatedly, there is some evidence that eliciting a feeling of\ndisgust leads to harsher moral judgments (Schnall et al. 2008).\nPerceptions of cleanliness seem to lead to less severe moral judgments\n(Schnall, Benton, and Harvey 2008). In each of these cases, perception\nof embodied cues seems to mediate moral judgments. Moral\nsentimentalists have observed that many people have strong aversive\nreactions to harmless actions that violate taboos, such as consensual\nprotected sex between adult siblings, cleaning a toilet with the\nnational flag, eating one\u2019s pet that had been run over, etc. In\nthese cases, the strong negative affective response precedes the moral\njudgment, and often people have a difficult time articulating\nwhy they think these victimless, harmless actions are morally\nwrong (Strejcek and Zhong 2014; Haidt 2001; Haidt, Koller, and Dias\n1993; Cushman, Young, and Hauser 2006). From the perspective of\nembodied cognition, this ordering confirms the notion that we make\nmoral judgments on the basis of embodied cues.\n\n\nDual process theories of moral psychology reject the moral\nsentimentalism claim that all moral judgments are made in the same\nway.  Dual process theories maintain that we have two systems of moral\ndecision-making: a system for Utilitarian reasoning that is driven by\naffect-less, abstract deliberation, and system for Deontological\nreasoning that is driven by automatic, intuitive, emotional heuristics\nlike gut feelings (Greene, 2014). Dual process theories are meant to\nexplain the seemingly inconsistent moral intuitions ordinary folks\nhave about moral dilemmas. For example, in a standard trolley case\nwhere an out-of-control trolley is heading toward five innocent,\nunaware individuals on the track ahead, most people have the intuition\nthat we ought to throw the switch so that the trolley goes onto a spur\nof the track, thereby killing one person on the spur but saving five\nlives.  However, in the footbridge variation of the trolley problem\nwhere saving the five lives requires pushing an individual off a\nfootbridge to derail the trolley, most people have the intuition that\nwe should not do this even though the consequences are the same as in\nthe standard trolley dilemma. The dual process theory holds that in\nthe former case, our reasoning is guided by a System-2 type of\nabstract reasoning. However, in the latter case, our moral reasoning\nis guided by an aversive physiological response triggered by imagining\npushing an individual off a footbridge. The dual process view\npartially vindicates the moral sentimentalist position insofar as it\nposits a distinctive System 1 type of moral reasoning that is based on\nembodied gut instincts. However, it maintains that there is a separate\nsystem operating on different inputs and processes for more abstract\nmoral reasoning.\n\n\nRecently, theorists have challenged dual process theories\u2019\nstrict dichotomy between reason and emotion (Huebner 2015; Maibom\n2010; Woodward 2016). On the one hand, brain areas that are associated\nwith emotions like fear, anger, and disgust are implicated in complex\nlearning and inferential processing. On the other hand, individuals\nwho are clearly impaired in moral decision-making\u2014psychopaths\nand those with damaged vmPFC\u2014also suffer deficits in other kinds\nof learning and inferential processing. Abstract reasoning is not, as\nit turns out, cut off from affective processes. Somatic markers,\naffective cues, and physiological responses are central to reasoning,\nlearning, and decision-making. For the proponent of embodied moral\ncognition, this serves as further confirmation of the idea that all\ncognition, including moral cognition, is deeply shaped by embodied\ncues. Though see May (2018), May and Kumar (2018) and Railton (2017)\nfor a moral rationalist take on these findings.\n7. Conclusion\n\n\nThis article aims to convey a sense of the breadth of topics that fall\nwithin the field of embodied cognition, as well as the numerous\ncontroversies that have been of special philosophical interest. As\nwith any nascent research program, there remain questions about how\nembodied cognition relates to its forebears, in particular\ncomputational cognitive science and ecological psychology. Some of the\nhardest philosophical questions arising within embodied cognition,\nsuch as those concerning representation, explanation, and the very\nmeaning of \u2018mind\u2019, are of a sort that any theory of mind\nmust address.  Apart from philosophical challenges to the conceptual\nintegrity of embodied cognition there loom psychological concerns\nabout the replicability of some of the most-cited findings within\nembodied cognition; although, in fairness, worries about replicability\nhave recently arisen in many areas of psychology (Goldhill 2019;\nLakens 2014; Maxwell, Lau, and Howard 2015; Rabelo et\nal. 2015). Whatever the future of embodied cognition, careful study of\nits aims, methods, conceptual foundations, and motivations will\ndoubtless enrich the philosophy of psychology.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Adams, Fred, and Ken Aizawa, 2001, \u201cThe Bounds of\nCognition,\u201d <em>Philosophical Psychology</em>, 14(1):\n43\u201364.  doi:10.1080/09515080120033571",
                "\u2013\u2013\u2013, 2008, <em>The Bounds of Cognition</em>,\nMalden, MA: Blackwell.",
                "\u2013\u2013\u2013, 2009, \u201cWhy the Mind Is Still in the\nHead,\u201d in Philip Robbins and Murat Aydede (eds.), <em>The\nCambridge Handbook of Situated Cognition</em>, 1st edition, Cambridge, New\nYork: Cambridge University Press, pp, 78\u201395.",
                "\u2013\u2013\u2013, 2010, \u201cDefending the Bounds of\nCognition,\u201d in Richard Menary (ed.), <em>The Extended Mind</em>,\nCambridge, Mass.: MIT Press, pp, 67\u201380.",
                "Andrews, Kristin, Shannon Spaulding, and Evan Westra, 2020,\n\u201cIntroduction to <em>Folk Psychology: Pluralistic Approaches</em>,\u201d\n<em>Synthese</em>, August, 1\u201316, doi:10.1007/s11229-020-02837-3",
                "Baggs, Edward, and Anthony Chemero, 2018, \u201cRadical\nEmbodiment in Two Directions,\u201d <em>Synthese</em>, 198\n(Supplement 9): 2175\u20132190. doi:10.1007/s11229-018-02020-9",
                "Barsalou, Lawrence W, 1999, \u201cPerceptual Symbol\nSystems,\u201d <em>Behavioral and Brain Sciences</em>, 22(4): 577\u2013660.\ndoi:10.1017/S0140525X99002149",
                "\u2013\u2013\u2013, 2008, \u201cGrounded Cognition,\u201d\n<em>Annual Review of Psychology</em>, 59(1): 617\u201345.\ndoi:10.1146/annurev.psych.59.103006.093639",
                "Barsalou, Lawrence W., W. Kyle Simmons, Aron K. Barbey, and\nChristine D. Wilson, 2003, \u201cGrounding Conceptual Knowledge in\nModality-Specific Systems,\u201d <em>Trends in Cognitive\nSciences</em>, 7(2): 84\u201391.\ndoi:10.1016/S1364-6613(02)00029-3",
                "Barsalou, Lawrence W., and Katja Wiemer-Hastings, 2005,\n\u201cSituating Abstract Concepts,\u201d in Diane Pecher and Rolf A.\nZwaan <em>(</em>eds.), <em>Grounding Cognition</em> (1st edition), pp.\n129\u201363, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511499968.007",
                "Bechtel, William, 1998, \u201cRepresentations and Cognitive\nExplanations: Assessing the Dynamicist\u2019s Challenge in Cognitive\nScience,\u201d <em>Cognitive Science</em>, 22(3): 295\u2013318.\ndoi:10.1207/s15516709cog2203_2.",
                "Beer, Randall D, 2000, \u201cDynamical Approaches to Cognitive\nScience,\u201d <em>Trends in Cognitive Sciences</em>, 4(3):\n91\u201399. doi:10.1016/S1364-6613(99)01440-0",
                "\u2013\u2013\u2013, 2003, \u201cThe Dynamics of Active\nCategorical Perception in an Evolved Model Agent,\u201d <em>Adaptive\nBehavior</em>, 11(4): 209\u201343.\ndoi:10.1177/1059712303114001",
                "Broadbent, Donald E., 1958, <em>Perception and Communication</em>,\nNew York: Pergamon Press.",
                "Brooks, Rodney. A., 1991a, \u201cNew Approaches to\nRobotics,\u201d <em>Science</em>, 253 (5025): 1227\u201332.\ndoi:10.1126/science.253.5025.1227",
                "\u2013\u2013\u2013, 1991b, \u201cIntelligence without\nRepresentation,\u201d <em>Artificial Intelligence</em>, 47(1\u20133):\n139\u201359. doi:10.1016/0004-3702(91)90053-M",
                "Buccino, Giovanni, Lucia Riggio, Gabor Melli, Ferdinand Binkofski,\nVittorio Gallese, and Giacomo Rizzolatti, 2005, \u201cListening to\nAction-Related Sentences Modulates the Activity of the Motor System: A\nCombined TMS and Behavioral Study,\u201d <em>Cognitive Brain\nResearch</em>, 24(3): 355\u201363. doi:10.1016/j.cogbrainres.2005.02.020",
                "Chemero, Anthony, 2001, \u201cDynamical Explanation and Mental\nRepresentations,\u201d <em>Trends in Cognitive Sciences</em>, 5(4):\n141\u201342. doi:10.1016/S1364-6613(00)01627-2",
                "\u2013\u2013\u2013, 2009, <em>Radical Embodied Cognitive\nScience</em>, Cambridge, MA: MIT Press.",
                "\u2013\u2013\u2013, 2016, \u201cSensorimotor Empathy,\u201d\n<em>Journal of Consciousness Studies</em>, 23(5\u20136):\n138\u201352.",
                "\u2013\u2013\u2013, 2021, \u201cEpilogue: What Embodiment\nIs,\u201d in Nancy Dess (ed.), <em>A Multidisciplinary Approach to\nEmbodiment: Understanding Human Being</em>, New York: Routledge,\npp. 133\u201340.",
                "Chomsky, Noam, 1959, \u201cOn Certain Formal Properties of\nGrammars,\u201d <em>Information and Control</em>, 2(2): 137\u201367.\ndoi:10.1016/S0019-9958(59)90362-6",
                "\u2013\u2013\u2013, 1980, \u201cOn Cognitive Structures and Their\nDevleopment: A Reply to Piaget,\u201d in Massimo Piattelli-Palmarini\n(ed.), <em>Language and Learning\u202f: The Debate between Jean Piaget\nand Noam Chomsky</em>, Cambridge, Mass.: Harvard University Press.",
                "Clark, Andy, 1997, \u201cThe Dynamical Challenge,\u201d\n<em>Cognitive Science</em>, 21(4): 461\u201381.\ndoi:10.1207/s15516709cog2104_3",
                "\u2013\u2013\u2013, 2008, <em>Supersizing the Mind: Embodiment,\nAction, and Cognitive Extension</em>, Oxford, New York: Oxford\nUniversity Press.",
                "\u2013\u2013\u2013, 2010, \u201cCoupling, Constitution, and the\nCognitive Kind: A Reply to Adams and Aizawa,\u201d in Richard Menary\n(ed.), <em>The Extended Mind</em>, Cambridge, Mass.: MIT Press, pp.\n81\u2013100.",
                "Clark, Andy, and David J. Chalmers, 1998, \u201cThe Extended\nMind,\u201d <em>Analysis</em>, 58(1): 7\u201319.",
                "Clark, Andy, and Josefa Toribio, 1994, \u201cDoing without\nRepresenting?\u201d <em>Synthese</em>, 101(3): 401\u201331.\ndoi:10.1007/BF01063896.",
                "Cushman, Fiery, Liane Young, and Marc Hauser, 2006, \u201cThe Role\nof Conscious Reasoning and Intuition in Moral Judgment: Testing Three\nPrinciples of Harm,\u201d <em>Psychological Science</em>, 17(12):\n1082\u201389.",
                "Damasio, Antonio R., 1994, \u201cDescartes\u2019 Error and the\nFuture of Human Life,\u201d <em>Scientific American</em>, 271(4):\n144\u2013144.",
                "Davies, Martin, and Tony Stone, 1995a, <em>Folk Psychology: The\nTheory of Mind Debate</em>, Oxford: Blackwell.",
                "\u2013\u2013\u2013, 1995b, <em>Mental Simulation: Evaluations\nand Applications</em> (Volume 4), Oxford: Blackwell.",
                "Dietrich, Eric, and Arthur B. Markman, 2001, \u201cDynamical\nDescription versus Dynamical Modeling,\u201d <em>Trends in Cognitive\nSciences</em>, 5(8): 332.\ndoi:10.1016/S1364-6613(00)01705-8",
                "Dove, Guy, 2009, \u201cBeyond Perceptual Symbols: A Call for\nRepresentational Pluralism,\u201d <em>Cognition</em>, 110(3):\n412\u201331. doi:10.1016/j.cognition.2008.11.016",
                "\u2013\u2013\u2013, 2016, \u201cThree Symbol Ungrounding\nProblems: Abstract Concepts and the Future of Embodied\nCognition,\u201d <em>Psychonomic Bulletin &amp; Review</em>, 23(4):\n1109\u201321.",
                "Edmiston, Pierce, and Gary Lupyan, 2017, \u201cVisual Interference\nDisrupts Visual Knowledge,\u201d <em>Journal of Memory and\nLanguage</em>, 92 (February): 281\u201392.\ndoi:10.1016/j.jml.2016.07.002",
                "Eliasmith, Chris, 1996, \u201cThe Third Contender: A Critical\nExamination of the Dynamicist Theory of Cognition,\u201d\n<em>Philosophical Psychology</em>, 9(4): 441\u201363.\ndoi:10.1080/09515089608573194",
                "Fiske, Susan T., and Shelley E. Taylor, 2013, <em>Social Cognition:\nFrom Brains to Culture</em>, London: Sage.",
                "Fodor, Jerry A., 1987, <em>Psychosemantics</em><em>: The Problem of\nMeaning in the Philosophy of Mind</em>, Cambridge, Mass.: MIT\nPress.",
                "Fuchs, Thomas, 2013, \u201cThe Phenomenology and Development of\nSocial Perspectives,\u201d <em>Phenomenology and the Cognitive\nSciences</em>, 12(4): 655\u2013683.\ndoi:10.1007/s11097-012-9267-x",
                "Gallagher, Shaun, 2005, <em>How the Body Shapes the Mind</em>,\nOxford, Oxford University Press.",
                "\u2013\u2013\u2013, 2008, \u201cInference or Interaction: Social\nCognition without Precursors,\u201d <em>Philosophical\nExplorations</em>, 11(3): 163\u201374.",
                "\u2013\u2013\u2013, 2020, <em>Action and Interaction</em>, Oxford:\nUniversity Press.",
                "Gallagher, Shaun, and Daniel D. Hutto, 2008, \u201cUnderstanding\nOthers through Primary Interaction and Narrative Practice,\u201d in\nChris Sinha, Esa Itkonen, Jordan Zlatev, and Timothy P. Racine (eds.),\n<em>The Shared Mind: Perspectives on Intersubjectivity</em>,\nAmsterdam: John Benjamins, pp. 17\u201338.",
                "Gallese, Vittorio, 2009, \u201cMirror Neurons and the Neural\nExploitation Hypothesis: From Embodied Simulation to Social\nCognition,\u201d in Jaimie A. Pineda (ed.), <em>Mirror Neuron\nSystems</em>, New York: Humana, pp. 163\u201390.",
                "Gibson, James J., 1966, <em>The Senses Considered as Perceptual\nSystems</em>, Boston: Houghton Mifflin.",
                "\u2013\u2013\u2013, 1979, <em>The Ecological Approach to Visual\nPerception</em>, Boston: Houghton Mifflin.",
                "Glenberg, Arthur M., and Michael P. Kaschak, 2002, \u201cGrounding\nLanguage in Action,\u201d <em>Psychonomic Bulletin &amp; Review</em>,\n9(3): 558\u201365. doi:10.3758/BF03196313",
                "Goldhill, Olivia, 2019, \u201cThe Replication Crisis Is Killing\nPsychologists\u2019 Theory of How the Body Influences the Mind,\u201d\n<em>Quartz</em>, 16 January 2019, \n [<a href=\"https://qz.com/1525854/psychologys-replication-crisis-is-debunking-embodied-cognition-theory/\" target=\"other\">Goldhill 2019 available online</a>].",
                "Goldman, Alvin I., 2009, \u201cMirroring, Mindreading, and\nSimulation,\u201d in Jaimie A. Pineda (ed.), <em>Mirror Neuron\nSystems</em>, New York: Humana, pp. 311\u201330.",
                "Goldman, Alvin I., and Frederique de Vignemont, 2009, \u201cIs\nSocial Cognition Embodied?\u201d <em>Trends in Cognitive\nSciences</em>, 13(4): 154\u201359.",
                "Greene, Joshua D., \u201cBeyond Point-and-Shoot Morality,\u201d\n<em>Ethics</em>, 124(4): 695\u2013726.",
                "Gu, Jun, Chen-Bo Zhong, and Elizabeth Page-Gould, 2013,\n\u201cListen to Your Heart: When False Somatic Feedback Shapes Moral\nBehavior,\u201d <em>Journal of Experimental Psychology: General</em>,\n142(2): 307.",
                "Haidt, Jonathan, 2001, \u201cThe Emotional Dog and Its Rational\nTail: A Social Intuitionist Approach to Moral Judgment,\u201d\n<em>Psychological Review</em>, 108(4): 814\u2013834.",
                "Haidt, Jonathan, Silvia Helena Koller, and Maria G Dias, 1993,\n\u201cAffect, Culture, and Morality, or Is It Wrong to Eat Your\nDog?\u201d <em>Journal of Personality and Social Psychology</em>,\n65(4): 613\u2013628.",
                "Haken, Hermann, J. A. Scott Kelso, and Herbert Bunz, 1985, \u201cA\nTheoretical Model of Phase Transitions in Human Hand Movements,\u201d\n<em>Biological Cybernetics</em>, 51(5): 347\u201356.\ndoi:10.1007/BF00336922",
                "Hare, Robert D., 1999, <em>Without Conscience: The Disturbing World\nof the Psychopaths among Us</em>, New York: Guilford Press.",
                "Hatfield, Gary, 1991, \u201cRepresentation and Rule-Instantiation\nin Connectionist Systems,\u201d in Terence Horgan and John Tienson\n(eds.), <em>Connectionism and the Philosophy of Mind</em> (Studies in\nCognitive Systems), Dordrecht: Springer Netherlands, pp. 90\u2013112.\ndoi:10.1007/978-94-011-3524-5_5",
                "Heidegger, Martin, 1975, <em>The Basic Problems of\nPhenomenology</em>, translated by Albert Hofstadter, 1988,\nBloomington: Indiana University Press.",
                "Hickok, Gregory, 2009, \u201cEight Problems for the Mirror Neuron\nTheory of Action Understanding in Monkeys and Humans,\u201d\n<em>Journal of Cognitive Neuroscience</em>, 21(7): 1229\u201343.\ndoi:10.1162/jocn.2009.21189",
                "Huebner, Bryce, 2015, \u201cDo Emotions Play a Constitutive Role\nin Moral Cognition?\u201d <em>Topoi</em>, 34(2): 427\u201340.",
                "Husserl, Edmund, 1929, <em>Cartesian Meditations: An Introduction to\nPhenomenology</em>, translated by Dorian Cairns, 2012, Dordrect:\nSpringer Science &amp; Business Media.",
                "Hutchins, Edwin, 1996, <em>Cognition in the Wild</em> (second\nprinting), Cambridge, Mass.: MIT Press.",
                "Hutto, Daniel D., 2008, <em>Folk Psychological Narratives: The\nSociocultural Basis of Understanding Reasons</em>, Cambridge, Mass.:\nMIT Press.",
                "Hutto, Daniel D., and Erik Myin, 2013, <em>Radicalizing Enactivism:\nBasic Minds without Content</em>, Cambridge, Mass.: MIT Press.",
                "Hutto, Daniel D., and M. Ratcliffe, 2007, <em>Folk Psychology\nRe-Assessed</em>, Dordrecht; London: Springer.",
                "Kelso, J. A. Scott, 1995, <em>Dynamic Patterns\u202f: The\nSelf-Organization of Brain and Behavior</em>, Cambridge, Mass.: MIT\nPress.",
                "Lakens, Dani\u00ebl, 2014, \u201cGrounding Social\nEmbodiment,\u201d <em>Social Cognition</em>, 32 (Supplement):\n168\u201383. doi:10.1521/soco.2014.32.supp.168",
                "Lakoff, George, and Mark Johnson, 1980, <em>Metaphors We Live\nBy</em>, Chicago: University of Chicago Press.",
                "\u2013\u2013\u2013, 1999, <em>Philosophy in the Flesh: The\nEmbodied Mind and Its Challenge to Western Thought</em>, New York:\nBasic Books.",
                "Leeuwen, Marco van, 2005, \u201cQuestions For The Dynamicist: The\nUse of Dynamical Systems Theory in the Philosophy of Cognition,\u201d\n<em>Minds and Machines</em>, 15(3\u20134): 271\u2013333.\ndoi:10.1007/s11023-004-8339-2",
                "Mahon, Bradford Z., 2015, \u201cWhat Is Embodied about\nCognition?\u201d <em>Language, Cognition and Neuroscience</em>, 30(4):\n420\u201329. doi:10.1080/23273798.2014.987791",
                "Mahon, Bradford Z., and Alfonso Caramazza, 2008, \u201cA Critical\nLook at the Embodied Cognition Hypothesis and a New Proposal for\nGrounding Conceptual Content,\u201d <em>Journal of\nPhysiology-Paris</em>, Links and Interactions Between Language and\nMotor Systems in the Brain, 102(1): 59\u201370.\ndoi:10.1016/j.jphysparis.2008.03.004",
                "Maibom, Heidi, 2010, \u201cWhat Experimental Evidence Shows Us\nabout the Role of Emotions in Moral Judgement,\u201d <em>Philosophy\nCompass</em>, 5(11): 999\u20131012.",
                "Marr, David, 1982, <em>Vision: A Computational Investigation into\nthe Human Representation and Processing of Visual Information</em>, San\nFrancisco: W. H. Freeman.",
                "Martin, Taylor, and Daniel L. Schwartz, 2005a, \u201cPhysically\nDistributed Learning: Adapting and Reinterpreting Physical Environments\nin the Development of Fraction Concepts,\u201d <em>Cognitive\nScience</em>, 29(4): 587\u2013625.\ndoi:10.1207/s15516709cog0000_15",
                "\u2013\u2013\u2013, 2005b, \u201cPhysically Distributed Learning:\nAdapting and Reinterpreting Physical Environments in the Development of\nFraction Concepts,\u201d <em>Cognitive Science</em>, 29(4):\n587\u2013625. doi:10.1207/s15516709cog0000_15",
                "Matthen, Mohan, 2014, \u201cDebunking Enactivism: A Critical\nNotice of Hutto and Myin\u2019s Radicalizing\nEnactivism,\u201d <em>Canadian Journal of Philosophy</em>, 44(1):\n118\u201328. doi:10.1080/00455091.2014.905251",
                "Maxwell, Scott E., Michael Y. Lau, and George S. Howard, 2015,\n\u201cIs Psychology Suffering from a Replication Crisis? What Does\n\u2018Failure to Replicate\u2019 Really Mean?\u201d <em>American\nPsychologist</em>, 70(6): 487\u201398.\ndoi:10.1037/a0039400",
                "May, Joshua, 2018, <em>Regard for Reason in the Moral Mind</em>,\nOxford: Oxford University Press.",
                "May, Joshua, and Victor Kumar, 2018, \u201cMoral Reasoning and\nEmotion,\u201d in Karen Jones, Mark Timmons and Aaron Zimmerman\n(eds.), <em>Routledge Handbook on Moral Epistemology</em>.\nLondon: Routledge, pp. 139\u2013156.",
                "Menary, Richard, 2008, <em>Cognitive Integration: Mind and Cognition\nUnbounded</em>, Basingstoke, New York: Palgrave Macmillan.",
                "Merleau-Ponty, Maurice, 1962, <em>Phenomenology of Perception</em>,\ntranslated by Colin Smith, London: Routledge.",
                "Michaels, Claire, and Zsolt Palatinus, 2014, \u201cA Ten\nCommandments for Ecological Psychology,\u201d in Lawrence Shapiro\n(ed.), <em>The Routledge Handbook of Embodied Cognition</em>, New\nYork: Routledge, Taylor &amp; Francis Group, pp. 19\u201328.",
                "Newell, Allen, John C. Shaw, and Herbert A. Simon, 1958,\n\u201cElements of a Theory of Human Problem Solving,\u201d\n<em>Psychological Review</em>, 65(3): 151\u201366.\ndoi:10.1037/h0048495",
                "Nichols, Shaun, 2004, <em>Sentimental Rules: On the Natural\nFoundations of Moral Judgment</em>, Oxford: Oxford University\nPress.",
                "No\u00eb, Alva, 2004, <em>Action in Perception</em>, Cambridge,\nMass: MIT Press.",
                "O\u2019Regan, J. Kevin, and Alva No\u00eb, 2001, \u201cA\nSensorimotor Account of Vision and Visual Consciousness,\u201d\n<em>Behavioral and Brain Sciences</em>, 24(5): 939\u201373.\ndoi:10.1017/S0140525X01000115",
                "Pouw, Wim T. J. L., Tamara van Gog, and Fred Paas, 2014, \u201cAn\nEmbedded and Embodied Cognition Review of Instructional\nManipulatives,\u201d <em>Educational Psychology Review</em>, 26(1):\n51\u201372. doi:10.1007/s10648-014-9255-5",
                "Prinz, Jesse J., 2004, <em>Gut Reactions: A Perceptual Theory of\nEmotion</em>, Oxford: Oxford University Press.",
                "Prinz, Jesse J., and Lawrence W. Barsalou, 2000, \u201cSteering a\nCourse for Embodied Representation,\u201d in Eric Dietrich and Arthur\nMarkman (eds.), <em>Cognitive Dynamics: Conceptual Change in Humans\nand Machines</em>, Cambridge, MA: MIT Press, pp. 51\u201377.",
                "Pulverm\u00fcller, Friedemann, 2005, \u201cBrain Mechanisms Linking\nLanguage and Action,\u201d <em>Nature Reviews Neuroscience</em>, 6(7):\n576\u201382. doi:10.1038/nrn1706",
                "Rabelo, Andr\u00e9 L. A., Victor N. Keller, Ronaldo Pilati, and\nJelte M. Wicherts, 2015, \u201cNo Effect of Weight on Judgments of\nImportance in the Moral Domain and Evidence of Publication Bias from a\nMeta-Analysis,\u201d <em>PLoS ONE</em>, 10(8).\ndoi:10.1371/journal.pone.0134808",
                "Railton, Peter, 2017, \u201cMoral Learning: Conceptual Foundations\nand Normative Relevance,\u201d <em>Cognition</em>, 167 (October):\n172\u201390.",
                "Rey, Georges, 1983, \u201cConcepts and Stereotypes,\u201d\n<em>Cognition</em>, 15(1): 237\u201362.\ndoi:10.1016/0010-0277(83)90044-6",
                "\u2013\u2013\u2013, 1985, \u201cConcepts and Conceptions: A Reply\nto Smith, Medin and Rips,\u201d <em>Cognition</em>, 19(3):\n297\u2013303. doi:10.1016/0010-0277(85)90037-X",
                "Rupert, Robert D., 2004, \u201cChallenges to the Hypothesis of\nExtended Cognition,\u201d <em>The Journal of Philosophy</em>, 101(8):\n389\u2013428.",
                "Sauer, Niko, 2010, \u201cCausality and Causation: What We Learn\nfrom Mathematical Dynamic Systems Theory,\u201d <em>Transactions of\nthe Royal Society of South Africa</em>, 65(1): 65\u201368.\ndoi:10.1080/00359191003680091",
                "Schnall, Simone, Jennifer Benton, and Sophie Harvey, 2008,\n\u201cWith a Clean Conscience: Cleanliness Reduces the Severity of\nMoral Judgments,\u201d <em>Psychological Science</em>, 19(12):\n1219\u201322.",
                "Schnall, Simone, Jonathan Haidt, Gerald L Clore, and Alexander H\nJordan, 2008, \u201cDisgust as Embodied Moral Judgment,\u201d\n<em>Personality and Social Psychology Bulletin</em>, 34(8):\n1096\u20131109.",
                "Shapiro, Lawrence, 2007, \u201cThe Embodied Cognition Research\nProgramme,\u201d <em>Philosophy Compass</em>, 2(2): 338\u201346.\ndoi:10.1111/j.1747-9991.2007.00064.x",
                "\u2013\u2013\u2013, 2012, \u201cEmbodied Cognition,\u201d in\nEric Margolis, Richard Samuels and Stephen P. Stich (eds.), <em>The\nOxford Handbook of Philosophy of Cognitive Science</em>, New York:\nOxford University Press, pp. 118\u2013147.",
                "\u2013\u2013\u2013, 2013, \u201cDynamics and Cognition,\u201d\n<em>Minds and Machines</em>, 23(3): 353\u201375.\ndoi:10.1007/s11023-012-9290-2",
                "\u2013\u2013\u2013, 2019a, <em>Embodied Cognition</em>, Second\nEdition, London; New York: Routledge.",
                "\u2013\u2013\u2013, 2019b, \u201cMatters of the Flesh: The\nRole(s) of Body in Cognition,\u201d in Matteo Colombo, Elizabeth\nIrvine and Mog Stapleton (eds.), <em>Andy Clark and His Critics</em>,\nNew York, NY: Oxford University Press, pp. 69\u201380.",
                "\u2013\u2013\u2013, 2019c, \u201cFlesh Matters: The Body in\nCognition,\u201d <em>Mind &amp; Language</em>, 34(1): 3\u201320.\ndoi:10.1111/mila.12203",
                "Spaulding, Shannon, 2010, \u201cEmbodied Cognition and\nMindreading,\u201d <em>Mind &amp; Language</em>, 25(1):\n119\u201340.",
                "\u2013\u2013\u2013, 2011, \u201cA Critique of Embodied\nSimulation,\u201d <em>Review of Philosophy and Psychology</em>, 2(3):\n579\u201399.",
                "\u2013\u2013\u2013, 2013, \u201cMirror Neurons and Social\nCognition,\u201d <em>Mind &amp; Language</em>, 28(2):\n233\u201357.",
                "Spivey, Michael J., 2007, <em>The Continuity of Mind</em> (Oxford\nPsychology Series), Oxford, New York: Oxford University Press.",
                "Sternberg, Saul, 1969, \u201cMemory-Scanning: Mental Processes\nRevealed by Reaction-Time Experiments,\u201d <em>American\nScientist</em>, 57(4): 421\u201357.",
                "Symes, Ed, Rob Ellis, and Mike Tucker, 2007, \u201cVisual Object\nAffordances: Object Orientation,\u201d <em>Acta Psychologica</em>,\n124(2): 238\u201355. doi:10.1016/j.actpsy.2006.03.005",
                "Tettamanti, Marco, Giovanni Buccino, Maria Cristina Saccuman,\nVittorio Gallese, Massimo Danna, Paola Scifo, Ferruccio Fazio, Giacomo\nRizzolatti, Stefano F. Cappa, and Daniela Perani, 2005,\n\u201cListening to Action-Related Sentences Activates Fronto-Parietal\nMotor Circuits,\u201d <em>Journal of Cognitive Neuroscience</em>,\n17(2): 273\u201381. doi:10.1162/0898929053124965",
                "Thelen, Esther, Gregor Sch\u00f6ner, Christian Scheier, and Linda B.\nSmith, 2001, \u201cThe Dynamics of Embodiment: A Field Theory of\nInfant Perseverative Reaching,\u201d <em>Behavioral and Brain\nSciences</em>, 24(1): 1\u201334.\ndoi:10.1017/S0140525X01003910",
                "Thelen, Esther, and Linda Smith (eds.), 1993, <em>A Dynamic Systems\nApproach to Development: Applications</em>, Cambridge, Mass.: MIT\nPress.",
                "Thompson, Evan, 2010, <em>Mind in Life</em>, Cambridge, MA:\nHarvard University Press.",
                "Trevarthen, Colwyn, 1979, \u201cCommunication and Cooperation in\nEarly Infancy: A Description of Primary Intersubjectivity,\u201d in\nMargaret Bullowa (ed.) <em>Before Speech: The Beginning of\nInterpersonal Communication</em>, Cambridge: Cambridge University\nPress, pp. 321\u2013348.",
                "Tucker, Mike, and Rob Ellis, 1998, \u201cOn the Relations between\nSeen Objects and Components of Potential Actions,\u201d <em>Journal of\nExperimental Psychology: Human Perception and Performance</em>, 24(3):\n830\u201346. doi:10.1037/0096-1523.24.3.830",
                "\u2013\u2013\u2013, 2001, \u201cThe Potentiation of Grasp Types\nduring Visual Object Categorization,\u201d <em>Visual Cognition</em>,\n8(6): 769\u2013800. doi:10.1080/13506280042000144",
                "\u2013\u2013\u2013, 2004, \u201cAction Priming by Briefly\nPresented Objects,\u201d <em>Acta Psychologica</em>, 116(2):\n185\u2013203. doi:10.1016/j.actpsy.2004.01.004",
                "Van Gelder, Tim, 1995, \u201cWhat Might Cognition Be, If Not\nComputation?\u201d <em>The Journal of Philosophy</em>, 92(7):\n345\u201381. doi:10.2307/2941061",
                "\u2013\u2013\u2013, 1998, \u201cThe Dynamical Hypothesis in\nCognitive Science,\u201d <em>Behavioral and Brain Sciences</em>,\n21(5): 615\u201328. doi:10.1017/S0140525X98001733",
                "Varela, Francisco J., Evan Thompson, and Eleanor Rosch, 2017,\n<em>The Embodied Mind, Revised Edition: Cognitive Science and Human\nExperience</em>, Cambridge, Mass: MIT Press.",
                "Ward, Dave, David Silverman, and Mario Villalobos, 2017,\n\u201cIntroduction: The Varieties of Enactivism,\u201d\n<em>Topoi</em>, 36(3): 365\u201375.\ndoi:10.1007/s11245-017-9484-6",
                "Wilson, Andrew D., and Sabrina Golonka, 2013, \u201cEmbodied\nCognition Is Not What You Think It Is,\u201d <em>Frontiers in\nPsychology</em>, 4, published online 12 February 2013. \ndoi:10.3389/fpsyg.2013.00058",
                "Wilson, Margaret, 2002, \u201cSix Views of Embodied\nCognition,\u201d <em>Psychonomic Bulletin &amp; Review</em>, 9(4):\n625\u201336. doi:10.3758/BF03196322",
                "Wilson, Robert A., 1994, \u201cWide Computationalism,\u201d\n<em>Mind</em>, 103(411): 351\u201372. doi:10.1093/mind/103.411.351",
                "Wilson, Robert A., and Andy Clark, 2001, \u201cHow to Situate\nCognition: Letting Nature Take Its Course,\u201d in Philip Robbins\nand Murat Aydede (eds.) <em>The Cambridge Handbook of Situated\nCognition</em>, 1st ed., Cambridge: Cambridge University Press, pp.\n55\u201377.  doi:10.1017/CBO9780511816826.004",
                "Woodward, James, 2016, \u201cEmotion versus Cognition in Moral\nDecision-Making: A Dubious Dichotomy,\u201d in S. Matthew Liao (ed.),\n<em>Moral Brains: The Neuroscience of Morality</em>, Oxford: Oxford\nUniversity Press, pp. 87\u2013116.",
                "Zahavi, Dan, 2005, <em>Subjectivity and Selfhood: Investigating\nthe First-Person Perspective</em>, Cambridge, Mass.: MIT Press.",
                "Zednik, Carlos, 2011, \u201cThe Nature of Dynamical\nExplanation,\u201d <em>Philosophy of Science</em>, 78(2):\n238\u201363."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Adams, Fred, and Ken Aizawa, 2001, \u201cThe Bounds of\nCognition,\u201d <em>Philosophical Psychology</em>, 14(1):\n43\u201364.  doi:10.1080/09515080120033571</li>\n<li>\u2013\u2013\u2013, 2008, <em>The Bounds of Cognition</em>,\nMalden, MA: Blackwell.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cWhy the Mind Is Still in the\nHead,\u201d in Philip Robbins and Murat Aydede (eds.), <em>The\nCambridge Handbook of Situated Cognition</em>, 1st edition, Cambridge, New\nYork: Cambridge University Press, pp, 78\u201395.</li>\n<li>\u2013\u2013\u2013, 2010, \u201cDefending the Bounds of\nCognition,\u201d in Richard Menary (ed.), <em>The Extended Mind</em>,\nCambridge, Mass.: MIT Press, pp, 67\u201380.</li>\n<li>Andrews, Kristin, Shannon Spaulding, and Evan Westra, 2020,\n\u201cIntroduction to <em>Folk Psychology: Pluralistic Approaches</em>,\u201d\n<em>Synthese</em>, August, 1\u201316, doi:10.1007/s11229-020-02837-3</li>\n<li>Baggs, Edward, and Anthony Chemero, 2018, \u201cRadical\nEmbodiment in Two Directions,\u201d <em>Synthese</em>, 198\n(Supplement 9): 2175\u20132190. doi:10.1007/s11229-018-02020-9</li>\n<li>Barsalou, Lawrence W, 1999, \u201cPerceptual Symbol\nSystems,\u201d <em>Behavioral and Brain Sciences</em>, 22(4): 577\u2013660.\ndoi:10.1017/S0140525X99002149</li>\n<li>\u2013\u2013\u2013, 2008, \u201cGrounded Cognition,\u201d\n<em>Annual Review of Psychology</em>, 59(1): 617\u201345.\ndoi:10.1146/annurev.psych.59.103006.093639</li>\n<li>Barsalou, Lawrence W., W. Kyle Simmons, Aron K. Barbey, and\nChristine D. Wilson, 2003, \u201cGrounding Conceptual Knowledge in\nModality-Specific Systems,\u201d <em>Trends in Cognitive\nSciences</em>, 7(2): 84\u201391.\ndoi:10.1016/S1364-6613(02)00029-3</li>\n<li>Barsalou, Lawrence W., and Katja Wiemer-Hastings, 2005,\n\u201cSituating Abstract Concepts,\u201d in Diane Pecher and Rolf A.\nZwaan <em>(</em>eds.), <em>Grounding Cognition</em> (1st edition), pp.\n129\u201363, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511499968.007</li>\n<li>Bechtel, William, 1998, \u201cRepresentations and Cognitive\nExplanations: Assessing the Dynamicist\u2019s Challenge in Cognitive\nScience,\u201d <em>Cognitive Science</em>, 22(3): 295\u2013318.\ndoi:10.1207/s15516709cog2203_2.</li>\n<li>Beer, Randall D, 2000, \u201cDynamical Approaches to Cognitive\nScience,\u201d <em>Trends in Cognitive Sciences</em>, 4(3):\n91\u201399. doi:10.1016/S1364-6613(99)01440-0</li>\n<li>\u2013\u2013\u2013, 2003, \u201cThe Dynamics of Active\nCategorical Perception in an Evolved Model Agent,\u201d <em>Adaptive\nBehavior</em>, 11(4): 209\u201343.\ndoi:10.1177/1059712303114001</li>\n<li>Broadbent, Donald E., 1958, <em>Perception and Communication</em>,\nNew York: Pergamon Press.</li>\n<li>Brooks, Rodney. A., 1991a, \u201cNew Approaches to\nRobotics,\u201d <em>Science</em>, 253 (5025): 1227\u201332.\ndoi:10.1126/science.253.5025.1227</li>\n<li>\u2013\u2013\u2013, 1991b, \u201cIntelligence without\nRepresentation,\u201d <em>Artificial Intelligence</em>, 47(1\u20133):\n139\u201359. doi:10.1016/0004-3702(91)90053-M</li>\n<li>Buccino, Giovanni, Lucia Riggio, Gabor Melli, Ferdinand Binkofski,\nVittorio Gallese, and Giacomo Rizzolatti, 2005, \u201cListening to\nAction-Related Sentences Modulates the Activity of the Motor System: A\nCombined TMS and Behavioral Study,\u201d <em>Cognitive Brain\nResearch</em>, 24(3): 355\u201363. doi:10.1016/j.cogbrainres.2005.02.020</li>\n<li>Chemero, Anthony, 2001, \u201cDynamical Explanation and Mental\nRepresentations,\u201d <em>Trends in Cognitive Sciences</em>, 5(4):\n141\u201342. doi:10.1016/S1364-6613(00)01627-2</li>\n<li>\u2013\u2013\u2013, 2009, <em>Radical Embodied Cognitive\nScience</em>, Cambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cSensorimotor Empathy,\u201d\n<em>Journal of Consciousness Studies</em>, 23(5\u20136):\n138\u201352.</li>\n<li>\u2013\u2013\u2013, 2021, \u201cEpilogue: What Embodiment\nIs,\u201d in Nancy Dess (ed.), <em>A Multidisciplinary Approach to\nEmbodiment: Understanding Human Being</em>, New York: Routledge,\npp. 133\u201340.</li>\n<li>Chomsky, Noam, 1959, \u201cOn Certain Formal Properties of\nGrammars,\u201d <em>Information and Control</em>, 2(2): 137\u201367.\ndoi:10.1016/S0019-9958(59)90362-6</li>\n<li>\u2013\u2013\u2013, 1980, \u201cOn Cognitive Structures and Their\nDevleopment: A Reply to Piaget,\u201d in Massimo Piattelli-Palmarini\n(ed.), <em>Language and Learning\u202f: The Debate between Jean Piaget\nand Noam Chomsky</em>, Cambridge, Mass.: Harvard University Press.</li>\n<li>Clark, Andy, 1997, \u201cThe Dynamical Challenge,\u201d\n<em>Cognitive Science</em>, 21(4): 461\u201381.\ndoi:10.1207/s15516709cog2104_3</li>\n<li>\u2013\u2013\u2013, 2008, <em>Supersizing the Mind: Embodiment,\nAction, and Cognitive Extension</em>, Oxford, New York: Oxford\nUniversity Press.</li>\n<li>\u2013\u2013\u2013, 2010, \u201cCoupling, Constitution, and the\nCognitive Kind: A Reply to Adams and Aizawa,\u201d in Richard Menary\n(ed.), <em>The Extended Mind</em>, Cambridge, Mass.: MIT Press, pp.\n81\u2013100.</li>\n<li>Clark, Andy, and David J. Chalmers, 1998, \u201cThe Extended\nMind,\u201d <em>Analysis</em>, 58(1): 7\u201319.</li>\n<li>Clark, Andy, and Josefa Toribio, 1994, \u201cDoing without\nRepresenting?\u201d <em>Synthese</em>, 101(3): 401\u201331.\ndoi:10.1007/BF01063896.</li>\n<li>Cushman, Fiery, Liane Young, and Marc Hauser, 2006, \u201cThe Role\nof Conscious Reasoning and Intuition in Moral Judgment: Testing Three\nPrinciples of Harm,\u201d <em>Psychological Science</em>, 17(12):\n1082\u201389.</li>\n<li>Damasio, Antonio R., 1994, \u201cDescartes\u2019 Error and the\nFuture of Human Life,\u201d <em>Scientific American</em>, 271(4):\n144\u2013144.</li>\n<li>Davies, Martin, and Tony Stone, 1995a, <em>Folk Psychology: The\nTheory of Mind Debate</em>, Oxford: Blackwell.</li>\n<li>\u2013\u2013\u2013, 1995b, <em>Mental Simulation: Evaluations\nand Applications</em> (Volume 4), Oxford: Blackwell.</li>\n<li>Dietrich, Eric, and Arthur B. Markman, 2001, \u201cDynamical\nDescription versus Dynamical Modeling,\u201d <em>Trends in Cognitive\nSciences</em>, 5(8): 332.\ndoi:10.1016/S1364-6613(00)01705-8</li>\n<li>Dove, Guy, 2009, \u201cBeyond Perceptual Symbols: A Call for\nRepresentational Pluralism,\u201d <em>Cognition</em>, 110(3):\n412\u201331. doi:10.1016/j.cognition.2008.11.016</li>\n<li>\u2013\u2013\u2013, 2016, \u201cThree Symbol Ungrounding\nProblems: Abstract Concepts and the Future of Embodied\nCognition,\u201d <em>Psychonomic Bulletin &amp; Review</em>, 23(4):\n1109\u201321.</li>\n<li>Edmiston, Pierce, and Gary Lupyan, 2017, \u201cVisual Interference\nDisrupts Visual Knowledge,\u201d <em>Journal of Memory and\nLanguage</em>, 92 (February): 281\u201392.\ndoi:10.1016/j.jml.2016.07.002</li>\n<li>Eliasmith, Chris, 1996, \u201cThe Third Contender: A Critical\nExamination of the Dynamicist Theory of Cognition,\u201d\n<em>Philosophical Psychology</em>, 9(4): 441\u201363.\ndoi:10.1080/09515089608573194</li>\n<li>Fiske, Susan T., and Shelley E. Taylor, 2013, <em>Social Cognition:\nFrom Brains to Culture</em>, London: Sage.</li>\n<li>Fodor, Jerry A., 1987, <em>Psychosemantics</em><em>: The Problem of\nMeaning in the Philosophy of Mind</em>, Cambridge, Mass.: MIT\nPress.</li>\n<li>Fuchs, Thomas, 2013, \u201cThe Phenomenology and Development of\nSocial Perspectives,\u201d <em>Phenomenology and the Cognitive\nSciences</em>, 12(4): 655\u2013683.\ndoi:10.1007/s11097-012-9267-x</li>\n<li>Gallagher, Shaun, 2005, <em>How the Body Shapes the Mind</em>,\nOxford, Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 2008, \u201cInference or Interaction: Social\nCognition without Precursors,\u201d <em>Philosophical\nExplorations</em>, 11(3): 163\u201374.</li>\n<li>\u2013\u2013\u2013, 2020, <em>Action and Interaction</em>, Oxford:\nUniversity Press.</li>\n<li>Gallagher, Shaun, and Daniel D. Hutto, 2008, \u201cUnderstanding\nOthers through Primary Interaction and Narrative Practice,\u201d in\nChris Sinha, Esa Itkonen, Jordan Zlatev, and Timothy P. Racine (eds.),\n<em>The Shared Mind: Perspectives on Intersubjectivity</em>,\nAmsterdam: John Benjamins, pp. 17\u201338.</li>\n<li>Gallese, Vittorio, 2009, \u201cMirror Neurons and the Neural\nExploitation Hypothesis: From Embodied Simulation to Social\nCognition,\u201d in Jaimie A. Pineda (ed.), <em>Mirror Neuron\nSystems</em>, New York: Humana, pp. 163\u201390.</li>\n<li>Gibson, James J., 1966, <em>The Senses Considered as Perceptual\nSystems</em>, Boston: Houghton Mifflin.</li>\n<li>\u2013\u2013\u2013, 1979, <em>The Ecological Approach to Visual\nPerception</em>, Boston: Houghton Mifflin.</li>\n<li>Glenberg, Arthur M., and Michael P. Kaschak, 2002, \u201cGrounding\nLanguage in Action,\u201d <em>Psychonomic Bulletin &amp; Review</em>,\n9(3): 558\u201365. doi:10.3758/BF03196313</li>\n<li>Goldhill, Olivia, 2019, \u201cThe Replication Crisis Is Killing\nPsychologists\u2019 Theory of How the Body Influences the Mind,\u201d\n<em>Quartz</em>, 16 January 2019, \n [<a href=\"https://qz.com/1525854/psychologys-replication-crisis-is-debunking-embodied-cognition-theory/\" target=\"other\">Goldhill 2019 available online</a>].</li>\n<li>Goldman, Alvin I., 2009, \u201cMirroring, Mindreading, and\nSimulation,\u201d in Jaimie A. Pineda (ed.), <em>Mirror Neuron\nSystems</em>, New York: Humana, pp. 311\u201330.</li>\n<li>Goldman, Alvin I., and Frederique de Vignemont, 2009, \u201cIs\nSocial Cognition Embodied?\u201d <em>Trends in Cognitive\nSciences</em>, 13(4): 154\u201359.</li>\n<li>Greene, Joshua D., \u201cBeyond Point-and-Shoot Morality,\u201d\n<em>Ethics</em>, 124(4): 695\u2013726.</li>\n<li>Gu, Jun, Chen-Bo Zhong, and Elizabeth Page-Gould, 2013,\n\u201cListen to Your Heart: When False Somatic Feedback Shapes Moral\nBehavior,\u201d <em>Journal of Experimental Psychology: General</em>,\n142(2): 307.</li>\n<li>Haidt, Jonathan, 2001, \u201cThe Emotional Dog and Its Rational\nTail: A Social Intuitionist Approach to Moral Judgment,\u201d\n<em>Psychological Review</em>, 108(4): 814\u2013834.</li>\n<li>Haidt, Jonathan, Silvia Helena Koller, and Maria G Dias, 1993,\n\u201cAffect, Culture, and Morality, or Is It Wrong to Eat Your\nDog?\u201d <em>Journal of Personality and Social Psychology</em>,\n65(4): 613\u2013628.</li>\n<li>Haken, Hermann, J. A. Scott Kelso, and Herbert Bunz, 1985, \u201cA\nTheoretical Model of Phase Transitions in Human Hand Movements,\u201d\n<em>Biological Cybernetics</em>, 51(5): 347\u201356.\ndoi:10.1007/BF00336922</li>\n<li>Hare, Robert D., 1999, <em>Without Conscience: The Disturbing World\nof the Psychopaths among Us</em>, New York: Guilford Press.</li>\n<li>Hatfield, Gary, 1991, \u201cRepresentation and Rule-Instantiation\nin Connectionist Systems,\u201d in Terence Horgan and John Tienson\n(eds.), <em>Connectionism and the Philosophy of Mind</em> (Studies in\nCognitive Systems), Dordrecht: Springer Netherlands, pp. 90\u2013112.\ndoi:10.1007/978-94-011-3524-5_5</li>\n<li>Heidegger, Martin, 1975, <em>The Basic Problems of\nPhenomenology</em>, translated by Albert Hofstadter, 1988,\nBloomington: Indiana University Press.</li>\n<li>Hickok, Gregory, 2009, \u201cEight Problems for the Mirror Neuron\nTheory of Action Understanding in Monkeys and Humans,\u201d\n<em>Journal of Cognitive Neuroscience</em>, 21(7): 1229\u201343.\ndoi:10.1162/jocn.2009.21189</li>\n<li>Huebner, Bryce, 2015, \u201cDo Emotions Play a Constitutive Role\nin Moral Cognition?\u201d <em>Topoi</em>, 34(2): 427\u201340.</li>\n<li>Husserl, Edmund, 1929, <em>Cartesian Meditations: An Introduction to\nPhenomenology</em>, translated by Dorian Cairns, 2012, Dordrect:\nSpringer Science &amp; Business Media.</li>\n<li>Hutchins, Edwin, 1996, <em>Cognition in the Wild</em> (second\nprinting), Cambridge, Mass.: MIT Press.</li>\n<li>Hutto, Daniel D., 2008, <em>Folk Psychological Narratives: The\nSociocultural Basis of Understanding Reasons</em>, Cambridge, Mass.:\nMIT Press.</li>\n<li>Hutto, Daniel D., and Erik Myin, 2013, <em>Radicalizing Enactivism:\nBasic Minds without Content</em>, Cambridge, Mass.: MIT Press.</li>\n<li>Hutto, Daniel D., and M. Ratcliffe, 2007, <em>Folk Psychology\nRe-Assessed</em>, Dordrecht; London: Springer.</li>\n<li>Kelso, J. A. Scott, 1995, <em>Dynamic Patterns\u202f: The\nSelf-Organization of Brain and Behavior</em>, Cambridge, Mass.: MIT\nPress.</li>\n<li>Lakens, Dani\u00ebl, 2014, \u201cGrounding Social\nEmbodiment,\u201d <em>Social Cognition</em>, 32 (Supplement):\n168\u201383. doi:10.1521/soco.2014.32.supp.168</li>\n<li>Lakoff, George, and Mark Johnson, 1980, <em>Metaphors We Live\nBy</em>, Chicago: University of Chicago Press.</li>\n<li>\u2013\u2013\u2013, 1999, <em>Philosophy in the Flesh: The\nEmbodied Mind and Its Challenge to Western Thought</em>, New York:\nBasic Books.</li>\n<li>Leeuwen, Marco van, 2005, \u201cQuestions For The Dynamicist: The\nUse of Dynamical Systems Theory in the Philosophy of Cognition,\u201d\n<em>Minds and Machines</em>, 15(3\u20134): 271\u2013333.\ndoi:10.1007/s11023-004-8339-2</li>\n<li>Mahon, Bradford Z., 2015, \u201cWhat Is Embodied about\nCognition?\u201d <em>Language, Cognition and Neuroscience</em>, 30(4):\n420\u201329. doi:10.1080/23273798.2014.987791</li>\n<li>Mahon, Bradford Z., and Alfonso Caramazza, 2008, \u201cA Critical\nLook at the Embodied Cognition Hypothesis and a New Proposal for\nGrounding Conceptual Content,\u201d <em>Journal of\nPhysiology-Paris</em>, Links and Interactions Between Language and\nMotor Systems in the Brain, 102(1): 59\u201370.\ndoi:10.1016/j.jphysparis.2008.03.004</li>\n<li>Maibom, Heidi, 2010, \u201cWhat Experimental Evidence Shows Us\nabout the Role of Emotions in Moral Judgement,\u201d <em>Philosophy\nCompass</em>, 5(11): 999\u20131012.</li>\n<li>Marr, David, 1982, <em>Vision: A Computational Investigation into\nthe Human Representation and Processing of Visual Information</em>, San\nFrancisco: W. H. Freeman.</li>\n<li>Martin, Taylor, and Daniel L. Schwartz, 2005a, \u201cPhysically\nDistributed Learning: Adapting and Reinterpreting Physical Environments\nin the Development of Fraction Concepts,\u201d <em>Cognitive\nScience</em>, 29(4): 587\u2013625.\ndoi:10.1207/s15516709cog0000_15</li>\n<li>\u2013\u2013\u2013, 2005b, \u201cPhysically Distributed Learning:\nAdapting and Reinterpreting Physical Environments in the Development of\nFraction Concepts,\u201d <em>Cognitive Science</em>, 29(4):\n587\u2013625. doi:10.1207/s15516709cog0000_15</li>\n<li>Matthen, Mohan, 2014, \u201cDebunking Enactivism: A Critical\nNotice of Hutto and Myin\u2019s Radicalizing\nEnactivism,\u201d <em>Canadian Journal of Philosophy</em>, 44(1):\n118\u201328. doi:10.1080/00455091.2014.905251</li>\n<li>Maxwell, Scott E., Michael Y. Lau, and George S. Howard, 2015,\n\u201cIs Psychology Suffering from a Replication Crisis? What Does\n\u2018Failure to Replicate\u2019 Really Mean?\u201d <em>American\nPsychologist</em>, 70(6): 487\u201398.\ndoi:10.1037/a0039400</li>\n<li>May, Joshua, 2018, <em>Regard for Reason in the Moral Mind</em>,\nOxford: Oxford University Press.</li>\n<li>May, Joshua, and Victor Kumar, 2018, \u201cMoral Reasoning and\nEmotion,\u201d in Karen Jones, Mark Timmons and Aaron Zimmerman\n(eds.), <em>Routledge Handbook on Moral Epistemology</em>.\nLondon: Routledge, pp. 139\u2013156.</li>\n<li>Menary, Richard, 2008, <em>Cognitive Integration: Mind and Cognition\nUnbounded</em>, Basingstoke, New York: Palgrave Macmillan.</li>\n<li>Merleau-Ponty, Maurice, 1962, <em>Phenomenology of Perception</em>,\ntranslated by Colin Smith, London: Routledge.</li>\n<li>Michaels, Claire, and Zsolt Palatinus, 2014, \u201cA Ten\nCommandments for Ecological Psychology,\u201d in Lawrence Shapiro\n(ed.), <em>The Routledge Handbook of Embodied Cognition</em>, New\nYork: Routledge, Taylor &amp; Francis Group, pp. 19\u201328.</li>\n<li>Newell, Allen, John C. Shaw, and Herbert A. Simon, 1958,\n\u201cElements of a Theory of Human Problem Solving,\u201d\n<em>Psychological Review</em>, 65(3): 151\u201366.\ndoi:10.1037/h0048495</li>\n<li>Nichols, Shaun, 2004, <em>Sentimental Rules: On the Natural\nFoundations of Moral Judgment</em>, Oxford: Oxford University\nPress.</li>\n<li>No\u00eb, Alva, 2004, <em>Action in Perception</em>, Cambridge,\nMass: MIT Press.</li>\n<li>O\u2019Regan, J. Kevin, and Alva No\u00eb, 2001, \u201cA\nSensorimotor Account of Vision and Visual Consciousness,\u201d\n<em>Behavioral and Brain Sciences</em>, 24(5): 939\u201373.\ndoi:10.1017/S0140525X01000115</li>\n<li>Pouw, Wim T. J. L., Tamara van Gog, and Fred Paas, 2014, \u201cAn\nEmbedded and Embodied Cognition Review of Instructional\nManipulatives,\u201d <em>Educational Psychology Review</em>, 26(1):\n51\u201372. doi:10.1007/s10648-014-9255-5</li>\n<li>Prinz, Jesse J., 2004, <em>Gut Reactions: A Perceptual Theory of\nEmotion</em>, Oxford: Oxford University Press.</li>\n<li>Prinz, Jesse J., and Lawrence W. Barsalou, 2000, \u201cSteering a\nCourse for Embodied Representation,\u201d in Eric Dietrich and Arthur\nMarkman (eds.), <em>Cognitive Dynamics: Conceptual Change in Humans\nand Machines</em>, Cambridge, MA: MIT Press, pp. 51\u201377.</li>\n<li>Pulverm\u00fcller, Friedemann, 2005, \u201cBrain Mechanisms Linking\nLanguage and Action,\u201d <em>Nature Reviews Neuroscience</em>, 6(7):\n576\u201382. doi:10.1038/nrn1706</li>\n<li>Rabelo, Andr\u00e9 L. A., Victor N. Keller, Ronaldo Pilati, and\nJelte M. Wicherts, 2015, \u201cNo Effect of Weight on Judgments of\nImportance in the Moral Domain and Evidence of Publication Bias from a\nMeta-Analysis,\u201d <em>PLoS ONE</em>, 10(8).\ndoi:10.1371/journal.pone.0134808</li>\n<li>Railton, Peter, 2017, \u201cMoral Learning: Conceptual Foundations\nand Normative Relevance,\u201d <em>Cognition</em>, 167 (October):\n172\u201390.</li>\n<li>Rey, Georges, 1983, \u201cConcepts and Stereotypes,\u201d\n<em>Cognition</em>, 15(1): 237\u201362.\ndoi:10.1016/0010-0277(83)90044-6</li>\n<li>\u2013\u2013\u2013, 1985, \u201cConcepts and Conceptions: A Reply\nto Smith, Medin and Rips,\u201d <em>Cognition</em>, 19(3):\n297\u2013303. doi:10.1016/0010-0277(85)90037-X</li>\n<li>Rupert, Robert D., 2004, \u201cChallenges to the Hypothesis of\nExtended Cognition,\u201d <em>The Journal of Philosophy</em>, 101(8):\n389\u2013428.</li>\n<li>Sauer, Niko, 2010, \u201cCausality and Causation: What We Learn\nfrom Mathematical Dynamic Systems Theory,\u201d <em>Transactions of\nthe Royal Society of South Africa</em>, 65(1): 65\u201368.\ndoi:10.1080/00359191003680091</li>\n<li>Schnall, Simone, Jennifer Benton, and Sophie Harvey, 2008,\n\u201cWith a Clean Conscience: Cleanliness Reduces the Severity of\nMoral Judgments,\u201d <em>Psychological Science</em>, 19(12):\n1219\u201322.</li>\n<li>Schnall, Simone, Jonathan Haidt, Gerald L Clore, and Alexander H\nJordan, 2008, \u201cDisgust as Embodied Moral Judgment,\u201d\n<em>Personality and Social Psychology Bulletin</em>, 34(8):\n1096\u20131109.</li>\n<li>Shapiro, Lawrence, 2007, \u201cThe Embodied Cognition Research\nProgramme,\u201d <em>Philosophy Compass</em>, 2(2): 338\u201346.\ndoi:10.1111/j.1747-9991.2007.00064.x</li>\n<li>\u2013\u2013\u2013, 2012, \u201cEmbodied Cognition,\u201d in\nEric Margolis, Richard Samuels and Stephen P. Stich (eds.), <em>The\nOxford Handbook of Philosophy of Cognitive Science</em>, New York:\nOxford University Press, pp. 118\u2013147.</li>\n<li>\u2013\u2013\u2013, 2013, \u201cDynamics and Cognition,\u201d\n<em>Minds and Machines</em>, 23(3): 353\u201375.\ndoi:10.1007/s11023-012-9290-2</li>\n<li>\u2013\u2013\u2013, 2019a, <em>Embodied Cognition</em>, Second\nEdition, London; New York: Routledge.</li>\n<li>\u2013\u2013\u2013, 2019b, \u201cMatters of the Flesh: The\nRole(s) of Body in Cognition,\u201d in Matteo Colombo, Elizabeth\nIrvine and Mog Stapleton (eds.), <em>Andy Clark and His Critics</em>,\nNew York, NY: Oxford University Press, pp. 69\u201380.</li>\n<li>\u2013\u2013\u2013, 2019c, \u201cFlesh Matters: The Body in\nCognition,\u201d <em>Mind &amp; Language</em>, 34(1): 3\u201320.\ndoi:10.1111/mila.12203</li>\n<li>Spaulding, Shannon, 2010, \u201cEmbodied Cognition and\nMindreading,\u201d <em>Mind &amp; Language</em>, 25(1):\n119\u201340.</li>\n<li>\u2013\u2013\u2013, 2011, \u201cA Critique of Embodied\nSimulation,\u201d <em>Review of Philosophy and Psychology</em>, 2(3):\n579\u201399.</li>\n<li>\u2013\u2013\u2013, 2013, \u201cMirror Neurons and Social\nCognition,\u201d <em>Mind &amp; Language</em>, 28(2):\n233\u201357.</li>\n<li>Spivey, Michael J., 2007, <em>The Continuity of Mind</em> (Oxford\nPsychology Series), Oxford, New York: Oxford University Press.</li>\n<li>Sternberg, Saul, 1969, \u201cMemory-Scanning: Mental Processes\nRevealed by Reaction-Time Experiments,\u201d <em>American\nScientist</em>, 57(4): 421\u201357.</li>\n<li>Symes, Ed, Rob Ellis, and Mike Tucker, 2007, \u201cVisual Object\nAffordances: Object Orientation,\u201d <em>Acta Psychologica</em>,\n124(2): 238\u201355. doi:10.1016/j.actpsy.2006.03.005</li>\n<li>Tettamanti, Marco, Giovanni Buccino, Maria Cristina Saccuman,\nVittorio Gallese, Massimo Danna, Paola Scifo, Ferruccio Fazio, Giacomo\nRizzolatti, Stefano F. Cappa, and Daniela Perani, 2005,\n\u201cListening to Action-Related Sentences Activates Fronto-Parietal\nMotor Circuits,\u201d <em>Journal of Cognitive Neuroscience</em>,\n17(2): 273\u201381. doi:10.1162/0898929053124965</li>\n<li>Thelen, Esther, Gregor Sch\u00f6ner, Christian Scheier, and Linda B.\nSmith, 2001, \u201cThe Dynamics of Embodiment: A Field Theory of\nInfant Perseverative Reaching,\u201d <em>Behavioral and Brain\nSciences</em>, 24(1): 1\u201334.\ndoi:10.1017/S0140525X01003910</li>\n<li>Thelen, Esther, and Linda Smith (eds.), 1993, <em>A Dynamic Systems\nApproach to Development: Applications</em>, Cambridge, Mass.: MIT\nPress.</li>\n<li>Thompson, Evan, 2010, <em>Mind in Life</em>, Cambridge, MA:\nHarvard University Press.</li>\n<li>Trevarthen, Colwyn, 1979, \u201cCommunication and Cooperation in\nEarly Infancy: A Description of Primary Intersubjectivity,\u201d in\nMargaret Bullowa (ed.) <em>Before Speech: The Beginning of\nInterpersonal Communication</em>, Cambridge: Cambridge University\nPress, pp. 321\u2013348.</li>\n<li>Tucker, Mike, and Rob Ellis, 1998, \u201cOn the Relations between\nSeen Objects and Components of Potential Actions,\u201d <em>Journal of\nExperimental Psychology: Human Perception and Performance</em>, 24(3):\n830\u201346. doi:10.1037/0096-1523.24.3.830</li>\n<li>\u2013\u2013\u2013, 2001, \u201cThe Potentiation of Grasp Types\nduring Visual Object Categorization,\u201d <em>Visual Cognition</em>,\n8(6): 769\u2013800. doi:10.1080/13506280042000144</li>\n<li>\u2013\u2013\u2013, 2004, \u201cAction Priming by Briefly\nPresented Objects,\u201d <em>Acta Psychologica</em>, 116(2):\n185\u2013203. doi:10.1016/j.actpsy.2004.01.004</li>\n<li>Van Gelder, Tim, 1995, \u201cWhat Might Cognition Be, If Not\nComputation?\u201d <em>The Journal of Philosophy</em>, 92(7):\n345\u201381. doi:10.2307/2941061</li>\n<li>\u2013\u2013\u2013, 1998, \u201cThe Dynamical Hypothesis in\nCognitive Science,\u201d <em>Behavioral and Brain Sciences</em>,\n21(5): 615\u201328. doi:10.1017/S0140525X98001733</li>\n<li>Varela, Francisco J., Evan Thompson, and Eleanor Rosch, 2017,\n<em>The Embodied Mind, Revised Edition: Cognitive Science and Human\nExperience</em>, Cambridge, Mass: MIT Press.</li>\n<li>Ward, Dave, David Silverman, and Mario Villalobos, 2017,\n\u201cIntroduction: The Varieties of Enactivism,\u201d\n<em>Topoi</em>, 36(3): 365\u201375.\ndoi:10.1007/s11245-017-9484-6</li>\n<li>Wilson, Andrew D., and Sabrina Golonka, 2013, \u201cEmbodied\nCognition Is Not What You Think It Is,\u201d <em>Frontiers in\nPsychology</em>, 4, published online 12 February 2013. \ndoi:10.3389/fpsyg.2013.00058</li>\n<li>Wilson, Margaret, 2002, \u201cSix Views of Embodied\nCognition,\u201d <em>Psychonomic Bulletin &amp; Review</em>, 9(4):\n625\u201336. doi:10.3758/BF03196322</li>\n<li>Wilson, Robert A., 1994, \u201cWide Computationalism,\u201d\n<em>Mind</em>, 103(411): 351\u201372. doi:10.1093/mind/103.411.351</li>\n<li>Wilson, Robert A., and Andy Clark, 2001, \u201cHow to Situate\nCognition: Letting Nature Take Its Course,\u201d in Philip Robbins\nand Murat Aydede (eds.) <em>The Cambridge Handbook of Situated\nCognition</em>, 1st ed., Cambridge: Cambridge University Press, pp.\n55\u201377.  doi:10.1017/CBO9780511816826.004</li>\n<li>Woodward, James, 2016, \u201cEmotion versus Cognition in Moral\nDecision-Making: A Dubious Dichotomy,\u201d in S. Matthew Liao (ed.),\n<em>Moral Brains: The Neuroscience of Morality</em>, Oxford: Oxford\nUniversity Press, pp. 87\u2013116.</li>\n<li>Zahavi, Dan, 2005, <em>Subjectivity and Selfhood: Investigating\nthe First-Person Perspective</em>, Cambridge, Mass.: MIT Press.</li>\n<li>Zednik, Carlos, 2011, \u201cThe Nature of Dynamical\nExplanation,\u201d <em>Philosophy of Science</em>, 78(2):\n238\u201363.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "artificial intelligence",
            "cognitive science",
            "concepts",
            "connectionism",
            "externalism about the mind",
            "functionalism",
            "intentionality",
            "language of thought hypothesis",
            "mental content: causal theories of",
            "mental content: teleological theories of",
            "mental representation",
            "mind: computational theory of",
            "moral sentimentalism",
            "neuroscience, philosophy of",
            "other minds",
            "phenomenology"
        ],
        "entry_link": [
            {
                "../artificial-intelligence/": "artificial intelligence"
            },
            {
                "../cognitive-science/": "cognitive science"
            },
            {
                "../concepts/": "concepts"
            },
            {
                "../connectionism/": "connectionism"
            },
            {
                "../content-externalism/": "externalism about the mind"
            },
            {
                "../functionalism/": "functionalism"
            },
            {
                "../intentionality/": "intentionality"
            },
            {
                "../language-thought/": "language of thought hypothesis"
            },
            {
                "../content-causal/": "mental content: causal theories of"
            },
            {
                "../content-teleological/": "mental content: teleological theories of"
            },
            {
                "../mental-representation/": "mental representation"
            },
            {
                "../computational-mind/": "mind: computational theory of"
            },
            {
                "../moral-sentimentalism/": "moral sentimentalism"
            },
            {
                "../neuroscience/": "neuroscience, philosophy of"
            },
            {
                "../other-minds/": "other minds"
            },
            {
                "../phenomenology/": "phenomenology"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=embodied-cognition\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/embodied-cognition/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=embodied-cognition&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/embodied-cognition/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=embodied-cognition": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/embodied-cognition/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=embodied-cognition&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/embodied-cognition/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "Wilson, Rob and Lucia Foglia, \u201cEmbodied Cognition,\u201d \n<em>Stanford Encyclopedia of Philosophy</em> (Summer 2021 Edition),\n Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/sum2021/entries/embodied-cognition/\" target=\"other\">https://plato.stanford.edu/archives/sum2021/entries/embodied-cognition/</a>&gt;.\n  [This was the previous entry on Embodied Cognition in the\n <em>Stanford Encyclopedia of Philosophy</em> \u2014 see the\n <a class=\"plain\" href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=embodied-cognition\" target=\"other\">version history</a>.]",
            "<a href=\"https://iep.utm.edu/lot-hypo/\" target=\"other\">The Language of Thought Hypothesis</a>,\n  entry by Matthew Katz in the <em>Internet Encyclopedia of Philosophy</em>.",
            "<a href=\"http://www.iep.utm.edu/compmind/\" target=\"other\">The Computational Theory of Mind</a>,\n entry by Marcin Milkowski in the <em>Internet Encyclopedia of Philosophy</em>.",
            "<a href=\"https://iep.utm.edu/functism/\" target=\"other\">Functionalism</a>,\n entry by Thomas Polger in the <em>Internet Encyclopedia of Philosophy</em>."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/archives/sum2021/entries/embodied-cognition/": "https://plato.stanford.edu/archives/sum2021/entries/embodied-cognition/"
            },
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=embodied-cognition": "version history"
            },
            {
                "https://iep.utm.edu/lot-hypo/": "The Language of Thought Hypothesis"
            },
            {
                "http://www.iep.utm.edu/compmind/": "The Computational Theory of Mind"
            },
            {
                "https://iep.utm.edu/functism/": "Functionalism"
            }
        ]
    }
}