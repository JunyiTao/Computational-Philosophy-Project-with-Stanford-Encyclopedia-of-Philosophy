{
    "url": "epistemology-bayesian",
    "title": "Bayesian Epistemology",
    "authorship": {
        "year": "Copyright \u00a9 2022",
        "author_text": "Hanti Lin\n<ika@ucdavis.edu>",
        "author_links": [
            {
                "mailto:ika%40ucdavis%2eedu": "ika@ucdavis.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2022</a> by\n\n<br/>\nHanti Lin\n&lt;<a href=\"mailto:ika%40ucdavis%2eedu\"><em>ika<abbr title=\" at \">@</abbr>ucdavis<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Mon Jun 13, 2022"
    ],
    "preamble": "\n\nWe can think of belief as an all-or-nothing affair. For example, I\nbelieve that I am alive, and I don\u2019t believe that I am a\nhistorian of the Mongol Empire. However, often we want to make\ndistinctions between how strongly we believe or disbelieve\nsomething. I strongly believe that I am alive, am fairly confident\nthat I will stay alive until my next conference presentation, less\nconfident that the presentation will go well, and strongly disbelieve\nthat its topic will concern the rise and fall of the Mongol Empire.\nThe idea that beliefs can come in different strengths is a central\nidea behind Bayesian epistemology. Such strengths are called\ndegrees of belief, or credences. Bayesian\nepistemologists study norms governing degrees of beliefs, including\nhow one\u2019s degrees of belief ought to change in response to a\nvarying body of evidence. Bayesian epistemology has a long history.\nSome of its core ideas can be identified in Bayes\u2019 (1763)\nseminal paper in statistics (Earman 1992: ch. 1), with applications\nthat are now very influential in many areas of philosophy and of\nscience.\n\nThe present entry focuses on the more traditional, general issues\nabout Bayesian epistemology, and, along the way, interested readers\nwill be referred to entries that discuss the more specific topics. A\ntutorial on Bayesian epistemology will be provided in the first\nsection for beginners and those who want a quick overview.\n",
    "toc": [
        {
            "#TutoBayeEpis": "1. A Tutorial on Bayesian Epistemology"
        },
        {
            "#CaseStud": "1.1 A Case Study"
        },
        {
            "#TwoCoreNorm": "1.2 Two Core Norms"
        },
        {
            "#Appl": "1.3 Applications"
        },
        {
            "#BayeDiviWhatDoesCoheRequ": "1.4 Bayesians Divided: What Does Coherence Require?"
        },
        {
            "#BayeDiviProbPrio": "1.5 Bayesians Divided: The Problem of the Priors"
        },
        {
            "#AtteFounDutcBookArgu": "1.6 An Attempted Foundation: Dutch Book Arguments"
        },
        {
            "#AlteFoun": "1.7 Alternative Foundations"
        },
        {
            "#ObjeCond": "1.8 Objections to Conditionalization"
        },
        {
            "#ObjeAbouIdea": "1.9 Objections about Idealization"
        },
        {
            "#ConcEncoNonBaye": "1.10 Concerns, or Encouragements, from Non-Bayesians"
        },
        {
            "#BitMathForm": "2. A Bit of Mathematical Formalism"
        },
        {
            "#SyncNormIRequCohe": "3. Synchronic Norms (I): Requirements of Coherence"
        },
        {
            "#VersProb": "3.1 Versions of Probabilism"
        },
        {
            "#CounAddi": "3.2 Countable Additivity"
        },
        {
            "#Regu": "3.3 Regularity"
        },
        {
            "#NormCondCred": "3.4 Norms of Conditional Credences"
        },
        {
            "#ChanCredPrin": "3.5 Chance-Credence Principles"
        },
        {
            "#ReflOtheDefePrin": "3.6 Reflection and Other Deference Principles"
        },
        {
            "#SyncNormIIProbPrio": "4. Synchronic Norms (II): The Problem of the Priors"
        },
        {
            "#SubjBaye": "4.1 Subjective Bayesianism"
        },
        {
            "#ObjeBaye": "4.2 Objective Bayesianism"
        },
        {
            "#ForwLookBaye": "4.3 Forward-Looking Bayesianism"
        },
        {
            "#ConnUniqDeba": "4.4 Connection to the Uniqueness Debate"
        },
        {
            "#IssuAbouDiacNorm": "5. Issues about Diachronic Norms"
        },
        {
            "#OldEvid": "5.1 Old Evidence"
        },
        {
            "#NewTheo": "5.2 New Theory"
        },
        {
            "#UnceLear": "5.3 Uncertain Learning"
        },
        {
            "#MemoLoss": "5.4 Memory Loss"
        },
        {
            "#SelfLocaCred": "5.5 Self-Locating Credences"
        },
        {
            "#BayeWithKine": "5.6 Bayesianism without Kinematics"
        },
        {
            "#ProbIdea": "6. The Problem of Idealization"
        },
        {
            "#DeIdeaUnde": "6.1 De-idealization and Understanding"
        },
        {
            "#StriForIdea": "6.2 Striving for Ideals"
        },
        {
            "#ApplEmpoIdea": "6.3 Applications Empowered by Idealization"
        },
        {
            "#ClosExpaTerrBaye": "7. Closing: The Expanding Territory of Bayesianism"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. A Tutorial on Bayesian Epistemology\n\nThis section provides an introductory tutorial on Bayesian\nepistemology, with references to subsequent sections or related\nentries for details.\n1.1 A Case Study\n\nFor a glimpse of what Bayesian epistemology is, let\u2019s see what\nBayesians have to say about this episode in scientific inquiry:\n\n\nExample (Eddington\u2019s Observation).\nEinstein\u2019s theory of General Relativity entails that light can\nbe deflected by a massive body such as the Sun. This physical effect,\npredicted by Einstein in a 1911 paper, was observed during a solar\neclipse on May 29, 1919, from locations chosen from Eddington\u2019s\ntwo expeditions. This result surprised the physics community and was\ndeemed a significant confirmation of Einstein\u2019s theory.\n\n\n\nThe above case makes a general point:\n\n\nThe Principle of Hypothetico-Deductive\nConfirmation. Suppose that a scientist is testing a hypothesis\nH. She deduces from it an empirical consequence E, and\ndoes an experiment, being not sure whether E is true. It turns\nout that she obtains E as new evidence as a result of the\nexperiment. Then she ought to become more confident in H.\nMoreover, the more surprising the evidence E is, the higher the\ncredence in H ought to be raised.\n\n\n\nThis intuition about how credences ought to change can be vindicated\nin Bayesian epistemology by appeal to two norms. But before turning to\nthem, we need a setting. Divide the space of possibilities into four,\naccording to whether hypothesis H is true or false and whether\nevidence E is true or false. Since H logically implies\nE, there are only three distinct possibilities on the table,\nwhich are depicted as the three dots in\n figure 1.\n\n\n\nFigure 1: A Space of Three\nPossibilities. [An\n extended description of figure 1.]\n\n\nThose possibilities are mutually exclusive in the sense that\nno two of them can hold together; and they are jointly\nexhaustive in the sense that at least one of them must hold. A\nperson can be more or less confident that a given possibility holds.\nSuppose that it makes sense to say of a person that she is, say, 80%\nconfident that a certain possibility holds. In this case, say that\nthis person\u2019s degree of belief, or credence, in that possibility\nis equal to 0.8. A credence might be any other real number. (How to\nmake sense of real-valued credences is a major topic for Bayesians, to\nbe discussed in\n \u00a71.6\n and\n \u00a71.7\n below.)\n\nNow I can sketch the two core norms in Bayesian epistemology.\nAccording to the first norm, called Probabilism, one\u2019s\ncredences in the three possibilities in\n figure 1\n ought to fit together so nicely that they are non-negative and sum to\n1. Such a distribution of credences can be represented by a bar chart,\nas depicted on the left of\n figure 2.\n\n\n\nFigure 2: Conditionalization on\nEvidence. [An\n extended description of figure 2.]\n\n\nNow, suppose that a person with this credence distribution receives\nE as new evidence. It seems that as a result, there should be\nsome change in credences. But how should they change? According to the\nsecond norm, called the Principle of Conditionalization, the\npossibility incompatible with E (i.e., the rightmost\npossibility) should have its credence dropped down to 0, and to\nsatisfy Probabilism, the remaining credences should be scaled\nup\u2014rescaled to sum to 1. So this person\u2019s credence in\nhypothesis H has to rise in a way such as that depicted in\n figure 2.\n \n\nMoreover, suppose that new evidence E is very surprising. It\nmeans that the person starts out being highly confident in the falsity\nof E, as depicted on the left of\n figure 3.\n\n\n\nFigure 3: Conditionalization on\nSurprising Evidence. [An\n extended description of figure 3.]\n\n\nThen conditionalization on E requires a total credence collapse\nfollowed by a dramatic scaling-up of the other credences. In\nparticular, the credence in H is raised significantly, unless\nit is zero to begin with. This vindicates the intuition reported in\nthe case of Eddington\u2019s Observation.\n\n1.2 Two Core Norms\n\nThe two Bayesian norms sketched above can be stated a bit more\ngenerally as follows. (A formal statement will be provided after this\ntutorial, in\n section 2.)\n Suppose that there are some possibilities under consideration, which\nare mutually exclusive and jointly exhaustive. A proposition under\nconsideration is one that is true or false in each of those\npossibilities, so it can be identified with the set of the\npossibilities in which it is true. When those possibilities are finite\nin number, and when you have credences in all of them, Probabilism\ntakes a simple form, saying that your credences ought to be\nprobabilistic in this sense:\n\n\n(Non-Negativity) The credences assigned to the\npossibilities under consideration are non-negative real numbers.\n(Sum-to-One) The credences assigned to the\npossibilities under consideration sum to 1.\n(Additivity) The credence assigned to a\nproposition under consideration is equal to the sum of the credences\nassigned to the possibilities in that proposition.\n\n\n\nWhile this norm is synchronic in that it constrains your\ncredences at each time, the next norm is diachronic. Suppose\nthat you just received a piece of evidence E, which is true in\nat least some possibilities under consideration. Suppose further that\nE exhausts all the evidence you just received. Then the\nPrinciple of Conditionalization says that your credences ought to\nchange as if you followed the procedure below (although it is possible\nto design other procedures to the same effect):\n\n\n(Zeroing) For each possibility incompatible\nwith evidence E, drop its credence down to zero.\n(Rescaling) For the possibilities compatible\nwith evidence E, rescale their credences by a common factor to\nmake them sum to 1.\n(Resetting) Now that there is a new credence\ndistribution over the individual possibilities, reset the credences in\npropositions according to the Additivity rule in Probabilism.\n\n\n\nThe second step, rescaling, deserves attention. It is designed to\nensure compliance with Probabilism, but it also has an independent,\nintuitive appeal. Consider any two possibilities in which new evidence\nE is true. Thus the new evidence alone cannot distinguish those\ntwo possibilities and, hence, it seems to favor the two equally. So it\nseems that, if a person starts out being twice as confident in one of\nthose two possibilities as in the other, she should remain so after\nthe credence change in light of E, as required by the rescaling\nstep. The essence of conditionalization is preservation of certain\nratios of credences, which is a feature inherited by generalizations\nof conditionalization (see\n section 5\n for details).\n\nSo there you have it: Probabilism and the Principle of\nConditionalization, which are held by most Bayesians to be the two\ncore norms in Bayesian epistemology.\n\n\n1.3 Applications\n\nBayesian epistemology features an ambition: to develop a simple\nnormative framework that consists of little or nothing more than the\ntwo core Bayesian norms, with the goal of explaining or justifying a\nwide range of intuitively good epistemic practices and perhaps also of\nguiding our inquiries, all done with a focus on credence change. That\nsounds quite ambitious, given the narrow focus on credence change. But\nmany Bayesians maintain that credence change is a unifying theme that\nunderlies many different aspects of our epistemic endeavors. Let me\nmention some examples below.\n\nFirst of all, it seems that a hypothesis H is\nconfirmed by new evidence E exactly when one\u2019s\ncredence in H ought to increase in response to the acquisition\nof E. Extending that idea, it also seems that how much\nH is confirmed correlates with how much its credence ought to\nbe raised. With those ideas in mind, Bayesians have developed several\naccounts of confirmation; see\n section 3 of the entry on confirmation.\n Through the concept of confirmation, some Bayesians have also\ndeveloped accounts of closely related concepts. For example, being\nsupported by evidence seems to be the same as or similar to\nbeing confirmed by evidence, which is ultimately explained by\nBayesians in terms of credence change. So there are some Bayesian\naccounts of evidential support; see\n section 3 of the entry on Bayes\u2019 theorem\n and\n sections 2.3\u20132.5 of the entry on imprecise probabilities.\n Here is another example: how well a theory explains\na body of evidence seems to be closely related to how well the theory\nis confirmed by the evidence, which is ultimately explained by\nBayesians in terms of credence change. So there are some Bayesian\naccounts of explanatory power; see\n section 2 of the entry on abduction.\n\nThe focus on credence change also sheds light on another aspect of our\nepistemic practices: inductive inference. An inductive inference is\noften understood as a process that results in the formation of an\nall-or-nothing attitude: believing or accepting the truth of a\nhypothesis H on the basis of one\u2019s evidence E.\nThat does not appear to fit the Bayesian picture well. But to\nBayesians, what really matters is how new evidence E ought to\nchange one\u2019s credence in H\u2014whether one\u2019s\ncredence ought to be raised or lowered, and by\nhow much. To be sure, there is the issue of whether the\nresulting credence would be high enough to warrant the formation of\nthe attitude of believing or accepting. But to many Bayesians, that\nissue seems only secondary, or better forgone as argued by Jeffrey\n(1970). If so, the fundamental issue about inductive inference is\nultimately how credences ought to change in light of new evidence. So\nBayesians have had much to say about various kinds of inductive\ninferences and related classic problems in philosophy of science. See\nthe following footnote for a long list of relevant survey articles (or\nresearch papers, in cases where survey articles are not yet\n available).[1]\n\nFor monographs on applications in epistemology and philosophy of\nscience, see Earman (1992), Bovens & Hartmann (2004), Howson &\nUrbach (2006), and Sprenger & Hartmann (2019). In fact, there are\nalso applications to natural language semantics and pragmatics: for\nindicative conditionals, see the survey by Briggs (2019: sec. 6 and 7)\nand sections 3 and 4.2 of the entry on\n indicative conditionals;\n for epistemic modals, see Yalcin (2012).\n\nThe applications mentioned above rely on the assumption of some or\nother norms for credences. Although the correct norms are held by most\nBayesians to include at least Probabilism and the Principle of\nConditionalization, it is debated whether there are more and, if so,\nwhat they are. It is to this issue that I now turn.\n\n\n1.4 Bayesians Divided: What Does Coherence Require?\n\nProbabilism is often regarded as a coherence norm, which says\nhow one\u2019s opinions ought to fit together on pain of incoherence.\nSo, if Probabilism matters, the reason seems to be that coherence\nmatters. This raises a question that divides Bayesians: What does\nthe coherence of credences require? A typical Bayesian thinks\nthat coherence requires at least that one\u2019s credences follow\nProbabilism. But there are actually different versions of Probabilism\nand Bayesians disagree about which one is correct. Bayesians also\ndisagree about whether the coherence of credences requires more than\nProbabilism and, if so, to what extent. For example, does coherence\nrequire that one\u2019s credence in a contingent proposition\nlie strictly between 0 and 1? Another issue is what coherence requires\nof conditional credences, i.e., the credences that one has on the\nsupposition of the truth of one or another proposition. Those and\nother related questions have far-reaching impacts on applications of\nBayesian epistemology. For more on the issue of what coherence\nrequires, see\n section 3.\n\n\n1.5 Bayesians Divided: The Problem of the Priors\n\nThere is another issue that divides Bayesians. The package of\nProbabilism and the Principle of Conditionalization seems to explain\nwell why one\u2019s credence in General Relativity ought to rise in\nEddington\u2019s Observation Case. But that particular Bayesian\nexplanation relies on a crucial feature of the case: the evidence\nE is entailed by the hypothesis H in question.\nBut such an entailment is missing in many interesting cases, such as\nthis one:\n\n\nExample (Enumerative Induction). After a day\nof field research, we observed one hundred black ravens without a\ncounterexample. So the newly acquired evidence is E = \u201cwe\nhave observed one hundred ravens and they all were black\u201d. We\nare interested in this hypothesis H = \u201cthe next raven to\nbe observed will be black\u201d.\n\n\n\nNow, should the credence in the hypothesis be increased or lowered,\naccording to the two core Bayesian norms? Well, it depends. Note that\nin the present case H entails neither E nor its\nnegation, so the possibilities in H can be categorized into two\ngroups: those compatible with E, and those incompatible with\nE. As a result of conditionalization, the possibilities\nincompatible with E will have their credences be dropped down\nto zero; those compatible, scaled up. If the scaling up outweighs the\ndropping down for the possibilities inside H, the credence in\nH will rise and thus behave inductively; otherwise, it will\nstay constant or even go down and thus behave counter-inductively. So\nit all depends on the specific details of the prior, which is\nshorthand for the assignment of credences that one has before one\nacquires the new evidence in question. To sum up: Probabilism and the\nPrinciple of Conditionalization, alone, are too weak to entitle us to\nsay whether one\u2019s credence ought to change inductively or\ncounter-inductively in the above example.\n\nThis point just made generalizes to most applications of Bayesian\nepistemology. For example, some coherent priors lead to enumerative\ninduction and some don\u2019t (Carnap 1955), and some coherent priors\nlead to Ockham\u2019s razor and some don\u2019t (Forster 1995: sec.\n3). So, besides the coherence norms (such as Probabilism), are there\nany other norms that govern one\u2019s prior? This is known as\nthe problem of the priors.\n\nThis issue divides Bayesians. First of all, there is the party of\nsubjective Bayesians, who hold that every prior is permitted\nunless it fails to be coherent. So, to those Bayesians, the correct\nnorms for priors are exhausted by Probabilism and the other coherence\nnorms if any. Second, there is the party of objective\nBayesians, who propose that the correct norms for priors include\nnot just the coherence norms but also a norm that codifies the\nepistemic virtue of freedom from bias. Those Bayesians think that\nfreedom from bias requires at least that, roughly speaking,\none\u2019s credences be evenly distributed to certain possibilities\nunless there is a reason not to. This norm, known as the Principle\nof Indifference, has long been a source of controversy. Last but\nnot the least, some Bayesians even propose to take seriously certain\nepistemic virtues that have been extensively studied in other\nepistemological traditions, and argue that those virtues need to be\ncodified into norms for priors. For more on those attempted solutions\nto the problem of the priors, see\n section 4\n below. Also see\n section 3.3 of the entry on interpretations of probability.\n\nSo far I have been mostly taking for granted the package of\nProbabilism and the Principle of Conditionalization. But is there any\ngood reason to accept those two norms? This is the next topic.\n\n\n1.6 An Attempted Foundation: Dutch Book Arguments\n\nThere have been a number of arguments advanced in support of the two\ncore Bayesian norms. Perhaps the most influential is of the kind\ncalled Dutch Book arguments. Dutch Book arguments are\nmotivated by a simple, intuitive idea: Belief guides action. So, the\nmore strongly you believe that it will rain tomorrow, the more\ninclined you are, or ought to be, to bet on bad weather. This idea,\nwhich connects degrees of belief to betting dispositions, can be\ncaptured at least partially by the following:\n\n\nA Credence-Betting Bridge Principle (Toy\nVersion). If one\u2019s credence in a proposition A is\nequal to a real number a, then it is acceptable for one to buy\nthe bet \u201cWin $100 if A is true\u201d at the price\n\\(\\$100 \\cdot a\\) (and at any lower price).\n\n\n\nThis bridge principle might be construed as part of a definition or as\na necessary truth that captures the nature of credences, or understood\nas a norm that jointly constrains credences and betting dispositions\n(Christensen 1996; Pettigrew 2020a: sec. 3.1). The hope is that,\nthrough this bridge principle or perhaps a refined one, bad credences\ngenerate bad symptoms in betting dispositions. If so, a close look at\nbetting dispositions might help us sort out bad credences from good\nones. This is the strategy that underlies Dutch Book arguments.\n\nTo illustrate, consider an agent who has a .75 credence in proposition\nA and a .30 credence in its negation \\(\\neg A\\) (which violates\nProbabilism). Assuming the bridge principle stated above, the agent is\nwilling to bet as follows:\n\nBuy \u201cwin $100 if A is true\u201d at \\(\\$75\\).\nBuy \u201cwin $100 if \\(\\neg A\\) is true\u201d at \\(\\$30\\).\n\n\nSo the agent is willing to accept each of those two offers.\nBut it is actually very bad to accept both at the same time,\nfor that leads to a sure loss (of $5):\n\n\n\n\n\nA is true\nA is false  \n\n\nbuy \u201cwin $100 if A is\ntrue\u201d at $75\n\\(-\\$75 + \\$100\\)\n\\(-\\$75\\) \n\nbuy \u201cwin $100 if \\(\\neg A\\) is\ntrue\u201d at $30\n\\(-\\$30\\)\n\\(-\\$30 + \\$100\\) \n\nnet payoff\n\\(-\\$5\\)\n\\(-\\$5\\)  \n\n\n\nSo this agent\u2019s betting dispositions make her susceptible to a\nset of bets that are individually acceptable but jointly inflict a\nsure loss. Such a set of bets is called a Dutch Book. The\nabove agent is susceptible to a Dutch Book, which sounds bad for the\nagent. So what has gone wrong? The problem seems to be this: Belief\nguides action, and in this case, bad beliefs result in bad actions:\ngarbage in, garbage out. Therefore, the agent should not have had the\ncombination of credence .75 in \\(A\\) and .30 in \\(\\neg A\\) to begin\nwith\u2014or so a Dutch Book argument would conclude.\n\nThe above line of thought can be generalized and turned into a\ntemplate for Dutch Book arguments:\n\n\nA Template for Dutch Book Arguments\n\nPremise 1. You should follow such and such a credence-betting\nbridge principle (or, due to the nature of credences, you do so\nnecessarily).\nPremise 2. If you do, and if your credences violate constraint\nC, then provably you are susceptible to a Dutch Book.\nPremise 3. But you should not be so susceptible.\nConclusion. So your credences should satisfy constraint\nC.\n\n\n\nThere is a Dutch Book argument for Probabilism (Ramsey 1926, de\nFinetti 1937). The idea can be extended to develop an argument for the\nPrinciple of Conditionalization (Lewis 1999, Teller 1973). Dutch Book\narguments have also been developed for other norms for credences, but\nthey require modifying the concept of a Dutch Book in one way or\nanother. See\n section 3\n for references.\n\nAn immediate worry about Dutch Book arguments is that a higher\ncredence might not be correlated with a stronger disposition to bet.\nConsider a person who loathes very much the anxiety caused by placing\na bet. So, though she is very confident in a proposition, she might\nstill refuse to buy a bet on its truth even at a low price\u2014and\nrightly so. This seems to be a counterexample to premise 1 in the\nabove. For more on Dutch Book arguments, including objections to them\nas well as refinements of them, see the survey by H\u00e1jek (2009)\nand the entry on\n Dutch Book arguments.\n\nThere is a notable worry that applies even if we have a Dutch Book\nargument that is logically valid and only has true premises. A Dutch\nBook argument seems to give only a practical reason for\naccepting an epistemic norm: \u201cDon\u2019t have such and\nsuch combinations of credences, for otherwise there would be something\nbad pragmatically\u201d. Such a reason seems unsatisfactory for those\nwho wish to explain the correctness of the Bayesian norms with a\nreason that is distinctively epistemic or at least non-pragmatic. Some\nBayesians still think that Dutch Book arguments are good, and address\nthe present worry by trying to give a non-pragmatic reformulation of\nDutch Book arguments (Christensen 1996; Christensen 2004: sec. 5.3).\nSome other Bayesians abandon Dutch Book arguments and pursue\nalternative foundations of Bayesian epistemology, to which I turn\nnow.\n\n\n1.7 Alternative Foundations\n\nA second proposed type of foundation for Bayesian epistemology is\nbased on the idea of accurate estimation. This idea has two\nparts: estimation, and its accuracy. On this approach, one\u2019s\ncredence in a proposition A is one\u2019s estimate of\nthe truth value of A, where A\u2019s truth value is\nidentified with 1 if it is true and 0 if it is false (Jeffrey 1986).\nThe closer one\u2019s credence in A is to the truth value of\nA, the more accurate one\u2019s estimate is. Then a\nBayesian may argue that one\u2019s credences ought to be\nprobabilistic, for otherwise the overall accuracy of one\u2019s\ncredence assignment would be dominated\u2014namely, it\nwould, come what may, be lower than the overall accuracy of another\ncredence assignment that one could have adopted. To some Bayesians,\nthis gives a distinctively epistemic reason or explanation why\none\u2019s credences ought to be probabilistic. The result is the\nso-called accuracy-dominance argument for Probabilism (Joyce\n1998). This approach has also been extended to argue for the Principle\nof Conditionalization (Briggs & Pettigrew 2020). For more on this\napproach, see the entry on\n epistemic utility arguments for probabilism\n as well as Pettigrew (2016).\n\nThere is a third proposed type of foundation for Bayesian\nepistemology. It appeals to a kind of doxastic state called\ncomparative probability, which concerns a person\u2019s\ntaking one proposition to be more probable than, or as\nprobable as, or less probable than another proposition.\nOn this approach, we postulate some bridge principles that connect\none\u2019s credences to one\u2019s comparative probabilities. Here\nis an example of such a bridge principle: for any propositions\nX and Y, if X is equivalent to the disjunction of\ntwo incompatible propositions, each of which one takes to be\nmore probable than Y, then one\u2019s credence in X\nshould be more than twice of that in Y. With such\nbridge principles, a Bayesian may argue from norms for comparative\nprobabilities to norms for credences, such as Probabilism. See\nFishburn (1986) for the historical development of this approach. See\nStef\u00e1nsson (2017) for a recent defense and development. For a\ngeneral survey of this approach, see Konek (2019). This approach has\nbeen extended by Joyce (2003: sec. 4) to justify the Principle of\nConditionalization.\n\nThe above are just some of the attempts to provide foundations for\nBayesian epistemology. For more, see the surveys by Weisberg (2011:\nsec. 4) and Easwaran (2011).\n\nThere is a distinctive class of worries for all the three proposed\nfoundations presented above, due to the fact that they rely on one or\nanother account of the nature of credences. This is where Bayesian\nepistemology meets philosophy of mind. Recall that they try to\nunderstand credences in relation to some other mental states: (i)\nbetting dispositions, (ii) estimates of truth values, or (iii)\ncomparative probabilities. But those accounts of credences are\napparently vulnerable to counterexamples. (An example was mentioned\nabove: a person who dislikes the anxiety caused by betting seems to be\na counterexample to the betting account of credences). For more on\nsuch worries, see Eriksson and H\u00e1jek (2007). For more on\naccounts of credences, see\n section 3.3 of the entry on interpretations of probability\n and\n section 3.4 of the entry on imprecise probabilities.\n\nThere is a fourth, application-driven style of argument for\nnorms for credences that seems to be explicit or implicit in the minds\nof many Bayesians. The idea is that a good argument for the two core\nBayesian norms can be obtained by appealing to applications. The goal\nis to account for a comprehensive range of intuitively good\nepistemic practices, all done with a simple set of general\nnorms consisting of little or nothing more than the two core Bayesian\nnorms. If this Bayesian normative system is so good that, of the known\ncompetitors, it strikes the best balance of those two virtues just\nmentioned\u2014comprehensiveness and simplicity\u2014then\nthat is a good reason for accepting the two core Bayesian\nnorms. In fact, the method just described is applicable to any norm,\nfor credences or for actions, in epistemology or in ethics. Some\nphilosophers argue that this method in its full generality, called\nReflective Equilibrium, is the ultimate method for finding a\ngood reason for or against norms (Goodman 1955; Rawls 1971). For more\non this method and its controversies, see the entry on\n reflective equilibrium.\n\nThe above are some ways to argue for Bayesian norms. The rest of this\nintroductory tutorial is meant to sketch some general objections,\nleaving detailed discussions to subsequent sections.\n\n\n1.8 Objections to Conditionalization\n\nThe Principle of Conditionalization requires one to react to new\nevidence by conditionalizing on it. So this principle, when construed\nliterally, appears to be silent on the case in which one receives\nno new evidence. That is, it seems to be too weak to require\nthat one shouldn\u2019t arbitrarily change credences when there is no\nnew evidence. To remedy this, the Principle of Conditionalization is\nusually understood such that the case of no new evidence is identified\nwith the limiting case in which one acquires a logical truth as\ntrivial new evidence, which rules out no possibilities. In that case,\nconditionalization on the trivial new evidence lowers no credences,\nand thus rescales credences only by a factor of 1\u2014no credence\nchange at all\u2014as desired. Once the Principle of\nConditionalization is construed that way, it is no longer too weak,\nbut then the worry is that it becomes too strong. Consider the\nfollowing case, which Earman (1992) adapts from Glymour (1980):\n\n\nExample (Mercury). It is 1915. Einstein has\njust developed a new theory, General Relativity. He assesses the new\ntheory with respect to some old data that have been known for at least\nfifty years: the anomalous rate of the advance of Mercury\u2019s\nperihelion (which is the point on Mercury\u2019s orbit that is\nclosest to the Sun). After some derivations and calculations, Einstein\nsoon recognizes that his new theory entails the old data about the\nadvance of Mercury\u2019s perihelion, while the Newtonian theory does\nnot. Now, Einstein increases his credence in his new theory, and\nrightly so.\n\n\n\nNote that, during his derivation and calculation, Einstein does not\nperform any experiment or collect any new astronomical data, so the\nbody of his evidence seems to remain unchanged, only consisting of the\nold data. Despite gaining no new evidence, Einstein changes (in fact,\nraises) his credence in the new theory, and rightly so\u2014against\nthe usual construal of the Principle of Conditionalization. Therefore,\nthere is a dilemma for that principle: when construed literally, it is\ntoo weak to prohibit arbitrary credence change; when construed in the\nusual way, it is too strong to accommodate Einstein\u2019s credence\nchange in the Mercury Case. This problem is Earman\u2019s problem\nof old evidence.\n\nThe problem of old evidence is sometimes presented in a different\nway\u2014in Glymour\u2019s (1980) way\u2014whose target of attack\nis not the Principle of Conditionalization but this:\n\n\nBayesian Confirmation Theory (A Simple\nVersion). Evidence E confirms hypothesis H for a\nperson at a time if and only if, at that time, her credence in\nH would be raised if she were to conditionalize on E\n(whether or not she actually does that).\n\n\n\nIf E is an old piece of evidence that a person had received\nbefore, this person\u2019s credence in E is currently 1. So,\nconditionalization on E at the present time would involve\ndropping no credence, followed by rescaling credences with a factor of\n1\u2014so there is no credence change at all. Then, by the Bayesian\naccount of confirmation stated above, old evidence E must fail\nto confirm new theory H. But that result seems to be wrong\nbecause the old data about the advance of Mercury\u2019s perihelion\nconfirmed Einstein\u2019s new theory; this is Glymour\u2019s\nproblem of old evidence, construed as a challenge to a Bayesian\naccount of confirmation. But, if Earman (1992) is right, the Mercury\nCase challenges not just Bayesian confirmation theory, but actually\ncuts deeper, all the way to one of the two core Bayesian\nnorms\u2014namely, the Principle of Conditionalization\u2014as\nsuggested by Earman\u2019s problem of old evidence. For attempted\nsolutions to Earman\u2019s old evidence problem (about\nconditionalization), see\n section 5.1\n below. For more on Glymour\u2019s old evidence problem (about\nconfirmation), see\n section 3.5 of the entry on confirmation.\n\nThe above is just the beginning of a series of problems for the\nPrinciple of Conditionalization, which will be discussed after this\ntutorial, in\n section 5.\n But here is a rough sketch: The problem of old evidence arises when a\nnew theory is developed to accommodate some old evidence. When the\nfocus is shifted from old evidence to new theory, we shall discover\nanother problem, no less thorny. Also note that the problem of old\nevidence results from a kind of inflexibility in conditionalization:\nno credence change is permitted without new evidence. Additional\nproblems have been directed at other kinds of inflexibility in\nconditionalization, such as the preservation of fully certain\ncredences. In response, some Bayesians defend the Principle of\nConditionalization by trying to develop it into better versions, as\nyou will see in\n section 5.\n\n\n1.9 Objections about Idealization\n\nAnother worry is that the two core Bayesian norms are not the kind of\nnorms that we ought to follow, in that they are too demanding to be\nactually followed by ordinary human beings\u2014after all,\nought implies can. More specifically, those Bayesian\nnorms are often thought to be too demanding for at least three\nreasons:\n\n(Sharpness) Probabilism demands that\none\u2019s credence in a proposition be extremely sharp, as sharp as\nan individual real number, precise to potentially infinitely many\ndigits.\n(Perfect Fit) Probabilism demands that\none\u2019s credences fit together nicely; for example, some credences\nare required to sum to exactly 1, no more and no less\u2014a perfect\nfit. The Principle of Conditionalization also demands a perfect fit\namong three things: prior credences, posterior credences, and new\nevidence.\n(Logical Omniscience) Probabilism is often\nthought to demand that one be logically omniscient, having\ncredence 1 in every logical truth and credence 0 in every logical\nfalsehood.\n\n\nThe last point, logical omniscience, might not be immediately clear\nfrom the preceding presentation, but it can be seen from this\nobservation: A logical truth is true in all possibilities, so it has\nto be assigned credence 1 by Sum-to-One and Additivity in\nProbabilism.\n\nSo the worry is that, although Bayesians have a simple normative\nframework, they seem to enjoy the simplicity because they idealize\naway from the complications in humans\u2019 epistemic endeavors and\nturn instead to normative standards that can be met only by highly\nidealized agents. If so, there are pervasive counterexamples to the\ntwo core Bayesian norms: all human beings. Call this the problem\nof idealization. For different ways of presenting this problem,\nsee Harman (1986: ch. 3), Foley (1992: sec. 4.4), Pollock (2006: ch.\n6), and Horgan (2017).\n\nIn reply, Bayesians have developed at least three strategies, which\nmight complement each other. The first strategy is to remove\nidealization gradually, one step at a time, and explain why this is a\ngood way of doing epistemology\u2014just like this has long been\ntaken as a good way of doing science. The second strategy is to\nexplain why it makes sense for we human beings to strive for\nsome ideals, including the ideals that the two core Bayesian norms\npoint to, even though human beings cannot attain those ideals. The\nthird strategy is to explain how the kind of idealization in question\nactually empowers and facilitates the applications of\nBayesian epistemology in science (including especially\nscientists\u2019 use of Bayesian statistics). For more on those\nreplies to the problem of idealization, see\n section 6.\n\n1.10 Concerns, or Encouragements, from Non-Bayesians\n\nIn the eyes of those immersed in the epistemology of all-or-nothing\nopinions such as believing or accepting propositions, Bayesians seem\nto say and care too little about many important and traditional\nissues. Let me give some examples below.\n\nFirst of all, the more traditional epistemologists would like to see\nBayesians engage with varieties of skepticism. For example, there is\nCartesian skepticism, which is the view that we cannot know\nwhether an external world, as we understand it through our\nperceptions, exists. There is also the Pyrrhonian skeptical\nworry that no belief can ever be justified because, once a belief is\nto be justified with a reason, the adduced reason is in need of\njustification as well, which kickstarts an infinite regress of\njustifications that can never be finished. Note that the above\nskeptical views are expressed in terms of knowledge and justification.\nSo, the more traditional epistemologists would also like to hear what\nBayesians have to say about knowledge and\njustification, rather than just norms for credences.\n\nSecond, the more traditional philosophers of science would like to see\nBayesians contribute to some classic debates, such as the one between\nscientific realism and anti-realism. Scientific realism is,\nroughly, the view that we have good reason to believe that our best\nscientific theories are true, literally or approximately. But the\nanti-realists disagree. Some of them, such as the\ninstrumentalists, think that we only have good reason to\nbelieve that our best scientific theories are good tools for certain\npurposes. Bayesians often compare the credences assigned to competing\nscientific theories, but one might like to see a comparison between,\non the one hand, the credence that a certain theory T is true\nand, on the other hand, the credence that T is a good tool for\nsuch and such purposes.\n\nLast but not least, frequentists about statistical inference would\nurge that Bayesians also think about a certain epistemic virtue,\nreliability, rather than focus exclusively on coherence.\nNamely, they would like to see Bayesians take seriously the analysis\nand design of reliable inference methods\u2014reliable in the sense\nof having a low objective, physical chance of making errors.\n\nTo be sure, Bayesian epistemology was not initially designed to\naddress the concerns just expressed. But those concerns need not be\ntaken as objections, but rather as encouragements to Bayesians to\nexplore new territories. In fact, Bayesians have begun such\nexplorations in some of their more recent works, as you will see in\nthe\n closing section, 7.\n\nThe above finishes the introductory tutorial on Bayesian epistemology.\nThe following sections, as well as many other encyclopedia entries\ncited above, elaborate on one or another more specific topic in\nBayesian epistemology. Indeed, the above tutorial only shows you what\ntopics there are and aims to help you jump to the sections below, or\nto the relevant entries, that interest you.\n\n2. A Bit of Mathematical Formalism\n\nTo facilitate subsequent discussions, a bit of mathematical formalism\nis needed. Indeed, the two core Bayesian norms were only stated above\nin a simple, finite setting\n (section 1.2),\n but there can be an infinity of possibilities under consideration.\nFor example, think about this question: What\u2019s the objective,\nphysical chance for a carbon-14 atom to decay in 20 years? Every\npossible chance in the unit interval \\([0, 1]\\) is a possibility to\nwhich a credence can be assigned. So the two core Bayesian norms need\nto be stated in a more general way than above.\n\nLet \\(\\Omega\\) be a set of possibilities that are mutually exclusive\nand jointly exhaustive. There is no restriction on the size of\n\\(\\Omega\\); it can be finite or infinite. Let \\(\\cal A\\) be a set of\npropositions identified with some subsets of \\(\\Omega\\). Assume that\n\\(\\cal A\\) contains \\(\\Omega\\) and the empty set \\(\\varnothing\\), and\nis closed under the standard Boolean operations: conjunction\n(intersection), disjunction (union), and negation (complement). This\nclosure assumption means that, whenever \\(A\\) and \\(B\\) are in \\(\\cal\nA\\), so are their intersection \\(A \\cap B\\), union \\(A \\cup B\\), and\ncomplement \\(\\Omega \\mcomplement A\\), which are often written in\nlogical notation as conjunction \\(A \\wedge B\\), disjunction \\(A \\vee\nB\\), and negation \\(\\neg A\\). When \\(\\cal A\\) satisfies the assumption\njust stated, it is called an algebra of\n sets/propositions.[2]\n\nLet \\(\\Cr\\) be an assignment of credences to some propositions. We\nwill often think of \\(\\Cr(A)\\) as denoting one\u2019s credence in\nproposition \\(A\\) and refer to \\(\\Cr\\) as one\u2019s credence\nfunction or credence assignment. Next, we need a\ndefinition from probability theory:\n\n\n\n\nDefinition (Probability Measure). A credence\nfunction \\(\\Cr(\\wcdot)\\) is said to be probabilistic, also\ncalled a probability measure, if it is a real-valued function\ndefined on an algebra \\({\\cal A}\\) of propositions and satisfies the\nthree axioms of probability:\n\n(Non-Negativity) \\(\\Cr(A) \\ge 0\\) for every\n\\(A\\) in \\(\\cal A\\).\n(Normalization) \\(\\Cr(\\Omega) = 1\\).\n(Finite Additivity) \\(\\Cr(A \\cup B) = \\Cr(A) +\n\\Cr(B)\\) for any two incompatible propositions (i.e., disjoint sets)\n\\(A\\) and \\(B\\) in \\(\\cal A\\).\n\n\n\n\nNow Probabilism can be stated as follows:\n\n\nProbabilism (Standard Version). One\u2019s\nassignment of credences at each time ought to be a probability\nmeasure.\n\n\n\nWhen it is clear from the context that the credence assignment \\(\\Cr\\)\nis assumed to be probabilistic, it is often written \\(\\Pr\\) or \\(P\\).\nThe process of conditionalization can be defined as follows:\n\n\n\n\nDefinition (Conditionalization). Suppose that\n\\(\\Cr(E) \\neq 0\\). A (new) credence function \\(\\Cr'(\\wcdot)\\) is said\nto be obtained from (old) credence function \\(\\Cr(\\wcdot)\\) by\nconditionalization on \\(E\\) if, for each \\(X \\in {\\cal\nA}\\), \n\\[\\Cr'(X) = \\frac{\\Cr(X\\cap E)}{\\Cr(E)}.\\]\n \n\n\n\nConditionalization changes the credence in \\(X\\) from \\(\\Cr(X)\\) to\n\\(\\Cr'(X)\\), which can be understood as involving two steps:\n\n\\[\\Cr(X) \\ovrightarrow{(i)}\n\\Cr(X \\cap E) \\ovrightarrow{(ii)} \\frac{\\Cr(X\\cap E)}{\\Cr(E)} = \\Cr'(X) .\\]\n\n\nTransition (i) corresponds to the zeroing step in the the informal\npresentation in\n section 1.2\n of conditionalization; transition (ii), the rescaling step. Now the\nsecond norm can be stated as follows:\n\n\nThe Principle of Conditionalization (Standard\nVersion). One\u2019s credences ought to change by and only by\nconditionalization on the new evidence received.\n\n\n\nThe two norms just stated reduce to the informal versions presented in\nthe tutorial\n section 1.2\n when \\(\\Omega\\) contains only finitely many possibilities and \\(\\cal\nA\\) is the set of all subsets of \\(\\Omega\\).\n\nLet \\(\\Cr(X \\mid E)\\) denote one\u2019s credence in \\(X\\) on the\nsupposition of the truth of \\(E\\) (whether or not one will actually\nreceive \\(E\\) as new evidence); it is also called credence in \\(X\\)\ngiven \\(E\\), or credence in \\(X\\) conditional on \\(E\\). So \\(\\Cr(X\n\\mid E)\\) denotes a conditional credence, while \\(\\Cr(X)\\)\ndenotes an unconditional one. The connection between those\ntwo kinds of credences is often expressed by\n\n\nThe Ratio Formula \n\\[\\Cr(X\\mid E) = \\frac{\\Cr(X \\cap E)}{\\Cr(E)} \\quad\\text{ if } \\Cr(E) \\neq 0.\\]\n\n\n\nIt is debatable whether this formula should be construed as a\ndefinition or as a normative constraint. See H\u00e1jek (2003) for\nsome objections to the definitional construal and for further\ndiscussion. \\(\\Cr(X \\mid E)\\) is often taken as shorthand for the\ncredence in \\(X\\) that results from conditionalization on \\(E\\),\nassuming that the Ratio Formula holds.\n\nMany applications of Bayesian epistemology make use Bayes\u2019\ntheorem. It has different versions, of which two are particularly\nsimple:\n\n\n\n\nBayes\u2019 Theorem (Simplest Version). Suppose\nthat \\(\\Cr\\) is probabilistic and assigns nonzero credences to \\(H\\)\nand \\(E\\), and that the Ratio Formula\n holds.[3]\n Then we have: \n\\[\n        \\Cr(H\\mid E) = \\frac{\\Cr(E \\mid H) \\cdot \\Cr(H)}{\\Cr(E)} .\n        \\]\n\n\n\n\n\n\n\nBayes\u2019 Theorem (Finite Version). Suppose\nfurther that hypotheses \\(H_1, \\ldots, H_N\\) are mutually exclusive\nand finite in number, and that each is assigned a nonzero credence and\ntheir disjunction is assigned credence 1 by \\(\\Cr\\). Then we have:\n\n\\[\n        \\Cr(H_i\\mid E) = \\frac{\\Cr(E \\mid H_i) \\cdot \\Cr(H_i)}{\\sum_{j=1}^{N} \\Cr(E \\mid H_j) \\cdot \\Cr(H_j)} .\n   \\]\n \n\n\n\nThis theorem is often useful for calculating credences that result\nfrom conditionalization on evidence \\(E\\), which are represented on\nthe left side of the formula. Indeed, this theorem is very useful and\nimportant in statistical applications of Bayesian epistemology (see\n section 3.5\n below). For more on the significance of this theorem, see the entry\non\n Bayes\u2019 theorem.\n But this theorem is not essential to some other applications of\nBayesian epistemology. Indeed, the case studies in the tutorial\nsection make no reference to Bayes\u2019 theorem. As Earman (1992:\nch. 1) points out in his presentation of Bayes\u2019 (1763) seminal\nessay, Bayesian epistemology is Bayesian not really because\nBayes\u2019 theorem is used in a certain way, but because\nBayes\u2019 essay already contains the core ideas of Bayesian\nepistemology: Probabilism and the Principle of Conditionalization.\n\nHere are some introductory textbooks on Bayesian epistemology (and\nrelated topics) that include presentations of elementary probability\ntheory: Skyrms (1966 [2000]), Hacking (2001), Howson & Urbach\n(2006), Huber (2018), Weisberg (2019\n [Other Internet Resources]),\n and Titelbaum (forthcoming).\n\n\n3. Synchronic Norms (I): Requirements of Coherence\n\nA coherence norm states how one\u2019s opinions ought to fit together\non pain of incoherence. Most Bayesians agree that the correct\ncoherence norms include at least Probabilism, but they disagree over\nwhich version of Probabilism is right. There is also the question of\nwhether there are correct coherence norms that go beyond Probabilism\nand, if so, what they are. Those issues were only sketched in the\ntutorial\n section 1.4.\n They will be detailed in this section.\n\nTo argue that a certain norm is not just correct but ought to be\nfollowed on pain of incoherence, Bayesians traditionally\nproceed by way of a Dutch Book argument (as presented in the tutorial\n section 1.6).\n For the susceptibility to a Dutch Book is traditionally taken by\nBayesians to imply one\u2019s personal incoherence. So, as you will\nsee below, the norms discussed in this section have all been defended\nwith one or another type of Dutch Book argument, although it is\ndebatable whether some types are more plausible than others.\n\n3.1 Versions of Probabilism\n\nProbabilism is often stated as follows:\n\n\nProbabilism (Standard Version). One\u2019s\nassignment of credences ought to be probabilistic in this sense: it is\na probability measure.\n\n\n\nThis norm implies that one should have a credence in a logical truth\n(indeed, a credence of 1) and that, when one has credences in some\npropositions, one should also have credences in their\nconjunctions, disjunctions, and negations. So Probabilism in its\nstandard version asks one to have credences in certain propositions.\nBut that seems to be in tension with the fact that Probabilism is\noften understood as a coherence norm. To see why, note that\ncoherence is a matter of fitting things together nicely. So coherence\nis supposed to put a constraint on the combinations of attitudes that\none may have, without saying that one must have an attitude\ntoward such and such propositions\u2014contrary to the above version\nof Probabilism. If so, the right version of Probabilism must be weak\nenough to allow the absence of some credences, also called\ncredence gaps.\n\nThe above line of thought has led some Bayesians to develop and defend\na weaker version of Probabilism (de Finetti 1970 [1974], Jeffrey 1983,\nZynda 1996):\n\n\nProbabilism (Extensibility Version).\nOne\u2019s assignment of credences ought to be probabilistically\nextensible in this sense: either it is already a probability measure,\nor it can be turned into a probability measure by assigning new\ncredences to some more propositions without changing the existing\ncredences.\n\n\n\nIt is the second disjunct that allows credence gaps. De Finetti (1970\n[1974: sec. 3]) also argues that, when the Dutch Book argument for\nProbabilism is carefully examined, it can be seen to support only the\nextensibility version rather than the standard one. His idea is to\nadopt a liberal conception of betting dispositions: one is permitted\nto lack any betting disposition about a proposition, which in turn\npermits one to lack a credence in that proposition.\n\nThe above two versions of Probabilism are still similar in that they\nboth imply that any credence ought to be sharp\u2014being an\nindividual real number. But some Bayesians maintain that coherence\ndoes not require that much but allows credences to be unsharp\nin a certain sense. An even weaker version of Probabilism has been\ndeveloped accordingly, defended with a Dutch Book argument that works\nwith a more liberal conception of betting dispositions than mentioned\nabove (Smith 1961; Walley 1991: ch. 2 and 3). See\n supplement A\n for some non-technical details. Bayesians actually disagree over\nwhether coherence allows credences to be unsharp. For this debate, see\nthe survey by Mahtani (2019) and the entry on\n imprecise probabilities.\n\n\n3.2 Countable Additivity\n\nProbabilism, as stated in\n section 2,\n implies Finite Additivity, the norm that one\u2019s credence in the\ndisjunction of two incompatible disjuncts ought to be equal to the sum\nof the credences in those two disjuncts. Finite Additivity can be\nnaturally strengthened as follows:\n\n\n\n\nCountable Additivity. It ought to be that, for any\npropositions \\(A_1,\\) \\(A_2,\\)\u2026, \\(A_n,\\)\u2026 that are\nmutually exclusive, if one has credences in those propositions and in\ntheir disjunction \\(\\bigcup_{n=1}^{\\infty} A_n\\), then one\u2019s\ncredence function \\(\\Cr\\) satisfies the following formula:\n\n\\[\\Cr\\left( \\bigcup_{n=1}^{\\infty} A_n \\right) = \\sum_{n = 1}^{\\infty} \\Cr\\left(A_n\\right).\\]\n \n\n\n\nCountable Additivity has extensive applications, both in statistics\nand in philosophy of science; for a concise summary and relevant\nreferences, see J. Williamson (1999: sec. 3).\n\nAlthough Countable Additivity is a natural strengthening of Finite\nAdditivity, the former is much more controversial. De Finetti (1970\n[1974]) proposes a counterexample:\n\n\nExample (Infinite Lottery). There is a fair\nlottery with a countable infinity of tickets. Since it is fair, there\nis one and only one winning ticket, and all tickets are equally likely\nto win. For an agent taking all those for granted (i.e., with full\ncredence), what should be her credence in the proposition \\(A_n\\) that\nthe n-th ticket will win?\n\n\n\nThe answer seems to be 0. To see why, note that all those propositions\n\\(A_n\\) should be assigned equal credences \\(c\\), by the fairness of\nthe lottery. Then it is not hard to show that, in order to satisfy\nProbabilism, a positive \\(c\\) is too high and a negative \\(c\\) is too\n low.[4]\n So, by Probabilism, the only alternative is \\(c = 0\\). But this\nresult violates Countable Additivity: by the fairness of the lottery,\nthe left side is \n\\[\\Cr\\left(\\bigcup_{n = 1}^{\\infty} A_n\\right) = 1,\\]\n\n\nbut the right side is \n\\[\\sum_{n = 1}^{\\infty} \\Cr\\left(A_n\\right) = \\sum_{n=1}^{\\infty} c = 0.\\]\n\n\nDe Finetti thus concludes that this is a counterexample to Countable\nAdditivity. For closely related worries about Countable Additivity,\nsee Kelly (1996: ch. 13) and Seidenfeld (2001). Also see Bartha (2004:\nsec. 3) for discussions and further references.\n\nDespite the above controversy, attempts have been made to argue for\nCountable Additivity, partly because of the interest in saving its\nextensive applications. For example, J. Williamson (1999) defends the\nidea that there is a good Dutch Book argument for Countable Additivity\neven though the Dutch Book involved has to contain a countable\ninfinity of bets and the agent involved has to be able to accept or\nreject that many bets. Easwaran (2013) provides further defense of the\nDutch Book argument for Countable Additivity (and another argument for\nit). The above two authors also argue that the Infinite Lottery Case\nonly appears to be a counterexample to Countable Additivity and can be\nexplained away.\n\nIt is debatable whether we really need to defend Countable Additivity\nin order to save its extensive applications. Bartha (2004) thinks that\nthe answer is negative. He argues that, even if Countable Additivity\nis abandoned due to the Infinite Lottery Case, this poses no serious\nthreat to its extensive applications.\n\n\n3.3 Regularity\n\nA contingent proposition is true in some cases, while a logical\nfalsehood is true in no cases at all. So perhaps the credence in the\nformer should always be greater than the credence in the latter, which\nmust be 0. This line of thought motivates the following norm:\n\n\nRegularity. It ought to be that, if one has a\ncredence in a logically consistent proposition, it is greater than\n0.\n\n\n\nRegularity has been defended with a Dutch Book argument\u2014a\nsomewhat nonstandard one. Kemeny (1955) and Shimony (1955) show that\nany violation of Regularity opens the door to a nonstandard,\nweak Dutch Book, which is a set of bets that guarantees no\ngain but has a possible loss. In contrast, a standard Dutch Book has a\nsure loss. This raises the question whether it is really so bad to be\nvulnerable to a weak Dutch Book.\n\nOne might object to Regularity on the ground that it is in conflict\nwith Conditionalization. To see the conflict, note that\nconditionalization on a contingent proposition \\(E\\) drops the\ncredence in another contingent proposition, \\(\\neg E\\), down to zero.\nBut that violates Regularity. In reply, defenders of Regularity can\nreplace conditionalization by a generalization of it called\nJeffrey Conditionalization, which need not drop any credence\ndown to zero. Jeffrey Conditionalization will be defined and discussed\nin\n section 5.3.\n\nThere is a more serious objection to Regularity. Consider the\nfollowing case:\n\n\nExample (Coin). An agent is interested in the\nbias of a certain coin\u2014the objective, physical chance\nfor that coin to land heads when tossed. This agent\u2019s credences\nare distributed uniformly over the possible biases of the\ncoin. This means that her credence in \u201cthe bias falls within\ninterval \\([a, b]\\)\u201d is equal to the length of the interval,\n\\(b-a\\), provided that the interval is nested within \\([0, 1]\\). Now\nthink about \u201cthe coin is fair\u201d, which says that the bias\nis equal to 0.5, i.e., that the bias falls within the trivial interval\n\\([0.5, 0.5]\\). So \u201cthe coin is fair\u201d is assigned credence\n\\(0.5 - 0.5\\), which equals 0 and violates Regularity.\n\n\n\nBut there seems to be nothing incoherent in this agent\u2019s\ncredences.\n\nOne possible response is to insist on Regularity and hold that the\nagent in the Coin Case is actually incoherent in a subtle way. Namely,\nthat agent\u2019s credence in \u201cthe coin is fair\u201d should\nnot be zero but should be an infinitesimal\u2014smaller than\nany positive real number but still greater than zero (Lewis 1980). On\nthis view, the fault lies not with Regularity but with the standard\nversion of Probabilism, which needs to be relaxed to permit\ninfinitesimal credences. For worries about this appeal to\ninfinitesimals, see H\u00e1jek (2012) and Easwaran (2014). For a\nsurvey of infinitesimal credences/probabilities, see Wenmackers\n(2019).\n\nThe above response to the Coin Case implements a general strategy. The\nidea is that some doxastic states are so nuanced that even real\nnumbers are too coarse-grained to distinguish them, so real-valued\ncredences need to be supplemented with something else for a\nbetter representation of one\u2019s doxastic states. The above\nresponse proposes that the supplement be infinitesimal\ncredences. A second response proposes, instead, that the\nsupplement be comparative probability, with a very different\nresult: abandoning Regularity rather than saving it.\n\nThis second response can be developed as follows. While being assigned\na higher numerical credence implies being taken as more probable,\nbeing assigned the same numerical credence does not really imply being\ntaken as equally probable. That is, (real-valued) numerical credences\nactually do not have enough structure to represent everything there is\nin a qualitative ordering of comparative probability, as H\u00e1jek\n(2003) suggests. So, in the Coin Case, the contingent proposition\n\u201cthe coin is fair\u201d is assigned credence 0, the same\ncredence as a logical falsehood is assigned. But it does not mean that\nthose two propositions, one contingent and one self-contradictory,\nshould be taken as equally probable. Instead, the contingent\nproposition \u201cthe coin is fair\u201d should still be taken as\nmore probable than a logical falsehood. That is, the following norm\nstill holds:\n\n\nComparative Regularity. It ought to be that,\nwhenever one has a judgment of comparative probability between a\ncontingent proposition and a logical falsehood, the former is taken to\nbe more probable than the latter.\n\n\n\nSo, although the second response bites the bullet and abandons\nRegularity (due to the Coin Case), it manages to settle on a variant,\nComparative Regularity. But even Comparative Regularity can be\nchallenged: see T. Williamson (2007) for a putative counterexample.\nAnd see Haverkamp and Schulz (2012) for a reply in support of\nComparative Regularity.\n\nNote that the second response makes use of one\u2019s ordering of\ncomparative probability, which can be too nuanced to be fully captured\nby real-valued credences. As it turns out, such an ordering can still\nbe fully captured by real-valued conditional credences (as\nexplained in\n supplement B),\n provided that it makes sense for a person to have a credence in a\nproposition conditional on a zero-credence proposition. It is\nto this kind of conditional credence that I now turn.\n\n\n3.4 Norms of Conditional Credences\n\nIn Bayesian epistemology, a doxastic state is standardly represented\nby a credence assignment \\(\\Cr\\), with conditional credences\ncharacterized by\n\n\nThe Ratio Formula \n\\[ \\Cr(A\\mid B) = \\frac{\\Cr(A \\cap B)}{\\Cr(B)}\\quad \\text{ if } \\Cr(B) \\neq 0.\\]\n\n\n\nThe Ratio Formula might be taken to define conditional credences (on\nthe left) in terms of unconditional credences (on the right), or be\ntaken as a normative constraint on those two kinds of mental states\nwithout defining one by the other. See H\u00e1jek (2003) for some\nobjections to the definitional construal and for further\ndiscussion.\n\nWhether the Ratio Formula is construed as a definition or a norm, it\napplies only when the conditioning proposition \\(B\\) is assigned a\nnonzero credence: \\(\\Cr(B) \\neq 0\\). But perhaps this qualification is\ntoo restrictive:\n\n\nExample (Coin, Continued). Conditional on\n\u201cthe coin is fair\u201d, the agent has a 0.5 credence in\n\u201cthe coin will land heads the next time it is\ntossed\u201d\u2014and rightly so. But this agent assigns a\nzero credence in the conditioning proposition, \u201cthe\ncoin is fair\u201d, as in the previous Coin Case.\n\n\n\nThis 0.5 conditional credence seems to make perfect sense, but it\neludes the Ratio Formula. Worse, the above case is not rare: the above\nconditional credence is a credence in an event conditional on a\nstatistical hypothesis, and such conditional credences, often called\nlikelihoods, have been extensively employed in statistical\napplications of Bayesian epistemology (as will be explained in\n section 3.5).\n\nThere are three possible ways out. They differ in the importance they\nattribute to the Ratio Formula as a stand-alone norm. So you can\nexpect a reformatory approach which takes it to be unimportant, a\nconservative one which retains its importance, and a middle way\nbetween the two.\n\nOn the reformatory approach, the Ratio Formula is no longer\nimportant and, instead, is derived as a mere consequence of something\nmore fundamental. While the standard Bayesian view takes norms of\nunconditional credences to be fundamental and then uses the Ratio\nFormula as a bridge to conditional credences, the reformatory approach\nreverses the direction, taking norms of conditional credences as\nfundamental. Following Popper (1959) and R\u00e9nyi (1970), this\nidea can be implemented with a version of Probabilism designed\ndirectly for conditional credences:\n\n\n\n\nProbabilism (Conditional Version). It ought to be\nthat one\u2019s assignment of conditional credences \\(\\Cr( \\wcdot\n\\mid \\wcdot)\\) is a Popper-R\u00e9nyi function over an algebra\n\\({\\cal A}\\) of propositions, namely, a function satisfying the\nfollowing axioms:\n\n(Probability) For any logically consistent\nproposition \\(A \\in {\\cal A}\\) held fixed, \\(\\Cr( \\wcdot \\mid A)\\) is\na probability measure on \\({\\cal A}\\) with \\(\\Cr( A \\mid A) =\n1\\).\n\n\n(Multiplication) For any propositions \\(A\\),\n\\(B\\), and \\(C\\) in \\({\\cal A}\\) such that \\(B \\cap C\\) is logically\nconsistent, \n\\[\\Cr(A\\cap B \\mid C)  = \\Cr(A \\mid B \\cap C) \\cdot \\Cr(B \\mid C) .\\]\n \n \n\n\n\nThis approach is often called the approach of coherent conditional\nprobability, because it seeks to impose coherence constraints\ndirectly on conditional credences without a detour through\nunconditional credences. Once those constraints are in place, one may\nthen add a constraint\u2014normative or definitional\u2014on\nunconditional credences: \n\\[\\Cr(A) = \\Cr(A \\mid \\top),\\]\n\n\nwhere \\(\\top\\) is a logical truth. From the above we can derive the\nRatio Formula and the standard version of Probabilism. See\nH\u00e1jek (2003) for a defense of this approach. A Dutch Book\nargument for the conditional version of Probabilism is developed by\nStalnaker (1970).\n\nIn contrast to the reformatory nature of the above approach, the\nsecond one is conservative. On this approach, the Ratio\nFormula is sufficient by itself as a norm (or definition) for\nconditional credences. It makes sense to have a credence conditional\non \u201cthe coin is fair\u201d because one\u2019s credence in that\nconditioning proposition ought to be an infinitesimal rather than\nzero. This approach may be called the approach of\ninfinitesimals. It forms a natural package with the\ninfinitesimal approach to saving Regularity from the Coin Case, which\nwas discussed in\n section 3.3.\n\nBetween the conservative and the reformatory, there is the\nmiddle way, due to Kolmogorov (1933). The idea is to think\nabout the cases where the Ratio Formula applies, and then use them to\n\u201capproximate\u201d the cases where it does not apply. If this\ncan be done, then although the Ratio Formula is not all there is to\nnorms for conditional credences, it comes close. To be more precise,\nwhen we try to conditionalize on a zero-credence proposition \\(B\\), we\ncan approximate \\(B\\) by a sequence of propositions \\(B_1,\\)\n\\(B_2,\\)\u2026 such that:\n\nthose propositions \\(B_1, B_2, \\ldots\\) are progressively more\nspecific (i.e., \\(B_i \\supset B_{i+1}\\)),\nthey jointly say what \\(B\\) says (i.e., \\(\\bigcap_{i=1}^{\\infty}\nB_i = B\\)).\n\n\nIn that case, it seems tempting to accept the norm or definition that\nconditionalization on \\(B\\) be approximated by successive\nconditionalizations on \\(B_1, B_2, \\ldots\\), or in symbols:\n\n\\[\\Cr(A \\mid B) = \\lim_{i \\to \\infty}\\Cr(A \\mid B_i),\\]\n\n\nwhere each term \\(\\Cr(A \\mid B_i)\\) is governed by the Ratio Formula\nbecause \\(\\Cr(B_i)\\) is nonzero by design. An important consequence of\nthis approach is that, when one chooses a different sequence of\npropositions to approximate \\(B\\), the limit of conditionalizations\nmight be different, and, hence, a credence conditional on \\(B\\) is, or\nought to be, relativized to how one presents \\(B\\) as the limit of a\nsequence of approximating propositions. This relativization is often\nillustrated with what\u2019s called the Borel-Kolmogorov\nparadox; see Rescorla (2015) for an accessible presentation and\ndiscussion. Once the mathematical details are refined, this approach\nbecomes what\u2019s known as the theory of regular conditional\n probability.[5]\n A Dutch Book argument for this way of assigning conditional credences\nis developed by Rescorla (2018).\n\nFor a critical comparison of those three approaches to conditional\ncredences, see the survey by Easwaran (2019).\n\n\n3.5 Chance-Credence Principles\n\nRecall the Coin Case discussed above: one\u2019s credence in\n\u201cthe coin will land heads the next time it is tossed\u201d\nconditional on \u201cthe coin is fair\u201d is equal to 0.5. This\n0.5 conditional credence seems to be the only permissible alternative\nuntil the result of the next coin toss is observed. This example\nsuggests a general norm, which connects chances to conditional\ncredences:\n\n\n\n\nThe Principal Principle/Direct Inference\nPrinciple. Let \\(\\Cr\\) be one\u2019s prior, i.e., the credence\nassignment that one has at the beginning of an inquiry. Let \\(E\\) be\nthe event that such and such things will happen at a certain future\ntime. Let \\(A\\) be a proposition that entails \\(\\Ch(E) = c\\), which\nsays that the chance for \\(E\\) to come out true is equal to \\(c\\).\nThen one\u2019s prior \\(\\Cr\\) ought to be such that \\(\\Cr(E \\mid A) =\nc\\), if \\(A\\) is an \u201cordinary\u201d proposition in that it is\nlogically equivalent to the conjunction of \\(\\Ch(E) = c\\) with an\n\u201cadmissible\u201d proposition.\n\n\n\nThe if-clause refers to \u201cadmissible\u201d propositions, which\nare roughly propositions that give no more information about whether\nor not \\(E\\) is true than is already contained in \\(\\Ch(E) = c\\). To\nsee why we need the qualification imposed by the if-clause, suppose\nfor instance that the event \\(E\\) is \u201cthe coin will land heads\nthe next time it is tossed\u201d. If the conditioning proposition\n\\(A\\) is \u201cthe coin is fair\u201d, it is a paradigmatic example\nof an \u201cordinary\u201d proposition. This reproduces the Coin\nCase, with the conditional credence being the chance 0.5.\nAlternatively, if the conditioning proposition \\(A\\) is the\nconjunction of \u201cthe coin is fair\u201d and \\(E\\), then the\nconditional credence \\(\\Cr(E \\mid A)\\) should be 1 rather than the 0.5\nchance of \\(E\\) that \\(A\\) entails. After all, to be given this \\(A\\)\nis to be given a lot of information, which entails \\(E\\). So this case\nis supposed to be ruled out by an account of \u201cadmissible\u201d\npropositions. Lewis (1980) initiates a systematic quest for such an\naccount, which has invited counterexamples and responses. See Joyce\n(2011: sec. 4.2) for a survey.\n\nThe Principal Principle has been defended with an argument based on\nconsiderations about the accuracies of credences (Pettigrew 2012), and\nwith a nonstandard Dutch Book argument (Pettigrew 2020a: sec.\n2.8).\n\nThe Principal Principle is important perhaps mainly because of its\nextensive applications in Bayesian statistics, in which this principle\nis more often called the Direct Inference Principle. To illustrate,\nsuppose that you are somehow certain that one of the following two\nhypotheses is true: \\(H_1 =\\) \u201cthe coin has a bias 0.4\u201d\nand \\(H_2 =\\) \u201cthe coin has a bias 0.6\u201d, which are\nparadigmatic examples of \u201cordinary\u201d hypotheses. Then your\ncredence in the first hypothesis \\(H_1\\) given evidence \\(E\\) that the\ncoin lands heads ought to be expressible as\n follows:[6]\n \n\\[\\begin{align}\n        \\Cr(H_1 \\mid E)\n        &= \\frac{ \\Cr(E \\mid H_1) \\cdot \\Cr(H_1) }{ \\sum_{i =1}^2 \\Cr(E \\mid H_i) \\cdot \\Cr(H_i) } &{\\text{by Bayes' Theorem}\\\\ \\text{(as stated in \u00a72)}}\n        \\\\\n        &= \\frac{ 0.4 \\cdot \\Cr(H_1) }{ 0.4 \\cdot \\Cr(H_1) + 0.6 \\cdot \\Cr(H_2) } &{\\text{by the Principal}\\\\ \\text{Principle}}\n    \\end{align}\\]\n\n\nSo Bayes\u2019 Theorem works by expressing posterior credences in\nterms of some prior credences \\(\\Cr(H_i)\\) and some prior conditional\ncredences \\(\\Cr(E \\mid H_i)\\). The latter, called\nlikelihoods, are subjective opinions, but they can\nbe replaced by objective chances thanks to the Principal\nPrinciple. So this principle is often taken to be an important way to\nreduce some subjective factors in the Bayesian account of scientific\ninference. For discussions of other subjective factors, see\n section 4.1.\n\nEven though the Principal Principle has important, extensive\napplications in Bayesian statistics as just explained, de Finetti\n(1970 [1974]) argues that it is actually dispensable and thus need not\nbe accepted as a norm. To be more specific, he argues that the\nPrincipal Principle is dispensable in a way that changes little of the\nactual practice of Bayesian statistics. His argument relies on his\nexchangeability theorem. See Gillies (2000: 69\u201382) for\na non-technical introduction to this topic; also see Joyce (2011: sec.\n4.1) for a more advanced survey.\n\n3.6 Reflection and Other Deference Principles\n\nWe have just discussed the Principal Principle, which in a sense asks\none to defer to a kind of expert (Gaifman 1986): the chance of an\nevent \\(E\\) can be understood as an expert at predicting whether \\(E\\)\nwill come out true. So, conditional on that expert\u2019s saying so\nand so about \\(E\\), one\u2019s opinion ought to defer to that expert.\nConstrued that way, the Principal Principle is a kind of deference\nprinciple. There can be different deference principles, referring\nto different kinds of experts.\n\nHere is another example of a deference principle, proposed by van\nFraassen (1984):\n\n\n\n\nThe Reflection Principle. One\u2019s credence at\nany time \\(t_1\\) in a proposition \\(A\\), conditional on the\nproposition that one\u2019s future credence at \\(t_2\\) \\((> t_1)\\)\nin \\(A\\) will be equal to \\(x\\), ought to be equal to \\(x\\); or put\nsymbolically: \n\\[\\Cr_{t_1}( A \\mid \\Cr_{t_2}(A) = x )  = x.\\]\n\n\nMore generally, it ought to be that \n\\[\\Cr_{t_1}( A \\mid \\Cr_{t_2}(A) \\in [x, x'] )  \\in  [x, x'].\\]\n \n\n\n\nHere, one\u2019s future self is taken as an expert to which one ought\nto defer. The Reflection Principle admits of a Dutch Book argument\n(van Fraassen 1984). There is another way to defend the Reflection\nPrinciple: this synchronic norm is argued to follow from the\nsynchronic norm that one ought, at any time, to be fully\ncertain that one will follow the diachronic Principle of\nConditionalization (as suggested by Weisberg\u2019s 2007 modification\nof van Fraassen\u2019s 1995 argument).\n\nThe Reflection Principle has invited some putative counterexamples.\nHere is one, adapted from Talbott (1991):\n\n\nExample (Dinner). Today is March 15, 1989.\nSomeone is very confident that she is now having spaghetti for dinner.\nShe is also very confident that, on March 15, 1990 (exactly one year\nfrom today), she will have completely forgotten what she is having for\ndinner now.\n\n\n\nSo, this person\u2019s current assignment of credences\n\\(\\Cr_\\textrm{1989}\\) has the following properties, where \\(A\\) is the\nproposition that she has spaghetti for dinner on March 15, 1989:\n\n\\[\\begin{align}\n    \\Cr_\\textrm{1989} \\big( A \\big) &= \\text{high} \n    \\\\\n    \\Cr_\\textrm{1989} \\Big( \\Cr_\\textrm{1989+1}(A) \\mbox{ is low}  \\Big) &= \\text{high} .\n    \\end{align}\\]\n\n\nBut conditionalization on a proposition with a high credence can only\nslightly change the credence assignment. For such a conditionalization\ninvolves lowering just a small bit of credence down to zero and hence\nit only requires a slight rescaling, by a factor close to 1. So,\nassuming that \\(\\Cr\\) is a probability measure, we have:\n\n\\[\n    \\Cr_\\textrm{1989} \\Big( A \\Bigm\\vert \\Cr_\\textrm{1989+1}(A) \\mbox{ is low}  \\Big) = \\text{still high} ,\n\\]\n\n\nwhich violates the Reflection Principle.\n\nThe Dinner Case serves as a putative counterexample to the Reflection\nPrinciple by allowing one to suspect that one will lose some memories.\nSo it allows one to have a specific kind of epistemic\nself-doubt\u2014to doubt one\u2019s own ability to achieve or\nretain an epistemically favorable state. In fact, some are worried\nthat the Reflection Principle is generally incompatible with epistemic\nself-doubt, which seems rational and permissible. For more on this\nworry, see the entry on\n epistemic self-doubt.\n\n\n4. Synchronic Norms (II): The Problem of the Priors\n\nMuch of what Bayesians have to say about confirmation and inductive\ninference depends crucially on the norms that govern one\u2019s prior\ncredences (the credences that one has at the beginning of an inquiry).\nBut what are those norms? This is known as the problem of the\npriors. Some potential solutions were only sketched in the\ntutorial\n section 1.5.\n They will be detailed in this section.\n\n4.1 Subjective Bayesianism\n\nSubjective Bayesianism is the view that every prior is permitted\nunless it fails to be coherent (de Finetti 1970 [1974]; Savage 1972;\nJeffrey 1965; van Fraassen 1989: ch. 7). Holding that view as the\ncommon ground, subjective Bayesians often disagree over what coherence\nrequires (which was the topic of the preceding\n section 3).\n\nThe most common worry for subjective Bayesianism is that, on that\nview, anything goes. For example, under just Probabilism and\nRegularity, there is a prior that follows enumerative induction and\nthere also is a prior whose posterior never generalizes from data,\ndefying enumerative induction (see Carnap 1955 for details, but see\nFitelson 2006 for a concise presentation). Under just Probabilism and\nthe Principal Principle, there is a prior that follows Ockham\u2019s\nrazor in statistical model selection but there also is a prior that\ndoes not (Forster 1995: sec. 3; Sober 2002: sec.\n 6).[7]\n So, although subjective Bayesianism does not really say that anything\ngoes, it seems to permit too much, failing to account for some\nimportant aspects of scientific objectivity\u2014or so the worry\ngoes. Subjective Bayesians have replied with at least two\nstrategies.\n\nHere is one: argue that, despite appearances, coherence alone captures\neverything there is to scientific objectivity. For example, it might\nbe argued that it is actually correct to permit a wide range of\npriors, for people come with different background opinions and it\nseems wrong\u2014objectively wrong\u2014to require all of them to\nchange to the same opinion at once. What ought to be the case is,\nrather, that people\u2019s opinions be brought closer and closer to\neach other as their shared evidence accumulates. This idea of\nmerging-of-opinions as a kind of scientific objectivity can\nbe traced back to Peirce (1877), although he develops this idea for\nthe epistemology of all-or-nothing beliefs rather than credences. Some\nsubjective Bayesians propose to develop this Peircean idea in the\nframework of subjective Bayesianism: to have the ideal of\nmerging-of-opinions be derived as a norm\u2014derived solely from\ncoherence norms. That is, they prove so-called merging-of-opinions\ntheorems (Blackwell & Dubins 1962; Gaifman & Snir 1982).\nSuch a theorem states that, under such and such contingent initial\nconditions together with such and such coherence norms, two agents\nmust be certain that their credences in the hypotheses under\nconsideration will merge with each other in the long run as\nthe shared evidence accumulates indefinitely.\n\nThe above theorem is stated with two italicized parts, which are the\ntargets of some worries. The merging of the two agents\u2019 opinions\nmight not happen and is only believed with certainty to happen in the\nlong run. And the long run might be too long. There is another worry:\nthe proof of such a theorem requires Countable Additivity as a norm of\ncredences, which is controversial, as was discussed in\n section 3.2.\n See Earman (1992: ch. 6) for more on those\n worries.[8]\n For a recent development of merging-of-opinions theorems and a\ndefense of their use, see Huttegger (2015).\n\nWhether or not merging-of-opinions theorems can capture the intended\nkind of scientific objectivity, it is still debated whether there are\nother kinds of scientific objectivity that elude subjective\nBayesianism. For more on this issue, see\n section 4.2 of the entry on scientific objectivity,\n Gelman & Hennig (2017) (including peer discussions), Sprenger\n(2018), and Sprenger & Hartmann (2019: ch. 11).\n\nHere is a second strategy in defense of scientific objectivity for\nsubjective Bayesians: distance themselves from any substantive theory\nof inductive inference and hold instead that Bayesian epistemology can\nbe construed as a kind of deductive logic. This view draws on some\nparallel features between deductive logic and Bayesian epistemology.\nFirst, the coherence of credences can be construed as an analogue of\nthe logical consistency of propositions or all-or-nothing beliefs\n(Jeffrey 1983). Second, just as premises are inputs into a deductive\nreasoning process, prior credences are inputs into the process of an\ninquiry. And, just as the job of deductive logic is not to say what\npremises we should have except that they be logically consistent,\nBayesian epistemology need not say what prior credences we should have\nexcept that they be coherent (Howson 2000: 135\u2013145). Call this\nview the deductive construal of Bayesian epistemology, for\nlack of a standard name.\n\nYet it might be questioned whether the above parallelism really works\nin favor of subjective Bayesianism. Just as substantive theories of\ninductive inferences have been developed with deductive logic as their\nbasis, to take the parallelism seriously it seems that there should\nalso be a substantive account of inductive inferences with the\ndeductive construal of Bayesian epistemology as their basis. Indeed,\nthe anti-subjectivists to be discussed below\u2014objective Bayesians\nand forward-looking Bayesians\u2014all think that a substantive\naccount of inductive inferences is furnished by norms that go beyond\nthe consideration of coherence. It is to such a view that I turn now.\nBut for more on subjective Bayesianism, see the survey by Joyce\n(2011).\n\n4.2 Objective Bayesianism\n\nObjective Bayesians contend that, in addition to coherence,\nthere is another epistemic virtue or ideal that needs to be codified\ninto a norm for prior credences: freedom from bias and avoidance of\noverly strong opinions (Jeffreys 1939; Carnap 1945; Jaynes 1957, 1968;\nRosenkrantz 1981; J. Williamson 2010). This view is often motivated by\na case like this:\n\n\nExample (Six-Faced Die). Suppose that there is\na cubic die with six faces that look symmetric, and we are going to\ntoss it. Suppose further that we have no other idea about this die.\nNow, what should our credence be that the die will come up 6?\n\n\n\nAn intuitive answer is \\(1/6\\), for it seems that we ought to\ndistribute our credences evenly, with an equal credence, \\(1/6\\), in\neach of the six possible outcomes. While subjective Bayesians would\nonly say that we may do so, objective Bayesians would make\nthe stronger claim that we ought to do so. More generally,\nobjective Bayesians are sympathetic to this norm:\n\n\nThe Principle of Indifference. A\nperson\u2019s credences in any two propositions should be equal if\nher total evidence no more supports one than the other (the\nevidential symmetry version), or if she has no sufficient\nreason to have a higher credence in one than in the other (the\ninsufficient reason version).\n\n\n\nA standard worry about the Indifference Principle comes from\nBertrand\u2019s paradox. Here is a simplified version\n(adapted from van Fraassen 1989):\n\n\nExample (Square). Suppose that there is a\nsquare and that we know for sure that its side length is between 1 and\n4 centimeters. Suppose further that we have no other idea about that\nsquare. Now, how confident should we be that the square has a side\nlength between 1 and 2 centimeters?\n\n\n\nNow, have a look at the two groups of propositions listed in the table\nbelow. The left group (1)\u2013(3) focuses on possible side lengths\nand divides up possibilities by 1-cm-long intervals; the right group\n\\((1')\\)\u2013\\((15')\\) focuses on possible areas instead:\n\n\n\n\nPartition By\nLength\nPartition By\nArea  \n\n\n(1) The side length is 1 to 2 cm.\n\\((1')\\) The area is 1 to 2\ncm2. \n\n(2) The side length is 2 to 3 cm.\n\\((2')\\) The area is 2 to 3\ncm2. \n\n(3) The side length is 3 to 4 cm.\n\\((3')\\) The area is 3 to 4\ncm2. \n\n\n\\(\\;\\;\\vdots\\) \n\n\n\\((15')\\) The area is 15 to 16\ncm2  \n\n\n\nThe Indifference Principle seems ask us to assign a \\(1/3\\) credence\nto each proposition in the left group \\((1)\\)\u2013\\((3)\\) and,\nsimultaneously, assign \\(1/15\\) to each one in the right group\n\\((1')\\)\u2013\\((15')\\). If so, it asks us to assign unequal\ncredences to equivalent propositions: \\(1/3\\) to \\((1)\\), and \\(3/15\\)\nto the disjunction \\((1') \\!\\vee (2') \\!\\vee (3')\\). That violates\nProbabilism.\n\nIn reply, objective Bayesians may reply that Bertrand\u2019s paradox\nprovides no conclusive reason against the Indifference Principle and\nperhaps the fault lies elsewhere. Following White (2010), let\u2019s\nthink about how the Indifference Principle works: it outputs a\nnormative recommendation for credence assignment only when it receives\none or another input, which is a judgement about insufficient\nreason or evidential symmetry. Indeed, Bertrand\u2019s paradox has to\nbe generated by at least two inputs, such as, first, the\nlack-of-evidence judgement about the left group in the above table\nand, second, that about the right group. So perhaps the fault lies not\nwith the Indifference Principle but with one of the two\ninputs\u2014after all, garbage in, garbage out. White (2010)\nsubstantiates the above idea with an argument to this effect: at least\none of the two inputs in Bertrand\u2019s paradox must be mistaken,\nbecause they already contradict each other even when we only assume\ncertain weak, plausible principles that have nothing to do with\ncredences and concern just the evidential support relation.\n\nThere still remains the task of developing a systematic account to\nguide one\u2019s judgments of evidential symmetry (or insufficient\nreason) before those judgments are passed as inputs to the\nIndifference Principle. An important source of inspiration has been\nthe symmetry in the Six-Faced Die Case: it is a kind of\nphysical symmetry due to the cubic shape of the die; it is\nalso a kind of permutation symmetry because nothing essential\nchanges when the six faces of the die are relabeled. Those two aspects\nof the symmetry\u2014physical and permutational\u2014are extended by\ntwo influential approaches to the Indifference Principle,\nrespectively, which are presented in turn below.\n\nThe first approach to the Indifference Principle looks for a wider\nrange of physical symmetries, including especially the\nsymmetries associated with a change of coordinate or unit. This\napproach, developed by Jeffreys (1946) and Jaynes (1968, 1973), yields\na consistent, somewhat surprising answer 1/2 (rather than 1/3 or 1/15)\nto the question in the Square Case. See\n supplement C\n for some non-technical details.\n\nThe second approach to the Indifference Principle focuses on\npermutation symmetries and proposes to look for those not in\na physical system but in the language in use. This approach\nis due to Carnap (1945, 1955). He maintains, for example, that two\nsentences ought to be assigned equal prior credences if one differs\nfrom the other only by a permutation of the names in use. Although\nCarnap says little about the Square Case, he has much to say about how\nhis approach to the Indifference Principle helps to justify\nenumerative induction; see the survey by Fitelson (2006). So objective\nBayesianism is often regarded as a substantive account of inductive\ninference, while many subjective Bayesians often take their view as a\nquantitative analogue of deductive logic (as presented in\n section 4.1).\n For refinement of Carnap\u2019s approach, see Maher (2004). The most\ncommon worry for Carnap\u2019s approach is that it renders the\nnormative import of the Indifference Principle too sensitive to the\nchoice of a language; for a reply, see J. Williamson (2010: chap. 9).\nFor more criticisms, see Kelly & Glymour (2004).\n\nThe Indifference Principle has been challenged for another reason.\nThis principle is often understood to dictate equal\nreal-valued credences in cases of ignorance, but there is the\nworry that sometimes we are too ignorant to be justified in having\nsharp, real-valued credences, as suggested by this case (Keynes 1921:\nch. 4):\n\n\n\n\nExample (Two Urns). Suppose that there are two\nurns, a and b. Urn a contains 10 balls. Exactly\nhalf of those are white; the other half, black. Urn b contains\n10 balls, each of which is either black or white, but we have no idea\nabout the white-to-black ratio. Those two urns are each shaken well. A\nball is to be drawn from each. What should our credences be in the\nfollowing propositions?\n\n (A) The ball from urn a is white.\n (B) The ball from urn b is white.\n \n\n\n\nBy the Principle of Indifference, the answers seems to be 0.5 and 0.5,\nrespectively. If so, there should be equal credences (namely 0.5) in\nA and in B. But this result sounds wrong to Keynes. He\nthinks that, compared with urn a, we have much less background\ninformation about urn b, and that this severe lack of\nbackground information should be reflected in the difference between\nthe doxastic attitudes toward propositions A and\nB\u2014a difference that the Principle of Indifference fails\nto make. If so, what is the difference? It is relatively\nuncontroversial that the credence in A should be 0.5, being the\nratio of the white balls in urn a (perhaps thanks to the\nPrincipal Principle). On the other hand, some Bayesians (Keynes 1921;\nJoyce 2005) argue that the credence in B does not have to be an\nindividual real number but, instead, is at least permitted to be\nunsharp, being the interval \\([0, 1]\\), which covers all the possible\nwhite-to-black ratios under consideration. This is only one motivation\nfor an interval account of unsharp credences; for another\nmotivation, see\n supplement A.\n\nIn reply to the Two Urns Case, objective Bayesians have defended one\nor another version of the Indifference Principle. White (2010) does it\nwhile maintaining that credences ought to be sharp. Weatherson (2007:\nsec. 4) defends a version that allows credences to be unsharp. Eva\n(2019) defends a version that governs comparative probabilities rather\nthan numerical credences. For more on this debate, see the survey by\nMahtani (2019) and the entry on\n imprecise probabilities.\n\nThe Principle of Indifference appears unhelpful when one has had\nsubstantive reason or evidence against some assignments of credences\n(making the principle inapplicable with a false if-clause). The\nstandard remedy appeals to a generalization of the Indifference\nPrinciple, called the Principle of Maximum Entropy (Jaynes\n1968); for more on this, see\n supplement D.\n\nThe above has only mentioned the versions of objective Bayesianism\nthat are more well-known in philosophy. There are other versions,\ndeveloped and discussed mostly by statisticians. For a survey, see\nKass & Wasserman (1996) and Berger (2006).\n4.3 Forward-Looking Bayesianism\n\nSome Bayesians propose that some norms for priors can be obtained by\nlooking into possible futures, with two steps (Good 1976):\n\n\nStep I (Think Ahead). Develop a normative\nconstraint C on the posteriors in some possible futures in\nwhich new evidence is acquired.\nStep II (Solve Backwards). Require one\u2019s\npriors to be such that, after conditionalization on new evidence, its\nposterior must satisfy C.\n\n\n\nFor lack of a standard name, this approach may be called\nforward-looking Bayesianism. This name is used here as an\numbrella term to cover different possible implementations, of which\ntwo are presented below.\n\nHere is one implementation. It might be held that one ought to favor a\nhypothesis if it explains the available evidence better than any other\ncompeting hypotheses do. This view is called inference to the best\nexplanation (IBE) if construed as a method for theory choice, as\noriginally developed in the epistemology of all-or-nothing beliefs\n(Harman 1986). It can be carried over to Bayesian epistemology as\nfollows:\n\n\nExplanationist Bayesianism (Preliminary\nVersion). One\u2019s prior ought to be such that, given each\nbody of evidence under consideration, a hypothesis that explains the\nevidence better has a higher posterior.\n\n\n\nWhat\u2019s stated here is only a preliminary version. More\nsophisticated versions are developed by Lipton (2004: ch. 7) and\nWeisberg (2009a). This view is resisted by some Bayesians to varying\ndegrees. van Fraassen (1989: ch. 7) argues that IBE should be rejected\nbecause it is in tension with the two core Bayesian norms. Okasha\n(2000) argues that IBE only serves as a good heuristic for guiding\none\u2019s credence change. Henderson (2014) argues that IBE need not\nbe assumed to guide one\u2019s credence change because it can be\njustified by little more than the two core Bayesian norms. For more on\nIBE, see the entry on\n abduction,\n in which sections 3.1 and 4 discuss explanationist Bayesianism.\n\nHere is another implementation of forward-looking Bayesianism. It\nmight be thought that, although a scientific method for theory choice\nis subject to error due to its inductive nature, it is supposed to be\nable, in a sense, to correct itself. This view is called the\nself-corrective thesis, originally developed in the epistemology\nof all-or-nothing beliefs by Peirce (1903) and Reichenbach (1938: sec.\n38\u201340). But it can be carried over to Bayesian epistemology as\nfollows:\n\n\nSelf-Correctionist Bayesianism (Preliminary\nVersion). One\u2019s prior ought, if possible, to have at least\nthe following self-corrective property in every possible state of the\nworld under consideration: one\u2019s posterior credence in the true\nhypothesis under consideration would eventually become high and stay\nso if the evidence were to accumulate indefinitely.\n\n\n\nAn early version of this view is developed by Freedman (1963) in\nstatistics; see Wasserman (1998: sec. 1\u20133) for a minimally\ntechnical overview. The self-corrective property concerns the long\nrun, so it invites the standard, Keynesian worry that the long run\nmight be too long. For replies, see Diaconis & Freedman (1986b:\npp. 63\u201364) and Kelly (2000: sec. 7). A related worry is that a\nlong-run norm puts no constraint on what matters, namely, our doxastic\nstates in the short run (Carnap 1945). A possible reply is that the\nself-corrective property is only a minimum qualification of\npermissible priors and can be conjoined with other norms for credences\nto generate a significant constraint on priors. To substantiate that\nreply, it has been argued that such a constraint on priors is actually\nstronger than what the rival Bayesians have to offer in some important\ncases of statistical inference (Diaconis & Freedman 1986a) and\nenumerative induction (Lin forthcoming).\n\nThe above two versions of forward-looking Bayesianism both encourage\nBayesians to do this: assimilate some ideas (such as IBE or\nself-correction) that have long been taken seriously in some\nnon-Bayesian traditions of epistemology. Forward-looking Bayesianism\nseems to be a convenient template for doing that.\n4.4 Connection to the Uniqueness Debate\n\nThe above approaches to the problem of the priors are mostly developed\nwith this question in mind:\n\n\nThe Question of Norms. What are the correct\nnorms that we can articulate to govern prior credences?\n\n\n\nThe interest in this question leads naturally to a different but\nclosely related question. Imagine that you are unsympathetic to\nsubjective Bayesianism. Then you might try to add one norm after\nanother to narrow down the candidate pool for the permissible priors,\nand you might be wondering what this process might end up with. This\nraises a more abstract question:\n\n\nThe Question of Uniqueness. Given each\npossible body of evidence, is there exactly one permissible credence\nassignment or doxastic state (whether or not we can articulate norms\nto single out that state)?\n\n\n\nImpermissive Bayesianism is the view that says\n\u201cyes\u201d; permissive Bayesianism says\n\u201cno\u201d. The question of uniqueness is often addressed in a\nway that is somewhat orthogonal to the question of norms, as is\nsuggested by the \u2018whether-or-not\u2019 clause in the\nparentheses. Moreover, the uniqueness question is often debated in a\nbroader context that considers not just credences but all possible\ndoxastic states, thus going beyond Bayesian epistemology. Readers\ninterested in the uniqueness question are referred to the survey by\nKopec and Titelbaum (2016).\n\nLet me close this section with some clarifications. The two terms\n\u2018objective Bayesianism\u2019 and \u2018impermissive\nBayesianism\u2019 are sometimes used interchangeably. But those two\nterms are used in the present entry to distinguish two different\nviews, and neither implies the other. For example, many prominent\nobjective Bayesians such as Carnap (1955), Jaynes (1968), and J.\nWilliamson (2010) are not committed to impermissivism, even though\nsome objective Bayesians tend to be sympathetic to impermissivism. For\nelaboration on the point just made, see\n supplement E.\n\n\n5. Issues about Diachronic Norms\n\nThe Principle of Conditionalization has been challenged with several\nputative counterexamples. This section will examine some of the most\ninfluential ones. We will see that, to save that principle, some\nBayesians have tried to refine it into one or another version. A\nnumber of versions have been systematically compared in papers such as\nthose of Meacham (2015, 2016), Pettigrew (2020b), and Rescorla (2021),\nwhile the emphasis below will be centered on the proposed\ncounterexamples.\n\n5.1 Old Evidence\n\nLet\u2019s start with the problem of old evidence, which was\npresented above (in the tutorial\n section 1.8)\n but is reproduced below for ease of reference:\n\n\nExample (Mercury). It is 1915. Einstein has\njust developed a new theory, General Relativity. He assesses the new\ntheory with respect to some old data that have been known for at least\nfifty years: the anomalous rate of the advance of Mercury\u2019s\nperihelion (which is the point on Mercury\u2019s orbit that is\nclosest to the Sun). After some derivations and calculations, Einstein\nsoon recognizes that his new theory entails the old data about the\nadvance of Mercury\u2019s perihelion, while the Newtonian theory does\nnot. Now, Einstein increases his credence in his new theory, and\nrightly so.\n\n\n\nThere appears to be no change in the body of Einstein\u2019s evidence\nwhen he is simply doing some derivations and calculations. But the\nlimiting case of no new evidence seems to be just the case in\nwhich the new evidence E is trivial, being a logical truth,\nruling out no possibilities. Now, conditionalization on new evidence\nE as a logical truth changes no credence; but Einstein changes\nhis credences nonetheless\u2014and rightly so. This is called the\nproblem of old evidence, formulated as a counterexample to the\nPrinciple of Conditionalization.\n\nTo save the Principle of Conditionalization, a standard reply is to\nnote that Einstein seems to discover something new, a logical\nfact:\n\n\n\\((E_\\textrm{logical})\\) The new theory, together with such and\nsuch auxiliary hypotheses, logically implies such and such old\nevidence.\n\n\n\nThe hope is that, once this proposition has a less-than-certain\ncredence, Einstein\u2019s credence change can then be explained and\njustified as a result of conditionalization on this proposition\n(Garber 1983, Jeffrey 1983, and Niiniluoto 1983). There are four\nworries about this approach.\n\nAn initial worry is that the discovery of the logical fact\n\\(E_\\textrm{logical}\\) does not sound like adding anything to the body\nof Einstein\u2019s evidence but seems only to make clear the\nevidential relation between the new theory and the existing,\nunaugmented body of evidence. If so, there is no new evidence after\nall. This worry might be addressed by providing a modified version of\nthe Conditionalization Principle, according to which the thing to be\nconditionalized on is not exactly what one acquires as new evidence\nbut, rather, what one learns. Indeed, it seems to sound\nnatural to say that Einstein learns something nontrivial from his\nderivations. For more on the difference between learning and acquiring\nevidence, see Maher (1992: secs 2.1 and 2.3). So this approach to the\nproblem of old evidence is often called logical learning.\n\nA second worry for the logical learning approach points to an internal\ntension: On the one hand, this approach has to work by permitting a\nless-than-certain credence in a logical fact such as\n\\(E_\\textrm{logical}\\), and that amounts to permitting one to make a\ncertain kind of logical error. On the other hand, this approach has\nbeen developed on the assumption of Probabilism, which seems to\nrequire that one be logically omniscient and make no logical error (as\nmentioned in the tutorial\n section 1.9).\n van Fraassen (1988) argues that these two aspects of the logical\nlearning approach contradict each other under some weak\nassumptions.\n\nA third worry is that the logical learning approach depends for its\nsuccess on certain questionable assumptions about prior credences. For\ncriticisms of those assumptions as well as possible improvements, see\nSprenger (2015), Hartmann & Fitelson (2015), and Eva &\nHartmann (2020).\n\nThere is a fourth worry, which deserves a subsection of its own.\n\n5.2 New Theory\n\nThe logical learning approach to the problem of old evidence invites\nanother worry. It seems to fail to address a variant of the Mercury\nCase, due to Earman (1992: sec. 5.5):\n\n\nExample (Physics Student). A physics student\njust started studying Einstein\u2019s theory of general relativity.\nLike most physics students, the first thing she learns about the\ntheory, even before hearing any details of the theory itself, is the\nlogical fact \\(E_\\textrm{logical}\\) as formulated above. After\nlearning that, this student forms an initial credence 1 in\n\\(E_\\textrm{logical}\\), and an initial credence in the new,\nEinsteinian theory. She also lowers her credence in the old, Newtonian\ntheory.\n\n\n\nThe student\u2019s formation of a new, initial credence in\nthe new theory seems to pose a relatively little threat to the\nPrinciple of Conditionalization, which is most naturally construed as\na norm that governs, not credence formation, but credence change. So\nthe more serious problem lies in the student\u2019s change\nof her credence in the old theory. If this credence drop really\nresults from conditionalization on what was just learned,\n\\(E_\\textrm{logical}\\), then the credence in \\(E_\\textrm{logical}\\)\nmust be boosted to 1 from somewhere below 1, which unfortunately never\nhappens. So it seems that the student\u2019s credence drop violates\nthe Principle of Conditionalization and rightly so, which is known as\nthe problem of new theory. The following presents two reply\nstrategies for Bayesians.\n\nOne reply strategy is to qualify the Conditionalization Principle and\nmake it weaker in order to avoid counterexamples. The following is one\nway to implement this strategy (see\n supplement F\n for another one):\n\n\nThe Principle of Conditionalization (Plan/Rule\nVersion). It ought to be that, if one has a plan (or follows a\nrule) for changing credences in the case of learning E, then\nthe plan (or rule) is to conditionalize on E.\n\n\n\nNote how this version is immune from the Physics Student Case: what is\nlearned, \\(E_\\textrm{logical}\\), is something entirely new to the\nstudent, so the student simply did not have in mind a plan for\nresponding to \\(E_\\textrm{logical}\\)\u2014so the if-clause is not\nsatisfied. The Bayesians who adopt this version, such as van Fraassen\n(1989: ch. 7), often add that one is not required to have a\nplan for responding to any particular piece of new evidence.\n\nThe plan version is independently motivated. Note that this version\nputs a normative constraint on the plan that one has at\neach time when one has a plan, whereas the standard version\nconstrains the act of credence change across different\ntimes. So the plan version is different from the standard, act\nversion. But it turns out to be the former, rather then the latter,\nthat is supported by the major existing arguments for the Principle of\nConditionalization. See, for example, the Dutch Book argument by Lewis\n(1999), the expected accuracy argument by Greaves & Wallace\n(2006), and the accuracy dominance argument by Briggs & Pettigrew\n(2020).\n\nWhile the plan version of the Conditionalization Principle is weak\nenough to avoid the Physics Student counterexample, it might be\nworried that it is too weak. There are actually two worries here. The\nfirst worry is that the plan version is too weak because it leaves\nopen an important question: Even if one\u2019s plan for credence\nchange is always a plan to conditionalize on new evidence, should one\nactually follow such a plan whenever new evidence is acquired? For\ndiscussions of this issue, see Levi (1980: ch. 4), van Fraassen (1989:\nch. 7), and Titelbaum (2013a: parts III and IV). (Terminological note:\ninstead of \u2018plan\u2019, Levi uses \u2018confirmational\ncommitment\u2019 and van Fraassen uses \u2018rule\u2019.) The\nsecond worry is that the plan version is too weak because it only\navoids the problem of new theory, without giving a positive account as\nto why the student\u2019s credence in the old theory ought to\ndrop.\n\nA positive account is promised by the next strategy for solving the\nproblem of new theory. It operates with a series of ideas. The first\nidea is that, typically, a person only considers possibilities that\nare not jointly exhaustive, and she only has credences\nconditional on the set C of the considered\npossibilities\u2014lacking an unconditional credence in C\n(Shimony 1970; Salmon 1990). This deviates from the standard Bayesian\nview in allowing two things: credence gaps\n (section 3.1),\n and primitive conditional credences\n (section 3.4).\n The second idea is that the set C of the considered\npossibilities might shrink or expand in time. It might shrink because\nsome of those possibilities are ruled out by new evidence, or it might\nexpand because a new possibility\u2014a new theory\u2014is taken\ninto consideration. The third and last idea is a diachronic norm\n(sketched by Shimony 1970 and Salmon 1990, developed in detail by\nWenmackers & Romeijn 2016):\n\n\nThe Principle of Generalized Conditionalization\n(Considered Possibilities Version). It ought to be that, if two\npossibilities are under consideration at an earlier time and remain so\nat a later time, then their credence ratio be preserved across those\ntwo times.\n\n\n\nHere, a credence ratio has to be understood in such a way that it can\nexist without any unconditional credence. To see how this is possible,\nsuppose for simplicity that an agent starts with two old theories as\nthe only possibilities under consideration, \\(\\mathsf{old}_1\\) and\n\\(\\mathsf{old}_2\\), with a credence ratio \\(1:2\\) but without any\nunconditional credence. This can be understood to mean that, while the\nagent lacks an unconditional credence in the set \\(\\{\\mathsf{old}_1 ,\n\\mathsf{old}_2\\}\\), she still has a conditional credence\n\\(\\frac{1}{1+2}\\) in \\(\\mathsf{old}_1\\) given that set. Now, suppose\nthat this agent then thinks of a new theory: \\(\\mathsf{new}\\). Then,\nby the diachronic norm stated above, the credence ratio among\n\\(\\mathsf{old}_1\\), \\(\\mathsf{old}_2\\), \\(\\mathsf{new}\\) should now be\n\\(1:2:x\\). Notice the change of this agent\u2019s conditional\ncredence in \\(\\mathsf{old}_1\\) given the varying set of the\nconsidered possibilities: it drops from \\(\\frac{1}{1+2}\\) down to\n\\(\\frac{1}{1+2+x}\\), provided that \\(x>0\\). Wenmackers &\nRomeijn (2016) argues that this is why there appears to be a drop in\nthe student\u2019s credence in the old theory\u2014it is actually a\ndrop in a conditional credence given the varying set of the considered\npossibilities.\n\nThe above account invites a worry from the perspective of rational\nchoice theory. According to the standard construal of Bayesian\ndecision theory, the kind of doxastic state that ought to enter\ndecision-making is unconditional credence rather than\nconditional credence. So Earman (1992: sec. 7.3) is led to think that\nwhat we really need is an epistemology for unconditional\ncredence, which the above account fails to provide. A possible reply\nis anticipated by some Bayesian decision theorists, such as Savage\n(1972: sec. 5.5) and Harsanyi (1985). They argue that, when making a\ndecision, we often only have conditional credences\u2014conditional\non a simplifying assumption that makes the decision problem in\nquestion manageable. For other Bayesian decision theorists who follow\nSavage and Harsanyi, see the references in Joyce (1999: sec. 2.6, 4.2,\n5.5 and 7.1). For more on rational choice theory, see the entry on\n decision theory\n and the entry on\n normative theories of rational choice: expected utility.\n\n5.3 Uncertain Learning\n\nWhen we change our credences, the Principle of Conditionalization\nrequires us to raise the credence in some proposition, such as the\ncredence in the new evidence, all the way to 1. But it seems that we\noften have credence changes that do not accompany such as a radical\nrise to certainty, as witnessed by the following case:\n\n\nExample (Mudrunner). A gambler is very\nconfident that a certain racehorse, called Mudrunner, performs\nexceptionally well on muddy courses. A look at the extremely cloudy\nsky has an immediate effect on this gambler\u2019s opinion: an\nincrease in her credence in the proposition \\((\\textsf{muddy})\\) that\nthe course will be muddy\u2014an increase without reaching\ncertainty. Then this gambler raises her credence in the hypothesis\n\\((\\textsf{win})\\) that Mudrunner will win the race, but nothing\nbecomes fully certain. (Jeffrey 1965 [1983: sec. 11.3])\n\n\n\nConditionalization is too inflexible to accommodate this case.\n\nJeffrey proposes a now-standard solution that replaces\nconditionalization by a more flexible process for credence change,\ncalled Jeffrey conditionalization. Recall that\nconditionalization has a defining feature: it preserves the credence\nratios of the possibilities inside new evidence E while the\ncredence in E is raised all the way to 1. Jeffrey\nconditionalization does something similar: it preserves the same\ncredence ratios without having to raise any credence to 1,\nand also preserves some other credence ratios, i.e., the\ncredence ratios of the possibilities outside E. A simple\nversion of Jeffrey\u2019s norm can be stated informally as follows\n(in the style of the tutorial\n section 1.2):\n\n\n\n\nThe Principle of Jeffrey Conditionalization (Simplified\nVersion). It ought to be that, if the direct experiential impact\non one\u2019s credences causes the credence in E to rise to a\nreal number e (which might be less than 1), then one\u2019s\ncredences are changed as follows:\n\nFor the possibilities inside E, rescale their credences\nupward by a common factor so that they sum to e; for the\npossibilities outside E, rescale their credences downward by a\ncommon factor so that they sum to \\(1-e\\) (to obey the rule of\nSum-to-One).\nReset the credence in each proposition H by adding up the\nnew credences in the possibilities inside H (to obey the rule\nof Additivity).\n \n\n\n\nThis reduces to standard conditionalization in the special case that\n\\(e = 1\\). The above formulation is quite simplified; see\n supplement G\n for a general statement. This principle has been defended with a\nDutch Book argument; see Armendt (1980) and Skyrms (1984) for\ndiscussions.\n\nJeffrey conditionalization is flexible enough to accommodate the\nMudrunner Case. Suppose that the immediate effect of the\ngambler\u2019s sky-looking experience is to raise the credence in\n\\(E\\), i.e. \\(\\Cr(\\mathsf{muddy})\\). One feature of Jeffrey\nconditionalization is that, since certain credence ratios are required\nto be held constant, one has to hold constant the conditional\ncredences given \\(E\\) and also those given \\(\\neg E\\), such as\n\\(\\Cr(\\mathsf{win} \\mid \\mathsf{muddy})\\) and \\(\\Cr(\\mathsf{win} \\mid\n\\neg\\mathsf{muddy})\\). The credences mentioned above can be used to\nexpress \\(\\Cr(\\mathsf{win})\\) as follows (thanks to Probabilism and\nthe Ratio Formula): \n\\[\\begin{multline}\n        \\Cr(\\mathsf{win}) = \\underbrace{\\Cr(\\mathsf{win} \\mid \\mathsf{muddy})}_\\textrm{high, held constant} \\wcdot \\underbrace{\\Cr(\\mathsf{muddy})}_\\textrm{raised} \n    \\\\\n      {}  + \n        \\underbrace{\\Cr(\\mathsf{win} \\mid \\neg\\mathsf{muddy})}_\\textrm{low, held constant} \\wcdot \\underbrace{\\Cr(\\neg\\mathsf{muddy})}_\\textrm{lowered}.\n    \\end{multline}\\]\n\n\nIt seems natural to suppose that the first conditional credence is\nhigh and the second is low, by the description of the Mudrunner Case.\nThe annotations in the above equation imply that \\(\\Cr(\\mathsf{win})\\)\nmust go up. This is how Jeffrey conditionalization accommodates the\nMudrunner Case.\n\nAlthough Jeffrey conditionalization is more flexible than\nconditionalization, there is the worry that it is still too inflexible\ndue to something it inherits from conditionalization: the preservation\nof certain credence ratios or conditional credences (Bacchus, Kyburg,\n& Thalos 1990; Weisberg 2009b). Here is an example due to Weisberg\n(2009b: sec. 5):\n\n\n\n\nExample (Red Jelly Bean). An agent with a prior\n\\(\\Cr_\\textrm{old}\\) has a look at a jelly bean. The reddish\nappearance of that jelly bean has only one immediate effect on this\nagent\u2019s credences: an increased credence in the proposition\nthat\n\n\\((\\textsf{red})\\)\n there is a red jelly bean.\n\n\nThen this agent comes to have a posterior \\(\\Cr_\\textrm{new}\\). If\nthis agent later learns that\n\n\\((\\textsf{tricky})\\)\n the lighting is tricky,\n\n\nher credence in the redness of the jelly bean will drop. So,\n\n(\\(a\\))\n \\(\\Cr_\\textrm{new}( \\textsf{red} \\mid \\textsf{tricky} ) <\n\\Cr_\\textrm{new}( \\textsf{red} )\\).\n\n\nBut if, instead, the tricky lighting had been learned before\nthe look at the jelly bean, it would not have changed the credence in\nthe jelly bean\u2019s redness; that is:\n\n(\\(b\\))\n\\(\\Cr_\\textrm{old}( \\textsf{red} \\mid \\textsf{tricky} ) =\n\\Cr_\\textrm{old}( \\textsf{red} ).\\)\n \n\n\n\nYet it can be proved (with elementary probability theory) that\n\\(\\Cr_\\textrm{new}\\) cannot be obtained from \\(\\Cr_\\textrm{old}\\) by a\nJeffrey conditionalization on \\(\\textsf{red}\\) (assuming the two\nconditions \\((a)\\) and \\((b)\\) in the above case, the Ratio Formula,\nand that \\(\\Cr_\\textrm{old}\\) is probabilistic). See\n supplement H\n for a sketch of proof.\n\nThe above example is used by Weisberg (2009b) not just to argue\nagainst the Principle of Jeffrey Conditionalization, but also to\nillustrate a more general point: that principle is in tension with an\ninfluential thesis called confirmational holism, most\nfamously defended by Duhem (1906) and Quine (1951). Confirmational\nholism says roughly that how one should revise one\u2019s beliefs\ndepends on a good deal of one\u2019s background opinions\u2014such\nas the opinions about the quality of the lighting, the reliability of\none\u2019s vision, the details of one\u2019s experimental setup\n(which are conjoined with a tested scientific theory to predict\nexperimental outcomes). In reply, Konek (forthcoming) develops and\ndefends an even more flexible version of conditionalization, flexible\nenough to be compatible with confirmational holism. For more on\nconfirmational holism, see the entry on\n underdetermination of scientific theory\n and the survey by Ivanova (2021).\n\nFor a more detailed discussion of Jeffrey conditionalization, see the\nsurveys by Joyce (2011: sec. 3.2 and 3.3) and Weisberg (2011: sec. 3.4\nand 3.5).\n\n\n\n5.4 Memory Loss\n\nConditionalization in the standard version preserves certainties,\nwhich fails to accommodate cases of memory loss (Talbott 1991):\n\n\nExample (Dinner). At 6:30 PM on March 15,\n1989, Bill is certain that he is having spaghetti for dinner that\nnight. But by March 15 of the next year, Bill has completely forgotten\nwhat he had for dinner one year ago.\n\n\n\nThere are even putative counterexamples that appear to be\nworse\u2014with an agent who faces only the danger of memory loss\nrather than actual memory loss. Here is one such example (Arntzenius\n2003):\n\n\nExample (Shangri-La). A traveler has reached a\nfork in the road to Shangri-La. The guardians will flip a fair coin to\ndetermine her path. If it comes up heads, she will travel the path by\nthe Mountains and correctly remember that all along. If instead it\ncomes up tails, she will travel by the Sea\u2014with her memory\naltered upon reaching Shangri-La so that she will incorrectly remember\nhaving traveled the path by the Mountains. So, either way, once in\nShangri-La the traveler will remember having traveled the path by the\nMountains. The guardians explain this entire arrangement to the\ntraveler, who believes those words with certainty. It turns out that\nthe coin comes up heads. So the traveler travels the path by the\nMountains and has credence 1 that she does. But once she reaches\nShangri-La and recalls the guardians\u2019 words, that credence\nsuddenly drops from 1 down to 0.5.\n\n\n\nThat credence drop violates the Principle of Conditionalization, and\nall that happens without any actual loss of memory.\n\nIt may be replied that conditionalization can be plausibly generalized\nto accommodate the above case. Here is an attempt made by Titelbaum\n(2013a: ch. 6), who develops an idea that can be traced back to Levi\n(1980: sec. 4.3):\n\n\nThe Principle of Generalized Conditionalization\n(Certainties Version). It ought to be that, if two considered\npossibilities each entail one\u2019s certainties at an earlier time\nand continue to do so at a later time, then their credence ratio are\npreserved across those two times.\n\n\n\nThis norm allows the set of one\u2019s certainties to expand or\nshrink, while incorporating the core idea of conditionalization:\npreservation of credence ratios. To see how this norm accommodates the\nShangri-La Case, assume for simplicity that the traveler starts at the\ninitial time with a set of certainties, which expands upon seeing the\ncoin toss result at a later time, but shrinks back to the\noriginal set of certainties upon reaching Shangri-La at the\nfinal time. Note that there is no change in one\u2019s certainties\nacross the initial time and the final time. So, by the above norm,\none\u2019s credences at the final time (upon reaching Shangri-La)\nshould be identical to those at the initial time (the start of the\ntrip). In particular, one\u2019s final credence in traveling the path\nby the Mountains should be the same as the initial credence, which is\n0.5. For more on the attempts to save conditionalization from cases of\nactual or potential memory loss, see Meacham (2010), Moss (2012), and\nTitelbaum (2013a: ch. 6 and 7).\n\nThe Principle of Generalized Conditionalization, as stated above,\nmight be thought to be an incomplete diachronic norm because it leaves\nopen the question of how one\u2019s certainties ought to change.\nEarly attempts at a positive answer are due to Harper (1976, 1978) and\nLevi (1980: ch. 1\u20134). Their ideas are developed independently of\nthe issue of memory loss, but are motivated by the scenarios in which\nan agent finds a need to revise or even retract what she used to take\nto be her evidence. Although Harper\u2019s and Levi\u2019s\napproaches are not identical, they share the common idea that\none\u2019s certainties ought to change under the constraint of\ncertain diachronic axioms, now known as the AGM axioms in the\nbelief revision\n literature.[9]\n For some reasons against the Harper-Levi approach to norms of\ncertainty change, see Titelbaum (2013a: sec. 7.4.1).\n5.5 Self-Locating Credences\n\nOne\u2019s self-locating credences are, for example,\ncredences about who one is, where one is, and what time it is. Such\ncredences pose some challenges to conditionalization. Let me mention\ntwo below.\n\nTo begin with, consider the following case, adapted from Titelbaum\n(2013a: ch. 12):\n\n\nExample (Writer). At \\(t_1\\) it\u2019s midday\non Wednesday, and a writer is sitting in an office finishing a\nmanuscript for a publisher, with a deadline by the end of next day,\nbeing certain that she only has three more sections to go. Then, at\n\\(t_2\\), she notices that it gets dark out\u2014in fact, she has lost\nsense of time because of working too hard, and she is now only sure\nthat it is either Wednesday evening or early Thursday morning. She\nalso notices that she has only got one section done since the midday.\nSo the writer utters to herself: \u201cNow, I still have two more\nsections to go\u201d. That is the new evidence for her to change\ncredences.\n\n\n\nThe problem is that it is not immediately clear what exactly is the\nproposition E that the writer should conditionalize on. The\nright E appears to be the proposition expressed by the\nwriter\u2019s utterance: \u201cNow, I still have two more sections\nto go\u201d. And the expressed proposition must be one of the\nfollowing two candidates, depending on when the utterance is actually\nmade (assuming the standard account of indexicals, due to Kaplan\n1989):\n\n\\((A)\\)\n The writer still has two more sections to go on Wednesday\nevening.\n\n\n\\((B)\\) \n The writer still has two more sections to go on early Thursday\nMorning.\n\n\nBut, with the lost sense of time, it also seems that the writer should\nconditionalize on a less informative body of evidence: the disjunction\n\\(A \\vee B\\). So exactly what should she conditionalize on? \\(A\\),\n\\(B\\), or \\(A \\vee B\\)? See Titelbaum (2016) for a survey of some\nproposed solutions to this problem.\n\nWhile the previous problem concerns only the inputs that should be\npassed to the conditionalization process, conditionalization itself is\nchallenged when self-locating credences meet the danger of memory\nloss. Consider the following case, made popular in epistemology by\nElga (2000):\n\n\nExample (Sleeping Beauty). Sleeping Beauty\nparticipates in an experiment. She knows for sure that she will be\ngiven a sleeping pill that induces limited amnesia. She knows for sure\nthat, after she falls asleep, a fair coin will be flipped. If it lands\nheads, she will be awakened on Monday and asked: \u201cHow confident\nare you that the coin landed heads?\u201d. She will not be informed\nwhich day it is. If the coin lands tails, she will be awaken on both\nMonday and on Tuesday and asked the same question each time. The\namnesia effect is designed to ensure that, if awakened on Tuesday she\nwill not remember being woken on Monday. And Sleeping Beauty knows all\nthat for sure.\n\n\n\nWhat should her answer be when she is awakened on Monday and asked how\nconfident she is in the coin\u2019s landing heads? Lewis (2001)\nemploys the Principle of Conditionalization to argue that the answer\nis \\(1/2\\). His reasoning proceeds as follows: Sleeping Beauty, upon\nher awakening, acquires no new evidence or acquires only a piece of\nnew evidence that she is already certain of, so by conditionalization\nher credence in the coin\u2019s landing heads ought to remain the\nsame as it was before the sleep: \\(1/2\\).\n\nBut Elga (2000) argues that the answer is \\(1/3\\) rather than \\(1/2\\).\nIf so, that will seem to be a counterexample to the Principle of\nConditionalization. Here is a sketch of his argument. Imagine that we\nare Sleeping Beauty and reason as follows. We just woke up, and there\nare only three possibilities on the table, regarding how the coin\nlanded and what day it is today:\n\n\\((A)\\)\n Heads and it\u2019s Monday.\n\n\n\\((B)\\) \n Tails and it\u2019s Monday.\n\n\n\\((C)\\) \nTails and it\u2019s Tuesday.\n\n\nIf we are told that it\u2019s Monday (\\(A \\vee B\\)), we will judge\nthat the coin\u2019s landing heads (\\(A\\)) is as probable as its\nlanding tails (\\(B\\)). So \n\\[\\Cr(A \\mid A \\vee B) = \\Cr(B \\mid A \\vee B) = 1/2.\\]\n\n\nIf we are told that it lands tails (\\(B \\vee C\\)), we will judge that\ntoday being Monday (\\(B\\)) and today being Tuesday (\\(C\\)) are equally\nprobable. So  \n\\[\\Cr(B \\mid B \\vee C) = \\Cr(C \\mid B \\vee C) = 1/2.\\]\n\n\nThe only way to meet the above conditions is to distribute the\nunconditional credences evenly:  \n\\[\\Cr(A) = \\Cr(B) = \\Cr(C) = 1/3.\\]\n\n\nHence the credence in landing heads, \\(A\\), is equal to \\(1/3\\), or so\nElga concludes. This result seems to challenge the Principle of\nConditionalization, which recommends the answer \\(1/2\\) as explained\nabove. For more on the Sleeping Beauty problem, see the survey by\nTitelbaum (2013b).\n5.6 Bayesianism without Kinematics\n\nConfronted with the existing problems for the Principle of\nConditionalization, some Bayesians turn away from any diachronic norm\nand develop another variety of Bayesianism: time-slice\nBayesianism. On this view, what credences you should (or may)\nhave at any particular time depend solely on the total\nevidence you have at that same time\u2014independently of your\nearlier credences. To specify this dependency relation is to specify\nexclusively synchronic norms\u2014and to forget about diachronic\nnorms. Strictly speaking, there is still a diachronic norm, but it is\nderived rather than fundamental: when the time flows from \\(t\\) to\n\\(t'\\), your credences ought to change in a certain way\u2014they\nought to change to the credences that you ought to have with respect\nto your total evidence at the latter time \\(t'\\)\u2014and the earlier\ntime \\(t\\) is to be ignored. Any diachronic norm, if correct, is at\nmost an epiphenomenon that arises when correct synchronic norms are\napplied repeatedly across different times, according to time-slice\nBayesianism. (This view is stated above in terms of one\u2019s total\nevidence, but that can be replaced by one\u2019s total reasons or\ninformation.)\n\nA particular version of this view is held by J. Williamson (2010: ch.\n4), who is so firmly an objective Bayesian that he argues that the\nPrinciple of Conditionalization should be rejected if it is in\nconflict with repeated applications of certain synchronic norms, such\nas Probabilism and the Principle of Maximum Entropy (which generalizes\nthe Principle of Indifference; see\n supplement D).\n Time-slice Bayesianism as a general position is developed and\ndefended by Hedden (2015a, 2015b).\n\n\n6. The Problem of Idealization\n\nA worry about Bayesian epistemology is that the two core Bayesian\nnorms are so demanding that they can be followed only by highly\nidealized agents\u2014being logically omniscient, with\nprecise credences that always fit together\nperfectly. This is the problem of idealization, which was\npresented in the tutorial\n section 1.9.\n This section surveys three reply strategies for Bayesians, which\nmight complement each other. As will become clear below, the work on\nthis problem is quite interdisciplinary, with contributions from\nepistemologists as well as scientists and other philosophers.\n6.1 De-idealization and Understanding\n\nOne reply to the problem of idealization is to look at how idealized\nmodels are used and valued in science, and to argue that certain\nvalues of idealization can be carried over to epistemology. When a\nscientist studies a complex system, she might not really need an\naccurate description of it but might rather want to pursue the\nfollowing:\n\nsome simplified, idealized models of the whole (such as a block\nsliding on a frictionless, perfectly flat plane in vacuum);\ngradual de-idealizations of the above (such as adding more and\nmore realistic considerations about friction);\nan articulated reason why de-idealizations should be done this way\nrather than another to improve upon the simpler models.\n\n\nParts 1 and 2 do not have to be ladders that will be kicked away once\nwe reach a more realistic model. Instead, the three parts, 1\u20133,\nmight work together to help the scientist achieve a deeper\nunderstanding of the complex system under study\u2014a kind of\nunderstanding that an accurate description (alone) does not provide.\nThe above is one of the alleged values of idealized models in\nscientific modeling; for more, see section 4.2 of the entry on\n understanding\n and the survey by Elliott-Graves and Weisberg (2014: sec. 3). Some\nBayesians have argued that certain values of idealization are\napplicable not just in science but also in epistemology (Howson 2000:\n173\u2013177; Titelbaum 2013a: ch. 2\u20135; Schupbach 2018). For\nmore on the values of building more or less idealized models not just\nin epistemology but generally in philosophy, see T. Williamson\n(2017).\n\nThe above reply to the problem of idealization has been reinforced by\na sustained project of de-idealization in Bayesian epistemology. The\nfollowing gives you the flavor of how this project may be pursued.\nLet\u2019s start with the usual complaint that Probabilism\nimplies:\n\n\nStrong Normalization. An agent ought to assign\ncredence 1 to every logical truth.\n\n\n\nThe worry is that a person can meet this demand only by luck or with\nan unrealistic ability\u2014the ability to demarcate all logical\ntruths from the other propositions. But some Bayesians argue that the\nstandard version of Probabilism can be suitably de-idealized to obtain\na weak version that does not imply Strong Normalization. For example,\nthe extensibility version of Probabilism (discussed in\n section 3.1)\n permits one to have credence gaps and, thus, have no credence in any\nlogical truth (de Finetti 1970 [1974]; Jeffrey 1983; Zynda 1996).\nIndeed, the extensibility version of Probabilism only implies:\n\n\nWeak Normalization. It ought to be that, if an\nagent has a credence in a logical truth, that credence is equal to\n1.\n\n\n\nSome Bayesians have tried to de-idealize Probabilism further, to set\nit free from the commitment that any credence ought to be as sharp as\nan individual real number, precise to every digit. For example, Walley\n(1991: ch. 2 and 3) develops a version of Probabilism according to\nwhich a credence is permitted to be unsharp in this way. A credence\ncan be bounded by one or another interval of real numbers\nwithout being equal to any particular real number or any\nparticular interval\u2014even the tightest bound on a credence can be\nan incomplete description of that credence. This\ninterval-bound approach gives rise to a Dutch Book argument for an\neven weaker version of Probabilism, which only implies:\n\n\nVery Weak Normalization. It ought to be that,\nif an agent has a credence in a logical truth, then that credence is\nbounded only by intervals that include 1.\n\n\n\nSee\n supplement A\n for some non-technical details. For more details and related\ncontroversies, see the survey by Mahtani (2019) and the entry on\n imprecise probabilities.\n\nThe above are just some of the possible steps that might be taken in\nthe Bayesian project of de-idealization. There are more: Can Bayesians\nprovide norms for agents who can lose memories and forget what they\nused to take as certain? See Meacham (2010), Moss (2012), and\nTitelbaum (2013a: ch. 6 and 7) for positive accounts; also see\n section 5.4\n for discussion. Can Bayesians develop norms for agents who are\nsomewhat incoherent and incapable of being perfectly coherent? See\nStaffel (2019) for a positive account. Can Bayesians provide norms\neven for agents who are so cognitively underpowered that they only\nhave all-or-nothing beliefs without a numerical credence? See Lin\n(2013) for a positive account. Can Bayesians develop norms that\nexplain how one may be rationally uncertain whether one is rational?\nSee Dorst (2020) for a positive account. Can Bayesians develop a\ndiachronic norm for cognitively bounded agents? See Huttegger (2017a,\n2017b) for a positive account.\n\nWhile the project of de-idealization can be pursued gradually and\nincrementally as illustrated above, Bayesians disagree about how far\nthis project should be pursued. Some Bayesians want to push it\nfurther: they think that Very Weak Normalization is still too strong\nto be plausible, so Probabilism needs to be abandoned altogether and\nreplaced by a norm that permits credences less than 1 in logical\ntruths. For example, Garber (1983) tries to do that for certain\nlogical truths; Hacking (1967) and Talbott (2016), for all logical\ntruths. On the other hand, Bayesians of the more traditional variety\nretain a more or less de-idealized version of Probabilism, and try to\ndefend it by clarifying its normative content, to which I now\nturn.\n6.2 Striving for Ideals\n\nProbabilism is often thought to have a counterexample to this effect:\nit implies that we should meet a very high standard, but it is not the\ncase that we should, because we cannot. In reply, some Bayesians hold\nthat this is actually not a counterexample, and that the apparent\ncounterexample can be explained away once an appropriate reading of\n\u2018ought\u2019 is in place and clearly distinguished from another\nreading.\n\nTo see that there are two readings of \u2018ought\u2019, think about\nthe following scenario. Suppose that this is true:\n\n\n (i) We ought to launch a war now.\n\n\n\nThe truth of this particular norm might sound like a counterexample to\nthe general norm below:\n\n\n (ii) There ought to be no war.\n\n\n\nBut perhaps there can be a context in which (i) and (ii) are both true\nand hence the former is not a counterexample to the latter. An example\nis the context in which we know for sure that we are able to launch a\nwar that ends all existing wars. Indeed, the occurrences of\n\u2018ought\u2019 in those two sentences seem to have very different\nreadings. Sentence (ii) can be understood to express a norm which\nportrays what the state of the world ought to be\nlike\u2014what the world would be like if things were ideal.\nSuch a norm is often called an ought-to-be norm or\nevaluative norm, pointing to one or another ideal. On the\nother hand, sentence (i) can be understood as a norm which specifies\nwhat an agent ought to do in a less-than-ideal situation that\nshe turns out to be in\u2014possibly with the goal to improve the\nexisting situation and bring it closer to the ideal specified by an\nought-to-be norm, or at least to prevent the situation from getting\nworse. This kind of norm is often called an ought-to-do norm,\na deliberative norm, or a prescriptive norm. So,\nalthough the truth of (i) can sound like a counterexample to (ii), the\ntension between the two seems to disappear with appropriate readings\nof \u2018ought\u2019.\n\nSimilarly, suppose that an ordinary human has some incoherent\ncredences, and that it is not the case that she ought to remove the\nincoherence right away because she has not detected the incoherence.\nThe norm just stated can be thought of as an ought-to-do norm and,\nhence, need not be taken as a counterexample to Probabilism construed\nas an ought-to-be norm:\n\n\nProbabilism (Ought-to-Be Version). It\nought to be that one\u2019s credences fit together in the\nprobabilistic way.\n\n\n\nThe ought-to-be reading of \u2018ought\u2019 has been employed\nimplicitly or explicitly to defend Bayesian norms\u2014not just by\nBayesian philosophers (Zynda 1996; Christensen 2004: ch. 6; Titelbaum\n2013a: ch. 3 and 4; Wedgwood 2014; Eder forthcoming), but also by\nBayesian psychologists (Baron 2012). The distinction between the\nought-to-be and the ought-to-do oughts is most often defended in the\nbroader context of normative studies, such as in deontic logic\n(Casta\u00f1eda 1970; Horty 2001: sec. 3.3 and 3.4) and in\nmetaethics (Broome 1999; Wedgwood 2006; Schroeder 2011).\n\nThe ought-to-be construal of Probabilism still leaves us a\nprescriptive issue: How should a person go about detecting and fixing\nthe incoherence of one\u2019s credences, noting that it is absurd to\nstrive for coherence at all costs? This is an issue about\nought-to-do/prescriptive norms, addressed by a prescriptive research\nprogram in an area of psychology called judgment and decision\nmaking. For a survey of that area, see Baron (2004, 2012) and\nElqayam & Evans (2013). In fact, many psychologists even think\nthat, for better or worse, this prescriptive program has become the\n\u201cnew paradigm\u201d in the psychology of reasoning; for\nreferences, see Elqayam & Over (2013).\n\nThe prescriptive issue mentioned above raises some other questions.\nThere is an empirical, computational question: What is the\nextent to which a human brain can approximate the Bayesian ideal of\nsynchronic and diachronic coherence? See Griffiths, Kemp, &\nTenenbaum (2008) for a survey of some recent results. And there are\nphilosophical questions: Why is it epistemically better for a\nhuman\u2019s credences to be less incoherent? Speaking of being\nless incoherent, how can we develop a measure of degrees of\nincoherence? See de Bona & Staffel (2018) and Staffel (2019) for\nproposals.\n6.3 Applications Empowered by Idealization\n\nThere is a third approach to the problem of idealization: to some\nBayesians, some aspects of the Bayesian idealization are to be\nutilized rather than removed, because it is those aspects of\nidealization that empower certain important applications of\nBayesian epistemology in science. Here is the idea. Consider a human\nscientist confronted with an empirical problem. When some hypotheses\nhave been stated for consideration and some data have been collected,\nthere remains an inferential task\u2014the task of inferring from the\ndata to one of the hypotheses. This inferential task can be done by\nhuman scientists alone, but it has been done increasingly often this\nway: by developing a computer program (in Bayesian statistics) to\nsimulate an idealized Bayesian agent as if that agent were hired to\nperform the inferential task. The purpose of this inferential task\nwould be undermined if what is simulated by the computer were a\ncognitively underpowered agent who mimics the limited capacities of\nhuman agents. Howson (1992: sec. 6) suggests that this inferential\ntask is what Bayesian epistemology and Bayesian statistics were mainly\ndesigned for at the early stages of their development. See Fienberg\n(2006) for the historical development of Bayesian statistics.\n\nSo, on the above view, idealization is essential to the existing\napplications of Bayesian epistemology in science. If so, the real\nissue is whether the kind of scientific inquiry empowered by\nBayesian idealization serves the purpose of the inferential task\nbetter than do the non-Bayesian rivals, such as so-called\nfrequentism and likelihoodism in statistics. For a\ncritical comparison of those three schools of thought about\nstatistical inference, see Sober (2008: ch. 1), Hacking (2016), and\nthe entry on\n philosophy of statistics.\n For an introduction to both Bayesian statistics and frequentist\nstatistics written for philosophers, see Howson & Urbach (2006:\nch. 5\u20138).\n\n\n7. Closing: The Expanding Territory of Bayesianism\n\nBayesian epistemology, despite the problems presented above, has been\nexpanding its scope of application. In addition to the more standard,\nolder areas of application listed in\n section 1.3,\n the newer ones can be found in the entry on\n epistemic self-doubt,\n sections 5.1 and 5.4 of the entry on\n disagreement,\n Adler (2006 [2017]: sec. 6.3), and sections 3.6 and 4 of the entry on\n social epistemology.\n\nIn their more recent works, Bayesians have also started to contribute\nto some epistemological issues that have traditionally been among the\nmost central concerns for many non-Bayesians, especially for those\nimmersed in the epistemology of all-or-nothing beliefs. I wish to\nclose by giving four groups of examples.\n\n Skeptical Challenges: Central to traditional\nepistemology is the issue of how to address certain skeptical\nchallenges. The Cartesian skeptic thinks that we are not justified in\nbelieving that we are not a brain in a vat. Huemer (2016) and Shogenji\n(2018) have each developed a Bayesian argument against this variety of\nskepticism. There is also the Pyrrhonian skeptic, who holds the view\nthat no belief can be justified due to the regress problem of\njustification: once a belief is justified with a reason, that reason\nis in need of justification, too, which kickstarts a regress. An\nattempt to reply to this skeptic quickly leads to a difficult choice\namong three positions: first, foundationalism (roughly, that the\nregress can be stopped); second, coherentism (roughly, that it is\npermissible for the regress of justifications to be circular); and\nthird, infinitism (roughly, that it is permissible for the regress of\njustifications to extend ad infinitum). To that issue\nBayesians have made some contributions. For example, White (2006)\ndevelops a Bayesian argument against an influential version of\nfoundationalism, followed by a reply from Weatherson (2007); for more,\nsee\n section 3.2 of the entry on formal epistemology.\n Klein & Warfield (1994) develop a probabilistic argument against\ncoherentism, which initiates a debate joined by many Bayesians; for\nmore, see\n section 7 of the entry on coherentist theories of epistemic justification.\n Peijnenburg (2007) defends infinitism by developing a Bayesian\nversion of it. For more on the Cartesian and Pyrrhonian skeptical\nviews, see the entry on\n skepticism.\n Theories of Knowledge and Justified Beliefs:\nWhile traditional epistemologists praise knowledge and have\nextensively studied what turns a belief into knowledge, Moss (2013,\n2018) develops a Bayesian counterpart: she argues that a credence can\nalso be knowledge-like, a property that can be studied by Bayesians.\nTraditional epistemology also features a number of competing accounts\nof justified belief, and the possibilities of their Bayesian\ncounterparts have been explored by Dunn (2015) and Tang (2016). For\nmore on the prospects of such Bayesian counterparts, see H\u00e1jek\nand Lin (2017).\n The Scientific Realism/Anti-Realism Debate:\nOne of the most classic debates in philosophy of science is that\nbetween scientific realism and anti-realism. The scientific realist\ncontends that science pursues theories are true literally or at least\napproximately, while the anti-realist denies that. An early\ncontribution to this debate is van Fraassen\u2019s (1989: part II)\nBayesian argument against inference to the best explanation (IBE),\nwhich is often used by scientific realists to defend their view. Some\nBayesians have joined the debate and try to save IBE instead; see\nsections 3.1 and 4 of the entry on\n abduction.\n Another influential defense of scientific realism proceeds with the\nso-called no-miracle argument. (This argument runs roughly as\nfollows: scientific realism is correct because it is the only\nphilosophical view that does not render the success of science a\nmiracle.) Howson (2000: ch. 3) and Magnus & Callender (2004)\nmaintain that the no-miracle argument commits a fallacy that can be\nmade salient from a Bayesian perspective. In reply, Sprenger &\nHartmann (2019: ch. 5) contend that Bayesian epistemology makes\npossible a better version of the no-miracle argument for scientific\nrealism. An anti-realist view is instrumentalism, which says that\nscience only need to pursue theories that are useful for making\nobservable predictions. Vassend (forthcoming) argues that\nconditionalization can be generalized in a way that caters to both the\nscientific realist and the instrumentalist\u2014regardless of whether\nevidence should be utilized in science to help us pursue truth or\nusefulness.\n Frequentist Concerns: Frequentists about\nstatistical inference design inference procedures for the purposes of,\nsay, testing a working hypothesis, identifying the truth among a set\nof competing hypotheses, or producing accurate estimates of certain\nquantities. And they want to design procedures that infer\nreliably\u2014with a low objective, physical chance of\nmaking errors. Those concerns have been incorporated into Bayesian\nstatistics, leading to the Bayesian counterparts of some frequentist\naccounts. In fact, those results have already appeared in standard\ntextbooks on Bayesian statistics, such as the influential one by\nGelman et al. (2014: sec. 4.4 and ch. 6). The line between frequentist\nand Bayesian statistics is blurring.\n\n\nSo, as can be seen from the many examples in I\u2013IV, Bayesians\nhave been assimilating ideas and concerns from the epistemological\ntradition of all-or-nothing beliefs. In fact, there have also been\nattempts to develop a joint epistemology\u2014an epistemology for\nagents who have both credences and all-or-nothing beliefs at the same\ntime; for details, see\n section 4.2 of the entry on formal representations of belief.\n\nIt is debatable which, if any, of the above topics can be adequately\naddressed in Bayesian epistemology. But Bayesians have been expanding\ntheir territory and their momentum will surely continue.\n\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Adler, Jonathan, 2006 [2017], \u201cEpistemological Problems of\nTestimony\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2017 Edition), Edward N. Zalta (ed.), first written 2006. URL\n=\n &lt;<a href=\"https://plato.stanford.edu/archives/win2017/entries/testimony-episprob/\" target=\"other\">https://plato.stanford.edu/archives/win2017/entries/testimony-episprob/</a>&gt;.",
                "Armendt, Brad, 1980, \u201cIs There a Dutch Book Argument for\nProbability Kinematics?\u201d, <em>Philosophy of Science</em>, 47(4):\n583\u2013588. doi:10.1086/288958",
                "Arntzenius, Frank, 2003, \u201cSome Problems for\nConditionalization and Reflection\u201d, <em>Journal of\nPhilosophy</em>, 100(7): 356\u2013370.\ndoi:10.5840/jphil2003100729",
                "Bacchus, Fahiem, Henry E. Kyburg Jr, and Mariam Thalos, 1990,\n\u201cAgainst Conditionalization\u201d, <em>Synthese</em>, 85(3):\n475\u2013506. doi:10.1007/BF00484837",
                "Baron, Jonathan, 2004, \u201cNormative Models of Judgment and\nDecision Making\u201d, in <em>Blackwell Handbook of Judgment and\nDecision Making</em>, Derek J. Koehler and Nigel Harvey (eds.),\nLondon: Blackwell, 19\u201336.",
                "\u2013\u2013\u2013, 2012, \u201cThe Point of Normative Models\nin Judgment and Decision Making\u201d, <em>Frontiers in\nPsychology</em>, 3: art. 577. doi:10.3389/fpsyg.2012.00577",
                "Bartha, Paul, 2004, \u201cCountable Additivity and the de Finetti\nLottery\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 55(2): 301\u2013321. doi:10.1093/bjps/55.2.301",
                "Bayes, Thomas, 1763, \u201cAn Essay Towards Solving a Problem in\nthe Doctrine of Chances\u201d, <em>Philosophical Transactions of the\nRoyal Society of London</em>, 53: 370\u2013418. Reprinted 1958,\n<em>Biometrika</em>, 45(3\u20134): 296\u2013315, with G. A.\nBarnard\u2019s \u201cThomas Bayes: A Biographical Note\u201d,\n<em>Biometrika</em>, 45(3\u20134): 293\u2013295.\ndoi:10.1098/rstl.1763.0053 doi:10.1093/biomet/45.3-4.296\ndoi:10.1093/biomet/45.3-4.293 (note)",
                "Belot, Gordon, 2013, \u201cBayesian Orgulity\u201d,\n<em>Philosophy of Science</em>, 80(4): 483\u2013503.\ndoi:10.1086/673249",
                "Berger, James, 2006, \u201cThe Case for Objective Bayesian\nAnalysis\u201d, <em>Bayesian Analysis</em>, 1(3): 385\u2013402.\ndoi:10.1214/06-BA115",
                "Blackwell, David and Lester Dubins, 1962, \u201cMerging of\nOpinions with Increasing Information\u201d, <em>The Annals of\nMathematical Statistics</em>, 33(3): 882\u2013886.\ndoi:10.1214/aoms/1177704456",
                "Bovens, Luc and Stephan Hartmann, 2004, <em>Bayesian\nEpistemology</em>, Oxford: Oxford University Press.\ndoi:10.1093/0199269750.001.0001",
                "Briggs, R.A., 2019, \u201cConditionals\u201d, in Pettigrew and\nWeisberg 2019: 543\u2013590.",
                "Briggs, R.A. and Richard Pettigrew, 2020, \u201cAn\nAccuracy-Dominance Argument for Conditionalization\u201d,\n<em>No\u00fbs</em>, 54(1): 162\u2013181. doi:10.1111/nous.12258",
                "Broome, John, 1999, \u201cNormative Requirements\u201d,\n<em>Ratio</em>, 12(4): 398\u2013419. doi:10.1111/1467-9329.00101",
                "Carnap, Rudolf, 1945, \u201cOn Inductive Logic\u201d,\n<em>Philosophy of Science</em>, 12(2): 72\u201397.\ndoi:10.1086/286851",
                "\u2013\u2013\u2013, 1955, \u201cStatistical and Inductive\nProbability and Inductive Logic and Science\u201d (leaflet),\nBrooklyn, NY: Galois Institute of Mathematics and Art.",
                "\u2013\u2013\u2013, 1963, \u201cReplies and Systematic\nExpositions\u201d, in <em>The Philosophy of Rudolf Carnap</em>, Paul\nArthur Schilpp (ed.), La Salle, IL: Open Court, 859\u20131013.",
                "Casta\u00f1eda, Hector-Neri, 1970, \u201cOn the Semantics of\nthe Ought-to-Do\u201d, <em>Synthese</em>, 21(3\u20134):\n449\u2013468. doi:10.1007/BF00484811",
                "Christensen, David, 1996, \u201cDutch-Book Arguments\nDepragmatized: Epistemic Consistency For Partial Believers\u201d,\n<em>Journal of Philosophy</em>, 93(9): 450\u2013479.\ndoi:10.2307/2940893",
                "\u2013\u2013\u2013, 2004, <em>Putting Logic in Its Place:\nFormal Constraints on Rational Belief</em>, Oxford: Oxford University\nPress. doi:10.1093/0199263256.001.0001",
                "de Bona, Glauber and Julia Staffel, 2018, \u201cWhy Be\n(Approximately) Coherent?\u201d, <em>Analysis</em>, 78(3):\n405\u2013415. doi:10.1093/analys/anx159",
                "de Finetti, Bruno, 1937, <em>\u201cLa Pr\u00e9vision: Ses Lois\nLogiques, Ses Sources Subjectives\u201d</em>, <em>Annales de\nl\u2019institut Henri Poincar\u00e9</em>, 7(1):1\u201368.\nTranslated as \u201cForesight: its Logical Laws, its Subjective\nSources\u201d, Henry E. .Kyburg, Jr. (trans.), in <em>Studies in\nSubjective Probability</em>, Henry Ely Kyburg and Henry Edward Smokler\n(eds), New York: Wiley, 1964, 97\u2013158. Second edition,\nHuntington: Robert Krieger, 1980, 53\u2013118.",
                "\u2013\u2013\u2013, 1970 [1974], <em>Teoria delle\nprobabilit\u00e0</em>, Torino: G. Einaudi. Translated as <em>Theory\nof Probability</em>, two volumes, Antonio Machi and Adrian Smith\n(trans), New York: John Wiley, 1974.",
                "Diaconis, Persi and David Freedman, 1986a, \u201cOn the\nConsistency of Bayes Estimates\u201d, <em>The Annals of\nStatistics</em>, 14(1): 1\u201326. doi:10.1214/aos/1176349830",
                "\u2013\u2013\u2013, 1986b, \u201cRejoinder: On the Consistency\nof Bayes Estimates\u201d, <em>The Annals of Statistics</em>, 14(1):\n63\u201367. doi:10.1214/aos/1176349842",
                "Dorling, Jon, 1979, \u201cBayesian Personalism, the Methodology\nof Scientific Research Programmes, and Duhem\u2019s Problem\u201d,\n<em>Studies in History and Philosophy of Science Part A</em>, 10(3):\n177\u2013187. doi:10.1016/0039-3681(79)90006-2",
                "Dorst, Kevin, 2020, \u201cEvidence: A Guide for the\nUncertain\u201d, <em>Philosophy and Phenomenological Research</em>,\n100(3): 586\u2013632. doi:10.1111/phpr.12561",
                "Duhem, Pierre, 1906 [1954], <em>La th\u00e9orie physique: son\nobjet et sa structure</em>, Paris: Chevalier &amp; Rivi\u00e8re.\nTranslated as <em>The Aim and Structure of Physical Theory</em>,\nPhilip P. Wiener (trans.), Princeton, NJ: Princeton University Press,\n1954.",
                "Dunn, Jeff, 2015, \u201cReliability for Degrees of Belief\u201d,\n<em>Philosophical Studies</em>, 172(7): 1929\u20131952.\ndoi:10.1007/s11098-014-0380-2",
                "Earman, John (ed.), 1983, <em>Testing Scientific Theories</em>,\n(Minnesota Studies in the Philosophy of Science 10), Minneapolis, MN:\nUniversity of Minnesota Press.",
                "\u2013\u2013\u2013, 1992, <em>Bayes or Bust? A Critical\nExamination of Bayesian Confirmation Theory</em>, Cambridge, MA: MIT\nPress.",
                "Easwaran, Kenny, 2011, \u201cBayesianism I: Introduction and\nArguments in Favor\u201d, <em>Philosophy Compass</em>, 6(5):\n312\u2013320. doi:10.1111/j.1747-9991.2011.00399.x",
                "\u2013\u2013\u2013, 2013, \u201cWhy Countable\nAdditivity?\u201d, <em>Thought: A Journal of Philosophy</em>, 2(1):\n53\u201361. doi:10.1002/tht3.60",
                "\u2013\u2013\u2013, 2014, \u201cRegularity and Hyperreal\nCredences\u201d, <em>Philosophical Review</em>, 123(1): 1\u201341.\ndoi:10.1215/00318108-2366479",
                "\u2013\u2013\u2013, 2019, \u201cConditional\nProbabilities\u201d, in Pettigrew and Weisberg 2019:\n131\u2013198.",
                "Eder, Anna-Maria, forthcoming, \u201cEvidential Probabilities and\nCredences\u201d, <em>The British Journal for the Philosophy of\nScience</em>, first online: 24 December 2020.\ndoi:10.1093/bjps/axz043",
                "Elga, Adam, 2000, \u201cSelf-Locating Belief and the Sleeping\nBeauty Problem\u201d, <em>Analysis</em>, 60(2): 143\u2013147.\ndoi:10.1093/analys/60.2.143",
                "Elliott-Graves, Alkistis and Michael Weisberg, 2014,\n\u201cIdealization\u201d, <em>Philosophy Compass</em>, 9(3):\n176\u2013185. doi:10.1111/phc3.12109",
                "Elqayam, Shira and Jonathan St. B. T. Evans, 2013,\n\u201cRationality in the New Paradigm: Strict versus Soft Bayesian\nApproaches\u201d, <em>Thinking &amp; Reasoning</em>, 19(3\u20134):\n453\u2013470. doi:10.1080/13546783.2013.834268",
                "Elqayam, Shira and David E. Over, 2013, \u201cNew Paradigm\nPsychology of Reasoning: An Introduction to the Special Issue Edited\nby Elqayam, Bonnefon, and Over\u201d, <em>Thinking &amp;\nReasoning</em>, 19(3\u20134): 249\u2013265.\ndoi:10.1080/13546783.2013.841591",
                "Eriksson, Lina and Alan H\u00e1jek, 2007, \u201cWhat Are\nDegrees of Belief?\u201d, <em>Studia Logica</em>, 86(2):\n183\u2013213. doi:10.1007/s11225-007-9059-4",
                "Eva, Benjamin, 2019, \u201cPrinciples of Indifference\u201d,\n<em>The Journal of Philosophy</em>, 116(7): 390\u2013411.\ndoi:10.5840/jphil2019116724",
                "Eva, Benjamin and Stephan Hartmann, 2020, \u201cOn the Origins of\nOld Evidence\u201d, <em>Australasian Journal of Philosophy</em>,\n98(3): 481\u2013494. doi:10.1080/00048402.2019.1658210",
                "Fienberg, Stephen E., 2006, \u201cWhen Did Bayesian Inference\nBecome \u2018Bayesian\u2019?\u201d, <em>Bayesian Analysis</em>,\n1(1): 1\u201340. doi:10.1214/06-BA101",
                "Fishburn, Peter C., 1986, \u201cThe Axioms of Subjective\nProbability\u201d, <em>Statistical Science</em>, 1(3): 335\u2013345.\ndoi:10.1214/ss/1177013611",
                "Fitelson, Branden, 2006, \u201cInductive Logic\u201d, in <em>The\nPhilosophy of Science: An Encyclopedia</em>, Sahotra Sarkar and\nJessica Pfeifer (eds), New York: Routledge, 384\u2013394.",
                "Fitelson, Branden and Andrew Waterman, 2005, \u201cBayesian\nConfirmation and Auxiliary Hypotheses Revisited: A Reply to\nStrevens\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 56(2): 293\u2013302. doi:10.1093/bjps/axi117",
                "Foley, Richard, 1992, <em>Working without a Net: A Study of\nEgocentric Epistemology</em>, New York: Oxford University Press.",
                "Forster, Malcolm R., 1995, \u201cBayes and Bust: Simplicity as a\nProblem for a Probabilist\u2019s Approach to Confirmation\u201d,\n<em>The British Journal for the Philosophy of Science</em>, 46(3):\n399\u2013424. doi:10.1093/bjps/46.3.399",
                "Forster, Malcolm and Elliott Sober, 1994, \u201cHow to Tell When\nSimpler, More Unified, or Less <i>Ad Hoc</i> Theories Will Provide\nMore Accurate Predictions\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, 45(1): 1\u201335.\ndoi:10.1093/bjps/45.1.1",
                "Freedman, David A., 1963, \u201cOn the Asymptotic Behavior of\nBayes\u2019 Estimates in the Discrete Case\u201d, <em>The Annals of\nMathematical Statistics</em>, 34(4): 1386\u20131403.\ndoi:10.1214/aoms/1177703871",
                "Gabbay, Dov M., Stephan Hartman, and John Woods (eds), 2011,\n<em>Handbook of the History of Logic, Volume 10: Inductive Logic</em>,\nBoston: Elsevier. ",
                "Gaifman, Haim, 1986, \u201c A Theory of Higher Order\nProbabilities\u201d, <em>Proceedings of the 1986 Conference on\nTheoretical Aspects of Reasoning about Knowledge</em>, San Francisco:\nMorgan Kaufmann Publishers, 275\u2013292.",
                "Gaifman, Haim and Marc Snir, 1982, \u201cProbabilities over Rich\nLanguages, Testing and Randomness\u201d, <em>Journal of Symbolic\nLogic</em>, 47(3): 495\u2013548. doi:10.2307/2273587",
                "Garber, Daniel, 1983, \u201cOld Evidence and Logical Omniscience\nin Bayesian Confirmation Theory\u201d, in Earman 1983: 99\u2013131.\n [<a href=\"https://hdl.handle.net/11299/185350\" target=\"other\">Garber 1983 available online</a>]",
                "Gelman, Andrew, John B. Carlin, Hal Steven Stern, David B. Dunson,\nAki Vehtari, and Donald B. Rubin, 2014, <em>Bayesian Data\nAnalysis</em>, third edition, (Chapman &amp; Hall/CRC Texts in\nStatistical Science), Boca Raton, FL: CRC Press.",
                "Gelman, Andrew and Christian Hennig, 2017, \u201cBeyond\nSubjective and Objective in Statistics\u201d, <em>Journal of the\nRoyal Statistical Society: Series A (Statistics in Society)</em>,\n180(4): 967\u20131033. Includes discussions of the paper.\ndoi:10.1111/rssa.12276",
                "Gendler, Tamar Szabo and John Hawthorne (eds), 2010, <em>Oxford\nStudies in Epistemology, Volume 3</em>, Oxford: Oxford University\nPress.",
                "Gillies, Donald, 2000, <em>Philosophical Theories of\nProbability</em>, (Philosophical Issues in Science), London/New York:\nRoutledge.",
                "Glymour, Clark N., 1980, \u201cWhy I Am Not a Bayesian\u201d, in\nhis <em>Theory and Evidence</em>, Princeton, NJ: Princeton University\nPress.",
                "Good, Irving John, 1976, \u201cThe Bayesian Influence, or How to\nSweep Subjectivism under the Carpet\u201d, in <em>Foundations of\nProbability Theory, Statistical Inference, and Statistical Theories of\nScience</em>, William Leonard Harper and Clifford Alan Hooker (eds.),\nDordrecht: Springer Netherlands, 125\u2013174. Reprinted in his\n<em>Good Thinking: The Foundations of Probability and Its\nApplications</em>, Minneapolis, MN: University of Minnesota Press,\n22\u201358. doi:10.1007/978-94-010-1436-6_5",
                "Goodman, Nelson, 1955, <em>Fact, Fiction, and Forecast</em>,\nCambridge, MA: Harvard University Press.",
                "Greaves, Hilary and David Wallace, 2006, \u201cJustifying\nConditionalization: Conditionalization Maximizes Expected Epistemic\nUtility\u201d, <em>Mind</em>, 115(459): 607\u2013632.\ndoi:10.1093/mind/fzl607",
                "Griffiths, Thomas L., Charles Kemp, and Joshua B. Tenenbaum, 2008,\n\u201cBayesian Models of Cognition\u201d, in <em>The Cambridge\nHandbook of Computational Psychology</em>, Ron Sun (ed.), Cambridge:\nCambridge University Press, 59\u2013100.\ndoi:10.1017/CBO9780511816772.006",
                "Hacking, Ian, 1967, \u201cSlightly More Realistic Personal\nProbability\u201d, <em>Philosophy of Science</em>, 34(4):\n311\u2013325. doi:10.1086/288169",
                "\u2013\u2013\u2013, 2001, <em>An Introduction to Probability\nand Inductive Logic</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511801297",
                "\u2013\u2013\u2013, 2016, <em>Logic of Statistical\nInference</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9781316534960",
                "H\u00e1jek, Alan, 2003, \u201cWhat Conditional Probability\nCould Not Be\u201d, <em>Synthese</em>, 137(3): 273\u2013323.\ndoi:10.1023/B:SYNT.0000004904.91112.16",
                "\u2013\u2013\u2013, 2009, \u201cDutch Book Arguments\u201d,\nin <em>The Handbook of Rational and Social Choice</em>, Paul Anand,\nPrasanta Pattanaik, and Clemens Puppe (eds.), New York: Oxford\nUniversity Press, 173\u2013195.\ndoi:10.1093/acprof:oso/9780199290420.003.0008",
                "\u2013\u2013\u2013, 2012, \u201cIs Strict Coherence\nCoherent?\u201d, <em>Dialectica</em>, 66(3): 411\u2013424.\ndoi:10.1111/j.1746-8361.2012.01310.x",
                "H\u00e1jek, Alan and Hanti Lin, 2017, \u201cA Tale of Two\nEpistemologies?\u201d, <em>Res Philosophica</em>, 94(2):\n207\u2013232.",
                "Harman, Gilbert, 1986, <em>Change in View: Principles of\nReasoning</em>, Cambridge, MA: MIT Press.",
                "Harsanyi, John C., 1985, \u201cAcceptance of Empirical\nStatements: A Bayesian Theory without Cognitive Utilities\u201d,\n<em>Theory and Decision</em>, 18(1): 1\u201330.",
                "Harper, William L., 1976, \u201cRational Conceptual\nChange\u201d, <em>PSA: Proceedings of the Biennial Meeting of the\nPhilosophy of Science Association</em>, 1976(2): 462\u2013494.\ndoi:10.1086/psaprocbienmeetp.1976.2.192397",
                "\u2013\u2013\u2013, 1978, \u201cBayesian Learning Models with\nRevision of Evidence\u201d, <em>Philosophia</em>, 7(2):\n357\u2013367. doi:10.1007/BF02378821",
                "Hartmann, Stephan and Branden Fitelson, 2015, \u201cA New\nGarber-Style Solution to the Problem of Old Evidence\u201d,\n<em>Philosophy of Science</em>, 82(4): 712\u2013717.\ndoi:10.1086/682916",
                "Haverkamp, Nick and Moritz Schulz, 2012, \u201cA Note on\nComparative Probability\u201d, <em>Erkenntnis</em>, 76(3):\n395\u2013402. doi:10.1007/s10670-011-9307-x",
                "Heckerman, David, 1996 [2008], \u201cA Tutorial on Learning with\nBayesian Networks\u201d. Technical Report MSR-TR-95-06, Redmond, WA:\nMicrosoft Research. Reprinted in <em>Innovations in Bayesian Networks:\nTheory and Applications</em>, Dawn E. Holmes and Lakhmi C. Jain\n(eds.), (Studies in Computational Intelligence, 156),\nBerlin/Heidelberg: Springer Berlin Heidelberg, 2008, 33\u201382.\ndoi:10.1007/978-3-540-85066-3_3",
                "Hedden, Brian, 2015a, \u201cTime-Slice Rationality\u201d,\n<em>Mind</em>, 124(494): 449\u2013491. doi:10.1093/mind/fzu181",
                "\u2013\u2013\u2013, 2015b, <em>Reasons without Persons:\nRationality, Identity, and Time</em>, Oxford/New York: Oxford\nUniversity Press. doi:10.1093/acprof:oso/9780198732594.001.0001",
                "Henderson, Leah, 2014, \u201cBayesianism and Inference to the\nBest Explanation\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 65(4): 687\u2013715. doi:10.1093/bjps/axt020",
                "Hitchcock, Christopher (ed.), 2004, <em>Contemporary Debates in\nPhilosophy of Science</em>, (Contemporary Debates in Philosophy 2),\nMalden, MA: Blackwell.",
                "Horgan, Terry, 2017, \u201cTroubles for Bayesian Formal\nEpistemology\u201d, <em>Res Philosophica</em>, 94(2): 233\u2013255.\ndoi:10.11612/resphil.1535",
                "Horty, John F., 2001, <em>Agency and Deontic Logic</em>,\nOxford/New York: Oxford University Press.\ndoi:10.1093/0195134613.001.0001",
                "Howson, Colin, 1992, \u201cDutch Book Arguments and\nConsistency\u201d, <em>PSA: Proceedings of the Biennial Meeting of\nthe Philosophy of Science Association</em>, 1992(2): 161\u2013168.\ndoi:10.1086/psaprocbienmeetp.1992.2.192832",
                "\u2013\u2013\u2013, 2000, <em>Hume\u2019s Problem: Induction\nand the Justification of Belief</em>, Oxford: Clarendon Press.",
                "Howson, Colin and Peter Urbach, 2006, <em>Scientific Reasoning:\nThe Bayesian Approach</em>, third edition, Chicago: Open Court. First\nedition, 1989.",
                "Huber, Franz, 2018, <em>A Logical Introduction to Probability and\nInduction</em>, New York: Oxford University Press.",
                "Huemer, Michael, 2016, \u201cSerious Theories and Skeptical\nTheories: Why You Are Probably Not a Brain in a Vat\u201d,\n<em>Philosophical Studies</em>, 173(4): 1031\u20131052.\ndoi:10.1007/s11098-015-0539-5",
                "Hume, David, 1748/1777 [2008], <em>An Enquiry Concerning Human\nUnderstanding</em>, London. Last edition corrected by the author,\n1777. 1777 edition reprinted, Peter Millican (ed.), (Oxford\nWorld\u2019s Classics), New York/Oxford: Oxford University Press.\n",
                "Huttegger, Simon M., 2015, \u201cMerging of Opinions and\nProbability Kinematics\u201d, <em>The Review of Symbolic Logic</em>,\n8(4): 611\u2013648. doi:10.1017/S1755020315000180",
                "\u2013\u2013\u2013, 2017a, \u201cInductive Learning in Small\nand Large Worlds\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 95(1): 90\u2013116. doi:10.1111/phpr.12232",
                "\u2013\u2013\u2013, 2017b, <em>The Probabilistic Foundations of\nRational Learning</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/9781316335789",
                "Ivanova, Milena, 2021, <em>Duhem and Holism</em>, Cambridge:\nCambridge University Press. doi:10.1017/9781009004657",
                "Jaynes, Edwin T., 1957, \u201cInformation Theory and Statistical\nMechanics\u201d, <em>Physical Review</em>, 106(4): 620\u2013630.\ndoi:10.1103/PhysRev.106.620",
                "\u2013\u2013\u2013, 1968, \u201cPrior Probabilities\u201d,\n<em>IEEE Transactions on Systems Science and Cybernetics</em>, 4(3):\n227\u2013241. doi:10.1109/TSSC.1968.300117",
                "\u2013\u2013\u2013, 1973, \u201cThe Well-Posed Problem\u201d,\n<em>Foundations of Physics</em>, 3(4): 477\u2013492.\ndoi:10.1007/BF00709116",
                "Jeffrey, Richard C., 1965 [1983], <em>The Logic of Decision</em>,\n(McGraw-Hill Series in Probability and Statistics), New York:\nMcGraw-Hill. Second edition, Chicago: University of Chicago Press,\n1983.",
                "\u2013\u2013\u2013, 1970, \u201cDracula Meets Wolfman:\nAcceptance vs. Partial Belief\u201d, in <em>Induction, Acceptance and\nRational Belief</em>, Marshall Swain (ed.), Dordrecht: Springer\nNetherlands, 157\u2013185. doi:10.1007/978-94-010-3390-9_8",
                "\u2013\u2013\u2013, 1983, \u201cBayesianism with a Human\nFace\u201d, in Earman 1983: 133\u2013156.\n [<a href=\"https://conservancy.umn.edu/handle/11299/185349\" target=\"other\">Jeffrey 1983 available online</a>]",
                "\u2013\u2013\u2013, 1986, \u201cProbabilism and\nInduction\u201d, <em>Topoi</em>, 5(1): 51\u201358.\ndoi:10.1007/BF00137829",
                "Jeffreys, Harold, 1939, <em>Theory of Probability</em>, Oxford:\nOxford University Press.",
                "\u2013\u2013\u2013, 1946, \u201cAn Invariant Form for the\nPrior Probability in Estimation Problems\u201d, <em>Proceedings of\nthe Royal Society of London. Series A. Mathematical and Physical\nSciences</em>, 186(1007): 453\u2013461.\ndoi:10.1098/rspa.1946.0056",
                "Joyce, James M., 1998, \u201cA Nonpragmatic Vindication of\nProbabilism\u201d, <em>Philosophy of Science</em>, 65(4):\n575\u2013603. doi:10.1086/392661",
                "\u2013\u2013\u2013, 1999, <em>The Foundations of Causal\nDecision Theory</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511498497",
                "\u2013\u2013\u2013, 2003 [2021], \u201cBayes\u2019\nTheorem\u201d, <em>The Stanford Encyclopedia of Philosophy</em> (Fall\n2021 edition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/fall2021/entries/bayes-theorem/\" target=\"other\">https://plato.stanford.edu/archives/fall2021/entries/bayes-theorem/</a>&gt;",
                "\u2013\u2013\u2013, 2005, \u201cHow Probabilities Reflect\nEvidence\u201d, <em>Philosophical Perspectives</em>, 19(1):\n153\u2013178. doi:10.1111/j.1520-8583.2005.00058.x",
                "\u2013\u2013\u2013, 2011, \u201cThe Development of Subjective\nBayesianism\u201d, in Gabbay, Hartmann, and Woods 2011:\n415\u2013475. doi:10.1016/B978-0-444-52936-7.50012-4",
                "Kaplan, David, 1989, \u201cDemonstratives. An Essay on the\nSemantics, Logic, Metaphysics, and Epistemology of Demonstratives and\nOther Indexicals\u201d, in <em>Themes from Kaplan</em>, Joseph Almog,\nJohn Perry, and Howard Wettstein (eds.), New York: Oxford University\nPress, 481\u2013563.",
                "Kass, Robert E. and Larry Wasserman, 1996, \u201cThe Selection of\nPrior Distributions by Formal Rules\u201d, <em>Journal of the\nAmerican Statistical Association</em>, 91(435): 1343\u20131370.",
                "Kelly, Kevin T., 1996, <em>The Logic of Reliable Inquiry</em>,\n(Logic and Computation in Philosophy), New York: Oxford University\nPress.",
                "\u2013\u2013\u2013, 2000, \u201cThe Logic of Success\u201d,\n<em>The British Journal for the Philosophy of Science</em>, 51(S1):\n639\u2013666. doi:10.1093/bjps/51.4.639",
                "Kelly, Kevin T., and Clark Glymour, 2004, \u201cWhy Probability\nDoes Not Capture the Logic of Scientific Justification\u201d, in\nHitchcock 2004: 94\u2013114.",
                "Kemeny, John G., 1955, \u201cFair Bets and Inductive\nProbabilities\u201d, <em>Journal of Symbolic Logic</em>, 20(3):\n263\u2013273. doi:10.2307/2268222",
                "Keynes, John Maynard, 1921, <em>A Treatise on Probability</em>,\nLondon: Macmillan.",
                "Klein, Peter and Ted A. Warfield, 1994, \u201cWhat Price\nCoherence?\u201d, <em>Analysis</em>, 54(3): 129\u2013132.\ndoi:10.1093/analys/54.3.129",
                "Kolmogorov, A. N., 1933, <em>Grundbegriffe der\nWahrscheinlichkeitsrechnung</em>, Berlin: Springer. Translated as\n<em>Foundations of the Theory of Probability</em>, Nathan Morrison\n(ed.), New York: Chelsea, 1950. Second English edition with an added\nbibliography by A.T. Bharucha-Reid, New York: Chelsea, 1956. Second\nedition reprinted Mineola, NY: Dover, 2018. ",
                "Konek, Jason, 2019, \u201cComparative Probabilities\u201d, in\nPettigrew and Weisberg 2019: 267\u2013348.",
                "\u2013\u2013\u2013, forthcoming, \u201cThe Art of\nLearning\u201d, in <em>Oxford Studies in Epistemology, Volume 7</em>,\nOxford: Oxford University Press.",
                "Kopec, Matthew and Michael G. Titelbaum, 2016, \u201cThe\nUniqueness Thesis\u201d, <em>Philosophy Compass</em>, 11(4):\n189\u2013200. doi:10.1111/phc3.12318",
                "Laplace, Pierre Simon, 1814 [1902], <em>Essai philosophique sur\nles probabilit\u00e9s</em>, Paris: Mme. Ve. Courcier. Translated as\n<em>A Philosophical Essay on Probabilities</em>, Frederick Wilson\nTruscott and Frederick Lincoln Emory (trans.), New York: J. Wiley,\n1902.",
                "Levi, Isaac, 1980, <em>The Enterprise of Knowledge: An Essay on\nKnowledge, Credal Probability, and Chance</em>, Cambridge, MA: MIT\nPress.",
                "Lewis, David, 1980, \u201cA Subjectivist\u2019s Guide to\nObjective Chance\u201d, in <em>Studies in Inductive Logic and\nProbability, Volume 2</em>, R.C. Jeffrey (ed.), Berkeley, CA:\nUniversity of California Press, 263\u2013293. Reprinted in\nLewis\u2019s <em>Philosophical Papers, Volume 2</em>, Oxford: Oxford\nUniversity Press, 1986, ch. 19.",
                "\u2013\u2013\u2013, 1999, \u201cWhy Conditionalize?\u201d, in\nhis <em>Papers in Metaphysics and Epistemology</em>, Cambridge:\nCambridge University Press, 403\u2013407.",
                "\u2013\u2013\u2013, 2001, \u201cSleeping Beauty: Reply to\nElga\u201d, <em>Analysis</em>, 61(3): 171\u2013176.\ndoi:10.1093/analys/61.3.171",
                "Lin, Hanti, 2013, \u201cFoundations of Everyday Practical\nReasoning\u201d, <em>Journal of Philosophical Logic</em>, 42(6):\n831\u2013862. doi:10.1007/s10992-013-9296-0",
                "\u2013\u2013\u2013, forthcoming, \u201cModes of Convergence to\nthe Truth: Steps toward a Better Epistemology of Induction\u201d,\n<em>The Review of Symbolic Logic</em>, first online: 3 January 2022.\ndoi:10.1017/S1755020321000605",
                "Lipton, Peter, 2004, <em>Inference to the Best Explanation</em>,\nsecond edition, (International Library of Philosophy), London/New\nYork: Routledge/Taylor and Francis Group.",
                "Magnus, P. D. and Craig Callender, 2004, \u201cRealist Ennui and\nthe Base Rate Fallacy\u201d, <em>Philosophy of Science</em>, 71(3):\n320\u2013338. doi:10.1086/421536",
                "Maher, Patrick, 1992, \u201cDiachronic Rationality\u201d,\n<em>Philosophy of Science</em>, 59(1): 120\u2013141.\ndoi:10.1086/289657",
                "\u2013\u2013\u2013, 2004, \u201cProbability Captures the Logic\nof Scientific Confirmation\u201d, in Hitchcock 2004:\n69\u201393.",
                "Mahtani, Anna, 2019, \u201cImprecise Probabilities\u201d, in\nPettigrew and Weisberg 2019: 107\u2013130.",
                "Meacham, Chris J.G., 2010, \u201cUnravelling the Tangled Web:\nContinuity, Internalism, Non-uniqueness and Self-Locating\nBeliefs\u201d, in Gendler and Hawthorne 2010: 86\u2013125.",
                "\u2013\u2013\u2013, 2015, \u201cUnderstanding\nConditionalization\u201d, <em>Canadian Journal of Philosophy</em>,\n45(5\u20136): 767\u2013797. doi:10.1080/00455091.2015.1119611",
                "\u2013\u2013\u2013, 2016, \u201cUr-Priors, Conditionalization,\nand Ur-Prior Conditionalization\u201d, <em>Ergo, an Open Access\nJournal of Philosophy</em>, 3: art. 17.\ndoi:10.3998/ergo.12405314.0003.017",
                "Morey, Richard D., Jan-Willem Romeijn, and Jeffrey N. Rouder,\n2013, \u201cThe Humble Bayesian: Model Checking from a Fully Bayesian\nPerspective\u201d, <em>British Journal of Mathematical and\nStatistical Psychology</em>, 66(1): 68\u201375.\ndoi:10.1111/j.2044-8317.2012.02067.x",
                "Moss, Sarah, 2012, \u201cUpdating as Communication\u201d,\n<em>Philosophy and Phenomenological Research</em>, 85(2):\n225\u2013248. doi:10.1111/j.1933-1592.2011.00572.x",
                "\u2013\u2013\u2013, 2013, \u201cEpistemology\nFormalized\u201d, <em>Philosophical Review</em>, 122(1): 1\u201343.\ndoi:10.1215/00318108-1728705",
                "\u2013\u2013\u2013, 2018, <em>Probabilistic Knowledge</em>,\nOxford, United Kingdom: Oxford University Press.\ndoi:10.1093/oso/9780198792154.001.0001",
                "Niiniluoto, Ilkka, 1983, \u201cNovel Facts and\nBayesianism\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 34(4): 375\u2013379. doi:10.1093/bjps/34.4.375",
                "Okasha, Samir, 2000, \u201cVan Fraassen\u2019s Critique of\nInference to the Best Explanation\u201d, <em>Studies in History and\nPhilosophy of Science Part A</em>, 31(4): 691\u2013710.\ndoi:10.1016/S0039-3681(00)00016-9",
                "Peijnenburg, Jeanne, 2007, \u201cInfinitism Regained\u201d,\n<em>Mind</em>, 116(463): 597\u2013602. doi:10.1093/mind/fzm597",
                "Peirce, Charles Sanders, 1877, \u201cThe Fixation of\nBelief\u201d, <em>Popular Science Monthly</em>, 12: 1\u201315.\nReprinted in 1955, <em>Philosophical Writings of Peirce</em>, Justus\nBuchler (ed.), Dover Publications, 5\u201322.",
                "\u2013\u2013\u2013, 1903, \u201cThe Three Normative\nSciences\u201d, fifth Harvard lecture on pragmatism delivered 30\nApril 1903. Reprinted in 1998, <em>The Essential Peirce, Vol. 2\n(1893\u20131913)</em>, The Peirce Edition Project (ed.), Bloomington,\nIN: Indiana University Press, 196\u2013207 (ch. 14).",
                "Pettigrew, Richard, 2012, \u201cAccuracy, Chance, and the\nPrincipal Principle\u201d, <em>Philosophical Review</em>, 121(2):\n241\u2013275. doi:10.1215/00318108-1539098",
                "\u2013\u2013\u2013, 2016, <em>Accuracy and the Laws of\nCredence</em>, Oxford, United Kingdom: Oxford University Press.\ndoi:10.1093/acprof:oso/9780198732716.001.0001",
                "\u2013\u2013\u2013, 2020a, <em>Dutch Book Arguments</em>,\nCambridge: Cambridge University Press. doi:10.1017/9781108581813",
                "\u2013\u2013\u2013, 2020b, \u201cWhat Is Conditionalization,\nand Why Should We Do It?\u201d, <em>Philosophical Studies</em>,\n177(11): 3427\u20133463. doi:10.1007/s11098-019-01377-y",
                "Pettigrew, Richard and Jonathan Weisberg (eds), 2019, <em>The Open\nHandbook of Formal Epistemology</em>, PhilPapers Foundation.\n [<a href=\"https://philpapers.org/rec/PETTOH-2\" target=\"other\">Pettigrew and Weisberg (eds) 2019 available online</a>]",
                "Pollock, John L., 2006, <em>Thinking about Acting: Logical\nFoundations for Rational Decision Making</em>, Oxford/New York: Oxford\nUniversity Press.",
                "Popper, Karl R., 1959, <em>The Logic of Scientific Discovery</em>,\nNew York: Basic Books. Reprinted, London: Routledge, 1992.",
                "Putnam, Hilary, 1963, \u201cProbability and Confirmation\u201d,\n<em>The Voice of America Forum Lectures, Philosophy of Science\nSeries</em>, No. 10, Washington, D.C.: United States Information\nAgency, pp. 1\u201311. Reprinted in his <em>Mathematics, Matter, and\nMethod</em>, London/New York: Cambridge University Press, 1975,\n293\u2013304.",
                "Quine, W. V., 1951, \u201cMain Trends in Recent Philosophy: Two\nDogmas of Empiricism\u201d, <em>The Philosophical Review</em>, 60(1):\n20\u201343. doi:10.2307/2181906",
                "Ramsey, Frank Plumpton, 1926 [1931], \u201cTruth and\nProbability\u201d, manuscript. Printed in <em>Foundations of\nMathematics and Other Logical Essays</em>, R.B. Braithwaite (ed.),\nLondon: Kegan, Paul, Trench, Trubner &amp; Co. Ltd., 1931,\n156\u2013198.",
                "Rawls, John, 1971, <em>A Theory of Justice</em>, Cambridge, MA:\nHarvard University Press. Revised edition 1999.",
                "Reichenbach, Hans, 1938, <em>Experience and Prediction: An\nAnalysis of the Foundations and the Structure of Knowledge</em>,\nChicago: The University of Chicago Press.",
                "R\u00e9nyi, Alfr\u00e9d, 1970, <em>Foundations of\nProbability</em>, San Francisco: Holden-Day.",
                "Rescorla, Michael, 2015, \u201cSome Epistemological Ramifications\nof the Borel\u2013Kolmogorov Paradox\u201d, <em>Synthese</em>, 192:\n735\u2013767. doi:10.1007/s11229-014-0586-z",
                "\u2013\u2013\u2013, 2018, \u201cA Dutch Book Theorem and\nConverse Dutch Book Theorem for Kolmogorov Conditionalization\u201d,\n<em>The Review of Symbolic Logic</em>, 11(4): 705\u2013735.\ndoi:10.1017/S1755020317000296",
                "\u2013\u2013\u2013, 2021, \u201cOn the Proper Formulation of\nConditionalization\u201d, <em>Synthese</em>, 198(3): 1935\u20131965.\ndoi:10.1007/s11229-019-02179-9",
                "Rosenkrantz, Roger D., 1981, <em>Foundations and Applications of\nInductive Probability</em>, Atascadero, CA: Ridgeview.",
                "\u2013\u2013\u2013, 1983, \u201cWhy Glymour Is a\nBayesian\u201d, in Earman 1983: 69\u201397.\n [<a href=\"https://conservancy.umn.edu/handle/11299/185351\" target=\"other\">Rosenkrantz 1983 available online</a>]",
                "Salmon, Wesley C., 1990, \u201cRationality and Objectivity in\nScience or Tom Kuhn Meets Tom Bayes\u201d, in <em>Scientific\nTheories</em> (Minnesota Studies in the Philosophy of Science, 14), C.\nW. Savage (ed.), Minneapolis, MN: University of Minnesota Press,\n175\u2013205.",
                "Savage, Leonard J., 1972, <em>The Foundations of Statistics</em>,\nsecond revised edtion, New York: Dover Publications.",
                "Schoenfield, Miriam, 2014, \u201cPermission to Believe: Why\nPermissivism Is True and What It Tells Us About Irrelevant Influences\non Belief\u201d, <em>No\u00fbs</em>, 48(2): 193\u2013218.\ndoi:10.1111/nous.12006",
                "Schroeder, Mark, 2011, \u201cOught, Agents, and Actions\u201d,\n<em>Philosophical Review</em>, 120(1): 1\u201341.\ndoi:10.1215/00318108-2010-017",
                "Schupbach, Jonah N., 2018, \u201cTroubles for Bayesian Formal\nEpistemology? A Response to Horgan\u201d, <em>Res Philosophica</em>,\n95(1): 189\u2013197. doi:10.11612/resphil.1652",
                "Seidenfeld, Teddy, 1979, \u201cWhy I Am Not an Objective\nBayesian; Some Reflections Prompted by Rosenkrantz\u201d, <em>Theory\nand Decision</em>, 11(4): 413\u2013440. doi:10.1007/BF00139451",
                "\u2013\u2013\u2013, 2001, \u201cRemarks on the Theory of\nConditional Probability: Some Issues of Finite Versus Countable\nAdditivity\u201d, in <em>Probability Theory: Philosophy, Recent\nHistory and Relations to Science</em>, Vincent F. Hendricks, Stig\nAndur Pedersen, and Klaus Frovin J\u00f8rgensen (eds.), (Synthese\nLibrary 297), Dordrecht/Boston: Kluwer Academic Publishers,\n167\u2013178.",
                "Shimony, Abner, 1955, \u201cCoherence and the Axioms of\nConfirmation\u201d, <em>Journal of Symbolic Logic</em>, 20(1):\n1\u201328. doi:10.2307/2268039",
                "\u2013\u2013\u2013, 1970, \u201cScientific Inference\u201d,\nin <em>The Nature and Function of Scientific Theories</em> (Pittsburgh\nStudies in the Philosophy of Science, 4), Robert G. Colodny (ed.),\nPittsburgh, PA: University of Pittsburgh Press, 79\u2013172.",
                "Shogenji, Tomoji, 2018, <em>Formal Epistemology and Cartesian\nSkepticism: In Defense of Belief in the Natural World</em>, (Routledge\nStudies in Contemporary Philosophy 101), New York: Routledge, Taylor\n&amp; Francis Group.",
                "Skyrms, Brian, 1966 [2000], <em>Choice and Chance: An Introduction\nto Inductive Logic</em>, Belmont, CA: Dickenson. Fourth edition,\nBelmont, CA: Wadsworth, 2000.",
                "\u2013\u2013\u2013, 1984, <em>Pragmatics and Empiricism</em>,\nNew Haven, CT: Yale University Press.",
                "Smith, Cedric A. B., 1961, \u201cConsistency in Statistical\nInference and Decision\u201d, <em>Journal of the Royal Statistical\nSociety: Series B (Methodological)</em>, 23(1): 1\u201325.\ndoi:10.1111/j.2517-6161.1961.tb00388.x",
                "Sober, Elliott, 2002, \u201cBayesianism\u2014Its Scope and\nLimits\u201d, in <em>Bayes\u2019s Theorem</em> (Proceedings of the\nBritish Academy, 113), Richard Swinburne (ed.), Oxford: Oxford\nUniversity Press.",
                "\u2013\u2013\u2013, 2008, <em>Evidence and Evolution: The Logic\nbehind the Science</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511806285",
                "Sprenger, Jan, 2015, \u201cA Novel Solution to the Problem of Old\nEvidence\u201d, <em>Philosophy of Science</em>, 82(3): 383\u2013401.\ndoi:10.1086/681767",
                "\u2013\u2013\u2013, 2018, \u201cThe Objectivity of Subjective\nBayesianism\u201d, <em>European Journal for Philosophy of\nScience</em>, 8(3): 539\u2013558. doi:10.1007/s13194-018-0200-1",
                "Sprenger, Jan and Stephan Hartmann, 2019, <em>Bayesian Philosophy\nof Science: Variations on a Theme by the Reverend Thomas Bayes</em>,\nOxford/New York: Oxford University Press.\ndoi:10.1093/oso/9780199672110.001.0001",
                "Staffel, Julia, 2019, <em>Unsettled Thoughts: A Theory of Degrees\nof Rationality</em>, Oxford/New York: Oxford University Press.\ndoi:10.1093/oso/9780198833710.001.0001",
                "Stalnaker, Robert C., 1970, \u201cProbability and\nConditionals\u201d, <em>Philosophy of Science</em>, 37(1):\n64\u201380. doi:10.1086/288280",
                "Stef\u00e1nsson, H. Orri, 2017, \u201cWhat Is\n\u2018Real\u2019 in Probabilism?\u201d, <em>Australasian Journal of\nPhilosophy</em>, 95(3): 573\u2013587.\ndoi:10.1080/00048402.2016.1224906",
                "Strevens, Michael, 2001, \u201cThe Bayesian Treatment of\nAuxiliary Hypotheses\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, 52(3): 515\u2013537.\ndoi:10.1093/bjps/52.3.515",
                "Talbott, William J., 1991, \u201cTwo Principles of Bayesian\nEpistemology\u201d, <em>Philosophical Studies</em>, 62(2):\n135\u2013150. doi:10.1007/BF00419049",
                "\u2013\u2013\u2013, 2016, \u201cA Non-Probabilist Principle of\nHigher-Order Reasoning\u201d, <em>Synthese</em>, 193(10):\n3099\u20133145. doi:10.1007/s11229-015-0922-y",
                "Tang, Weng Hong, 2016, \u201cReliability Theories of Justified\nCredence\u201d, <em>Mind</em>, 125(497): 63\u201394.\ndoi:10.1093/mind/fzv199",
                "Teller, Paul, 1973, \u201cConditionalization and\nObservation\u201d, <em>Synthese</em>, 26(2): 218\u2013258.\ndoi:10.1007/BF00873264",
                "Titelbaum, Michael G., 2013a, <em>Quitting Certainties: A Bayesian\nFramework Modeling Degrees of Belief</em>, Oxford: Oxford University\nPress. doi:10.1093/acprof:oso/9780199658305.001.0001",
                "\u2013\u2013\u2013, 2013b, \u201cTen Reasons to Care About the\nSleeping Beauty Problem\u201d, <em>Philosophy Compass</em>, 8(11):\n1003\u20131017. doi:10.1111/phc3.12080",
                "\u2013\u2013\u2013, 2016, \u201cSelf-Locating\nCredences\u201d, in <em>The Oxford Handbook of Probability and\nPhilosophy</em>, Alan H\u00e1jek, and Christopher Hitchcock (eds),\nOxford: Oxford University Press, p. 666\u2013680.",
                "\u2013\u2013\u2013, forthcoming, <em>Fundamentals of Bayesian\nEpistemology</em>, Oxford University Press.",
                "van Fraassen, Bas C., 1984, \u201cBelief and the Will\u201d,\n<em>The Journal of Philosophy</em>, 81(5): 235\u2013256.\ndoi:10.2307/2026388",
                "\u2013\u2013\u2013, 1988, \u201cThe Problem of Old\nEvidence\u201d, in <em>Philosophical Analysis</em>, David F. Austin\n(ed.), Dordrecht: Springer Netherlands, 153\u2013165.\ndoi:10.1007/978-94-009-2909-8_10",
                "\u2013\u2013\u2013, 1989, <em>Laws and Symmetry</em>,\nOxford/New York: Oxford University Press.\ndoi:10.1093/0198248601.001.0001",
                "\u2013\u2013\u2013, 1995, \u201cBelief and the Problem of\nUlysses and the Sirens\u201d, <em>Philosophical Studies</em>, 77(1):\n7\u201337. doi:10.1007/BF00996309",
                "Vassend, Olav Benjamin, forthcoming, \u201cJustifying the Norms\nof Inductive Inference\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, first online: 17 December 2020.\ndoi:10.1093/bjps/axz041",
                "von Mises, Richard, 1928 [1981], <em>Wahrscheinlichkeit,\nStatistik, und Wahrheit</em>, J. Springer; third German edition, 1951.\nThird edition translated as <em>Probability, Statistics, and\nTruth</em>, second revised edition, Hilda Geiringer (trans.), London:\nGeorge Allen &amp; Unwin, 1951. Reprinted New York: Dover, 1981.",
                "Walley, Peter, 1991, <em>Statistical Reasoning with Imprecise\nProbabilities</em>, London: Chapman and Hall.",
                "Wasserman, Larry, 1998, \u201cAsymptotic Properties of\nNonparametric Bayesian Procedures\u201d, in <em>Practical\nNonparametric and Semiparametric Bayesian Statistics</em>, Dipak Dey,\nPeter M\u00fcller, and Debajyoti Sinha (eds.), (Lecture Notes in\nStatistics 133), New York: Springer New York, 293\u2013304.\ndoi:10.1007/978-1-4612-1732-9_16",
                "Weatherson, Brian, 2007, \u201cThe Bayesian and the\nDogmatist\u201d, <em>Proceedings of the Aristotelian Society\n(Hardback)</em>, 107(1pt2): 169\u2013185.\ndoi:10.1111/j.1467-9264.2007.00217.x",
                "Wedgwood, Ralph, 2006, \u201cThe Meaning of \u2018Ought\u2019\n\u201d, <em>Oxford Studies in Metaethics, Volume 1</em>, Russ\nShafer-Landau (ed.), Oxford: Clarendon Press, 127\u2013160.",
                "\u2013\u2013\u2013, 2014, \u201cRationality as a Virtue:\nRationality as a Virtue\u201d, <em>Analytic Philosophy</em>, 55(4):\n319\u2013338. doi:10.1111/phib.12055",
                "Weisberg, Jonathan, 2007, \u201cConditionalization, Reflection,\nand Self-Knowledge\u201d, <em>Philosophical Studies</em>, 135(2):\n179\u2013197. doi:10.1007/s11098-007-9073-4",
                "\u2013\u2013\u2013, 2009a, \u201cLocating IBE in the Bayesian\nFramework\u201d, <em>Synthese</em>, 167(1): 125\u2013143.\ndoi:10.1007/s11229-008-9305-y",
                "\u2013\u2013\u2013, 2009b, \u201cCommutativity or Holism? A\nDilemma for Conditionalizers\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, 60(4): 793\u2013812.\ndoi:10.1093/bjps/axp007",
                "\u2013\u2013\u2013, 2011, \u201cVarieties of\nBayesianism\u201d, in Gabbay, Hartmann, and Woods 2011:\n477\u2013551. doi:10.1016/B978-0-444-52936-7.50013-6",
                "Wenmackers, Sylvia, 2019, \u201cInfinitesimal\nProbabilities\u201d, in Pettigrew and Weisberg 2019:\n199\u2013265.",
                "Wenmackers, Sylvia and Jan-Willem Romeijn, 2016, \u201cNew Theory\nabout Old Evidence: A Framework for Open-Minded Bayesianism\u201d,\n<em>Synthese</em>, 193(4): 1225\u20131250.\ndoi:10.1007/s11229-014-0632-x",
                "White, Roger, 2006, \u201cProblems for Dogmatism\u201d,\n<em>Philosophical Studies</em>, 131(3): 525\u2013557.\ndoi:10.1007/s11098-004-7487-9",
                "\u2013\u2013\u2013, 2010, \u201cEvidential Symmetry and Mushy\nCredence\u201d, in Gendler and Hawthorne 2010: 161\u2013186.",
                "Williamson, Jon, 1999, \u201cCountable Additivity and Subjective\nProbability\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 50(3): 401\u2013416. doi:10.1093/bjps/50.3.401",
                "\u2013\u2013\u2013, 2010, <em>In Defence of Objective\nBayesianism</em>, Oxford/New York: Oxford University Press.\ndoi:10.1093/acprof:oso/9780199228003.001.0001",
                "Williamson, Timothy, 2007, \u201cHow Probable Is an Infinite\nSequence of Heads?\u201d, <em>Analysis</em>, 67(3): 173\u2013180.\ndoi:10.1093/analys/67.3.173",
                "\u2013\u2013\u2013, 2017, \u201cModel-Building in\nPhilosophy\u201d, in <em>Philosophy\u2019s Future: The Problem of\nPhilosophical Progress</em>, Russell Blackford and Damien Broderick\n(eds.), Hoboken, NJ: Wiley, 159\u2013171.\ndoi:10.1002/9781119210115.ch12",
                "Yalcin, Seth, 2012, \u201cBayesian Expressivism\u201d,\n<em>Proceedings of the Aristotelian Society (Hardback)</em>,\n112(2pt2): 123\u2013160. doi:10.1111/j.1467-9264.2012.00329.x",
                "Zynda, Lyle, 1996, \u201cCoherence as an Ideal of\nRationality\u201d, <em>Synthese</em>, 109(2): 175\u2013216.\ndoi:10.1007/BF00413767"
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Adler, Jonathan, 2006 [2017], \u201cEpistemological Problems of\nTestimony\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2017 Edition), Edward N. Zalta (ed.), first written 2006. URL\n=\n &lt;<a href=\"https://plato.stanford.edu/archives/win2017/entries/testimony-episprob/\" target=\"other\">https://plato.stanford.edu/archives/win2017/entries/testimony-episprob/</a>&gt;.</li>\n<li>Armendt, Brad, 1980, \u201cIs There a Dutch Book Argument for\nProbability Kinematics?\u201d, <em>Philosophy of Science</em>, 47(4):\n583\u2013588. doi:10.1086/288958</li>\n<li>Arntzenius, Frank, 2003, \u201cSome Problems for\nConditionalization and Reflection\u201d, <em>Journal of\nPhilosophy</em>, 100(7): 356\u2013370.\ndoi:10.5840/jphil2003100729</li>\n<li>Bacchus, Fahiem, Henry E. Kyburg Jr, and Mariam Thalos, 1990,\n\u201cAgainst Conditionalization\u201d, <em>Synthese</em>, 85(3):\n475\u2013506. doi:10.1007/BF00484837</li>\n<li>Baron, Jonathan, 2004, \u201cNormative Models of Judgment and\nDecision Making\u201d, in <em>Blackwell Handbook of Judgment and\nDecision Making</em>, Derek J. Koehler and Nigel Harvey (eds.),\nLondon: Blackwell, 19\u201336.</li>\n<li>\u2013\u2013\u2013, 2012, \u201cThe Point of Normative Models\nin Judgment and Decision Making\u201d, <em>Frontiers in\nPsychology</em>, 3: art. 577. doi:10.3389/fpsyg.2012.00577</li>\n<li>Bartha, Paul, 2004, \u201cCountable Additivity and the de Finetti\nLottery\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 55(2): 301\u2013321. doi:10.1093/bjps/55.2.301</li>\n<li>Bayes, Thomas, 1763, \u201cAn Essay Towards Solving a Problem in\nthe Doctrine of Chances\u201d, <em>Philosophical Transactions of the\nRoyal Society of London</em>, 53: 370\u2013418. Reprinted 1958,\n<em>Biometrika</em>, 45(3\u20134): 296\u2013315, with G. A.\nBarnard\u2019s \u201cThomas Bayes: A Biographical Note\u201d,\n<em>Biometrika</em>, 45(3\u20134): 293\u2013295.\ndoi:10.1098/rstl.1763.0053 doi:10.1093/biomet/45.3-4.296\ndoi:10.1093/biomet/45.3-4.293 (note)</li>\n<li>Belot, Gordon, 2013, \u201cBayesian Orgulity\u201d,\n<em>Philosophy of Science</em>, 80(4): 483\u2013503.\ndoi:10.1086/673249</li>\n<li>Berger, James, 2006, \u201cThe Case for Objective Bayesian\nAnalysis\u201d, <em>Bayesian Analysis</em>, 1(3): 385\u2013402.\ndoi:10.1214/06-BA115</li>\n<li>Blackwell, David and Lester Dubins, 1962, \u201cMerging of\nOpinions with Increasing Information\u201d, <em>The Annals of\nMathematical Statistics</em>, 33(3): 882\u2013886.\ndoi:10.1214/aoms/1177704456</li>\n<li>Bovens, Luc and Stephan Hartmann, 2004, <em>Bayesian\nEpistemology</em>, Oxford: Oxford University Press.\ndoi:10.1093/0199269750.001.0001</li>\n<li>Briggs, R.A., 2019, \u201cConditionals\u201d, in Pettigrew and\nWeisberg 2019: 543\u2013590.</li>\n<li>Briggs, R.A. and Richard Pettigrew, 2020, \u201cAn\nAccuracy-Dominance Argument for Conditionalization\u201d,\n<em>No\u00fbs</em>, 54(1): 162\u2013181. doi:10.1111/nous.12258</li>\n<li>Broome, John, 1999, \u201cNormative Requirements\u201d,\n<em>Ratio</em>, 12(4): 398\u2013419. doi:10.1111/1467-9329.00101</li>\n<li>Carnap, Rudolf, 1945, \u201cOn Inductive Logic\u201d,\n<em>Philosophy of Science</em>, 12(2): 72\u201397.\ndoi:10.1086/286851</li>\n<li>\u2013\u2013\u2013, 1955, \u201cStatistical and Inductive\nProbability and Inductive Logic and Science\u201d (leaflet),\nBrooklyn, NY: Galois Institute of Mathematics and Art.</li>\n<li>\u2013\u2013\u2013, 1963, \u201cReplies and Systematic\nExpositions\u201d, in <em>The Philosophy of Rudolf Carnap</em>, Paul\nArthur Schilpp (ed.), La Salle, IL: Open Court, 859\u20131013.</li>\n<li>Casta\u00f1eda, Hector-Neri, 1970, \u201cOn the Semantics of\nthe Ought-to-Do\u201d, <em>Synthese</em>, 21(3\u20134):\n449\u2013468. doi:10.1007/BF00484811</li>\n<li>Christensen, David, 1996, \u201cDutch-Book Arguments\nDepragmatized: Epistemic Consistency For Partial Believers\u201d,\n<em>Journal of Philosophy</em>, 93(9): 450\u2013479.\ndoi:10.2307/2940893</li>\n<li>\u2013\u2013\u2013, 2004, <em>Putting Logic in Its Place:\nFormal Constraints on Rational Belief</em>, Oxford: Oxford University\nPress. doi:10.1093/0199263256.001.0001</li>\n<li>de Bona, Glauber and Julia Staffel, 2018, \u201cWhy Be\n(Approximately) Coherent?\u201d, <em>Analysis</em>, 78(3):\n405\u2013415. doi:10.1093/analys/anx159</li>\n<li>de Finetti, Bruno, 1937, <em>\u201cLa Pr\u00e9vision: Ses Lois\nLogiques, Ses Sources Subjectives\u201d</em>, <em>Annales de\nl\u2019institut Henri Poincar\u00e9</em>, 7(1):1\u201368.\nTranslated as \u201cForesight: its Logical Laws, its Subjective\nSources\u201d, Henry E. .Kyburg, Jr. (trans.), in <em>Studies in\nSubjective Probability</em>, Henry Ely Kyburg and Henry Edward Smokler\n(eds), New York: Wiley, 1964, 97\u2013158. Second edition,\nHuntington: Robert Krieger, 1980, 53\u2013118.</li>\n<li>\u2013\u2013\u2013, 1970 [1974], <em>Teoria delle\nprobabilit\u00e0</em>, Torino: G. Einaudi. Translated as <em>Theory\nof Probability</em>, two volumes, Antonio Machi and Adrian Smith\n(trans), New York: John Wiley, 1974.</li>\n<li>Diaconis, Persi and David Freedman, 1986a, \u201cOn the\nConsistency of Bayes Estimates\u201d, <em>The Annals of\nStatistics</em>, 14(1): 1\u201326. doi:10.1214/aos/1176349830</li>\n<li>\u2013\u2013\u2013, 1986b, \u201cRejoinder: On the Consistency\nof Bayes Estimates\u201d, <em>The Annals of Statistics</em>, 14(1):\n63\u201367. doi:10.1214/aos/1176349842</li>\n<li>Dorling, Jon, 1979, \u201cBayesian Personalism, the Methodology\nof Scientific Research Programmes, and Duhem\u2019s Problem\u201d,\n<em>Studies in History and Philosophy of Science Part A</em>, 10(3):\n177\u2013187. doi:10.1016/0039-3681(79)90006-2</li>\n<li>Dorst, Kevin, 2020, \u201cEvidence: A Guide for the\nUncertain\u201d, <em>Philosophy and Phenomenological Research</em>,\n100(3): 586\u2013632. doi:10.1111/phpr.12561</li>\n<li>Duhem, Pierre, 1906 [1954], <em>La th\u00e9orie physique: son\nobjet et sa structure</em>, Paris: Chevalier &amp; Rivi\u00e8re.\nTranslated as <em>The Aim and Structure of Physical Theory</em>,\nPhilip P. Wiener (trans.), Princeton, NJ: Princeton University Press,\n1954.</li>\n<li>Dunn, Jeff, 2015, \u201cReliability for Degrees of Belief\u201d,\n<em>Philosophical Studies</em>, 172(7): 1929\u20131952.\ndoi:10.1007/s11098-014-0380-2</li>\n<li>Earman, John (ed.), 1983, <em>Testing Scientific Theories</em>,\n(Minnesota Studies in the Philosophy of Science 10), Minneapolis, MN:\nUniversity of Minnesota Press.</li>\n<li>\u2013\u2013\u2013, 1992, <em>Bayes or Bust? A Critical\nExamination of Bayesian Confirmation Theory</em>, Cambridge, MA: MIT\nPress.</li>\n<li>Easwaran, Kenny, 2011, \u201cBayesianism I: Introduction and\nArguments in Favor\u201d, <em>Philosophy Compass</em>, 6(5):\n312\u2013320. doi:10.1111/j.1747-9991.2011.00399.x</li>\n<li>\u2013\u2013\u2013, 2013, \u201cWhy Countable\nAdditivity?\u201d, <em>Thought: A Journal of Philosophy</em>, 2(1):\n53\u201361. doi:10.1002/tht3.60</li>\n<li>\u2013\u2013\u2013, 2014, \u201cRegularity and Hyperreal\nCredences\u201d, <em>Philosophical Review</em>, 123(1): 1\u201341.\ndoi:10.1215/00318108-2366479</li>\n<li>\u2013\u2013\u2013, 2019, \u201cConditional\nProbabilities\u201d, in Pettigrew and Weisberg 2019:\n131\u2013198.</li>\n<li>Eder, Anna-Maria, forthcoming, \u201cEvidential Probabilities and\nCredences\u201d, <em>The British Journal for the Philosophy of\nScience</em>, first online: 24 December 2020.\ndoi:10.1093/bjps/axz043</li>\n<li>Elga, Adam, 2000, \u201cSelf-Locating Belief and the Sleeping\nBeauty Problem\u201d, <em>Analysis</em>, 60(2): 143\u2013147.\ndoi:10.1093/analys/60.2.143</li>\n<li>Elliott-Graves, Alkistis and Michael Weisberg, 2014,\n\u201cIdealization\u201d, <em>Philosophy Compass</em>, 9(3):\n176\u2013185. doi:10.1111/phc3.12109</li>\n<li>Elqayam, Shira and Jonathan St. B. T. Evans, 2013,\n\u201cRationality in the New Paradigm: Strict versus Soft Bayesian\nApproaches\u201d, <em>Thinking &amp; Reasoning</em>, 19(3\u20134):\n453\u2013470. doi:10.1080/13546783.2013.834268</li>\n<li>Elqayam, Shira and David E. Over, 2013, \u201cNew Paradigm\nPsychology of Reasoning: An Introduction to the Special Issue Edited\nby Elqayam, Bonnefon, and Over\u201d, <em>Thinking &amp;\nReasoning</em>, 19(3\u20134): 249\u2013265.\ndoi:10.1080/13546783.2013.841591</li>\n<li>Eriksson, Lina and Alan H\u00e1jek, 2007, \u201cWhat Are\nDegrees of Belief?\u201d, <em>Studia Logica</em>, 86(2):\n183\u2013213. doi:10.1007/s11225-007-9059-4</li>\n<li>Eva, Benjamin, 2019, \u201cPrinciples of Indifference\u201d,\n<em>The Journal of Philosophy</em>, 116(7): 390\u2013411.\ndoi:10.5840/jphil2019116724</li>\n<li>Eva, Benjamin and Stephan Hartmann, 2020, \u201cOn the Origins of\nOld Evidence\u201d, <em>Australasian Journal of Philosophy</em>,\n98(3): 481\u2013494. doi:10.1080/00048402.2019.1658210</li>\n<li>Fienberg, Stephen E., 2006, \u201cWhen Did Bayesian Inference\nBecome \u2018Bayesian\u2019?\u201d, <em>Bayesian Analysis</em>,\n1(1): 1\u201340. doi:10.1214/06-BA101</li>\n<li>Fishburn, Peter C., 1986, \u201cThe Axioms of Subjective\nProbability\u201d, <em>Statistical Science</em>, 1(3): 335\u2013345.\ndoi:10.1214/ss/1177013611</li>\n<li>Fitelson, Branden, 2006, \u201cInductive Logic\u201d, in <em>The\nPhilosophy of Science: An Encyclopedia</em>, Sahotra Sarkar and\nJessica Pfeifer (eds), New York: Routledge, 384\u2013394.</li>\n<li>Fitelson, Branden and Andrew Waterman, 2005, \u201cBayesian\nConfirmation and Auxiliary Hypotheses Revisited: A Reply to\nStrevens\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 56(2): 293\u2013302. doi:10.1093/bjps/axi117</li>\n<li>Foley, Richard, 1992, <em>Working without a Net: A Study of\nEgocentric Epistemology</em>, New York: Oxford University Press.</li>\n<li>Forster, Malcolm R., 1995, \u201cBayes and Bust: Simplicity as a\nProblem for a Probabilist\u2019s Approach to Confirmation\u201d,\n<em>The British Journal for the Philosophy of Science</em>, 46(3):\n399\u2013424. doi:10.1093/bjps/46.3.399</li>\n<li>Forster, Malcolm and Elliott Sober, 1994, \u201cHow to Tell When\nSimpler, More Unified, or Less <i>Ad Hoc</i> Theories Will Provide\nMore Accurate Predictions\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, 45(1): 1\u201335.\ndoi:10.1093/bjps/45.1.1</li>\n<li>Freedman, David A., 1963, \u201cOn the Asymptotic Behavior of\nBayes\u2019 Estimates in the Discrete Case\u201d, <em>The Annals of\nMathematical Statistics</em>, 34(4): 1386\u20131403.\ndoi:10.1214/aoms/1177703871</li>\n<li>Gabbay, Dov M., Stephan Hartman, and John Woods (eds), 2011,\n<em>Handbook of the History of Logic, Volume 10: Inductive Logic</em>,\nBoston: Elsevier. </li>\n<li>Gaifman, Haim, 1986, \u201c A Theory of Higher Order\nProbabilities\u201d, <em>Proceedings of the 1986 Conference on\nTheoretical Aspects of Reasoning about Knowledge</em>, San Francisco:\nMorgan Kaufmann Publishers, 275\u2013292.</li>\n<li>Gaifman, Haim and Marc Snir, 1982, \u201cProbabilities over Rich\nLanguages, Testing and Randomness\u201d, <em>Journal of Symbolic\nLogic</em>, 47(3): 495\u2013548. doi:10.2307/2273587</li>\n<li>Garber, Daniel, 1983, \u201cOld Evidence and Logical Omniscience\nin Bayesian Confirmation Theory\u201d, in Earman 1983: 99\u2013131.\n [<a href=\"https://hdl.handle.net/11299/185350\" target=\"other\">Garber 1983 available online</a>]</li>\n<li>Gelman, Andrew, John B. Carlin, Hal Steven Stern, David B. Dunson,\nAki Vehtari, and Donald B. Rubin, 2014, <em>Bayesian Data\nAnalysis</em>, third edition, (Chapman &amp; Hall/CRC Texts in\nStatistical Science), Boca Raton, FL: CRC Press.</li>\n<li>Gelman, Andrew and Christian Hennig, 2017, \u201cBeyond\nSubjective and Objective in Statistics\u201d, <em>Journal of the\nRoyal Statistical Society: Series A (Statistics in Society)</em>,\n180(4): 967\u20131033. Includes discussions of the paper.\ndoi:10.1111/rssa.12276</li>\n<li>Gendler, Tamar Szabo and John Hawthorne (eds), 2010, <em>Oxford\nStudies in Epistemology, Volume 3</em>, Oxford: Oxford University\nPress.</li>\n<li>Gillies, Donald, 2000, <em>Philosophical Theories of\nProbability</em>, (Philosophical Issues in Science), London/New York:\nRoutledge.</li>\n<li>Glymour, Clark N., 1980, \u201cWhy I Am Not a Bayesian\u201d, in\nhis <em>Theory and Evidence</em>, Princeton, NJ: Princeton University\nPress.</li>\n<li>Good, Irving John, 1976, \u201cThe Bayesian Influence, or How to\nSweep Subjectivism under the Carpet\u201d, in <em>Foundations of\nProbability Theory, Statistical Inference, and Statistical Theories of\nScience</em>, William Leonard Harper and Clifford Alan Hooker (eds.),\nDordrecht: Springer Netherlands, 125\u2013174. Reprinted in his\n<em>Good Thinking: The Foundations of Probability and Its\nApplications</em>, Minneapolis, MN: University of Minnesota Press,\n22\u201358. doi:10.1007/978-94-010-1436-6_5</li>\n<li>Goodman, Nelson, 1955, <em>Fact, Fiction, and Forecast</em>,\nCambridge, MA: Harvard University Press.</li>\n<li>Greaves, Hilary and David Wallace, 2006, \u201cJustifying\nConditionalization: Conditionalization Maximizes Expected Epistemic\nUtility\u201d, <em>Mind</em>, 115(459): 607\u2013632.\ndoi:10.1093/mind/fzl607</li>\n<li>Griffiths, Thomas L., Charles Kemp, and Joshua B. Tenenbaum, 2008,\n\u201cBayesian Models of Cognition\u201d, in <em>The Cambridge\nHandbook of Computational Psychology</em>, Ron Sun (ed.), Cambridge:\nCambridge University Press, 59\u2013100.\ndoi:10.1017/CBO9780511816772.006</li>\n<li>Hacking, Ian, 1967, \u201cSlightly More Realistic Personal\nProbability\u201d, <em>Philosophy of Science</em>, 34(4):\n311\u2013325. doi:10.1086/288169</li>\n<li>\u2013\u2013\u2013, 2001, <em>An Introduction to Probability\nand Inductive Logic</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511801297</li>\n<li>\u2013\u2013\u2013, 2016, <em>Logic of Statistical\nInference</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9781316534960</li>\n<li>H\u00e1jek, Alan, 2003, \u201cWhat Conditional Probability\nCould Not Be\u201d, <em>Synthese</em>, 137(3): 273\u2013323.\ndoi:10.1023/B:SYNT.0000004904.91112.16</li>\n<li>\u2013\u2013\u2013, 2009, \u201cDutch Book Arguments\u201d,\nin <em>The Handbook of Rational and Social Choice</em>, Paul Anand,\nPrasanta Pattanaik, and Clemens Puppe (eds.), New York: Oxford\nUniversity Press, 173\u2013195.\ndoi:10.1093/acprof:oso/9780199290420.003.0008</li>\n<li>\u2013\u2013\u2013, 2012, \u201cIs Strict Coherence\nCoherent?\u201d, <em>Dialectica</em>, 66(3): 411\u2013424.\ndoi:10.1111/j.1746-8361.2012.01310.x</li>\n<li>H\u00e1jek, Alan and Hanti Lin, 2017, \u201cA Tale of Two\nEpistemologies?\u201d, <em>Res Philosophica</em>, 94(2):\n207\u2013232.</li>\n<li>Harman, Gilbert, 1986, <em>Change in View: Principles of\nReasoning</em>, Cambridge, MA: MIT Press.</li>\n<li>Harsanyi, John C., 1985, \u201cAcceptance of Empirical\nStatements: A Bayesian Theory without Cognitive Utilities\u201d,\n<em>Theory and Decision</em>, 18(1): 1\u201330.</li>\n<li>Harper, William L., 1976, \u201cRational Conceptual\nChange\u201d, <em>PSA: Proceedings of the Biennial Meeting of the\nPhilosophy of Science Association</em>, 1976(2): 462\u2013494.\ndoi:10.1086/psaprocbienmeetp.1976.2.192397</li>\n<li>\u2013\u2013\u2013, 1978, \u201cBayesian Learning Models with\nRevision of Evidence\u201d, <em>Philosophia</em>, 7(2):\n357\u2013367. doi:10.1007/BF02378821</li>\n<li>Hartmann, Stephan and Branden Fitelson, 2015, \u201cA New\nGarber-Style Solution to the Problem of Old Evidence\u201d,\n<em>Philosophy of Science</em>, 82(4): 712\u2013717.\ndoi:10.1086/682916</li>\n<li>Haverkamp, Nick and Moritz Schulz, 2012, \u201cA Note on\nComparative Probability\u201d, <em>Erkenntnis</em>, 76(3):\n395\u2013402. doi:10.1007/s10670-011-9307-x</li>\n<li>Heckerman, David, 1996 [2008], \u201cA Tutorial on Learning with\nBayesian Networks\u201d. Technical Report MSR-TR-95-06, Redmond, WA:\nMicrosoft Research. Reprinted in <em>Innovations in Bayesian Networks:\nTheory and Applications</em>, Dawn E. Holmes and Lakhmi C. Jain\n(eds.), (Studies in Computational Intelligence, 156),\nBerlin/Heidelberg: Springer Berlin Heidelberg, 2008, 33\u201382.\ndoi:10.1007/978-3-540-85066-3_3</li>\n<li>Hedden, Brian, 2015a, \u201cTime-Slice Rationality\u201d,\n<em>Mind</em>, 124(494): 449\u2013491. doi:10.1093/mind/fzu181</li>\n<li>\u2013\u2013\u2013, 2015b, <em>Reasons without Persons:\nRationality, Identity, and Time</em>, Oxford/New York: Oxford\nUniversity Press. doi:10.1093/acprof:oso/9780198732594.001.0001</li>\n<li>Henderson, Leah, 2014, \u201cBayesianism and Inference to the\nBest Explanation\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 65(4): 687\u2013715. doi:10.1093/bjps/axt020</li>\n<li>Hitchcock, Christopher (ed.), 2004, <em>Contemporary Debates in\nPhilosophy of Science</em>, (Contemporary Debates in Philosophy 2),\nMalden, MA: Blackwell.</li>\n<li>Horgan, Terry, 2017, \u201cTroubles for Bayesian Formal\nEpistemology\u201d, <em>Res Philosophica</em>, 94(2): 233\u2013255.\ndoi:10.11612/resphil.1535</li>\n<li>Horty, John F., 2001, <em>Agency and Deontic Logic</em>,\nOxford/New York: Oxford University Press.\ndoi:10.1093/0195134613.001.0001</li>\n<li>Howson, Colin, 1992, \u201cDutch Book Arguments and\nConsistency\u201d, <em>PSA: Proceedings of the Biennial Meeting of\nthe Philosophy of Science Association</em>, 1992(2): 161\u2013168.\ndoi:10.1086/psaprocbienmeetp.1992.2.192832</li>\n<li>\u2013\u2013\u2013, 2000, <em>Hume\u2019s Problem: Induction\nand the Justification of Belief</em>, Oxford: Clarendon Press.</li>\n<li>Howson, Colin and Peter Urbach, 2006, <em>Scientific Reasoning:\nThe Bayesian Approach</em>, third edition, Chicago: Open Court. First\nedition, 1989.</li>\n<li>Huber, Franz, 2018, <em>A Logical Introduction to Probability and\nInduction</em>, New York: Oxford University Press.</li>\n<li>Huemer, Michael, 2016, \u201cSerious Theories and Skeptical\nTheories: Why You Are Probably Not a Brain in a Vat\u201d,\n<em>Philosophical Studies</em>, 173(4): 1031\u20131052.\ndoi:10.1007/s11098-015-0539-5</li>\n<li>Hume, David, 1748/1777 [2008], <em>An Enquiry Concerning Human\nUnderstanding</em>, London. Last edition corrected by the author,\n1777. 1777 edition reprinted, Peter Millican (ed.), (Oxford\nWorld\u2019s Classics), New York/Oxford: Oxford University Press.\n</li>\n<li>Huttegger, Simon M., 2015, \u201cMerging of Opinions and\nProbability Kinematics\u201d, <em>The Review of Symbolic Logic</em>,\n8(4): 611\u2013648. doi:10.1017/S1755020315000180</li>\n<li>\u2013\u2013\u2013, 2017a, \u201cInductive Learning in Small\nand Large Worlds\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 95(1): 90\u2013116. doi:10.1111/phpr.12232</li>\n<li>\u2013\u2013\u2013, 2017b, <em>The Probabilistic Foundations of\nRational Learning</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/9781316335789</li>\n<li>Ivanova, Milena, 2021, <em>Duhem and Holism</em>, Cambridge:\nCambridge University Press. doi:10.1017/9781009004657</li>\n<li>Jaynes, Edwin T., 1957, \u201cInformation Theory and Statistical\nMechanics\u201d, <em>Physical Review</em>, 106(4): 620\u2013630.\ndoi:10.1103/PhysRev.106.620</li>\n<li>\u2013\u2013\u2013, 1968, \u201cPrior Probabilities\u201d,\n<em>IEEE Transactions on Systems Science and Cybernetics</em>, 4(3):\n227\u2013241. doi:10.1109/TSSC.1968.300117</li>\n<li>\u2013\u2013\u2013, 1973, \u201cThe Well-Posed Problem\u201d,\n<em>Foundations of Physics</em>, 3(4): 477\u2013492.\ndoi:10.1007/BF00709116</li>\n<li>Jeffrey, Richard C., 1965 [1983], <em>The Logic of Decision</em>,\n(McGraw-Hill Series in Probability and Statistics), New York:\nMcGraw-Hill. Second edition, Chicago: University of Chicago Press,\n1983.</li>\n<li>\u2013\u2013\u2013, 1970, \u201cDracula Meets Wolfman:\nAcceptance vs. Partial Belief\u201d, in <em>Induction, Acceptance and\nRational Belief</em>, Marshall Swain (ed.), Dordrecht: Springer\nNetherlands, 157\u2013185. doi:10.1007/978-94-010-3390-9_8</li>\n<li>\u2013\u2013\u2013, 1983, \u201cBayesianism with a Human\nFace\u201d, in Earman 1983: 133\u2013156.\n [<a href=\"https://conservancy.umn.edu/handle/11299/185349\" target=\"other\">Jeffrey 1983 available online</a>]</li>\n<li>\u2013\u2013\u2013, 1986, \u201cProbabilism and\nInduction\u201d, <em>Topoi</em>, 5(1): 51\u201358.\ndoi:10.1007/BF00137829</li>\n<li>Jeffreys, Harold, 1939, <em>Theory of Probability</em>, Oxford:\nOxford University Press.</li>\n<li>\u2013\u2013\u2013, 1946, \u201cAn Invariant Form for the\nPrior Probability in Estimation Problems\u201d, <em>Proceedings of\nthe Royal Society of London. Series A. Mathematical and Physical\nSciences</em>, 186(1007): 453\u2013461.\ndoi:10.1098/rspa.1946.0056</li>\n<li>Joyce, James M., 1998, \u201cA Nonpragmatic Vindication of\nProbabilism\u201d, <em>Philosophy of Science</em>, 65(4):\n575\u2013603. doi:10.1086/392661</li>\n<li>\u2013\u2013\u2013, 1999, <em>The Foundations of Causal\nDecision Theory</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511498497</li>\n<li>\u2013\u2013\u2013, 2003 [2021], \u201cBayes\u2019\nTheorem\u201d, <em>The Stanford Encyclopedia of Philosophy</em> (Fall\n2021 edition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/fall2021/entries/bayes-theorem/\" target=\"other\">https://plato.stanford.edu/archives/fall2021/entries/bayes-theorem/</a>&gt;</li>\n<li>\u2013\u2013\u2013, 2005, \u201cHow Probabilities Reflect\nEvidence\u201d, <em>Philosophical Perspectives</em>, 19(1):\n153\u2013178. doi:10.1111/j.1520-8583.2005.00058.x</li>\n<li>\u2013\u2013\u2013, 2011, \u201cThe Development of Subjective\nBayesianism\u201d, in Gabbay, Hartmann, and Woods 2011:\n415\u2013475. doi:10.1016/B978-0-444-52936-7.50012-4</li>\n<li>Kaplan, David, 1989, \u201cDemonstratives. An Essay on the\nSemantics, Logic, Metaphysics, and Epistemology of Demonstratives and\nOther Indexicals\u201d, in <em>Themes from Kaplan</em>, Joseph Almog,\nJohn Perry, and Howard Wettstein (eds.), New York: Oxford University\nPress, 481\u2013563.</li>\n<li>Kass, Robert E. and Larry Wasserman, 1996, \u201cThe Selection of\nPrior Distributions by Formal Rules\u201d, <em>Journal of the\nAmerican Statistical Association</em>, 91(435): 1343\u20131370.</li>\n<li>Kelly, Kevin T., 1996, <em>The Logic of Reliable Inquiry</em>,\n(Logic and Computation in Philosophy), New York: Oxford University\nPress.</li>\n<li>\u2013\u2013\u2013, 2000, \u201cThe Logic of Success\u201d,\n<em>The British Journal for the Philosophy of Science</em>, 51(S1):\n639\u2013666. doi:10.1093/bjps/51.4.639</li>\n<li>Kelly, Kevin T., and Clark Glymour, 2004, \u201cWhy Probability\nDoes Not Capture the Logic of Scientific Justification\u201d, in\nHitchcock 2004: 94\u2013114.</li>\n<li>Kemeny, John G., 1955, \u201cFair Bets and Inductive\nProbabilities\u201d, <em>Journal of Symbolic Logic</em>, 20(3):\n263\u2013273. doi:10.2307/2268222</li>\n<li>Keynes, John Maynard, 1921, <em>A Treatise on Probability</em>,\nLondon: Macmillan.</li>\n<li>Klein, Peter and Ted A. Warfield, 1994, \u201cWhat Price\nCoherence?\u201d, <em>Analysis</em>, 54(3): 129\u2013132.\ndoi:10.1093/analys/54.3.129</li>\n<li>Kolmogorov, A. N., 1933, <em>Grundbegriffe der\nWahrscheinlichkeitsrechnung</em>, Berlin: Springer. Translated as\n<em>Foundations of the Theory of Probability</em>, Nathan Morrison\n(ed.), New York: Chelsea, 1950. Second English edition with an added\nbibliography by A.T. Bharucha-Reid, New York: Chelsea, 1956. Second\nedition reprinted Mineola, NY: Dover, 2018. </li>\n<li>Konek, Jason, 2019, \u201cComparative Probabilities\u201d, in\nPettigrew and Weisberg 2019: 267\u2013348.</li>\n<li>\u2013\u2013\u2013, forthcoming, \u201cThe Art of\nLearning\u201d, in <em>Oxford Studies in Epistemology, Volume 7</em>,\nOxford: Oxford University Press.</li>\n<li>Kopec, Matthew and Michael G. Titelbaum, 2016, \u201cThe\nUniqueness Thesis\u201d, <em>Philosophy Compass</em>, 11(4):\n189\u2013200. doi:10.1111/phc3.12318</li>\n<li>Laplace, Pierre Simon, 1814 [1902], <em>Essai philosophique sur\nles probabilit\u00e9s</em>, Paris: Mme. Ve. Courcier. Translated as\n<em>A Philosophical Essay on Probabilities</em>, Frederick Wilson\nTruscott and Frederick Lincoln Emory (trans.), New York: J. Wiley,\n1902.</li>\n<li>Levi, Isaac, 1980, <em>The Enterprise of Knowledge: An Essay on\nKnowledge, Credal Probability, and Chance</em>, Cambridge, MA: MIT\nPress.</li>\n<li>Lewis, David, 1980, \u201cA Subjectivist\u2019s Guide to\nObjective Chance\u201d, in <em>Studies in Inductive Logic and\nProbability, Volume 2</em>, R.C. Jeffrey (ed.), Berkeley, CA:\nUniversity of California Press, 263\u2013293. Reprinted in\nLewis\u2019s <em>Philosophical Papers, Volume 2</em>, Oxford: Oxford\nUniversity Press, 1986, ch. 19.</li>\n<li>\u2013\u2013\u2013, 1999, \u201cWhy Conditionalize?\u201d, in\nhis <em>Papers in Metaphysics and Epistemology</em>, Cambridge:\nCambridge University Press, 403\u2013407.</li>\n<li>\u2013\u2013\u2013, 2001, \u201cSleeping Beauty: Reply to\nElga\u201d, <em>Analysis</em>, 61(3): 171\u2013176.\ndoi:10.1093/analys/61.3.171</li>\n<li>Lin, Hanti, 2013, \u201cFoundations of Everyday Practical\nReasoning\u201d, <em>Journal of Philosophical Logic</em>, 42(6):\n831\u2013862. doi:10.1007/s10992-013-9296-0</li>\n<li>\u2013\u2013\u2013, forthcoming, \u201cModes of Convergence to\nthe Truth: Steps toward a Better Epistemology of Induction\u201d,\n<em>The Review of Symbolic Logic</em>, first online: 3 January 2022.\ndoi:10.1017/S1755020321000605</li>\n<li>Lipton, Peter, 2004, <em>Inference to the Best Explanation</em>,\nsecond edition, (International Library of Philosophy), London/New\nYork: Routledge/Taylor and Francis Group.</li>\n<li>Magnus, P. D. and Craig Callender, 2004, \u201cRealist Ennui and\nthe Base Rate Fallacy\u201d, <em>Philosophy of Science</em>, 71(3):\n320\u2013338. doi:10.1086/421536</li>\n<li>Maher, Patrick, 1992, \u201cDiachronic Rationality\u201d,\n<em>Philosophy of Science</em>, 59(1): 120\u2013141.\ndoi:10.1086/289657</li>\n<li>\u2013\u2013\u2013, 2004, \u201cProbability Captures the Logic\nof Scientific Confirmation\u201d, in Hitchcock 2004:\n69\u201393.</li>\n<li>Mahtani, Anna, 2019, \u201cImprecise Probabilities\u201d, in\nPettigrew and Weisberg 2019: 107\u2013130.</li>\n<li>Meacham, Chris J.G., 2010, \u201cUnravelling the Tangled Web:\nContinuity, Internalism, Non-uniqueness and Self-Locating\nBeliefs\u201d, in Gendler and Hawthorne 2010: 86\u2013125.</li>\n<li>\u2013\u2013\u2013, 2015, \u201cUnderstanding\nConditionalization\u201d, <em>Canadian Journal of Philosophy</em>,\n45(5\u20136): 767\u2013797. doi:10.1080/00455091.2015.1119611</li>\n<li>\u2013\u2013\u2013, 2016, \u201cUr-Priors, Conditionalization,\nand Ur-Prior Conditionalization\u201d, <em>Ergo, an Open Access\nJournal of Philosophy</em>, 3: art. 17.\ndoi:10.3998/ergo.12405314.0003.017</li>\n<li>Morey, Richard D., Jan-Willem Romeijn, and Jeffrey N. Rouder,\n2013, \u201cThe Humble Bayesian: Model Checking from a Fully Bayesian\nPerspective\u201d, <em>British Journal of Mathematical and\nStatistical Psychology</em>, 66(1): 68\u201375.\ndoi:10.1111/j.2044-8317.2012.02067.x</li>\n<li>Moss, Sarah, 2012, \u201cUpdating as Communication\u201d,\n<em>Philosophy and Phenomenological Research</em>, 85(2):\n225\u2013248. doi:10.1111/j.1933-1592.2011.00572.x</li>\n<li>\u2013\u2013\u2013, 2013, \u201cEpistemology\nFormalized\u201d, <em>Philosophical Review</em>, 122(1): 1\u201343.\ndoi:10.1215/00318108-1728705</li>\n<li>\u2013\u2013\u2013, 2018, <em>Probabilistic Knowledge</em>,\nOxford, United Kingdom: Oxford University Press.\ndoi:10.1093/oso/9780198792154.001.0001</li>\n<li>Niiniluoto, Ilkka, 1983, \u201cNovel Facts and\nBayesianism\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 34(4): 375\u2013379. doi:10.1093/bjps/34.4.375</li>\n<li>Okasha, Samir, 2000, \u201cVan Fraassen\u2019s Critique of\nInference to the Best Explanation\u201d, <em>Studies in History and\nPhilosophy of Science Part A</em>, 31(4): 691\u2013710.\ndoi:10.1016/S0039-3681(00)00016-9</li>\n<li>Peijnenburg, Jeanne, 2007, \u201cInfinitism Regained\u201d,\n<em>Mind</em>, 116(463): 597\u2013602. doi:10.1093/mind/fzm597</li>\n<li>Peirce, Charles Sanders, 1877, \u201cThe Fixation of\nBelief\u201d, <em>Popular Science Monthly</em>, 12: 1\u201315.\nReprinted in 1955, <em>Philosophical Writings of Peirce</em>, Justus\nBuchler (ed.), Dover Publications, 5\u201322.</li>\n<li>\u2013\u2013\u2013, 1903, \u201cThe Three Normative\nSciences\u201d, fifth Harvard lecture on pragmatism delivered 30\nApril 1903. Reprinted in 1998, <em>The Essential Peirce, Vol. 2\n(1893\u20131913)</em>, The Peirce Edition Project (ed.), Bloomington,\nIN: Indiana University Press, 196\u2013207 (ch. 14).</li>\n<li>Pettigrew, Richard, 2012, \u201cAccuracy, Chance, and the\nPrincipal Principle\u201d, <em>Philosophical Review</em>, 121(2):\n241\u2013275. doi:10.1215/00318108-1539098</li>\n<li>\u2013\u2013\u2013, 2016, <em>Accuracy and the Laws of\nCredence</em>, Oxford, United Kingdom: Oxford University Press.\ndoi:10.1093/acprof:oso/9780198732716.001.0001</li>\n<li>\u2013\u2013\u2013, 2020a, <em>Dutch Book Arguments</em>,\nCambridge: Cambridge University Press. doi:10.1017/9781108581813</li>\n<li>\u2013\u2013\u2013, 2020b, \u201cWhat Is Conditionalization,\nand Why Should We Do It?\u201d, <em>Philosophical Studies</em>,\n177(11): 3427\u20133463. doi:10.1007/s11098-019-01377-y</li>\n<li>Pettigrew, Richard and Jonathan Weisberg (eds), 2019, <em>The Open\nHandbook of Formal Epistemology</em>, PhilPapers Foundation.\n [<a href=\"https://philpapers.org/rec/PETTOH-2\" target=\"other\">Pettigrew and Weisberg (eds) 2019 available online</a>]</li>\n<li>Pollock, John L., 2006, <em>Thinking about Acting: Logical\nFoundations for Rational Decision Making</em>, Oxford/New York: Oxford\nUniversity Press.</li>\n<li>Popper, Karl R., 1959, <em>The Logic of Scientific Discovery</em>,\nNew York: Basic Books. Reprinted, London: Routledge, 1992.</li>\n<li>Putnam, Hilary, 1963, \u201cProbability and Confirmation\u201d,\n<em>The Voice of America Forum Lectures, Philosophy of Science\nSeries</em>, No. 10, Washington, D.C.: United States Information\nAgency, pp. 1\u201311. Reprinted in his <em>Mathematics, Matter, and\nMethod</em>, London/New York: Cambridge University Press, 1975,\n293\u2013304.</li>\n<li>Quine, W. V., 1951, \u201cMain Trends in Recent Philosophy: Two\nDogmas of Empiricism\u201d, <em>The Philosophical Review</em>, 60(1):\n20\u201343. doi:10.2307/2181906</li>\n<li>Ramsey, Frank Plumpton, 1926 [1931], \u201cTruth and\nProbability\u201d, manuscript. Printed in <em>Foundations of\nMathematics and Other Logical Essays</em>, R.B. Braithwaite (ed.),\nLondon: Kegan, Paul, Trench, Trubner &amp; Co. Ltd., 1931,\n156\u2013198.</li>\n<li>Rawls, John, 1971, <em>A Theory of Justice</em>, Cambridge, MA:\nHarvard University Press. Revised edition 1999.</li>\n<li>Reichenbach, Hans, 1938, <em>Experience and Prediction: An\nAnalysis of the Foundations and the Structure of Knowledge</em>,\nChicago: The University of Chicago Press.</li>\n<li>R\u00e9nyi, Alfr\u00e9d, 1970, <em>Foundations of\nProbability</em>, San Francisco: Holden-Day.</li>\n<li>Rescorla, Michael, 2015, \u201cSome Epistemological Ramifications\nof the Borel\u2013Kolmogorov Paradox\u201d, <em>Synthese</em>, 192:\n735\u2013767. doi:10.1007/s11229-014-0586-z</li>\n<li>\u2013\u2013\u2013, 2018, \u201cA Dutch Book Theorem and\nConverse Dutch Book Theorem for Kolmogorov Conditionalization\u201d,\n<em>The Review of Symbolic Logic</em>, 11(4): 705\u2013735.\ndoi:10.1017/S1755020317000296</li>\n<li>\u2013\u2013\u2013, 2021, \u201cOn the Proper Formulation of\nConditionalization\u201d, <em>Synthese</em>, 198(3): 1935\u20131965.\ndoi:10.1007/s11229-019-02179-9</li>\n<li>Rosenkrantz, Roger D., 1981, <em>Foundations and Applications of\nInductive Probability</em>, Atascadero, CA: Ridgeview.</li>\n<li>\u2013\u2013\u2013, 1983, \u201cWhy Glymour Is a\nBayesian\u201d, in Earman 1983: 69\u201397.\n [<a href=\"https://conservancy.umn.edu/handle/11299/185351\" target=\"other\">Rosenkrantz 1983 available online</a>]</li>\n<li>Salmon, Wesley C., 1990, \u201cRationality and Objectivity in\nScience or Tom Kuhn Meets Tom Bayes\u201d, in <em>Scientific\nTheories</em> (Minnesota Studies in the Philosophy of Science, 14), C.\nW. Savage (ed.), Minneapolis, MN: University of Minnesota Press,\n175\u2013205.</li>\n<li>Savage, Leonard J., 1972, <em>The Foundations of Statistics</em>,\nsecond revised edtion, New York: Dover Publications.</li>\n<li>Schoenfield, Miriam, 2014, \u201cPermission to Believe: Why\nPermissivism Is True and What It Tells Us About Irrelevant Influences\non Belief\u201d, <em>No\u00fbs</em>, 48(2): 193\u2013218.\ndoi:10.1111/nous.12006</li>\n<li>Schroeder, Mark, 2011, \u201cOught, Agents, and Actions\u201d,\n<em>Philosophical Review</em>, 120(1): 1\u201341.\ndoi:10.1215/00318108-2010-017</li>\n<li>Schupbach, Jonah N., 2018, \u201cTroubles for Bayesian Formal\nEpistemology? A Response to Horgan\u201d, <em>Res Philosophica</em>,\n95(1): 189\u2013197. doi:10.11612/resphil.1652</li>\n<li>Seidenfeld, Teddy, 1979, \u201cWhy I Am Not an Objective\nBayesian; Some Reflections Prompted by Rosenkrantz\u201d, <em>Theory\nand Decision</em>, 11(4): 413\u2013440. doi:10.1007/BF00139451</li>\n<li>\u2013\u2013\u2013, 2001, \u201cRemarks on the Theory of\nConditional Probability: Some Issues of Finite Versus Countable\nAdditivity\u201d, in <em>Probability Theory: Philosophy, Recent\nHistory and Relations to Science</em>, Vincent F. Hendricks, Stig\nAndur Pedersen, and Klaus Frovin J\u00f8rgensen (eds.), (Synthese\nLibrary 297), Dordrecht/Boston: Kluwer Academic Publishers,\n167\u2013178.</li>\n<li>Shimony, Abner, 1955, \u201cCoherence and the Axioms of\nConfirmation\u201d, <em>Journal of Symbolic Logic</em>, 20(1):\n1\u201328. doi:10.2307/2268039</li>\n<li>\u2013\u2013\u2013, 1970, \u201cScientific Inference\u201d,\nin <em>The Nature and Function of Scientific Theories</em> (Pittsburgh\nStudies in the Philosophy of Science, 4), Robert G. Colodny (ed.),\nPittsburgh, PA: University of Pittsburgh Press, 79\u2013172.</li>\n<li>Shogenji, Tomoji, 2018, <em>Formal Epistemology and Cartesian\nSkepticism: In Defense of Belief in the Natural World</em>, (Routledge\nStudies in Contemporary Philosophy 101), New York: Routledge, Taylor\n&amp; Francis Group.</li>\n<li>Skyrms, Brian, 1966 [2000], <em>Choice and Chance: An Introduction\nto Inductive Logic</em>, Belmont, CA: Dickenson. Fourth edition,\nBelmont, CA: Wadsworth, 2000.</li>\n<li>\u2013\u2013\u2013, 1984, <em>Pragmatics and Empiricism</em>,\nNew Haven, CT: Yale University Press.</li>\n<li>Smith, Cedric A. B., 1961, \u201cConsistency in Statistical\nInference and Decision\u201d, <em>Journal of the Royal Statistical\nSociety: Series B (Methodological)</em>, 23(1): 1\u201325.\ndoi:10.1111/j.2517-6161.1961.tb00388.x</li>\n<li>Sober, Elliott, 2002, \u201cBayesianism\u2014Its Scope and\nLimits\u201d, in <em>Bayes\u2019s Theorem</em> (Proceedings of the\nBritish Academy, 113), Richard Swinburne (ed.), Oxford: Oxford\nUniversity Press.</li>\n<li>\u2013\u2013\u2013, 2008, <em>Evidence and Evolution: The Logic\nbehind the Science</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511806285</li>\n<li>Sprenger, Jan, 2015, \u201cA Novel Solution to the Problem of Old\nEvidence\u201d, <em>Philosophy of Science</em>, 82(3): 383\u2013401.\ndoi:10.1086/681767</li>\n<li>\u2013\u2013\u2013, 2018, \u201cThe Objectivity of Subjective\nBayesianism\u201d, <em>European Journal for Philosophy of\nScience</em>, 8(3): 539\u2013558. doi:10.1007/s13194-018-0200-1</li>\n<li>Sprenger, Jan and Stephan Hartmann, 2019, <em>Bayesian Philosophy\nof Science: Variations on a Theme by the Reverend Thomas Bayes</em>,\nOxford/New York: Oxford University Press.\ndoi:10.1093/oso/9780199672110.001.0001</li>\n<li>Staffel, Julia, 2019, <em>Unsettled Thoughts: A Theory of Degrees\nof Rationality</em>, Oxford/New York: Oxford University Press.\ndoi:10.1093/oso/9780198833710.001.0001</li>\n<li>Stalnaker, Robert C., 1970, \u201cProbability and\nConditionals\u201d, <em>Philosophy of Science</em>, 37(1):\n64\u201380. doi:10.1086/288280</li>\n<li>Stef\u00e1nsson, H. Orri, 2017, \u201cWhat Is\n\u2018Real\u2019 in Probabilism?\u201d, <em>Australasian Journal of\nPhilosophy</em>, 95(3): 573\u2013587.\ndoi:10.1080/00048402.2016.1224906</li>\n<li>Strevens, Michael, 2001, \u201cThe Bayesian Treatment of\nAuxiliary Hypotheses\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, 52(3): 515\u2013537.\ndoi:10.1093/bjps/52.3.515</li>\n<li>Talbott, William J., 1991, \u201cTwo Principles of Bayesian\nEpistemology\u201d, <em>Philosophical Studies</em>, 62(2):\n135\u2013150. doi:10.1007/BF00419049</li>\n<li>\u2013\u2013\u2013, 2016, \u201cA Non-Probabilist Principle of\nHigher-Order Reasoning\u201d, <em>Synthese</em>, 193(10):\n3099\u20133145. doi:10.1007/s11229-015-0922-y</li>\n<li>Tang, Weng Hong, 2016, \u201cReliability Theories of Justified\nCredence\u201d, <em>Mind</em>, 125(497): 63\u201394.\ndoi:10.1093/mind/fzv199</li>\n<li>Teller, Paul, 1973, \u201cConditionalization and\nObservation\u201d, <em>Synthese</em>, 26(2): 218\u2013258.\ndoi:10.1007/BF00873264</li>\n<li>Titelbaum, Michael G., 2013a, <em>Quitting Certainties: A Bayesian\nFramework Modeling Degrees of Belief</em>, Oxford: Oxford University\nPress. doi:10.1093/acprof:oso/9780199658305.001.0001</li>\n<li>\u2013\u2013\u2013, 2013b, \u201cTen Reasons to Care About the\nSleeping Beauty Problem\u201d, <em>Philosophy Compass</em>, 8(11):\n1003\u20131017. doi:10.1111/phc3.12080</li>\n<li>\u2013\u2013\u2013, 2016, \u201cSelf-Locating\nCredences\u201d, in <em>The Oxford Handbook of Probability and\nPhilosophy</em>, Alan H\u00e1jek, and Christopher Hitchcock (eds),\nOxford: Oxford University Press, p. 666\u2013680.</li>\n<li>\u2013\u2013\u2013, forthcoming, <em>Fundamentals of Bayesian\nEpistemology</em>, Oxford University Press.</li>\n<li>van Fraassen, Bas C., 1984, \u201cBelief and the Will\u201d,\n<em>The Journal of Philosophy</em>, 81(5): 235\u2013256.\ndoi:10.2307/2026388</li>\n<li>\u2013\u2013\u2013, 1988, \u201cThe Problem of Old\nEvidence\u201d, in <em>Philosophical Analysis</em>, David F. Austin\n(ed.), Dordrecht: Springer Netherlands, 153\u2013165.\ndoi:10.1007/978-94-009-2909-8_10</li>\n<li>\u2013\u2013\u2013, 1989, <em>Laws and Symmetry</em>,\nOxford/New York: Oxford University Press.\ndoi:10.1093/0198248601.001.0001</li>\n<li>\u2013\u2013\u2013, 1995, \u201cBelief and the Problem of\nUlysses and the Sirens\u201d, <em>Philosophical Studies</em>, 77(1):\n7\u201337. doi:10.1007/BF00996309</li>\n<li>Vassend, Olav Benjamin, forthcoming, \u201cJustifying the Norms\nof Inductive Inference\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, first online: 17 December 2020.\ndoi:10.1093/bjps/axz041</li>\n<li>von Mises, Richard, 1928 [1981], <em>Wahrscheinlichkeit,\nStatistik, und Wahrheit</em>, J. Springer; third German edition, 1951.\nThird edition translated as <em>Probability, Statistics, and\nTruth</em>, second revised edition, Hilda Geiringer (trans.), London:\nGeorge Allen &amp; Unwin, 1951. Reprinted New York: Dover, 1981.</li>\n<li>Walley, Peter, 1991, <em>Statistical Reasoning with Imprecise\nProbabilities</em>, London: Chapman and Hall.</li>\n<li>Wasserman, Larry, 1998, \u201cAsymptotic Properties of\nNonparametric Bayesian Procedures\u201d, in <em>Practical\nNonparametric and Semiparametric Bayesian Statistics</em>, Dipak Dey,\nPeter M\u00fcller, and Debajyoti Sinha (eds.), (Lecture Notes in\nStatistics 133), New York: Springer New York, 293\u2013304.\ndoi:10.1007/978-1-4612-1732-9_16</li>\n<li>Weatherson, Brian, 2007, \u201cThe Bayesian and the\nDogmatist\u201d, <em>Proceedings of the Aristotelian Society\n(Hardback)</em>, 107(1pt2): 169\u2013185.\ndoi:10.1111/j.1467-9264.2007.00217.x</li>\n<li>Wedgwood, Ralph, 2006, \u201cThe Meaning of \u2018Ought\u2019\n\u201d, <em>Oxford Studies in Metaethics, Volume 1</em>, Russ\nShafer-Landau (ed.), Oxford: Clarendon Press, 127\u2013160.</li>\n<li>\u2013\u2013\u2013, 2014, \u201cRationality as a Virtue:\nRationality as a Virtue\u201d, <em>Analytic Philosophy</em>, 55(4):\n319\u2013338. doi:10.1111/phib.12055</li>\n<li>Weisberg, Jonathan, 2007, \u201cConditionalization, Reflection,\nand Self-Knowledge\u201d, <em>Philosophical Studies</em>, 135(2):\n179\u2013197. doi:10.1007/s11098-007-9073-4</li>\n<li>\u2013\u2013\u2013, 2009a, \u201cLocating IBE in the Bayesian\nFramework\u201d, <em>Synthese</em>, 167(1): 125\u2013143.\ndoi:10.1007/s11229-008-9305-y</li>\n<li>\u2013\u2013\u2013, 2009b, \u201cCommutativity or Holism? A\nDilemma for Conditionalizers\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, 60(4): 793\u2013812.\ndoi:10.1093/bjps/axp007</li>\n<li>\u2013\u2013\u2013, 2011, \u201cVarieties of\nBayesianism\u201d, in Gabbay, Hartmann, and Woods 2011:\n477\u2013551. doi:10.1016/B978-0-444-52936-7.50013-6</li>\n<li>Wenmackers, Sylvia, 2019, \u201cInfinitesimal\nProbabilities\u201d, in Pettigrew and Weisberg 2019:\n199\u2013265.</li>\n<li>Wenmackers, Sylvia and Jan-Willem Romeijn, 2016, \u201cNew Theory\nabout Old Evidence: A Framework for Open-Minded Bayesianism\u201d,\n<em>Synthese</em>, 193(4): 1225\u20131250.\ndoi:10.1007/s11229-014-0632-x</li>\n<li>White, Roger, 2006, \u201cProblems for Dogmatism\u201d,\n<em>Philosophical Studies</em>, 131(3): 525\u2013557.\ndoi:10.1007/s11098-004-7487-9</li>\n<li>\u2013\u2013\u2013, 2010, \u201cEvidential Symmetry and Mushy\nCredence\u201d, in Gendler and Hawthorne 2010: 161\u2013186.</li>\n<li>Williamson, Jon, 1999, \u201cCountable Additivity and Subjective\nProbability\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 50(3): 401\u2013416. doi:10.1093/bjps/50.3.401</li>\n<li>\u2013\u2013\u2013, 2010, <em>In Defence of Objective\nBayesianism</em>, Oxford/New York: Oxford University Press.\ndoi:10.1093/acprof:oso/9780199228003.001.0001</li>\n<li>Williamson, Timothy, 2007, \u201cHow Probable Is an Infinite\nSequence of Heads?\u201d, <em>Analysis</em>, 67(3): 173\u2013180.\ndoi:10.1093/analys/67.3.173</li>\n<li>\u2013\u2013\u2013, 2017, \u201cModel-Building in\nPhilosophy\u201d, in <em>Philosophy\u2019s Future: The Problem of\nPhilosophical Progress</em>, Russell Blackford and Damien Broderick\n(eds.), Hoboken, NJ: Wiley, 159\u2013171.\ndoi:10.1002/9781119210115.ch12</li>\n<li>Yalcin, Seth, 2012, \u201cBayesian Expressivism\u201d,\n<em>Proceedings of the Aristotelian Society (Hardback)</em>,\n112(2pt2): 123\u2013160. doi:10.1111/j.1467-9264.2012.00329.x</li>\n<li>Zynda, Lyle, 1996, \u201cCoherence as an Ideal of\nRationality\u201d, <em>Synthese</em>, 109(2): 175\u2013216.\ndoi:10.1007/BF00413767</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "abduction",
            "Bayes\u2019 Theorem",
            "belief, formal representations of",
            "conditionals",
            "confirmation",
            "decision theory",
            "disagreement",
            "Dutch book arguments",
            "epistemic utility arguments for epistemic norms",
            "epistemology, formal",
            "epistemology: social",
            "induction: problem of",
            "justification, epistemic: coherentist theories of",
            "logic: inductive",
            "logic: of belief revision",
            "prediction versus accommodation",
            "probabilities, imprecise",
            "probability, interpretations of",
            "rational choice, normative: expected utility",
            "reflective equilibrium",
            "scientific objectivity",
            "scientific realism",
            "self-doubt, epistemic",
            "skepticism",
            "statistics, philosophy of",
            "underdetermination, of scientific theories",
            "understanding"
        ],
        "entry_link": [
            {
                "../abduction/": "abduction"
            },
            {
                "../bayes-theorem/": "Bayes\u2019 Theorem"
            },
            {
                "../formal-belief/": "belief, formal representations of"
            },
            {
                "../conditionals/": "conditionals"
            },
            {
                "../confirmation/": "confirmation"
            },
            {
                "../decision-theory/": "decision theory"
            },
            {
                "../disagreement/": "disagreement"
            },
            {
                "../dutch-book/": "Dutch book arguments"
            },
            {
                "../epistemic-utility/": "epistemic utility arguments for epistemic norms"
            },
            {
                "../formal-epistemology/": "epistemology, formal"
            },
            {
                "../epistemology-social/": "epistemology: social"
            },
            {
                "../induction-problem/": "induction: problem of"
            },
            {
                "../justep-coherence/": "justification, epistemic: coherentist theories of"
            },
            {
                "../logic-inductive/": "logic: inductive"
            },
            {
                "../logic-belief-revision/": "logic: of belief revision"
            },
            {
                "../prediction-accommodation/": "prediction versus accommodation"
            },
            {
                "../imprecise-probabilities/": "probabilities, imprecise"
            },
            {
                "../probability-interpret/": "probability, interpretations of"
            },
            {
                "../rationality-normative-utility/": "rational choice, normative: expected utility"
            },
            {
                "../reflective-equilibrium/": "reflective equilibrium"
            },
            {
                "../scientific-objectivity/": "scientific objectivity"
            },
            {
                "../scientific-realism/": "scientific realism"
            },
            {
                "../epistemic-self-doubt/": "self-doubt, epistemic"
            },
            {
                "../skepticism/": "skepticism"
            },
            {
                "../statistics/": "statistics, philosophy of"
            },
            {
                "../scientific-underdetermination/": "underdetermination, of scientific theories"
            },
            {
                "../understanding/": "understanding"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemology-bayesian\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/epistemology-bayesian/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=epistemology-bayesian&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/epistemology-bayesian/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemology-bayesian": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/epistemology-bayesian/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=epistemology-bayesian&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/epistemology-bayesian/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "Strevens, Michael, 2017,\n <a href=\"http://www.strevens.org/bct/\" target=\"other\"><em>Notes on Bayesian Confirmation Theory</em></a>",
            "Weisberg, Jonathan, 2019,\n <a href=\"https://jonathanweisberg.org/vip/\" target=\"other\"><em>Odds &amp; Ends: Introducing Probability &amp; Decision with a Visual Emphasis</em></a>,\n Version 0.3 Beta, Open Access Publication.",
            "Talbott, William, \u201cBayesian Epistemology\u201d,\n<em>Stanford Encyclopedia of Philosophy</em> (Spring 2022 Edition),\nEdward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/spr2022/entries/epistemology-bayesian/\">https://plato.stanford.edu/archives/spr2022/entries/epistemology-bayesian/</a>&gt;.\n [This was the previous entry on this topic in the <em>Stanford\nEncyclopedia of Philosophy</em> \u2014 see the\n <a class=\"plain\" href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemology-bayesian\" target=\"other\">version history</a>.]"
        ],
        "listed_links": [
            {
                "http://www.strevens.org/bct/": "Notes on Bayesian Confirmation Theory"
            },
            {
                "https://jonathanweisberg.org/vip/": "Odds & Ends: Introducing Probability & Decision with a Visual Emphasis"
            },
            {
                "https://plato.stanford.edu/archives/spr2022/entries/epistemology-bayesian/": "https://plato.stanford.edu/archives/spr2022/entries/epistemology-bayesian/"
            },
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemology-bayesian": "version history"
            }
        ]
    }
}