{
    "url": "dynamic-choice",
    "title": "Dynamic Choice",
    "authorship": {
        "year": "Copyright \u00a9 2020",
        "author_text": "Chrisoula Andreou\n<andreou@philosophy.utah.edu>",
        "author_links": [
            {
                "mailto:andreou%40philosophy%2eutah%2eedu": "andreou@philosophy.utah.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2020</a> by\n\n<br/>\nChrisoula Andreou\n&lt;<a href=\"mailto:andreou%40philosophy%2eutah%2eedu\"><em>andreou<abbr title=\" at \">@</abbr>philosophy<abbr title=\" dot \">.</abbr>utah<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Mon Oct 15, 2007",
        "substantive revision Tue Oct 20, 2020"
    ],
    "preamble": "\n\nSometimes a series of choices do not serve one\u2019s concerns well\neven though each choice in the series seems perfectly well suited to\nserving one\u2019s concerns. In such cases, one has a dynamic choice\nproblem. Otherwise put, one has a problem related to the fact that\none\u2019s choices are spread out over time. There is a growing\nphilosophical literature, which crosses over into psychology and\neconomics, on the obstacles to effective dynamic choice. This\nliterature examines the challenging choice situations and problematic\npreference structures that can prompt dynamic choice problems. It also\nproposes solutions to such problems. Increasingly, familiar but\npotentially puzzling phenomena\u2014including, for example,\nself-destructive addictive behavior and dangerous environmental\ndestruction\u2014have been illuminated by dynamic choice theory. This\nsuggests that the philosophical and practical significance of dynamic\nchoice theory is quite broad.\n",
    "toc": [
        {
            "#ChalChoiSituProbPrefStruDynaChoiProb": "1. Challenging Choice Situations, Problematic Preference Structures, and Dynamic Choice Problems"
        },
        {
            "#IncoAlte": "1.1 Incommensurable Alternatives"
        },
        {
            "#TimeBiasPref": "1.2 Time-Biased Preferences"
        },
        {
            "#IntrPref": "1.3 Intransitive Preferences"
        },
        {
            "#VaguGoalOtheChalWhol": "1.4 Vague Goals and other Challenging Wholes"
        },
        {
            "#AutoBeneCase": "1.5 Autonomous Benefit Cases"
        },
        {
            "#SolvDynaChoiProb": "2. Solving Dynamic Choice Problems"
        },
        {
            "#RatiIrra": "2.1 Rational Irrationality"
        },
        {
            "#ArraExteInce": "2.2 The Arrangement of External Incentives"
        },
        {
            "#SymbUtil": "2.3 Symbolic Utility"
        },
        {
            "#PlanReso": "2.4 Plans and Resoluteness"
        },
        {
            "#SomeFamiPhenIlluDynaChoiTheo": "3. Some Familiar Phenomena Illuminated by Dynamic Choice Theory"
        },
        {
            "#ConcRema": "4. Concluding Remarks"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. Challenging Choice Situations, Problematic Preference Structures, and Dynamic Choice Problems\n\nEffective choice over time can be extremely difficult given certain\nchallenging choice situations or problematic preference structures,\nsuch as the ones described below. As will become apparent, these\nchoice situations or preference structures can prompt a series of\ndecisions that serve one\u2019s large-scale, ongoing concerns very\nbadly. (Note that, as is standard in dynamic choice theory, the\ndiscussion in this entry leaves room for non-selfish preferences and\nconcerns; it thus leaves room for the possibility that one can be\ndetermined to serve one\u2019s preferences and concerns as well as\npossible without being an egoist.)\n1.1 Incommensurable Alternatives\n\nLet us first consider situations that involve choosing between\nincommensurable alternatives.\n\nAccording to the standard conception of incommensurability explored\nextensively by philosophers such as Joseph Raz and John Broome (see,\nfor example, Raz 1986 and Broome 2000), two alternatives are\nincommensurable if neither alternative is better than the other, nor\nare the two alternatives equally good.\n\nIt might seem as though the idea of incommensurable alternatives does\nnot really make sense. For if the value of an alternative (to a\nparticular agent) is neither higher nor lower than the value of\nanother alternative, then the values of the two alternatives must, it\nseems, be equal. But this assumes that there is a common measure that\none can use to express and rank the value of every alternative; and,\nif there are incommensurable alternatives, then this assumption is\nmistaken.\n\nNow consider the following: If all alternatives were commensurable,\nthen whenever one faced two alternatives neither of which was better\nthan the other, slightly improving one of the alternatives would, it\nseems, \u2018break the tie\u2019 and render one alternative, namely\nthe improved alternative, superior. But there seem to be cases in\nwhich there are two alternatives such that (i) neither alternative is\nbetter than the other and (ii) this feature is not changed by slightly\nimproving one of the alternatives. Consider, for example, the\nfollowing case: For Kay, neither of the following alternatives is\nbetter than the other:\n\n\n(A1) going on a six-day beach vacation with her children\n\n(A2) taking a two-month oil-painting course.\n\n\nFurthermore, although the alternative\n\n(A1+) going on a seven-day beach vacation with her children\n\n\nis a slight improvement on A1, A1+ is not better than A2.\nThis scenario seems possible, and if it is, then we have a case of\nincommensurable alternatives. For, in this case, A1 is not better than\nA2, A2 is not better than A1, and yet A1 and A2 are not equally good.\nIf A1 and A2 were equally good, then an improvement on A1, such as\nA1+, would be better than A2. But, for Kay, A1+\nis not better than A2.\n\nIt is often supposed that incommensurable alternatives must be\nincomparable. But things are complicated once it is recognized that\nthere is conceptual room for two alternatives that are not comparable\nas one better than the other or as equally good (and so are\nincommensurable according the conception of incommensurability\nidentified above) to be comparable as \u2018in the same league\u2019\nor \u2018on a par,\u2019 and thus not altogether incomparable, as\nwould be the case if there were no positive relation connecting the\noverall value of each option (see Chang 2002). For the purposes of\nthis discussion, the question of whether incommensurable alternatives\nare invariably incomparable can be put aside, since the dynamic choice\nproblem that will be discussed in relation to incommensurability\napplies regardless of whether the incommensurable options at issue are\nincomparable or are instead comparable as on a par.\n\nAlthough there is still some controversy concerning the possibility of\nincommensurable alternatives (compare, for example, Raz 1997 and Regan\n1997), there is widespread agreement that we often treat\nalternatives as incommensurable. Practically speaking, determining the\nvalue of two very different alternatives in terms of a common measure,\neven if this is possible, may be too taxing. It is thus often natural\nto treat two alternatives as though they are neither equal nor one\nbetter than the other.\n\nThe existence or appearance of incommensurable alternatives can give\nrise to dynamic choice problems. Consider Abraham\u2019s case, as\ndescribed by John Broome in his work on incommensurability:\n\nGod tells Abraham to take his son Isaac to the mountain, and there\nsacrifice him. Abraham has to decide whether or not to obey. Let us\nassume this is one of those choices where the alternatives are\nincommensur[able]. The option of obeying will show submission to God,\nbut the option of disobeying will save Isaac\u2019s life. Submitting\nto God and saving the life of one\u2019s son are such different\nvalues that they cannot be weighed determinately against each other;\nthat is the assumption. Neither option is better than the other, yet\nwe also cannot say that they are equally good. (Broome 2001, 114)\n\n\nGiven that the options of submitting to God and saving Isaac are\nincommensurable (and even if they were only incommensurable as far as\na reasonable person could tell), Abraham\u2019s deciding to submit to\nGod seems rationally permissible. So it is easy to see how\nAbraham\u2019s situation might prompt him to set out for the mountain\nin order to sacrifice Isaac. But it is also easy to see how, once at\nthe foot of the mountain, Abraham might decide to turn back. For, even\nthough, as Broome puts it, \u201cturning back at the foot of the\nmountain is definitely worse than never having set out at all\u201d\nsince \u201ctrust between father and son [has already been] badly\ndamaged\u201d (2001, 115), the option of saving Isaac by turning back\nand the option of submitting to God and sacrificing Isaac may be\nincommensurable. This becomes apparent if one recalls Kay\u2019s case\nand labels Abraham\u2019s above-mentioned options as follows:\n\n\n(B1) saving Isaac by turning back at the foot of the mountain\n\n(B1+) saving Isaac by refusing to set out for the\nmountain\n\n(B2) submitting to God and sacrificing Isaac.\n\n\nEven though B1+ is better than B1, both B1+ and\nB1 may be incommensurable with B2. But if B1 is incommensurable with\nB2, then Abraham could, once at the foot of the mountain, easily\ndecide to opt for B1 over B2. Given that B1 is worse than\nB1+, Abraham could thus easily end up with an outcome that\nis worse than another that was available to him, even if each of his\nchoices makes sense given the value of the alternatives he faces.\n\nThe moral, in general terms, is that in cases of incommensurability\n(or cases in which it is tempting to treat two alternatives as\nincommensurable), decisions that seem individually defensible can,\nwhen combined, result in a series of decisions that fit together very\npoorly relative to the agent\u2019s large-scale, ongoing\nconcerns.\n1.2 Time-Biased Preferences\n\nAnother source of dynamic choice problems is present-biased\npreferences.\n\nLike other animals, humans give more weight to present satisfaction\nthan to future satisfaction. In other words, we discount future\nutility. Insofar as one discounts future utility, one prefers, other\nthings equal, to get a reward sooner rather than later; relatedly, the\ncloser one gets to a future reward, the more the reward is valued. If\nwe map the value (to a particular agent) of a given future reward as a\nfunction of time, we get a discount curve, such as in Figure 1:\n\n\n\nFigure 1. The discounted value of a\nreward gradually increases as t, the time at which the reward\nwill be available, approaches.\n\n\nResearch in experimental psychology (see, for example, Kirby &\nHerrnstein 1995, Millar & Navarick 1984, Solnick et al. 1980, and\nAinslie 2001) suggests that, given how animals, including humans,\ndiscount future utility, there are plenty of cases in which the\ndiscount curves from two rewards, one a small reward and the other a\nlarger later reward, cross, as in Figure 2:\n\n\n\nFigure 2. Two crossing discount curves,\none tracking the discounted value of a small reward that will be\navailable at t1 and the other tracking the\ndiscounted value of a large reward that will be available at\nt2.\n\n\nIn such cases, the agent\u2019s discounting of future utility induces\na preference reversal with respect to the two possible rewards. When\nneither reward is imminent, before the discount curves cross, the\nagent consistently prefers the larger later reward over the smaller\nearlier reward. But when the opportunity to accept the small reward is\nsufficiently close, the discounted value of the small reward catches\nup with and then overtakes the discounted value of the larger later\nreward. As the discount curves cross, the agent\u2019s preferences\nreverse and she prefers the small reward over the larger later\nreward.\n\nDiscounting-induced preference reversals make consistent and efficient\nchoice over time a challenge. An agent subject to discounting-induced\npreference reversals can easily find herself performing a series of\nactions she planned against and will soon regret. Consider the agent\nwho wants to save for a decent retirement but, as each opportunity to\nsave approaches, prefers to spend her potential retirement\ncontribution on just one more trivial indulgence before finally\ntightening her belt for the sake of the future satisfaction she feels\nis essential to her well-being. Though this agent consistently plans\nto save for her retirement, her plans can be consistently thwarted by\nher discounting-induced preference reversals. Her life may thus end up\nlooking very different from the sort of life she wanted.\n\nInterestingly, in addition to giving more weight to present\nsatisfaction than to future satisfaction, human beings also seem to\ngive more weight to future satisfaction than to past satisfaction.\nRelatedly, human beings seem to discount past pain more than future\npain. Suppose, to appeal to a variation on Derek Parfit\u2019s famous\nthought experiment (1984, 165\u20136), your situation is such that\neither you\u2019ve already suffered a perfectly safe but terribly\npainful ten-hour medical procedure yesterday or else you will suffer a\nperfectly safe but terribly painful nine-hour medical procedure\ntomorrow. (You don\u2019t know which situation you\u2019re in\nbecause amnesia is administered right after the procedure and\nyou\u2019ve just woken up in the hospital confused about whether\nyou\u2019re recovering from the procedure or being prepped for it.)\nWouldn\u2019t you prefer to be in the former situation? Intuitively,\nit seems like the prevailing and rational response would be\n\u201cmost definitely!\u201d But there is some concern that this\nform of future bias, in which past rewards or costs are discounted\nmore than future rewards or costs, can lead to trouble (Dougherty\n2011; Greene and Sullivan 2015). For example, Preston Greene and\nMeghan Sullivan (2015) argue that it can be a recipe for a life of\n\u201cmeager returns\u201d and/or regret. Their reasoning is quite\nelaborate, but the following simple illustration and somewhat\nextemporized analysis, will hopefully provide a glimpse into some of\nthe interesting philosophical issues at stake. Consider Massimo, who\nthoroughly enjoys massages and who can choose between a longer massage\nearly on or a shorter massage later. If Massimo is future biased,\nthen, with some variation on the length and timing of the massages, he\ncan easily find himself faced with the following dilemma: if he opts\nfor getting a longer massage early on, he will, sometime after getting\nthe longer massage and before the shorter massage would have been\navailable, regret accepting a pleasure, now past, that could have\nstill been in the future (even if diminished); if, alternatively, he\nopts for getting a shorter massage later on (thus avoiding regret of\nthe preceding sort), he will face a life of \u201cmeager\nreturns,\u201d in which less pleasure later is, potentially\nroutinely, chosen over more pleasure earlier (a scenario that can\nitself generate regret and/or concern, particularly once both massage\ntimes are past, or if one recognizes, even as one is gladly awaiting a\nlesser pleasure after giving up a greater pleasure that would now have\nbeen in the past, that, insofar as the same sort of choice has arisen\nrepeatedly and will continue to arise repeatedly, repeated choices for\nless pleasure later make for a life that is both retrospectively and\nprospectively much less appealing than repeated choices for more\npleasure early on).\n1.3 Intransitive Preferences\n\nAn agent\u2019s preference structure need not be changing over time\nfor it to prompt dynamic choice problems. Such problems can also be\nprompted by preferences that are stable but intransitive.\n\nOne\u2019s preferences count as transitive if they satisfy the\nfollowing condition: for all x, y, and z,\nif one prefers x to y, and y to z,\nthen one also prefers x to z. If one\u2019s\npreferences over a set of options do not satisfy this condition, then\nthese preferences count as intransitive. When one\u2019s preferences\nover a set of options are intransitive, then one cannot rank the\noptions from most preferred to least preferred. This holds even if\none\u2019s preferences over the options are complete, in the sense\nthat all the options are ranked with respect to one another. Suppose,\nfor example, that one prefers job A to job B, job\nB to job C, but job C to job A. In\nthis case, one\u2019s complete preferences over the set {job\nA, job B, job C} form a preference loop,\nwhich can be represented as follows:\n\n\n\nFigure 3.\n\n\nwhere x > y is to be read as x is\npreferred to y.\n\nCould an agent really have intransitive preferences? Work\u00a0in\nexperimental and theoretical economics (see, for example,\u00a0Tversky\n1969) suggests that intransitive preferences exist and may\nbe\u00a0quite common. Consideration of the following situation might\nhelp make it clear how intransitive preferences can arise (whether or\nnot they are rational). Suppose Jay can accept one of three jobs: job\nA is very stimulating but low-paying; job B is\nsomewhat stimulating and pays decently; job C is not\nstimulating but pays very well. Given this situation, one can imagine\nJay having the following preferences: He prefers job A over\njob B because the difference between having a low-paying job\nand a decently-paying job is not significant enough to make Jay want\nto pass up a very stimulating job. Similarly, he prefers job\nB over job C because the difference between having a\ndecently-paying job and a high-paying job is not significant enough to\nmake Jay want to pass up a stimulating job. But he prefers job\nC over job A because the difference between having a\nhigh-paying job and a low-paying job is significant enough to make Jay\nwant to pass up even a very stimulating job.\n\nGiven the famous \u201cmoney pump argument,\u201d developed by\nDonald Davidson, J. McKinsey, and Patrick Suppes (1955), it is clear\nthat intransitive preferences can be problematic. Like Dutch book\narguments regarding betting, in which the rationality of an agent is\nput into question because the agent is susceptible to having a book\nmade against her (i.e., to accepting a series of bets which are such\nthat she is bound to lose more than she can gain), the money-pump\nargument is concerned with agents who are vulnerable to making a\ncombination of choices that lead to a sure loss. According to the\nmoney-pump argument, intransitive preferences are irrational because\nthey can prompt an agent to accept a series of trade offers that\nleaves the agent with the same option he began with, but with less\nmoney. Here is a case of the relevant sort. Suppose that Alex has the\nfollowing intransitive preferences: he prefers owning a computer of\ntype A to owning a computer of type B, owning a\ncomputer of type B to owning a computer of type C,\nand owning a computer of type C to owning a computer of type\nA. Suppose also that Alex owns a computer of type C\nand a hundred dollars in spending money. Suppose finally that, given\nhis preferences between different computer types, Alex prefers (i)\nowning a computer of type B and one less dollar of spending\nmoney over owning a computer of type C, (ii) owning a\ncomputer of type A and one less dollar of spending money over\nowning a computer of type B, and (iii) owning a computer of\ntype C and one less dollar of spending money over owning a\ncomputer of type A. Then a series of unanticipated trade\nopportunities can spell trouble for Alex. In particular, given the\nopportunity to trade his current (type C) computer and a\ndollar for a computer of type B, Alex\u2019s preferences\nwill prompt him to make the trade. Given the further opportunity to\ntrade his current (type B) computer and a dollar for a\ncomputer of type A, Alex\u2019s preferences will prompt him\nto trade again. And given the opportunity to trade his current (type\nA) computer and a dollar for a computer of type C,\nAlex\u2019s preferences will prompt him to make a third trade. But\nthis series of trades leaves Alex with the type of computer he started\noff with and only 97 dollars. And, given that unexpected trading\nopportunities may keep popping up, Alex\u2019s situation may continue\nto deteriorate. Even though he values his spending money, his\npreferences make him susceptible to being used as a \u2018money\npump.\u2019 Moreover, interesting variations on the basic money pump\nargument show that an agent with intransitive preferences like those\njust considered is susceptible to being money-pumped even if he shows\nforesight and correctly anticipates his upcoming trading\nopportunities. See, for example, Rabinowicz 2000 and Dougherty\n2014.\n\nEven if he does not serve as a money pump, an agent with intransitive\npreferences can get into a great deal of trouble. To see this,\nconsider Warren Quinn\u2019s \u201cpuzzle of the\nself-torturer\u201d (1993): Suppose someone\u2014who, for reasons\nthat will become apparent, Quinn calls the self-torturer\u2014has a\nspecial electric device attached to him. The device has 1001 settings:\n0, 1, 2, 3, \u2026, 1000 and works as follows: moving up a setting\nraises, by a tiny increment, the amount of electric current applied to\nthe self-torturer\u2019s body. The increments in current are so small\nthat the self-torturer cannot tell the difference between adjacent\nsettings. He can, however, tell the difference between settings that\nare far apart. And, in fact, there are settings at which the\nself-torturer would experience excruciating pain. Once a week, the\nself-torturer can compare all the different settings. He must then go\nback to the setting he was at and decide if he wants to move up a\nsetting. If he does so, he gets $10,000, but he can never permanently\nreturn to a lower setting. Like most of us, the self-torturer would\nlike to increase his fortune but also cares about feeling well. Since\nthe self-torturer cannot feel any difference in comfort between\nadjacent settings but gets $10,000 at each advance, he prefers, for\nany two consecutive settings s and s+1, stopping at\ns+1 to stopping at s. But, since he does not want to\nlive in excruciating pain, even for a great fortune, he also prefers\nstopping at a low setting, such as 0, over stopping at a high setting,\nsuch as 1000.\n\nGiven his preferences, the self-torturer cannot rank the setting\noptions he faces from most preferred to least preferred. More\nspecifically, his preferences incorporate the following preference\nloop:\n\n\n\nFigure 4.\n\n\nRelatedly, the self-torturer\u2019s preferences over the available\nsetting options are intransitive. If his preferences were transitive,\nthen, given that he prefers setting 2 to setting 1 and setting 1 to\nsetting 0, he would prefer setting 2 to setting 0. Given that he also\nprefers setting 3 to setting 2, he would (assuming transitivity)\nprefer setting 3 to setting 0. Given that he also prefers setting 4 to\nsetting 3, he would (assuming transitivity) prefer setting 4 to\nsetting 0. Continuing with this line of reasoning leads to the\nconclusion that he would, if his preferences were transitive, prefer\nsetting 1000 to setting 0. Since he does not prefer setting 1000 to\nsetting 0, his preferences are intransitive. And this intransitivity\ncan lead the self-torturer down a terrible path. In particular, if,\neach week, the self-torturer follows his preference over the pair of\nsettings he must choose between, he will end up in a situation that he\nfinds completely unacceptable. This is quite disturbing, particularly\nonce one realizes that, although the situation of the self-torturer is\npure science fiction, the self-torturer is not really alone in his\npredicament. As Quinn stresses, \u201cmost of us are like him in one\nway or another. [For example, most of us] like to eat but also care\nabout our appearance. Just one more bite will give us pleasure and\nwon\u2019t make us look fatter; but very many bites will\u201d\n(Quinn 1993, 199).\n\nGiven the money pump argument and the puzzle of the self-torturer, we\ncan, it seems, conclude that although intransitive preferences are\nsometimes understandable, acting on them can be far from sensible.\n(Note, however, that, as Duncan MacIntosh (2010) suggests, the notion\nof \u201can unacceptable situation\u201d plays an important role\nhere and the question of how to cash out this notion stands in need of\nadditional attention. For a recent attempt at addressing this issue,\nsee (Andreou 2015), wherein instrumental rationality is portrayed as\naccountable to \u201csubjective appraisal responses\u201d that go\nbeyond the agent\u2019s preferences and that sometimes allow some\noutcomes in a \u201cpreference loop\u201d to figure as (rationally)\nacceptable and others to figure as (rationally) unacceptable.)\n1.4 Vague Goals and other Challenging Wholes\n\nLike intransitive preferences, vague goals or projects can prompt\ndynamic choice problems even if the agent\u2019s preference structure\nis not changing over time. Indeed, some have suggested that the deep\nsource of the self-torturer\u2019s problem, and what prompts his\nintransitive preferences, is that his goal of avoiding extreme pain is\nvague in the sense that, in the situation described, avoiding extreme\npain requires engaging in a multitude of goal-directed actions that\nare not individually necessary or sufficient for the achievement of\nthe goal and that are thus dispensable and perhaps even dominated if\nconsidered individually (Tenenbaum and Raffman, 2012). It may be\nhelpful to consider a more familiar example of a vague goal or\nproject, such as that of writing a good book. As Sergio Tenenbaum and\nDiana Raffman explain, this project may be characterizable as follows\n(2012, 99\u2013100):\n\nIts completion requires the successful execution of many momentary\nactions.\nFor each momentary action in which you execute the project,\nfailure to execute that action would not have prevented you from\nwriting the book.\nOn many occasions when you execute the project, there is something\nelse that you would prefer to be doing, given how unlikely it is that\nexecuting the project at this time would make a difference to the\nsuccess of your writing the book.\nHad you failed to execute the project every time you would have\npreferred to be doing something else, you would not have written the\nbook.\nYou prefer executing the project at every momentary choice\nsituation in which you could work on the project, over not writing the\nbook at all.\n\n\nIt is not difficult to see how, in a case like this, seemingly\nrational \u201clocal\u201d decisions can lead one off course.\n\nTenenbaum and Raffman\u2019s discussion of the pursuit of vague goals\nis interestingly related to Luca Ferrero\u2019s suggestion that many\nactivities are \u201cmade up of momentary actions that relate in\nnon-local ways that span over the entire length of the\nactivities\u201d and \u201crequire the agent\u2019s continuous\nappreciation of the structure and outcome of the extended activities\ntaken as a whole\u201d (2009, 406). Ferrero focuses on activities\nthat have a narrative dimension, in that \u201cthe unfolding of the\ncharacteristic temporal structure of \u2026[the] activities can be\nfully and perspicuously described solely by a narrative\u201d\n(412\u20133), but the pursuit of vague goals also seems to fit\nFerrero\u2019s initial description, as well as his idea that\nactivities of the relevant sort involve the \u201cparadigmatic\noperation\u201d of the \u201cdiachronic will\u201d (406). In all\nsuch activities, relentless guidance by \u201cproximal\nconcerns\u201d interferes with what is required by \u201cthe\nactivity\u2019s global structure\u201d (406).\n1.5 Autonomous Benefit Cases\n\nThe discussions in the preceding three sections suggest that, when it\ncomes to serving one\u2019s concerns well, the ability to choose\ncounter-preferentially may be quite helpful. This point is reinforced\nby the possibility of autonomous benefit cases.\n\nIn autonomous benefit cases, one benefits from forming a certain\nintention but not from carrying out the associated action. The\nautonomous benefit cases that have figured most prominently in the\nliterature on dynamic choice are those in which carrying out the\naction associated with the beneficial intention is detrimental rather\nthan just unrewarding. Among the most famous autonomous benefit cases\nis Gregory Kavka\u2019s \u201ctoxin puzzle\u201d (1983). In\nKavka\u2019s invented case,\n\nan eccentric billionaire\u2026places before you a vial of\ntoxin\u2026[and provides you with the following information:] If you\ndrink [the toxin], [it] will make you painfully ill for a day, but\nwill not threaten your life or have any lasting effects\u2026. The\nbillionaire will pay you one million dollars tomorrow morning if, at\nmidnight tonight, you intend to drink the toxin tomorrow\nafternoon\u2026. You need not drink the toxin to receive the money;\nin fact, the money will already be in your bank account hours before\nthe time for drinking it arrives, if you succeed\u2026. [The]\narrangement of\u2026external incentives is ruled out, as are such\nalternative gimmicks as hiring a hypnotist to implant the\nintention\u2026 (Kavka 1983, 33\u20134)\n\n\nPart of what is interesting about this case is that, even though most\npeople would gladly drink the toxin for a million dollars, getting the\nmillion dollars is not that easy. This is because one does not get the\nmillion dollars for drinking the toxin. Indeed, one does not get\nanything but a day of illness for drinking the toxin. As Kavka\nexplains, by the time the toxin is to be consumed, one either already\nhas the million in one\u2019s account or not; and drinking the toxin\nwill not get one any (additional) funds. Assuming one has no desire to\nbe ill for nothing, drinking the toxin seems to involve acting\ncounter-preferentially\u2014and this is, if not impossible, at least\nno easy feat. So, given a clear understanding of the situation, one is\nlikely to find it difficult, if not impossible, to form the intention\nto drink the toxin. Presumably, one cannot form the intention to drink\nthe toxin if one is confident that one will not drink it. If only one\ncould somehow rely on the cooperation of one\u2019s future self, one\ncould then genuinely form the intention to drink the toxin and thus\nget the million\u2014a wonderful result from the perspective of both\none\u2019s current and one\u2019s future self. But, alas,\none\u2019s future self will, it seems, have no reason to drink the\ntoxin when the time for doing so arrives.\n\nHere again we have a situation in which doing well by oneself is not\neasy.\n2. Solving Dynamic Choice Problems\n\nGiven how much trouble dynamic choice problems can cause, it is\nnatural to wonder whether and how they can be solved. Various\nsolutions of varying scope have been proposed in the literature on\ndynamic choice. The first three subsections that follow focus on ideas\nregarding the practical issue of dealing with dynamic choice problems.\nThe fourth subsection focuses on attempts at resolving the theoretical\npuzzles concerning rational choice raised by various dynamic choice\nproblems.\n2.1 Rational Irrationality\n\nTwo strategies that we can sometimes use to solve (in the sense of\npractically deal with) dynamic choice problems are suggested in\nKavka\u2019s description of the toxin puzzle. One strategy is to use\ngimmicks that cause one to reason or choose in a way that does not\naccord with one\u2019s preferences. The other strategy involves the\narrangement of external incentives. Although such maneuvers are ruled\nout in Kavka\u2019s case, they can prove useful in less restrictive\ncases. This subsection considers the former strategy and the next\nsubsection considers the latter strategy.\n\nIf one accepts the common assumption that causing oneself to reason or\nchoose in a way that does not accord with one\u2019s preferences\ninvolves rendering oneself irrational, the former strategy can be\nthought of as aiming at rationally-induced irrationality. A fanciful\nbut clear illustration of this strategy is presented in Derek\nParfit\u2019s work (1984). In Parfit\u2019s example (which is\nlabeled Schelling\u2019s Answer to Armed Robbery because it\ndraws on Thomas Schelling\u2019s view that \u201cit is not a\nuniversal advantage in situations of conflict to be inalienably and\nmanifestly rational in decision and motivation\u201d (Schelling 1960,\n18)), a robber breaks into someone\u2019s house and orders the owner,\ncall him Moe, to open the safe in which he hoards his gold. The robber\nthreatens to shoot Moe\u2019s children unless Moe complies. But Moe\nrealizes that both he and his children will probably be shot even if\nhe complies, since the robber will want to get rid of them so that\nthey cannot record his getaway car information and get it to the\npolice (who will be arriving from the nearest town in about 15 minutes\nin response to Moe\u2019s call, which was prompted by the first signs\nof the break-in). Fortunately, Moe has a special drug at hand that, if\nconsumed, causes one to be irrational for a brief period. Recognizing\nthat this drug is his only real hope, Moe consumes the drug and\nimmediately loses his wits. He begins \u201creeling about the\nroom\u201d saying things like \u201cGo ahead. I love my children. So\nplease kill them\u201d (Parfit 1984, 13). Given Moe\u2019s current\nstate, the robber cannot do anything that will induce Moe to open the\nsafe. There is no point in killing Moe or his children. The only\nsensible thing to do now is to hurry off before the police arrive.\n\nGiven that consuming irrationality drugs and even hiring hypnotists\nare normally not feasible solutions to our dynamic choice problems,\nthe possibility of rationally inducing irrationality may seem\npractically irrelevant. But it may be that we often benefit from the\nnon-conscious employment of what is more or less a version of this\nstrategy. We sometimes, for example, engage in self-deception or\nindulge irrational fears or superstitions when it is convenient to do\nso. Many of us might, in toxin-type cases, be naturally prone to dwell\non and indulge superstitious fears, like the fear that one will\nsomehow be jinxed if one manages to get the million dollars but then\ndoes not drink the toxin. Given this fear, one might be quite\nconfident that one will drink the toxin if one gets the million; and\nso it might be quite easy for one to form the intention to drink the\ntoxin. Although this is not a solution to the toxin puzzle that one\ncan consciously plan on using (nor is it one that resolves the\ntheoretical issues raised by the case), it may nonetheless often help\nus effectively cope with toxin-type cases. (For a clear and compact\ndiscussion concerning self-deception, \u201cmotivationally biased\nbelief,\u201d and \u201cmotivated irrationality\u201d more\ngenerally, see, for example, Mele 2004.)\n2.2 The Arrangement of External Incentives\n\nThe other above-mentioned strategy that is often useful for dealing\nwith certain dynamic choice problems is the arrangement of external\nincentives that make it worthwhile for one\u2019s future self to\ncooperate with one\u2019s current plans. This strategy can be\nparticularly useful in dealing with discounting-induced preference\nreversals. Consider again the agent who wants to save for a decent\nretirement but, as each opportunity to save approaches, prefers to\nspend her potential retirement contribution on just one more trivial\nindulgence before finally tightening her belt for the sake of the\nfuture satisfaction she feels is essential to her well-being. If this\nagent\u2019s plans are consistently thwarted by her\ndiscounting-induced preference reversals, she might come to the\nconclusion that she will never manage to save for a decent retirement\nif she doesn\u2019t supplement her plans with incentives that will\nprevent the preference reversals that are causing her so much trouble.\nIf she is lucky, she may find an existing precommitment device that\nshe can take advantage of. Suppose, for example, that she can sign up\nfor a program at work that, starting in a month, automatically\ndeposits a portion of her pay into a retirement fund. If she cannot\nremove deposited funds without a significant penalty, and if she must\nprovide a month\u2019s notice to discontinue her participation in the\nprogram, signing up for the program might change the cost-and-reward\nstructure of spending her potential retirement contributions on\ntrivial indulgences enough to make this option consistently\ndispreferred. If no ready-made precommitment device is available, she\nmight be able to create a suitable one herself. If, for example, she\nis highly averse to breaking promises, she might be able to solve her\nproblem by simply promising a concerned friend that she will\nhenceforth deposit a certain percentage of her pay into a retirement\nfund.\n\nIn some cases, one might not be confident that one can arrange for\nexternal incentives that will get one\u2019s future self to\nvoluntarily cooperate with one\u2019s current plans. One might\ntherefore favor the related but more extreme strategy of making sure\nthat one\u2019s future self does not have the power to thwart\none\u2019s current plans. Rather than simply making cooperation more\nworthwhile (and thus, in a sense, more compelling), this strategy\ninvolves arranging for the use of force (which compels in a\nstronger sense of the term). A fictional but particularly famous\nemployment of the strategy (which is discussed in, for example, Elster\n1984) is its employment by Odysseus in Homer\u2019s Odyssey.\nBecause he longed to hear the enchanting singing of the Sirens, but\nfeared that he would thereby be lured into danger, Odysseus instructed\nhis companions to tie him to the mast of his ship and to resist his\n(anticipated) attempts at freeing himself from the requested\nbonds.\n2.3 Symbolic Utility\n\nAnother strategy for dealing with certain dynamic choice\nproblems\u2014this one proposed by Robert Nozick (1993)\u2014is the\nstrategy of investing actions with symbolic utility (or value) and\nthen allowing oneself to be influenced not only by the causal\nsignificance of one\u2019s actions, but also by their symbolic\nsignificance. According to Nozick, \u201cactions and outcomes can\nsymbolize still further events \u2026 [and] draw upon themselves the\nemotional meaning (and utility\u2026) of these other events\u201d\n(26). If \u201cwe impute to actions\u2026 utilities coordinate with\nwhat they symbolize, and we strive to realize (or avoid) them as we\nwould strive for what they stand for\u201d (32), our choices will\ndiffer from what they would be if we considered only the causal\nsignificance of our actions. Consider, for example, the case of the\nself-torturer. Suppose the self-torturer has moved up ten settings in\nten weeks. He is still in a very comfortable range, but he is starting\nto worry about ending up at a high setting that would leave him in\nexcruciating pain. It occurs to him that he should quit while he is\nahead, and he begins to symbolically associate moving up a setting at\nthe next opportunity with moving up a setting at every upcoming\nopportunity. By the time the next opportunity to move up a setting\ncomes around, the extremely negative symbolic significance of this\npotential action steers him away from performing the action. For a\nstructurally similar but more down-to-earth example, consider someone\nwho loves overeating but is averse to becoming overweight. If this\nindividual comes to symbolically associate having an extra helping\nwith overeating in general and thus with becoming overweight, he may\nbe averse to having the extra helping, even if, in causal terms, what\nhe does in this particular case is negligible.\n2.4 Plans and Resoluteness\n\nThe three strategies discussed so far suggest that, to cope with\ndynamic choice problems, one must either mess with one\u2019s\nrationality or else somehow change the payoffs associated with the\noptions one will face. Some philosophers\u2014including, for example,\nMichael Bratman (1999; 2006), David Gauthier (1986; 1994), and Edward\nMcClennen (1990; 1997)\u2014have, however, suggested that the\nrational agent will not need to resort to such gimmicks as often as\none might think\u2014a good thing, since making the necessary\narrangements can require a heavy investment of time, energy, and/or\nmoney. The key to their arguments is the idea that adopting plans can\naffect what it is rational for one to do even when the plans do not\naffect the payoffs associated with the options one will face;\nrelatedly, their arguments incorporate the idea that rationality at\nleast sometimes calls for resolutely sticking to a plan even if the\nplan disallows an action that would fit as well or better with\none\u2019s preferences than the action required by the plan. (For\nsome interesting discussion relating resoluteness, one\u2019s current\noptions, and the options one will face, see Portmore 2019.) For\nBratman, Gauthier, and McClennen, being resolute is not simply useful\nin coping with dynamic choice problems. Rather, it figures as part of\na conception of rationality that resolves the theoretical puzzles\nconcerning rationality and choice over time posed by various dynamic\nchoice problems. In particular, it figures as part of a conception of\nrationality whose dictates provide intuitively sensible guidance not\nonly in simple situations but also in challenging dynamic choice\nsituations. (Significantly, in some of his more recent work, Bratman\n(2014; 2018) distances himself from the idea that rational\nresoluteness involves acting contrary to one\u2019s current\npreferences by suggesting that when rationality calls for sticking to\na plan even if this is not called for by one\u2019s current\npreferences, there may be \u201crational pressure\u201d to change\none\u2019s current preferences.)\n\nWe are, as Michael Bratman (1983; 1987) stresses, planning creatures.\nOur reasoning is structured by our plans, which enable us to achieve\ncomplex personal and social goals. To benefit from planning, one must\ntake plans seriously. For Bratman, this involves, among other things,\n(i) recognizing a general rational pressure favoring sticking to\none\u2019s plan so long as there is no problem with the plan (Bratman\n2006, section 8), and (ii) \u201ctaking seriously how one will see\nmatters at the conclusion of one\u2019s plan, or at appropriate\nstages along the way, in the case of plans or policies that are\nongoing\u201d (1999, 86). In accordance with these proposed\nrequirements, Bratman (1999) concludes that rationality at least\nsometimes calls for sticking to a plan even if this is not called for\nby one\u2019s current preferences. Moreover, although this conception\nof rationality requires that one sometimes resist one\u2019s current\npreferences, it is taken to prompt more sensible choices in\nchallenging dynamic choice situations than do conceptions of\nrationality whose dictates do not take plans seriously.\n\nThe significance of the first requirement is easy to see. If there is\na general rational pressure favoring sticking to one\u2019s plan so\nlong as there is no problem with it, then a rational agent that takes\nplans seriously will not get into the sort of trouble Broome imagines\nAbraham might get into. When faced with incommensurable alternatives,\nthe rational agent who takes plans seriously will adopt a plan and\nthen stick to it even if his preferences are consistent with pursuing\nan alternative course of action.\n\nWhat about the significance of the second requirement? For Bratman, if\none is concerned about how one will see matters at the conclusion of\none\u2019s plan or at appropriate stages along the way, then one\nwill, other things equal, avoid adjusting one\u2019s plan in ways\nthat one will regret in the future. So Bratman\u2019s planning\nconception of rationality includes a \u201cno-regret\ncondition.\u201d And, according to Bratman, given this condition, his\nconception of rationality gives intuitively plausible guidance in\ncases of temptation like the case of the self-torturer or the\nretirement contribution case. In particular, it implies that, in such\ncases, the rational planner will adopt a plan and refrain from\nadjusting it. For in both sorts of cases, if the simple fact that\none\u2019s preferences favor adjusting one\u2019s plan leads one to\nadjust it, one is bound to end up, via repeated adjustments of\none\u2019s plan, in the situation one finds unacceptable. One is thus\nbound to experience future regret. And, while Bratman allows that\nregret can sometimes be misguided\u2014which is why he does not\npresent avoiding regret as an exceptionless imperative\u2014there are\nnot, for Bratman, any special considerations that would make regret\nmisguided if one gave into temptation in cases like the case of the\nself-torturer or the retirement contribution case.\n\nBased on their own reasoning concerning rational resoluteness,\nGauthier (1994) and McClennen (1990; 1997) argue that rational\nresoluteness can help an agent do well in autonomous benefit cases\nlike the toxin case. They maintain that being rational is not a matter\nof always choosing the action that best serves one\u2019s concerns.\nRather it is a matter of acting in accordance with the deliberative\nprocedure that best serves one\u2019s concerns. Now it might seem as\nthough the deliberative procedure that best serves one\u2019s\nconcerns must be the deliberative procedure that calls for always\nchoosing the action that best serves one\u2019s concerns. But\nautonomous benefit cases like the toxin case suggest that this is not\nquite right. For, the deliberative procedure that calls for always\nchoosing the action that best serves one\u2019s concerns does not\nserve one\u2019s concerns well in autonomous benefit cases. More\nspecifically, someone who reasons in accordance with this deliberative\nprocedure does worse in autonomous benefit cases than someone who is\nwilling to resolutely stick to a prior plan that he did well to adopt.\nAccordingly, Gauthier and McClennen deny that the best deliberative\nprocedure requires one to always choose the action that best serves\none\u2019s concerns; in their view, the best deliberative procedure\nrequires some resoluteness. Relatedly, they see drinking the toxin in\naccordance with a prior plan to drink the toxin as rational, indeed as\nrationally required, given that one did well to adopt the plan; so\nrationality helps one benefit, rather than hindering one from\nbenefiting, in autonomous benefit cases like the toxin case.\n\nNote that, while there is widespread agreement that a plausible\nconception of rationality will imply that the self-torturer should\nresist the temptation to keep advancing one more setting, there is no\nwidespread agreement that a plausible conception of rationality will\nimply that it is rational to drink the toxin. For those who find the\nidea that it is rational to drink the toxin completely\ncounter-intuitive, its emergence figures as a problematic, rather than\nwelcome, implication of Gauthier\u2019s and McClennen\u2019s views\nconcerning rational resoluteness.\n\nIf Bratman and/or Gauthier and McClennen are on the right\ntrack\u2014and this is, of course, a big if\u2014then (some form of)\nresoluteness may often be the key to keeping oneself out of potential\ndynamic choice traps. It may also be the key to resolving various\npuzzles concerning rationality and dynamic choice.\n\nIn an interesting critique of planning solutions to cases of\ntemptation, Tenenbaum and Raffman (2012) challenge the purported\ncentrality of resoluteness. They suggest that, in cases of temptation,\ninstrumental rationality may not require planning and resoluteness,\nbut simply exercising \u201csufficiently many\u201d\n\u201cpermissions\u201d to do something other than what \u201cwould\nbe best at a given moment\u201d when this is required by a\n\u201crationally innocent\u201d goal or project. For instance,\n\u201csuppose you take a break from writing an important memo and\nstart surfing the web. Surely surfing for one additional second will\nnot prevent you from completing the memo, but if you surf for long\nenough you won\u2019t have time to finish it\u201d (110).\nInstrumental rationality requires that you stop surfing at an\nacceptable point. But this need not involve stopping at a point\ndetermined by a prior plan. Whether or not you have a plan to stop at\ntime t, and whether or not you resolutely adhere to such a plan need\nnot be of crucial importance. What matters is that, ultimately, you\nstop in good time by exercising, at one or more points, the rational\npermission to do something other than what would be best at that\nmoment with an eye to achieving the rationally innocent goal of\ncompleting the important memo. Tenenbaum (forthcoming) develops a\ntheory of instrumental rationality that illuminates and accommodates\nthe need to exercise rational permissions of the sort just\ndescribed.\n3. Some Familiar Phenomena Illuminated by Dynamic Choice Theory\n\nAlthough dynamic choice problems are often presented with the help of\nfanciful thought experiments, their interest is not strictly\ntheoretical. As this section highlights, they can wreak havoc in our\nreal lives, supporting phenomena such as self-destructive addictive\nbehavior and dangerous environmental destruction. In some cases, these\nphenomena can be understood in terms of procrastination (Andreou\n2007), which seems to be, by its very nature, a dynamic choice problem\n(Stroud 2010).\n\nAccording to the most familiar model of self-destructive addictive\nbehavior, such behavior results from cravings that limit \u201cthe\nscope for volitional control of behavior\u201d and can in some cases\nbe irresistible, \u201coverwhelm[ing] decision making\naltogether\u201d (Loewenstein 1999, 235\u20136). But, as we know\nfrom dynamic choice theory, self-destructive behavior need not be\ncompelled. It can also be supported by challenging choice situations\nand problematic preference structures that prompt dynamic choice\nproblems. Reflection on this point has led to new ideas concerning\npossible sources of self-destructive addictive behavior. For example,\nGeorge Ainslie (2001) has developed the view that addictive habits\nsuch as smoking\u2014which can, it seems, flourish even in the\nabsence of irresistible craving\u2014are often supported by\ndiscounting-induced preference reversals. Given the possibility of\ndiscounting-induced preference reversals, even someone who cares\ndeeply about having a healthy future, and who therefore does not want\nto be a heavy smoker, can easily find herself smoking cigarette after\ncigarette, where this figures as a series of indulgences that she\nplans against and then regrets.\n\nReflection on dynamic choice theory has also led to new ideas in\nenvironmental philosophy. For example, Chrisoula Andreou (2006) argues\nthat, although dangerous environmental destruction is usually analyzed\nas resulting from interpersonal conflicts of interest, such\ndestruction can flourish even in the absence of such conflicts. In\nparticular, where individually negligible effects are involved, as is\nthe case among \u201ccreeping environmental problems\u201d such as\npollution, \u201can agent, whether it be an individual or a\nunified collective, can be led down a course of destruction\nsimply as a result of following its informed and perfectly\nunderstandable but intransitive preferences\u201d (Andreou\n2006, 96). Notice, for example, that if a unified collective values a\nhealthy community, but also values luxuries whose production or use\npromotes a carcinogenic environment, it can find itself in a situation\nthat is structurally similar to the situation of the self-torturer.\nLike the self-torturer, such a collective must cope with the fact that\nwhile one more day, and perhaps even one more month of indulgence can\nprovide great rewards without bringing about any significant\nalterations in (physical or psychic) health, \u201csustained\nindulgence is far from innocuous\u201d (Andreou 2006, 101).\n\nClearly, success in achieving a long-term goal can require showing\nsome restraint along the way; but it is tempting to put off showing\nrestraint and to favor a bit more indulgence over embarking on the\nchallenging doings or omissions that will serve the valued long-term\ngoal. Here, as in many other contexts, procrastination figures as a\nserious threat.\n\nThough both philosophically intriguing and practically significant,\nprocrastination has only recently received substantial attention as an\nimportant topic of philosophical debate. (Much of the debate can be\nfound in a collection of papers on the topic edited by Chrisoula\nAndreou and Mark D. White (2010).) It has perhaps been assumed that\nprocrastination is just a form of weakness of will and so, although\nthere has been little explicit discussion of procrastination, most of\nthe philosophical work necessary for understanding procrastination has\nalready been done. But, as Sarah Stroud has argued (2010), this\nassumption is problematic, since there are cases of procrastination\nthat do not fit with the traditional conception of weakness of will,\nwhich casts the agent as acting against her better judgment, or with\nthe influential revisionary conception of weakness of will due to\nRichard Holton (1999), which casts the agent as acting irresolutely.\nAlthough the well-developed literature on weakness of will is an\nimportant resource in the study of procrastination, there is a lot\nmore philosophical work that needs to be done, and the modeling work\nthat seems to be most promising focuses heavily on the fact that\nprocrastination is a problem faced by agents whose choices are spread\nout over time.\n4. Concluding Remarks\n\nWhen one performs a series of actions that do not serve one\u2019s\nconcerns well, it is natural to feel regret and frustration. Why, it\nmight be wondered, is one doing so badly by oneself? Self-loathing,\ncompulsion, or simple ignorance might in some cases explain the\nsituation; but, oftentimes, none of these things seems to be at the\nroot of the problem. For, in many cases, one\u2019s steps along a\ndisadvantageous course seem voluntary, motivated by the prospect of\nsome benefit, and performed in light of a correct understanding of the\nconsequences of each step taken. As we have seen, dynamic choice\ntheory makes it clear how such cases are possible.\n\nAlthough an agent with a dynamic choice problem can often be described\nas insufficiently resolute, she is normally guided by her preferences\nor her evaluation of the options she faces. As such, she is not, in\ngeneral, properly described as simply out of control. Still, the\ncontrol she exhibits is inadequate with respect to the task of\neffectively governing her (temporally-extended) self. So her problem\nis, at least in part, a problem of effective self-governance over\ntime. Accordingly, some work on choice over time (e.g. Velleman 2000;\nBratman, 2012) includes discussion of effective self-governance over\ntime and explores the connection between the requirements for\neffective self-governance over time and the requirements for rational\nchoice over time (sometimes referred to as the requirements of\ndiachronic rationality). Some big questions in this area include the\nfollowing: To what extent does self-governance over time (or at least\neffective self-governance over time) require cross-temporal coherence\nin the form of a presumption in favor of prior intentions? To what\nextent does diachronic rationality require self-governance over time?\nAnd to what extent does diachronic rationality require cross-temporal\ncoherence in the form of a presumption in favor of prior intentions.\nMy own view is that it is ensuring the avoidance of self-defeating\nbehavior rather than ensuring self-governance over time that is\nrationally required, and so diachronic rationality requires a\npresumption in favor of prior intentions only when this is necessary\nfor avoiding self-defeating behavior (Andreou, 2012). But debate on\nthis topic has not been very extensive and further exploration of the\ntopic is certainly in order.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Ainslie, George, 1999. \u201cThe Dangers of Willpower,\u201d in\n<em>Getting Hooked</em>, Jon Elster and Ole-J\u00f8rgen Skog (eds.),\nCambridge: Cambridge University Press, pp. 65\u201392.",
                "\u2013\u2013\u2013, 2001. <em>Breakdown of Will</em>,\nCambridge: Cambridge University Press.",
                "Andreou, Chrisoula, 2005. \u201cIncommensurable Alternatives and\nRational Choice,\u201d <em>Ratio</em>, 18(3): 249\u201361.",
                "\u2013\u2013\u2013, 2005. \u201cGoing from Bad (or Not So Bad)\nto Worse: On Harmful Addictions and Habits,\u201d <em>American\nPhilosophical Quarterly</em>, 42(4): 323\u201331.",
                "\u2013\u2013\u2013, 2006. \u201cEnvironmental Damage and the\nPuzzle of the Self-Torturer,\u201d <em>Philosophy &amp; Public\nAffairs</em>, 34(1): 95\u2013108.",
                "\u2013\u2013\u2013, 2007. \u201cThere Are Preferences and Then\nThere Are Preferences\u201d in <em>Economics and the Mind</em>,\nBarbara Montero and Mark D. White (eds.), New York: Routledge, pp. 115\u2013126.",
                "\u2013\u2013\u2013, 2007. \u201cUnderstanding\nProcrastination,\u201d <em>Journal for the Theory of Social\nBehaviour</em>, 37(2): 183\u201393.",
                "\u2013\u2013\u2013, 2012. \u201cSelf-Defeating\nSelf-Governance,\u201d <em>Philosophical Issues</em>, 22:\n20\u201334.",
                "\u2013\u2013\u2013, 2015. \u201cThe Real Puzzle of the\nSelf-Torturer: Uncovering a New Dimension of Instrumental\nRationality,\u201d <em>Canadian Journal of Philosophy</em>, 45:\n562\u201375",
                "Andreou, Chrisoula and Mark D. White (eds.), 2010. <em>The Thief\nof Time: Philosophical Essays on Procrastination</em>, Oxford: Oxford\nUniversity Press.",
                "Bratman, Michael, 1983. \u201cTaking Plans Seriously,\u201d\n<em>Social Theory and Practice</em>, 9: 271\u201387.",
                "\u2013\u2013\u2013, 1987. <em>Intentions, Plans, and Practical\nReason</em>, Cambridge, MA: Harvard University Press.",
                "\u2013\u2013\u2013, 1999. \u201cToxin, Temptation, and the\nStability of Intention,\u201d in <em>Faces of Intention</em>,\nCambridge: Cambridge University Press, pp. 58\u201390.",
                "\u2013\u2013\u2013, 2006. \u201cTemptation Revisited,\u201d\nin <em>Structures of Agency</em>, Oxford: Oxford University\nPress, pp. 257\u2013282.",
                "\u2013\u2013\u2013, 2012. \u201cTime, Rationality, and\nSelf-Governance,\u201d <em>Philosophical Issues</em>, 22:\n73\u201388.",
                "\u2013\u2013\u2013, 2014. \u201cTemptation and the\nAgent\u2019s Standpoint,\u201d <em>Inquiry</em>, 57:\n293\u2013310.",
                "\u2013\u2013\u2013, 2018. <em>Planning, Time, and\nSelf-Governance</em>, New York: Oxford University Press.",
                "Broome, John, 2000. \u201cIncommensurable Values,\u201d in\n<em>Well-Being and Morality: Essays in Honour of James Griffin</em>,\nRoger Crisp and Brad Hooker (eds.), Oxford: Oxford University\nPress, pp. 21\u201338.",
                "\u2013\u2013\u2013, 2001. \u201cAre Intentions Reasons? And\nHow Should We Cope with Incommensurable Values?\u201d in\n<em>Practical Rationality and Preference</em>, Christopher W. Morris\nand Arthur Ripstein (eds.), Cambridge: Cambridge University\nPress, pp. 98\u2013120.",
                "Chang, Ruth (ed.), 1997. <em>Incommensurability, Incomparability,\nand Practical Reason</em>, Cambridge, MA: Harvard University Press.",
                "\u2013\u2013\u2013, 2002. \u201cThe Possibility of\nParity,\u201d <em>Ethics</em>, 112: 659\u201388",
                "Davidson, Donald, McKinsey, J. and Suppes, Patrick, 1955.\n\u201cOutlines of a Formal Theory of Value,\u201d <em>Philosophy of\nScience</em>, 22: 140\u201360.",
                "Dougherty, Tom, 2011, \u201cOn Whether to Prefer Pain to\nPass,\u201d <em>Ethics</em>, 121: 521\u201337.",
                "\u2013\u2013\u2013, 2014, \u201cA Deluxe Money Pump,\u201d\n<em>Thought</em>, 3: 21\u201329.",
                "Elster, Jon, 1984. <em>Ulysses and the Sirens</em>, Cambridge:\nCambridge University Press.",
                "\u2013\u2013\u2013, 2000. <em>Ulysses Unbound</em>, Cambridge:\nCambridge University Press.",
                "Elster, Jon and Ole-J\u00f8rgen Skog (eds.), 1999. <em>Getting\nHooked</em>, Cambridge: Cambridge University Press.",
                "Ferrero, Luca, 2009. \u201cWhat Good is a Diachronic\nWill?,\u201d <em>Philosophical Studies</em>, 144: 403\u201330.",
                "Gauthier, David, 1986. <em>Morals by Agreement</em>, Oxford:\nClarendon Press.",
                "\u2013\u2013\u2013, 1994. \u201cAssure and Threaten,\u201d\n<em>Ethics</em>, 104(4): 690\u2013716.",
                "Greene, Preston\u00a0and Meghan Sullivan, 2015. \u201cAgainst\nTime Bias,\u201d <em>Ethics</em>, 125: 947\u201370.",
                "Holton, Richard, 1999. \u201cIntention and Weakness of\nWill,\u201d <em>Journal of Philosophy</em>, 96: 241\u201362.",
                "Kavka, Gregory S., 1983. \u201cThe Toxin Puzzle,\u201d\n<em>Analysis</em>, 43: 33\u20136.",
                "Kirby, Kris N. and R. J. Herrnstein, 1995. \u201cPreference\nReversals Due to Myopic Discounting of Delayed\nReward,\u201d\u00a0<em>Psychological Science</em>,\u00a06:\n83\u201389.",
                "Loewenstein, George and Jon Elster (eds.), 1992. <em>Choice Over\nTime</em>, New York: Russell Sage Foundation.",
                "Loewenstein, George, Daniel Read, and Roy Baumeister (eds.), 2003.\n<em>Time and Decision</em>, New York: Russell Sage Foundation.",
                "MacIntosh, Duncan, 2010. \u201cIntransitive Preferences,\nVagueness, and the Structure of Procrastination\u201d in <em>The\nThief of Time: Philosophical Essays on Procrastination</em>, Chrisoula\nAndreou and Mark D. White (eds.), Oxford: Oxford University\nPress, pp. 68\u201386.",
                "Mele, Alfred, 2004. \u201cMotivated Irrationality,\u201d in\n<em>The Oxford Handbook of Rationality</em>, Oxford: Oxford University\nPress, pp. 240\u2013256. ",
                "McClennen, Edward, 1990. <em>Rationality and Dynamic Choice</em>,\nCambridge: Cambridge University Press.",
                "\u2013\u2013\u2013, 1997. \u201cPragmatic Rationality and\nRules,\u201d <em>Philosophy and Public Affairs</em>, 26(3):\n210\u201358.",
                "Millar, Andrew and Douglas J. Navarick, 1984. \u201cSelf-Control\nand Choice in Humans: Effects of Video Game Playing as a Positive\nReinforcer,\u201d\u00a0<em>Learning and Motivation</em>,\n<em>15</em>:\u00a0203\u2013218.",
                "Nozick, Robert, 1993. <em>The Nature of Rationality</em>,\nPrinceton: Princeton University Press.",
                "Parfit, Derek, 1984. <em>Reasons and Persons</em>, Oxford:\nClarendon Press.",
                "Portmore, Douglas W., 2019. <em>Opting for the Best: Oughts and\nOptions</em>, New York: Oxford University Press.",
                "Quinn, Warren, 1993. \u201cThe Puzzle of the\nSelf-Torturer,\u201d in <em>Morality and Action</em>, Cambridge:\nCambridge University Press, pp. 198\u2013209. ",
                "Rabinowicz, Wlodek, 2000. \u201cMoney Pump with Foresight,\u201d\nin M. J. Almeida (ed.), <em>Imperceptible Harms and Benefits</em>\n(Library of Ethics and Applied Philosophy: 8), Dordrecht, London:\nKluwer Academic, pp. 123\u2013154. ",
                "Ramsey, Frank P., 1926. \u201cTruth and Probability,\u201d in\n<em>The Foundations of Mathematics and other Logical Essays</em>, R.\nB. Braithwaite (ed.), London: Routledge &amp; Kegan Paul, 1931, pp. 156\u2013198. ",
                "Raz, Joseph, 1997. \u201cIncommensurability and Agency,\u201d in\n<em>Incommensurability, Incomparability, and Practical Reason</em>,\nRuth Chang (ed.), Cambridge, MA: Harvard University Press, pp. 110\u2013128.",
                "\u2013\u2013\u2013, 1986. <em>The Morality of Freedom</em>,\nOxford: Clarendon Press.",
                "Regan, Donald, 1997. \u201cValue, Comparability, and\nChoice,\u201d in <em>Incommensurability, Incomparability, and\nPractical Reason</em>, Ruth Chang (ed.), Cambridge, MA: Harvard University\nPress, pp. 129\u2013150.",
                "Schelling, Thomas C., 1960. <em>The Strategy of Conflict</em>,\nCambridge, MA: Harvard University Press.",
                "Solnick, Jay V., Catherine H. Kannenberg, David\u00a0A. Eckerman,\nand Marcus B. Waller. \u201cAn Experimental Analysis of Impulsivity\nand Impulse Control in Humans,\u201d <em>Learning and\nMotivation</em>, 11: 61\u201377.",
                "Stroud, Sarah, 2010. \u201cIs Procrastination Weakness of\nWill?\u201d in <em>The Thief of Time: Philosophical Essays on\nProcrastination</em>, Chrisoula Andreou and Mark D. White (eds.),\nOxford: Oxford University Press, pp. 51\u201367.",
                "Tenenbaum, Sergio, forthcoming. <em>Rational Powers in\nAction</em>, New York: Oxford University Press.",
                "Tenenbaum, Sergio and Diana Raffman, 2012. \u201cVague Projects\nand the Puzzle of the Self-Torturer,\u201d <em>Ethics</em>, 123:\n86\u2013112.",
                "Tversky, Amos, 1969. \u201cIntransitivity of Preferences,\u201d\n<em>Psychological Review</em>, 76: 31\u201348.",
                "Velleman, David, 2000. \u201cDeciding How to Decide,\u201d in\n<em>The Possibility of Practical Reason</em>, Oxford: Clarendon\nPress, pp. 221\u2013243."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Ainslie, George, 1999. \u201cThe Dangers of Willpower,\u201d in\n<em>Getting Hooked</em>, Jon Elster and Ole-J\u00f8rgen Skog (eds.),\nCambridge: Cambridge University Press, pp. 65\u201392.</li>\n<li>\u2013\u2013\u2013, 2001. <em>Breakdown of Will</em>,\nCambridge: Cambridge University Press.</li>\n<li>Andreou, Chrisoula, 2005. \u201cIncommensurable Alternatives and\nRational Choice,\u201d <em>Ratio</em>, 18(3): 249\u201361.</li>\n<li>\u2013\u2013\u2013, 2005. \u201cGoing from Bad (or Not So Bad)\nto Worse: On Harmful Addictions and Habits,\u201d <em>American\nPhilosophical Quarterly</em>, 42(4): 323\u201331.</li>\n<li>\u2013\u2013\u2013, 2006. \u201cEnvironmental Damage and the\nPuzzle of the Self-Torturer,\u201d <em>Philosophy &amp; Public\nAffairs</em>, 34(1): 95\u2013108.</li>\n<li>\u2013\u2013\u2013, 2007. \u201cThere Are Preferences and Then\nThere Are Preferences\u201d in <em>Economics and the Mind</em>,\nBarbara Montero and Mark D. White (eds.), New York: Routledge, pp. 115\u2013126.</li>\n<li>\u2013\u2013\u2013, 2007. \u201cUnderstanding\nProcrastination,\u201d <em>Journal for the Theory of Social\nBehaviour</em>, 37(2): 183\u201393.</li>\n<li>\u2013\u2013\u2013, 2012. \u201cSelf-Defeating\nSelf-Governance,\u201d <em>Philosophical Issues</em>, 22:\n20\u201334.</li>\n<li>\u2013\u2013\u2013, 2015. \u201cThe Real Puzzle of the\nSelf-Torturer: Uncovering a New Dimension of Instrumental\nRationality,\u201d <em>Canadian Journal of Philosophy</em>, 45:\n562\u201375</li>\n<li>Andreou, Chrisoula and Mark D. White (eds.), 2010. <em>The Thief\nof Time: Philosophical Essays on Procrastination</em>, Oxford: Oxford\nUniversity Press.</li>\n<li>Bratman, Michael, 1983. \u201cTaking Plans Seriously,\u201d\n<em>Social Theory and Practice</em>, 9: 271\u201387.</li>\n<li>\u2013\u2013\u2013, 1987. <em>Intentions, Plans, and Practical\nReason</em>, Cambridge, MA: Harvard University Press.</li>\n<li>\u2013\u2013\u2013, 1999. \u201cToxin, Temptation, and the\nStability of Intention,\u201d in <em>Faces of Intention</em>,\nCambridge: Cambridge University Press, pp. 58\u201390.</li>\n<li>\u2013\u2013\u2013, 2006. \u201cTemptation Revisited,\u201d\nin <em>Structures of Agency</em>, Oxford: Oxford University\nPress, pp. 257\u2013282.</li>\n<li>\u2013\u2013\u2013, 2012. \u201cTime, Rationality, and\nSelf-Governance,\u201d <em>Philosophical Issues</em>, 22:\n73\u201388.</li>\n<li>\u2013\u2013\u2013, 2014. \u201cTemptation and the\nAgent\u2019s Standpoint,\u201d <em>Inquiry</em>, 57:\n293\u2013310.</li>\n<li>\u2013\u2013\u2013, 2018. <em>Planning, Time, and\nSelf-Governance</em>, New York: Oxford University Press.</li>\n<li>Broome, John, 2000. \u201cIncommensurable Values,\u201d in\n<em>Well-Being and Morality: Essays in Honour of James Griffin</em>,\nRoger Crisp and Brad Hooker (eds.), Oxford: Oxford University\nPress, pp. 21\u201338.</li>\n<li>\u2013\u2013\u2013, 2001. \u201cAre Intentions Reasons? And\nHow Should We Cope with Incommensurable Values?\u201d in\n<em>Practical Rationality and Preference</em>, Christopher W. Morris\nand Arthur Ripstein (eds.), Cambridge: Cambridge University\nPress, pp. 98\u2013120.</li>\n<li>Chang, Ruth (ed.), 1997. <em>Incommensurability, Incomparability,\nand Practical Reason</em>, Cambridge, MA: Harvard University Press.</li>\n<li>\u2013\u2013\u2013, 2002. \u201cThe Possibility of\nParity,\u201d <em>Ethics</em>, 112: 659\u201388</li>\n<li>Davidson, Donald, McKinsey, J. and Suppes, Patrick, 1955.\n\u201cOutlines of a Formal Theory of Value,\u201d <em>Philosophy of\nScience</em>, 22: 140\u201360.</li>\n<li>Dougherty, Tom, 2011, \u201cOn Whether to Prefer Pain to\nPass,\u201d <em>Ethics</em>, 121: 521\u201337.</li>\n<li>\u2013\u2013\u2013, 2014, \u201cA Deluxe Money Pump,\u201d\n<em>Thought</em>, 3: 21\u201329.</li>\n<li>Elster, Jon, 1984. <em>Ulysses and the Sirens</em>, Cambridge:\nCambridge University Press.</li>\n<li>\u2013\u2013\u2013, 2000. <em>Ulysses Unbound</em>, Cambridge:\nCambridge University Press.</li>\n<li>Elster, Jon and Ole-J\u00f8rgen Skog (eds.), 1999. <em>Getting\nHooked</em>, Cambridge: Cambridge University Press.</li>\n<li>Ferrero, Luca, 2009. \u201cWhat Good is a Diachronic\nWill?,\u201d <em>Philosophical Studies</em>, 144: 403\u201330.</li>\n<li>Gauthier, David, 1986. <em>Morals by Agreement</em>, Oxford:\nClarendon Press.</li>\n<li>\u2013\u2013\u2013, 1994. \u201cAssure and Threaten,\u201d\n<em>Ethics</em>, 104(4): 690\u2013716.</li>\n<li>Greene, Preston\u00a0and Meghan Sullivan, 2015. \u201cAgainst\nTime Bias,\u201d <em>Ethics</em>, 125: 947\u201370.</li>\n<li>Holton, Richard, 1999. \u201cIntention and Weakness of\nWill,\u201d <em>Journal of Philosophy</em>, 96: 241\u201362.</li>\n<li>Kavka, Gregory S., 1983. \u201cThe Toxin Puzzle,\u201d\n<em>Analysis</em>, 43: 33\u20136.</li>\n<li>Kirby, Kris N. and R. J. Herrnstein, 1995. \u201cPreference\nReversals Due to Myopic Discounting of Delayed\nReward,\u201d\u00a0<em>Psychological Science</em>,\u00a06:\n83\u201389.</li>\n<li>Loewenstein, George and Jon Elster (eds.), 1992. <em>Choice Over\nTime</em>, New York: Russell Sage Foundation.</li>\n<li>Loewenstein, George, Daniel Read, and Roy Baumeister (eds.), 2003.\n<em>Time and Decision</em>, New York: Russell Sage Foundation.</li>\n<li>MacIntosh, Duncan, 2010. \u201cIntransitive Preferences,\nVagueness, and the Structure of Procrastination\u201d in <em>The\nThief of Time: Philosophical Essays on Procrastination</em>, Chrisoula\nAndreou and Mark D. White (eds.), Oxford: Oxford University\nPress, pp. 68\u201386.</li>\n<li>Mele, Alfred, 2004. \u201cMotivated Irrationality,\u201d in\n<em>The Oxford Handbook of Rationality</em>, Oxford: Oxford University\nPress, pp. 240\u2013256. </li>\n<li>McClennen, Edward, 1990. <em>Rationality and Dynamic Choice</em>,\nCambridge: Cambridge University Press.</li>\n<li>\u2013\u2013\u2013, 1997. \u201cPragmatic Rationality and\nRules,\u201d <em>Philosophy and Public Affairs</em>, 26(3):\n210\u201358.</li>\n<li>Millar, Andrew and Douglas J. Navarick, 1984. \u201cSelf-Control\nand Choice in Humans: Effects of Video Game Playing as a Positive\nReinforcer,\u201d\u00a0<em>Learning and Motivation</em>,\n<em>15</em>:\u00a0203\u2013218.</li>\n<li>Nozick, Robert, 1993. <em>The Nature of Rationality</em>,\nPrinceton: Princeton University Press.</li>\n<li>Parfit, Derek, 1984. <em>Reasons and Persons</em>, Oxford:\nClarendon Press.</li>\n<li>Portmore, Douglas W., 2019. <em>Opting for the Best: Oughts and\nOptions</em>, New York: Oxford University Press.</li>\n<li>Quinn, Warren, 1993. \u201cThe Puzzle of the\nSelf-Torturer,\u201d in <em>Morality and Action</em>, Cambridge:\nCambridge University Press, pp. 198\u2013209. </li>\n<li>Rabinowicz, Wlodek, 2000. \u201cMoney Pump with Foresight,\u201d\nin M. J. Almeida (ed.), <em>Imperceptible Harms and Benefits</em>\n(Library of Ethics and Applied Philosophy: 8), Dordrecht, London:\nKluwer Academic, pp. 123\u2013154. </li>\n<li>Ramsey, Frank P., 1926. \u201cTruth and Probability,\u201d in\n<em>The Foundations of Mathematics and other Logical Essays</em>, R.\nB. Braithwaite (ed.), London: Routledge &amp; Kegan Paul, 1931, pp. 156\u2013198. </li>\n<li>Raz, Joseph, 1997. \u201cIncommensurability and Agency,\u201d in\n<em>Incommensurability, Incomparability, and Practical Reason</em>,\nRuth Chang (ed.), Cambridge, MA: Harvard University Press, pp. 110\u2013128.</li>\n<li>\u2013\u2013\u2013, 1986. <em>The Morality of Freedom</em>,\nOxford: Clarendon Press.</li>\n<li>Regan, Donald, 1997. \u201cValue, Comparability, and\nChoice,\u201d in <em>Incommensurability, Incomparability, and\nPractical Reason</em>, Ruth Chang (ed.), Cambridge, MA: Harvard University\nPress, pp. 129\u2013150.</li>\n<li>Schelling, Thomas C., 1960. <em>The Strategy of Conflict</em>,\nCambridge, MA: Harvard University Press.</li>\n<li>Solnick, Jay V., Catherine H. Kannenberg, David\u00a0A. Eckerman,\nand Marcus B. Waller. \u201cAn Experimental Analysis of Impulsivity\nand Impulse Control in Humans,\u201d <em>Learning and\nMotivation</em>, 11: 61\u201377.</li>\n<li>Stroud, Sarah, 2010. \u201cIs Procrastination Weakness of\nWill?\u201d in <em>The Thief of Time: Philosophical Essays on\nProcrastination</em>, Chrisoula Andreou and Mark D. White (eds.),\nOxford: Oxford University Press, pp. 51\u201367.</li>\n<li>Tenenbaum, Sergio, forthcoming. <em>Rational Powers in\nAction</em>, New York: Oxford University Press.</li>\n<li>Tenenbaum, Sergio and Diana Raffman, 2012. \u201cVague Projects\nand the Puzzle of the Self-Torturer,\u201d <em>Ethics</em>, 123:\n86\u2013112.</li>\n<li>Tversky, Amos, 1969. \u201cIntransitivity of Preferences,\u201d\n<em>Psychological Review</em>, 76: 31\u201348.</li>\n<li>Velleman, David, 2000. \u201cDeciding How to Decide,\u201d in\n<em>The Possibility of Practical Reason</em>, Oxford: Clarendon\nPress, pp. 221\u2013243.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "decision theory",
            "Dutch book arguments",
            "economics: philosophy of",
            "free rider problem",
            "practical reason",
            "preferences",
            "prisoner\u2019s dilemma",
            "rational choice, normative: expected utility",
            "value: incommensurable",
            "value: pluralism",
            "voting: methods",
            "weakness of will"
        ],
        "entry_link": [
            {
                "../decision-theory/": "decision theory"
            },
            {
                "../dutch-book/": "Dutch book arguments"
            },
            {
                "../economics/": "economics: philosophy of"
            },
            {
                "../free-rider/": "free rider problem"
            },
            {
                "../practical-reason/": "practical reason"
            },
            {
                "../preferences/": "preferences"
            },
            {
                "../prisoner-dilemma/": "prisoner\u2019s dilemma"
            },
            {
                "../rationality-normative-utility/": "rational choice, normative: expected utility"
            },
            {
                "../value-incommensurable/": "value: incommensurable"
            },
            {
                "../value-pluralism/": "value: pluralism"
            },
            {
                "../voting-methods/": "voting: methods"
            },
            {
                "../weakness-will/": "weakness of will"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=dynamic-choice\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/dynamic-choice/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=dynamic-choice&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/dynamic-choice/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=dynamic-choice": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/dynamic-choice/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=dynamic-choice&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/dynamic-choice/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "<a href=\"http://peasoup.us/\" target=\"other\">PEA Soup</a>\n<ul>\n<a href=\"http://peasoup.us/category/discussions/metaethics/practical-rationality/\" target=\"other\">PEA Soup: Practical Rationality</a>\n</ul> ",
            "<a href=\"http://peasoup.us/category/discussions/metaethics/practical-rationality/\" target=\"other\">PEA Soup: Practical Rationality</a>"
        ],
        "listed_links": [
            {
                "http://peasoup.us/": "PEA Soup"
            },
            {
                "http://peasoup.us/category/discussions/metaethics/practical-rationality/": "PEA Soup: Practical Rationality"
            }
        ]
    }
}