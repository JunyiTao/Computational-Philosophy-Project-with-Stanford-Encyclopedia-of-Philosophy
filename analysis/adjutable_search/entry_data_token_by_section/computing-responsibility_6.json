{
    "main_text": "Can computers be moral agents? || Creating autonomous moral agents\n2.2 Creating autonomous moral agents\n\nIn the absence of any definitive arguments for or against the\npossibility of future computer systems being morally responsible,\nresearchers within the field of machine ethics aim to further develop\nthe discussion by focusing instead on creating computer system that\ncan behave as if they are moral agents (Moor 2006,\nCervantes et al 2019 , Zoshak and Dew 2021). Research\nwithin this field has been concerned with the design and development\nof computer systems that can independently determine what the right\nthing to do would be in a given situation. According to Allen and\nWallach, such autonomous moral agents (AMAs) would have to be\ncapable of reasoning about the moral and social significance of their\nbehavior and use their assessment of the effects their behavior has on\nsentient beings to make appropriate choices (2012; see also Wallach\nand Allen 2009 and Allen et al. 2000). Such abilities are needed, they\nargue, because computers are becoming more and more complex and\ncapable of operating without direct human control in different\ncontexts and environments. Progressively autonomous technologies\nalready in development, such as military robots, driverless cars or\ntrains and service robots in the home and for healthcare, will be\ninvolved in moral situations that directly affect the safety and\nwell-being of humans. An autonomous bomb disposal robot might in the\nfuture be faced with the decision which bomb it should defuse first,\nin order to minimize casualties. Similarly, a moral decision that a\ndriverless car might have to make is whether to break for a crossing\ndog or avoid the risk of causing injury to the driver behind him. Such\ndecisions require judgment. Currently operators make such moral\ndecisions, or the decision is already inscribed in the design of the\ncomputer system. Machine ethics, Wallach and Allen argue, goes one\nstep beyond making engineers aware of the values they build into the\ndesign of their products, as it seeks to build ethical decision-making\ninto the machines.\n\nTo further specify what it means for computers to make ethical\ndecisions or to put \u2018ethics in the machine\u2019, Moor\ndistinguished between three different kinds of ethical agents:\nimplicit ethical agents, explicit ethical agents, and full ethical\nagents (2006). The first kind of agent is a computer that has the\nethics of its developers inscribed in their design. These agents are\nconstructed to adhere to the norms and values of the contexts in which\nthey are developed or will be used. Thus, ATM tellers are designed to\nhave a high level of security to prevent unauthorized people from\ndrawing money from accounts. An explicit ethical agent is a computer\nthat can \u2018do ethics\u2019. In other words, it can on the basis\nof an ethical model determine what would be the right thing to do,\ngiven certain inputs. The ethical model can be based on ethical\ntraditions, such as Kantian, Confucianism, Ubuntu, or utilitarian\nethics\u2014depending on the preferences of its creators. These\nagents would \u2018make ethical decisions\u2019 on behalf of its\nhuman users (and developers). Such agents are akin to the autonomous\nmoral agents described by Allen and Wallach. Finally, Moor defined\nfull ethical agents as entities that can make ethical judgments and\ncan justify them, much like human beings can. He claimed that although\nat the time of his writing there were no computer technologies that\ncould be called fully ethical, it is an empirical question whether or\nnot it would be possible in the future. Few, if any, philosophers\ntoday would argue that this question has been answered in the postive.\n\n\nThe effort to build AMAs raises the question of how this effort\naffects the ascription of moral responsibility. As human beings would\ndesign these artificial agents to behave within pre-specified\nformalized ethical frameworks, it is likely that responsibility will\nstill be ascribed to these human actors and those that deploy these\ntechnologies. However, as Allen and Wallach acknowledge, the danger of\nexclusively focusing on equipping robots with moral decision-making\nabilities, rather than also looking at the sociotechnical systems in\nwhich these robots are embedded, is that it may cause further\nconfusion about the distribution of responsibility (2012). Robots with\nmoral decision-making capabilities may present similar challenges to\nascribing responsibility as other technologies, when they introduce\nnew complexities that further obfuscate causal connections that lead\nback to their creators and users.\n",
    "section_title": "2.2 Creating autonomous moral agents",
    "entry_title": "Computing and Moral Responsibility",
    "hierarchy_title": "Computing and Moral Responsibility || Can computers be moral agents? || Creating autonomous moral agents",
    "tokenized_text": [
        "computer",
        "moral",
        "agent",
        "creating",
        "autonomous",
        "moral",
        "agent",
        "creating",
        "autonomous",
        "moral",
        "agent",
        "absence",
        "definitive",
        "argument",
        "possibility",
        "future",
        "computer",
        "system",
        "morally",
        "responsible",
        "researcher",
        "within",
        "field",
        "machine",
        "ethic",
        "aim",
        "develop",
        "discussion",
        "focusing",
        "instead",
        "creating",
        "computer",
        "system",
        "behave",
        "moral",
        "agent",
        "moor",
        "cervantes",
        "et",
        "al",
        "zoshak",
        "dew",
        "research",
        "within",
        "field",
        "concerned",
        "design",
        "development",
        "computer",
        "system",
        "independently",
        "determine",
        "right",
        "thing",
        "would",
        "given",
        "situation",
        "according",
        "allen",
        "wallach",
        "autonomous",
        "moral",
        "agent",
        "amas",
        "would",
        "capable",
        "reasoning",
        "moral",
        "social",
        "significance",
        "behavior",
        "use",
        "assessment",
        "effect",
        "behavior",
        "sentient",
        "being",
        "make",
        "appropriate",
        "choice",
        "see",
        "also",
        "wallach",
        "allen",
        "allen",
        "et",
        "al",
        "ability",
        "needed",
        "argue",
        "computer",
        "becoming",
        "complex",
        "capable",
        "operating",
        "without",
        "direct",
        "human",
        "control",
        "different",
        "context",
        "environment",
        "progressively",
        "autonomous",
        "technology",
        "already",
        "development",
        "military",
        "robot",
        "driverless",
        "car",
        "train",
        "service",
        "robot",
        "home",
        "healthcare",
        "involved",
        "moral",
        "situation",
        "directly",
        "affect",
        "safety",
        "wellbeing",
        "human",
        "autonomous",
        "bomb",
        "disposal",
        "robot",
        "might",
        "future",
        "faced",
        "decision",
        "bomb",
        "defuse",
        "first",
        "order",
        "minimize",
        "casualty",
        "similarly",
        "moral",
        "decision",
        "driverless",
        "car",
        "might",
        "make",
        "whether",
        "break",
        "crossing",
        "dog",
        "avoid",
        "risk",
        "causing",
        "injury",
        "driver",
        "behind",
        "decision",
        "require",
        "judgment",
        "currently",
        "operator",
        "make",
        "moral",
        "decision",
        "decision",
        "already",
        "inscribed",
        "design",
        "computer",
        "system",
        "machine",
        "ethic",
        "wallach",
        "allen",
        "argue",
        "go",
        "one",
        "step",
        "beyond",
        "making",
        "engineer",
        "aware",
        "value",
        "build",
        "design",
        "product",
        "seek",
        "build",
        "ethical",
        "decisionmaking",
        "machine",
        "specify",
        "mean",
        "computer",
        "make",
        "ethical",
        "decision",
        "put",
        "ethic",
        "machine",
        "moor",
        "distinguished",
        "three",
        "different",
        "kind",
        "ethical",
        "agent",
        "implicit",
        "ethical",
        "agent",
        "explicit",
        "ethical",
        "agent",
        "full",
        "ethical",
        "agent",
        "first",
        "kind",
        "agent",
        "computer",
        "ethic",
        "developer",
        "inscribed",
        "design",
        "agent",
        "constructed",
        "adhere",
        "norm",
        "value",
        "context",
        "developed",
        "used",
        "thus",
        "atm",
        "teller",
        "designed",
        "high",
        "level",
        "security",
        "prevent",
        "unauthorized",
        "people",
        "drawing",
        "money",
        "account",
        "explicit",
        "ethical",
        "agent",
        "computer",
        "ethic",
        "word",
        "basis",
        "ethical",
        "model",
        "determine",
        "would",
        "right",
        "thing",
        "given",
        "certain",
        "input",
        "ethical",
        "model",
        "based",
        "ethical",
        "tradition",
        "kantian",
        "confucianism",
        "ubuntu",
        "utilitarian",
        "ethicsdepending",
        "preference",
        "creator",
        "agent",
        "would",
        "make",
        "ethical",
        "decision",
        "behalf",
        "human",
        "user",
        "developer",
        "agent",
        "akin",
        "autonomous",
        "moral",
        "agent",
        "described",
        "allen",
        "wallach",
        "finally",
        "moor",
        "defined",
        "full",
        "ethical",
        "agent",
        "entity",
        "make",
        "ethical",
        "judgment",
        "justify",
        "much",
        "like",
        "human",
        "being",
        "claimed",
        "although",
        "time",
        "writing",
        "computer",
        "technology",
        "could",
        "called",
        "fully",
        "ethical",
        "empirical",
        "question",
        "whether",
        "would",
        "possible",
        "future",
        "philosopher",
        "today",
        "would",
        "argue",
        "question",
        "answered",
        "postive",
        "effort",
        "build",
        "amas",
        "raise",
        "question",
        "effort",
        "affect",
        "ascription",
        "moral",
        "responsibility",
        "human",
        "being",
        "would",
        "design",
        "artificial",
        "agent",
        "behave",
        "within",
        "prespecified",
        "formalized",
        "ethical",
        "framework",
        "likely",
        "responsibility",
        "still",
        "ascribed",
        "human",
        "actor",
        "deploy",
        "technology",
        "however",
        "allen",
        "wallach",
        "acknowledge",
        "danger",
        "exclusively",
        "focusing",
        "equipping",
        "robot",
        "moral",
        "decisionmaking",
        "ability",
        "rather",
        "also",
        "looking",
        "sociotechnical",
        "system",
        "robot",
        "embedded",
        "may",
        "cause",
        "confusion",
        "distribution",
        "responsibility",
        "robot",
        "moral",
        "decisionmaking",
        "capability",
        "may",
        "present",
        "similar",
        "challenge",
        "ascribing",
        "responsibility",
        "technology",
        "introduce",
        "new",
        "complexity",
        "obfuscate",
        "causal",
        "connection",
        "lead",
        "back",
        "creator",
        "user"
    ]
}