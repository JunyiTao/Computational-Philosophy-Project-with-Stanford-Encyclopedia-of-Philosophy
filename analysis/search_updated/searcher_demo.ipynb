{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from src.bm25 import *\n",
    "import src.preprocessing as preprocessing\n",
    "import src.utils as utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e2d76b1764456e9e789e255c83d03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bm25 = build_searcher('entry_data_token_by_section/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the searcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how to use the searcher. Note that the search is case-insensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query can be any string, here we read from a example query file\n",
    "query = open('toc.txt').read() \n",
    "\n",
    "# get scores for the query\n",
    "ranking = bm25.get_scores(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned object from `get_scores(query)` is a list of tuples in the form of `(section title, score, list of (token, token_score) pairs)`. The list is sorted by the relevance score in descending order. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reliabilist Epistemology || A Paradigm Shift in Analytic Epistemology',\n",
       " 104.64468000171928,\n",
       " [('reliabilist', 10.682715970501583),\n",
       "  ('gettier', 7.913633470759927),\n",
       "  ('safety', 6.460693400026655),\n",
       "  ('sensitivity', 5.790663622000863),\n",
       "  ('justified', 5.188410321299965),\n",
       "  ('justification', 4.705217440719186),\n",
       "  ('epistemic', 4.476381109480742),\n",
       "  ('modal', 3.9926725712569433),\n",
       "  ('theory', 3.9575494581618247),\n",
       "  ('first', 3.0909508783660558),\n",
       "  ('alternative', 2.8901483048141245),\n",
       "  ('belief', 2.7948843512884576),\n",
       "  ('knowledge', 2.512723295519643),\n",
       "  ('false', 2.5009147724367233),\n",
       "  ('relevant', 2.5005336499409045),\n",
       "  ('condition', 1.8708100531326974),\n",
       "  ('truth', 1.7237379582424155),\n",
       "  ('true', 1.6861872088247576),\n",
       "  ('case', 0.27215427778001605)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can exclude all sections under a specific entry by using `exclude_by_entry(ranking_list, entry)`. This is useful when the query text comes from a specific entry. \n",
    "\n",
    "For example, to exclude all sections under the entry \"The Analysis of Knowledge\", we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_e = exclude_by_entry(ranking,'The Analysis of Knowledge') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reweighting terms\n",
    "By default, every token is weighted by the BM25 score. We can also assign weights to important tokens by using `word_importance()`.\n",
    "\n",
    "Here we make \"Epistemic\" and \"justification\" twice as important as other words. And make \"know\" half as important as other words. Note that this weight will still be multiplied by the BM25 score, which will weight the tokens separately by the inverse document frequency and the term frequency. Defination of importance is also case-insensitive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epistemic': 2, 'know': 0.5, 'justification': 2}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "importance = {\n",
    "    'Epistemic': 2,\n",
    "    'know': 0.5,\n",
    "    'justification': 2,\n",
    "}\n",
    "\n",
    "ranking = bm25.get_scores(query, importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the top result does not change from the default score. But the scores are now different, note taht the score for \"justification\" and \"Epistemic\" are now higher and contribute more to the final score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reliabilist Epistemology || A Paradigm Shift in Analytic Epistemology',\n",
       " 118.53149599263838,\n",
       " [('reliabilist', 10.682715970501583),\n",
       "  ('justification', 9.410434881438372),\n",
       "  ('epistemic', 8.952762218961483),\n",
       "  ('gettier', 7.913633470759927),\n",
       "  ('safety', 6.460693400026655),\n",
       "  ('sensitivity', 5.790663622000863),\n",
       "  ('justified', 5.188410321299965),\n",
       "  ('modal', 3.9926725712569433),\n",
       "  ('theory', 3.9575494581618247),\n",
       "  ('first', 3.0909508783660558),\n",
       "  ('alternative', 2.8901483048141245),\n",
       "  ('belief', 2.7948843512884576),\n",
       "  ('knowledge', 2.512723295519643),\n",
       "  ('false', 2.5009147724367233),\n",
       "  ('relevant', 2.5005336499409045),\n",
       "  ('condition', 1.8708100531326974),\n",
       "  ('truth', 1.7237379582424155),\n",
       "  ('true', 1.6861872088247576),\n",
       "  ('case', 0.27215427778001605)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
