{
    "url": "game-ethics",
    "title": "Game Theory and Ethics",
    "authorship": {
        "year": "Copyright \u00a9 2021",
        "author_text": "Keith Hankins\n<keith.s.hankins@gmail.com>\nPeter Vanderschraaf\n<pvanderschraaf@arizona.edu>",
        "author_links": [
            {
                "mailto:keith%2es%2ehankins%40gmail%2ecom": "keith.s.hankins@gmail.com"
            },
            {
                "https://moralscience.arizona.edu/person/peter-vanderschraaf": "Peter Vanderschraaf"
            },
            {
                "mailto:pvanderschraaf%40arizona%2eedu": "pvanderschraaf@arizona.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2021</a> by\n\n<br/>\nKeith Hankins\n&lt;<a href=\"mailto:keith%2es%2ehankins%40gmail%2ecom\"><em>keith<abbr title=\" dot \">.</abbr>s<abbr title=\" dot \">.</abbr>hankins<abbr title=\" at \">@</abbr>gmail<abbr title=\" dot \">.</abbr>com</em></a>&gt;<br/>\n<a href=\"https://moralscience.arizona.edu/person/peter-vanderschraaf\" target=\"other\">Peter Vanderschraaf</a>\n&lt;<a href=\"mailto:pvanderschraaf%40arizona%2eedu\"><em>pvanderschraaf<abbr title=\" at \">@</abbr>arizona<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Mon Sep 27, 2021"
    ],
    "preamble": "\n\nGame theory is the study of interdependent choice and action.\nIt includes the study of strategic decision making, the\nanalysis of how the choices and decisions of a rational agent depend\non (or should be influenced by) the choices of other agents, as well\nas the study of group dynamics, the analysis of how the\ndistribution of strategies in a population evolves in various contexts\nand how these distributions impact the outcomes of individual\ninteractions. It should be distinguished from\n decision theory,\n the study of individual choice in contexts where the agent is\nchoosing independently of other agents, and from\n social choice theory,\n the study of collective decision making. Our focus will be on the\nrelevance of game theory to ethics and political philosophy. For a\nthorough discussion of game theory and its relevance to other areas of\nphilosophy see the entry on\n game theory.\n\nWe can distinguish between two ways in which game theory is relevant\nto ethics. The first is explanatory. Game theoretic tools can\nbe used to explain things ranging from (i) the function of morality\nand (ii) general features of our moral practices, to (iii) the\ndynamics of morally or politically significant social issues and (iv)\nthe emergence, existence, and stability of particular moral norms. The\nsecond way in which game theory is relevant to ethics is\njustificatory. Here game theoretic tools are used to justify\nthings ranging from (i) particular norms or principles, to (ii) large\nscale social institutions, or (iii) general characteristics of our\nmoral practices. In what follows, we shall consider each of these\nuses, including the ways in which the former complement the\nlatter.\n",
    "toc": [
        {
            "#Hist": "1. History"
        },
        {
            "#FuncMora": "2. The Function of Morality"
        },
        {
            "#RecoMoraPrudRati": "3. Reconciling Morality and Prudential Rationality"
        },
        {
            "#InseGoodStra": "3.1 The Inseparable Goods Strategy"
        },
        {
            "#SociSancStra": "3.2 The Social Sanctions Strategy"
        },
        {
            "#RefoDeciTheoStra": "3.3 The Reformed Decision Theory Strategy"
        },
        {
            "#LimiRecoProj": "3.4 Limitations of the Reconciliation Project"
        },
        {
            "#GameTheoCont": "4. Game Theory and Contractarianism"
        },
        {
            "#BargProb": "4.1 The Bargaining Problem"
        },
        {
            "#EvolApprSociCont": "4.2 Evolutionary Approaches to the Social Contract"
        },
        {
            "#AnalMoraSignSociIssu": "5. Analyzing Morally Significant Social Issues"
        },
        {
            "#NuclConf": "5.1 Nuclear Conflict"
        },
        {
            "#BadNorm": "5.2 Bad Norms"
        },
        {
            "#ClimChanEnvi": "5.3 Climate Change and the Environment"
        },
        {
            "#Conc": "6. Conclusion"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. History\n\nJohn von Neumann and Oskar Morgenstern laid the foundations of\nclassical game theory in their treatise Theory of Games and\nEconomic Behavior (von Neumann & Morgenstern 1944). Following\na series of refinements published in the 1950s by numerous theorists,\nmost notably John Nash, game theory then transformed social science\nover the course of the next several decades. Noncooperative game\ntheory, the more fundamental branch of game theory, explores\nscenarios where the results of an agent\u2019s actions depend upon\nwhat other agents do, and where agents lack external mechanisms for\nenforcing agreements. More precisely, it provides a model of how\nagents satisfying certain criteria of rationality interact in\ngames characterized by the actions or\nstrategies available to each of the agents and the\npayoffs they can achieve. Payoffs in such scenarios are a\nproduct of the joint strategy profile that is defined by the\nactions independently chosen by the respective agents and the\nstate of the world that obtains which reflects aspects of the\ngame that are variable and over which no agent has control. Many\nscenarios in noncooperative game theory can be fruitfully analyzed\nusing ordinal preferences constructed from agents\u2019\nrankings of possible outcomes. However, von Neumann and Morgenstern\nalso introduced a theory of cardinal utility that provides a\nmore precise account of payoffs by using agents\u2019 preferences\nover lotteries to reflect how much agents prefer one outcome to\nanother. Utilizing this framework, a more varied set of solution\nconcepts was developed to predict how games would be played, and to\ndetermine when individual agents are employing optimal strategies and\nwhat the consequences of this are for the set of all agents.\n\nOne of the most widely utilized solution concepts is the Nash\nequilibrium. Based upon the Bayesian rationality\ncriterion according to which one chooses so as to maximize her\nexpected utility, a Nash equilibrium is a profile of strategies\nadopted by a set of agents in which the strategy adopted by each agent\nmaximizes her respective payoff given the probabilistically\nindependent strategies adopted by other agents. In other words, at a\nNash equilibrium each agent\u2019s strategy is a best response to the\nothers\u2019 strategies, so that none can do better by acting\ndifferently given what others are doing. Although Nash was not the\nfirst to introduce this equilibrium concept, its broad applicability\nwas recognized only after Nash refined the concept and proved that if\na noncooperative game has finitely many pure strategy profiles, then\nat least one Nash equilibrium always exists. Prior to Nash\u2019s\nproof it was widely known that many games lack a Nash equilibrium in\npure strategies where each agent optimally responds to what\nevery other agent does by adopting one of the actions available to\nher. This initially limited the class of problems to which the concept\ncould be applied, but Nash showed that in such cases there will always\nbe a Nash equilibrium in mixed strategies were each agent\noptimally responds to what other agents do by choosing among a subset\nof the strategies available to her with some probability. The\nusefulness of this concept would then be further extended by\nsubsequent refinements, including most notably those made by John\nHarsanyi and Reinhard Selten (see, e.g., Harsanyi & Selten\n1988).\n\nIn addition to his work refining solution concepts in noncooperative\ngame theory Nash also made important contributions to cooperative\ngame theory, an approach to modeling strategic interactions that\nextends things by allowing for the possibility that agents can be\nconstrained by binding agreements. Among other things, cooperative\ngame theory provides a set of tools for analyzing questions related to\ncoalition building, as well as problems that arise in contexts where\nagents can rely on external authorities to enforce agreements.\nNash\u2019s most important contribution here was to introduce two\napproaches to analyzing the bargaining problem. This problem\nhas been important in contractarian approaches to justifying moral and\npolitical orders, a subject we\u2019ll return to in\n section 4.\n\nA third approach to using game theoretic tools to model social\ninteractions explores how boundedly rational agents might\nachieve certain outcomes as a result of inductive learning or\nthe presence of focal points. The inductive learning aspect\nof this approach is known as\n evolutionary game theory,\n so-called because much of the early work on inductive learning was\napplied to the question of why various biological traits or behavioral\npatterns emerge in particular populations. John Maynard Smith\u2019s\nEvolution and the Theory of Games (1982) is an early classic\nin this tradition, while subsequent work by anthropologists,\neconomists, and political scientists would apply this approach to\nproblems of interest to social and political philosophers, including\nespecially how cooperation can be sustained in large groups. Where\nmuch of the foundational work on inductive learning was done by\nbiologists, much of the early work on focal points was done by\neconomists, with Thomas Schelling\u2019s book The Strategy of\nConflict (1960) being particularly influential. Roughly speaking,\nfocal points are actions or outcomes that are likely to be\nsalient (Lewis 1969: 35\u201336) in the sense that they\n\u201cstand out\u201d to the agents involved in a game. As Schelling\nshowed, such points are especially important in games where the\nstrategy space is large and/or there are many potential\nequilibria.\n\nRichard Braithwaite was the first professional philosopher to formally\nemploy game theory in the analysis of a problem of ethics. In his 1954\nlecture Theory of Games as a Tool for the Moral Philosopher\n(published 1955), Braithwaite used Nash\u2019s bargaining problem to\nargue for a particular resolution to the fair division\nproblem. He also conjectured that game theory might transform moral\nphilosophy, much as statistics had transformed the social sciences.\nAlthough this transformation has not taken place in philosophy in the\nway that it has for some of the other social sciences, game theory has\nmade significant inroads into moral and political philosophy in the\nyears since Braithwaite\u2019s lecture. David Gauthier\u2019s\nMorals by Agreement (1986) and Ken Binmore\u2019s Game\nTheory and the Social Contract (2 volumes, 1994, 1998) are\narguably the first two works to present systematic moral theories\nbuilt from game-theoretic foundations. Gauthier\u2019s theory is\nrooted in classical game theory, although he proposes revisions to the\northodox account of Bayesian rationality that classical theory\ntypically assumes. Binmore\u2019s theory, on the other hand,\nintegrates elements of both evolutionary and classical game theory.\nOther significant uses of game theory in ethics include, but are not\nlimited to:\n\nanalyses of social conventions as equilibria of games predicated\nupon common knowledge (Lewis 1969; Vanderschraaf 2019);\nanalyses of social norms (Ullmann-Margalit 1977; Basu 2000;\nBicchieri 2006, 2017; Brennan, Eriksson, Goodin & Southwood\n2013);\nexplanations of elements of social contracts in terms of\nevolutionary game theory (Sugden 1986; Skyrms 1996); and\napplications of Nash\u2019s bargaining theory in alternative\nsocial contract theories (Gaus 2010; Muldoon 2016; Moehler 2018;\nVanderschraaf 2019).\n\n\nFurthermore, although the formal frameworks associated with game\ntheory did not emerge until the mid-twentieth century, it\u2019s now\nwidely recognized that the work of many earlier philosophers are\namenable to game theoretic analysis, and that, in many cases, these\nworks clearly anticipated important developments in game theory. For\ninstance, Barry (1965), Gauthier (1969), Hampton (1986), Kavka (1986),\nand Taylor (1987) provide game-theoretic characterizations of\nHobbes\u2019 arguments for the inevitability of war in the State of\nNature and for the benefit of establishing a sovereign. Indeed, this\nbranch of Hobbes scholarship continues to develop, as evidenced by\nrecent works by Vanderschraaf (2007 & 2010), Moehler (2009), and\nChung (2015). And, while Hobbes\u2019 arguments have attracted the\nmost attention from game-theoretic minded scholars, Grotius (1625),\nPufendorf (1673), Locke (1689), Hume (1740), and Rousseau (1755) also\noffer what can be interpreted as informal game-theoretic arguments in\ntheir discussions of morality, the State of Nature, and the natural\nlaw. Of these, Hume\u2019s analysis of convention in the\nTreatise (Hume 1740: 3.2.2\u201310) is particularly\nnoteworthy for its informal account of equilibria and analysis of the\nrole that mutual knowledge plays in allowing agents to arrive at and\nsustain certain equilibria (Vanderschraaf 1998). Moreover,\nHume\u2019s discussion of how agents can settle into conventions as\nthe result of gradual trial and error processes, and his suggestion\nthat agents follow some conventions as a result of properties that\nmake certain alternatives conspicuous, anticipates analyses of games\nbased on both inductive learning and focal points (Skyrms 1996; Sugden\n1986).\n2. The Function of Morality\n\nOne of the most widespread uses of game theory in ethics has been to\npostulate various functions of morality and to identify some\nof its important features. An early example of this is Edna\nUllmann-Margalit\u2019s The Emergence of Norms which argues\nthat morality can be understood as a system of norms that enable\nagents to coordinate their actions in order to achieve mutually\nadvantageous outcomes in situations where the pursuit of self-interest\nwould normally prevent this (Ullmann-Margalit 1977). The now classic\nexample she uses to illustrate this involves two soldiers who must\nchoose whether to man their mortars in order to stem the advance of\nthe enemy, or to flee. If both stay, it is certain that the\nenemy\u2019s advance will be halted, but the soldiers will almost\nsurely be injured. If both flee, the enemy will not only be able to\ntake the mountain pass, it will also be able to overtake and capture\nthe fleeing soldiers. And if just one of them stays while the other\nflees, the brave soldier will die trying to hold off the enemy, while\nthe other will have just enough time to escape to safety.\n\nThe scenario Ullmann-Margalit presents is an example of a\n prisoner\u2019s dilemma\n and is illustrated in\n Figure 1\n below. In this strategic form game, each soldier acts\nwithout observing the other\u2019s action. Each soldier has the\nchoice between the strategies of fleeing (F) or\nstaying (S). The cells in the matrix correspond to\nthe outcome of each possible pair of choices, with the numbers in the\ncells representing the utilities of the outcomes for the soldiers.\nSpecifically, higher numbers correspond to a more preferred outcome,\nand the first number represents the payoff of Soldier 1 who chooses\nbetween the actions corresponding to the rows, while the second number\nrepresents the payoff of Soldier 2 who chooses between the actions\ncorresponding to the columns.\n\n\n\n\n\u00a0\n\u00a0\nSoldier 2 \n\n\u00a0\n\u00a0\nS\nF  \n\n\nSoldier 1\nS\n(2,2)\n(0,3) \n\nF\n(3,0)\n(1,1)  \n\n\nS = stay, F = flee\n\nFigure 1. Ullmann-Margalit\u2019s\nMortarmen\u2019s Dilemma\n\n\nIn this situation each soldier has a reason to flee. This is because\nfleeing provides the only chance of escaping unharmed, which is the\noutcome each most prefers. However, the situation is a dilemma,\nbecause if each soldier pursues this course of action, then they will\nboth end up worse off than if neither had. Furthermore, the dilemma is\nmagnified by the fact that for each soldier, F is\nhis unique best response to any strategy the other soldier might\nchoose. That is, F is each soldier\u2019s\nstrictly dominant strategy, and \\((F,F)\\) is the unique\nNash equilibrium of this game even though both soldiers would\nfare better is they could somehow follow \\((S,S).\\)\n\nUllmann-Margalit pointed out that if the soldiers understood the\nnature of their predicament they might want to do something to prevent\nthemselves from both fleeing and subsequently being captured. More\nimportantly, she argued that the prisoner\u2019s dilemma that\ncharacterizes their predicament arises in innumerable interactions\nthat we find ourselves in every day. At first glance, the obvious\nsolution to these dilemmas might seem to be for the soldiers to simply\npledge to remain at their posts. The problem, however, is that in\nscenarios like this promises are unlikely to be credible, and, even\nwhen they are, they are prone to being exploited. Instead, what the\nsoldiers need is a way of literally or figuratively chaining\nthemselves to their mortars. Drawing on this observation,\nUllmann-Margalit\u2019s suggestion was that it is moral norms that do\nthis work. More specifically, it\u2019s not the promises to remain at\ntheir posts that solves the soldiers\u2019 predicament, so much as\ntheir commitment to keeping their promises and to sanctioning those\nwho don\u2019t.\n\nOne way of understanding views like this is that the function of\nmorality is to prevent failures of rationality. In the next section we\nwill discuss how game theory has been used to analyze the relationship\nbetween morality and prudential rationality. In the more recent\nliterature, though, there is growing consensus that the role norms of\nsocial morality play is not necessarily to constrain our instrumental\nreasoning so that we can overcome failures of prudential rationality,\nbut rather to transform mixed-motive games like the prisoner\u2019s\ndilemma into coordination problems where mutually advantageous\noutcomes are more stable and easier to arrive at. A classic example of\nthis approach is Bicchieri (2006). Like Ullmann-Margalit, Bicchieri\ncharacterizes norms in terms of our commitment to certain courses of\naction, and also emphasizes the importance of sanctions in this\ncontext. However, Bicchieri draws a distinction between social norms\nand other types of norm, and argues that what distinguishes the former\nfrom the latter is the conditional nature of our commitment to them.\nIn particular, compliance with social norms is grounded in both an\nindividual\u2019s (i) empirical expectation that a\nsufficiently large percentage of the population conforms to the norm,\nand (ii) her normative expectation that a sufficiently large\npercentage of the population expects others to conform to the norm.\nOnly when both of these expectations are satisfied will an individual\ncomply with a social norm. Because some individuals will be more\nsensitive to the expectations of others, or more inclined to want to\nsee a particular norm complied with, though, the relevant expectations\nmay vary between individuals. Only when expectations are satisfied for\na sufficiently large number of people, then, will the norm succeed in\ntransforming a social dilemma where mutually advantageous outcomes are\nunstable into a more easily solved coordination problem. And while it\nmight seem strange at first glance to suggest that norms we are only\nconditionally committed to are the lynchpin of social morality, given\nthe significant role social dilemmas play in preventing us from living\nwell together, this shouldn\u2019t be surprising. For a more thorough\ndiscussion of these issues see the entry on\n social norms.\n\nSo far our discussion has focused on how game theory has been used to\nillustrate some ostensible functions of morality and the role social\nnorms play in it. However, game theory has also been utilized to\nidentify particular norms that might be important, as well as to\nidentify important characteristics of norms. And, where the previous\nanalysis relied primarily on the tools of non-cooperative game theory,\nhere it is evolutionary game theory that has been especially\nilluminating. Particularly influential in this regard was the work of\nRobert Axelrod and colleagues in the early 1980s on the evolution of\ncooperation, along with the subsequent work of Robert Boyd, Peter\nRicherson, and various collaborators (see Axelrod 2006 and Boyd &\nRicherson 2005 for summaries of the relevant work). By analyzing the\nperformance of various fixed strategies in repeated social dilemmas\nthey were able to illustrate the important role that conditional\nstrategies and the willingness to sanction bad behavior play in\nallowing cooperation and other prosocial behaviors to not only emerge,\nbut become optimal from the standpoint of the individual. More\nspecifically, they showed that in environments where individuals have\na long-run interest in bringing about mutually advantageous outcomes\nbut a short-term interest in exploiting others for maximum gain, it is\nessential that (i) individuals not leave themselves vulnerable to\nrepeated exploitation, and (ii) at least some individuals be willing\nto punish exploitative behavior.\n\nFor Axelrod, who studied these issues primarily in the context of\nrepeated prisoner\u2019s dilemmas, the two requirements identified\nabove amount to the same thing. A strategy of unconditional\ncooperation allows an individual to be repeatedly taken advantage of.\nTo prevent this she should only cooperate with those who are similarly\nwilling to cooperate. More precisely, she should be nice\n(that is she should initially be willing to cooperate with anyone),\nbut she should also be provocable (that is she should be\nprepared to stop cooperating with anyone who takes advantage of her,\nat least for some amount of time). And, because sustained cooperation\nis in everybody\u2019s long-run interest, in this context withdrawing\nfuture cooperation as a consequence for being taken advantage of is a\nform of punishment.\n\nAs Boyd and Richerson showed, though, in many contexts it\u2019s not\nessential that everybody be willing to punish bad behavior. What is\nessential is that enough individuals are willing to do this.\nHowever, this generates a pair of puzzles. First, in many cases\nit\u2019s costly to police norms. In order to sustain cooperation,\nthen, groups often need some of their members to be prepared to engage\nin altruistic punishment. That is, some individuals need to\nbe willing to incur individual costs associated with punishment for\nthe benefit of others. Second, the willingness of some individuals to\npolice norms does not just allow the evolution of cooperation and\nother prosocial norms. Instead it potentially allows any norm to\nemerge and become stable. So, although we\u2019ve seen how game\ntheory can help explain why a disposition to comply with and police\ncertain norms may be important features of morality, important\nquestions remain concerning whether this is necessarily rational\nfrom the perspective of the individual. We\u2019ll turn to\nthose questions now. And in section 5 we\u2019ll return to the\nquestion of how to distinguish good from bad norms.\n3. Reconciling Morality and Prudential Rationality\n\nKavka (1984) dubs the body of attempts to establish that compliance\nwith moral requirements is demanded by, or at least compatible with,\nprudential rationality the Reconciliation Project. At least\nsince Plato philosophers have been grappling with this project, and\ngame theory can help us to distinguish between three approaches they\nhave taken.\n\nThe challenge presented by Hobbes\u2019 Foole in Leviathan\n(Hobbes 1651: chapter 15) nicely characterizes the core issue at stake\nin the Reconciliation Project. The Foole maintains that under certain\ncircumstances one\u2019s \u201cmost reasonable\u201d course of\naction is to commit an injustice. Specifically, the Foole claims one\nshould sometimes break a promise she has made as part of a covenant if\nthe other parties to the covenant have already kept (or will be\ncompelled to keep) their promises (Hobbes 1651: 15:5). This is because\nperforming as a covenant requires can be costly and rationality\nplausibly requires that such costs should be avoided if one\ndoesn\u2019t stand to gain anything further by incurring them. This\nchallenge is illustrated in the decision tree in\n Figure 2\n below.\n\n\n\nFigure 2. Foole\u2019s Opportunity Game\n[An\n extended description of figure 2\n is in the supplement.]\n\n\nHere Claudia and Laura have created a bilateral covenant by exchanging\npromises. But because Claudia has already performed her part of the\ncovenant, and Laura knows this, Laura stands in the position of the\nFoole and can either perform (P) as the covenant\nrequires of her or aggress (A) by breaking her\npromise and exploiting Claudia\u2019s earlier performance. As the\nFoole contends, given this payoff structure, A is\nLaura\u2019s unique Bayesian rational choice.\n\nImportantly, though, the Foole does not just present a challenge to\nthose who endorse her reasoning. This is because in order to avoid\nbeing taken advantage of by individuals who reason like the Foole,\nindividuals who might otherwise be inclined to keep their promises can\nsometimes find themselves with reason to break their promises. We see\nthis in\n Figure 3\n below which depicts the sequential prisoner\u2019s dilemma\nthat results from extending the decision tree from\n Figure 2\n to include Claudia\u2019s initial move.\n\n\n\nFigure 3. Sequential Prisoner\u2019s\nDilemma [An\n extended description of figure 3\n is in the supplement.]\n\n\nIn this extensive form game, which makes explicit the\nsequential order of the agents\u2019 actions, the\nith component of each payoff vector is the payoff\nof the ith agent who moves in the game (so\nClaudia\u2019s payoff is depicted first, since she acts first). Here\nwe can suppose that Claudia does not agree with the Foole that one\nshould break her promise if one\u2019s partner in a covenant has kept\nher promise, but a dilemma nevertheless arises if Claudia suspects\nthat Laura might agree with the Foole. This is because Claudia might\nreason that if she performs, then Laura, having already benefited and\nnot standing to gain anything further, will not reciprocate.\nConsequently, Claudia, anticipating (A)\nLaura\u2019s aggression, decides not to perform, leading Laura, now\nunderstandably, not to perform either, so that each ultimately does\nworse than if they had both performed.\n\nTo take up the Reconciliation Project is to argue alongside Hobbes\nthat the Foole is not right, and that we need not worry that for some\namong us rationality might counsel against acting as morality\nrequires. And, as we indicated above, there are three main strategies\nfor doing so.\n3.1 The Inseparable Goods Strategy\n\nThe inseparable goods strategy appeals to certain benefits\none can gain or preserve only by acting morally, that the Foole\napparently fails to consider. Plato\u2019s account of the benefits of\njustice in the Gorgias and Republic is one example\nof this approach. Plato maintains that if one commits an injustice,\nthen one\u2019s soul will consequently be corrupted, and he further\nmaintains that to have a corrupt soul is the worst of all possible\nmisfortunes (Gorgias 478c3\u2013478e5, Republic\n353d3\u2013354a7). Alternatively, one might follow Aquinas in arguing\nthat an injustice like stealing is a mortal sin which will bring about\nterrible consequences in the afterlife (Aquinas 1271: II.II Q. 66 A.\n6). Or Sidgwick, who emphasizes the internal sanctions of\nduty one is likely to suffer on account of their immoral conduct\n(Sidgwick 1874 [2011: 164]). Viewed through the lens of game theory,\nthe inseparable goods approach recommends that those who doubt the\nprudential rationality of acting morally should reevaluate their\npreferences in light of the totality of goods at stake. For example,\n Figure 4\n below illustrates how the scenario depicted in\n Figure 3\n would change if Laura becomes persuaded that she would suffer a cost\n\\(\\gamma > 1\\) as a result of breaking her covenant with Claudia,\nperhaps owing to the guilt she might feel for committing an\ninjustice.\n\n\n\n\n\nFigure 4. Sequential Exchange Game with\nRevised Payoffs, [An\n extended description of figure 4\n is in the supplement.]\n\n\nThis extensive form game depicts Laura\u2019s true payoffs, including\nthe cost of guilt that Sidgwick would call an internal sanction. In\nthis game if Claudia performs as promised, then to follow P\nas justice requires is now Laura\u2019s best response. However, this\nisn\u2019t because we\u2019ve simply assumed that one couldn\u2019t\never stand to gain by breaking a promise. To see why, note that if\nClaudia breaks her promise first, then A continues to be\nLaura\u2019s best response. As we saw in our discussion of the\nevolution of cooperation, morality can\u2019t require us to be\nsuckers. Or, to use Kavka\u2019s helpful terminology, justice may\nforbid violating a covenant offensively by breaking\none\u2019s promise unexpectedly, while permitting defensive\nviolations of covenants that others can no longer reasonably expect us\nto honor (Kavka 1986: 139). Accordingly, if Claudia offensively\nviolates her covenant with Laura by following A, then if\nLaura responds in kind, Laura\u2019s violation should not give rise\nto the internal sanctions associated with having committed an\ninjustice. Furthermore, note that the presence of internal sanctions\ncan change things even when these aren\u2019t universally felt. For\ninstance, even if Claudia herself would feel negligible guilt for\noffensively violating their covenant, if Claudia knows that Laura\nwould suffer the internal sanction cost \\(\\gamma > 1\\) of offensive\nviolation, then Claudia can expect Laura to perform when she does as\nwell, and in this case she fares best by following P at the\noutset.\n3.2 The Social Sanctions Strategy\n\nWhere the previous approach to the Reconciliation Project relied on\nsanctions that an agent imposes on herself, the social sanctions\nstrategy relies on costs imposed by others. This strategy is\nexemplified by Hobbes\u2019 response to the Foole and Hume\u2019s\ndiscussion of the harvesting dilemma, the latter of which Skyrms\n(1998) and Sobel (2009) identify with the game previously depicted in\n Figure 2.\n Hobbes maintains that to offensively violate a covenant is to make a\nchoice that tends towards self-destruction, since others will be\nunwilling to enter into future covenants with one known to do so\n(Hobbes 1651: 15:5). Similarly, Hume argues that we make promises in\norder to create expectations of our future conduct, and that we keep\npromises in order to preserve the trust of others that is needed if we\nhope to enter into and benefit from future covenants (Hume 1740:\n3.3.5: 8\u201312). As our earlier discussion of the evolution of\ncooperation anticipated, we can use the theory of repeated\ngames to shed light on this strategy.\n\nWhen agents engage in a sequence of interactions, each of which can be\ncharacterized as a single noncooperative game, then they can adopt\nhistory-dependent strategies where their actions in any\nparticular iteration of the game depend upon actions taken in prior\niterations. Early on, game theorists recognized that when agents\nengage in games that are repeated indefinitely they can use\nsuch strategies to arrive at equilibria that include acts that are\nnever parts of an equilibrium of any of the constituent games that are\nbeing repeated. This insight led to a body of results known as the\nfolk theorem that establishes conditions under which a\nprofile of history-dependent strategies will be an equilibrium of an\nindefinitely repeated game. Sugden (1986) and Skyrms (1998) were among\nthe first to argue that Hobbes\u2019s response to the Foole and\nHume\u2019s analysis of promises present proto-folk theorem\narguments.\n\nTo illustrate how the folk theorem might support the social sanctions\nstrategy, suppose that Laura and Claudia are interested in exchanging\nwith one another and that their situation has the structure of the\nprisoner\u2019s dilemma depicted in\n Figure 5\n below.\n\n\n\n\n\u00a0\n\u00a0\nParty 2 (Laura) \n\n\u00a0\n\u00a0\nP\nA  \n\n\nParty 1 (Claudia)\nP\n(2,2)\n(0,3) \n\nA\n(3,0)\n(1,1)  \n\n\nP = perform, A = anticipate\n\nFigure 5. Prisoner\u2019s Dilemma\n\n\nThis prisoner\u2019s dilemma is structurally identical to the\nMortarmen\u2019s Dilemma of\n Figure 1,\n but here we interpret the parties\u2019 strategies rather\ndifferently. (A, A) is the unique equilibrium of\nthis game that characterizes Laura and Claudia\u2019s particular\ninteraction with one another. However, if we suppose that their\ninteraction is one of an indefinite sequence of similar interactions\nthat they will enter into with each other and other members of their\ncommunity, then they can follow history-dependent strategies. One such\nstrategy, formulated by Sugden (1986), is the Humean\nstrategy:\n\n\\(h^{*}\\): follow P if my current partner is innocent, and\nfollow A if she is guilty,\n\nwhere one is guilty if she has offensively violated a covenant by\nanticipating or aggressing against an innocent partner at some point\nin the past, otherwise she is innocent. If Claudia expects all of her\npartners in the indefinitely repeated prisoner\u2019s dilemma to\nfollow \\(h^{*}\\), then \\(h^{*}\\) can be Claudia\u2019s best response.\nFor example, if Claudia and Laura are both innocent when they meet in\ntheir prisoner\u2019s dilemma, then if Claudia follows \\(h^{*}\\), she\nwill perform and remain innocent, and so she can expect her partners\nin future iterations to perform with her since they also follow\n\\(h^{*}\\). If, on the other hand, Claudia anticipates against Laura,\nthen Claudia becomes guilty and she should expect future partners to\nanticipate against her in future iterations as \\(h^{*}\\) requires. In\nother words, if Claudia has sufficiently high expectation that the\nsequence of iterated prisoner\u2019s dilemmas will continue, then the\nshort-run benefit from offensively violating her covenant with Laura\nwill be swamped by the long-run payoff from future mutually beneficial\ninteractions that \\(h^{*}\\) enables and anticipating precludes.\nFurthermore, the long-run benefit of keeping her reputation intact\nmeans that as long as Claudia\u2019s discount rate isn\u2019t too\nhigh, then this is likely to be true even if she misread things with\nLaura and gets exploited by her. Finally, because their situations are\nsymmetrical, \\(h^{*}\\) can be a best response for Laura and all the\nother community members, provided that they all expect most other\ncommunity members to follow \\(h^{*}\\).\n\nThe discussion above shows that obeying the requirement of justice to\nrefrain from offensively violating covenants can be rational, even\nthough it may not appear to be rational in any particular instance.\nLike the inseparable goods strategy, then, the social sanctions\nstrategy implies that the mistake the Foole makes is to misconstrue\nthe games that characterize social interactions where morality makes\ndemands on us. However, where the inseparable goods strategy suggests\nthat the Foole ignores some of the goods intrinsic to moral conduct,\nthe social sanctions strategy warns the Foole that the game they\nshould be concerned with is not any particular interaction, but rather\nthe indefinitely repeated series of social interactions in which they\nare inevitably engaged. That said, the strategy profile where every\nagent adopts \\(h^{*}\\) is not the only possible equilibrium of the\nindefinitely repeated prisoner\u2019s dilemma. In fact, there are an\nimmense number of possible equilibria of such a game, many of which do\nnot involve any individuals employing the \\(h^{*}\\) strategy, and not\nall of these lead to the cooperative outcome where all (or even most)\nagents keep their promises.\n3.3 The Reformed Decision Theory Strategy\n\nIn contrast to the inseparable goods and social sanctions strategies\nthat question the Foole\u2019s characterization of the scenarios that\ngive rise to a tension between morality and rationality, the\nreformed decision theory strategy recommends that agents like\nthe Foole revisit their understanding of rational choice. In\nparticular it proposes an account of rational choice that is more\nsubtle than the orthodox Bayesian account according to which rational\nchoice is a fairly straightforward matter of maximizing expected\nutility. David Gauthier (1986) and Edward McClennen (1990) are the\nmost prominent exemplars of this approach, with Gauthier proposing a\nprinciple of constrained maximization and McClennen a\nprinciple of resolute choice. For ease of exposition we focus\non Gauthier.\n\nIn Morals by Agreement Gauthier distinguishes between\nstraightforward maximizers and constrained\nmaximizers. A straightforward maximizer is an orthodox Bayesian\nwho, at any given moment in time, chooses so as to maximize her\nexpected utility given her beliefs regarding the relevant states of\naffairs and the choices her counterparts might make. A constrained\nmaximizer, on the other hand, departs from orthodox Bayesian reasoning\nby doing her part to bring about a fair and optimal outcome if (i) she\nexpects her counterparts to do their part in bringing about this\noutcome, and (ii) she benefits as a result of all following it. A\nconstrained maximizer thus constrains her pursuit of her interests\nsome of the time, but reverts to straightforward maximization if she\nexpects her counterparts to act as straightforward maximizers, or if\nshe does not stand to benefit from constraining her behavior relative\nto the scenario where no one constrains their behavior.\n\nFor example, if Claudia is a constrained maximizer, then in the\nprisoner\u2019s dilemma depicted in\n Figure 5\n Claudia will perform if she believes Laura is also a constrained\nmaximizer, but will anticipate if she believes Laura is a\nstraightforward maximizer. One way to understand how constrained\nmaximization modifies an agent\u2019s behavior is to regard adopting\none\u2019s principle of rationality as a meta-strategy for engaging\nin prisoner\u2019s dilemma-like games. If Claudia and Laura each\nadopt either the straightforward maximizer (SM) or the\nconstrained maximizer (CM) meta-strategy, then the\nprisoner\u2019s dilemma depicted in\n Figure 5\n is transformed into the game depicted in\n Figure 6\n below.\n\n\n\n\n\u00a0\n\u00a0\nParty 2 (Laura) \n\n\u00a0\n\u00a0\nCM\nSM  \n\n\nParty 1 (Claudia)\nCM\n(2,2)\n(1,1) \n\nSM\n(1,1)\n(1,1)  \n\n\nCM= constrained maximization, SM = straightforward\nmaximization\n\nFigure 6. Meta-Strategy Game for\nPrisoner\u2019s Dilemma\n\n\nHere, whatever strategy the other party follows, one always does at\nleast as well and sometimes better by following CM as opposed\nto SM. That is, CM is a weakly dominant\nstrategy for both Claudia and Laura, and (CM, CM) is\nthe unique Pareto-optimal Nash equilibrium. Gauthier argues that there\nare a wide variety of social dilemmas where constrained maximizers\nfare at least as well as straightforward maximizers, and can often\nfare strictly better, so long as agents\u2019 dispositions towards\nconstrained or straightforward maximization are sufficiently clear to\neach other. Accordingly, Gauthier concludes that agents should adopt\nthe constrained maximization principle, and that, when they do,\ncompliance with the requirements of morality coincides with rational\nchoice.\n3.4 Limitations of the Reconciliation Project\n\nAs we\u2019ve seen, game theory has been incorporated into each of\nthe main approaches to the Reconciliation Project. However,\ngame-theoretic analysis can also show why each of these strategies may\nfall short of fully reconciling morality with prudential rationality.\nFor instance, for the inseparable goods strategy to be effective,\nagents like the Foole must be persuaded that the goods intrinsic to\njust conduct are either of such great value, or that the costs\nassociated with injustice are so substantial, that one would be\nfoolish to risk acting unjustly. But it\u2019s far from obvious that\nthis is always (or even usually) true.\n\nSimilarly, although one can present social sanctions arguments for\nacting morally to agents like the Foole, these arguments depend on\nmembers of society being willing to sanction bad behavior and capable\nof doing so effectively, and this is by no means guaranteed. In fact\nthis is a difficulty that the functional analysis of norms clearly\nanticipates. For example, in addition to highlighting the importance\nof conditional strategies and the willingness to sanction bad behavior\nAxelrod (1984) also emphasized the importance of employing strategies\nthat are easy for others to interpret. While Bicchieri (2006)\nemphasizes the problems that are prone to arise in circumstances where\nit\u2019s not clear which norm applies, and Boyd & Richerson\n(2005) have drawn attention to the costs associated with policing\nnorms. Accordingly, the Foole can object that, even if all the members\nof her community were committed to following something like the Humean\nstrategy to the best of their abilities, it\u2019s not obvious that\nthey would be able to reliably follow it. In fact, the Humean strategy\nrests upon some rather demanding epistemic assumptions, including\nespecially that community members can reliably distinguish between\nguilty and innocent partners, something that may become increasingly\nunlikely as the size of a community increases.\n\nFurthermore, as the folk theorem implies, although it\u2019s\ncertainly possible that all of the members of a community could follow\na strategy like \\(h^{*}\\) in a situation like the Foole finds herself\nin, there are likely to be many other equilibria as well. Moreover,\nsome of these equilibria may be hard to distinguish from one another,\nespecially if agents like the Foole are sufficiently rare, and in some\nof these equilibria it may be in the Foole\u2019s interest to\noffensively violate covenants. The effectiveness of the social\nsanctions strategy, then, is plainly dependent upon the ability of\ncommunity members to build and maintain reliable reputations, and to\nrely on this information in their interactions with one another.\n\nFinally, the revisionary principles at the heart of the reformed\ndecision theory strategy proposed by Gauthier and McClennen rest upon\nan agent\u2019s ability to adopt a disposition to conditionally\nfollow certain pro-social strategies regardless of whether doing so is\nin an agent\u2019s best interest at the moment of action. Critics of\nthis strategy, however, have questioned what it means to bind oneself\nto her past commitments in this way, and they have also identified\nnumerous cases where doing so would be in neither an agent\u2019s\nshort nor long-run interest. Furthermore, while Gauthier\u2019s\nanalysis of the benefits of constrained maximization is analogous in\nsome ways to Bicchieri\u2019s analysis of how social norms can\ntransform mixed-motive social dilemmas into coordination games, the\nlatter depend on sanctions (or expectations of sanctions) in a way\nthat the former do not. As a result, even if agents could credibly\nadopt dispositions to constrain their future behavior, for a rule like\nconstrained maximization to do its practical work, agents must be able\nto recognize who has and has not adopted the dispositions in\nquestion. However, some critics doubt that we can reliably recognize\nwho adopts such dispositions. Of course, proponents of the reformed\ndecision theory strategy are well aware of these criticisms and have\ndeveloped careful responses in their works. So far, though, its\ncritics have not been assuaged and the reformed decision theory\nstrategy has been the least influential of the approaches described\nhere.\n4. Game Theory and Contractarianism\n\nArguably the most systematic use of game theory in moral and political\nphilosophy has been in contractarian approaches to justifying moral or\npolitical orders. Philosophers have typically characterized the\nsocial contract as a set of rules for regulating the\ninteractions of members of a community. By providing a formal model of\ninteractive decision-making, game theory is clearly relevant to the\nanalysis of such contracts. What has been particularly distinctive of\ngame theoretic analysis of the social contract, though, is an emphasis\non bargaining problems. As we will discuss below, the Nash bargaining\nproblem provides a simple, yet flexible and conceptually powerful\nframework for identifying which of the rules that might comprise a\ncontract can be said to be mutually beneficial (or acceptable) to each\nmember of a community. In the main text of the two subsections that\nfollow we try to present a relatively non-technical overview of this\nframework. Where formal characterizations of concepts are important,\nor where discussion of technical issues is likely to be illuminating\nfor some readers, we\u2019ve included such discussion in notes that\nappear at the end of the respective subsections. For a more thorough\nanalysis of contractarian approaches to justifying moral and political\norders, including further discussion of some of these technical\nissues, see the entry on\n contemporary approaches to the social contract.\n4.1 The Bargaining Problem\n\nAs Gauthier (1986) argues, the bargaining problem provides a framework\nfor a contractarian analysis of the social contract by\nmodeling how parties with partially conflicting interests might arrive\nat a mutually acceptable set of rules they can each follow to their\nown advantage. This contrasts with the contractualist\napproach of Harsanyi (1953, 1955, 1977), Rawls (1958, 1971), and\nScanlon (1982, 1998) that characterizes the social contract as an\nobject of rational choice made under constraints designed to ensure\nthat the choice is appropriately unbiased, and which, in principle,\ncould be made by a single agent. Braithwaite (1955) was the first to\nuse the Nash bargaining problem to derive a social contract, in his\ncase a rule for fairly dividing a resource between two claimants.\nLater, Hampton (1986) and Kavka (1986) argued that the Hobbesian\ndevice of creating a commonwealth by design incorporates\nelements of a Nash bargaining problem. Gauthier (1986) and Binmore\n(1994, 1998) used the Nash bargaining problem for developing\nstandalone theories of distributive justice. More recently, Muldoon\n(2016) and Moehler (2018) have used the Nash bargaining problem to\nmodel the problem of how members of deeply pluralistic societies can\nfind rules for living together peacefully.\n\nNash characterized the bargaining problem as a combination of (i) a\nfeasible set of payoffs that a group of agents might achieve\neach of which is associated with a respective set of actions the\nagents must jointly agree to follow, and (ii) a nonagreement\npoint that specifies what each agent receives in case they fail\nto follow any of these joint action sets. An example of Nash\u2019s\nbargaining problem is the 2-agent Wine Problem depicted in\n Figure 7\n below.\n\n\n\n\n\u00a0\n\u00a0\nAgent 2 (Laura) \n\n\u00a0\n\u00a0\nD\nH  \n\n\nAgent 1 (Claudia)\nD\n(0,0)\n(0,1) \n\nH\n(1,0)\n(\u22121,\u22121)  \n\n\nD= dove (claim none), H = hawk (claim all)\n\nFigure 7. Wine Problem\n\n\nIn this game Claudia and Laura each have two pure strategies:\nhawk (H), which is to claim an available bottle of\nwine, or dove (D), which is to leave the bottle for\nthe other. The game has two Nash equilibria in pure strategies:\n(H,D), the outcome most favorable to Claudia, and\n(D,H), the outcome most favorable to Laura. If both\ntry to claim the bottle, at the resulting (H,H)\noutcome they fight and neither gets any wine, the worst outcome for\nthem both. The Wine Problem is an example of a conflictual\ncoordination game (Vanderschraaf & Richards 1997), so-called\nbecause it has multiple equilibria, any of which the agents achieve\nonly by coordinating their actions, and where coordination is\ncomplicated by the conflicting preferences of the agents over the\ndifferent available\n equilibria.[1]\n\nOne might think that a natural solution to the Wine Problem is for\nClaudia and Laura to each claim half of the bottle.\n Figure 8\n below thus illustrates an extended version of the Wine Problem in\nwhich each agent now has a third pure strategy, M, in which\nshe claims half the bottle.\n\n\n\n\n\u00a0\n\u00a0\nAgent 2 (Laura) \n\n\u00a0\n\u00a0\nD\nM\nH  \n\n\nAgent 1 (Claudia)\nD\n\\((0,0)\\)\n\\((0,\\frac{1}{2})\\)\n\\((0,1)\\) \n\nM\n\\((\\frac{1}{2},0)\\)\n\\((\\frac{1}{2},\\frac{1}{2})\\)\n\\(({-1},{-1})\\) \n\nH\n\\((1,0)\\)\n\\(({-1},{-1})\\)\n\\(({-1},{-1})\\)  \n\n\nD = dove (claim none), M = moderate (claim half),\nH = hawk (claim all)\n\nFigure 8. Extended Wine Problem\n\n\nIn this game, Laura and Claudia each receives the amount of wine she\nclaims if their claims are compatible, that is, if there is\nenough wine to satisfy each claim. However, if their claims are\nincompatible, they fight. There is now a new Nash equilibrium\nin pure strategies, \\((M,M)\\), where Laura and Claudia each receive\nhalf the bottle. It\u2019s not a foregone conclusion that they will\nsettle into \\((M,M)\\), though, for \\((H,D)\\) and \\((D,H)\\) remain\nequilibria, and the former continues to be most preferred by Claudia,\nand the latter most preferred by Laura.\n\nFurthermore, if each can claim half the bottle why should they not be\nable to claim other shares?\n Figure 9\n below summarizes the bargaining problem that arises when Claudia can\nclaim any share \\(x_1\\) of the wine and Laura can similarly claim any\nshare \\(x_2\\).\n\n\n\nFigure 9. Wine Bargaining Problem [An\n extended description of figure 9\n is in the supplement.]\n\n\nHere Claudia\u2019s payoffs are depicted on the horizontal axis, and\nLaura\u2019s payoffs are depicted in the vertical axis. The green\nshaded region represents the feasible set of payoff vectors\n\\(\\Lambda\\) where Laura and Claudia make compatible claims, that is\nwhere \\(x_1 +x_2 \\le 1.\\) While the payoff vector \\(\\bu_0 =\n({-1},{-1})\\) corresponding to the (H,H) outcome\nrepresents their nonagreement point.\n\nIn the social contract context we can think of the nonagreement point\n\\(\\bu_0\\) as representing the State of Nature, and the feasible set\n\\(\\Lambda\\) as representative of the various contracts parties might\nagree to. Each point \\(\\bu \\in \\Lambda\\) that is weakly Pareto\nsuperior to \\(\\bu_0\\) thus characterizes a social contract with a\ncooperative surplus (Gauthier 1986:\n 141).[2]\n And, when a set of claims constitutes an equilibrium solution to the\nassociated bargaining problem, this allows us to say that the parties\nto a contract all have good reason to comply with its terms. As we\nwill see below, though, there are various approaches to identifying\nthe most attractive equilibrium from a normative point of view. An\nadvantage of using the Nash bargaining approach to modeling the social\ncontract, then, is that this formalization helps to clarify the\ndifferences between these\n approaches.[3]\n\nThe Basis Game that Braithwaite analyzed in his Cambridge lecture is\nideal for illustrating the axiomatic approach to the bargaining\nproblem. In this game two agents, Luke and Matthew, vie for shares of\na limited resource. Like the Wine Problem, the Braithwaite Basis Game\nis a conflictual coordination game in which each agent has two pure\nstrategies available, H in which the agent claims all of the\ngood at stake, and D in which he claims none. Here\n(H,D) is the Nash equilibrium most favorable to Luke\nand (D,H) is the equilibrium most favorable to\nMatthew. As\n Figure 10\n illustrates, though, this game has asymmetries not present in the\nWine\n Problem.[4]\n\n\n\n\n\u00a0\n\u00a0\nAgent 2 (Matthew) \n\n\u00a0\n\u00a0\nD\nH  \n\n\nAgent 1 (Luke)\nD\n\\((\\frac{1}{6},0)\\)\n\\((\\frac{1}{2},1)\\) \n\nH\n\\((1,\\frac{2}{9})\\)\n\\((0,\\frac{1}{9})\\)  \n\n\nD= dove (claim none), H = hawk (claim all)\n\nFigure 10. Braithwaite Basis Game\n\n\nAgain, as before, this game can be extended to accommodate the case\nwhere agents can claim shares of the good. And if the nonagreement\npoint again results in the payoffs generated by the conflict outcome\n(H, H), as Braithwaite supposed, then Matthew and\nLuke are in a Nash bargaining problem with feasible set \\(\\Lambda\\)\nand nonagreement point \\(\\bu_0 = \\left(0,\\frac{1}{9}\\right)\\).\n Figure 11\n depicts the feasible set \\(\\Lambda\\) for such a game (again shaded in\ngreen). This time, though, the figure also identifies the payoff\nvectors associated with three solutions concepts that have been\nespecially influential in in game theoretic analyses of the social\ncontract (namely the Nash, proportional, and\nmaximin proportionate gain solutions).\n\n\n\nFigure 11. Braithwaite Bargaining\nProblem [An\n extended description of figure 11\n is in the supplement.]\n\n\nHere Luke\u2019s payoffs are depicted on the horizontal axis, while\nMatthew\u2019s are on the vertical axis. As we can see, although the\nsolutions differ, each leaves Matthew with a higher payoff than Luke\nreceives. This is because each solution allocates Matthew a larger\nshare of the\n good,[5]\n and is due to the asymmetry in the nonagreement point that\ncharacterizes the Braithwaite Problem. Specifically, (H,\nH) is Luke\u2019s worst possible outcome, but not\nMatthew\u2019s, so Matthew has a threat advantage. In less\ntechnical terms, because failing to agree is less bad for Matthew he\ncan use the threat of nonagreement to press for an agreement that is\nmore favorable to him. And this asymmetry distinguishes the\nBraithwaite Bargaining Problem from the Wine Division Problem depicted\nin\n Figure 9\n where the three solutions coincide with the point \\(\\bu^{*} =\n\\left(\\frac{1}{2}, \\frac{1}{2}\\right)\\) in which the agents involved\neach receive equal shares.\n\nIn his own analysis Braithwaite favored the proportional\nsolution to the bargaining problem that selects the point on the\nPareto frontier where the payoffs for each agent relative to the\nnonagreement point are proportionate to some independently specified\nmeasure of fair\n gains.[6]\n Gauthier (1986, 2013), on the other hand, defends the maximin\nproportionate gain solution that also selects a point on the\nPareto frontier by comparing the payoffs for agents relative to the\nnonagreement point, but which, in addition, takes into account how\nagents fare relative to their ideal\n payoffs.[7]\n In the game theory literature, however, the Nash solution\nhas remained the most widely utilized solution concept, and this has\narguably been true among philosophers offering game-theoretic\ntreatments of the social contract as well (see, e.g., Binmore 1994,\n1998; Muldoon 2016). Roughly speaking, this solution picks out the\npoint that maximizes the cooperative surplus, although some\nphilosophers have offered refinements on the concept that guarantee\npayoffs also meet a minimum threshold (Moehler\n 2018).[8]\n\nAt the heart of debates utilizing game-theoretic treatments of the\nsocial contract is the fact that each of the solution concepts\nmentioned above, and indeed any solution to the bargaining problem,\nmight satisfy several but not all of the intuitively\nplausible constraints we might want ]a fair bargaining procedure to\nrealize. For instance, Nash\u2019s solution is the only solution\nconcept that satisfies all four of:\n\nPareto optimality,\nsymmetry,\nscale (or utility) invariance, and\nreapplication\n stability.[9]\n\n\nBut it fails to satisfy both:\n\nindividual monotonicity, and\npopulation monotonicity.\n\n\nIn this context, an outcome (or its associated payoff vector) is\nPareto optimal if there are no other outcomes that are better for some\nagents without being worse for\n others.[10]\n A solution is symmetric if the payoffs that agents receive from\nidentical shares of a good are equivalent when those agents have\nequivalent utility functions, nonagreement points, and\n strategies.[11]\n It is scale invariant if the solution does not depend on how the\npayoffs are\n represented.[12]\n And it is reapplication stable if the application of a solution\nconcept to a bargaining problem does not generate downstream\nbargaining problems among subsets of agents over the relative shares\nof a good they can\n claim.[13]\n While a solution is individually monotone if an agent is guaranteed\nto do at least as well when a bargaining problem is modified by\nexpanding the feasible set to include new outcomes that are all more\nfavorable to the agent. And it is population monotone if, for a given\nset of claimants, none lose while others gain merely because some\nmembers of the set depart and/or new claimants arrive.\n\nThe maximin proportionate gain solution, on the other hand, is both\nindividually and population monotone, but is not reapplication stable.\nWhile the proportional solution is individually monotone, population\nmonotone, and reapplication stable, but not scale invariant.\nUltimately, then, much like\n Arrow\u2019s Impossibility Theorem\n and related results have cast doubt on whether there exist uniquely\nbest procedures for aggregating preferences or making collective\ndecisions, there is not a single solution concept for bargaining\nproblems that is clearly best. That said, the application of\nbargaining theory to philosophical analyses of the social contract has\nbeen useful insofar as it has provided a framework for illustrating\nwhat features of a social contract a theorist regards as valuable, and\nfor identifying what the tradeoffs associated with these features\nmight be. So, for example, one might conjecture that the reapplication\nstability properties associated with the Nash and proportional\nsolution concepts would allow a social contract based upon one of them\nto be better suited to forestalling conflict in the face of social\nchange. This is because such a contract would be renegotiation-proof\nwith respect to changes in the benefits of cooperation that might\narise in the future, e.g., as a result of an influx of new members in\nsociety or the discovery of new technologies for resource development.\nBut this stability would have to come at the price of either using a\nprivileged representation of agent\u2019s payoffs, or accepting that\nthe parties to the contract will not necessarily be made better off if\nthey are given more to bargain over. And while this tradeoff may\nultimately be justified, the important point is that any tradeoff the\ncontract theorist makes commits her to a certain set of normative\njudgments, and game theory can help clarify what these are. For\ninstance, many game theoretically minded philosophers have contended\nthat any account that privileges certain representations of\nagents\u2019 utilities cannot avoid incorporating certain moral\njudgments into these utilities (Sen 1980; Moehler 2018).\n4.2 Evolutionary Approaches to the Social Contract\n\nHaving focused on the use of bargaining theory in philosophical\nanalyses of the social contract, we will now briefly turn our\nattention to the relevance of evolutionary game theory to this task.\nRecall that evolutionary game theory is the formal approach to\nmodeling how the distribution of traits in a population will evolve\nover time when those traits determine how the agents who possess them\nwill interact. Gaus (2010) and Muldoon (2016) are two recent works\nthat draw on informal evolutionary models in order to show how and why\nthe terms of a social contract might evolve over time to accommodate a\ndiverse polity. While, taking a more formal approach, Alexander (2007)\nexplores how the equilibria that characterize prosocial norms in\nsocial networks evolve over time. It is the works of Brian Skyrms\n(1996 [2014], 2004), though, that have been the most influential in\nbringing evolutionary game theory to bear on the social contract.\n\nOne of Skyrms\u2019 signature uses of evolutionary game theory is to\nexplain the origins of various \u201cfair\u201d solutions to the\nNash bargaining problem (1996 [2014]: Chapter 1). As we have seen\nabove, different axiomatic solution concepts can recommend different\nsolutions to the same bargaining problem. However, even if one\nendorses the arguments in favor of a particular solution concept, this\ndoesn\u2019t yet show that the actual claimants engaged in a\nbargaining problem would tend to follow this solution. This is because\na typical bargaining problem will often have a large number of\nequilibria each of which is likely to be more favorable to some and\nless favorable to others. Accordingly, one might doubt that actual\nclaimants could settle into any equilibrium, let alone an equilibrium\nthat characterizes an outcome we would regard as fair.\n\nTo gain traction on this problem Skyrms considers a simple but\nnontrivial 3-piece Nash Demand Game that is structurally\nsimilar to the Extended Wine Problem of\n Figure 8.\n In this now familiar game a pair of agents vie for shares of a good.\nEach issues a claim and receives a payoff equivalent to her claim when\nthe pair\u2019s claims are compatible, and each receives nothing when\ntheir claims are incompatible. In Skyrms\u2019 version a claimant can\nissue a minimal claim, D, to 1/3 of the good; a maximal\nclaim, H, to 2/3 of the good; or a \u201cmiddle\u201d\nclaim, M, to 1/2 of it.\n [14]\n As Skyrms notes (1996 [2014: 4]), in games of this sort we tend to\nthink there is one outcome claimants ought to follow, namely, the fair\noutcome where each claims half of the good at stake. This corresponds\nto each side following M, and, as we saw earlier,\n(M,M) is an equilibrium of the game. But the\nquestion remains, why would claimants opt for the fair outcome when\nthere are other equilibria that might be preferable?\n\nOne answer to this question is that when agents repeatedly have to\ncome to agreements with one another over the division of a good, but\ncan only obtain a share of the good when they agree on a feasible\ndivision, agents who restrain themselves from pressing maximal claims\nare more likely to encounter other agents with whom feasible bargains\nare possible. In other words, as we saw in a slightly different\ncontext in section 2, in the long run the benefits from successfully\ncoming to terms with like-minded agents outweigh the foregone gains\nthat can occasionally be gotten by pressing for less equitable\ndivisions. Skyrms tests this rationale by applying a dynamic model of\nevolution, the replicator dynamic, to his Nash Demand Game.\n Figure 12\n illustrates a simplex that one can use to summarize this\ndynamic.\n\n\n\nFigure 12. Strategy Simplex for\nSkyrms\u2019s Nash Demand Game [An\n extended description of figure 12\n is in the supplement.]\n\n\nEach point in the simplex corresponds to a particular mix of types of\nagents in the population that can represented by an ordered triplet\n\\((z_1,z_2,z_3),\\) where \\(z_1\\) is the fraction of the population\nthat follows D, \\(z_2\\) the fraction that follow M,\nand \\(z_3\\) the fraction that follow H. Points closer to a\nvertex of the simplex thus represent mixes where more agents follow\nthe strategy associated with that vertex. The replicator dynamic then\nsummarizes the evolution of population states where the fractions of\nrepresented strategies change over time in proportion to their\naverage reproductive fitness. Here a strategy\u2019s average\nreproductive fitness corresponds to its average payoff relative to the\naverage payoff of other strategies represented in the population at a\ngiven\n time.[15]\n To illustrate, in\n Figure 12,\n the point \\(z_0 = \\left(\\frac{1}{6}, \\frac{1}{3},\n\\frac{1}{2}\\right)\\) represents an initial state where \\(\\frac{1}{6}\\)\nof the population follow D, \\(\\frac{1}{3}\\) follow\nM, and \\(\\frac{1}{2}\\) follow H. Given this starting\npoint, the replicator dynamic then traces an orbit starting\nat \\(z_0\\) that converges to \\(\\be_2 = (0,1,0),\\) the vertex point\nwhere the entire population follows the pure strategy M.\n\nBy applying the replicator dynamic across a wide swath of initial\nstates in the\n Figure 12\n simplex, Skyrms then showed that the fair outcome, \\(\\be_2,\\) where\neveryone presses equal claims, is the most likely to evolve. We\nreplicate Skyrms\u2019 experiment here.\n Figure 13\n depicts 200 orbits of the replicator dynamic starting from initial\npopulation states chosen at random from the\n Figure 12\n simplex.\n\n\n\nFigure 13. Replicator Dynamic Orbits of\nSkyrms\u2019s Nash Demand Game [An\n extended description of figure 13\n is in the supplement.]\n\n\nAs this figure illustrates most initial distributions of claimant\ntypes eventually converge to an equilibrium where all agents follow\nM and press claims of 1/2. To use a technical term, we can\nsay that \\(\\be_2\\) has the largest basin of\n attraction.[16]\n To see why this is the case, we can consider how different pure\nstrategy types fare when agents of a population meet at random and\nengage in the Nash Demand Game. Agents who press claims of D\nalways arrive at feasible bargains, but in particular interactions\nthey never do as well as partners who press claims of M or\nH. On the other hand, agents who press claims of H\nonly arrive at feasible bargains when matched with agents who press\nminimal claims of D and can thus be exploited. Meanwhile,\nagents who press claims of M arrive at feasible bargains when\nmatched against either D-following partners or other\nM-following partners. On average, then, M-followers\ndo better than both D-followers and H-followers\nunless there are so many H-followers and so few\nM-followers in the population that in an individual encounter\nan M-follower is more likely to meet an H-follower\nthan either another M-follower or a\n D-follower.[17]\n Indeed, M is an evolutionarily stable strategy\n(Maynard Smith 1982) of this game. What this means is that, if\n\\(\\be_2\\) is the current population state so that M is the\nsole incumbent strategy, then \\(\\be_2\\) can repel any limited\ninvasion of some different mutant\n strategy.[18]\n\nIn some respects Skyrms\u2019 observation shows how Gauthier\u2019s\nargument for constrained maximization might have been strengthened by\ndrawing on resources from outside the confines of rational choice\ntheory. Indeed, Skyrms shows that the basin of attraction for the\nequitable equilibrium where all agents press claims of 1/2 expands\nwhen agents become more likely to interact with agents of their own\nstrategy type, as they might if they are somewhat able to recognize\nagents like themselves. For example,\n Figure 14\n depicts a series of orbits of a correlated replicator\ndynamic Skyrms uses to model such situations. In this dynamic, an\nagent meets a counterpart of the same pure strategy type with\nprobability .2 greater than the random chance probability of the\nordinary replicator\n dynamic.[19]\n And, as we can see, even with this relatively minor increase in the\nlikelihood of same type interactions, all of the modified\nreplicator dynamic orbits now converge to \\(\\be_2\\)\n .[20]\n\n\n\nFigure 14. Correlated Replicator Dynamic\nOrbits of Skyrms\u2019s Nash Demand Game [An\n extended description of figure 14\n is in the supplement.]\n\n\nAlternatively, Skyrms showed how evolved attachments to particular\nplaces or things, and more importantly the ability to signal\nthese attachments can help solve conflictual coordination problems\nlike the Nash Demand Game. In particular, Skyrms (1996 [2014]: chap.\n4) showed that by developing a primitive notion of property rights,\nagents involved in such games could correlate their behavior by\nplaying Hawk at home and Dove away from home, and thereby avoid the\nsorts of interactions that lead to conflict or to both agents\nabandoning a resource. At the end of the day, though, the evolutionary\ngame theory utilized by Skyrms can only lend so much support to a view\nlike Gauthier\u2019s. For one thing, the game Skyrms models assumes\nthat agents have fixed types and cannot revise their claims in light\nof the claims made by others. Furthermore, it is one thing to offer an\nexplanation of why a trait like fair division or constrained\nmaximization would evolve, or to show why this might be beneficial to\nboth individual agents and groups, but to show either of these is not\nnecessarily to show that constraining one\u2019s behavior is the\nrational course of action.\n5. Analyzing Morally Significant Social Issues\n\nIf contractarian approaches to justifying moral and political orders\nhave been the area of ethics where the use of game theory has been\nmost systematic, the area where its deployment is likely to be most\nimpactful going forward is in the analysis of morally significant\nsocial issues. Examples range from global issues, like how to combat\nclimate change; to issues that arise within states or communities,\nlike tax policy or how to manage common pool resources; to issues that\nprimarily concern individuals and groups, like how to elicit optimal\nlevels of effort from individuals engaged in cooperative endeavors.\nBelow we will discuss three examples in more detail.\n5.1 Nuclear Conflict\n\nMany of the early advances in game theory were made during World War\nII and the early stages of the Cold War by individuals working with\norganizations interested in advancing our understanding of nuclear\nconflict. John von Neumann, for instance, whose early contributions to\ngame theory we described in section 1, did work for the Manhattan\nProject that was instrumental in the development of nuclear weapons,\nand he is often credited with having developed the strategy of\nmutually assured destruction (MAD) that played a prominent role in\nCold War nuclear policy (Macrae 1992). MAD is a policy governing the\nuse of nuclear weapons whereby nuclear powers avoid nuclear conflict\nby credibly threatening to retaliate against a nuclear first strike\nwith a nuclear strike that would be destructive enough to negate any\nstrategic or tactical advantage of a first strike.\n\nUnsurprisingly, ethical issues associated with the use of nuclear\nweapons would eventually receive extensive attention in the\nphilosophical literature. Much of this work focused on how nuclear\nethics raises problems for utilitarian or deontological approaches to\nethics, especially the question of whether it\u2019s acceptable to\nthreaten great evil so that it might be avoided. And, while most of\nthe philosophers working in this area made little use of game theory,\nmany of the questions they addressed were framed by the important work\nof Gregory Kavka, Russell Hardin, and a few others who made extensive\nuse of both formal and informal game theoretic tools (see, e.g., Kavka\n1987; R. Hardin 1983; Gauthier 1984; MacLean 1984). In particular,\nthis work helped identify a number of paradoxes associated with MAD\nand other theories of deterrence, clarified the case both for and\nagainst unilateral disarmament, and would have implications for more\ngeneral debates about rationality (especially debates concerning the\nnature of intentions and whether modularity is a demand of\nrationality).\n\nThe analysis of nuclear conflict was also responsible for many of the\nearly developments in cooperative game theory. Among the earliest\nexamples of this kind of work was Lloyd Shapley and Martin\nShubik\u2019s effort to predict the behavior of members of the United\nNations Security Council (Shapley & Shubik 1954). The\nShapley-Shubik power index quantifies the likelihood that any given\nmember of a voting body casts a deciding vote. This provides a measure\nof the influence of each member and helps us analyze how likely\nvarious coalitions are to form, how stable those coalitions will be,\nand how the gains secured by a winning coalition will be\ndistributed.\n\nPerhaps the most influential application of game theory to problems\nassociated with nuclear conflict is found in Schelling\u2019s seminal\nworks The Strategy of Conflict (1960)and Arms and\nInfluence (1966) which together reshaped the game-theoretic\nanalysis of conflict. One of Schelling\u2019s most important insights,\nwhich the prospect of nuclear war makes especially clear, was the\nobservation that only in rare circumstances are the interests of\nparties engaged in conflict completely opposed. This led Schelling to\nemphasize the ways conflict creates and shapes opportunities for\nbargaining and cooperation. These were issues that had increasingly\ncome to be studied using the tools of cooperative game theory, but\nSchelling would revitalize non-cooperative game theory by showing how\nsuch issues could be more productively analyzed through\nnon-cooperative approaches. Arms races to develop more effective\nnuclear weapons, and the extensive efforts that governments make to\nguard nuclear secrets, are also emblematic of the importance of\ninformation and timing to the analysis of conflict, and the emphasis\nSchelling placed on these issues would lead game theorists to\nre-prioritize the extensive form analysis of games that is better able\nto capture the influence of incomplete information and the dynamic\nnature of conflict. Finally, tying together many of the issues\nsketched above is Schelling\u2019s early work on commitment and\nthreats. As Schelling showed, by pre-committing to a costly course of\naction (or by limiting one\u2019s future options) an agent can\ninfluence the actions of other agents with whom she is engaged in\nconflict. In fact, Schelling showed that in some cases irrationality\ncan even be an advantage, an argument that Kavka (1987) would develop\nfurther in the context of deterrence.\n5.2 Bad Norms\n\nIf nuclear conflict was the first morally significant social issue to\nbe extensively analyzed using game theoretic tools, in the recent\nphilosophical literature it has been the analysis of harmful,\ndestructive, and wasteful norms where game theoretic tools have been\nmost prevalent. Specifically game theoretic tools have been used to\nexplain: 1) what bad norms are, 2) when and why they emerge, and 3)\nwhether they can be changed, and, if so, how.\n\nOf these topics, the question of what distinguishes good norms from\nbad norms has received by far the least attention (a notable exception\nis Thrasher 2018). One explanation for this is that it is often taken\nto be obvious that certain norms are bad. For instance, honor killings\nhave received extensive attention in the norms literature, and,\nperhaps unsurprisingly, such killings are typically assumed to provide\na clear instance of a harm that violates the rights of at least some\nof those subjected to the practice. Instead of focusing on what makes\nhonor norms bad, then, the literature has tended to focus on why such\nnorms emerge and how they might be changed.\n\nTo answer these questions game theoretic tools have been used to\ncharacterize the underlying social dynamics that give rise to the\npractice in question, and to then illustrate how the practice is\nresponsive to these dynamics. A dynamic common to several of these\npractices is the role norms play in signaling a group\u2019s\ncommitment to certain values or courses of action. For example, in the\ncase of honor killing, when these killings target members of an\noutgroup, they might deter future slights at the hands of the outgroup\nby signaling the ingroup\u2019s commitment to seeking revenge for\n(real or perceived) slights (Boehm 1986; Nisbett & Cohen 1996;\nSkarbek 2014; Thrasher & Handfield 2018). This can be especially\nimportant in the absence of strong institutions that maintain public\norder. However, one thing that makes honor norms bad, is that a\ngroup\u2019s commitment to seeking revenge for slights can risk\nsetting off (or perpetuating) a cycle of violence.\n\nHonor killings can also be directed towards members of one\u2019s own\ngroup who violate certain norms. For instance, there are many places\nwhere it is not uncommon for members of a family to kill children\n(especially girls) who break norms of sexual morality or who otherwise\nfail to adhere to traditional gender norms. In these cases the desire\nof a group\u2019s members to adhere to such norms is typically\nexplained by the belief that doing so makes members of the group more\nattractive marriage partners, and the role honor killings play is to\nsignal that the family (or group to which the family belongs) is\ncommitted to the norm(s) in question (United Nations Population Fund\n2000; Chesler & Bloom 2012; Skarbek 2014; Thrasher & Handfield\n2018). In some circumstances, though, a group\u2019s commitment to a\nnorm may be driven by pluralistic ignorance. That is, there\nare cases where two (or more) groups may each be engaged in a practice\nlike footbinding or female genital cutting that they themselves would\nprefer not to engage in, but where they remain committed to the norm\non the basis of the mistaken belief that other groups are committed to\nthe norm (Bicchieri & Fukui 1999; Bicchieri 2017). Here\nunderstanding the conditional nature of each group\u2019s preferences\nis crucial to identifying the role played by pluralistic ignorance in\nsustaining the norm in question, while understanding the role of\npluralistic ignorance in sustaining the norm helps explain why it is\nbad.\n\nIn addition to helping identify why a norm might be bad and what\nsustains it, game theoretic analysis can also help us identify when\nand how such norms might be changed. For example, in the case of\npractices sustained by pluralistic ignorance, the key to changing the\npractices lies in changing the beliefs of multiple groups. As game\ntheoretic analysis illustrates, though, it may be that this is only\npossible if each group publicly and simultaneously signals to the\nother that they do not in fact have an unconditional preference for\nengaging in the practice in question. This is because, without knowing\nthat their beliefs about the other group\u2019s normative commitments\nare mistaken, if one group is asked to reveal their preferences\nunilaterally, whatever motivates their conditional preference is\nlikely to give them reason to conceal their true preferences\n(Bicchieri 2017).\n\nAlternatively, game theoretic analysis can also help us understand\npractices like open defecation which seem to be sustained not by\npluralistic ignorance, but by a strong commitment to norms that\noutweigh the concern of individuals or communities for things like\npublic health. For instance, in rural India where open defecation is\ncommon, the practice tends to be sustained by purity norms that\ninteract with caste systems in ways that make communities reluctant to\nutilize latrines even when they are made available. Combating the\npublic health crises exacerbated by open defection is thus not only a\nmatter of building the requisite infrastructure, but of undermining\nthe prevailing norms that prevent the infrastructure from being\nutilized (Coffey & Spears 2017), and of incentivizing individuals\nto police new norms that promote better sanitation practices\n(Bicchieri 2017). And, in such cases, game theoretic analysis allows\nus to see how the relevant behaviors might be incentivized.\n\nThe analysis of bad norms isn\u2019t just limited to cases where the\nnorms in question are clearly the culprit in bringing about bad\noutcomes, though. Game theory can also tell us about the ways in which\nseemingly innocent norms and preferences can give rise to bad\noutcomes. Perhaps the most famous example of this is Schelling\u2019s\n(1971) model of segregation which helps illustrate why segregation can\nbe so difficult to combat. Schelling showed that even when agents\ndon\u2019t mind living alongside members of other groups, even very\nminimal preferences for having some neighbors like oneself can lead to\nindividuals sorting themselves into relatively segregated communities\nover time. For example, Figure 15 below shows how a group of\nindividual agents randomly distributed around a grid will segregate\nthemselves over time when individual agents have preferences for being\nsurrounded by certain thresholds of neighbors like\n them.[21]\n Here Figure 15a depicts a random initial distribution on a \\(20\\times\n20\\) grid, where 10% of squares are empty in order to facilitate\nmovement, and there are two types of agent in equal proportion to one\nanother. Figure 15b depicts the sorting that occurs if agents prefer\nto be surrounded by neighbors of whom at least 20% are like them.\nFigure 15c shows how things change when the threshold is increased to\njust 30%. And Figure 15d shows what things are like when the threshold\nis 50%.\n\n\n\n\na. Initial Distribution\n\n\n\n\nb. 20% Threshold\n\n\n\n\nc. 30% Threshold\n\n\n\n\nd. 50% Threshold\n\n\nFigure 15. Schelling Segregation Models\n[An\n extended description of figure 15\n is in the supplement.]\n\n\nIf we compare Figures 15a and 15b we see that when agents have a\npreference to have at least 1 out of every 5 of their neighbors be\nlike them, the distribution isn\u2019t substantially impacted.\nHowever, if we compare Figures 15a and 15b to Figure 15c we see that\nwhen that threshold is increased from 20% to 30% the agents become\nsignificantly segregated. And by the time the threshold reaches 50%\nagents have been sorted into almost completely homogeneous\nneighborhoods. In other words, even when agents have no objection to\nthe vast majority of their neighbors being different from them (in the\ncase of Figure 15c, as many as 70%), a preference to have just some\nneighbors like oneself can have massive distributional consequences,\nand in addition to being unintended these may be undesirable. However,\nwhile we might criticize the underlying preferences in light of these\nconsequences, and there may be thresholds for neighborhood composition\nthat seem obviously discriminatory, when the preference in question is\nto have just 30% of one\u2019s neighbors be like oneself (in a world\nwith only two groups) it\u2019s far from obvious that this preference\nis objectionable.\n5.3 Climate Change and the Environment\n\nFinally, at least for our purposes, game theory has been crucial to\nthe analysis of many important problems in environmental ethics, the\nmost famous probably being the tragedy of the commons (G.\nHardin 1968) where game theory has been used to show how resources can\neasily be depleted or degraded when they are held in common and use of\nthe resource is not regulated. The idea of the tragedy of the commons\nis that when access to a scarce resource is not limited in some way\nthere is a tendency for use of the resource to exceed the\nenvironment\u2019s capacity to regenerate the resource. So, for\nexample, we overgraze land, deplete fish and game stocks, run down the\nwater level in aquifers, or emit too much pollution into the\nenvironment. Generally speaking, common pool resource\nproblems arise in situations where (i) individuals stand to benefit\nfrom using the resource to the greatest extent possible and (ii) the\nactions of any one individual have a negligible impact on the\nresource, but (iii) the actions of every individual taken together\nhave a large impact. In these cases it\u2019s often easy for an\nindividual to see that the actions of the community as a whole are\nproblematic, but because any individual\u2019s decision to refrain\nfrom exploiting a resource is unlikely to make a difference by itself,\nindividuals reasonably infer that they might as well exploit a\nresource for themselves while they can. As such, common pool resource\nproblems are a species of collective action problem and are\nanalogous in some ways to problems we\u2019ve discussed in previous\nsections (e.g., how to ensure that members of a community are willing\nto police norms even when doing so is costly).\n\nCommon pool resource problems are generally solved in one of two ways:\n(1) by taking the resource in question out of the commons, that is by\ncreating property rights in it, or (2) by finding ways to collectively\nmanage the resource, for instance by regulating who can access the\ncommons at a given time. Which approach is best suited to solving a\nparticular problem, and what form that approach should take, depends\non many factors, e.g., how excludable the resource is, whether it is\nstationary, and how quickly the resource can be regenerated. By\nproviding a framework for analyzing the strategic behavior of\nindividuals in different contexts, game theory provides a useful tool\nfor identifying the solutions most likely to work in a given case.\nHere Elinor Ostrom\u2019s work on common pool resources, which won\nher the 2009 Nobel Prize in Economics, has been especially\ninfluential. Ostrom used game theoretic analysis complemented by\nextensive field work to show that, although there is a surprising\namount of diversity in the ways that communities have managed to\nsustainably govern common resources, the success of these approaches\ntends to be a function of a number of underlying principles (Ostrom\n1990). Some of these principles reflect things we\u2019ve already\ndiscussed in other contexts, e.g., the importance of monitoring and\nsanctions. While others are perhaps less obvious. For instance, the\nimportance of accommodating nested or overlapping jurisdictions of\nresponsibility. Because the ways in which these principles manifest\nthemselves is highly dependent on context, though, rather than saying\nmore about them here, we\u2019ll instead turn to another problem that\nhas received a lot of attention in environmental ethics: climate\nchange.\n\nGame theory has played an important role in the moral and political\nanalysis of climate change. In particular, it has been crucial to the\nanalysis of why addressing climate change is difficult. Here, the\nconsensus in the literature is that states (and other entities)\ninterested in addressing climate change confront a massive free\nrider problem stemming from that fact that many of the things\nthat can be done to prevent further climate change or mitigate its\neffects are either quasi-public goods or things which\ngenerate substantial positive externalities. For example,\ndrastic reductions of carbon emissions and increased investment in\ncarbon sequestration or alternative energy technologies are things\nwhich benefit most countries regardless of who invests in them. And,\nbecause investing in these things is costly (at least in the short\nterm), we tend to underinvest in them, a problem that is exacerbated\nby the fact that the most serious costs of climate change arguably\nfall on future generations.\n\nBroadly speaking there are two schools of thought with respect to how\nwe should confront the problem described above. One school exemplified\nby Garvey (2008), Gardiner (2011), and Broome (2012) acknowledges the\ncollective and political nature of the problem, but maintains that in\naddition to state action individuals have responsibilities to do\nthings like reduce their carbon footprints to mitigate the effects of\nclimate change. On the other hand, members of the other school of\nthought (e.g., Brennan 2009, Nordhaus 2014) tend to be skeptical of\nhow much unilateral action (at either the individual or state level)\ncan do, and so argue that our efforts are best spent trying to find\nworkable collective mechanisms to address climate change.\n6. Conclusion\n\nMany of the early applications of game theory to ethics were limited\nto contractarian theories and work exploring the relationship between\nmorality and rationality. It has increasingly come to be an important\ntool in the study of applied problems in moral and political\nphilosophy, though, and this promises to become even more true as the\nnumber of scholars working on issues at the intersection of\nphilosophy, politics, and economics increases. That said, game theory\nremains an important tool for analyzing the function of morality and\nfor identifying some of its necessary features. And new contributions\nto the social contract tradition continue to be made using ever more\nsophisticated applications of game theoretic tools.\n\nHowever, even if the use of game theory in ethics has become more\nwidespread, many moral and political philosophers remain skeptical of\nthis trend. One worry voiced by skeptics is that game theoretic\nanalyses often rely on simplifying assumptions that give us reason to\ndoubt how relevant these analyses are to real world problems. For\ninstance, individuals are rarely the selfish utility maximizers game\ntheory so often assumes. This worry is misplaced for two reasons.\nFirst, most philosophers inclined to use formal methods in their work\nare acutely aware of the assumptions they rely on. This doesn\u2019t\nmean that formal work never uses misguided models or assumptions, or\nthat we shouldn\u2019t look critically at the conclusions we draw\nfrom game theoretic analysis and other formal work like it. But when\nresults are interpreted correctly they can be extremely helpful. For\ninstance, when simplifying assumptions are made for the sake of\ncomputational tractability, they can provide a useful tool for\nnarrowing down future lines of inquiry. And sometimes simplifying\nassumptions are made so that we might ask speculative questions such\nas whether rational utility maximizers could reason their way into\nmorality, as is the case in the social contract tradition. Second, at\nthe end of the day, formal models aren\u2019t really so different\nfrom the thought experiments that are perhaps more familiar in\nphilosophy. One advantage of game theory and other formal tools,\nthough, is that they force the philosopher using them to be explicit\nabout the assumptions they are making, and they often allow the adept\npractitioner to say something precise about where the action is and\nhow various assumptions affect things.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Alexander, J. McKenzie, 2007, <em>The Structural Evolution of\nMorality</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511550997",
                "Aquinas, Thomas, 1271 [1989], <em>Summa Theologiae:</em>,\ntranslated in <em>Summa Theologiae: A Concise Translation</em>,\nTimothy McDermott (ed.), Notre Dame, IN: Christian Classics.",
                "Axelrod, Robert, 1984 [2006], <em>The Evolution of\nCooperation</em>, New York: Basic Books. Revised Edition, New York:\nBasic Boats, 2006.",
                "Barry, Brian, 1965 [1990], <em>Political Argument</em>, New York:\nHumanities Press. Reprinted as <em>Political Argument: A Reissue with\nNew Introduction</em>, Berkeley: University of California Press,\n1990.",
                "Basu, Kaushik, 2000, <em>Prelude to Political Economy: A Study of\nthe Social and Political Foundations of Economics</em>, Oxford: Oxford\nUniversity Press. doi:10.1093/0198296711.001.0001",
                "Bicchieri, Cristina, 2006, <em>The Grammar of Society: The Nature\nand Dynamics of Social Norms</em>, Cambridge: Cambridge University\nPress. doi:10.1017/CBO9780511616037",
                "\u2013\u2013\u2013, 2017, <em>Norms in the Wild: How to\nDiagnose, Measure, and Change Social Norms</em>, New York: Oxford\nUniversity Press. doi:10.1093/acprof:oso/9780190622046.001.0001",
                "Bicchieri, Cristina and Yoshitaka Fukui, 1999, \u201cThe Great\nIllusion: Ignorance, Informational Cascades, and the Persistence of\nUnpopular Norms\u201d, in <em>Experience, Reality, and Scientific\nExplanation</em>, Maria Carla Galavotti and A. Pagnani (eds),\nDordrecht: Springer, 89\u2013121.",
                "Binmore, Ken, 1994, <em>Game Theory and the Social Contract Volume\nI: Playing Fair</em>, Cambridge, MA: MIT Press.",
                "\u2013\u2013\u2013, 1998, <em>Game Theory and the Social\nContract Volume II: Just Playing</em>, Cambridge, MA: MIT Press.",
                "Boehm, Christopher, 1986, <em>Blood Revenge: The Enactment and\nManagement of Conflict in Montenegro and Other Tribal Societies</em>,\nPhiladelphia, PA: University of Pennsylvania Press.",
                "Boyd, Robert and Peter Richerson, 2005, <em>The Origin and\nEvolution of Cultures</em>, Oxford: Oxford University Press.",
                "Braithwaite, Richard B., 1955 [2009], <em>Theory of Games as a\nTool for the Moral Philosopher: An inaugural lecture delivered in\nCambridge on 2 December 1954</em>, Cambridge: Cambridge University\nPress. Reprinted 2009.",
                "Brennan, Geoffrey, 2009, \u201cClimate Change: A Rational Choice\nPolitics View\u201d, <em>Australian Journal of Agricultural and\nResource Economics</em>, 53(3): 309\u2013326.\ndoi:10.1111/j.1467-8489.2009.00457.x",
                "Brennan, Geoffrey, Lina Eriksson, Robert E. Goodin, and Nicholas\nSouthwood, 2013, <em>Explaining Norms</em>, Oxford University Press.\ndoi:10.1093/acprof:oso/9780199654680.001.0001",
                "Broome, John, 2012, <em>Climate Matters: Ethics in a Warming\nWorld</em>, New York: W.W. Norton.",
                "Chesler, Phyllis and Nathan Bloom, 2012, \u201cHindu vs. Muslim\nHonor Killings\u201d, <em>Middle East Quarterly</em>, 19:\n43\u201352.\n [<a href=\"https://www.meforum.org/3287/hindu-muslim-honor-killings\" target=\"other\">Chesler and Bloom 2012 available online</a>]",
                "Chung, Hun, 2015, \u201cHobbes\u2019s State of Nature: A Modern\nBayesian Game-Theoretic Analysis\u201d, <em>Journal of the American\nPhilosophical Association</em>, 1(3): 485\u2013508.\ndoi:10.1017/apa.2015.12",
                "Coffey, Diane and Dean Spears, 2017, <em>Where India Goes:\nAbandoned Toilets, Stunted Development and the Costs of Caste</em>,\nNoida, Uttar Pradesh: HarperCollins India.",
                "Eshel, Ilan and L. L. Cavalli-Sforza, 1982, \u201cAssortment of\nEncounters and Evolution of Cooperativeness\u201d, <em>Proceedings of\nthe National Academy of Sciences</em>, 79(4): 1331\u20131335.\ndoi:10.1073/pnas.79.4.1331",
                "Gardiner, Stephen M., 2011, <em>A Perfect Moral Storm: The Ethical\nTragedy of Climate Change</em>, Oxford: Oxford University Press.\ndoi:10.1093/acprof:oso/9780195379440.001.0001",
                "Garvey, James, 2008, <em>The Ethics of Climate Change: Right and\nWrong in a Warming World</em>, London: Continuum.",
                "Gaus, Gerald, 2010, <em>The Order of Public Reason: A Theory of\nFreedom and Morality in a Diverse and Bounded World</em>, Cambridge:\nCambridge University Press. doi:10.1017/CBO9780511780844",
                "Gauthier, David P., 1969, <em>The Logic of Leviathan: The Moral\nand Political Theory of Thomas Hobbes</em>, Oxford: Clarendon Press.\ndoi:10.1093/acprof:oso/9780198246169.001.0001",
                "\u2013\u2013\u2013, 1984, \u201cDeterrence, Maximization, and\nRationality\u201d, <em>Ethics</em>, 94(3): 474\u2013495.\ndoi:10.1086/292561",
                "\u2013\u2013\u2013, 1985, \u201cBargaining and justice\u201d,\n<em>Social Philosophy and Policy</em>, 2(2): 29\u201347.",
                "\u2013\u2013\u2013, 1986, <em>Morals By Agreement</em>, Oxford:\nClarendon Press.",
                "\u2013\u2013\u2013, 2013, \u201cTwenty-Five On\u201d,\n<em>Ethics</em>, 123(4): 601\u2013624. doi:10.1086/670246",
                "Grotius, Hugo, 1625 [2005], <em>De iure belli ac pacis libri\ntres</em>, Paris: Buon. Translated as <em>The Rights of War and\nPeace</em>, Richard Tuck and Jean Barbeyrac (eds), Indianapolis, IN:\nLiberty Fund.",
                "Hampton, Jean, 1986, <em>Hobbes and the Social Contract\nTradition</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511625060",
                "Hardin, Garrett, 1968, \u201cThe Tragedy of the Commons\u201d,\n<em>Science</em>, 162(3859): 1243\u20131248.\ndoi:10.1126/science.162.3859.1243",
                "Hardin, Russell, 1983, \u201cUnilateral Versus Mutual\nDisarmament\u201d, <em>Philosophy &amp; Public Affairs</em>, 12(3):\n236\u2013254.",
                "Harsanyi, John C., 1953, \u201cCardinal Utility in Welfare\nEconomics and in the Theory of Risk-Taking\u201d, <em>Journal of\nPolitical Economy</em>, 61(5): 434\u2013435. doi:10.1086/257416",
                "\u2013\u2013\u2013, 1955, \u201cCardinal Welfare,\nIndividualistic Ethics, and Interpersonal Comparisons of\nUtility\u201d, <em>Journal of Political Economy</em>, 63(4):\n309\u2013321. doi:10.1086/257678",
                "\u2013\u2013\u2013, 1977, <em>Rational Behaviour and Bargaining\nEquilibrium in Games and Social Situations</em>, Cambridge: Cambridge\nUniversity Press. doi:10.1017/CBO9780511571756",
                "Harsanyi, John and Reinhard Selten, 1988, <em>A General Theory of\nEquilibrium Selection in Games</em>, Cambridge, MA: MIT Press.",
                "Hobbes, Thomas, 1651 [1994], <em>Leviathan</em>, London. Reprinted\nEdwin Curley (ed.), Indianapolis, IN: Hackett, 1994.",
                "Hume, David, 1740 [2011], <em>A Treatise of Human Nature</em>,\nLondon. Reprinted David Fate Norton and Mary J. Norton (eds), Oxford:\nClarendon Press, 2011.",
                "Kalai, Ehud, 1977, \u201cProportional Solutions to Bargaining\nSituations: Interpersonal Utility Comparisons\u201d,\n<em>Econometrica</em>, 45(7): 1623\u20131630.\ndoi:10.2307/1913954",
                "Kalai, Ehud and Meir Smorodinsky, 1975, \u201cOther Solutions to\nNash\u2019s Bargaining Problem\u201d, <em>Econometrica</em>, 43(3):\n513\u2013518. doi:10.2307/1914280",
                "Kavka, Gregory S., 1984, \u201cThe Reconciliation Project\u201d,\nin <em>Morality, Reason and Truth</em>, David Copp and David Zimmerman\n(eds), Totowa: Rowan and Allanheld, 297\u2013319.",
                "\u2013\u2013\u2013, 1986, <em>Hobbesian Moral and Political\nTheory</em>, Princeton, NJ: Princeton University Press.",
                "\u2013\u2013\u2013, 1987, <em>Moral Paradoxes of Nuclear\nDeterrence</em>, Cambridge: Cambridge University Press.",
                "Lensberg, Terje, 1988, \u201cStability and the Nash\nSolution\u201d, <em>Journal of Economic Theory</em>, 45(2):\n330\u2013341. doi:10.1016/0022-0531(88)90273-6",
                "Lewis, David, 1969, <em>Convention: A Philosophical Study</em>,\nCambridge, MA: Harvard University Press.",
                "Locke, John, 1689 [1960], <em>The Second Treatise of\nGovernment</em>, Reprinted in <em>Two Treatises of Government</em>,\nPeter Laslett (ed.), Cambridge: Cambridge University Press, 1960,\n283\u2013446.",
                "Luce, R. Duncan and Howard Raiffa, 1957, <em>Games and Decisions:\nIntroduction and Critical Survey</em>, New York: John Wiley and\nSons.",
                "MacLean, Douglas (ed.), 1984, <em>The Security Gamble: Deterrence\nDilemmas in the Nuclear Age</em>, Rowman &amp; Allanheld.",
                "Macrae, Norman, 1992, <em>John von Neumann: The Scientific Genius\nWho Pioneered the Modern Computer, Game Theory, Nuclear Deterrence,\nand Much More</em>, New York: Pantheon Press.",
                "Maynard Smith, John, 1982, <em>Evolution and the Theory of\nGames</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511806292",
                "McClennen, Edward F., 1990, <em>Rationality and Dynamic Choice:\nFoundational Explorations</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511983979",
                "Moehler, Michael, 2009, \u201cWhy Hobbes\u2019 State of Nature\nIs Best Modeled by an Assurance Game\u201d, <em>Utilitas</em>, 21(3):\n297\u2013326. doi:10.1017/S0953820809990069",
                "\u2013\u2013\u2013, 2018, <em>Minimal Morality: A Multilevel\nSocial Contract Theory</em>, Oxford: Oxford University Press.\ndoi:10.1093/oso/9780198785927.001.0001",
                "Muldoon, Ryan, 2016, <em>Social Contract Theory for a Diverse\nWorld</em>, New York: Routledge. doi:10.4324/9781315545882",
                "Nash, John, 1950, \"The Bargaining Problem\",\n<em>Econometrica</em>, 18(2): 155\u2013162. doi:10.2307/1907266",
                "\u2013\u2013\u2013, 2002, <em>The Essential John Nash</em>,\nHarold W. Kuhn and Sylvia Nassar (eds), Princeton, NJ: Princeton\nUniversity Press.",
                "Nisbett, Richard and Dov Cohen, 1996, <em>Culture of Honor: The\nPsychology of Violence in the South</em>, Boulder, CO: Westview\nPress.",
                "Nordhaus, William, 2014, \u201cThe Ethics of Efficient Markets\nand Commons Tragedies: A Review of John Broome\u2019s <em>Climate\nMatters: Ethics in a Warming World</em>\u201d, <em>Journal of\nEconomic Literature</em>, 52(4): 1135\u20131141.\ndoi:10.1257/jel.52.4.1135",
                "Ostrom, Elinor, 1990, <em>Governing the Commons: The Evolution of\nInstitutions for Collective Action</em>, Cambridge: Cambridge\nUniversity Press. doi:10.1017/CBO9780511807763",
                "Plato, <em>Plato: Complete Works</em>, John Cooper (ed.),\nIndianapolis: Hackett, 1997.",
                "Pufendorf, Samuel, 1673 [1991], <em>De officio hominis et civis\njuxta legem naturalem</em>, London: Sumtibus Adami Junghans.\nTranslated as <em>On the Duty of Man and Citizen according to Natural\nLaw</em>, James Tully (ed.) and Michael Silverthorne (trans.),\nCambridge: Cambridge University Press. doi:10.1017/9781316160800",
                "Raiffa, Howard, 1953, \u201cArbitration Schemes for Generalized\nTwo-Person Games\u201d, in <em>Contributions to the Theory of Games,\nVolume II</em>, Harold William Kuhn and Albert William Tucker (eds.),\n(Annals of Mathematics Studies 28), Princeton, NJ: Princeton\nUniversity Press, 361\u2013388. doi:10.1515/9781400881970-022",
                "Rawls, John, 1958, \u201cJustice as Fairness\u201d, <em>The\nPhilosophical Review</em>, 67(2): 164\u2013194.\ndoi:10.2307/2182612",
                "\u2013\u2013\u2013, 1971, <em>A Theory of Justice</em>,\nCambridge, MA: Harvard University Press.",
                "Roth, Alvin E., 1979, <em>Axiomatic Models of Bargaining</em>,\n(Lecture Notes in Economics and Mathematical Systems 170), Berlin,\nHeidelberg: Springer Berlin Heidelberg.\ndoi:10.1007/978-3-642-51570-5",
                "Rousseau, Jean-Jacques, 1755 [1997], <em>Discours sur\nl\u2019origine et les fondements de l\u2019in\u00e9galit\u00e9 parmi\nles hommes</em>, translated as \u201cDiscourse on the Origin and\nNature of Inequality Among Men\u201d, in <em>The Discourses and Other\nEarly Political Writings</em>, Victor Gourevitch (ed.), Cambridge:\nCambridge University Press.",
                "Rubinstein, Ariel, 1982, \u201cPerfect Equilibrium in a\nBargaining Model\u201d, <em>Econometrica</em>, 50(1): 97\u2013109.\ndoi:10.2307/1912531",
                "Scanlon, Thomas M., 1982, \u201cContractualism and\nUtilitarianism\u201d, in <em>Utilitarianism and Beyond</em>, Amartya\nSen and Bernard Williams (eds.), Cambridge: Cambridge University\nPress, 103\u2013128. doi:10.1017/CBO9780511611964.007",
                "\u2013\u2013\u2013, 1998, <em>What We Owe to Each Other</em>,\nCambridge, MA: Belknap Press.",
                "Schelling, Thomas C., 1960, <em>The Strategy of Conflict</em>,\nCambridge, MA: Harvard University Press.",
                "\u2013\u2013\u2013, 1966, <em>Arms and Influence</em>, New\nHaven, CT: Yale University Press.",
                "\u2013\u2013\u2013, 1971, \u201cDynamic Models of\nSegregation\u201d, <em>The Journal of Mathematical Sociology</em>,\n1(2): 143\u2013186. doi:10.1080/0022250X.1971.9989794",
                "Sen, Amartya, 1980, \u201cEquality of What?\u201d, Tanner\nLectures on Human Values delivered at Stanford University 22 May 1979,\ncollected in <em>Tanner Lectures on Human Values</em>, Sterling M.\nMcMurrin (ed.), Cambridge: Cambridge University Press, 1980,\n197\u2013220.\n [<a href=\"https://tannerlectures.utah.edu/_resources/documents/a-to-z/s/sen80.pdf\" target=\"other\">Sen 1980 available online</a>]",
                "Shapley, L. S. and Martin Shubik, 1954, \u201cA Method for\nEvaluating the Distribution of Power in a Committee System\u201d,\n<em>American Political Science Review</em>, 48(3): 787\u2013792.\ndoi:10.2307/1951053",
                "Skarbek, David, 2014, <em>The Social Order of the Underworld: How\nPrison Gangs Govern the American Penal System</em>, Oxford: Oxford\nUniversity Press. doi:10.1093/acprof:oso/9780199328499.001.0001",
                "Sidgwick, Henry, 1874 [2011], <em>The Methods of Ethics</em>,\nCambridge: Cambridge University Press.\ndoi:10.1017/CBO9781139136617",
                "Skyrms, Brian, 1996 [2014], <em>Evolution of the Social\nContract</em>, Cambridge: Cambridge University Press; second edition,\n2014. doi:10.1017/CBO9781139924825",
                "\u2013\u2013\u2013, 1998, \u201cThe Shadow of the\nFuture\u201d, in <em>Rational Commitment and Social Justice: Essays\nfor Gregory Kavka</em>, Jules L. Coleman and Christopher W. Morris\n(eds.), Cambridge: Cambridge University Press, 12\u201321.\ndoi:10.1017/CBO9780511527364.003",
                "\u2013\u2013\u2013, 2004, <em>The Stag Hunt and the Evolution\nof Social Structure</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9781139165228",
                "Sobel, Jordan Howard, 2009, <em>Walls and Vaults: A Natural\nScience of Morals (Virtue Ethics According to David Hume)</em>,\nHoboken, NJ: John Wiley &amp; Sons, Inc.\ndoi:10.1002/9781118031605",
                "St\u00e4hl, Ingolf, 1972, <em>Bargaining Theory</em>, Stockholm:\nEconomic Research Institute.",
                "Sugden, Robert, 1986, <em>The Economics of Rights, Co-operation,\nand Welfare</em>, Oxford: Blackwell Press.",
                "Taylor, Michael, 1987, <em>The Possibility of Cooperation</em>,\nCambridge: Cambridge University Press.",
                "Thrasher, John, 2018, \u201cEvaluating Bad Norms\u201d,\n<em>Social Philosophy and Policy</em>, 35(1): 196\u2013216.\ndoi:10.1017/S0265052518000055",
                "Thrasher, John and Toby Handfield, 2018, \u201cHonor and\nViolence: An Account of Feuds, Duels, and Honor Killings\u201d,\n<em>Human Nature</em>, 29(4): 371\u2013389.\ndoi:10.1007/s12110-018-9324-4",
                "Thomson, William and Terje Lensberg, 1989, <em>Axiomatic Theory of\nBargaining with a Variable Number of Agents</em>, Cambridge: Cambridge\nUniversity Press. doi:10.1017/CBO9780511664489",
                "Ullmann-Margalit, Edna, 1977, <em>The Emergence of Norms</em>,\nOxford: Clarendon Press.",
                "United Nations Population Fund (UNFPA), 2000, \u201cViolence\nAgainst Women and Girls: A Human Rights and Health Priority\u201d, in\n<em>The State of World Population, 2000</em>, United Nations\nPopulation Fund, 25\u201330.\n [<a href=\"https://www.unfpa.org/publications/state-world-population-2000\" target=\"other\">UNFPA 2000 available online</a>]",
                "Vanderschraaf, Peter, 1998, \u201cThe Informal Game Theory in\nHume\u2019s Account of Convention\u201d, <em>Economics and\nPhilosophy</em>, 14(2): 215\u2013247.\ndoi:10.1017/S0266267100003849",
                "\u2013\u2013\u2013, 2007, \u201cCovenants and\nReputations\u201d, <em>Synthese</em>, 157(2): 167\u2013195.\ndoi:10.1007/s11229-006-9147-4",
                "\u2013\u2013\u2013, 2010, \u201cThe Invisible Foole\u201d,\n<em>Philosophical Studies</em>, 147(1): 37\u201358.\ndoi:10.1007/s11098-009-9449-8",
                "\u2013\u2013\u2013, 2019, <em>Strategic Justice: Convention and\nProblems of Balancing Divergent Interests</em>, New York: Oxford\nUniversity Press. doi:10.1093/oso/9780199832194.001.0001",
                "Vanderschraaf, Peter and Diana Richards, 1997, \u201cJoint\nBeliefs in Conflictual Coordination Games\u201d, <em>Theory and\nDecision</em>, 42(3): 287\u2013310. doi:10.1023/A:1004962809537",
                "Von Neumann, John and Oskar Morgenstern, 1944 [2004]. <em>Theory\nof Games and Economic Behavior</em>, Princeton, NJ: Princeton\nUniversity Press. Sixtieth-Anniversary Edition, Princeton and Oxford:\nPrinceton University Press, 2004."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Alexander, J. McKenzie, 2007, <em>The Structural Evolution of\nMorality</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511550997</li>\n<li>Aquinas, Thomas, 1271 [1989], <em>Summa Theologiae:</em>,\ntranslated in <em>Summa Theologiae: A Concise Translation</em>,\nTimothy McDermott (ed.), Notre Dame, IN: Christian Classics.</li>\n<li>Axelrod, Robert, 1984 [2006], <em>The Evolution of\nCooperation</em>, New York: Basic Books. Revised Edition, New York:\nBasic Boats, 2006.</li>\n<li>Barry, Brian, 1965 [1990], <em>Political Argument</em>, New York:\nHumanities Press. Reprinted as <em>Political Argument: A Reissue with\nNew Introduction</em>, Berkeley: University of California Press,\n1990.</li>\n<li>Basu, Kaushik, 2000, <em>Prelude to Political Economy: A Study of\nthe Social and Political Foundations of Economics</em>, Oxford: Oxford\nUniversity Press. doi:10.1093/0198296711.001.0001</li>\n<li>Bicchieri, Cristina, 2006, <em>The Grammar of Society: The Nature\nand Dynamics of Social Norms</em>, Cambridge: Cambridge University\nPress. doi:10.1017/CBO9780511616037</li>\n<li>\u2013\u2013\u2013, 2017, <em>Norms in the Wild: How to\nDiagnose, Measure, and Change Social Norms</em>, New York: Oxford\nUniversity Press. doi:10.1093/acprof:oso/9780190622046.001.0001</li>\n<li>Bicchieri, Cristina and Yoshitaka Fukui, 1999, \u201cThe Great\nIllusion: Ignorance, Informational Cascades, and the Persistence of\nUnpopular Norms\u201d, in <em>Experience, Reality, and Scientific\nExplanation</em>, Maria Carla Galavotti and A. Pagnani (eds),\nDordrecht: Springer, 89\u2013121.</li>\n<li>Binmore, Ken, 1994, <em>Game Theory and the Social Contract Volume\nI: Playing Fair</em>, Cambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 1998, <em>Game Theory and the Social\nContract Volume II: Just Playing</em>, Cambridge, MA: MIT Press.</li>\n<li>Boehm, Christopher, 1986, <em>Blood Revenge: The Enactment and\nManagement of Conflict in Montenegro and Other Tribal Societies</em>,\nPhiladelphia, PA: University of Pennsylvania Press.</li>\n<li>Boyd, Robert and Peter Richerson, 2005, <em>The Origin and\nEvolution of Cultures</em>, Oxford: Oxford University Press.</li>\n<li>Braithwaite, Richard B., 1955 [2009], <em>Theory of Games as a\nTool for the Moral Philosopher: An inaugural lecture delivered in\nCambridge on 2 December 1954</em>, Cambridge: Cambridge University\nPress. Reprinted 2009.</li>\n<li>Brennan, Geoffrey, 2009, \u201cClimate Change: A Rational Choice\nPolitics View\u201d, <em>Australian Journal of Agricultural and\nResource Economics</em>, 53(3): 309\u2013326.\ndoi:10.1111/j.1467-8489.2009.00457.x</li>\n<li>Brennan, Geoffrey, Lina Eriksson, Robert E. Goodin, and Nicholas\nSouthwood, 2013, <em>Explaining Norms</em>, Oxford University Press.\ndoi:10.1093/acprof:oso/9780199654680.001.0001</li>\n<li>Broome, John, 2012, <em>Climate Matters: Ethics in a Warming\nWorld</em>, New York: W.W. Norton.</li>\n<li>Chesler, Phyllis and Nathan Bloom, 2012, \u201cHindu vs. Muslim\nHonor Killings\u201d, <em>Middle East Quarterly</em>, 19:\n43\u201352.\n [<a href=\"https://www.meforum.org/3287/hindu-muslim-honor-killings\" target=\"other\">Chesler and Bloom 2012 available online</a>]</li>\n<li>Chung, Hun, 2015, \u201cHobbes\u2019s State of Nature: A Modern\nBayesian Game-Theoretic Analysis\u201d, <em>Journal of the American\nPhilosophical Association</em>, 1(3): 485\u2013508.\ndoi:10.1017/apa.2015.12</li>\n<li>Coffey, Diane and Dean Spears, 2017, <em>Where India Goes:\nAbandoned Toilets, Stunted Development and the Costs of Caste</em>,\nNoida, Uttar Pradesh: HarperCollins India.</li>\n<li>Eshel, Ilan and L. L. Cavalli-Sforza, 1982, \u201cAssortment of\nEncounters and Evolution of Cooperativeness\u201d, <em>Proceedings of\nthe National Academy of Sciences</em>, 79(4): 1331\u20131335.\ndoi:10.1073/pnas.79.4.1331</li>\n<li>Gardiner, Stephen M., 2011, <em>A Perfect Moral Storm: The Ethical\nTragedy of Climate Change</em>, Oxford: Oxford University Press.\ndoi:10.1093/acprof:oso/9780195379440.001.0001</li>\n<li>Garvey, James, 2008, <em>The Ethics of Climate Change: Right and\nWrong in a Warming World</em>, London: Continuum.</li>\n<li>Gaus, Gerald, 2010, <em>The Order of Public Reason: A Theory of\nFreedom and Morality in a Diverse and Bounded World</em>, Cambridge:\nCambridge University Press. doi:10.1017/CBO9780511780844</li>\n<li>Gauthier, David P., 1969, <em>The Logic of Leviathan: The Moral\nand Political Theory of Thomas Hobbes</em>, Oxford: Clarendon Press.\ndoi:10.1093/acprof:oso/9780198246169.001.0001</li>\n<li>\u2013\u2013\u2013, 1984, \u201cDeterrence, Maximization, and\nRationality\u201d, <em>Ethics</em>, 94(3): 474\u2013495.\ndoi:10.1086/292561</li>\n<li>\u2013\u2013\u2013, 1985, \u201cBargaining and justice\u201d,\n<em>Social Philosophy and Policy</em>, 2(2): 29\u201347.</li>\n<li>\u2013\u2013\u2013, 1986, <em>Morals By Agreement</em>, Oxford:\nClarendon Press.</li>\n<li>\u2013\u2013\u2013, 2013, \u201cTwenty-Five On\u201d,\n<em>Ethics</em>, 123(4): 601\u2013624. doi:10.1086/670246</li>\n<li>Grotius, Hugo, 1625 [2005], <em>De iure belli ac pacis libri\ntres</em>, Paris: Buon. Translated as <em>The Rights of War and\nPeace</em>, Richard Tuck and Jean Barbeyrac (eds), Indianapolis, IN:\nLiberty Fund.</li>\n<li>Hampton, Jean, 1986, <em>Hobbes and the Social Contract\nTradition</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511625060</li>\n<li>Hardin, Garrett, 1968, \u201cThe Tragedy of the Commons\u201d,\n<em>Science</em>, 162(3859): 1243\u20131248.\ndoi:10.1126/science.162.3859.1243</li>\n<li>Hardin, Russell, 1983, \u201cUnilateral Versus Mutual\nDisarmament\u201d, <em>Philosophy &amp; Public Affairs</em>, 12(3):\n236\u2013254.</li>\n<li>Harsanyi, John C., 1953, \u201cCardinal Utility in Welfare\nEconomics and in the Theory of Risk-Taking\u201d, <em>Journal of\nPolitical Economy</em>, 61(5): 434\u2013435. doi:10.1086/257416</li>\n<li>\u2013\u2013\u2013, 1955, \u201cCardinal Welfare,\nIndividualistic Ethics, and Interpersonal Comparisons of\nUtility\u201d, <em>Journal of Political Economy</em>, 63(4):\n309\u2013321. doi:10.1086/257678</li>\n<li>\u2013\u2013\u2013, 1977, <em>Rational Behaviour and Bargaining\nEquilibrium in Games and Social Situations</em>, Cambridge: Cambridge\nUniversity Press. doi:10.1017/CBO9780511571756</li>\n<li>Harsanyi, John and Reinhard Selten, 1988, <em>A General Theory of\nEquilibrium Selection in Games</em>, Cambridge, MA: MIT Press.</li>\n<li>Hobbes, Thomas, 1651 [1994], <em>Leviathan</em>, London. Reprinted\nEdwin Curley (ed.), Indianapolis, IN: Hackett, 1994.</li>\n<li>Hume, David, 1740 [2011], <em>A Treatise of Human Nature</em>,\nLondon. Reprinted David Fate Norton and Mary J. Norton (eds), Oxford:\nClarendon Press, 2011.</li>\n<li>Kalai, Ehud, 1977, \u201cProportional Solutions to Bargaining\nSituations: Interpersonal Utility Comparisons\u201d,\n<em>Econometrica</em>, 45(7): 1623\u20131630.\ndoi:10.2307/1913954</li>\n<li>Kalai, Ehud and Meir Smorodinsky, 1975, \u201cOther Solutions to\nNash\u2019s Bargaining Problem\u201d, <em>Econometrica</em>, 43(3):\n513\u2013518. doi:10.2307/1914280</li>\n<li>Kavka, Gregory S., 1984, \u201cThe Reconciliation Project\u201d,\nin <em>Morality, Reason and Truth</em>, David Copp and David Zimmerman\n(eds), Totowa: Rowan and Allanheld, 297\u2013319.</li>\n<li>\u2013\u2013\u2013, 1986, <em>Hobbesian Moral and Political\nTheory</em>, Princeton, NJ: Princeton University Press.</li>\n<li>\u2013\u2013\u2013, 1987, <em>Moral Paradoxes of Nuclear\nDeterrence</em>, Cambridge: Cambridge University Press.</li>\n<li>Lensberg, Terje, 1988, \u201cStability and the Nash\nSolution\u201d, <em>Journal of Economic Theory</em>, 45(2):\n330\u2013341. doi:10.1016/0022-0531(88)90273-6</li>\n<li>Lewis, David, 1969, <em>Convention: A Philosophical Study</em>,\nCambridge, MA: Harvard University Press.</li>\n<li>Locke, John, 1689 [1960], <em>The Second Treatise of\nGovernment</em>, Reprinted in <em>Two Treatises of Government</em>,\nPeter Laslett (ed.), Cambridge: Cambridge University Press, 1960,\n283\u2013446.</li>\n<li>Luce, R. Duncan and Howard Raiffa, 1957, <em>Games and Decisions:\nIntroduction and Critical Survey</em>, New York: John Wiley and\nSons.</li>\n<li>MacLean, Douglas (ed.), 1984, <em>The Security Gamble: Deterrence\nDilemmas in the Nuclear Age</em>, Rowman &amp; Allanheld.</li>\n<li>Macrae, Norman, 1992, <em>John von Neumann: The Scientific Genius\nWho Pioneered the Modern Computer, Game Theory, Nuclear Deterrence,\nand Much More</em>, New York: Pantheon Press.</li>\n<li>Maynard Smith, John, 1982, <em>Evolution and the Theory of\nGames</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511806292</li>\n<li>McClennen, Edward F., 1990, <em>Rationality and Dynamic Choice:\nFoundational Explorations</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511983979</li>\n<li>Moehler, Michael, 2009, \u201cWhy Hobbes\u2019 State of Nature\nIs Best Modeled by an Assurance Game\u201d, <em>Utilitas</em>, 21(3):\n297\u2013326. doi:10.1017/S0953820809990069</li>\n<li>\u2013\u2013\u2013, 2018, <em>Minimal Morality: A Multilevel\nSocial Contract Theory</em>, Oxford: Oxford University Press.\ndoi:10.1093/oso/9780198785927.001.0001</li>\n<li>Muldoon, Ryan, 2016, <em>Social Contract Theory for a Diverse\nWorld</em>, New York: Routledge. doi:10.4324/9781315545882</li>\n<li>Nash, John, 1950, \"The Bargaining Problem\",\n<em>Econometrica</em>, 18(2): 155\u2013162. doi:10.2307/1907266</li>\n<li>\u2013\u2013\u2013, 2002, <em>The Essential John Nash</em>,\nHarold W. Kuhn and Sylvia Nassar (eds), Princeton, NJ: Princeton\nUniversity Press.</li>\n<li>Nisbett, Richard and Dov Cohen, 1996, <em>Culture of Honor: The\nPsychology of Violence in the South</em>, Boulder, CO: Westview\nPress.</li>\n<li>Nordhaus, William, 2014, \u201cThe Ethics of Efficient Markets\nand Commons Tragedies: A Review of John Broome\u2019s <em>Climate\nMatters: Ethics in a Warming World</em>\u201d, <em>Journal of\nEconomic Literature</em>, 52(4): 1135\u20131141.\ndoi:10.1257/jel.52.4.1135</li>\n<li>Ostrom, Elinor, 1990, <em>Governing the Commons: The Evolution of\nInstitutions for Collective Action</em>, Cambridge: Cambridge\nUniversity Press. doi:10.1017/CBO9780511807763</li>\n<li>Plato, <em>Plato: Complete Works</em>, John Cooper (ed.),\nIndianapolis: Hackett, 1997.</li>\n<li>Pufendorf, Samuel, 1673 [1991], <em>De officio hominis et civis\njuxta legem naturalem</em>, London: Sumtibus Adami Junghans.\nTranslated as <em>On the Duty of Man and Citizen according to Natural\nLaw</em>, James Tully (ed.) and Michael Silverthorne (trans.),\nCambridge: Cambridge University Press. doi:10.1017/9781316160800</li>\n<li>Raiffa, Howard, 1953, \u201cArbitration Schemes for Generalized\nTwo-Person Games\u201d, in <em>Contributions to the Theory of Games,\nVolume II</em>, Harold William Kuhn and Albert William Tucker (eds.),\n(Annals of Mathematics Studies 28), Princeton, NJ: Princeton\nUniversity Press, 361\u2013388. doi:10.1515/9781400881970-022</li>\n<li>Rawls, John, 1958, \u201cJustice as Fairness\u201d, <em>The\nPhilosophical Review</em>, 67(2): 164\u2013194.\ndoi:10.2307/2182612</li>\n<li>\u2013\u2013\u2013, 1971, <em>A Theory of Justice</em>,\nCambridge, MA: Harvard University Press.</li>\n<li>Roth, Alvin E., 1979, <em>Axiomatic Models of Bargaining</em>,\n(Lecture Notes in Economics and Mathematical Systems 170), Berlin,\nHeidelberg: Springer Berlin Heidelberg.\ndoi:10.1007/978-3-642-51570-5</li>\n<li>Rousseau, Jean-Jacques, 1755 [1997], <em>Discours sur\nl\u2019origine et les fondements de l\u2019in\u00e9galit\u00e9 parmi\nles hommes</em>, translated as \u201cDiscourse on the Origin and\nNature of Inequality Among Men\u201d, in <em>The Discourses and Other\nEarly Political Writings</em>, Victor Gourevitch (ed.), Cambridge:\nCambridge University Press.</li>\n<li>Rubinstein, Ariel, 1982, \u201cPerfect Equilibrium in a\nBargaining Model\u201d, <em>Econometrica</em>, 50(1): 97\u2013109.\ndoi:10.2307/1912531</li>\n<li>Scanlon, Thomas M., 1982, \u201cContractualism and\nUtilitarianism\u201d, in <em>Utilitarianism and Beyond</em>, Amartya\nSen and Bernard Williams (eds.), Cambridge: Cambridge University\nPress, 103\u2013128. doi:10.1017/CBO9780511611964.007</li>\n<li>\u2013\u2013\u2013, 1998, <em>What We Owe to Each Other</em>,\nCambridge, MA: Belknap Press.</li>\n<li>Schelling, Thomas C., 1960, <em>The Strategy of Conflict</em>,\nCambridge, MA: Harvard University Press.</li>\n<li>\u2013\u2013\u2013, 1966, <em>Arms and Influence</em>, New\nHaven, CT: Yale University Press.</li>\n<li>\u2013\u2013\u2013, 1971, \u201cDynamic Models of\nSegregation\u201d, <em>The Journal of Mathematical Sociology</em>,\n1(2): 143\u2013186. doi:10.1080/0022250X.1971.9989794</li>\n<li>Sen, Amartya, 1980, \u201cEquality of What?\u201d, Tanner\nLectures on Human Values delivered at Stanford University 22 May 1979,\ncollected in <em>Tanner Lectures on Human Values</em>, Sterling M.\nMcMurrin (ed.), Cambridge: Cambridge University Press, 1980,\n197\u2013220.\n [<a href=\"https://tannerlectures.utah.edu/_resources/documents/a-to-z/s/sen80.pdf\" target=\"other\">Sen 1980 available online</a>]</li>\n<li>Shapley, L. S. and Martin Shubik, 1954, \u201cA Method for\nEvaluating the Distribution of Power in a Committee System\u201d,\n<em>American Political Science Review</em>, 48(3): 787\u2013792.\ndoi:10.2307/1951053</li>\n<li>Skarbek, David, 2014, <em>The Social Order of the Underworld: How\nPrison Gangs Govern the American Penal System</em>, Oxford: Oxford\nUniversity Press. doi:10.1093/acprof:oso/9780199328499.001.0001</li>\n<li>Sidgwick, Henry, 1874 [2011], <em>The Methods of Ethics</em>,\nCambridge: Cambridge University Press.\ndoi:10.1017/CBO9781139136617</li>\n<li>Skyrms, Brian, 1996 [2014], <em>Evolution of the Social\nContract</em>, Cambridge: Cambridge University Press; second edition,\n2014. doi:10.1017/CBO9781139924825</li>\n<li>\u2013\u2013\u2013, 1998, \u201cThe Shadow of the\nFuture\u201d, in <em>Rational Commitment and Social Justice: Essays\nfor Gregory Kavka</em>, Jules L. Coleman and Christopher W. Morris\n(eds.), Cambridge: Cambridge University Press, 12\u201321.\ndoi:10.1017/CBO9780511527364.003</li>\n<li>\u2013\u2013\u2013, 2004, <em>The Stag Hunt and the Evolution\nof Social Structure</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9781139165228</li>\n<li>Sobel, Jordan Howard, 2009, <em>Walls and Vaults: A Natural\nScience of Morals (Virtue Ethics According to David Hume)</em>,\nHoboken, NJ: John Wiley &amp; Sons, Inc.\ndoi:10.1002/9781118031605</li>\n<li>St\u00e4hl, Ingolf, 1972, <em>Bargaining Theory</em>, Stockholm:\nEconomic Research Institute.</li>\n<li>Sugden, Robert, 1986, <em>The Economics of Rights, Co-operation,\nand Welfare</em>, Oxford: Blackwell Press.</li>\n<li>Taylor, Michael, 1987, <em>The Possibility of Cooperation</em>,\nCambridge: Cambridge University Press.</li>\n<li>Thrasher, John, 2018, \u201cEvaluating Bad Norms\u201d,\n<em>Social Philosophy and Policy</em>, 35(1): 196\u2013216.\ndoi:10.1017/S0265052518000055</li>\n<li>Thrasher, John and Toby Handfield, 2018, \u201cHonor and\nViolence: An Account of Feuds, Duels, and Honor Killings\u201d,\n<em>Human Nature</em>, 29(4): 371\u2013389.\ndoi:10.1007/s12110-018-9324-4</li>\n<li>Thomson, William and Terje Lensberg, 1989, <em>Axiomatic Theory of\nBargaining with a Variable Number of Agents</em>, Cambridge: Cambridge\nUniversity Press. doi:10.1017/CBO9780511664489</li>\n<li>Ullmann-Margalit, Edna, 1977, <em>The Emergence of Norms</em>,\nOxford: Clarendon Press.</li>\n<li>United Nations Population Fund (UNFPA), 2000, \u201cViolence\nAgainst Women and Girls: A Human Rights and Health Priority\u201d, in\n<em>The State of World Population, 2000</em>, United Nations\nPopulation Fund, 25\u201330.\n [<a href=\"https://www.unfpa.org/publications/state-world-population-2000\" target=\"other\">UNFPA 2000 available online</a>]</li>\n<li>Vanderschraaf, Peter, 1998, \u201cThe Informal Game Theory in\nHume\u2019s Account of Convention\u201d, <em>Economics and\nPhilosophy</em>, 14(2): 215\u2013247.\ndoi:10.1017/S0266267100003849</li>\n<li>\u2013\u2013\u2013, 2007, \u201cCovenants and\nReputations\u201d, <em>Synthese</em>, 157(2): 167\u2013195.\ndoi:10.1007/s11229-006-9147-4</li>\n<li>\u2013\u2013\u2013, 2010, \u201cThe Invisible Foole\u201d,\n<em>Philosophical Studies</em>, 147(1): 37\u201358.\ndoi:10.1007/s11098-009-9449-8</li>\n<li>\u2013\u2013\u2013, 2019, <em>Strategic Justice: Convention and\nProblems of Balancing Divergent Interests</em>, New York: Oxford\nUniversity Press. doi:10.1093/oso/9780199832194.001.0001</li>\n<li>Vanderschraaf, Peter and Diana Richards, 1997, \u201cJoint\nBeliefs in Conflictual Coordination Games\u201d, <em>Theory and\nDecision</em>, 42(3): 287\u2013310. doi:10.1023/A:1004962809537</li>\n<li>Von Neumann, John and Oskar Morgenstern, 1944 [2004]. <em>Theory\nof Games and Economic Behavior</em>, Princeton, NJ: Princeton\nUniversity Press. Sixtieth-Anniversary Edition, Princeton and Oxford:\nPrinceton University Press, 2004.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "Arrow\u2019s theorem",
            "decision theory",
            "functionalism",
            "game theory",
            "game theory: evolutionary",
            "prisoner\u2019s dilemma",
            "public reason",
            "social choice theory",
            "social contract: contemporary approaches to",
            "social norms"
        ],
        "entry_link": [
            {
                "../arrows-theorem/": "Arrow\u2019s theorem"
            },
            {
                "../decision-theory/": "decision theory"
            },
            {
                "../functionalism/": "functionalism"
            },
            {
                "../game-theory/": "game theory"
            },
            {
                "../game-evolutionary/": "game theory: evolutionary"
            },
            {
                "../prisoner-dilemma/": "prisoner\u2019s dilemma"
            },
            {
                "../public-reason/": "public reason"
            },
            {
                "../social-choice/": "social choice theory"
            },
            {
                "../contractarianism-contemporary/": "social contract: contemporary approaches to"
            },
            {
                "../social-norms/": "social norms"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=game-ethics\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/game-ethics/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=game-ethics&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/game-ethics/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=game-ethics": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/game-ethics/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=game-ethics&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/game-ethics/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "<a href=\"http://gametheory101.com/\" target=\"other\">Game Theory 101</a>,\na website managed by William Spaniel associated with his textbook of\nthe same name that includes an extensive library of videos that\nexplain most of the important ideas and topics in game theory.",
            "<a href=\"http://veconlab.econ.virginia.edu/\" target=\"other\">Veconlab: Experimental Economics Laboratory</a>,\na website managed by Charlie Holt that provides a platform for running\nexperiments that can be used in the classroom to illustrate numerous\ngame theoretic scenarios.",
            "Verbeek, Bruno and Peter Vanderschraaf, \u201cGame Theory and\nEthics\u201d, <em>Stanford Encyclopedia of Philosophy</em> (Fall 2021\nEdition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/fall2021/entries/game-ethics/\">https://plato.stanford.edu/archives/fall2021/entries/game-ethics/</a>&gt;.\n [This was the previous entry on this topic in the <em>Stanford\nEncyclopedia of Philosophy</em> \u2014 see the\n <a class=\"plain\" href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=game-ethics\" target=\"other\">version history</a>.]"
        ],
        "listed_links": [
            {
                "http://gametheory101.com/": "Game Theory 101"
            },
            {
                "http://veconlab.econ.virginia.edu/": "Veconlab: Experimental Economics Laboratory"
            },
            {
                "https://plato.stanford.edu/archives/fall2021/entries/game-ethics/": "https://plato.stanford.edu/archives/fall2021/entries/game-ethics/"
            },
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=game-ethics": "version history"
            }
        ]
    }
}