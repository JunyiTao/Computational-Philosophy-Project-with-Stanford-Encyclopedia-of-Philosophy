{
    "url": "causation-mani",
    "title": "Causation and Manipulability",
    "authorship": {
        "year": "Copyright \u00a9 2023",
        "author_text": "James Woodward\n<jfw@pitt.edu>",
        "author_links": [
            {
                "https://www.hps.pitt.edu/people/james-woodward": "James Woodward"
            },
            {
                "mailto:jfw%40pitt%2eedu": "jfw@pitt.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2023</a> by\n\n<br/>\n<a href=\"https://www.hps.pitt.edu/people/james-woodward\" target=\"other\">James Woodward</a>\n&lt;<a href=\"mailto:jfw%40pitt%2eedu\"><em>jfw<abbr title=\" at \">@</abbr>pitt<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Fri Aug 17, 2001",
        "substantive revision Sat May 6, 2023"
    ],
    "preamble": "\n\nManipulability theories of causation, according to which causes are to\nbe regarded as handles or devices for manipulating effects, have\nconsiderable intuitive appeal and are popular among many scientists\nand statisticians. This article surveys several prominent versions of\nsuch theories advocated by philosophers, and the many difficulties\nthey face. Until recently, philosophical statements of the\nmanipulationist approach have generally been reductionist in\naspiration and have assigned a central role to human action. These\ncontrast with more recent discussions employing a broadly\nmanipulationist framework for understanding causation, such as those\ndue to the computer scientist Judea Pearl and others, which are\nnon-reductionist and rely instead on the notion of an intervention.\nThis is simply an appropriately exogenous causal process; it has no\nessential connection with human action. This interventionist framework\nmanages to avoid at least some of these difficulties faced by\ntraditional philosophical versions of the manipulability theory and\nhelps to clarify the content of causal claims.\n",
    "toc": [
        {
            "#Intr": "1. Introduction"
        },
        {
            "#AgenTheo": "2. Agency Theories. "
        },
        {
            "#CausFreeActi": "3. Causation and Free Action"
        },
        {
            "#Inte": "4. Interventions"
        },
        {
            "#StruEquaDireGrapManiTheoCaus": "5. Structural Equations, Directed Graphs, and Manipulationist Theories of Causation"
        },
        {
            "#CircProb": "6. Is Circularity a Problem?"
        },
        {
            "#PlurCausConc": "7. The Plurality of Causal Concepts"
        },
        {
            "#InteDoNotInvoHumaActi": "8. Interventions That Do Not Involve Human Action"
        },
        {
            "#InteCoun": "9. Interventions and Counterfactuals"
        },
        {
            "#PossImpoInte": "10. Possible and Impossible Interventions "
        },
        {
            "#ScopInteAcco": "11. The Scope of Interventionist Accounts"
        },
        {
            "#AlleCausUnmaForLogiConcMetaReas": "12. (Alleged) Causes That Are Unmanipulable for Logical, Conceptual, or Metaphysical Reasons"
        },
        {
            "#SomeCritInteAcco": "13. Some Criticisms of Interventionist Accounts"
        },
        {
            "#SomeRecePosiDeve": "14. Some Recent Positive Developments."
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        },
        {
            "early-agency.html": "An Early Version of an Agency Theory"
        },
        {
            "role-causal.html": "The Role of the Manipulability Theory in Clarifying Causal Claims"
        },
        {
            "additional-criticisms.html": "Additional Recent Criticisms of the Interventionist Account"
        }
    ],
    "main_text": "\n1. Introduction\n\nA commonsensical idea about causation is that causal relationships are\nrelationships that are potentially exploitable for purposes of\nmanipulation and control: very roughly, if \\(C\\) is genuinely a cause\nof \\(E\\), then if I can manipulate \\(C\\) in the right way, this should\nbe a way of manipulating or changing \\(E\\). This idea is the\ncornerstone of manipulability theories of causation developed by\nphilosophers such as Gasking (1955), Collingwood (1940), von Wright\n(1971), Menzies and Price (1993), and Woodward (2003). It is also an\nidea that is advocated by many non-philosophers. For example, in their\nextremely influential text on experimental design (1979) Cook and\nCampbell write:\n\n\nThe paradigmatic assertion in causal relationships is that\nmanipulation of a cause will result in the manipulation of an\neffect. \u2026 Causation implies that by varying one factor I\ncan make another vary. (Cook & Campbell 1979: 36, emphasis in\noriginal)\n\n\nSimilar ideas are commonplace in econometrics and in the so-called\nstructural equations or causal modeling literature, and more recently\nhave been forcefully reiterated by the computer scientist Judea Pearl\nin very influential book length treatment of causality (Pearl\n2009).\n\nAt least until relatively recently philosophical discussion has been\nunsympathetic to manipulability theories: two standard complaints have\nbeen that manipulability theories are unilluminatingly circular and\nthat they lead to a conception of causation that is unacceptably\nanthropocentric or at least insufficiently general in the sense that\nit is linked much too closely to the practical possibility of human\nmanipulation (see, e.g., Hausman 1986, 1998). Both objections seem\nprima facie plausible. Suppose that \\(X\\) is a variable that\ntakes one of two different values, 0 and 1, depending on whether some\nevent of interest occurs. Then for an event or process \\(M\\) to\nqualify as a manipulation of \\(X\\), it would appear that there must be\na causal connection between \\(M\\) and \\(X\\): to manipulate \\(X\\), one\nmust cause it to change in value. How then can we use the\nnotion of manipulation to provide a non-circular account of causation?\nMoreover, it is uncontroversial that causal relationships can obtain\nin circumstances in which manipulation of the cause by human beings is\nnot practically possible\u2014think of the causal relationship\nbetween the gravitational attraction of the moon and the tides or\ncausal relationships in the very early universe. How can a\nmanipulability theory avoid generating a notion of causation that is\nso closely tied to what humans can do that it is inapplicable to such\ncases?\n\nThese philosophical criticisms of manipulability theories contrasts\nwith the widespread view among statisticians, theorists of\nexperimental design, and many social and natural scientists that an\nappreciation of the connection between causation and manipulation can\nplay an important role in clarifying the meaning of causal claims and\nunderstanding their distinctive features. This in turn generates a\npuzzle. Are non-philosophers simply mistaken in thinking that focusing\non the connection between causation and manipulation can tell us\nsomething valuable about causation? Does the widespread invocation of\nsomething like a manipulability conception among practicing scientists\nshow that the usual philosophical criticisms of manipulability\ntheories of causation are misguided?\n\nThe ensuing discussion is organized as follows.\n Section 2\n describes a well-known version of an manipulability theory due to\nMenzies and Price (1993) which assigns a central role to the notion of\nagency or free action.\n Section 3\n describes reasons why the notion of a free action seems an inadequate\nbasis for the formulation of a manipulability theory.\n Section 4\n introduces the notion of an intervention which allows for a more\nadequate statement of the manipulability approach to causation and\nwhich has figured prominently in recent discussion.\n Section 5\n considers Pearl\u2019s \u201cinterventionist\u201d formulation of\na manipulability theory and an alternative to it, due to Woodward\n(2003).\n Section 6\n takes up the charge that manipulability theories are circular.\n Section 7\n explores how interventionist ideas can be used to explicate a variety\nof different causal concepts.\n Section 8\n returns to the relationship between interventions and human actions,\nwhile\n \u00a79\n discusses the role of counterfactuals in interventionist theories.\nSections\n 10,\n 11 and\n 12\n consider the scope of manipulability accounts, while\n \u00a713\n considers some objections to such accounts and\n \u00a714\n some recent positive developments.\n\nAs we shall see, the somewhat different assessments of manipulability\naccounts of causation within and outside of philosophy derive in part\nfrom the different goals or aspirations that underlie the versions of\nthe theory developed by these two groups. Early philosophical\ndefenders of the manipulability conception such as von Wright and\nMenzies and Price attempted to turn the connection between causation\nand manipulability into a reductive analysis: their strategy was to\ntake as primitive the notion of manipulation (or some related notion\nlike agency or bringing about an outcome as a result of a free\naction), to argue that this notion is not itself causal (or at least\ndoes not presuppose all of the features of causality the investigator\nis trying to analyze), and to then attempt to use this notion to\nconstruct a non-circular reductive definition of what it is for a\nrelationship to be causal. Philosophical critics have (quite\nreasonably) assessed such approaches in terms of this aspiration\n(i.e., they have tended to think that manipulability accounts are of\ninterest only insofar as they lead to a non-circular analysis of\ncausal claims) and have found the claim of a successful reduction\nunconvincing. By contrast, statisticians and other non-philosophers\nwho have explored the link between causation and manipulation\ngenerally have not had reductionist aspirations\u2014instead their\ninterest has been in unpacking what causal claims mean and in showing\nhow they figure in inference by tracing their interconnections with\nother related concepts (including manipulation but also probability)\nbut without suggesting that the notion of manipulation is itself a\ncausally innocent notion.\n\nThe impulse toward reduction contributes to the other features that\ncritics have found objectionable in standard formulations of the\nmanipulability theory. To carry through the reduction, one needs to\nshow that the notion of agency is independent of or prior to the\nnotion of causality and this in turn apparently requires that human\nactions or manipulations be given a special status\u2014they\ncan\u2019t be ordinary causal transactions, but must instead be an\nindependent fundamental feature of the world in their own right. This\nboth seems problematic on its own terms (it is prima facie\ninconsistent with various naturalizing programs) and leads directly to\nthe problem of anthropocentricity: if the only way in which we\nunderstand causation is by means of our prior grasp of an independent\nnotion of agency, then it is hard to see what could justify us in\nextending the notion of causation to circumstances in which\nmanipulation by human beings is not possible and the relevant\nexperience of agency unavailable. Both von Wright and Menzies and\nPrice struggle with this difficulty.\n\nOne way out of these problems is to follow Pearl and others in\nreformulating the manipulability approach in terms of the notion of an\nintervention, where this is characterized in purely causal terms that\nmake no essential reference to human action. Some human actions will\nqualify as interventions but they will do so in virtue of their causal\ncharacteristics, not because they are free or carried out by humans.\nThis \u201cinterventionist\u201d reformulation allows the\nmanipulability theory to avoid a number of counterexamples to more\ntraditional versions of the theory. Moreover, when so reformulated, it\nis arguable that the theory may be extended readily to capture causal\nclaims in contexts in which human manipulation is impossible. However,\nthe price of such a reformulation is that we lose the possibility of a\nreduction of causal claims to claims that are non-causal. Fortunately\n(or so\n \u00a7\u00a77 and\n 8 argue) an interventionist formulation of a manipulability\ntheory may be non-trivial and illuminating even if non- reductive.\n2. Agency Theories.\n\nA comparatively early and influential statement of a manipulability\ntheory which assigns a central role to human agency is due to von\nWright (1971; see\n An Early Version of an Agency Theory\n for further discussion). However, this entry will focus on the more\nrecent version developed by Peter Menzies and Huw Price (1993) (also\ndiscussed in a series of papers written by Price alone [1991, 1992,\nand more recently, 2017 which argues that the contrast between agency\nversions of a manipulability theory and non-agency versions is not as\nsharp as is suggested below) . Menzies\u2019 and Price\u2019s basic\nthesis is that:\n\n\n\u2026 an event \\(A\\) is a cause of a distinct event \\(B\\) just in\ncase bringing about the occurrence of \\(A\\) would be an effective\nmeans by which a free agent could bring about the occurrence of \\(B\\).\n(1993: 187)\n\n\nThey take this connection between free agency and causation to support\na probabilistic analysis of causation (according to which \u201c\\(A\\)\ncauses \\(B\\)\u201d can be plausibly identified with \u201c\\(A\\)\nraises the probability of \\(B\\)\u201d) provided that the\nprobabilities appealed to are what they call \u201cagent\nprobabilities,\u201d where\n\n\n[a]gent probabilities are to be thought of as conditional\nprobabilities, assessed from the agent\u2019s perspective under the\nsupposition that antecedent condition is realized ab initio,\nas a free act of the agent concerned. Thus the agent probability that\none should ascribe to \\(B\\) conditional on \\(A\\) is the probability\nthat \\(B\\) would hold were one to choose to realize \\(A\\). (1993:\n190)\n\n\nThe idea is thus that the agent probability of \\(B\\) conditional on\n\\(A\\) is the probability that \\(B\\) would have conditional on the\nassumption that \\(A\\) has a special sort of status or history\u2014in\nparticular, on the assumption that A is realized by a free act. \\(A\\)\nwill be a cause of \\(B\\) just in case the probability of \\(B\\)\nconditional on the assumption that \\(A\\) is realized by a free act is\ngreater than the unconditional probability of \\(B\\); \\(A\\) will be a\nspurious cause of \\(B\\) just in case these two probabilities are\nequal. As an illustration, consider a structure in which atmospheric\npressure, represented by a variable \\(Z\\), is a common cause of the\nreading \\(X\\) of a barometer and the occurrence of a storm \\(Y\\), with\nno causal relationship between \\(X\\) and \\(Y. X\\) and \\(Y\\) will be\ncorrelated, but Price\u2019s and Menzies\u2019 intuitive idea is\nthat conditional on the realization of \\(X\\) by a free act, this\ncorrelation will disappear, indicating that the correlation between\n\\(X\\) and \\(Y\\) is spurious and does not reflect a causal connection\nfrom \\(X\\) to \\(Y\\). If, by contrast, this correlation were to\npersist, this would be an indication that \\(X\\) was after all a cause\nof \\(Y\\). (What \u201cfree act\u201d might mean in this context will\nbe explored below, but a charitable interpretation, although not one\nthat Price and Menzies explicitly adopt, is that the manipulation of\n\\(X\\) should satisfy the conditions we would associate with an ideal\nexperiment designed to determine whether \\(X\\) causes\n\\(Y\\)\u2014thus, for example, the experimenter should manipulate the\nposition of the barometer dial in a way that is independent of the\natmospheric pressure \\(Z\\), perhaps by setting its value after\nconsulting the output of some randomizing device.)\n\nMenzies and Price claim that they can appeal to this notion of agency\nto provide a non-circular, reductive analysis of causation. They claim\nthat circularity is avoided because we have a grasp of the\nexperience of agency that is independent of our grasp of the\ngeneral notion of causation.\n\n\nThe basic premise is that from an early age, we all have direct\nexperience of acting as agents. That is, we have direct experience not\nmerely of the Humean succession of events in the external world, but\nof a very special class of such successions: those in which the\nearlier event is an action of our own, performed in circumstances in\nwhich we both desire the later event, and believe that it is more\nprobable given the act in question than it would be otherwise. To put\nit more simply, we all have direct personal experience of doing one\nthing and thence achieving another. \u2026 It is this common and\ncommonplace experience that licenses what amounts to an ostensive\ndefinition of the notion of \u2018bringing about\u2019. In other\nwords, these cases provide direct non-linguistic acquaintance with the\nconcept of bringing about an event; acquaintance which does not depend\non prior acquisition of any causal notion. An agency theory thus\nescapes the threat of circularity. (1993: 194\u20135)\n\n\nMenzies and Price recognize that, once the notion of causation has\nbeen tied in this way to our \u201cpersonal experience of doing one\nthing and hence achieving another\u201d (1993: 194), a problem arises\nconcerning unmanipulable causes. To use their own example, what can it\nmean to say that \u201cthe 1989 San Francisco earthquake was caused\nby friction between continental plates\u201d (1993: 195) if no one\nhas (or given the present state of human capabilities could have) the\ndirect personal experience of bringing about an earthquake by\nmanipulating these plates? Their response to this difficulty is\ncomplex, but the central idea is captured in the following\npassages\n\n\n\u2026 we would argue that when an agent can bring about one event\nas a means to bringing about another, this is true in virtue of\ncertain basic intrinsic features of the situation involved, these\nfeatures being essentially non-causal though not necessarily physical\nin character. Accordingly, when we are presented with another\nsituation involving a pair of events which resembles the given\nsituation with respect to its intrinsic features, we infer that the\npair of events are causally related even though they may not be\nmanipulable. (1993: 197)\n\nClearly, the agency account, so weakened, allows us to make causal\nclaims about unmanipulable events such as the claim that the 1989 San\nFrancisco earthquake was caused by friction between continental\nplates. We can make such causal claims because we believe that there\nis another situation that models the circumstances surrounding the\nearthquake in the essential respects and does support a means-end\nrelation between an appropriate pair of events. The paradigm example\nof such a situation would be that created by seismologists in their\nartificial simulations of the movement of continental plates. (1993:\n197)\n\n\nOne problem with this suggestion has to do with how we are to\nunderstand the \u201cintrinsic\u201d but (allegedly)\n\u201cnon-causal\u201d features in virtue of which the movements of\nthe continental plates \u201cresemble\u201d the artificial models\nwhich the seismologists are able to manipulate. It is well-known that\nsmall scale models and simulations of naturally occurring phenomena\nthat superficially resemble or mimic those phenomena may nonetheless\nfail to capture their causally relevant features because, for example,\nthe models fail to \u201cscale up\u201d\u2014because causal\nprocesses that are not represented in the model become quite important\nat the length scales that characterize the naturally occurring\nphenomena. Thus, when we ask what it is for a model or simulation\nwhich contains manipulable causes to \u201cresemble\u201d phenomena\ninvolving unmanipulable causes, the relevant notion of resemblance\nseems to require that the same causal processes are operative\nin both. If the extension of their account to unmanipulable causes\nrequires a notion of resemblance that is already causal in character\nand which, ex hypothesi cannot be explained in terms of our\nexperience of agency, then their reduction fails.\n\nIt might be thought that this difficulty can be avoided by the simple\nexpedient of adopting a counterfactual formulation of the\nmanipulability theory. Indeed, it is clear that some\ncounterfactual formulation is required if the theory is to be even\nremotely plausible: after all, no one supposes that \\(A\\) can only be\na cause of \\(B\\) if \\(A\\) is in fact manipulated. One thus might\nconsider a formulation along the lines of:\n\n(CF) \\(A\\)\ncauses \\(B\\) if and only if \\(B\\) would change if an appropriate\nmanipulation [by humans] on \\(A\\) were to be carried\nout.\n\n\nThe suggestion under consideration attempts to avoid the difficulties\nposed by causes that are not manipulable by human beings by contending\nthat for\n (CF)\n to be true, it is not required that the manipulation in question be\npractically possible for human beings to carry out or even that human\nbeings exist. Instead all that is required is that \\(if\\) human beings\nwere to carry out the requisite manipulation of \\(A\\) (e.g., the\ncontinental plates), \\(B\\) (whether or not an earthquake occurs) would\nchange. (The possibility of adopting such a counterfactual formulation\nis sympathetically explored, but not fully endorsed by Ernest Sosa and\nMichael Tooley in the introduction to their 1993.)\n\nOne problem with this suggestion is that, independently of whether a\ncounterfactual formulation is adopted, the notion of a free action or\nhuman manipulation cannot by itself, for reasons to be described in\n \u00a73,\n do the work (that of distinguishing between genuine and spurious\ncausal relationships) that Menzies and Price wish it to do. But in\naddition to this, a counterfactual formulation along the lines of\n (CF)\n seems completely unilluminating unless accompanied by some account of\nhow we are to understand and assess such counterfactuals and, more\nspecifically, what sort of situation or possibility we are supposed to\nenvision when we imagine that the antecedent of\n (CF)\n is true. Consider, for example, a causal claim about the very early\nuniverse during which temperatures are so high that atoms and\nmolecules and presumably anything we can recognize as an agent cannot\nexist. What counterfactual scenario are we supposed to envision when\nwe ask, along the lines of\n (CF),\n what would happen if human beings were to exist and were able to\ncarry out certain manipulations in this situation? A satisfying\nversion of an agency theory should give us an account of how our\nexperience of agency in ordinary contexts gives us a purchase on how\nto understand and evaluate such counterfactuals. To their credit,\nMenzies and Price attempt to do this, but it is not clear that they\nare successful.\n3. Causation and Free Action\n\nAs we have seen, Menzies and Price assign a central role to\n\u201cfree action\u201d in the elucidation of causation. They do not\nfurther explain what they mean by this phrase, preferring instead, as\nthe passage quoted above indicates, to point to a characteristic\nexperience we have as agents. It seems clear, however, that whether\n(as soft determinists would have it) a free action is understood as an\naction that is uncoerced or unconstrained or due to voluntary choices\nof the agent, or whether, as libertarians would have it, a free action\nis an action that is uncaused or not deterministically caused, the\npersistence of a correlation between \\(A\\) and \\(B\\) when \\(A\\) is\nrealized as a \u201cfree act\u201d is not sufficient for\n\\(A\\) to cause \\(B\\). Suppose , in the example described above, the\nposition of the barometer dial \\(X\\) is set by a free act (in either\nof the above senses) of the experimenter but that this free act (and\nhence \\(X)\\) is correlated with \\(Z\\), the variable measuring\natmospheric pressure, perhaps because the experimenter observes the\natmospheric pressure and freely chooses to set \\(X\\) in a way that is\ncorrelated with \\(Z\\). (This possibility is compatible with the\nexperimenter\u2019s act of setting \\(X\\) being free in either of the\nabove two senses.) In this case, \\(X\\) will remain correlated with\n\\(Y\\) when produced by a free act, even though \\(X\\) does not cause\n\\(Y\\). Suppose, then, that we respond to this difficulty by adding to\nour characterization of \\(A\\)\u2019s being realized by a free act the\nidea that this act must not itself be correlated with any other cause\nof \\(A\\). (Passages in Price 1991 suggest such an additional proviso,\nalthough the condition in question seems to have nothing to do with\nthe usual understanding of free action.) Even with this proviso, it\nneed not be the case that \\(A\\) causes \\(B\\) if \\(A\\) remains\ncorrelated with \\(B\\) when \\(A\\) is produced by an act that is free in\nthis sense, since it still remains possible that the free act that\nproduces \\(A\\) also causes \\(B\\) via a route that does not go through\n\\(A\\). As an illustration, consider a case in which an\nexperimenter\u2019s administration of a drug to a treatment group (by\ninducing patients to ingest it) has a placebo effect that enhances\nrecovery, even though the drug itself has no effect on recovery. There\nis a correlation between ingestion of the drug and recovery that\npersists under the experimenter\u2019s free act of administering the\ndrug even though ingestion of the drug does not cause recovery.\n4. Interventions\n\nExamples like those just described show that if we wish to follow\nMenzies and Price in defending the claim that if an association\nbetween \\(A\\) and \\(B\\) persists when \\(A\\) is given the right sort of\n\u201cindependent causal history\u201d or is\n\u201cmanipulated\u201d in the right way, then \\(A\\) causes \\(B\\),\nwe need to be more precise by what we mean by the quoted phases. There\nhave been a number of attempts to do this in the recent literature on\ncausation. The basic idea that all of these discussions attempt to\ncapture is that of a \u201csurgical\u201d change in \\(A\\) which is\nof such a character that if any change occurs in \\(B\\), it occurs only\nas a result of its causal connection, if any, to \\(A\\) and not in any\nother way. In other words, the change in \\(B\\), if any, that is\nproduced by the manipulation of \\(A\\) should be produced only via a\ncausal route that goes through \\(A\\). Manipulations or changes in the\nvalue of a variable that have the right sort of surgical features have\ncome to be called interventions in the recent literature\n(e.g., Spirtes, Glymour, and Scheines 2000; Meek and Glymour 1994;\nHausman 1998; Pearl 2009; Woodward 1997, 2000, 2003; Woodward and\nHitchcock 2003; Cartwright 2003) and this entry will follow this\npractice. The characterization of the notion of an intervention is\nrightly seen by many writers as central to the development of a\nplausible version of a manipulability theory. One of the most detailed\nattempts to think systematically about interventions and their\nsignificance for understanding causation is due to Pearl 2009 and is\ndiscussed in the following section.\n5. Structural Equations, Directed Graphs, and Manipulationist Theories of Causation\n\nA great deal of recent work on causation has used systems of equations\nand directed graphs to represent causal relationships. Judea Pearl\n(e.g., Pearl 2009) is an influential example of this approach. His\nwork provides a striking illustration of the heuristic usefulness of a\nmanipulationist framework in specifying what it is to give such\nsystems a causal\n interpretation.[1]\n Pearl characterizes the notion of an intervention by reference to a\nprimitive notion of a causal mechanism. A functional causal model is a\nsystem of equations \\(X_i = F(Pa_i, U_i)\\) where \\(Pa_i\\) represents\nthe parents or direct causes of \\(X_i\\) that are explicitly included\nin the model and \\(U_i\\) represents an error variable that summarizes\nthe impact of all excluded variables. Each equation represents a\ndistinct causal mechanism which is understood to be\n\u201cautonomous\u201d in the sense in which that notion is used in\neconometrics; this means roughly that it is possible to interfere with\nor disrupt each mechanism (and the corresponding equation) without\ndisrupting any of the others. The simplest sort of intervention in\nwhich some variable \\(X_i\\) is set to some particular value \\(x_i\\)\namounts, in Pearl\u2019s words, to\n\n\nlifting \\(X_i\\) from the influence of the old functional mechanism\n\\(X_i = F_i(Pa_i, U_i)\\) and placing it under the influence of a new\nmechanism that sets the value \\(x_i\\) while keeping all other\nmechanisms undisturbed. (Pearl 2009: 70; I have altered the notation\nslightly)\n\n\nIn other words, the intervention disrupts completely the relationship\nbetween \\(X_i\\) and its parents so that the value of \\(X_i\\) is\ndetermined entirely by the intervention. Furthermore, the intervention\nis surgical in the sense that no other causal relationships in the\nsystem are changed. Formally, this amounts to replacing the equation\ngoverning \\(X_i\\) with a new equation \\(X_i = x_i\\), substituting for\nthis new value of \\(X_i\\) in all the equations in which \\(X_i\\) occurs\nbut leaving the other equations themselves unaltered. In a graphical\nrepresentation of causal relationships (see below), an intervention of\nthis sort on a variable \\(X_i\\) breaks or removes all other arrows\ndirected into \\(X_i\\), so that the value of \\(X_i\\) is now completely\nfixed by the intervention. Pearl\u2019s assumption is that the other\nvariables that change in value under this intervention will do so only\nif they are effects of \\(X_i\\).\n\nAgain, if we want to use this notion of an intervention to elucidate\nwhat it is for \\(X\\) to cause \\(Y\\) it is natural to move to a\ncounterfactual formulation in the sense that what matters for whether\n\\(X\\) causes \\(Y\\) is what would happen to \\(Y\\) if an intervention on\n\\(X\\) of the sort described above were to occur. Following what has\nbecome an established usage I will call such counterfactuals, the\nantecedents of which correspond to claims about interventions (If\n\\(X\\) were set to value \\(x\\) under an intervention, then\u2026)\ninterventionist counterfactuals. These are the\ncounterfactuals that (under some interpretation, perhaps not\nnecessarily involving Pearl\u2019s particular notion of an\nintervention) seem most suitable for formulating a manipulability\ntheory of causation.\n\nThe need for such a counterfactual formulation raises several\nquestions that will be explored in more detail below. First, how\nshould one understand (what is the appropriate interpretation of or\nsemantics for) the counterfactuals in question? Without attempting to\nanswer this question in detail, it seems plausible that if\ninterventionist counterfactuals are to be useful in elucidating causal\nclaims, their semantics must be different from the familiar\nLewis/Stalnaker possible world semantics in some respects, as is\nargued by Woodward (2003), Briggs (2012), and Fine (2012). For\nexample, on the Lewis/Stalnaker semantics, counterfactuals with\nlogically or metaphysically impossible antecedents are always\nvacuously true, but if there are causal claims that might be\nassociated with such counterfactuals, we don\u2019t want them to be\nautomatically true (cf.\n \u00a712).\n\nA second difference is that an interventionist counterfactual of form\n\u201cIf an intervention were to set \\(X=x\\), then \\(Y= y\\)\u201d is\nmost naturally understood as requiring for its truth that all\nsuch interventions (or at least all such interventions within the\nbackground circumstances in which the causal model of interest is\ntaken to hold) would be followed by \\(Y= y\\). This has the consequence\nthat, for example, \u201cstrong centering\u201d which holds for the\nLewis/Stalnaker semantics, does not hold for interventionist\ncounterfactuals. According to strong centering the actual world is\nmore similar to itself than any other possible world. Thus if both\n\\(p\\) and \\(q\\) hold in the actual world, then the\n\u201ccounterfactual\u201d (that is, subjunctive conditional)\n\u201cif \\(p\\) were the case, \\(q\\) would be the case\u201d, is\nautomatically true, As an illustration of the difference this makes,\nsuppose that \\(X\\) and \\(Y\\) obey the following\nintervention\u2013supporting functional relation: If and only if \\(X=\n1\\).5, then \\(Y= 3\\). Suppose that in the actual world, \\(X= 1.5,\\)\n\\(Y= 3.\\) Now consider the counterfactual \\(C\\) : If \\(1\\lt X \\lt 3,\\)\nthen \\(Y=3.\\) Assuming strong centering, the closest world to the\nactual world in which the antecedent of \\(C\\) is true is the actual\nworld in which \\(X=1.5\\). In this world, \\(Y=3\\), so \\(C\\) is true. By\ncontrast, \\(C\\) is false under an interventionist interpretation,\nsince values of \\(X\\) between 1 and 3 other than 1.5 are not followed\nby 3. Arguably the interventionist verdict that \\(C\\) (and the\nassociated causal claim that \u201c\\(X\\) being between 1 and 3 causes\n\\(Y=3)\\)\u201d are false is the correct view. Several other\ndifferences between interventionist counterfactuals and the\nLewis/Stalnaker semantics will be noted below.\n\nA second general issue, related to the one just described, concerns\nthe sense, if any, in which interventions must be\n\u201cpossible\u201d and the bearing of this on the truth of the\nassociated causal claims. Returning to the notion of intervention\nassociated with Pearl above, note that this notion says nothing about\nwhether there is an actual or even possible causal factor that might\naccomplish the surgical modification Pearl describes. We may if we\nwish represent such an intervention \\(I\\) by means of arrow directed\ninto the variable \\(X_i\\) that is intervened on which breaks all other\narrows directed into \\(X_i\\) (and Pearl sometimes uses this\nrepresentation) but both the \\(I\\) variable and this arrow seem\ndispensable. We could instead just think of \\(X_i\\) as set to some new\nvalue in the arrow-breaking or equation replacement manner described\nabove, with no further restrictions on when such a setting operation\nis possible (or when it is permissible or legitimate to invoke it). I\nwill call this a setting intervention. This contrasts with an\nalternative conception of interventions and their connection to causal\nclaims according to which the truth of a claim like \u201c\\(X\\)\ncauses \\(Y\\)\u201d requires that interventions on \\(X\\) must be\n\u201cpossible\u201d in some non-trivial sense of this notion, which\nthen must be specified. (In other words, the truth of \u201c\\(X\\)\ncauses \\(Y\\)\u201d requires both that \\(Y\\) changes under an\nintervention on \\(X\\) and that this intervention be\npossible.) When a possibility condition of this sort is imposed, I\nwill say we are making use of a possibility constrained\nnotion of intervention. Use of this notion raises the difficult\nquestion of how the relevant notion of possibility should be\nunderstood. I will suggest below that the best way of making sense of\nthis notion is in terms of some notion of conceptual or mathematical\n(or if you like, \u201cmetaphysical\u201d) coherence\u2014roughly\nspeaking, the issue is whether there is an appropriately empirically\ngrounded theoretical/mathematical apparatus that allows for a coherent\ndescription of the possible intervention in question and allows us to\ndetermine what would happen if the intervention were realized. In some\ncases (see below) such a description may be available even though the\nintervention in question may not be physically\n possible.[2]\n Recognizing obvious worries about the clarity of this notion of\npossibility (which in my view should be acknowledged by defenders of\nthis notion), one might think that it is preferable to always employ\nthe setting notion in formulating an interventionist account. However,\nas we shall see, formulations in terms of the \u201cpossibility\nconstrained\u201d notion have appealing features (they seem to do a\nbetter job of capturing the truth conditions for some causal claims)\nand a number of writers seem to rely on such a conception.\n\nReturning to Pearl, and following his framework, let us represent the\nproposition that the value of \\(X\\) has been set by an intervention to\nsome particular value, \\(x_0\\), by means of a \u201c\\(\\do\\)\u201d\noperator \\((\\do(X=x_0)\\), or more simply, \\(\\do x_0)\\). It is\nimportant to understand that conditioning on the information that the\nvalue of \\(X\\) has been set to \\(x_0\\) will in general be\nquite different from conditioning on the information that the value of\n\\(X\\) has been observed to be \\(x_0\\) (see Meek and Glymour\n1994; Pearl 2009). For example, in the case in which \\(X\\) and \\(Y\\)\nare joint effects of the common cause \\(Z\\), and \\(X\\) does not cause\n\\(Y\\), \\(P(Y/X=x_0) \\ne P(Y)\\); that is, \\(Y\\) and \\(X\\) are not\nindependent. However, \\(P(Y/\\do(X=x_0) = P(Y)\\); that is, \\(Y\\) will\nbe independent of \\(X\\), if the value of \\(X\\) is set by an\nintervention. This is because the intervention on \\(X\\) will break the\ncausal connection from \\(Z\\) to \\(X\\), so that the probabilistic\ndependence between \\(Y\\) and \\(X\\) that is produced by \\(Z\\) in the\nundisturbed system will no longer hold once the intervention occurs.\nIn this way, we may capture Menzies\u2019 and Price\u2019s idea that\n\\(X\\) causes \\(Y\\) if and only if the correlation between \\(X\\) and\n\\(Y\\) would persist under the right sort of manipulation of \\(X\\).\n\nThis framework allows for a simple definitions of various causal\nnotions. For example, Pearl defines the \u201ccausal effect\u201d of\n\\(X\\) on \\(Y\\) associated with the \u201crealization\u201d of a\nparticular value \\(x\\) of \\(X\\) as:\n\n(C)\\(P(Y\n\\mid{\\do x})\\)\n\n\nthat is, as the distribution that \\(Y\\) would assume under an\nintervention that sets the value of \\(X\\) to the value \\(x\\). Again,\nit is obvious that this is a version of a counterfactual account of\ncausation.\n\nOne of the many attractions of this approach is that it yields a very\nnatural account of what it is to give a causal interpretation to a\nsystem of equations of the sort employed in the so-called causal\nmodeling literature. For example, if a linear regression equation \\(Y\n= aX + U\\) makes a causal claim, it is to be understood as claiming\nthat if an intervention were to occur that sets the value of \\(X=x_0\\)\nin circumstances \\(U=u_0\\), the value of \\(Y\\) would be \\(y = ax_0 +\nu_0\\), or alternatively that an intervention that changes \\(X\\) by\namount \\(dx\\) will change \\(Y\\) by amount \\(a\\; dx\\). As another\nillustration consider the system of equations\n\n(1)\\(Y = aX +\nU\\)\n(2) \\(Z = bX +\ncY + V\\)\n\n\nWe may rewrite these as follows:\n\n(1)\\(Y = aX +\nU\\)\n(3) \\(Z = dX +\nW\\)\n\n\nwhere \\(d = b + ac\\) and \\(W = cU + V\\). Since (3) has been obtained\nby substituting (1) into (2), the system (1)\u2013(2) has exactly the\nsame solutions in \\(X, Y\\), and \\(Z\\) as the system (1)\u2013(3).\nSince \\(X, Y\\) and \\(Z\\) are the only measured variables,\n(1)\u2013(2) and (1)\u2013(3) are \u201cobservationally\nequivalent\u201d in the sense that they imply or represent exactly\nthe same facts about the patterns of correlations that obtain among\nthe measured variables. Nonetheless, the two systems correspond to\ndifferent causal structures. (1)\u2013(2) says that \\(X\\) is a direct\ncause of \\(Y\\) and that \\(X\\) and \\(Y\\) are direct causes of \\(Z\\). By\ncontrast, (1)\u2013(3) says that \\(X\\) is a direct cause of \\(Y\\) and\nthat \\(X\\) is a direct cause of \\(Z\\) but says nothing about a causal\nrelation between \\(Y\\) and \\(Z\\). We can cash this difference out\nwithin the interventionist/manipulationist framework described\nabove\u2014(2) claims that an intervention on \\(Y\\) will change \\(Z\\)\nwhile (1)\u2013(3) denies this. (Recall that an intervention on \\(Y\\)\nwith respect to \\(Z\\) must not be correlated with any other cause of\n\\(Z\\) such as \\(X\\), and will break any causal connection between\n\\(X\\) and \\(Y\\).) Thus while the two systems of equations agree about\nthe correlations so far observed, they disagree about what would\nhappen under an intervention on \\(Y\\). According to an\ninterventionist/manipulationist account of causation, it is the system\nthat gets such counterfactuals right that correctly represents the\ncausal facts.\n\nOne possible limitation of the notion of a setting intervention (or at\nleast Pearl\u2019s characterization of it) concerns the scope of the\nrequirement that an intervention on \\(X_i\\) leave intact all\nother mechanisms besides the mechanism that previously determined the\nvalue of \\(X_i\\). If, as Pearl apparently intends, we understand this\nto include the requirement that an intervention on \\(X_i\\) must leave\nintact the causal mechanism if any, that connects \\(X_i\\) to its\npossible effects \\(Y\\), then an obvious worry about circularity\narises, at least if we want to use the notion of an intervention to\ncharacterize what it is for \\(X_i\\) to cause \\(Y\\). A closely related\nproblem is that given the way Pearl characterizes the notion of an\nintervention, his definition\n (C)\n of the causal effect of \\(X\\) on \\(Y\\), seems to give us not the\ncausal contribution made by \\(X = x\\) alone to \\(Y\\) but rather the\ncombined impact on \\(Y\\) of this contribution and whatever\ncontribution is made to the value of \\(Y\\) by other causes of \\(Y\\)\nbesides \\(X\\). For example, in the case of the regression equation \\(Y\n= aX+U\\), the causal effect in Pearl\u2019s sense of \\(X=x\\\n\\textrm{on}\\ Y\\) is apparently \\(P(Y) = ax + U\\), rather than, as one\nmight expect, just \\(ax\\). In part for these reasons (and for other\nreasons, described below), Woodward (2003) and Woodward and Hitchcock\n(2003) explore a different way of characterizing the notion of an\nintervention which does not make reference to the relationship between\nthe variable intervened on and its effects. For Woodward and\nHitchcock, in contrast to Pearl, an intervention \\(I\\) on a variable\n\\(X\\) is always defined with respect to a second variable \\(Y\\) (the\nintent being to use the notion of an intervention on \\(X\\) with\nrespect to \\(Y\\) to characterize what it is for \\(X\\) to cause \\(Y)\\).\nSuch an intervention \\(I\\) must meet the following requirements\n (M1\u2013M4):\n\n(M1)\\(I\\)\nmust be the only cause of \\(X\\); i.e., as with Pearl, the intervention\nmust completely disrupt the causal relationship between \\(X\\) and its\nprevious causes so that the value of \\(X\\) is set entirely by\n\\(I\\),\n(M2)\\(I\\)\nmust not directly cause \\(Y\\) via a route that does not go through\n\\(X\\) as in the placebo example,\n(M3)\\(I\\)\nshould not itself be caused by any cause that affects \\(Y\\) via a\nroute that does not go through \\(X\\), and\n(M4)\\(I\\)\nleaves the values taken by any causes of \\(Y\\) except those that are\non the directed path from \\(I\\) to \\(X\\) to \\(Y\\) (should this exist)\nunchanged.\n\n\nThis characterization makes explicit reference to conditions that must\nbe satisfied by the intervention variable \\(I.\\) Although perhaps not\nmandatory, questions about what it means for such an \\(I\\) to be\npossible and how we are to understand the antecedents of the\nassociated interventionist counterfactuals (\u201cIf an intervention\nsatisfying\n (M1)\u2013(M4)\n on \\(X\\) were to occur,\u2026\u201d) thus arise in a natural way\non this characterization\u2014or at so I will assume in what\nfollows.\n\nPutting aside these issues about possibility for the present, the most\nnatural way of defining the notion of causal effect in the framework\nassociated with\n (M1)\u2013(M4)\n is in terms of the difference made to the value of \\(Y\\) by\na change or difference in the value of \\(X\\). (This is also\neffectively the definition of causal effect adopted in Rubin 1974.\nFocusing on differences in this way allows us to isolate the\ncontribution made to \\(Y\\) by \\(X\\) alone from the contribution made\nto \\(Y\\) by its other causes. Moreover, since in the non-linear case,\nthe change in the value of \\(Y\\) caused by a given change in the value\nof \\(X\\) will depend on the values of the other causes of \\(Y\\), it\nseems to follow that the notion of causal effect must be relativized\nto a background context \\(B_i\\) which incorporates information about\nthese other values. In deterministic contexts, we might thus define\nthe causal effect on \\(Y\\) of a change in the value of \\(X\\) from\n\\(X=x\\) to \\(X=x'\\) in circumstances \\(B_i\\) as:\n\n(CD) \\(Y_{\\do\nx, B_i} - Y_{\\do x', B_i}\\)\n\n\nthat is, as the difference between the value that \\(Y\\) would take\nunder an intervention that sets \\(X=x\\) in circumstances \\(B_i\\) and\nthe value that \\(Y\\) would take under an intervention that sets\n\\(X=x'\\) in \\(B_i\\), where the notion of an intervention is now\nunderstood in terms of\n (M1)\u2013(M4)\n rather than in the way recommended by Pearl. In non-deterministic\ncontexts, the characterization of causal effect is less\nstraightforward, but one natural proposal is to define this notion in\nterms of expectations: If we let \\(E P_{\\do x, B_{i}}(Y)\\) be the\nexpectation of \\(Y\\) with respect to the probability distribution\n\\(P\\) if \\(X\\) is set to \\(X=x\\) by means of an intervention, then the\ncausal effect on \\(Y\\) of a change in \\(X\\) from \\(X=x''\\) to \\(X=x\\)\nmight be defined as: \\(E P_{\\do x, B_{i}}(Y) - E P_{\\do x', B_{i}}\n(Y)\\).\n\nThis Section will not attempt to adjudicate among these and various\nother proposals concerning the best way to characterize the notions of\nintervention and causal effect. Instead, we make the following comment\non the general strategy they embody. Note first that the notion of an\nintervention, when understood along either of the lines described\nabove, is an unambiguously causal notion in the sense that causal\nnotions are required for its characterization\u2014thus the proposals\nvariously speak of an intervention on \\(X\\) as breaking the causal\nconnection between \\(X\\) and its causes while leaving other causal\nmechanisms intact or as not affecting \\(Y\\) via a causal route that\ndoes not go through \\(X\\). This has the immediate consequence that one\ncannot use the notion of an intervention to provide a reduction of\ncausal claims to non-causal claims. Moreover, to the extent that\nreliance on some notion like that of an intervention is unavoidable in\nany satisfactory version of a manipulability theory, any such theory\nmust be non-reductionist. Indeed, we can now see that critics who have\ncharged manipulability theories with circularity have in one important\nsense understated their case: manipulability theories turn out to be\n\u201ccircular\u201d not just in the obvious sense that for an\naction or event \\(I\\) to constitute an intervention on a variable\n\\(X\\), there must be a causal relationship between \\(I\\) and \\(X\\),\nbut in the sense that \\(I\\) must meet a number of other causal\nconditions as well.\n6. Is Circularity a Problem?\n\nSuppose that we agree that any plausible version of a manipulability\ntheory must make use of the notion of an intervention and that this\nmust be characterized in causal terms. Does this sort of\n\u201ccircularity\u201d make any such theory trivial and\nunilluminating? It is arguable that it does not, for at least two\nreasons. First, it may be, as writers like Woodward (2003) contend,\nthat in characterizing what it is for a process \\(I\\) to qualify as an\nintervention on \\(X\\) for the purposes of characterizing what it is\nfor \\(X\\) to cause \\(Y\\), we need not make use of information about\nthe causal relationship, if any, between \\(X\\) and \\(Y\\). Instead, it\nmay be that we need only to make use of other sorts of causal\ninformation, e.g., about the causal relationship between \\(I\\) and\n\\(Y\\) or about whether \\(I\\) is caused by causes that cause \\(Y\\)\nwithout causing \\(X\\), as in\n (M1)\u2013(M4)\n above. To the extent that this is so, we may use one set of claims\nabout causal relationships (e.g., that \\(X\\) has been changed in a way\nthat meets the conditions for an intervention) together with\ncorrelational information (that \\(X\\) and \\(Y\\) remain correlated\nunder this change) to characterize what it is for a different\nrelationship (the relationship between \\(X\\) and \\(Y)\\) to be causal.\nThis does not yield a reduction of causal talk to non-causal talk, but\nit is also not viciously circular in the sense that it presupposes\nthat we already have causal information about the very relationship\nthat we are trying to characterize. One reason for thinking that there\nmust be some way of characterizing the notion of an\nintervention along the lines just described is that we do sometimes\nlearn about causal relationships by performing experiments\u2014and\nit is not easy to see how this is possible if to characterize the\nnotion of an intervention on \\(X\\) we had to make reference to the\ncausal relationship between \\(X\\) and its effects.\n\nA related point is that even if manipulability accounts of causation\nare non-reductive, they can conflict with other accounts of\ncausation, leading to different causal judgments in particular cases.\nAs an illustration consider a simple version of manipulability account\nalong the lines of\n (CD),\n according to which a sufficient condition for \\(X\\) to cause (have a\ncausal effect on \\(Y)\\) is that some change in the value of \\(X\\)\nproduced by an intervention is associated with a change in the value\nof \\(Y\\) (in the background circumstances of interest). Such an\naccount implies that omissions (e.g., the failure of a gardener to\nwater a plant) can be causes (e.g., of the plant\u2019s death) since\na change under an intervention in whether the gardener waters is\nassociated with a change in the value of the variable measuring\nwhether the plant dies. For a similar reason relationships involving\n\u201cdouble prevention\u201d (Hall 2000) or \u201ccausation by\ndisconnection\u201d (Schaffer 2000) count as genuine causal\nrelationships on interventionist accounts. Consider, by contrast, the\nverdicts about these cases reached by a simple version of a causal\nprocess theory (in the sense of Salmon 1984, Dowe 2000) according\nto which a necessary condition for a particular instantiation \\(x\\) of\na value \\(X\\) to cause a particular instantiation \\(y\\) of a value\n\\(Y\\) is that there be a spatio-temporally continuous process\nconnecting \\(x\\) to \\(y\\) involving the transfer of energy, momentum\nor perhaps some other conserved quantity. According to such a theory,\n\u201ccausation\u201d by omission or by double prevention does not\nqualify as genuine causation. Similarly, if an \u201caction at a\ndistance\u201d version of Newtonian gravitational theory had turned\nout to be correct, this would be a theory that described genuine\ncausal relationships according to interventionist accounts of\ncausation, but not according to causal process accounts. Whether one\nregards the verdicts about these cases reached by causal process\naccounts or by interventionist accounts as more defensible, the very\nfact that the accounts lead to inconsistent judgments shows that\ninterventionist approaches are not trivial or vacuous, despite their\n\u201ccircular\u201d, non-reductive character.\n7. The Plurality of Causal Concepts\n\nA second respect in which reliance on the notion of an intervention\nneed not be thought of as introducing a vicious circularity is this:\nSo far, I have been following Menzies and Price in assuming that there\nis just one causal notion or locution \\((A\\) causes \\(B\\), where \\(A\\)\nand \\(B\\) are types of events) that we are trying to analyze. But in\nfact there are many such notions. For example, among causal notions\nbelonging to the family of so-called type causal notions (i.e., causal\nclaims that relate types of events or variables) there is a\ndistinction to be drawn between what we might call claims about total\nor net causes and claims about direct causes. Even if the notion of an\nintervention presupposes some causal notion such as some notion of\ntype causation, it may be that we can use it to characterize other\ncausal notions.\n\nAs an illustration consider the causal structure represented by the\nfollowing equations and associated directed graph\n\n\n\n\\[ \\begin{align*}\nY & = aX + cZ\\\\\n Z & = bX\\\\\n \n\\end{align*} \\]\n\n\n\n\n\n\n\nIn this structure, there are two different causal routes from \\(X\\) to\n\\(Y\\)\u2014a direct causal relationship and an indirect relationship\nwith \\(Z\\) as an intermediate variable. If \\(a = {-bc}\\), there is\ncancellation along these two routes. This means that no intervention\non \\(X\\) will change the value of \\(Y\\). In one natural sense, this\nseems to mean that \\(X\\) does not cause \\(Y\\), assuming that (C*) a\nnecessary condition for \\(X\\) to cause \\(Y\\) is that some\ninterventions on \\(X\\) are associated with changes in the value of\n\\(Y,\\) as an obvious extension of CD seems to suggest. In another\nnatural sense, however, \\(X\\) does seem to be a cause\u2014indeed a\ndirect cause\u2014of \\(Y\\). We can resolve this apparent\ninconsistency by distinguishing between two kinds of causal claims\n(for a related distinction, see Hitchcock 2001b )\u2014the claim\n\\(X\\) is a total or net cause of \\(Y\\), where this is captured by (C*)\nand the claim that \\(X\\) is a direct cause of \\(Y\\), where this is\nunderstood along the following lines: \\(X\\) is a direct cause of \\(Y\\)\nif and only if under some intervention that changes the value of\n\\(X\\), the value of \\(Y\\) changes when all other variables in the\nsystem of interest distinct from \\(X\\) and \\(Y\\) including those that\nare on some causal route from \\(X\\) to \\(Y\\), are held fixed at some\nvalue, also by interventions. (For related, but different,\ncharacterizations of direct causation along these lines, see Pearl\n2009 and Woodward 2003.) Fixing the other values of other variables\nmeans that each of these values is fixed by separate interventions\nthat are independent of each other and of the intervention that\nchanges the value of \\(X\\). The effect of intervening to fix the\nvalues of these variables is thus that each variable intervened on is\ndisconnected from its causes, including \\(X\\). In the example under\ndiscussion, \\(X\\) qualifies as a direct cause of \\(Y\\) because if we\nwere to fix the value of \\(Z\\) in a way that disconnects it from the\nvalue of \\(X\\), and then intervene to change the value of \\(X\\), the\nvalue of \\(Y\\) would change. This idea can then be generalized to\nprovide a characterization of \u201ccontributing\u201d causation\nalong a causal route, i.e., to capture the sense in which \\(X\\) is an\nindirect cause of \\(Y\\) along the route that goes through \\(Z\\)\n(Woodward 2003).\n\nSo far our focus has been on type causal claims of various kinds.\nThere are also a number of proposals in the literature that provide\ninterventionist treatments of token or actual cause claims (these have\nto do with the event of \\(X\\)\u2019s taking on a particular value\nbeing an actual cause of \\(Y\\)\u2019s taking on a particular value,\nas when it is claimed that Jones\u2019 smoking caused his lung\ncancer), including those that involve various forms of pre-emption and\nover-determination (e.g., Halpern and Pearl 2005 a, b; ; Hitchcock\n2001a; Woodward 2003; Hitchcock 2007a; Hall 2007; Glymour and Wimberly\n2007; Halpern and Hitchcock 2015; Halpern 2016; Weslake 2013 [Other\nInternet Resources]). Considerations of space preclude detailed\ndescription, but one strategy that has been explored is to appeal to\nwhat will happen to the effect under combinations of\ninterventions that both affect the cause and that fix certain other\nvariables to specific values. As an illustration, consider a standard\ncase of causal pre-emption: Gunman one shoots \\((s_1)\\) victim,\ncausing his death \\(d\\), while gunman two does not shoot but would\nhave shot \\((s_2)\\) also causing \\(d\\), if \\(s_1\\) had not occurred.\nIf we fix (via an intervention) the behavior of the gunman two at its\nactual value (he does not shoot), then an independent intervention\nthat alters whether gunman one shoots will alter whether victim dies,\nthus identifying \\(s_1\\) as the actual cause of \\(d\\), despite the\nabsence of counterfactual dependence (of the usual sort) between \\(d\\)\nand \\(s_1\\). Accounts along these lines are able to deal with a number\n(although admittedly not all; see Hitchcock 2007a for details) of the\nstandard counterexamples to other counterfactual treatments of token\ncausation.\n\nIt is worth adding that although this appeal to combinations of\ninterventions may seem artificial, it maps on to standard experimental\nprocedures in an intuitive way. Consider a case of genetic\nredundancy\u2014gene complex \\(G_1\\) is involved in causing\nphenotypic trait \\(P\\) but if \\(G_1\\) is inactivated another gene\ncomplex \\(G_2\\) (which is inactive when \\(G_1\\) is active) will become\nactive and will cause \\(P\\). The geneticist may test for this\npossibility by, first, intervening on \\(G_2\\) so that it is fixed at\nthe value = inactive, then intervening to vary \\(G_1\\) and observing\nwhether there is a corresponding change in \\(P\\). Second, the\ninvestigator may intervene to render \\(G_1\\) inactive and then,\nindependently of this intervening to change \\(G_2\\) and observing\nwhether there is a change in \\(P\\). As this example illustrates, we\nmay think of different complex causal structures in which there are\nmultiple pathways, redundancy, cancellation and so on, as encoding\ndifferent sets of claims about what will happen under various possible\ncombinations of interventions.\n\nThus even if a \u201cmanipulationist\u201d or\n\u201cinterventionist\u201d framework does not yield a reduction of\ncausal talk to non-causal talk, it provides a natural way of marking\nthe distinctions among a number of different causal notions and\nexhibiting their interrelations. More generally, even if a\nmanipulationist account of causation does not yield a reduction but\ninstead simply connects \u201ccausation\u201d (or better, various\nmore specific causal concepts) with other concepts within the same\ncircle, we still face many non-trivial choices about how the concepts\non this circle are to be elucidated and connected up with one another.\nFor example, it is far from obvious how to characterize the notion of\nan intervention so as to avoid the various counterexamples to a\nversion of the manipulability theory like that of Menzies and Price.\nIt is in part because the notion of manipulation/intervention has an\ninteresting and complex fine structure\u2014a structure that is left\nlargely unexplored in traditional manipulability theories-- that\nworking out the connection between causation and manipulation turns\nout to be interesting and non-trivial rather than banal and\nobvious.\n8. Interventions That Do Not Involve Human Action\n\nWe noted above that a free action need not meet the conditions for an\nintervention, on any of the conceptions of intervention described in\n \u00a75.\n It is also true that a process or event can qualify as an\nintervention even if it does not involve human action or intention at\nany point. This should be apparent from the way in which the notion of\nan intervention has been characterized, for this is entirely in terms\nof causal and correlational concepts and makes no reference to human\nbeings or their activities. In other words, a purely\n\u201cnatural\u201d process involving no animate beings at all can\nqualify as an intervention as long as it has the right sort of causal\nhistory\u2014indeed, this sort of possibility is often described by\nscientists as a \u201cnatural experiment\u201d. Moreover, even when\nmanipulations are carried out by human beings, it is the causal\nfeatures of those manipulations and not the fact that they are carried\nout by human beings or are free or are attended by a special\nexperience of agency that matters for recognizing and characterizing\ncausal relationships. Thus, by giving up any attempt at reduction and\ncharacterizing the notion of an intervention in causal terms, an\n\u201cinterventionist\u201d approach of the sort described under\n \u00a7\u00a74\u20135\n and\n 7\n avoids the second classical problem besetting manipulability\ntheories\u2014that of anthropocentrism and commitment to a privileged\nstatus for human action. For example, under this approach \\(X\\) will\nqualify as a (total) cause of \\(Y\\) as long as it is true that for\nsome value of \\(X\\) that if \\(X\\) were to be changed to that value by\na process having the right sort of causal characteristics, the value\nof \\(Y\\) would change. Obviously, this claim can be true even if human\nbeings lack the power to manipulate \\(X\\) or even in a world in which\nhuman beings do not or could not exist. There is nothing in the\ninterventionist version of a manipulability theory that commits us to\nthe view that all causal claims are in some way dependent for their\ntruth on the existence of human beings or involve a\n\u201cprojection\u201d on to the world of our experience of\nagency.\n9. Interventions and Counterfactuals\n\nWe noted above that interventionist versions of manipulability\ntheories are counterfactual theories. What is the relationship between\nsuch theories and more familiar versions of counterfactual theories\nsuch as the theory of David Lewis? Lewis\u2019 theory is an account\nof what it is for one individual token event to cause another while,\nas explained above, versions of interventionist treatments are\navailable for different sorts of type causal claims as well as token\ncausal claims. But if we abstract away from this, there are both\nimportant similarities and important differences between the two\napproaches. As readers of Lewis will be aware, any counterfactual\ntheory must explain what we should envision as changed and what should\nbe held fixed when we evaluate a counterfactual the antecedent of\nwhich is not true of the actual world\u2014within Lewis\u2019\nframework, this is the issue of which worlds in which the antecedent\nof the counterfactual holds are \u201cclosest\u201d or \u201cmost\nsimilar\u201d to the actual world. Lewis\u2019 answer to this\nquestion invokes a \u201csimilarity\u201d ordering that ranks the\nimportance of various respects of resemblance between worlds in\nassessing overall similarity. (Lewis 1979). For example, avoiding\ndiverse, widespread violations of law is said to be the most important\nconsideration, preserving perfect match of particular fact over the\nlargest possible spatio-temporal region is next in importance and more\nimportant than avoiding small localized violations of law, and so on.\nAs is well-known the effect of this similarity ordering is, at least\nin most situations, to rule out so-called \u201cback-tracking\u201d\ncounterfactuals (e.g., the sort of counterfactual that is involved in\nreasoning that if the effect of some cause had not occurred, then the\ncause would not have occurred). When the antecedent of a\ncounterfactual is not true of the actual world, Lewis\u2019\nsimilarity metric commonly leads us (at least in deterministic\ncontexts) to think of that antecedent as made true by a\n\u201csmall\u201d miracle.\n\nThe notion of an intervention plays a somewhat (but only somewhat)\nsimilar role within manipulability theories of causation to\nLewis\u2019 similarity ordering. Like Lewis\u2019 ordering, the\ncharacterization of an intervention tells us what should be envisioned\nas changed and what should be held fixed when we evaluate the sorts of\ncounterfactuals that are relevant to elucidating causal claims. For\nexample, on Pearl\u2019s understanding of an intervention, in\nevaluating an interventionist counterfactual like \u201cIf \\(X\\) were\nto be set by an intervention to such and such a value, the value of\n\\(Y\\) would be so and so\u201d, we are to consider a situation in\nwhich the previously existing causal relationship between \\(X\\) and\nits causes is disrupted, but all other causal relationships in the\nsystem of interest are left unchanged. A moment\u2019s thought will\nalso show that, as in Lewis\u2019 account, both Pearl\u2019s (in its\nsetting version) and the characterization of interventions in terms of\n M1\u2013M4\n rule out backtracking counterfactuals\u2014for example, in\nevaluating a counterfactual of the form \u201cif an intervention were\nto occur that changes \\(E\\), (where \\(E\\) is an effect of \\(C)\\), then\n\\(C\\) would change\u201d, Pearl holds that we should consider a\nsituation in which the relationship between \\(E\\) and its causes (in\nthis case, \\(C)\\) is disrupted, but all other causal relationships are\nleft unchanged, so that \\(C\\) still occurs, and the above\ncounterfactual is false, as it should be. Moreover, there is a clear\nsimilarity between Lewis\u2019 idea that the appropriate\ncounterfactuals for analyzing causation are often counterfactuals the\nantecedents of which are made true by \u201cmiracles\u201d, and the\nidea of an intervention as an exogenous change that disrupts the\nmechanism that was previously responsible for the cause event\nC\u2014both of these notions function so as to provide \\(C\\)\nwith the kind of \u201cindependent causal history\u201d (recall\nMenzies and Price) that allows us to distinguish the effects (if any)\nof \\(C\\) on \\(E\\) from the effects of other \u201cconfounding\u201d\nvariables on \\(E\\). From this perspective, one might think of an\ninterventionist treatment of causation as explaining why Lewis\u2019\naccount, with its somewhat ad hoc looking similarity\nordering, works as well as it does\u2014Lewis\u2019 account works\nbecause his similarity ordering picks out roughly those relationships\nthat are stable under interventions and hence exploitable for purposes\nof manipulation and control and, as a manipulability theory claims, it\nis just these relationships that are causal.\n\nAs noted above, however, this is not to say that the two\napproaches are identical or always yield identical assessments of\nparticular causal and counterfactual claims. One central difference is\nthat Lewis\u2019 account is reductionist in aspiration\u2014the\nelements that go into his similarity metric (avoidance of big\nmiracles, perfect match of particular facts etc.) are (at least\nofficially) characterized in non-causal, non-modal terms. By contrast,\nas explained above, the notion of an intervention and the standards\nfor evaluating counterfactuals to which it gives rise are\ncharacterized in causal terms, so that the resulting account is\nnon-reductionist.\n\nThere are other differences as well, a number of which are explored in\nan important paper by Briggs (2012). We have already noted that strong\ncentering holds in Lewis\u2019 semantics but not for counterfactuals\nwith an interventionist interpretation. In addition, the inference\nfrom (i) \u201cif \\(p\\) or \\(q\\) were the case, \\(r\\) would be the\ncase\u201d to (ii) \u201cif \\(p\\) were the case, \\(r\\) would be the\ncase\u201d is invalid within Lewis\u2019 semantics but valid if\nthese counterfactuals are given an interventionist interpretation\n(Briggs 2012; Fine 2012). Very roughly this is because within an\ninterventionist framework, (i) is interpreted as claiming that for any\nrealization of its antedent-- either p or q--\nr will follow. It is arguable that in each of these cases,\nthe assessments provided by the interventionist interpretation are\ncorrect, assuming that what we want to capture are those\ncounterfactuals that behave in a way that is appropriate for causal\ninterpretation. In addition, Woodward 2003 describes several specific\nexamples in which the two approaches diverge in their judgments about\nwhich causal relations are present and in which the interventionist\napproach seems more\n satisfactory.[3]\n10. Possible and Impossible Interventions\n\nIn the versions of a manipulability theory considered under\n \u00a75ff\n above, causal claims are elucidated in terms of counterfactuals about\nwhat would happen under interventions. As we have seen, the notion of\nan intervention should be understood without reference to human\naction, and this permits formulation of a manipulability theory that\napplies to causal claims in situations in which manipulation by human\nbeings is not a practical possibility.\n\nHowever, as already intimated, interesting questions arise about how\nfar this framework may be extended to other sorts of cases in which\ninterventions are not \u201cpossible\u201d. These also illustrate\nsome additional differences between thinking of interventions as\nsetting or, alternatively, in terms of\n M1\u2013M4\n and as possibility constrained. Consider the (presumably true) causal\nclaim\n (G):\n\n(G) The\ngravitational attraction of the moon causes the motion of the\ntides.\n\n\nWithin Pearl\u2019s framework and using the notion of a setting\nintervention, it might be argued that there is no problem with\ncapturing claims like (G), at least if we assume (as we did above)\nthat the relevant setting operation is always \u201cpossible\u201d\nor legitimate: we just imagine the gravitational attraction of the\nmoon set to some different value via a setting intervention (we\ndon\u2019t need to specify how this comes about\u2014whether the\nmass of the moon or its distance from the earth etc. is different) and\nthen note (by applying Newtonian gravitational theory) that the motion\nof the tides would be\n different.[4]\n\nSuppose, by contrast, we require that interventions be\n\u201cpossible\u201d in some more demanding sense (that is, we adopt\na notion of possibility constrained intervention) and we consider\ncounterfactuals of the form: \u201cif an intervention meeting\n M1\u2013M4\n were to occur that sets the gravitational attraction of the moon to a\ndifferent value, then\u2026\u201d. It may well be that there is no\nphysically possible process that will meet the conditions\n M1\u2013M4\n for intervention on the moon\u2019s position with respect to the\ntides\u2014all possible processes that would alter the gravitational\nforce exerted by the moon may be insufficiently\n\u201csurgical\u201d. For example, it may very well be that any\npossible process that alters the position of the moon by altering the\nposition of some other massive object will have an independent impact\non the tides in violation of condition\n (M2)\n for an intervention. Woodward (2003) argues that nonetheless we have\na principled basis in Newtonian mechanics and gravitational theory\nthemselves for answering questions about what would happen if such a\nsurgical intervention were to occur and that this is enough to\nvindicate the causal claim\n (G).\n On this view of the matter, what is crucial is not whether the\nantecedent of the relevant counterfactual is nomologically or\nphysically possible but rather whether we are in possession of\nwell-grounded scientific theories and accompanying mathematics that\nallow us to reliably answer questions about what would happen under\nthe supposition of such antecedents. We count interventions as\n\u201cpossible\u201d as long as this is the case. Such interventions\nshould be distinguished from interventions that are logically,\nconceptually or mathematically inconsistent or incoherent (see below\nfor additional illustrations).\n11. The Scope of Interventionist Accounts\n\nOne context in which issues about the range of cases in which\ninterventionist account may be legitimately or fruitfully applied\nconcerns \u201ccosmological\u201d claims in which fundamental\nphysical theories are understood as applying to the whole universe.\nConsider the following claim\n\n(4) The\nstate \\(S_t\\) of the entire universe at time \\(t\\) causes the state\n\\(S_{t +d}\\) of the entire universe at time \\(t+d\\), where \\(S_t\\) and\n\\(S_{t+d}\\) are specifications in terms of some fundamental physical\ntheory.\n\n\nOn an interventionist construal,\n (4)\n is unpacked as a claim to the effect that under some possible\nintervention that changes \\(S_t\\), there would be an associated change\nin \\(S_{t+d}\\). This raises the worry that it is unclear what would be\ninvolved in such an intervention (given that there is nothing in\naddition to \\(S_t\\) that might realize the intervention) and unclear\nhow to assess what would happen if it were to occur, given the\nstipulation that \\(S_t\\) is a specification of the entire state of the\nuniverse.\n\nCommenting on an example like this, Pearl writes:\n\n\nIf you wish to include the whole universe in the model, causality\ndisappears because interventions disappear\u2014the manipulator and\nthe manipulated lose their distinction. (2009: 419-20)\n\n\nNote that here Pearl seems to invoke a notion of intervention that is\ndifferent from (and stronger than) a pure setting conception. After\nall, as Reutlinger (2012) notes, it is arguable that there is no\nproblem about imagining the state of the universe at \\(S_t\\) set to\nsome different value and then determining by reference to the laws\ngoverning its evolution what its state will be at \\(S_{t\n +1}\\).[5]\n Pearl\u2019s remark seems to assume that the imagined intervention\nhas to meet some additional constraint beyond this (having to do in\nsome way with the possibility of realizing the intervention).\nPearl\u2019s claim is controversial\u2014it is discussed\nsympathetically by Hitchcock 2007b and Woodward 2007 and criticized by\nother writers such as Reutlinger 2012.\n\nWe will not try to resolve the issues surrounding this particular\nclaim of Pearl\u2019s here, but there is a related and more general\nissue concerning the implications of interventionism for the status of\ncausal claims in physics, even outside of cosmological contexts, that\ndeserves discussion. Return to the contrast between explicating causal\nclaims by appealing to a pure setting notion of intervention and,\nalternatively, explicating them by reference to interventions that\nmeet some further non-trivial constraints regarding possibility, as\ndiscussed above. Consider cases in which there is a physical law\naccording to which there is counterfactual dependence between \\(Y\\)\nand \\(X\\) but interventions on \\(X\\) are in some appropriately\nrelevant sense impossible. A pure setting treatment may conclude that\nsuch relationships are causal while an account relying on a\npossibility constrained notion of intervention will not.\n\nTwo possible illustrations are discussed in Woodward (2016). The field\nequations of General Relativity describe a lawful or nomological\nrelationship between the stress energy tensor and the spacetime\nmetric. \u201cSetting\u201d the former to different values (by\nspecifying initial and boundary conditions) one may calculate the\nassociated different values of the latter. One may doubt, however,\nthat it is appropriate to think of the field equations as describing a\ncausal relationship between the stress-energy tensor and the\nmetric. It is arguable that a possibility constrained interventionist\naccount supports this judgment: specification of the stress energy\ntensor requires reference to the metric in such a way that\ninterventions on the former with respect to the latter will violate\nthe conditions\n M1\u2013M4\n for an intervention. One might conclude on these grounds that\nalthough there is a relation of nomic dependence between the state of\nthe stress energy tensor and the metric, this relation is not causal.\nEmployment of a setting conception of intervention seems to realize\nthe opposite conclusion.\n\nAs a second example, the spins of the entangled particles in an\nEPR\u2013type experiment are lawfully related by a conservation law.\nIt is arguable (cf. Skyrms 1984; Butterfield 1992) that many standard\nphilosophical theories, including regularity and Lewis-style\ncounterfactual theories treat this relationship as causal, and a\nsetting version of an interventionist theory seems to suggest a\nsimilar conclusion. By contrast, various no signaling theorems are\ncommonly interpreted as implying that it is impossible both to\nintervene on one of the separated spin settings and to use the\nrelationship between the two settings to manipulate the other setting.\nIn this case a possibility constrained version of interventionism can\njudge that no causal relationship is present. Although the matter is\ncontroversial among philosophers, most physicists agree with this\njudgment of non-causality.\n\nBoth of these examples illustrate different implications of setting\nand possibility constrained versions of interventionism in physics\ncontexts and how the latter framework requires more than just the\npresence of a nomically sufficient condition or law-based\ncounterfactual dependence for causation. More generally, if one\nthinks, as many philosophers of physics and some physicists do, that\ncausal concepts do not apply, at least in any straightforward way, to\nsome or many fundamental physics contexts, then it is arguably a\nconsideration in favor of a version of interventionism that imposes a\nnon-trivial possibility constraint that it might be used to support\nthis judgment. By contrast, a setting version of interventionism will\ntend to find causation in physics whenever there is nomic\ndependence.\n\nThere has been considerable discussion recently both about the extent\nto which fundamental physics is causal and about what interventionist\nframeworks imply about the status of causal claims in physics. A\nnumber of the essays in Price and Corry 2007 (Price 2007; Hitchcock\n2007b; Woodward 2007) express varying degrees of skepticism about the\napplicability of causal notions in portions of physics, in part on the\nbasis of interventionist considerations. By contrast, Frisch (2014)\nargues vigorously that many physical theories, at least in classical\nphysics, such as classical electromagnetism, make extensive use of\ncausal concepts and that the relevant notion of cause is captured by\nthe interventionist framework and associated technical ideas (such as\nstructural equations and directed graphs). He suggests that writers\nlike Price, Hitchcock, and Woodward (in his 2007 but see his 2016 for\na more nuanced view) underestimate the degree to which interventionist\nideas of causation are applicable to such contexts. Of course it is\nalso possible, consistently, with the views of both Frisch and these\nother writers, that causal notions, understood along possibility\nconstrained interventionist lines, are important in many areas of\nphysics but that there are other physical theories that are not\nfruitfully interpreted as making causal claims, whether understood\nalong interventionist or other lines. In any case, the question of the\nscope of interventionist theories and their implications for causal\nclaims in fundamental physics is an important and at present\nunresolved\n issue.[6]\n12. (Alleged) Causes That Are Unmanipulable for Logical, Conceptual, or Metaphysical Reasons\n\nSeveral statisticians (e.g., Holland 1986; Rubin 1986), as well as\nsimilarly minded epidemiologists (e.g., Hernan and Taubman 2008) who\nadvocate treatments of causation in terms of manipulation-based ideas\n(in this case in terms of \u201cpotential outcome\u201d theory) have\nheld that causal claims involving causes that are unmanipulable in\nprinciple are defective or lack a clear meaning\u2014they think of\nthis conclusion as following directly from a manipulationist approach\nto causation. What is meant by an unmanipulable cause is not made very\nclear, but what these authors have in mind are not candidate causes\nthat cannot be manipulated as a practical matter, but rather\ncandidates that are such that we lack any clear conception of what\nwould be involved in manipulating them or any basis for assessing what\nwould happen under such manipulations\u2014cases in which\nmanipulation seems \u201cimpossible\u201d for conceptual or (if you\nlike) \u201cmetaphysical\u201d reasons. Proposed examples include\nsuch candidate causes as race, membership in a particular species, and\ngender. Other examples discussed in this connection involve cases in\nwhich there are many different things one might have in mind by\n\u201cmanipulation\u201d of the candidate causes with different\nresults flowing from alternative understandings of\n\u201cmanipulation\u201d so that the claims in question are taken,\nfrom a manipulationist or interventionist standpoint, to be unclear or\nambiguous. All such cases contrast with the case involving\n (G)\n above, where the notion of manipulating the moon\u2019s orbit seems\nperfectly clear and well-defined, and the problem is simply that the\nworld happens to be arranged in such a way that an intervention that\nproduces such a change is not physically possible.\n\nA sympathetic reconstruction of the position under discussion might go\nas follows. On an interventionist account of causation, causes\n(whether we think of them as events, types of events, properties,\nfacts, or what have you) must be representable by means of\nvariables\u2014where this means, at a minimum, that it must\nbe possible for the cause to change or to assume different values, for\nwhatever object, unit or system those values are assigned to, as when\nit is possible for the same particle to be either at position \\(p_1\\)\nspecified by a position variable \\(P\\) or at some alternative position\n\\(p_2\\). This is required if we are to have a well-defined notion of\nmanipulating a candidate cause and well-defined answers to\ncounterfactual queries about what would happen if the cause were to be\nmanipulated in some way\u2014matters which are central to what causal\nclaims mean on any version of a manipulability theory worthy of the\nname. However, for some putative causes, there may be no well-defined\nnotion of change or variation in value and if so, a manipulability\ntheory will not count these as genuine causes. Suppose, for example,\nwe lack any coherent conception of what it is for something to exist\nbut to be non-physical. Then there will be no well-defined notion of\nintervening to change whether something is or is not a physical object\nand being a physical object will not be a factor or property that can\nserve as a cause. (Of course it is consistent with this that there are\ntrue and perhaps even lawful generalizations about all physical\nobjects.) For example, although to the best of our knowledge, it is a\nlaw of nature that\n\n(L) no physical object\ncan be accelerated from a velocity less than that of light to a\nvelocity greater than light,\n\n\n(L) is not, according to this version of a manipulability theory, a\ncausal generalization: being a physical object is not a cause\nof the incapacity in question.\n\nMoreover, even with respect to variables that can take more than one\nvalue, the notion of an intervention or manipulation will not be\nwell-defined if there is no well-defined notion of changing\nthe values of that variable. Suppose that we introduce a variable\n\u201canimal\u201d which takes the values \\(\\{\\)lizard, kitten,\nraven\\(\\}\\). By construction, this variable has more than one value,\nbut if, as seems plausible, we have no coherent idea of what it is to\nchange a raven into lizard or kitten, there will be no well-defined\nnotion of an intervention for this variable and being an animal (or\nbeing a raven) will not be the sort of thing that can count as a\nbona fide cause on a manipulability theory. The notion of\nchanging the value of a variable seems to involve the idea of an\nalteration from one value of the variable to another in circumstances\nin which the very same system or entity can possess both values and\nthis notion seems inapplicable to the case under discussion.\n\nNote that, just as with some of the examples considered in\n \u00a712,\n this conclusion does not seem to follow on the pure setting\ninterpretation of the interventionist account. One can, after all, set\nup an equation \\(Y = X\\) with a candidate variable \\(X\\), taking the\nvalues 0 and 1, according to whether some object is a kitten or lizard\nand a candidate effect variable \\(Y\\), taking the values 0 and 1\naccording to whether that object is warm-blooded or cold-blooded. Then\nsetting \\(X\\) to 0 rather than 1 changes whether \\(Y= 0\\) or 1, and if\nthis is sufficient for causation, being a kitten rather than a lizard\ncauses warmbloodiness rather than coldbloodiness. If one thinks, that\nthere is something defective or problematic about these causal claims,\nthis requires, within an interventionist framework, a richer\nconception of what is required for causation than what is suggested by\nthe setting conception of intervention. A similar point applies to the\nother examples described in this section.\n\nSome readers will take it to be intuitively obvious that, e.g., being\na raven can be a cause of some particular organism\u2019s being\nblack, that being a kitten can be a cause of warm-bloodiness and so\non. If causal claims like\n\n(R) \u201cRaveness\ncauses blackness\u201d \n\n\nare true, it will be an important advantage of a setting version of\ninterventionism over a formulation in terms of a possibility\nconstrained notion of intervention that the former but not the latter\nis able to capture claims like (R). By contrast, others will think\nthat claims like (R) are, if not false, at least unclear and\nunperspicuous, and that it is a point in favor of a possibility\nconstrained version of the interventionist account that it can capture\nthis. Those who take this second view will think that claims like (R)\nshould be replaced by claims that involve causes that are\nstraightforwardly manipulable. For example, (R) might be replaced by a\nclaim that identified the genetic factors and biochemical pathways\nthat are responsible for raven pigmentation\u2014factors and pathways\nfor which there is a well-defined notion of manipulation and which are\nsuch that if they were appropriately manipulated, this would lead to\nchanges in pigmentation. Theorists like Rubin and Holland will think\nthat such a replacement would be clearer and more perspicuous than the\noriginal claim (R). Another illustration of this general idea that\nreplacing claims involving non-manipulable candidate causes with\nclaims involving candidate manipulable causes clarifies their meaning\nis discussed in\n The Role of the Manipulability Theory in Clarifying Causal Claims.\n13. Some Criticisms of Interventionist Accounts\n\nA number of other criticisms besides the classic charges of\nanthropomorphism and circularity have been advanced against\ninterventionist accounts. One complaint is that interventionist\naccounts (at least as I have formulated them) appeal to\ncounterfactuals and that counterfactuals cannot be (as it is often\nput) \u201cbarely true\u201d: if a counterfactual is true, this must\nbe so in virtue of some \u201ctruth maker\u201d which is not itself\nmodal or counterfactual. Standard candidates for such truth makers are\nfundamental laws of nature or perhaps fundamental physical/chemical\nprocesses or mechanisms. Often the further suggestion is made that we\ncan then explain the notion of causation in terms of such truth makers\nrather than along interventionist lines\u2014for example, the notion\nof causation (as well as the truth conditions for counterfactuals)\nmight be explained in terms of laws (Hiddleston 2005). Thus appealing\nto interventionist counterfactuals is not necessary, once we take\naccount of the truth conditions of such counterfactuals.\n\nThese claims raise a number of issues that can be explored only\nbriefly. First, let us distinguish between providing an ordinary\nscientific explanation for why some counterfactual claim is true and\nproviding truth conditions (or identifying a truth maker) in the sense\ndescribed above, where these truth conditions are specified in\nnon-modal, non-counterfactual terms. The expectation that (i) whenever\nsome macro-level interventionist counterfactual is true, there will be\nsome more fundamental scientific explanation of why it is true seems\nplausible and well grounded in scientific practice. By contrast, the\nexpectation that (ii) for every true counterfactual there must be a\ntruth maker that can be characterized in non-modal, non-counterfactual\nterms is a metaphysical doctrine that requires some independent\nargument; it does not follow just from (i). Suppose that it is true\nthat\n\n(5) if\nsubjects with disease \\(D\\) were to be assigned treatment via an\nintervention with drug \\(G\\), they would be more likely to recover.\n\n\n\nThen it is very plausible that there will be some explanation, which\nmay or may not be known at present, that explains why\n (5)\n is true in terms of more fundamental biochemical mechanisms or\nphysical/chemical laws and various initial and boundary conditions.\nWhat is less obviously correct is the further idea that we can\nelucidate these underlying mechanisms/laws without appealing to\ncounterfactuals. It is this further idea that is appealed to when it\nis claimed that it must be possible to describe a truth maker for a\ncounterfactual like\n (5)\n that does not itself appeal to counterfactual or modal claims. The\ncorrectness of this idea is not guaranteed merely by the existence of\nan explanation in the ordinary sense for why\n (5)\n is true; instead it seems to depend on whether a reductivist account\nof laws, mechanisms, etc. in terms of non-modal primitives can be\ngiven\u2014a matter on which the jury is still\n out.[7]\n\nA different line of criticism has been advanced against\ninterventionist accounts in several recent papers by Nancy Cartwright\n(e.g., 2001, 2002). According to Cartwright such accounts are\n\u201coperationalist\u201d. Classical operationalism is often\ncriticized as singling out just one possible procedure for testing\nsome claim of interest and contending that the claim only makes sense\nor only has a truth value when that procedure can actually be carried\nout. Similarly, Cartwright complains that the interventionist account\n\u201coverlooks the possibility of devising other methods for\nmeasuring\u201d causal relationships and also suggests that the\naccount leads us to\n\n\nwithhold the concept [of cause] from situations that seem the same in\nall other aspects relevant to its application just because our test\ncannot be applied in those situations. (2002: 422)\n\n\nIf interventionism is formulated as above, this criticism seems\nmisplaced. The interventionist account does not hold that causal\nconcepts apply or make sense only when the appropriate interventions\ncan actually be carried out. Nor does it deny that there are other\nways of testing causal claims besides carrying out interventions.\nInstead, interventionism holds that causal claims apply or have truth\nvalues whenever the appropriate counterfactuals concerning what would\nhappen if interventions were to be performed have truth values. As\nexplained above, interventionists think that sometimes such\ncounterfactuals are true even if the interventions in question cannot\nactually be performed. Similarly, interventionists can readily agree\nthat causal claims may be tested and confirmed by, for example, purely\nobservational data, not involving interventions or\nmanipulations\u2014their view, though, is that what is confirmed in\nthis way is a claim about what would happen if certain interventions\nwere to be performed. In fact, thinking of causal claims in this way\nhelps to clarify why certain strategies for causal inference with\nobservational data, such as the use of instrumental variables, are\nmore likely to lead to reliable conclusions than alternatives\n(Woodward 2015).\n\nIn a related criticism, Cartwright contends that the interventionist\naccount is \u201cmonolithic\u201d: it takes just one of the criteria\ncommonly thought to be relevant to whether a relationship is\ncausal\u2014whether it is potentially exploitable for purposes of\nmanipulation\u2014and gives it a privileged or pre-eminent place,\nallowing it to trump other criteria (like spatio-temporal contiguity\nor transmission of energy-momentum), when it comes into conflict with\nthem. By contrast, Cartwright favors a \u201cpluralistic\u201d\naccount, according to which a variety of diverse criteria are relevant\nto whether a relationship is causal and which of these are most\nappropriate or important will depend on the causal claim at issue.\n\nThe interventionist account is indeed mono-criterial. Whether this\nfeature is objectionable depends on whether there are realistic cases\nin which (i) intervention-based criteria and criteria based on other\nconsiderations come into conflict and (ii) it is clear that\nthe causal judgments supported by these other criteria are more\ndefensible than those supported by interventionist criteria.\nCartwright does not present any uncontroversial cases of this kind. We\nhave seen that interventionist accounts and accounts that take, e.g.,\nspatio-temporal continuity to be crucial for causation do yield\nconflicting judgments in some realistic cases (e.g., those involving\ndouble prevention), but it is far from clear that the interventionist\naccount is mistaken in the judgments that it recommends about such\ncases.\n\nTwo still more recent criticisms directed against\n M1\u2013M4\n and possibility constrained notions of interventionism are Reutlinger\n2012 and Glynn 2013. These are discussed in the supplementary document\n Additional Recent Criticisms of the Interventionist Account.\n14. Some Recent Positive Developments.\n\nThe material above has largely focused on the use of interventionist\nor manipulability based ideas to provide an interpretation of causal\nclaims, with little attention paid to the use of these ideas in causal\ninference\u2014that is, inference to causal relationships from\nexperimental and non-experimental data. The latter is an important\nsubject in its own right. Roughly speaking, if one thinks of causal\nclaims as claims about the outcomes of possible manipulations or\nexperiments, then this suggests distinctive ways of conceptualizing\nproblems of causal inference from non-experimental data: these may be\nconceptualized as problems of inferring from such data (and other\nassumptions) what the outcome of a possible experiment would be\nwithout doing the experiment in question. This point of view can used\nto motivate or rationalize the use of such procedures as instrumental\nvariables or regression discontinuity designs\u2014see, e.g., Angrist\nand Pischke 2009 for econometric applications of these ideas.\n\nAnother important extension of interventionist ideas, also with a\nfocus on inference but containing conceptual innovations as well is\ndue to Eberhardt (Eberhardt 2007, Eberhardt and Scheines 2007). These\nauthors generalize the notion of intervention in two ways. First, they\nconsider interventions that do not deterministically fix the value of\nvariable(s) intervened on but rather merely impose a probability\ndistribution on those variables. Second, they explore the use of what\nhave come to be called \u201csoft\u201d interventions. These are\ninterventions that unlike the fully surgical (\u201chard\u201d)\ninterventions considered above (both Pearl\u2019s setting\ninterventions and the notion associated with\n M1\u2013M4),\n do not completely break the previously existing relationships between\nthe variable \\(X\\) intervened on and its causes \\(C\\) but rather\nsupply an exogenous source \\(I\\) of variation to \\(X\\) that leaves its\nrelations to \\(C\\) intact but where \\(I\\) is uncorrelated with \\(C\\).\nCertain experiments are naturally modeled in this way. For example, in\nan experiment in which subjects are randomly given various amounts of\nadditional income (besides whatever income they have from other\nsources) this additional income functions as a soft, rather than a\nhard intervention. Soft interventions may be possible in practice or\nin principle in certain situations in which hard interventions are\nnot. Eberhardt 2007 and Eberhardt and Scheines 2007 explore what can\nbe learned from various combinations of soft and hard, indeterministic\nand deterministic interventions together with non-experimental data in\nvarious contexts. Unsurprisingly each kind of intervention and\nassociated data have both advantages and limitations from the point of\nview of inference.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Angrist, Joshua D. and J\u00f6rn-Steffen Pischke, 2009,\n\u201cMostly Harmless Econometrics\u201d, Princeton: Princeton\nUniversity Press.",
                "Butterfield, Jeremy, 1992, \u201cDavid Lewis Meets John\nBell\u201d, <em>Philosophy of Science</em>, 59(1): 26\u201343.\ndoi:10.1086/289652",
                "Briggs, Rachel, 2012, \u201cInterventionist\nCounterfactuals\u201d, <em>Philosophical Studies</em>, 160(1):\n139\u2013166. doi:10.1007/s11098-012-9908-5",
                "Cartwright, Nancy, 2001, \u201cModularity: It Can\u2014and\nGenerally Does\u2014Fail\u201d, in Maria Carla Galavotti, Patrick\nSuppes, and Domenico Constantini (eds.) <em>Stochastic Causality</em>,\nStanford: CSLI Publications.",
                "\u2013\u2013\u2013, 2002, \u201cAgainst Modularity, the Causal\nMarkov Condition, and Any Link Between the Two: Comments on Hausman\nand Woodward\u201d, <em>British Journal for the Philosophy of\nScience</em>, 53(3): 411\u201353. doi:10.1093/bjps/53.3.411",
                "\u2013\u2013\u2013, 2003, \u201cTwo Theorems on Invariance and\nCausality\u201d, <em>Philosophy of Science</em>, 70(1): 203\u201324.\ndoi:10.1086/367876",
                "Collingwood, R.G., 1940, <em>An Essay on Metaphysics</em>, Oxford:\nClarendon Press.",
                "Cook, Thomas D. and Donald T. Campbell, 1979,\n<em>Quasi-Experimentation: Design and Analysis Issues for Field\nSettings</em>, Boston: Houghton Miflin Company.",
                "Dowe, Phil, 2000, <em>Physical Causation</em>, Cambridge:\nCambridge University Press.",
                "Eberhardt, Frederick, 2007, <em>Causation and Intervention</em>,\n(Ph.D. Thesis), Carnegie Mellon University.\n [<a href=\"http://people.hss.caltech.edu/~fde/papers/PhDthesis.pdf\" target=\"other\">Eberhardt 2007 available online</a>]",
                "Eberhardt, Frederick and Richard Scheines, 2007,\n\u201cInterventions and Causal Inference\u201d, <em>Philosophy of\nScience</em>, 74(5): 981\u2013995. doi:10.1086/525638",
                "Fine, Kit, 2012, \u201cCounterfactuals Without Possible\nWorlds\u201d, <em>Journal of Philosophy</em>, 109(3): 221\u2013246.\ndoi:10.5840/jphil201210938",
                "Frisch, Mathias, 2014, <em>Causal Reasoning in Physics</em>,\nCambridge: Cambridge University Press.",
                "Gasking, Douglas, 1955, \u201cCausation and Recipes\u201d,\n<em>Mind</em>, 64(256): 479\u2013487.",
                "Glymour, Clark and Frank Wimberly, 2007, \u201cActual Causation\nand Thought Experiments\u201d, in Joseph Keim Campbell, Michael\nO\u2019Rourke, and Harry S. Silverstein (eds.) <em>Causation and\nExplanation</em>, Cambridge, MA: MIT Press, pp 43\u201367.",
                "Glynn, Luke, 2013, \u201cOf Miracles and Interventions\u201d,\n<em>Erkenntnis</em>, 78 (Supplement 1): 43\u201364.\ndoi:10.1007/s10670-013-9436-5",
                "Haavelmo, Trygve, 1944, \u201cThe Probability Approach in\nEconometrics\u201d, <em>Econometrica</em>, 12 (Supplement), pp.\niii\u2013vi, 1\u2013115. doi:10.2307/1906935",
                "Hall, Ned, 2000, \u201cCausation and the Price of\nTransitivity\u201d, <em>The Journal of Philosophy</em>, 97(4):\n198\u2013222. doi:10.2307/2678390",
                "Hall, Ned, 2007, \u201cStructural Equations and Causation\u201d,\n<em>Philosophical Studies</em>, 132(1): 109\u2013136.",
                "Halpern, Joseph Y., 2016, <em>Actual Causality</em>, Cambridge,\nMA: MIT Press.",
                "Halpern, Joseph Y. and Christopher Hitchcock, 2015, \u201cGraded\nCausation and Defaults\u201d, <em>British Journal for the Philosophy\nof Science</em>, 66(2): pp. 413\u2013457.\ndoi:10.1093/bjps/axt050",
                "Halpern, Joseph Y. and Judea Pearl, 2005a, \u201cCauses and\nExplanations: A Structural Model Approach; Part I: Causes\u201d,\n<em>British Journal for the Philosophy of Science</em>, 56(4):\n843\u201387. doi:10.1093/bjps/axi147",
                "\u2013\u2013\u2013, 2005b, \u201cCauses and Explanations: A\nStructural Model Approach; Part II: Explanations\u201d, <em>British\nJournal for the Philosophy of Science</em>, 56(4): 889\u2013911.\ndoi:10.1093/bjps/axi148",
                "Hausman, Daniel M., 1986, \u201cCausation and\nExperimentation\u201d, <em>American Philosophical Quarterly</em>,\n23(2): 143\u201354",
                "\u2013\u2013\u2013, 1998, <em>Causal Asymmetries</em>,\nCambridge: Cambridge University Press.",
                "Hernan, Miguel and Taubman, Sarah, 2008, \u201cDoes Obesity\nShorten Life? The Importance of Well-defined Interventions to Answer\nCausal Questions \u201d, <em>International Journal of Obesity</em>,\n32 (Supplement 3): S8\u201314.",
                "Hiddleston, Eric, 2005, Review of <em>Making Things Happen</em>\n(Woodward 2003), <em>Philosophical Review</em>, 114(4): 545\u201347.\ndoi:10.1215/00318108-114-4-545",
                "Hitchcock, Christopher, 2001a, \u201cThe Intransitivity of\nCausation Revealed in Equations and Graphs\u201d, <em>The Journal of\nPhilosophy</em>, 98(6): 273\u201399. doi:10.2307/2678432",
                "\u2013\u2013\u2013, 2001b, \u201cA Tale of Two Effects\u201d,\n<em>Philosophical Review</em>, 110(3): 361\u201396.\ndoi:10.1215/00318108-110-3-361",
                "\u2013\u2013\u2013, 2007a, \u201cPrevention, Preemption, and\nthe Principle of Sufficient Reason\u201d, <em>Philosophical\nReview</em>, 116(4): 495\u2013532. doi:10.1215/00318108-2007-012",
                "\u2013\u2013\u2013, 2007b, \u201cWhat Russell Got\nRight\u201d, in Price and Corry 2007: 45\u201365.",
                "Hitchcock, Christopher and James Woodward, 2003,\n\u201cExplanatory Generalizations, Part II: Plumbing Explanatory\nDepth\u201d, <em>N\u00f4us</em>, 37(2): 181\u201399.\ndoi:10.1111/1468-0068.00435",
                "Holland, Paul W., 1986, \u201cStatistics and Causal\nInference\u201d, <em>Journal of the American Statistical\nAssociation</em>, 81(396): 945\u2013960.",
                "Lewis, David, 1973, \u201cCausation\u201d, <em>Journal of\nPhilosophy</em>, 70(17): 556\u2013567.",
                "\u2013\u2013\u2013, 1979, \u201cCounterfactual Dependence and\nTime\u2019s Arrow\u201d, <em>N\u00f4us</em>, 13(4): 455\u201376.\ndoi:10.2307/2215339",
                "Maudlin, Tim, 2007, <em>The Metaphysics Within Physics</em>,\nOxford: Oxford University Press.\ndoi:10.1093/acprof:oso/9780199218219.001.0001",
                "Meek, Christopher and Clark Glymour, 1994, \u201cConditioning and\nIntervening\u201d, <em>British Journal for the Philosophy of\nScience</em>, 45(4): 1001\u20131021. doi:10.1093/bjps/45.4.1001",
                "Menzies, Peter and Huw Price, 1993, \u201cCausation as a\nSecondary Quality\u201d, <em>British Journal for the Philosophy of\nScience</em>, 44(2): 187\u2013203. doi:10.1093/bjps/44.2.187",
                "Norton, John D., 2007, \u201cCausation as Folk Science\u201d, in\nPrice and Corry 2007: 11\u201344.",
                "Pearl, Judea, 2009, <em>Causality</em>, New York: Cambridge\nUniversity Press.",
                "Price, Huw, 1991, \u201cAgency and Probabilistic\nCausality\u201d, <em>British Journal for the Philosophy of\nScience</em>, 42(2): 157\u201376. doi:10.1093/bjps/42.2.157",
                "\u2013\u2013\u2013, 1992, \u201cAgency and Causal\nAsymmetry\u201d, <em>Mind</em>, 101(403): 501\u2013520.",
                "\u2013\u2013\u2013, 2007 , \u201cCausal\nPerspectivalism\u201d, in Price and Corry 2007: 250\u2013292.",
                "\u2013\u2013\u2013, 2017, \u201cCausation, Intervention and\nAgency: Woodward on Menzies and Price\u201d, in H. Beebee, C.\nHitcock, and H. Price (eds.), <em>Making a Difference: Essays on the\nPhilosophy of Causation</em>, Oxford University Press, pp.\n73\u201398.",
                "Price, Huw and Richard Corry (eds), 2007, <em>Causation, Physics,\nand the Constitution of Reality: Russell\u2019s Republic\nRevisited</em>, Oxford: Oxford University Press.",
                "Reutlinger, Alexander, 2012, \u201cGetting Rid of\nInterventions\u201d, <em>Studies in the History and Philosophy of\nBiological and Biomedical Sciences</em>, 43(4): 787\u201395.\ndoi:10.1016/j.shpsc.2012.05.006",
                "Rubin, Donald B., 1974, \u201cEstimating Causal Effects of\nTreatments in Randomized and Nonrandomized Studies\u201d, <em>Journal\nof Educational Psychology</em>, 66(5): 688\u2013701.",
                "\u2013\u2013\u2013, 1986, \u201cComment: Which Ifs Have Causal\nAnswers?\u201d, <em>Journal of the American Statistical\nAssociation</em>, 81(396): 961\u2013962.",
                "Salmon, Wesley C., 1984, <em>Scientific Explanation and the Causal\nStructure of the World</em>, Princeton: Princeton University\nPress.",
                "Schaffer, Jonathan, 2000, \u201cCausation by\nDisconnection\u201d, <em>Philosophy of Science</em>, 67(2):\n285\u2013300. doi:10.1086/392776",
                "Skyrms, Brian, 1984, \u201cEPR:Lessons from Metaphysics\u201d,\n<em>Midwest Studies in Philosophy</em>, 9(1): 245\u201355.\ndoi:10.1111/j.1475-4975.1984.tb00062.x",
                "Sosa, Ernest and Michael Tooley (eds.), 1993, <em>Causation</em>,\nOxford: Oxford University Press.",
                "Spirtes, Peter, Clark Glymour, and Richard Scheines, 2000,\n<em>Causation, Prediction and Search</em>, Cambridge, MA: MIT\nPress.",
                "von Wright, Georg Henrik, 1971, <em>Explanation and\nUnderstanding</em>, Ithaca, NY: Cornell University Press.",
                "Woodward, James/Jim, 1997, \u201cExplanation, Invariance, and\nIntervention\u201d, <em>Philosophy of Science</em>, 64(supplement):\nS26\u2013S41.",
                "\u2013\u2013\u2013, 2000, \u201cExplanation and Invariance in\nthe Special Sciences\u201d, <em>British Journal for the Philosophy of\nScience</em>, 51(2): 197\u2013254. doi:10.1093/bjps/51.2.197",
                "\u2013\u2013\u2013, 2003, <em>Making Things Happen: A Theory of\nCausal Explanation</em>, Oxford: Oxford University Press.",
                "\u2013\u2013\u2013, 2007, \u201cCausation with a Human\nFace\u201d, in Price and Corry 2007: 66\u2013105.",
                "\u2013\u2013\u2013, 2014, \u201cSimplicity in the Best Systems\nAccount of Laws of Nature\u201d, <em>British Journal for the\nPhilosophy of Science</em>, 65: 91\u2013123. ",
                "\u2013\u2013\u2013, 2015, \u201cMethodology, Ontology and\nInterventionism\u201d, <em>Synthese</em>, 192(11): 3577\u20133599.\ndoi:10.1007/s11229-014-0479-1",
                "\u2013\u2013\u2013, 2016, \u201cCausation in Science\u201d,\nin <em>Oxford Handbook of the Philosophy of Science</em>, edited by\nPaul Humphreys, New York: Oxford University Press, 163\u2013184;\nlonger online version at doi:10.1093/oxfordhb/9780199368815.013.8",
                "Woodward, James and Christopher Hitchcock, 2003,\n\u201cExplanatory Generalizations, Part I: A Counterfactual\nAccount\u201d, <em>No\u00fbs</em>, 37(1): 1\u201324.\ndoi:10.1111/1468-0068.00426"
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Angrist, Joshua D. and J\u00f6rn-Steffen Pischke, 2009,\n\u201cMostly Harmless Econometrics\u201d, Princeton: Princeton\nUniversity Press.</li>\n<li>Butterfield, Jeremy, 1992, \u201cDavid Lewis Meets John\nBell\u201d, <em>Philosophy of Science</em>, 59(1): 26\u201343.\ndoi:10.1086/289652</li>\n<li>Briggs, Rachel, 2012, \u201cInterventionist\nCounterfactuals\u201d, <em>Philosophical Studies</em>, 160(1):\n139\u2013166. doi:10.1007/s11098-012-9908-5</li>\n<li>Cartwright, Nancy, 2001, \u201cModularity: It Can\u2014and\nGenerally Does\u2014Fail\u201d, in Maria Carla Galavotti, Patrick\nSuppes, and Domenico Constantini (eds.) <em>Stochastic Causality</em>,\nStanford: CSLI Publications.</li>\n<li>\u2013\u2013\u2013, 2002, \u201cAgainst Modularity, the Causal\nMarkov Condition, and Any Link Between the Two: Comments on Hausman\nand Woodward\u201d, <em>British Journal for the Philosophy of\nScience</em>, 53(3): 411\u201353. doi:10.1093/bjps/53.3.411</li>\n<li>\u2013\u2013\u2013, 2003, \u201cTwo Theorems on Invariance and\nCausality\u201d, <em>Philosophy of Science</em>, 70(1): 203\u201324.\ndoi:10.1086/367876</li>\n<li>Collingwood, R.G., 1940, <em>An Essay on Metaphysics</em>, Oxford:\nClarendon Press.</li>\n<li>Cook, Thomas D. and Donald T. Campbell, 1979,\n<em>Quasi-Experimentation: Design and Analysis Issues for Field\nSettings</em>, Boston: Houghton Miflin Company.</li>\n<li>Dowe, Phil, 2000, <em>Physical Causation</em>, Cambridge:\nCambridge University Press.</li>\n<li>Eberhardt, Frederick, 2007, <em>Causation and Intervention</em>,\n(Ph.D. Thesis), Carnegie Mellon University.\n [<a href=\"http://people.hss.caltech.edu/~fde/papers/PhDthesis.pdf\" target=\"other\">Eberhardt 2007 available online</a>]</li>\n<li>Eberhardt, Frederick and Richard Scheines, 2007,\n\u201cInterventions and Causal Inference\u201d, <em>Philosophy of\nScience</em>, 74(5): 981\u2013995. doi:10.1086/525638</li>\n<li>Fine, Kit, 2012, \u201cCounterfactuals Without Possible\nWorlds\u201d, <em>Journal of Philosophy</em>, 109(3): 221\u2013246.\ndoi:10.5840/jphil201210938</li>\n<li>Frisch, Mathias, 2014, <em>Causal Reasoning in Physics</em>,\nCambridge: Cambridge University Press.</li>\n<li>Gasking, Douglas, 1955, \u201cCausation and Recipes\u201d,\n<em>Mind</em>, 64(256): 479\u2013487.</li>\n<li>Glymour, Clark and Frank Wimberly, 2007, \u201cActual Causation\nand Thought Experiments\u201d, in Joseph Keim Campbell, Michael\nO\u2019Rourke, and Harry S. Silverstein (eds.) <em>Causation and\nExplanation</em>, Cambridge, MA: MIT Press, pp 43\u201367.</li>\n<li>Glynn, Luke, 2013, \u201cOf Miracles and Interventions\u201d,\n<em>Erkenntnis</em>, 78 (Supplement 1): 43\u201364.\ndoi:10.1007/s10670-013-9436-5</li>\n<li>Haavelmo, Trygve, 1944, \u201cThe Probability Approach in\nEconometrics\u201d, <em>Econometrica</em>, 12 (Supplement), pp.\niii\u2013vi, 1\u2013115. doi:10.2307/1906935</li>\n<li>Hall, Ned, 2000, \u201cCausation and the Price of\nTransitivity\u201d, <em>The Journal of Philosophy</em>, 97(4):\n198\u2013222. doi:10.2307/2678390</li>\n<li>Hall, Ned, 2007, \u201cStructural Equations and Causation\u201d,\n<em>Philosophical Studies</em>, 132(1): 109\u2013136.</li>\n<li>Halpern, Joseph Y., 2016, <em>Actual Causality</em>, Cambridge,\nMA: MIT Press.</li>\n<li>Halpern, Joseph Y. and Christopher Hitchcock, 2015, \u201cGraded\nCausation and Defaults\u201d, <em>British Journal for the Philosophy\nof Science</em>, 66(2): pp. 413\u2013457.\ndoi:10.1093/bjps/axt050</li>\n<li>Halpern, Joseph Y. and Judea Pearl, 2005a, \u201cCauses and\nExplanations: A Structural Model Approach; Part I: Causes\u201d,\n<em>British Journal for the Philosophy of Science</em>, 56(4):\n843\u201387. doi:10.1093/bjps/axi147</li>\n<li>\u2013\u2013\u2013, 2005b, \u201cCauses and Explanations: A\nStructural Model Approach; Part II: Explanations\u201d, <em>British\nJournal for the Philosophy of Science</em>, 56(4): 889\u2013911.\ndoi:10.1093/bjps/axi148</li>\n<li>Hausman, Daniel M., 1986, \u201cCausation and\nExperimentation\u201d, <em>American Philosophical Quarterly</em>,\n23(2): 143\u201354</li>\n<li>\u2013\u2013\u2013, 1998, <em>Causal Asymmetries</em>,\nCambridge: Cambridge University Press.</li>\n<li>Hernan, Miguel and Taubman, Sarah, 2008, \u201cDoes Obesity\nShorten Life? The Importance of Well-defined Interventions to Answer\nCausal Questions \u201d, <em>International Journal of Obesity</em>,\n32 (Supplement 3): S8\u201314.</li>\n<li>Hiddleston, Eric, 2005, Review of <em>Making Things Happen</em>\n(Woodward 2003), <em>Philosophical Review</em>, 114(4): 545\u201347.\ndoi:10.1215/00318108-114-4-545</li>\n<li>Hitchcock, Christopher, 2001a, \u201cThe Intransitivity of\nCausation Revealed in Equations and Graphs\u201d, <em>The Journal of\nPhilosophy</em>, 98(6): 273\u201399. doi:10.2307/2678432</li>\n<li>\u2013\u2013\u2013, 2001b, \u201cA Tale of Two Effects\u201d,\n<em>Philosophical Review</em>, 110(3): 361\u201396.\ndoi:10.1215/00318108-110-3-361</li>\n<li>\u2013\u2013\u2013, 2007a, \u201cPrevention, Preemption, and\nthe Principle of Sufficient Reason\u201d, <em>Philosophical\nReview</em>, 116(4): 495\u2013532. doi:10.1215/00318108-2007-012</li>\n<li>\u2013\u2013\u2013, 2007b, \u201cWhat Russell Got\nRight\u201d, in Price and Corry 2007: 45\u201365.</li>\n<li>Hitchcock, Christopher and James Woodward, 2003,\n\u201cExplanatory Generalizations, Part II: Plumbing Explanatory\nDepth\u201d, <em>N\u00f4us</em>, 37(2): 181\u201399.\ndoi:10.1111/1468-0068.00435</li>\n<li>Holland, Paul W., 1986, \u201cStatistics and Causal\nInference\u201d, <em>Journal of the American Statistical\nAssociation</em>, 81(396): 945\u2013960.</li>\n<li>Lewis, David, 1973, \u201cCausation\u201d, <em>Journal of\nPhilosophy</em>, 70(17): 556\u2013567.</li>\n<li>\u2013\u2013\u2013, 1979, \u201cCounterfactual Dependence and\nTime\u2019s Arrow\u201d, <em>N\u00f4us</em>, 13(4): 455\u201376.\ndoi:10.2307/2215339</li>\n<li>Maudlin, Tim, 2007, <em>The Metaphysics Within Physics</em>,\nOxford: Oxford University Press.\ndoi:10.1093/acprof:oso/9780199218219.001.0001</li>\n<li>Meek, Christopher and Clark Glymour, 1994, \u201cConditioning and\nIntervening\u201d, <em>British Journal for the Philosophy of\nScience</em>, 45(4): 1001\u20131021. doi:10.1093/bjps/45.4.1001</li>\n<li>Menzies, Peter and Huw Price, 1993, \u201cCausation as a\nSecondary Quality\u201d, <em>British Journal for the Philosophy of\nScience</em>, 44(2): 187\u2013203. doi:10.1093/bjps/44.2.187</li>\n<li>Norton, John D., 2007, \u201cCausation as Folk Science\u201d, in\nPrice and Corry 2007: 11\u201344.</li>\n<li>Pearl, Judea, 2009, <em>Causality</em>, New York: Cambridge\nUniversity Press.</li>\n<li>Price, Huw, 1991, \u201cAgency and Probabilistic\nCausality\u201d, <em>British Journal for the Philosophy of\nScience</em>, 42(2): 157\u201376. doi:10.1093/bjps/42.2.157</li>\n<li>\u2013\u2013\u2013, 1992, \u201cAgency and Causal\nAsymmetry\u201d, <em>Mind</em>, 101(403): 501\u2013520.</li>\n<li>\u2013\u2013\u2013, 2007 , \u201cCausal\nPerspectivalism\u201d, in Price and Corry 2007: 250\u2013292.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cCausation, Intervention and\nAgency: Woodward on Menzies and Price\u201d, in H. Beebee, C.\nHitcock, and H. Price (eds.), <em>Making a Difference: Essays on the\nPhilosophy of Causation</em>, Oxford University Press, pp.\n73\u201398.</li>\n<li>Price, Huw and Richard Corry (eds), 2007, <em>Causation, Physics,\nand the Constitution of Reality: Russell\u2019s Republic\nRevisited</em>, Oxford: Oxford University Press.</li>\n<li>Reutlinger, Alexander, 2012, \u201cGetting Rid of\nInterventions\u201d, <em>Studies in the History and Philosophy of\nBiological and Biomedical Sciences</em>, 43(4): 787\u201395.\ndoi:10.1016/j.shpsc.2012.05.006</li>\n<li>Rubin, Donald B., 1974, \u201cEstimating Causal Effects of\nTreatments in Randomized and Nonrandomized Studies\u201d, <em>Journal\nof Educational Psychology</em>, 66(5): 688\u2013701.</li>\n<li>\u2013\u2013\u2013, 1986, \u201cComment: Which Ifs Have Causal\nAnswers?\u201d, <em>Journal of the American Statistical\nAssociation</em>, 81(396): 961\u2013962.</li>\n<li>Salmon, Wesley C., 1984, <em>Scientific Explanation and the Causal\nStructure of the World</em>, Princeton: Princeton University\nPress.</li>\n<li>Schaffer, Jonathan, 2000, \u201cCausation by\nDisconnection\u201d, <em>Philosophy of Science</em>, 67(2):\n285\u2013300. doi:10.1086/392776</li>\n<li>Skyrms, Brian, 1984, \u201cEPR:Lessons from Metaphysics\u201d,\n<em>Midwest Studies in Philosophy</em>, 9(1): 245\u201355.\ndoi:10.1111/j.1475-4975.1984.tb00062.x</li>\n<li>Sosa, Ernest and Michael Tooley (eds.), 1993, <em>Causation</em>,\nOxford: Oxford University Press.</li>\n<li>Spirtes, Peter, Clark Glymour, and Richard Scheines, 2000,\n<em>Causation, Prediction and Search</em>, Cambridge, MA: MIT\nPress.</li>\n<li>von Wright, Georg Henrik, 1971, <em>Explanation and\nUnderstanding</em>, Ithaca, NY: Cornell University Press.</li>\n<li>Woodward, James/Jim, 1997, \u201cExplanation, Invariance, and\nIntervention\u201d, <em>Philosophy of Science</em>, 64(supplement):\nS26\u2013S41.</li>\n<li>\u2013\u2013\u2013, 2000, \u201cExplanation and Invariance in\nthe Special Sciences\u201d, <em>British Journal for the Philosophy of\nScience</em>, 51(2): 197\u2013254. doi:10.1093/bjps/51.2.197</li>\n<li>\u2013\u2013\u2013, 2003, <em>Making Things Happen: A Theory of\nCausal Explanation</em>, Oxford: Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 2007, \u201cCausation with a Human\nFace\u201d, in Price and Corry 2007: 66\u2013105.</li>\n<li>\u2013\u2013\u2013, 2014, \u201cSimplicity in the Best Systems\nAccount of Laws of Nature\u201d, <em>British Journal for the\nPhilosophy of Science</em>, 65: 91\u2013123. </li>\n<li>\u2013\u2013\u2013, 2015, \u201cMethodology, Ontology and\nInterventionism\u201d, <em>Synthese</em>, 192(11): 3577\u20133599.\ndoi:10.1007/s11229-014-0479-1</li>\n<li>\u2013\u2013\u2013, 2016, \u201cCausation in Science\u201d,\nin <em>Oxford Handbook of the Philosophy of Science</em>, edited by\nPaul Humphreys, New York: Oxford University Press, 163\u2013184;\nlonger online version at doi:10.1093/oxfordhb/9780199368815.013.8</li>\n<li>Woodward, James and Christopher Hitchcock, 2003,\n\u201cExplanatory Generalizations, Part I: A Counterfactual\nAccount\u201d, <em>No\u00fbs</em>, 37(1): 1\u201324.\ndoi:10.1111/1468-0068.00426</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "causal models",
            "causation: counterfactual theories of",
            "causation: probabilistic",
            "causation: the metaphysics of",
            "mechanism in science",
            "Salmon, Wesley",
            "scientific explanation: causal approaches to"
        ],
        "entry_link": [
            {
                "../causal-models/": "causal models"
            },
            {
                "../causation-counterfactual/": "causation: counterfactual theories of"
            },
            {
                "../causation-probabilistic/": "causation: probabilistic"
            },
            {
                "../causation-metaphysics/": "causation: the metaphysics of"
            },
            {
                "../science-mechanisms/": "mechanism in science"
            },
            {
                "../wesley-salmon/": "Salmon, Wesley"
            },
            {
                "../causal-explanation-science/": "scientific explanation: causal approaches to"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=causation-mani\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/causation-mani/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=causation-mani&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/causation-mani/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=causation-mani": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/causation-mani/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=causation-mani&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/causation-mani/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "Weslake, Brad, 2013,\n \u201c<a href=\"http://bweslake.s3.amazonaws.com/research/papers/weslake_ac.pdf\" target=\"other\">A Partial Theory of Actual Causation</a>\u201d,\n unpublished manuscript.",
            "<a href=\"http://bayes.cs.ucla.edu/jp_home.html\" target=\"other\">Links to Judea Pearl\u2019s work on causality</a>"
        ],
        "listed_links": [
            {
                "http://bweslake.s3.amazonaws.com/research/papers/weslake_ac.pdf": "A Partial Theory of Actual Causation"
            },
            {
                "http://bayes.cs.ucla.edu/jp_home.html": "Links to Judea Pearl\u2019s work on causality"
            }
        ]
    }
}