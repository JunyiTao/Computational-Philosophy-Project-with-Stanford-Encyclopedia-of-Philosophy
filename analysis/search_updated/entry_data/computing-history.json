{
    "url": "computing-history",
    "title": "The Modern History of Computing",
    "authorship": {
        "year": "Copyright \u00a9 2006",
        "author_text": "B. Jack Copeland\n<jack.copeland@canterbury.ac.nz>",
        "author_links": [
            {
                "https://www.canterbury.ac.nz/arts/contact-us/people/jack-copeland.html": "B. Jack Copeland"
            },
            {
                "mailto:jack%2ecopeland%40canterbury%2eac%2enz": "jack.copeland@canterbury.ac.nz"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2006</a> by\n\n<br/>\n<a href=\"https://www.canterbury.ac.nz/arts/contact-us/people/jack-copeland.html\" target=\"other\">B. Jack Copeland</a>\n&lt;<a href=\"mailto:jack%2ecopeland%40canterbury%2eac%2enz\"><em>jack<abbr title=\" dot \">.</abbr>copeland<abbr title=\" at \">@</abbr>canterbury<abbr title=\" dot \">.</abbr>ac<abbr title=\" dot \">.</abbr>nz</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Mon Dec 18, 2000",
        "substantive revision Fri Jun 9, 2006"
    ],
    "preamble": "\n\n\nHistorically, computers were human clerks who calculated in accordance\nwith effective methods. These human computers did the sorts of\ncalculation nowadays carried out by electronic computers, and many\nthousands of them were employed in commerce, government, and research\nestablishments. The term computing machine, used increasingly\nfrom the 1920s, refers to any machine that does the work of a human\ncomputer, i.e., any machine that calculates in accordance with\neffective methods. During the late 1940s and early 1950s, with the\nadvent of electronic computing machines, the phrase \u2018computing\nmachine\u2019 gradually gave way simply to \u2018computer\u2019,\ninitially usually with the prefix \u2018electronic\u2019 or\n\u2018digital\u2019. This entry surveys the history of these\nmachines. \n\n",
    "toc": [
        {
            "#Bab": "Babbage"
        },
        {
            "#analog": "Analog Computers"
        },
        {
            "#UTM": "The Universal Turing Machine"
        },
        {
            "#Flow": "Electromechanical versus Electronic Computation"
        },
        {
            "#Atan": "Atanasoff"
        },
        {
            "#Col": "Colossus"
        },
        {
            "#ACE": "Turing's Automatic Computing Engine"
        },
        {
            "#MUC": "The Manchester Machine"
        },
        {
            "#ENIAC": "ENIAC and EDVAC"
        },
        {
            "#Others": "Other Notable Early Computers"
        },
        {
            "#Mems": "High-Speed Memory"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\nBabbage\n\n\nCharles Babbage was Lucasian Professor of Mathematics at Cambridge\nUniversity from 1828 to 1839 (a post formerly held by Isaac Newton).\nBabbage's proposed Difference Engine was a special-purpose digital\ncomputing machine for the automatic production of mathematical tables\n(such as logarithm tables, tide tables, and astronomical tables). The\nDifference Engine consisted entirely of mechanical components \u2014\nbrass gear wheels, rods, ratchets, pinions, etc. Numbers were\nrepresented in the decimal system by the positions of 10-toothed metal\nwheels mounted in columns. Babbage exhibited a small working model in\n1822. He never completed the full-scale machine that he had designed\nbut did complete several fragments. The largest \u2014 one ninth of\nthe complete calculator \u2014 is on display in the London Science\nMuseum. Babbage used it to perform serious computational work,\ncalculating various mathematical tables. In 1990, Babbage's Difference\nEngine No. 2 was finally built from Babbage's designs and is also on\ndisplay at the London Science Museum. \n\n\nThe Swedes Georg and Edvard Scheutz (father and son) constructed a\nmodified version of Babbage's Difference Engine. Three were made, a\nprototype and two commercial models, one of these being sold to an\nobservatory in Albany, New York, and the other to the\nRegistrar-General's office in London, where it calculated and printed\nactuarial tables.\n\n\nBabbage's proposed Analytical Engine, considerably more ambitious\nthan the Difference Engine, was to have been a general-purpose\nmechanical digital computer. The Analytical Engine was to have had a\nmemory store and a central processing unit (or \u2018mill\u2019) and\nwould have been able to select from among alternative actions\nconsequent upon the outcome of its previous actions (a facility\nnowadays known as conditional branching). The behaviour of the\nAnalytical Engine would have been controlled by a program of\ninstructions contained on punched cards connected together with ribbons\n(an idea that Babbage had adopted from the Jacquard weaving loom).\nBabbage emphasised the generality of the Analytical Engine, saying\n\u2018the conditions which enable a finite machine to make\ncalculations of unlimited extent are fulfilled in the Analytical\nEngine\u2019 (Babbage [1994], p. 97).\n\n\nBabbage worked closely with Ada Lovelace, daughter of the poet\nByron, after whom the modern programming language ADA is named.\nLovelace foresaw the possibility of using the Analytical Engine for\nnon-numeric computation, suggesting that the Engine might even be\ncapable of composing elaborate pieces of music.\n\n\nA large model of the Analytical Engine was under construction at the\ntime of Babbage's death in 1871 but a full-scale version was never\nbuilt. Babbage's idea of a general-purpose calculating engine was never\nforgotten, especially at Cambridge, and was on occasion a lively topic\nof mealtime discussion at the war-time headquarters of the Government\nCode and Cypher School, Bletchley Park, Buckinghamshire, birthplace of\nthe electronic digital computer.\nAnalog computers\n\n\nThe earliest computing machines in wide use were not digital but\nanalog. In analog representation, properties of the representational\nmedium ape (or reflect or model) properties of the represented\nstate-of-affairs. (In obvious contrast, the strings of binary digits\nemployed in digital representation do not represent by means\nof possessing some physical property \u2014 such as length \u2014\nwhose magnitude varies in proportion to the magnitude of the property\nthat is being represented.) Analog representations form a diverse\nclass. Some examples: the longer a line on a road map, the longer the\nroad that the line represents; the greater the number of clear plastic\nsquares in an architect's model, the greater the number of windows in\nthe building represented; the higher the pitch of an acoustic depth\nmeter, the shallower the water. In analog computers, numerical\nquantities are represented by, for example, the angle of rotation of a\nshaft or a difference in electrical potential. Thus the output voltage\nof the machine at a time might represent the momentary speed of the\nobject being modelled. \n\n\nAs the case of the architect's model makes plain, analog\nrepresentation may be discrete in nature (there is no such\nthing as a fractional number of windows). Among computer scientists,\nthe term \u2018analog\u2019 is sometimes used narrowly, to indicate\nrepresentation of one continuously-valued quantity by another\n(e.g., speed by voltage). As Brian Cantwell Smith has remarked:\n\u2018Analog\u2019 should \u2026 be a predicate on a\nrepresentation whose structure corresponds to that of which it\nrepresents \u2026 That continuous representations should historically\nhave come to be called analog presumably betrays the recognition that,\nat the levels at which it matters to us, the world is more\nfoundationally continuous than it is discrete. (Smith [1991], p.\n271)\n\n\nJames Thomson, brother of Lord Kelvin, invented the mechanical\nwheel-and-disc integrator that became the foundation of analog\ncomputation (Thomson [1876]). The two brothers constructed a device for\ncomputing the integral of the product of two given functions, and\nKelvin described (although did not construct) general-purpose analog\nmachines for integrating linear differential equations of any order and\nfor solving simultaneous linear equations. Kelvin's most successful\nanalog computer was his tide predicting machine, which remained in use\nat the port of Liverpool until the 1960s. Mechanical analog devices\nbased on the wheel-and-disc integrator were in use during World War I\nfor gunnery calculations. Following the war, the design of the\nintegrator was considerably improved by Hannibal Ford (Ford [1919]). \n\n\nStanley Fifer reports that the first semi-automatic mechanical\nanalog computer was built in England by the Manchester firm of\nMetropolitan Vickers prior to 1930 (Fifer [1961], p. 29); however, I\nhave so far been unable to verify this claim. In 1931, Vannevar Bush,\nworking at MIT, built the differential analyser, the first large-scale\nautomatic general-purpose mechanical analog computer. Bush's design was\nbased on the wheel and disc integrator. Soon copies of his machine were\nin use around the world (including, at Cambridge and Manchester\nUniversities in England, differential analysers built out of kit-set\nMeccano, the once popular engineering toy).\n\n\nIt required a skilled mechanic equipped with a lead hammer to set up\nBush's mechanical differential analyser for each new job. Subsequently,\nBush and his colleagues replaced the wheel-and-disc integrators and\nother mechanical components by electromechanical, and finally by\nelectronic, devices.\n\n\nA differential analyser may be conceptualised as a collection of\n\u2018black boxes\u2019 connected together in such a way as to allow\nconsiderable feedback. Each box performs a fundamental process, for\nexample addition, multiplication of a variable by a constant, and\nintegration. In setting up the machine for a given task, boxes are\nconnected together so that the desired set of fundamental processes is\nexecuted. In the case of electrical machines, this was done typically\nby plugging wires into sockets on a patch panel (computing machines\nwhose function is determined in this way are referred to as\n\u2018program-controlled\u2019).\n\n\nSince all the boxes work in parallel, an electronic differential\nanalyser solves sets of equations very quickly. Against this has to be\nset the cost of massaging the problem to be solved into the form\ndemanded by the analog machine, and of setting up the hardware to\nperform the desired computation. A major drawback of analog computation\nis the higher cost, relative to digital machines, of an increase in\nprecision. During the 1960s and 1970s, there was considerable interest\nin \u2018hybrid\u2019 machines, where an analog section is controlled\nby and programmed via a digital section. However, such machines are now\na rarity.\nThe Universal Turing Machine\n\n\nIn 1936, at Cambridge University, Turing invented the principle of the\nmodern computer. He described an abstract digital computing machine\nconsisting of a limitless memory and a scanner that moves back and\nforth through the memory, symbol by symbol, reading what it finds and\nwriting further symbols (Turing [1936]). The actions of the scanner are\ndictated by a program of instructions that is stored in the memory in\nthe form of symbols. This is Turing's stored-program concept, and\nimplicit in it is the possibility of the machine operating on and\nmodifying its own program. (In London in 1947, in the course of what\nwas, so far as is known, the earliest public lecture to mention\ncomputer intelligence, Turing said, \u2018What we want is a machine\nthat can learn from experience\u2019, adding that the\n\u2018possibility of letting the machine alter its own instructions\nprovides the mechanism for this\u2019 (Turing [1947] p. 393). Turing's\ncomputing machine of 1936 is now known simply as the universal Turing\nmachine. Cambridge mathematician Max Newman remarked that right from\nthe start Turing was interested in the possibility of actually building\na computing machine of the sort that he had described (Newman in\ninterview with Christopher Evans in Evans [197?]. \n\n\nFrom the start of the Second World War Turing was a leading\ncryptanalyst at the Government Code and Cypher School, Bletchley Park.\nHere he became familiar with Thomas Flowers' work involving large-scale\nhigh-speed electronic switching (described below). However, Turing\ncould not turn to the project of building an electronic stored-program\ncomputing machine until the cessation of hostilities in Europe in\n1945.\n\n\nDuring the wartime years Turing did give considerable thought to the\nquestion of machine intelligence. Colleagues at Bletchley Park recall\nnumerous off-duty discussions with him on the topic, and at one point\nTuring circulated a typewritten report (now lost) setting out some of\nhis ideas. One of these colleagues, Donald Michie (who later founded\nthe Department of Machine Intelligence and Perception at the University\nof Edinburgh), remembers Turing talking often about the possibility of\ncomputing machines (1) learning from experience and (2) solving\nproblems by means of searching through the space of possible solutions,\nguided by rule-of-thumb principles (Michie in interview with Copeland,\n1995). The modern term for the latter idea is \u2018heuristic\nsearch\u2019, a heuristic being any rule-of-thumb principle that cuts\ndown the amount of searching required in order to find a solution to a\nproblem. At Bletchley Park Turing illustrated his ideas on machine\nintelligence by reference to chess. Michie recalls Turing experimenting\nwith heuristics that later became common in chess programming (in\nparticular minimax and best-first).\n\n\nFurther information about Turing and the computer, including his\nwartime work on codebreaking and his thinking about artificial\nintelligence and artificial life, can be found in Copeland 2004.\nElectromechanical versus Electronic Computation\n\n\nWith some exceptions \u2014 including Babbage's purely mechanical\nengines, and the finger-powered National Accounting Machine - early\ndigital computing machines were electromechanical. That is to say,\ntheir basic components were small, electrically-driven, mechanical\nswitches called \u2018relays\u2019. These operate relatively slowly,\nwhereas the basic components of an electronic computer \u2014\noriginally vacuum tubes (valves) \u2014 have no moving parts save\nelectrons and so operate extremely fast. Electromechanical digital\ncomputing machines were built before and during the second world war by\n(among others) Howard Aiken at Harvard University, George Stibitz at\nBell Telephone Laboratories, Turing at Princeton University and\nBletchley Park, and Konrad Zuse in Berlin. To Zuse belongs the honour\nof having built the first working general-purpose program-controlled\ndigital computer. This machine, later called the Z3, was functioning in\n1941. (A program-controlled computer, as opposed to a stored-program\ncomputer, is set up for a new task by re-routing wires, by means of\nplugs etc.) \n\n\nRelays were too slow and unreliable a medium for large-scale\ngeneral-purpose digital computation (although Aiken made a valiant\neffort). It was the development of high-speed digital techniques using\nvacuum tubes that made the modern computer possible.\n\n\nThe earliest extensive use of vacuum tubes for digital\ndata-processing appears to have been by the engineer Thomas Flowers,\nworking in London at the British Post Office Research Station at Dollis\nHill. Electronic equipment designed by Flowers in 1934, for controlling\nthe connections between telephone exchanges, went into operation in\n1939, and involved between three and four thousand vacuum tubes running\ncontinuously. In 1938\u20131939 Flowers worked on an experimental\nelectronic digital data-processing system, involving a high-speed data\nstore. Flowers' aim, achieved after the war, was that electronic\nequipment should replace existing, less reliable, systems built from\nrelays and used in telephone exchanges. Flowers did not investigate the\nidea of using electronic equipment for numerical calculation, but has\nremarked that at the outbreak of war with Germany in 1939 he was\npossibly the only person in Britain who realized that vacuum tubes\ncould be used on a large scale for high-speed digital computation. (See\nCopeland 2006 for m more information on Flowers' work.)\nAtanasoff\n\n\nThe earliest comparable use of vacuum tubes in the U.S. seems to have\nbeen by John Atanasoff at what was then Iowa State College (now\nUniversity). During the period 1937\u20131942 Atanasoff developed\ntechniques for using vacuum tubes to perform numerical calculations\ndigitally. In 1939, with the assistance of his student Clifford Berry,\nAtanasoff began building what is sometimes called the Atanasoff-Berry\nComputer, or ABC, a small-scale special-purpose electronic digital\nmachine for the solution of systems of linear algebraic equations. The\nmachine contained approximately 300 vacuum tubes. Although the\nelectronic part of the machine functioned successfully, the computer as\na whole never worked reliably, errors being introduced by the\nunsatisfactory binary card-reader. Work was discontinued in 1942 when\nAtanasoff left Iowa State. \nColossus\n\n\nThe first fully functioning electronic digital computer was Colossus,\nused by the Bletchley Park cryptanalysts from February 1944. \n\n\nFrom very early in the war the Government Code and Cypher School\n(GC&CS) was successfully deciphering German radio communications\nencoded by means of the Enigma system, and by early 1942 about 39,000\nintercepted messages were being decoded each month, thanks to\nelectromechanical machines known as \u2018bombes\u2019. These were\ndesigned by Turing and Gordon Welchman (building on earlier work by\nPolish cryptanalysts).\n\n\nDuring the second half of 1941, messages encoded by means of a\ntotally different method began to be intercepted. This new cipher\nmachine, code-named \u2018Tunny\u2019 by Bletchley Park, was broken\nin April 1942 and current traffic was read for the first time in July\nof that year. Based on binary teleprinter code, Tunny was used in\npreference to Morse-based Enigma for the encryption of high-level\nsignals, for example messages from Hitler and members of the German\nHigh Command.\n\n\nThe need to decipher this vital intelligence as rapidly as possible\nled Max Newman to propose in November 1942 (shortly after his\nrecruitment to GC&CS from Cambridge University) that key parts of\nthe decryption process be automated, by means of high-speed electronic\ncounting devices. The first machine designed and built to Newman's\nspecification, known as the Heath Robinson, was relay-based with\nelectronic circuits for counting. (The electronic counters were\ndesigned by C.E. Wynn-Williams, who had been using thyratron tubes in\ncounting circuits at the Cavendish Laboratory, Cambridge, since 1932\n[Wynn-Williams 1932].) Installed in June 1943, Heath Robinson was\nunreliable and slow, and its high-speed paper tapes were continually\nbreaking, but it proved the worth of Newman's idea. Flowers recommended\nthat an all-electronic machine be built instead, but he received no\nofficial encouragement from GC&CS. Working independently at the\nPost Office Research Station at Dollis Hill, Flowers quietly got on\nwith constructing the world's first large-scale programmable electronic\ndigital computer. Colossus I was delivered to Bletchley Park in January\n1943.\n\n\nBy the end of the war there were ten Colossi working round the clock\nat Bletchley Park. From a cryptanalytic viewpoint, a major difference\nbetween the prototype Colossus I and the later machines was the\naddition of the so-called Special Attachment, following a key discovery\nby cryptanalysts Donald Michie and Jack Good. This broadened the\nfunction of Colossus from \u2018wheel setting\u2019 \u2014 i.e.,\ndetermining the settings of the encoding wheels of the Tunny machine\nfor a particular message, given the \u2018patterns\u2019 of the\nwheels \u2014 to \u2018wheel breaking\u2019, i.e., determining the\nwheel patterns themselves. The wheel patterns were eventually changed\ndaily by the Germans on each of the numerous links between the German\nArmy High Command and Army Group commanders in the field. By 1945 there\nwere as many 30 links in total. About ten of these were broken and read\nregularly.\n\n\nColossus I contained approximately 1600 vacuum tubes and each of the\nsubsequent machines approximately 2400 vacuum tubes. Like the smaller\nABC, Colossus lacked two important features of modern computers. First,\nit had no internally stored programs. To set it up for a new task, the\noperator had to alter the machine's physical wiring, using plugs and\nswitches. Second, Colossus was not a general-purpose machine, being\ndesigned for a specific cryptanalytic task involving counting and\nBoolean operations.\n\n\nF.H. Hinsley, official historian of GC&CS, has estimated that\nthe war in Europe was shortened by at least two years as a result of\nthe signals intelligence operation carried out at Bletchley Park, in\nwhich Colossus played a major role. Most of the Colossi were destroyed\nonce hostilities ceased. Some of the electronic panels ended up at\nNewman's Computing Machine Laboratory in Manchester (see below), all\ntrace of their original use having been removed. Two Colossi were\nretained by GC&CS (renamed GCHQ following the end of the war). The\nlast Colossus is believed to have stopped running in 1960.\n\n\nThose who knew of Colossus were prohibited by the Official Secrets\nAct from sharing their knowledge. Until the 1970s, few had any idea\nthat electronic computation had been used successfully during the\nsecond world war. In 1970 and 1975, respectively, Good and Michie\npublished notes giving the barest outlines of Colossus. By 1983,\nFlowers had received clearance from the British Government to publish a\npartial account of the hardware of Colossus I. Details of the later\nmachines and of the Special Attachment, the uses to which the Colossi\nwere put, and the cryptanalytic algorithms that they ran, have only\nrecently been declassified. (For the full account of Colossus and the\nattack on Tunny see Copeland 2006.)\n\n\nTo those acquainted with the universal Turing machine of 1936, and\nthe associated stored-program concept, Flowers' racks of digital\nelectronic equipment were proof of the feasibility of using large\nnumbers of vacuum tubes to implement a high-speed general-purpose\nstored-program computer. The war over, Newman lost no time in\nestablishing the Royal Society Computing Machine Laboratory at\nManchester University for precisely that purpose. A few months after\nhis arrival at Manchester, Newman wrote as follows to the Princeton\nmathematician John von Neumann (February 1946):\nI am \u2026 hoping to embark on a computing machine\nsection here, having got very interested in electronic devices of this\nkind during the last two or three years. By about eighteen months ago I\nhad decided to try my hand at starting up a machine unit when I got\nout. \u2026 I am of course in close touch with Turing.\nTuring's Automatic Computing Engine\n\n\nTuring and Newman were thinking along similar lines. In 1945 Turing\njoined the National Physical Laboratory (NPL) in London, his brief to\ndesign and develop an electronic stored-program digital computer for\nscientific work. (Artificial Intelligence was not far from Turing's\nthoughts: he described himself as \u2018building a brain\u2019 and\nremarked in a letter that he was \u2018more interested in the\npossibility of producing models of the action of the brain than in the\npractical applications to computing\u2019.) John Womersley, Turing's\nimmediate superior at NPL, christened Turing's proposed machine the\nAutomatic Computing Engine, or ACE, in homage to Babbage's Difference\nEngine and Analytical Engine. \n\n\nTuring's 1945 report \u2018Proposed Electronic Calculator\u2019\ngave the first relatively complete specification of an electronic\nstored-program general-purpose digital computer. The report is\nreprinted in full in Copeland 2005.\n\n\nThe first electronic stored-program digital computer to be proposed\nin the U.S. was the EDVAC (see below). The \u2018First Draft of a\nReport on the EDVAC\u2019 (May 1945), composed by von Neumann,\ncontained little engineering detail, in particular concerning\nelectronic hardware (owing to restrictions in the U.S.). Turing's\n\u2018Proposed Electronic Calculator\u2019, on the other hand,\nsupplied detailed circuit designs and specifications of hardware units,\nspecimen programs in machine code, and even an estimate of the cost of\nbuilding the machine (\u00a311,200). ACE and EDVAC differed\nfundamentally from one another; for example, ACE employed distributed\nprocessing, while EDVAC had a centralised structure.\n\n\nTuring saw that speed and memory were the keys to computing.\nTuring's colleague at NPL, Jim Wilkinson, observed that Turing\n\u2018was obsessed with the idea of speed on the machine\u2019\n[Copeland 2005, p. 2]. Turing's design had much in common with today's\nRISC architectures and it called for a high-speed memory of roughly the\nsame capacity as an early Macintosh computer (enormous by the standards\nof his day). Had Turing's ACE been built as planned it would have been\nin a different league from the other early computers. However, progress\non Turing's Automatic Computing Engine ran slowly, due to\norganisational difficulties at NPL, and in 1948 a \u2018very fed\nup\u2019 Turing (Robin Gandy's description, in interview with\nCopeland, 1995) left NPL for Newman's Computing Machine Laboratory at\nManchester University. It was not until May 1950 that a small pilot\nmodel of the Automatic Computing Engine, built by Wilkinson, Edward\nNewman, Mike Woodger, and others, first executed a program. With an\noperating speed of 1 MHz, the Pilot Model ACE was for some time the\nfastest computer in the world.\n\n\nSales of DEUCE, the production version of the Pilot Model ACE, were\nbuoyant \u2014 confounding the suggestion, made in 1946 by the\nDirector of the NPL, Sir Charles Darwin, that \u2018it is very\npossible that \u2026 one machine would suffice to solve all the\nproblems that are demanded of it from the whole country\u2019\n[Copeland 2005, p. 4]. The fundamentals of Turing's ACE design were\nemployed by Harry Huskey (at Wayne State University, Detroit) in the\nBendix G15 computer (Huskey in interview with Copeland, 1998). The G15\nwas arguably the first personal computer; over 400 were sold worldwide.\nDEUCE and the G15 remained in use until about 1970. Another computer\nderiving from Turing's ACE design, the MOSAIC, played a role in\nBritain's air defences during the Cold War period; other derivatives\ninclude the Packard-Bell PB250 (1961). (More information about these\nearly computers is given in [Copeland 2005].)\nThe Manchester Machine\n\n\nThe earliest general-purpose stored-program electronic digital computer\nto work was built in Newman's Computing Machine Laboratory at\nManchester University. The Manchester \u2018Baby\u2019, as it became\nknown, was constructed by the engineers F.C. Williams and Tom Kilburn,\nand performed its first calculation on 21 June 1948. The tiny program,\nstored on the face of a cathode ray tube, was just seventeen\ninstructions long. A much enlarged version of the machine, with a\nprogramming system designed by Turing, became the world's first\ncommercially available computer, the Ferranti Mark I. The first to be\ncompleted was installed at Manchester University in February 1951; in\nall about ten were sold, in Britain, Canada, Holland and Italy. \n\n\nThe fundamental logico-mathematical contributions by Turing and\nNewman to the triumph at Manchester have been neglected, and the\nManchester machine is nowadays remembered as the work of Williams and\nKilburn. Indeed, Newman's role in the development of computers has\nnever been sufficiently emphasised (due perhaps to his thoroughly\nself-effacing way of relating the relevant events).\n\n\nIt was Newman who, in a lecture in Cambridge in 1935, introduced\nTuring to the concept that led directly to the Turing machine: Newman\ndefined a constructive process as one that a machine can carry\nout (Newman in interview with Evans, op. cit.). As a result of his\nknowledge of Turing's work, Newman became interested in the\npossibilities of computing machinery in, as he put it, \u2018a rather\ntheoretical way\u2019. It was not until Newman joined GC&CS in\n1942 that his interest in computing machinery suddenly became\npractical, with his realisation that the attack on Tunny could be\nmechanised. During the building of Colossus, Newman tried to interest\nFlowers in Turing's 1936 paper \u2014 birthplace of the stored-program\nconcept - but Flowers did not make much of Turing's arcane notation.\nThere is no doubt that by 1943, Newman had firmly in mind the idea of\nusing electronic technology in order to construct a stored-program\ngeneral-purpose digital computing machine.\n\n\nIn July of 1946 (the month in which the Royal Society approved\nNewman's application for funds to found the Computing Machine\nLaboratory), Freddie Williams, working at the Telecommunications\nResearch Establishment, Malvern, began the series of experiments on\ncathode ray tube storage that was to lead to the Williams tube memory.\nWilliams, until then a radar engineer, explains how it was that he came\nto be working on the problem of computer memory:\n[O]nce [the German Armies] collapsed \u2026 nobody was\ngoing to care a toss about radar, and people like me \u2026 were\ngoing to be in the soup unless we found something else to do. And\ncomputers were in the air. Knowing absolutely nothing about them I\nlatched onto the problem of storage and tackled that. (Quoted in\nBennett 1976.)\n\n\nNewman learned of Williams' work, and with the able help of Patrick\nBlackett, Langworthy Professor of Physics at Manchester and one of the\nmost powerful figures in the University, was instrumental in the\nappointment of the 35 year old Williams to the recently vacated Chair\nof Electro-Technics at Manchester. (Both were members of the appointing\ncommittee (Kilburn in interview with Copeland, 1997).) Williams\nimmediately had Kilburn, his assistant at Malvern, seconded to\nManchester. To take up the story in Williams' own words:\n[N]either Tom Kilburn nor I knew the first thing about\ncomputers when we arrived in Manchester University. We'd had enough\nexplained to us to understand what the problem of storage was and what\nwe wanted to store, and that we'd achieved, so the point now had been\nreached when we'd got to find out about computers \u2026 Newman\nexplained the whole business of how a computer works to us. (F.C.\nWilliams in interview with Evans [1976])\n\n\nElsewhere Williams is explicit concerning Turing's role and gives\nsomething of the flavour of the explanation that he and Kilburn\nreceived:\nTom Kilburn and I knew nothing about computers, but a lot\nabout circuits. Professor Newman and Mr A.M. Turing \u2026 knew a lot\nabout computers and substantially nothing about electronics. They took\nus by the hand and explained how numbers could live in houses with\naddresses and how if they did they could be kept track of during a\ncalculation. (Williams [1975], p. 328)\n\n\nIt seems that Newman must have used much the same words with\nWilliams and Kilburn as he did in an address to the Royal Society on\n4th March 1948:\nProfessor Hartree \u2026 has recalled that all the\nessential ideas of the general-purpose calculating machines now being\nmade are to be found in Babbage's plans for his analytical engine. In\nmodern times the idea of a universal calculating machine was\nindependently introduced by Turing \u2026 [T]he machines now being\nmade in America and in this country \u2026 [are] in certain general\nrespects \u2026 all similar. There is provision for storing numbers,\nsay in the scale of 2, so that each number appears as a row of, say,\nforty 0's and 1's in certain places or \"houses\" in the machine.\n\u2026 Certain of these numbers, or \"words\" are read, one after\nanother, as orders. In one possible type of machine an order consists\nof four numbers, for example 11, 13, 27, 4. The number 4 signifies\n\"add\", and when control shifts to this word the \"houses\" H11 and H13\nwill be connected to the adder as inputs, and H27 as output. The\nnumbers stored in H11 and H13 pass through the adder, are added, and\nthe sum is passed on to H27. The control then shifts to the next order.\nIn most real machines the process just described would be done by three\nseparate orders, the first bringing [H11] (=content of H11) to a\ncentral accumulator, the second adding [H13] into the accumulator, and\nthe third sending the result to H27; thus only one address would be\nrequired in each order. \u2026 A machine with storage, with this\nautomatic-telephone-exchange arrangement and with the necessary adders,\nsubtractors and so on, is, in a sense, already a universal machine.\n(Newman [1948], pp. 271\u2013272)\n\n\nFollowing this explanation of Turing's three-address concept (source\n1, source 2, destination, function) Newman went on to describe program\nstorage (\u2018the orders shall be in a series of houses X1, X2,\n\u2026\u2019) and conditional branching. He then summed up:\nFrom this highly simplified account it emerges that the\nessential internal parts of the machine are, first, a storage for\nnumbers (which may also be orders). \u2026 Secondly, adders,\nmultipliers, etc. Thirdly, an \"automatic telephone exchange\" for\nselecting \"houses\", connecting them to the arithmetic organ, and\nwriting the answers in other prescribed houses. Finally, means of\nmoving control at any stage to any chosen order, if a certain condition\nis satisfied, otherwise passing to the next order in the normal\nsequence. Besides these there must be ways of setting up the machine at\nthe outset, and extracting the final answer in useable form. (Newman\n[1948], pp. 273\u20134)\n\n\nIn a letter written in 1972 Williams described in some detail what\nhe and Kilburn were told by Newman:\nAbout the middle of the year [1946] the possibility of an\nappointment at Manchester University arose and I had a talk with\nProfessor Newman who was already interested in the possibility of\ndeveloping computers and had acquired a grant from the Royal Society of\n\u00a330,000 for this purpose. Since he understood computers and I\nunderstood electronics the possibilities of fruitful collaboration were\nobvious. I remember Newman giving us a few lectures in which he\noutlined the organisation of a computer in terms of numbers being\nidentified by the address of the house in which they were placed and in\nterms of numbers being transferred from this address, one at a time, to\nan accumulator where each entering number was added to what was already\nthere. At any time the number in the accumulator could be transferred\nback to an assigned address in the store and the accumulator cleared\nfor further use. The transfers were to be effected by a stored program\nin which a list of instructions was obeyed sequentially. Ordered\nprogress through the list could be interrupted by a test instruction\nwhich examined the sign of the number in the accumulator. Thereafter\noperation started from a new point in the list of instructions. This\nwas the first information I received about the organisation of\ncomputers. \u2026 Our first computer was the simplest embodiment of\nthese principles, with the sole difference that it used a subtracting\nrather than an adding accumulator. (Letter from Williams to Randell,\n1972; in Randell [1972], p. 9)\n\n\nTuring's early input to the developments at Manchester, hinted at by\nWilliams in his above-quoted reference to Turing, may have been via the\nlectures on computer design that Turing and Wilkinson gave in London\nduring the period December 1946 to February 1947 (Turing and Wilkinson\n[1946\u20137]). The lectures were attended by representatives of\nvarious organisations planning to use or build an electronic computer.\nKilburn was in the audience (Bowker and Giordano [1993]). (Kilburn\nusually said, when asked from where he obtained his basic knowledge of\nthe computer, that he could not remember (letter from Brian Napper to\nCopeland, 2002); for example, in a 1992 interview he said:\n\u2018Between early 1945 and early 1947, in that period, somehow or\nother I knew what a digital computer was \u2026 Where I got this\nknowledge from I've no idea\u2019 (Bowker and Giordano [1993], p.\n19).)\n\n\nWhatever role Turing's lectures may have played in informing\nKilburn, there is little doubt that credit for the Manchester computer\n\u2014 called the \u2018Newman-Williams machine\u2019 in a\ncontemporary document (Huskey 1947) \u2014 belongs not only to\nWilliams and Kilburn but also to Newman, and that the influence on\nNewman of Turing's 1936 paper was crucial, as was the influence of\nFlowers' Colossus.\n\n\nThe first working AI program, a draughts (checkers) player written\nby Christopher Strachey, ran on the Ferranti Mark I in the Manchester\nComputing Machine Laboratory. Strachey (at the time a teacher at Harrow\nSchool and an amateur programmer) wrote the program with Turing's\nencouragement and utilising the latter's recently completed\nProgrammers' Handbook for the Ferranti. (Strachey later became Director\nof the Programming Research Group at Oxford University.) By the summer\nof 1952, the program could, Strachey reported, \u2018play a complete\ngame of draughts at a reasonable speed\u2019. (Strachey's program formed the\nbasis for Arthur Samuel's well-known checkers program.) The first\nchess-playing program, also, was written for the Manchester Ferranti,\nby Dietrich Prinz; the program first ran in November 1951. Designed for\nsolving simple problems of the mate-in-two variety, the program would\nexamine every possible move until a solution was found. Turing started\nto program his \u2018Turochamp\u2019 chess-player on the Ferranti\nMark I, but never completed the task. Unlike Prinz's program, the\nTurochamp could play a complete game (when hand-simulated) and operated\nnot by exhaustive search but under the guidance of heuristics.\nENIAC and EDVAC\n\n\nThe first fully functioning electronic digital computer to be built in\nthe U.S. was ENIAC, constructed at the Moore School of Electrical\nEngineering, University of Pennsylvania, for the Army Ordnance\nDepartment, by J. Presper Eckert and John Mauchly. Completed in 1945,\nENIAC was somewhat similar to the earlier Colossus, but considerably\nlarger and more flexible (although far from general-purpose). The\nprimary function for which ENIAC was designed was the calculation of\ntables used in aiming artillery. ENIAC was not a stored-program\ncomputer, and setting it up for a new job involved reconfiguring the\nmachine by means of plugs and switches. For many years, ENIAC was\nbelieved to have been the first functioning electronic digital\ncomputer, Colossus being unknown to all but a few. \n\n\nIn 1944, John von Neumann joined the ENIAC group. He had become\n\u2018intrigued\u2019 (Goldstine's word, [1972], p. 275) with\nTuring's universal machine while Turing was at Princeton University\nduring 1936\u20131938. At the Moore School, von Neumann emphasised the\nimportance of the stored-program concept for electronic computing,\nincluding the possibility of allowing the machine to modify its own\nprogram in useful ways while running (for example, in order to control\nloops and branching). Turing's paper of 1936 (\u2018On Computable\nNumbers, with an Application to the Entscheidungsproblem\u2019) was\nrequired reading for members of von Neumann's post-war computer project\nat the Institute for Advanced Study, Princeton University (letter from\nJulian Bigelow to Copeland, 2002; see also Copeland [2004], p. 23).\nEckert appears to have realised independently, and prior to von\nNeumann's joining the ENIAC group, that the way to take full advantage\nof the speed at which data is processed by electronic circuits is to\nplace suitably encoded instructions for controlling the processing in\nthe same high-speed storage devices that hold the data itself\n(documented in Copeland [2004], pp. 26\u20137). In 1945, while ENIAC\nwas still under construction, von Neumann produced a draft report,\nmentioned previously, setting out the ENIAC group's ideas for an\nelectronic stored-program general-purpose digital computer, the EDVAC\n(von Neuman [1945]). The EDVAC was completed six years later, but not\nby its originators, who left the Moore School to build computers\nelsewhere. Lectures held at the Moore School in 1946 on the proposed\nEDVAC were widely attended and contributed greatly to the dissemination\nof the new ideas.\n\n\nVon Neumann was a prestigious figure and he made the concept of a\nhigh-speed stored-program digital computer widely known through his\nwritings and public addresses. As a result of his high profile in the\nfield, it became customary, although historically inappropriate, to\nrefer to electronic stored-program digital computers as \u2018von\nNeumann machines\u2019.\n\n\nThe Los Alamos physicist Stanley Frankel, responsible with von\nNeumann and others for mechanising the large-scale calculations\ninvolved in the design of the atomic bomb, has described von Neumann's\nview of the importance of Turing's 1936 paper, in a letter:\nI know that in or about 1943 or \u201844 von Neumann was\nwell aware of the fundamental importance of Turing's paper of 1936\n\u2026 Von Neumann introduced me to that paper and at his urging I\nstudied it with care. Many people have acclaimed von Neumann as the\n\"father of the computer\" (in a modern sense of the term) but I am sure\nthat he would never have made that mistake himself. He might well be\ncalled the midwife, perhaps, but he firmly emphasized to me, and to\nothers I am sure, that the fundamental conception is owing to Turing,\nin so far as not anticipated by Babbage \u2026 Both Turing and von\nNeumann, of course, also made substantial contributions to the\n\"reduction to practice\" of these concepts but I would not regard these\nas comparable in importance with the introduction and explication of\nthe concept of a computer able to store in its memory its program of\nactivities and of modifying that program in the course of these\nactivities. (Quoted in Randell [1972], p. 10)\nOther Notable Early Computers\n\n\nOther notable early stored-program electronic digital computers were: \n\nEDSAC, 1949, built at Cambridge University by Maurice Wilkes\nBINAC, 1949, built by Eckert's and Mauchly's Electronic Control\nCo., Philadelphia (opinions differ over whether BINAC ever actually\nworked)\nWhirlwind I, 1949, Digital Computer Laboratory, Massachusetts\nInstitute of Technology, Jay Forrester\nSEAC, 1950, US Bureau of Standards Eastern Division, Washington\nD.C., Samuel Alexander, Ralph Slutz\nSWAC, 1950, US Bureau of Standards Western Division, Institute for\nNumerical Analysis, University of California at Los Angeles, Harry\nHuskey\nUNIVAC, 1951, Eckert-Mauchly Computer Corporation, Philadelphia\n(the first computer to be available commercially in the U.S.)\nthe IAS computer, 1952, Institute for Advanced Study, Princeton\nUniversity, Julian Bigelow, Arthur Burks, Herman Goldstine, von\nNeumann, and others (thanks to von Neumann's publishing the\nspecifications of the IAS machine, it became the model for a group of\ncomputers known as the Princeton Class machines; the IAS computer was\nalso a strong influence on the IBM 701)\nIBM 701, 1952, International Business Machine's first mass-produced\nelectronic stored-program computer.\n\nHigh-Speed Memory\n\n\nThe EDVAC and ACE proposals both advocated the use of mercury-filled\ntubes, called \u2018delay lines\u2019, for high-speed internal\nmemory. This form of memory is known as acoustic memory. Delay lines\nhad initially been developed for echo cancellation in radar; the idea\nof using them as memory devices originated with Eckert at the Moore\nSchool. Here is Turing's description: \nIt is proposed to build \"delay line\" units consisting of\nmercury \u2026 tubes about 5\u2032 long and 1\u2033 in diameter in\ncontact with a quartz crystal at each end. The velocity of sound in\n\u2026 mercury \u2026 is such that the delay will be 1.024 ms. The\ninformation to be stored may be considered to be a sequence of 1024\n\u2018digits\u2019 (0 or 1) \u2026 These digits will be represented\nby a corresponding sequence of pulses. The digit 0 \u2026 will be\nrepresented by the absence of a pulse at the appropriate time, the\ndigit 1 \u2026 by its presence. This series of pulses is impressed on\nthe end of the line by one piezo-crystal, it is transmitted down the\nline in the form of supersonic waves, and is reconverted into a varying\nvoltage by the crystal at the far end. This voltage is amplified\nsufficiently to give an output of the order of 10 volts peak to peak\nand is used to gate a standard pulse generated by the clock. This pulse\nmay be again fed into the line by means of the transmitting crystal, or\nwe may feed in some altogether different signal. We also have the\npossibility of leading the gated pulse to some other part of the\ncalculator, if we have need of that information at the time. Making use\nof the information does not of course preclude keeping it also. (Turing\n[1945], p. 375)\n\n\nMercury delay line memory was used in EDSAC, BINAC, SEAC, Pilot\nModel ACE, EDVAC, DEUCE, and full-scale ACE (1958). The chief advantage\nof the delay line as a memory medium was, as Turing put it, that delay\nlines were \"already a going concern\" (Turing [1947], p. 380). The\nfundamental disadvantages of the delay line were that random access is\nimpossible and, moreover, the time taken for an instruction, or number,\nto emerge from a delay line depends on where in the line it happens to\nbe.\n\n\nIn order to minimize waiting-time, Turing arranged for instructions\nto be stored not in consecutive positions in the delay line, but in\nrelative positions selected by the programmer in such a way that each\ninstruction would emerge at exactly the time it was required, in so far\nas this was possible. Each instruction contained a specification of the\nlocation of the next. This system subsequently became known as\n\u2018optimum coding\u2019. It was an integral feature of every\nversion of the ACE design. Optimum coding made for difficult and untidy\nprogramming, but the advantage in terms of speed was considerable.\nThanks to optimum coding, the Pilot Model ACE was able to do a floating\npoint multiplication in 3 milliseconds (Wilkes's EDSAC required 4.5\nmilliseconds to perform a single fixed point multiplication).\n\n\nIn the Williams tube or electrostatic memory, previously mentioned,\na two-dimensional rectangular array of binary digits was stored on the\nface of a commercially-available cathode ray tube. Access to data was\nimmediate. Williams tube memories were employed in the Manchester\nseries of machines, SWAC, the IAS computer, and the IBM 701, and a\nmodified form of Williams tube in Whirlwind I (until replacement by\nmagnetic core in 1953).\n\n\nDrum memories, in which data was stored magnetically on the surface\nof a metal cylinder, were developed on both sides of the Atlantic. The\ninitial idea appears to have been Eckert's. The drum provided\nreasonably large quantities of medium-speed memory and was used to\nsupplement a high-speed acoustic or electrostatic memory. In 1949, the\nManchester computer was successfully equipped with a drum memory; this\nwas constructed by the Manchester engineers on the model of a drum\ndeveloped by Andrew Booth at Birkbeck College, London.\n\n\nThe final major event in the early history of electronic computation\nwas the development of magnetic core memory. Jay Forrester realised\nthat the hysteresis properties of magnetic core (normally used in\ntransformers) lent themselves to the implementation of a\nthree-dimensional solid array of randomly accessible storage points. In\n1949, at Massachusetts Institute of Technology, he began to investigate\nthis idea empirically. Forrester's early experiments with metallic core\nsoon led him to develop the superior ferrite core memory. Digital\nEquipment Corporation undertook to build a computer similar to the\nWhirlwind I as a test vehicle for a ferrite core memory. The Memory\nTest Computer was completed in 1953. (This computer was used in 1954\nfor the first simulations of neural networks, by Belmont Farley and\nWesley Clark of MIT's Lincoln Laboratory (see Copeland and Proudfoot\n[1996]).\n\n\nOnce the absolute reliability, relative cheapness, high capacity and\npermanent life of ferrite core memory became apparent, core soon\nreplaced other forms of high-speed memory. The IBM 704 and 705\ncomputers (announced in May and October 1954, respectively) brought\ncore memory into wide use.\n",
    "bibliography": {
        "categories": [
            "Works Cited",
            "Further Reading"
        ],
        "cat_ref_text": {
            "Works Cited": [
                "</h3>\n<ul>",
                "Babbage, C. (ed. by Campbell-Kelly, M.), 1994, <em>Passages from\nthe Life of a Philosopher</em>, New Brunswick: Rutgers University\nPress",
                "Bennett, S., 1976, \u2018F.C. Williams: his contribution to the\ndevelopment of automatic control\u2019, National Archive for the\nHistory of Computing, University of Manchester, England. (This is a\ntypescript based on interviews with Williams in 1976.)",
                "Bowker, G., and Giordano, R., 1993, \u2018Interview with Tom\nKilburn\u2019, <em>Annals of the History of Computing</em>,\n<strong>15</strong>: 17\u201332.",
                "Copeland, B.J. (ed.), 2004, <em>The Essential Turing</em> Oxford\nUniversity Press",
                "Copeland, B.J. (ed.), 2005, <em>Alan Turing's Automatic Computing\nEngine: The Master Codebreaker's Struggle to Build the Modern\nComputer</em> Oxford University Press",
                "Copeland, B.J. and others, 2006, <em>Colossus: The Secrets of\nBletchley Park's Codebreaking Computers</em> Oxford University\nPress",
                "Copeland, B.J., and Proudfoot, D., 1996, \u2018On Alan Turing's\nAnticipation of Connectionism\u2019 <em>Synthese</em>,\n<strong>108</strong>: 361\u2013377",
                "Evans, C., 197?, interview with M.H.A. Newman in \u2018The\nPioneers of Computing: an Oral History of Computing\u2019, London:\nScience Museum",
                "Fifer, S., 1961, <em>Analog Computation: Theory, Techniques,\nApplications</em> New York: McGraw-Hill",
                "Ford, H., 1919, \u2018Mechanical Movement\u2019, <em>Official\nGazette of the United States Patent Office</em>, October 7, 1919:\n48",
                "Goldstine, H., 1972, <em>The Computer from Pascal to von\nNeumann</em> Princeton University Press",
                "Huskey, H.D., 1947, \u2018The State of the Art in Electronic\nDigital Computing in Britain and the United States\u2019, in [Copeland\n2005]",
                "Newman, M.H.A., 1948, \u2018General Principles of the Design of\nAll-Purpose Computing Machines\u2019 <em>Proceedings of the Royal\nSociety of London</em>, series A, <strong>195</strong> (1948):\n271\u2013274",
                "Randell, B., 1972, \u2018On Alan Turing and the Origins of Digital\nComputers\u2019, in Meltzer, B., Michie, D. (eds), <em>Machine\nIntelligence 7</em>, Edinburgh: Edinburgh University Press, 1972",
                "Smith, B.C., 1991, \u2018The Owl and the Electric\nEncyclopaedia\u2019, <em>Artificial Intelligence</em>,\n<strong>47</strong>: 251\u2013288",
                "Thomson, J., 1876, \u2018On an Integrating Machine Having a New\nKinematic Principle\u2019 <em>Proceedings of the Royal Society of\nLondon</em>, <strong>24</strong>: 262\u20135",
                "Turing, A.M., 1936, \u2018On Computable Numbers, with an\nApplication to the Entscheidungsproblem\u2019 <em>Proceedings of the\nLondon Mathematical Society</em>, Series 2, <strong>42</strong>\n(1936\u201337): 230\u2013265. Reprinted in <em>The Essential\nTuring</em> (Copeland [2004]).",
                "Turing, A.M, 1945, \u2018Proposed Electronic Calculator\u2019, in\n<em>Alan Turing's Automatic Computing Engine</em> (Copeland\n[2005])",
                "Turing, A.M., 1947, \u2018Lecture on the Automatic Computing\nEngine\u2019, in <em>The Essential Turing</em> (Copeland [2004])",
                "Turing, A.M., and Wilkinson, J.H., 1946\u20137, \u2018The\nTuring-Wilkinson Lecture Series (1946-7)\u2019, in <em>Alan Turing's\nAutomatic Computing Engine</em> (Copeland [2005])",
                "von Neumann, J., 1945, \u2018First Draft of a Report on the\nEDVAC\u2019, in Stern, N. <em>From ENIAC to UNIVAC: An Appraisal of\nthe Eckert-Mauchly Computers</em> Bedford, Mass.: Digital Press (1981),\npp. 181\u2013246",
                "Williams, F.C., 1975, \u2018Early Computers at Manchester\nUniversity\u2019 <em>The Radio and Electronic Engineer</em>,\n<strong>45</strong> (1975): 237\u2013331",
                "Wynn-Williams, C.E., 1932, \u2018A Thyratron \"Scale of Two\"\nAutomatic Counter\u2019 <em>Proceedings of the Royal Society of\nLondon</em>, series A, <strong>136</strong>: 312\u2013324\n</ul>\n<h3>"
            ],
            "Further Reading": [
                "</h3>\n<ul>",
                "Copeland, B.J., 2004, \u2018Colossus \u2014 Its Origins and\nOriginators\u2019 <em>Annals of the History of Computing</em>,\n<strong>26</strong>: 38\u201345",
                "Metropolis, N., Howlett, J., Rota, G.C. (eds), 1980, <em>A History\nof Computing in the Twentieth Century</em> New York: Academic\nPress",
                "Randell, B. (ed.), 1982, <em>The Origins of Digital Computers:\nSelected Papers</em> Berlin: Springer-Verlag",
                "Williams, M.R., 1997, <em>A History of Computing Technology</em>\nLos Alamitos: IEEE Computer Society Press\n</ul>\n</div>"
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2><a name=\"Bib\">Bibliography</a></h2>\n<h3>Works Cited</h3>\n<ul>\n<li>Babbage, C. (ed. by Campbell-Kelly, M.), 1994, <em>Passages from\nthe Life of a Philosopher</em>, New Brunswick: Rutgers University\nPress</li>\n<li>Bennett, S., 1976, \u2018F.C. Williams: his contribution to the\ndevelopment of automatic control\u2019, National Archive for the\nHistory of Computing, University of Manchester, England. (This is a\ntypescript based on interviews with Williams in 1976.)</li>\n<li>Bowker, G., and Giordano, R., 1993, \u2018Interview with Tom\nKilburn\u2019, <em>Annals of the History of Computing</em>,\n<strong>15</strong>: 17\u201332.</li>\n<li>Copeland, B.J. (ed.), 2004, <em>The Essential Turing</em> Oxford\nUniversity Press</li>\n<li>Copeland, B.J. (ed.), 2005, <em>Alan Turing's Automatic Computing\nEngine: The Master Codebreaker's Struggle to Build the Modern\nComputer</em> Oxford University Press</li>\n<li>Copeland, B.J. and others, 2006, <em>Colossus: The Secrets of\nBletchley Park's Codebreaking Computers</em> Oxford University\nPress</li>\n<li>Copeland, B.J., and Proudfoot, D., 1996, \u2018On Alan Turing's\nAnticipation of Connectionism\u2019 <em>Synthese</em>,\n<strong>108</strong>: 361\u2013377</li>\n<li>Evans, C., 197?, interview with M.H.A. Newman in \u2018The\nPioneers of Computing: an Oral History of Computing\u2019, London:\nScience Museum</li>\n<li>Fifer, S., 1961, <em>Analog Computation: Theory, Techniques,\nApplications</em> New York: McGraw-Hill</li>\n<li>Ford, H., 1919, \u2018Mechanical Movement\u2019, <em>Official\nGazette of the United States Patent Office</em>, October 7, 1919:\n48</li>\n<li>Goldstine, H., 1972, <em>The Computer from Pascal to von\nNeumann</em> Princeton University Press</li>\n<li>Huskey, H.D., 1947, \u2018The State of the Art in Electronic\nDigital Computing in Britain and the United States\u2019, in [Copeland\n2005]</li>\n<li>Newman, M.H.A., 1948, \u2018General Principles of the Design of\nAll-Purpose Computing Machines\u2019 <em>Proceedings of the Royal\nSociety of London</em>, series A, <strong>195</strong> (1948):\n271\u2013274</li>\n<li>Randell, B., 1972, \u2018On Alan Turing and the Origins of Digital\nComputers\u2019, in Meltzer, B., Michie, D. (eds), <em>Machine\nIntelligence 7</em>, Edinburgh: Edinburgh University Press, 1972</li>\n<li>Smith, B.C., 1991, \u2018The Owl and the Electric\nEncyclopaedia\u2019, <em>Artificial Intelligence</em>,\n<strong>47</strong>: 251\u2013288</li>\n<li>Thomson, J., 1876, \u2018On an Integrating Machine Having a New\nKinematic Principle\u2019 <em>Proceedings of the Royal Society of\nLondon</em>, <strong>24</strong>: 262\u20135</li>\n<li>Turing, A.M., 1936, \u2018On Computable Numbers, with an\nApplication to the Entscheidungsproblem\u2019 <em>Proceedings of the\nLondon Mathematical Society</em>, Series 2, <strong>42</strong>\n(1936\u201337): 230\u2013265. Reprinted in <em>The Essential\nTuring</em> (Copeland [2004]).</li>\n<li>Turing, A.M, 1945, \u2018Proposed Electronic Calculator\u2019, in\n<em>Alan Turing's Automatic Computing Engine</em> (Copeland\n[2005])</li>\n<li>Turing, A.M., 1947, \u2018Lecture on the Automatic Computing\nEngine\u2019, in <em>The Essential Turing</em> (Copeland [2004])</li>\n<li>Turing, A.M., and Wilkinson, J.H., 1946\u20137, \u2018The\nTuring-Wilkinson Lecture Series (1946-7)\u2019, in <em>Alan Turing's\nAutomatic Computing Engine</em> (Copeland [2005])</li>\n<li>von Neumann, J., 1945, \u2018First Draft of a Report on the\nEDVAC\u2019, in Stern, N. <em>From ENIAC to UNIVAC: An Appraisal of\nthe Eckert-Mauchly Computers</em> Bedford, Mass.: Digital Press (1981),\npp. 181\u2013246</li>\n<li>Williams, F.C., 1975, \u2018Early Computers at Manchester\nUniversity\u2019 <em>The Radio and Electronic Engineer</em>,\n<strong>45</strong> (1975): 237\u2013331</li>\n<li>Wynn-Williams, C.E., 1932, \u2018A Thyratron \"Scale of Two\"\nAutomatic Counter\u2019 <em>Proceedings of the Royal Society of\nLondon</em>, series A, <strong>136</strong>: 312\u2013324</li>\n</ul>\n<h3>Further Reading</h3>\n<ul>\n<li>Copeland, B.J., 2004, \u2018Colossus \u2014 Its Origins and\nOriginators\u2019 <em>Annals of the History of Computing</em>,\n<strong>26</strong>: 38\u201345</li>\n<li>Metropolis, N., Howlett, J., Rota, G.C. (eds), 1980, <em>A History\nof Computing in the Twentieth Century</em> New York: Academic\nPress</li>\n<li>Randell, B. (ed.), 1982, <em>The Origins of Digital Computers:\nSelected Papers</em> Berlin: Springer-Verlag</li>\n<li>Williams, M.R., 1997, <em>A History of Computing Technology</em>\nLos Alamitos: IEEE Computer Society Press</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "computability and complexity",
            "recursive functions",
            "Turing, Alan",
            "Turing machines"
        ],
        "entry_link": [
            {
                "../computability/": "computability and complexity"
            },
            {
                "../recursive-functions/": "recursive functions"
            },
            {
                "../turing/": "Turing, Alan"
            },
            {
                "../turing-machine/": "Turing machines"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<td valign=\"top\"><img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=computing-history\" target=\"other\">How to cite this entry</a>.",
            "<td valign=\"top\"><img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/computing-history/\" target=\"other\">Preview the PDF version of this entry</a> at the <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<td valign=\"top\"><img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=computing-history&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<td valign=\"top\"><img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"http://philpapers.org/sep/computing-history/\" target=\"other\">Enhanced bibliography for this entry</a> at <a href=\"http://philpapers.org\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=computing-history": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/computing-history/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=computing-history&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "http://philpapers.org/sep/computing-history/": "Enhanced bibliography for this entry"
            },
            {
                "http://philpapers.org": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "<a href=\"http://www.turing.org.uk/turing/\" target=\"other\">The Alan Turing Home Page</a>",
            "<a href=\"https://www.acms.org.au/\" target=\"other\">Australian Computer Museum Society</a>",
            "<a href=\"https://bletchleypark.org.uk/\" target=\"other\">The Bletchley Park Home Page</a>",
            "<a href=\"http://www.cbi.umn.edu/\" target=\"other\">Charles Babbage Institute</a>",
            "<a href=\"http://cryptocellar.org/\" target=\"other\">Frode Weierud's CryptoCellar</a>",
            "<a href=\"http://www.cis.upenn.edu/~lc/home.html\" target=\"other\">Logic and Computation Group at Penn</a>",
            "<a href=\"http://www.chstm.manchester.ac.uk/research/nahc/\" target=\"other\">National Archive for the History of Computing</a>",
            "<a href=\"https://www.nsa.gov/about/cryptologic-heritage/museum/\" target=\"other\">National Cryptologic Museum</a>"
        ],
        "listed_links": [
            {
                "http://www.turing.org.uk/turing/": "The Alan Turing Home Page"
            },
            {
                "https://www.acms.org.au/": "Australian Computer Museum Society"
            },
            {
                "https://bletchleypark.org.uk/": "The Bletchley Park Home Page"
            },
            {
                "http://www.cbi.umn.edu/": "Charles Babbage Institute"
            },
            {
                "http://cryptocellar.org/": "Frode Weierud's CryptoCellar"
            },
            {
                "http://www.cis.upenn.edu/~lc/home.html": "Logic and Computation Group at Penn"
            },
            {
                "http://www.chstm.manchester.ac.uk/research/nahc/": "National Archive for the History of Computing"
            },
            {
                "https://www.nsa.gov/about/cryptologic-heritage/museum/": "National Cryptologic Museum"
            }
        ]
    }
}