{
    "main_text": "Main Debates || Artificial Moral Agents\n2.9 Artificial Moral Agents\n\nIf\n one takes machine ethics to concern moral agents, in some substantial\nsense, then these agents can be called \u201cartificial moral\nagents\u201d, having rights and responsibilities. However, the\ndiscussion about artificial entities challenges a number of common\nnotions in ethics and it can be very useful to understand these in\nabstraction from the human case (cf. Misselhorn 2020; Powers and\nGanascia forthcoming).\n\nSeveral authors use \u201cartificial moral agent\u201d in a less\ndemanding sense, borrowing from the use of \u201cagent\u201d in\nsoftware engineering in which case matters of responsibility and\nrights will not arise (Allen, Varner, and Zinser 2000). James Moor\n(2006) distinguishes four types of machine agents: ethical impact\nagents (e.g., robot jockeys), implicit ethical agents (e.g., safe\nautopilot), explicit ethical agents (e.g., using formal methods to\nestimate utility), and full ethical agents (who \u201ccan make\nexplicit ethical judgments and generally is competent to reasonably\njustify them. An average adult human is a full ethical agent\u201d.)\nSeveral ways to achieve \u201cexplicit\u201d or \u201cfull\u201d\nethical agents have been proposed, via programming it in (operational\nmorality), via \u201cdeveloping\u201d the ethics itself (functional\nmorality), and finally full-blown morality with full intelligence and\nsentience (Allen, Smit, and Wallach 2005; Moor 2006). Programmed\nagents are sometimes not considered \u201cfull\u201d agents because\nthey are \u201ccompetent without comprehension\u201d, just like the\nneurons in a brain (Dennett 2017; Hakli and M\u00e4kel\u00e4\n2019).\n\nIn some discussions, the notion of \u201cmoral patient\u201d plays a\nrole: Ethical agents have responsibilities while ethical\npatients have rights because harm to them matters. It seems\nclear that some entities are patients without being agents, e.g.,\nsimple animals that can feel pain but cannot make justified choices.\nOn the other hand, it is normally understood that all agents will also\nbe patients (e.g., in a Kantian framework). Usually, being a person is\nsupposed to be what makes an entity a responsible agent, someone who\ncan have duties and be the object of ethical concerns. Such personhood\nis typically a deep notion associated with phenomenal consciousness,\nintention and free will (Frankfurt 1971; Strawson 1998). Torrance\n(2011) suggests \u201cartificial (or machine) ethics could be defined\nas designing machines that do things that, when done by humans, are\nindicative of the possession of \u2018ethical status\u2019 in those\nhumans\u201d (2011: 116)\u2014which he takes to be \u201cethical\nproductivity and ethical receptivity\u201d (2011:\n117)\u2014his expressions for moral agents and patients.\n2.9.1 Responsibility for Robots\n\nThere is broad consensus that accountability, liability, and the rule\nof law are basic requirements that must be upheld in the face of new\ntechnologies (European Group on Ethics in Science and New Technologies\n2018, 18), but the issue in the case of robots is how this can be done\nand how responsibility can be allocated. If the robots act, will they\nthemselves be responsible, liable, or accountable for their actions?\nOr should the distribution of risk perhaps take precedence over\ndiscussions of responsibility?\n\nTraditional distribution of responsibility already occurs: A car maker\nis responsible for the technical safety of the car, a driver is\nresponsible for driving, a mechanic is responsible for proper\nmaintenance, the public authorities are responsible for the technical\nconditions of the roads, etc. In general\n\n\nThe effects of decisions or actions based on AI are often the result\nof countless interactions among many actors, including designers,\ndevelopers, users, software, and hardware.\u2026 With distributed\nagency comes distributed responsibility. (Taddeo and Floridi 2018:\n751).\n\n\nHow this distribution might occur is not a problem that is specific to\nAI, but it gains particular urgency in this context (Nyholm 2018a,\n2018b). In classical control engineering, distributed control is often\nachieved through a control hierarchy plus control loops across these\nhierarchies.\n2.9.2 Rights for Robots\n\nSome authors have indicated that it should be seriously considered\nwhether current robots must be allocated rights (Gunkel 2018a, 2018b;\nDanaher forthcoming; Turner 2019). This position seems to rely largely\non criticism of the opponents and on the empirical observation that\nrobots and other non-persons are sometimes treated as having rights.\nIn this vein, a \u201crelational turn\u201d has been proposed: If we\nrelate to robots as though they had rights, then we might be\nwell-advised not to search whether they \u201creally\u201d do have\nsuch rights (Coeckelbergh 2010, 2012, 2018). This raises the question\nhow far such anti-realism or quasi-realism can go, and what it means\nthen to say that \u201crobots have rights\u201d in a human-centred\napproach (Gerdes 2016). On the other side of the debate, Bryson has\ninsisted that robots should not enjoy rights (Bryson 2010), though she\nconsiders it a possibility (Gunkel and Bryson 2014).\n\nThere is a wholly separate issue whether robots (or other AI systems)\nshould be given the status of \u201clegal entities\u201d or\n\u201clegal persons\u201d in a sense natural persons, but also\nstates, businesses, or organisations are \u201centities\u201d,\nnamely they can have legal rights and duties. The European Parliament\nhas considered allocating such status to robots in order to deal with\ncivil liability (EU Parliament 2016; Bertolini and Aiello 2018), but\nnot criminal liability\u2014which is reserved for natural persons. It\nwould also be possible to assign only a certain subset of rights and\nduties to robots. It has been said that \u201csuch legislative action\nwould be morally unnecessary and legally troublesome\u201d because it\nwould not serve the interest of humans (Bryson, Diamantis, and Grant\n2017: 273). In environmental ethics there is a long-standing\ndiscussion about the legal rights for natural objects like trees (C.\nD. Stone 1972).\n\nIt has also been said that the reasons for developing robots with\nrights, or artificial moral patients, in the future are ethically\ndoubtful (van Wynsberghe and Robbins 2019). In the community of\n\u201cartificial consciousness\u201d researchers there is a\nsignificant concern whether it would be ethical to create such\nconsciousness since creating it would presumably imply ethical\nobligations to a sentient being, e.g., not to harm it and not to end\nits existence by switching it off\u2014some authors have called for a\n\u201cmoratorium on synthetic phenomenology\u201d (Bentley et al.\n2018: 28f).\n2.10 Singularity\n2.10.1 Singularity and Superintelligence\n\nIn some quarters, the aim of current AI is thought to be an\n\u201cartificial general intelligence\u201d (AGI), contrasted to a\ntechnical or \u201cnarrow\u201d AI. AGI is usually distinguished\nfrom traditional notions of AI as a general purpose system, and from\nSearle\u2019s notion of \u201cstrong AI\u201d:\n\n\ncomputers given the right programs can be literally said to\nunderstand and have other cognitive states. (Searle 1980:\n417)\n\n\nThe idea of singularity is that if the trajectory of\nartificial intelligence reaches up to systems that have a human level\nof intelligence, then these systems would themselves have the ability\nto develop AI systems that surpass the human level of intelligence,\ni.e., they are \u201csuperintelligent\u201d (see below). Such\nsuperintelligent AI systems would quickly self-improve or develop even\nmore intelligent systems. This sharp turn of events after reaching\nsuperintelligent AI is the \u201csingularity\u201d from which the\ndevelopment of AI is out of human control and hard to predict\n(Kurzweil 2005: 487).\n\nThe fear that \u201cthe robots we created will take over the\nworld\u201d had captured human imagination even before there were\ncomputers (e.g., Butler 1863) and is the central theme in\n\u010capek\u2019s famous play that introduced the word\n\u201crobot\u201d (\u010capek 1920). This fear was first formulated\nas a possible trajectory of existing AI into an \u201cintelligence\nexplosion\u201d by Irvin Good:\n\n\nLet an ultraintelligent machine be defined as a machine that can far\nsurpass all the intellectual activities of any man however clever.\nSince the design of machines is one of these intellectual activities,\nan ultraintelligent machine could design even better machines; there\nwould then unquestionably be an \u201cintelligence explosion\u201d,\nand the intelligence of man would be left far behind. Thus the first\nultraintelligent machine is the last invention that man need ever\nmake, provided that the machine is docile enough to tell us how to\nkeep it under control. (Good 1965: 33)\n\n\nThe optimistic argument from acceleration to singularity is spelled\nout by Kurzweil (1999, 2005, 2012) who essentially points out that\ncomputing power has been increasing exponentially, i.e., doubling ca.\nevery 2 years since 1970 in accordance with \u201cMoore\u2019s\nLaw\u201d on the number of transistors, and will continue to do so\nfor some time in the future. He predicted in (Kurzweil 1999) that by\n2010 supercomputers will reach human computation capacity, by 2030\n\u201cmind uploading\u201d will be possible, and by 2045 the\n\u201csingularity\u201d will occur. Kurzweil talks about an increase\nin computing power that can be purchased at a given cost\u2014but of\ncourse in recent years the funds available to AI companies have also\nincreased enormously: Amodei and Hernandez (2018 [OIR]) thus estimate\nthat in the years 2012\u20132018 the actual computing power available\nto train a particular AI system doubled every 3.4 months, resulting in\nan 300,000x increase\u2014not the 7x increase that doubling every two\nyears would have created.\n\nA common version of this argument (Chalmers 2010) talks about an\nincrease in \u201cintelligence\u201d of the AI system (rather than\nraw computing power), but the crucial point of\n\u201csingularity\u201d remains the one where further development of\nAI is taken over by AI systems and accelerates beyond human level.\nBostrom (2014) explains in some detail what would happen at that point\nand what the risks for humanity are. The discussion is summarised in\nEden et al. (2012); Armstrong (2014); Shanahan (2015). There are\npossible paths to superintelligence other than computing power\nincrease, e.g., the complete emulation of the human brain on a\ncomputer (Kurzweil 2012; Sandberg 2013), biological paths, or networks\nand organisations (Bostrom 2014: 22\u201351).\n\nDespite obvious weaknesses in the identification of\n\u201cintelligence\u201d with processing power, Kurzweil seems right\nthat humans tend to underestimate the power of exponential growth.\nMini-test: If you walked in steps in such a way that each step is\ndouble the previous, starting with a step of one metre, how far would\nyou get with 30 steps? (answer: almost 3 times further than the\nEarth\u2019s only permanent natural satellite.) Indeed, most progress\nin AI is readily attributable to the availability of processors that\nare faster by degrees of magnitude, larger storage, and higher\ninvestment (M\u00fcller 2018). The actual acceleration and its speeds\nare discussed in (M\u00fcller and Bostrom 2016; Bostrom, Dafoe, and\nFlynn forthcoming); Sandberg (2019) argues that progress will continue\nfor some time.\n\nThe participants in this debate are united by being technophiles in\nthe sense that they expect technology to develop rapidly and bring\nbroadly welcome changes\u2014but beyond that, they divide into those\nwho focus on benefits (e.g., Kurzweil) and those who focus on risks\n(e.g., Bostrom). Both camps sympathise with \u201ctranshuman\u201d\nviews of survival for humankind in a different physical form, e.g.,\nuploaded on a computer (Moravec 1990, 1998; Bostrom 2003a, 2003c).\nThey also consider the prospects of \u201chuman enhancement\u201d in\nvarious respects, including intelligence\u2014often called\n\u201cIA\u201d (intelligence augmentation). It may be that future AI\nwill be used for human enhancement, or will contribute further to the\ndissolution of the neatly defined human single person. Robin Hanson\nprovides detailed speculation about what will happen economically in\ncase human \u201cbrain emulation\u201d enables truly intelligent\nrobots or \u201cems\u201d (Hanson 2016).\n\nThe argument from superintelligence to risk requires the assumption\nthat superintelligence does not imply benevolence\u2014contrary to\nKantian traditions in ethics that have argued higher levels of\nrationality or intelligence would go along with a better understanding\nof what is moral and better ability to act morally (Gewirth 1978;\nChalmers 2010: 36f). Arguments for risk from superintelligence say\nthat rationality and morality are entirely independent\ndimensions\u2014this is sometimes explicitly argued for as an\n\u201corthogonality thesis\u201d (Bostrom 2012; Armstrong 2013;\nBostrom 2014: 105\u2013109).\n\nCriticism of the singularity narrative has been raised from various\nangles. Kurzweil and Bostrom seem to assume that intelligence is a\none-dimensional property and that the set of intelligent agents is\ntotally-ordered in the mathematical sense\u2014but neither discusses\nintelligence at any length in their books. Generally, it is fair to\nsay that despite some efforts, the assumptions made in the powerful\nnarrative of superintelligence and singularity have not been\ninvestigated in detail. One question is whether such a singularity\nwill ever occur\u2014it may be conceptually impossible, practically\nimpossible or may just not happen because of contingent events,\nincluding people actively preventing it. Philosophically, the\ninteresting question is whether singularity is just a\n\u201cmyth\u201d (Floridi 2016; Ganascia 2017), and not on the\ntrajectory of actual AI research. This is something that practitioners\noften assume (e.g., Brooks 2017 [OIR]). They may do so because they\nfear the public relations backlash, because they overestimate the\npractical problems, or because they have good reasons to think that\nsuperintelligence is an unlikely outcome of current AI research\n(M\u00fcller forthcoming-a). This discussion raises the question\nwhether the concern about \u201csingularity\u201d is just a\nnarrative about fictional AI based on human fears. But even if one\ndoes find negative reasons compelling and the singularity not\nlikely to occur, there is still a significant possibility that one may\nturn out to be wrong. Philosophy is not on the \u201csecure path of a\nscience\u201d (Kant 1791: B15), and maybe AI and robotics\naren\u2019t either (M\u00fcller 2020). So, it appears that discussing\nthe very high-impact risk of singularity has justification even\nif one thinks the probability of such singularity ever occurring\nis very low.\n2.10.2 Existential Risk from Superintelligence\n\nThinking about superintelligence in the long term raises the question\nwhether superintelligence may lead to the extinction of the human\nspecies, which is called an \u201cexistential risk\u201d (or XRisk):\nThe superintelligent systems may well have preferences that conflict\nwith the existence of humans on Earth, and may thus decide to end that\nexistence\u2014and given their superior intelligence, they will have\nthe power to do so (or they may happen to end it because they do not\nreally care).\n\nThinking in the long term is the crucial feature of this literature.\nWhether the singularity (or another catastrophic event) occurs in 30\nor 300 or 3000 years does not really matter (Baum et al. 2019).\nPerhaps there is even an astronomical pattern such that an intelligent\nspecies is bound to discover AI at some point, and thus bring about\nits own demise. Such a \u201cgreat filter\u201d would contribute to\nthe explanation of the \u201cFermi paradox\u201d why there is no\nsign of life in the known universe despite the high probability of it\nemerging. It would be bad news if we found out that the \u201cgreat\nfilter\u201d is ahead of us, rather than an obstacle that Earth has\nalready passed. These issues are sometimes taken more narrowly to be\nabout human extinction (Bostrom 2013), or more broadly as concerning\nany large risk for the species (Rees 2018)\u2014of which AI is only\none (H\u00e4ggstr\u00f6m 2016; Ord 2020). Bostrom also uses the\ncategory of \u201cglobal catastrophic risk\u201d for risks that are\nsufficiently high up the two dimensions of \u201cscope\u201d and\n\u201cseverity\u201d (Bostrom and \u0106irkovi\u0107 2011; Bostrom\n2013).\n\nThese discussions of risk are usually not connected to the general\nproblem of ethics under risk (e.g., Hansson 2013, 2018). The long-term\nview has its own methodological challenges but has produced a wide\ndiscussion: (Tegmark 2017) focuses on AI and human life\n\u201c3.0\u201d after singularity while Russell, Dewey, and Tegmark\n(2015) and Bostrom, Dafoe, and Flynn (forthcoming) survey longer-term\npolicy issues in ethical AI. Several collections of papers have\ninvestigated the risks of artificial general intelligence (AGI) and\nthe factors that might make this development more or less risk-laden\n(M\u00fcller 2016b; Callaghan et al. 2017; Yampolskiy 2018), including\nthe development of non-agent AI (Drexler 2019).\n2.10.3 Controlling Superintelligence?\n\nIn a narrow sense, the \u201ccontrol problem\u201d is how we humans\ncan remain in control of an AI system once it is superintelligent\n(Bostrom 2014: 127ff). In a wider sense, it is the problem of how we\ncan make sure an AI system will turn out to be positive according to\nhuman perception (Russell 2019); this is sometimes called \u201cvalue\nalignment\u201d. How easy or hard it is to control a\nsuperintelligence depends significantly on the speed of\n\u201ctake-off\u201d to a superintelligent system. This has led to\nparticular attention to systems with self-improvement, such as\nAlphaZero (Silver et al. 2018).\n\nOne aspect of this problem is that we might decide a certain feature\nis desirable, but then find out that it has unforeseen consequences\nthat are so negative that we would not desire that feature after all.\nThis is the ancient problem of King Midas who wished that all he\ntouched would turn into gold. This problem has been discussed on the\noccasion of various examples, such as the \u201cpaperclip\nmaximiser\u201d (Bostrom 2003b), or the program to optimise chess\nperformance (Omohundro 2014).\n\nDiscussions about superintelligence include speculation about\nomniscient beings, the radical changes on a \u201clatter day\u201d,\nand the promise of immortality through transcendence of our current\nbodily form\u2014so sometimes they have clear religious undertones\n(Capurro 1993; Geraci 2008, 2010; O\u2019Connell 2017: 160ff). These\nissues also pose a well-known problem of epistemology: Can we know the\nways of the omniscient (Danaher 2015)? The usual opponents have\nalready shown up: A characteristic response of an atheist is\n\n\nPeople worry that computers will get too smart and take over the\nworld, but the real problem is that they\u2019re too stupid and\nthey\u2019ve already taken over the world (Domingos 2015)\n\n\nThe new nihilists explain that a \u201ctechno-hypnosis\u201d through\ninformation technologies has now become our main method of distraction\nfrom the loss of meaning (Gertz 2018). Both opponents would thus say\nwe need an ethics for the \u201csmall\u201d problems that occur with\nactual AI and robotics\n (sections 2.1 through 2.9\n above), and that there is less need for the \u201cbig ethics\u201d\nof existential risk from AI\n (section 2.10).\n3. Closing\n\nThe singularity thus raises the problem of the concept of AI again. It\nis remarkable how imagination or \u201cvision\u201d has played a\ncentral role since the very beginning of the discipline at the\n\u201cDartmouth Summer Research Project\u201d (McCarthy et al. 1955\n[OIR]; Simon and Newell 1958). And the evaluation of this vision is\nsubject to dramatic change: In a few decades, we went from the slogans\n\u201cAI is impossible\u201d (Dreyfus 1972) and \u201cAI is just\nautomation\u201d (Lighthill 1973) to \u201cAI will solve all\nproblems\u201d (Kurzweil 1999) and \u201cAI may kill us all\u201d\n(Bostrom 2014). This created media attention and public relations\nefforts, but it also raises the problem of how much of this\n\u201cphilosophy and ethics of AI\u201d is really about AI rather\nthan about an imagined technology. As we said at the outset, AI and\nrobotics have raised fundamental questions about what we should do\nwith these systems, what the systems themselves should do, and what\nrisks they have in the long term. They also challenge the human view\nof humanity as the intelligent and dominant species on Earth. We have\nseen issues that have been raised and will have to watch technological\nand social developments closely to catch the new issues early on,\ndevelop a philosophical analysis, and learn for traditional problems\nof philosophy.",
    "section_title": "2.9 Artificial Moral Agents",
    "entry_title": "Ethics of Artificial Intelligence and Robotics",
    "hierarchy_title": "Ethics of Artificial Intelligence and Robotics || Main Debates || Artificial Moral Agents",
    "tokenized_text": [
        "main",
        "debate",
        "artificial",
        "moral",
        "agent",
        "artificial",
        "moral",
        "agent",
        "one",
        "take",
        "machine",
        "ethic",
        "concern",
        "moral",
        "agent",
        "substantial",
        "sense",
        "agent",
        "called",
        "artificial",
        "moral",
        "agent",
        "right",
        "responsibility",
        "however",
        "discussion",
        "artificial",
        "entity",
        "challenge",
        "number",
        "common",
        "notion",
        "ethic",
        "useful",
        "understand",
        "abstraction",
        "human",
        "case",
        "cf",
        "misselhorn",
        "power",
        "ganascia",
        "forthcoming",
        "several",
        "author",
        "use",
        "artificial",
        "moral",
        "agent",
        "le",
        "demanding",
        "sense",
        "borrowing",
        "use",
        "agent",
        "software",
        "engineering",
        "case",
        "matter",
        "responsibility",
        "right",
        "arise",
        "allen",
        "varner",
        "zinser",
        "james",
        "moor",
        "distinguishes",
        "four",
        "type",
        "machine",
        "agent",
        "ethical",
        "impact",
        "agent",
        "eg",
        "robot",
        "jockey",
        "implicit",
        "ethical",
        "agent",
        "eg",
        "safe",
        "autopilot",
        "explicit",
        "ethical",
        "agent",
        "eg",
        "using",
        "formal",
        "method",
        "estimate",
        "utility",
        "full",
        "ethical",
        "agent",
        "make",
        "explicit",
        "ethical",
        "judgment",
        "generally",
        "competent",
        "reasonably",
        "justify",
        "average",
        "adult",
        "human",
        "full",
        "ethical",
        "agent",
        "several",
        "way",
        "achieve",
        "explicit",
        "full",
        "ethical",
        "agent",
        "proposed",
        "via",
        "programming",
        "operational",
        "morality",
        "via",
        "developing",
        "ethic",
        "functional",
        "morality",
        "finally",
        "fullblown",
        "morality",
        "full",
        "intelligence",
        "sentience",
        "allen",
        "smit",
        "wallach",
        "moor",
        "programmed",
        "agent",
        "sometimes",
        "considered",
        "full",
        "agent",
        "competent",
        "without",
        "comprehension",
        "like",
        "neuron",
        "brain",
        "dennett",
        "hakli",
        "m\u00e4kel\u00e4",
        "discussion",
        "notion",
        "moral",
        "patient",
        "play",
        "role",
        "ethical",
        "agent",
        "responsibility",
        "ethical",
        "patient",
        "right",
        "harm",
        "matter",
        "seems",
        "clear",
        "entity",
        "patient",
        "without",
        "agent",
        "eg",
        "simple",
        "animal",
        "feel",
        "pain",
        "make",
        "justified",
        "choice",
        "hand",
        "normally",
        "understood",
        "agent",
        "also",
        "patient",
        "eg",
        "kantian",
        "framework",
        "usually",
        "person",
        "supposed",
        "make",
        "entity",
        "responsible",
        "agent",
        "someone",
        "duty",
        "object",
        "ethical",
        "concern",
        "personhood",
        "typically",
        "deep",
        "notion",
        "associated",
        "phenomenal",
        "consciousness",
        "intention",
        "free",
        "frankfurt",
        "strawson",
        "torrance",
        "suggests",
        "artificial",
        "machine",
        "ethic",
        "could",
        "defined",
        "designing",
        "machine",
        "thing",
        "done",
        "human",
        "indicative",
        "possession",
        "ethical",
        "status",
        "human",
        "which",
        "take",
        "ethical",
        "productivity",
        "ethical",
        "receptivity",
        "his",
        "expression",
        "moral",
        "agent",
        "patient",
        "responsibility",
        "robot",
        "broad",
        "consensus",
        "accountability",
        "liability",
        "rule",
        "law",
        "basic",
        "requirement",
        "must",
        "upheld",
        "face",
        "new",
        "technology",
        "european",
        "group",
        "ethic",
        "science",
        "new",
        "technology",
        "issue",
        "case",
        "robot",
        "done",
        "responsibility",
        "allocated",
        "robot",
        "act",
        "responsible",
        "liable",
        "accountable",
        "action",
        "distribution",
        "risk",
        "perhaps",
        "take",
        "precedence",
        "discussion",
        "responsibility",
        "traditional",
        "distribution",
        "responsibility",
        "already",
        "occurs",
        "car",
        "maker",
        "responsible",
        "technical",
        "safety",
        "car",
        "driver",
        "responsible",
        "driving",
        "mechanic",
        "responsible",
        "proper",
        "maintenance",
        "public",
        "authority",
        "responsible",
        "technical",
        "condition",
        "road",
        "etc",
        "general",
        "effect",
        "decision",
        "action",
        "based",
        "ai",
        "often",
        "result",
        "countless",
        "interaction",
        "among",
        "many",
        "actor",
        "including",
        "designer",
        "developer",
        "user",
        "software",
        "hardware",
        "distributed",
        "agency",
        "come",
        "distributed",
        "responsibility",
        "taddeo",
        "floridi",
        "distribution",
        "might",
        "occur",
        "problem",
        "specific",
        "ai",
        "gain",
        "particular",
        "urgency",
        "context",
        "nyholm",
        "a",
        "b",
        "classical",
        "control",
        "engineering",
        "distributed",
        "control",
        "often",
        "achieved",
        "control",
        "hierarchy",
        "plus",
        "control",
        "loop",
        "across",
        "hierarchy",
        "right",
        "robot",
        "author",
        "indicated",
        "seriously",
        "considered",
        "whether",
        "current",
        "robot",
        "must",
        "allocated",
        "right",
        "gunkel",
        "a",
        "b",
        "danaher",
        "forthcoming",
        "turner",
        "position",
        "seems",
        "rely",
        "largely",
        "criticism",
        "opponent",
        "empirical",
        "observation",
        "robot",
        "nonpersons",
        "sometimes",
        "treated",
        "right",
        "vein",
        "relational",
        "turn",
        "proposed",
        "relate",
        "robot",
        "though",
        "right",
        "might",
        "welladvised",
        "search",
        "whether",
        "really",
        "right",
        "coeckelbergh",
        "raise",
        "question",
        "far",
        "antirealism",
        "quasirealism",
        "go",
        "mean",
        "say",
        "robot",
        "right",
        "humancentred",
        "approach",
        "gerdes",
        "side",
        "debate",
        "bryson",
        "insisted",
        "robot",
        "enjoy",
        "right",
        "bryson",
        "though",
        "considers",
        "possibility",
        "gunkel",
        "bryson",
        "wholly",
        "separate",
        "issue",
        "whether",
        "robot",
        "ai",
        "system",
        "given",
        "status",
        "legal",
        "entity",
        "legal",
        "person",
        "sense",
        "natural",
        "person",
        "also",
        "state",
        "business",
        "organisation",
        "entity",
        "namely",
        "legal",
        "right",
        "duty",
        "european",
        "parliament",
        "considered",
        "allocating",
        "status",
        "robot",
        "order",
        "deal",
        "civil",
        "liability",
        "eu",
        "parliament",
        "bertolini",
        "aiello",
        "criminal",
        "liabilitywhich",
        "reserved",
        "natural",
        "person",
        "would",
        "also",
        "possible",
        "assign",
        "certain",
        "subset",
        "right",
        "duty",
        "robot",
        "said",
        "legislative",
        "action",
        "would",
        "morally",
        "unnecessary",
        "legally",
        "troublesome",
        "would",
        "serve",
        "interest",
        "human",
        "bryson",
        "diamantis",
        "grant",
        "environmental",
        "ethic",
        "longstanding",
        "discussion",
        "legal",
        "right",
        "natural",
        "object",
        "like",
        "tree",
        "c",
        "d",
        "stone",
        "also",
        "said",
        "reason",
        "developing",
        "robot",
        "right",
        "artificial",
        "moral",
        "patient",
        "future",
        "ethically",
        "doubtful",
        "van",
        "wynsberghe",
        "robbins",
        "community",
        "artificial",
        "consciousness",
        "researcher",
        "significant",
        "concern",
        "whether",
        "would",
        "ethical",
        "create",
        "consciousness",
        "since",
        "creating",
        "would",
        "presumably",
        "imply",
        "ethical",
        "obligation",
        "sentient",
        "eg",
        "harm",
        "end",
        "existence",
        "switching",
        "offsome",
        "author",
        "called",
        "moratorium",
        "synthetic",
        "phenomenology",
        "bentley",
        "et",
        "al",
        "f",
        "singularity",
        "singularity",
        "superintelligence",
        "quarter",
        "aim",
        "current",
        "ai",
        "thought",
        "artificial",
        "general",
        "intelligence",
        "agi",
        "contrasted",
        "technical",
        "narrow",
        "ai",
        "agi",
        "usually",
        "distinguished",
        "traditional",
        "notion",
        "ai",
        "general",
        "purpose",
        "system",
        "searle",
        "notion",
        "strong",
        "ai",
        "computer",
        "given",
        "right",
        "program",
        "literally",
        "said",
        "understand",
        "cognitive",
        "state",
        "searle",
        "idea",
        "singularity",
        "trajectory",
        "artificial",
        "intelligence",
        "reach",
        "system",
        "human",
        "level",
        "intelligence",
        "system",
        "would",
        "ability",
        "develop",
        "ai",
        "system",
        "surpass",
        "human",
        "level",
        "intelligence",
        "ie",
        "superintelligent",
        "see",
        "superintelligent",
        "ai",
        "system",
        "would",
        "quickly",
        "selfimprove",
        "develop",
        "even",
        "intelligent",
        "system",
        "sharp",
        "turn",
        "event",
        "reaching",
        "superintelligent",
        "ai",
        "singularity",
        "development",
        "ai",
        "human",
        "control",
        "hard",
        "predict",
        "kurzweil",
        "fear",
        "robot",
        "created",
        "take",
        "world",
        "captured",
        "human",
        "imagination",
        "even",
        "computer",
        "eg",
        "butler",
        "central",
        "theme",
        "\u010dapek",
        "famous",
        "play",
        "introduced",
        "word",
        "robot",
        "\u010dapek",
        "fear",
        "first",
        "formulated",
        "possible",
        "trajectory",
        "existing",
        "ai",
        "intelligence",
        "explosion",
        "irvin",
        "good",
        "let",
        "ultraintelligent",
        "machine",
        "defined",
        "machine",
        "far",
        "surpass",
        "intellectual",
        "activity",
        "man",
        "however",
        "clever",
        "since",
        "design",
        "machine",
        "one",
        "intellectual",
        "activity",
        "ultraintelligent",
        "machine",
        "could",
        "design",
        "even",
        "better",
        "machine",
        "would",
        "unquestionably",
        "intelligence",
        "explosion",
        "intelligence",
        "man",
        "would",
        "left",
        "far",
        "behind",
        "thus",
        "first",
        "ultraintelligent",
        "machine",
        "last",
        "invention",
        "man",
        "need",
        "ever",
        "make",
        "provided",
        "machine",
        "docile",
        "enough",
        "tell",
        "u",
        "keep",
        "control",
        "good",
        "optimistic",
        "argument",
        "acceleration",
        "singularity",
        "spelled",
        "kurzweil",
        "essentially",
        "point",
        "computing",
        "power",
        "increasing",
        "exponentially",
        "ie",
        "doubling",
        "ca",
        "every",
        "year",
        "since",
        "accordance",
        "moore",
        "law",
        "number",
        "transistor",
        "continue",
        "time",
        "future",
        "predicted",
        "kurzweil",
        "supercomputer",
        "reach",
        "human",
        "computation",
        "capacity",
        "mind",
        "uploading",
        "possible",
        "singularity",
        "occur",
        "kurzweil",
        "talk",
        "increase",
        "computing",
        "power",
        "purchased",
        "given",
        "costbut",
        "course",
        "recent",
        "year",
        "fund",
        "available",
        "ai",
        "company",
        "also",
        "increased",
        "enormously",
        "amodei",
        "hernandez",
        "oir",
        "thus",
        "estimate",
        "year",
        "actual",
        "computing",
        "power",
        "available",
        "train",
        "particular",
        "ai",
        "system",
        "doubled",
        "every",
        "month",
        "resulting",
        "x",
        "increasenot",
        "x",
        "increase",
        "doubling",
        "every",
        "two",
        "year",
        "would",
        "created",
        "common",
        "version",
        "argument",
        "chalmers",
        "talk",
        "increase",
        "intelligence",
        "ai",
        "system",
        "rather",
        "raw",
        "computing",
        "power",
        "crucial",
        "point",
        "singularity",
        "remains",
        "one",
        "development",
        "ai",
        "taken",
        "ai",
        "system",
        "accelerates",
        "beyond",
        "human",
        "level",
        "bostrom",
        "explains",
        "detail",
        "would",
        "happen",
        "point",
        "risk",
        "humanity",
        "discussion",
        "summarised",
        "eden",
        "et",
        "al",
        "armstrong",
        "shanahan",
        "possible",
        "path",
        "superintelligence",
        "computing",
        "power",
        "increase",
        "eg",
        "complete",
        "emulation",
        "human",
        "brain",
        "computer",
        "kurzweil",
        "sandberg",
        "biological",
        "path",
        "network",
        "organisation",
        "bostrom",
        "despite",
        "obvious",
        "weakness",
        "identification",
        "intelligence",
        "processing",
        "power",
        "kurzweil",
        "seems",
        "right",
        "human",
        "tend",
        "underestimate",
        "power",
        "exponential",
        "growth",
        "minitest",
        "walked",
        "step",
        "way",
        "step",
        "double",
        "previous",
        "starting",
        "step",
        "one",
        "metre",
        "far",
        "would",
        "get",
        "step",
        "answer",
        "almost",
        "time",
        "earth",
        "permanent",
        "natural",
        "satellite",
        "indeed",
        "progress",
        "ai",
        "readily",
        "attributable",
        "availability",
        "processor",
        "faster",
        "degree",
        "magnitude",
        "larger",
        "storage",
        "higher",
        "investment",
        "m\u00fcller",
        "actual",
        "acceleration",
        "speed",
        "discussed",
        "m\u00fcller",
        "bostrom",
        "bostrom",
        "dafoe",
        "flynn",
        "forthcoming",
        "sandberg",
        "argues",
        "progress",
        "continue",
        "time",
        "participant",
        "debate",
        "united",
        "technophile",
        "sense",
        "expect",
        "technology",
        "develop",
        "rapidly",
        "bring",
        "broadly",
        "welcome",
        "changesbut",
        "beyond",
        "divide",
        "focus",
        "benefit",
        "eg",
        "kurzweil",
        "focus",
        "risk",
        "eg",
        "bostrom",
        "camp",
        "sympathise",
        "transhuman",
        "view",
        "survival",
        "humankind",
        "different",
        "physical",
        "form",
        "eg",
        "uploaded",
        "computer",
        "moravec",
        "bostrom",
        "a",
        "c",
        "also",
        "consider",
        "prospect",
        "human",
        "enhancement",
        "various",
        "respect",
        "including",
        "intelligenceoften",
        "called",
        "ia",
        "intelligence",
        "augmentation",
        "may",
        "future",
        "ai",
        "used",
        "human",
        "enhancement",
        "contribute",
        "dissolution",
        "neatly",
        "defined",
        "human",
        "single",
        "person",
        "robin",
        "hanson",
        "provides",
        "detailed",
        "speculation",
        "happen",
        "economically",
        "case",
        "human",
        "brain",
        "emulation",
        "enables",
        "truly",
        "intelligent",
        "robot",
        "em",
        "hanson",
        "argument",
        "superintelligence",
        "risk",
        "requires",
        "assumption",
        "superintelligence",
        "imply",
        "benevolencecontrary",
        "kantian",
        "tradition",
        "ethic",
        "argued",
        "higher",
        "level",
        "rationality",
        "intelligence",
        "would",
        "go",
        "along",
        "better",
        "understanding",
        "moral",
        "better",
        "ability",
        "act",
        "morally",
        "gewirth",
        "chalmers",
        "f",
        "argument",
        "risk",
        "superintelligence",
        "say",
        "rationality",
        "morality",
        "entirely",
        "independent",
        "dimensionsthis",
        "sometimes",
        "explicitly",
        "argued",
        "orthogonality",
        "thesis",
        "bostrom",
        "armstrong",
        "bostrom",
        "criticism",
        "singularity",
        "narrative",
        "raised",
        "various",
        "angle",
        "kurzweil",
        "bostrom",
        "seem",
        "assume",
        "intelligence",
        "onedimensional",
        "property",
        "set",
        "intelligent",
        "agent",
        "totallyordered",
        "mathematical",
        "sensebut",
        "neither",
        "discus",
        "intelligence",
        "length",
        "book",
        "generally",
        "fair",
        "say",
        "despite",
        "effort",
        "assumption",
        "made",
        "powerful",
        "narrative",
        "superintelligence",
        "singularity",
        "investigated",
        "detail",
        "one",
        "question",
        "whether",
        "singularity",
        "ever",
        "occurit",
        "may",
        "conceptually",
        "impossible",
        "practically",
        "impossible",
        "may",
        "happen",
        "contingent",
        "event",
        "including",
        "people",
        "actively",
        "preventing",
        "philosophically",
        "interesting",
        "question",
        "whether",
        "singularity",
        "myth",
        "floridi",
        "ganascia",
        "trajectory",
        "actual",
        "ai",
        "research",
        "something",
        "practitioner",
        "often",
        "assume",
        "eg",
        "brook",
        "oir",
        "may",
        "fear",
        "public",
        "relation",
        "backlash",
        "overestimate",
        "practical",
        "problem",
        "good",
        "reason",
        "think",
        "superintelligence",
        "unlikely",
        "outcome",
        "current",
        "ai",
        "research",
        "m\u00fcller",
        "forthcominga",
        "discussion",
        "raise",
        "question",
        "whether",
        "concern",
        "singularity",
        "narrative",
        "fictional",
        "ai",
        "based",
        "human",
        "fear",
        "even",
        "one",
        "find",
        "negative",
        "reason",
        "compelling",
        "singularity",
        "likely",
        "occur",
        "still",
        "significant",
        "possibility",
        "one",
        "may",
        "turn",
        "wrong",
        "philosophy",
        "secure",
        "path",
        "science",
        "kant",
        "b",
        "maybe",
        "ai",
        "robotics",
        "either",
        "m\u00fcller",
        "appears",
        "discussing",
        "highimpact",
        "risk",
        "singularity",
        "justification",
        "even",
        "one",
        "think",
        "probability",
        "singularity",
        "ever",
        "occurring",
        "low",
        "existential",
        "risk",
        "superintelligence",
        "thinking",
        "superintelligence",
        "long",
        "term",
        "raise",
        "question",
        "whether",
        "superintelligence",
        "may",
        "lead",
        "extinction",
        "human",
        "specie",
        "called",
        "existential",
        "risk",
        "xrisk",
        "superintelligent",
        "system",
        "may",
        "well",
        "preference",
        "conflict",
        "existence",
        "human",
        "earth",
        "may",
        "thus",
        "decide",
        "end",
        "existenceand",
        "given",
        "superior",
        "intelligence",
        "power",
        "may",
        "happen",
        "end",
        "really",
        "care",
        "thinking",
        "long",
        "term",
        "crucial",
        "feature",
        "literature",
        "whether",
        "singularity",
        "another",
        "catastrophic",
        "event",
        "occurs",
        "year",
        "really",
        "matter",
        "baum",
        "et",
        "al",
        "perhaps",
        "even",
        "astronomical",
        "pattern",
        "intelligent",
        "specie",
        "bound",
        "discover",
        "ai",
        "point",
        "thus",
        "bring",
        "demise",
        "great",
        "filter",
        "would",
        "contribute",
        "explanation",
        "fermi",
        "paradox",
        "sign",
        "life",
        "known",
        "universe",
        "despite",
        "high",
        "probability",
        "emerging",
        "would",
        "bad",
        "news",
        "found",
        "great",
        "filter",
        "ahead",
        "u",
        "rather",
        "obstacle",
        "earth",
        "already",
        "passed",
        "issue",
        "sometimes",
        "taken",
        "narrowly",
        "human",
        "extinction",
        "bostrom",
        "broadly",
        "concerning",
        "large",
        "risk",
        "specie",
        "rees",
        "of",
        "ai",
        "one",
        "h\u00e4ggstr\u00f6m",
        "ord",
        "bostrom",
        "also",
        "us",
        "category",
        "global",
        "catastrophic",
        "risk",
        "risk",
        "sufficiently",
        "high",
        "two",
        "dimension",
        "scope",
        "severity",
        "bostrom",
        "\u0107irkovi\u0107",
        "bostrom",
        "discussion",
        "risk",
        "usually",
        "connected",
        "general",
        "problem",
        "ethic",
        "risk",
        "eg",
        "hansson",
        "longterm",
        "view",
        "methodological",
        "challenge",
        "produced",
        "wide",
        "discussion",
        "tegmark",
        "focus",
        "ai",
        "human",
        "life",
        "singularity",
        "russell",
        "dewey",
        "tegmark",
        "bostrom",
        "dafoe",
        "flynn",
        "forthcoming",
        "survey",
        "longerterm",
        "policy",
        "issue",
        "ethical",
        "ai",
        "several",
        "collection",
        "paper",
        "investigated",
        "risk",
        "artificial",
        "general",
        "intelligence",
        "agi",
        "factor",
        "might",
        "make",
        "development",
        "le",
        "riskladen",
        "m\u00fcller",
        "b",
        "callaghan",
        "et",
        "al",
        "yampolskiy",
        "including",
        "development",
        "nonagent",
        "ai",
        "drexler",
        "controlling",
        "superintelligence",
        "narrow",
        "sense",
        "control",
        "problem",
        "human",
        "remain",
        "control",
        "ai",
        "system",
        "superintelligent",
        "bostrom",
        "ff",
        "wider",
        "sense",
        "problem",
        "make",
        "sure",
        "ai",
        "system",
        "turn",
        "positive",
        "according",
        "human",
        "perception",
        "russell",
        "sometimes",
        "called",
        "value",
        "alignment",
        "easy",
        "hard",
        "control",
        "superintelligence",
        "depends",
        "significantly",
        "speed",
        "takeoff",
        "superintelligent",
        "system",
        "led",
        "particular",
        "attention",
        "system",
        "selfimprovement",
        "alphazero",
        "silver",
        "et",
        "al",
        "one",
        "aspect",
        "problem",
        "might",
        "decide",
        "certain",
        "feature",
        "desirable",
        "find",
        "unforeseen",
        "consequence",
        "negative",
        "would",
        "desire",
        "feature",
        "ancient",
        "problem",
        "king",
        "midas",
        "wished",
        "touched",
        "would",
        "turn",
        "gold",
        "problem",
        "discussed",
        "occasion",
        "various",
        "example",
        "paperclip",
        "maximiser",
        "bostrom",
        "b",
        "program",
        "optimise",
        "chess",
        "performance",
        "omohundro",
        "discussion",
        "superintelligence",
        "include",
        "speculation",
        "omniscient",
        "being",
        "radical",
        "change",
        "latter",
        "day",
        "promise",
        "immortality",
        "transcendence",
        "current",
        "bodily",
        "formso",
        "sometimes",
        "clear",
        "religious",
        "undertone",
        "capurro",
        "geraci",
        "connell",
        "ff",
        "issue",
        "also",
        "pose",
        "wellknown",
        "problem",
        "epistemology",
        "know",
        "way",
        "omniscient",
        "danaher",
        "usual",
        "opponent",
        "already",
        "shown",
        "characteristic",
        "response",
        "atheist",
        "people",
        "worry",
        "computer",
        "get",
        "smart",
        "take",
        "world",
        "real",
        "problem",
        "stupid",
        "already",
        "taken",
        "world",
        "domingo",
        "new",
        "nihilist",
        "explain",
        "technohypnosis",
        "information",
        "technology",
        "become",
        "main",
        "method",
        "distraction",
        "loss",
        "meaning",
        "gertz",
        "opponent",
        "would",
        "thus",
        "say",
        "need",
        "ethic",
        "small",
        "problem",
        "occur",
        "actual",
        "ai",
        "robotics",
        "section",
        "le",
        "need",
        "big",
        "ethic",
        "existential",
        "risk",
        "ai",
        "section",
        "closing",
        "singularity",
        "thus",
        "raise",
        "problem",
        "concept",
        "ai",
        "remarkable",
        "imagination",
        "vision",
        "played",
        "central",
        "role",
        "since",
        "beginning",
        "discipline",
        "dartmouth",
        "summer",
        "research",
        "project",
        "mccarthy",
        "et",
        "al",
        "oir",
        "simon",
        "newell",
        "evaluation",
        "vision",
        "subject",
        "dramatic",
        "change",
        "decade",
        "went",
        "slogan",
        "ai",
        "impossible",
        "dreyfus",
        "ai",
        "automation",
        "lighthill",
        "ai",
        "solve",
        "problem",
        "kurzweil",
        "ai",
        "may",
        "kill",
        "u",
        "bostrom",
        "created",
        "medium",
        "attention",
        "public",
        "relation",
        "effort",
        "also",
        "raise",
        "problem",
        "much",
        "philosophy",
        "ethic",
        "ai",
        "really",
        "ai",
        "rather",
        "imagined",
        "technology",
        "said",
        "outset",
        "ai",
        "robotics",
        "raised",
        "fundamental",
        "question",
        "system",
        "system",
        "risk",
        "long",
        "term",
        "also",
        "challenge",
        "human",
        "view",
        "humanity",
        "intelligent",
        "dominant",
        "specie",
        "earth",
        "seen",
        "issue",
        "raised",
        "watch",
        "technological",
        "social",
        "development",
        "closely",
        "catch",
        "new",
        "issue",
        "early",
        "develop",
        "philosophical",
        "analysis",
        "learn",
        "traditional",
        "problem",
        "philosophy"
    ]
}