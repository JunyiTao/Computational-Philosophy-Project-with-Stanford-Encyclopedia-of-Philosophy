{
    "url": "ethics-internet-research",
    "title": "Internet Research Ethics",
    "authorship": {
        "year": "Copyright \u00a9 2021",
        "author_text": "Elizabeth A. Buchanan\n<buchanane@uwstout.edu>\nMichael Zimmer\n<michael.zimmer@marquette.edu>",
        "author_links": [
            {
                "https://www.uwstout.edu/sites/default/files/cv/2018-06/Elizabeth%20Anne%20Buchanan%20CV_0.pdf": "Elizabeth A. Buchanan"
            },
            {
                "mailto:buchanane%40uwstout%2eedu": "buchanane@uwstout.edu"
            },
            {
                "http://michaelzimmer.org": "Michael Zimmer"
            },
            {
                "mailto:michael%2ezimmer%40marquette%2eedu": "michael.zimmer@marquette.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2021</a> by\n\n<br/>\n<a href=\"https://www.uwstout.edu/sites/default/files/cv/2018-06/Elizabeth%20Anne%20Buchanan%20CV_0.pdf\" target=\"other\">Elizabeth A. Buchanan</a>\n&lt;<a href=\"mailto:buchanane%40uwstout%2eedu\"><em>buchanane<abbr title=\" at \">@</abbr>uwstout<abbr title=\" dot \">.</abbr>edu</em></a>&gt;<br/>\n<a href=\"http://michaelzimmer.org\" target=\"other\">Michael Zimmer</a>\n&lt;<a href=\"mailto:michael%2ezimmer%40marquette%2eedu\"><em>michael<abbr title=\" dot \">.</abbr>zimmer<abbr title=\" at \">@</abbr>marquette<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Fri Jun 22, 2012",
        "substantive revision Tue Jan 12, 2021"
    ],
    "preamble": "\n\nThere is little research that is not impacted in some way on or\nthrough the Internet. The Internet, as a field, a tool, and a venue,\nhas specific and far-reaching ethical issues. Internet research ethics\nis a subdiscipline that fits across many disciplines, ranging from\nsocial sciences, arts and humanities, medical/biomedical, and natural\nsciences. Extant ethical frameworks, including\n consequentialism,\n deontology,\n virtue ethics,\n and\n feminist ethics,\n have contributed to the ways in which ethical issues in Internet\nresearch are considered and evaluated.\n\nConceptually and historically, Internet research ethics is most\nrelated to computer and information ethics and includes such ethical\nissues as participant knowledge and consent, data privacy, security,\nanonymity and confidentiality, and integrity of data, intellectual\nproperty issues, and community, disciplinary, and professional\nstandards or norms. Throughout the Internet\u2019s evolution, there\nhas been continued debate whether there are new ethical dilemmas\nemerging, or if the existing dilemmas are similar to dilemmas in other\nresearch realms (Elgesem 2002; Walther 2002; Ess & AoIR 2002;\nMarhkam & Buchanan 2012). These debates are similar to\nphilosophical debates in computer and information ethics. For example,\nmany years ago, James Moor (1985) asked \u201cwhat is special about\ncomputers\u201d in order to understand what, if anything, is unique\nethically. Reminding us, however, that research itself must be guided\nby ethical principles, regardless of technological intervention, van\nHeerden et al. (2020) and Sloan et al. (2020) stress that the\n\u201cfundamental principles of conducting ethical social research\nremain the same\u201d (Ess & AoIR 2002; King 1996; Samuel and\nBuchanan, 2020).\n\nYet, as the Internet has evolved into a more social and communicative\ntool and venue, the ethical issues have shifted from purely\ndata-driven to more human-centered. \u201cOn-ground\u201d or\nface-to-face analogies, however, may not be applicable to online\nresearch. For example, the concept of the public park has been used as\na site where researchers might observe others with little ethical\ncontroversy, but online, the concepts of public versus private are\nmuch more complex (SACHRP 2013). Thus, some scholars suggest that the\nspecificity of Internet research ethics calls for new regulatory\nand/or professional and disciplinary guidance. For these reasons, the\nconcept of human subjects research policies and regulation, informs\nthis entry, which will continue discussions around ethical and\nmethodological complexity, including personal identifiability,\nreputational risk and harm, notions of public space and public text,\nownership, and longevity of data as they relate to Internet research.\nSpecifically, the emergence of the social web raises issues around\nsubject or participant recruitment practices, tiered informed consent\nmodels, and protection of various expectations and forms of privacy in\nan ever-increasing world of diffused and ubiquitous technologies.\nAdditional ethical concerns center on issues of anonymity and\nconfidentiality of data in spaces where researchers and their subjects\nmay not fully understand the terms and conditions of those venues or\ntools, challenges to data integrity as research projects can be\noutsourced or crowdsourced to online labor marketplaces, and\njurisdictional issues as more research is processed, stored, and\ndisseminated via cloud computing or in remote server locales,\npresenting myriad legal complexities given jurisdictional differences\nin data laws. Further, the dominance of big data research has\ncontinued across research spaces, with the notions of\n\u201creal-world data\u201d and pervasive computing readily accepted\nand used in all disciplines. The ease of access and availability to\nuse big data sets in myriad ways has enabled AI (artificial\nintelligence) and ML (machine learning) to grow as standard tools for\nresearchers.\n\nAs a result, researchers using the Internet as a tool for and/or a\nspace of research\u2014and their research ethics boards (REBs), also\nknown as institutional review boards (IRBs) in the United States or\nhuman research ethics committees (HRECs) in other countries such as\nAustralia\u2014have been confronted with a series of new ethical\nquestions: What ethical obligations do researchers have to protect the\nprivacy of subjects engaging in activities in \u201cpublic\u201d\nInternet spaces? What are such public spaces? Is there any reasonable\nexpectation of privacy in an era of pervasive and ubiquitous\nsurveillance and data tracking? How is confidentiality or anonymity\nassured online? How is and should informed consent be obtained online?\nHow should research on minors be conducted, and how do you prove a\nsubject is not a minor? Is deception (pretending to be someone you are\nnot, withholding identifiable information, etc.) an acceptable online\nnorm or a harm? How is \u201charm\u201d possible to someone existing\nin an online space? How identifiable are individuals in large data\nsets? Do human subjects protections apply to big data? As more\nindustry-sponsored research takes place, what ethical protections\nexist outside of current regulatory structures? As laws, such as the\nEU\u2019s General Data Protection Regulation (GDPR 2016) are enacted,\nwhat are the global implications for data privacy and individual\nrights?\n\nA growing number of scholars have explored these and related questions\n(see, for example, Bromseth 2002; Bruckman 2006; Buchanan 2004;\nBuchanan & Ess 2008; Johns, Chen & Hall 2003; Kitchin 2003,\n2008; King 1996; Mann 2003; Markham & Baym 2008; McKee &\nPorter 2009; Thorseth 2003; Ess 2016; Zimmer & Kinder-Kurlanda\n(eds.) 2017; Samuel & Buchanan, 2020), scholarly associations have\ndrafted ethical guidelines for Internet research (Ess &\nAssociation of Internet Researchers 2002; Markham, Buchanan, and AoIR\n2012; franzke et al., 2020; Kraut et al. 2004), and non-profit\nscholarly and scientific agencies such as AAAS (Frankel & Siang\n1999) are confronting the myriad of ethical concerns that Internet\nresearch poses to researchers and research ethics boards (REBs).\n\nGiven that over 50% of the world population uses the Internet, and\nthat 97% of the world population now lives within reach of a mobile\ncellular signal and 93% within reach of a 3G (or higher) network\n(International Telecommunications Union, 2019), continued exploration\nof the ethical issues related to research in this heavily mediated\nenvironment is critical.\n",
    "toc": [
        {
            "#Defi": "1. Definitions"
        },
        {
            "#HumaSubjRese": "2. Human Subjects Research"
        },
        {
            "#HistDeveIREDisc": "3. History and Development of IRE as a Discipline"
        },
        {
            "#KeyEthiIssuInteRese": "4. Key Ethical Issues in Internet Research"
        },
        {
            "#Priv": "4.1 Privacy"
        },
        {
            "#Recr": "4.2 Recruitment"
        },
        {
            "#InfoCons": "4.3 Informed Consent"
        },
        {
            "#MinoCons": "4.3.1 Minors and Consent"
        },
        {
            "#ClouCompReseEthi": "4.4 Cloud Computing and Research Ethics"
        },
        {
            "#BigDataCons": "4.5 Big Data Considerations"
        },
        {
            "#InteReseInduEthi": "4.6 Internet Research and Industry Ethics"
        },
        {
            "#ReseEthiBoarGuid": "5. Research Ethics Boards Guidelines"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#CiteEntr": "Cited in Entry"
        },
        {
            "#LawsGoveDocu": "Laws and Government Documents"
        },
        {
            "#ProfStan": "Professional Standards"
        },
        {
            "#JourForuBlog": "Journals, Forums, and Blogs"
        },
        {
            "#OtheReso": "Other Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. Definitions\n\nThe commonly accepted definition of Internet research ethics (IRE) has\nbeen used by Buchanan and Ess (2008, 2009), Buchanan (2011), and Ess\n& Association of Internet Researchers (AoIR) (2002):\n\n\nIRE is defined as the analysis of ethical issues and\napplication of research ethics principles as they pertain to research\nconducted on and in the Internet. Internet-based research, broadly\ndefined, is research which utilizes the Internet to collect\ninformation through an online tool, such as an online survey; studies\nabout how people use the Internet, e.g., through collecting data\nand/or examining activities in or on any online environments; and/or,\nuses of online datasets, databases, or repositories.\n\n\nThese examples were broadened in 2013 by the United States\nSecretary\u2019s Advisory Committee to the Office for Human Research\nProtections (SACHRP 2013), and included under the umbrella term\nInternet Research:\n\nResearch studying information that is already available on or via\nthe Internet without direct interaction with human subjects\n(harvesting, mining, profiling, scraping, observation or recording of\notherwise-existing data sets, chat room interactions, blogs, social\nmedia postings, etc.)\nResearch that uses the Internet as a vehicle for recruiting or\ninteracting, directly or indirectly, with subjects (Self-testing\nwebsites, survey tools, Amazon Mechanical Turk, etc.)\nResearch about the Internet itself and its effects (use patterns\nor effects of social media, search engines, email, etc.; evolution of\nprivacy issues; information contagion; etc.)\nResearch about Internet users: what they do, and how the Internet\naffects individuals and their behaviors Research that utilizes the\nInternet as an interventional tool, for example, interventions that\ninfluence subjects\u2019 behavior\nOthers (emerging and cross-platform types of research and methods,\nincluding m-research (mobile))\nRecruitment in or through Internet locales or tools, for example\nsocial media, push technologies\n\n\nA critical distinction in the definition of Internet research ethics\nis that between the Internet as a research tool versus a research\nvenue. The distinction between tool and venue plays out across\ndisciplinary and methodological orientations. As a tool, Internet\nresearch is enabled by search engines, data aggregators, digital\narchives, application programming interfaces (APIs), online survey\nplatforms, and crowdsourcing platforms. Internet-based research venues\ninclude such spaces as conversation applications (instant messaging\nand discussion forums, for example), online multiplayer games, blogs\nand interactive websites, and social networking platforms.\n\nAnother way of conceptualizing the distinction between tool and venue\ncomes from Kitchin (2008), who has referred to a distinction in\nInternet research using the concepts of \u201cengaged web-based\nresearch\u201d versus \u201cnon-intrusive web-based\nresearch:\u201d\n\n\nNon-intrusive analyses refer to techniques of data collection that do\nnot interrupt the naturally occurring state of the site or\ncybercommunity, or interfere with premanufactured text. Conversely,\nengaged analyses reach into the site or community and thus engage the\nparticipants of the web source (2008: 15).\n\n\nThese two constructs provide researchers with a way of recognizing\nwhen considering of human subject protections might need to occur.\nMcKee and Porter (2009), as well as Banks and Eble (2007) provide\nguidance on the continuum of human-subjects research, noting a\ndistinction between person-based versus text-based. For example, McKee\nand Porter provide a range of research variables (public/private,\ntopic sensitivity, degree of interaction, and subject vulnerability)\nwhich are useful in determining where on the continuum of text-based\nversus how person-based the research is, and whether or not subjects\nwould need to consent to the research (2009: 87\u201388).\n\nWhile conceptually useful for determining human subjects\nparticipation, the distinction between tool and venue or engaged\nversus non-intrusive web-based research is increasingly blurring in\nthe face of social media and their third-party applications. Buchanan\n(2016) has conceptualized three phases or stages of Internet research,\nand the emergence of social media characterize the second phase, circa\n2006\u20132014. The concept of social media entails\n\n\nA group of Internet-based applications that build on the ideological\nand technological foundations of Web 2.0, and that allow the creation\nand exchange of user-generated content (Kaplan & Haenlein 2010:\n61).\n\n\nA \u201csocial network site\u201d is a category of websites with\nprofiles, semi-persistent public commentary on the profile, and a\ntraversable publicly articulated social network displayed in relation\nto the profile.\n\nThis collapse of tool and venue can be traced primarily to the\nincreasing use of third-party sites and applications such as Facebook,\nTwitter, or any of the myriad online research tools where subject or\nparticipant recruitment, data collection, data analysis, and data\ndissemination can all occur in the same space. With these collapsing\nboundaries, the terms of \u201cinter-jurisdictional\ncoordination\u201d (Gilbert 2009: 3) are inherently challenging;\nGilbert has specifically argued against the terms of use or end-user\nlicense agreement stipulations in virtual worlds, noting that such\nagreements are often \u201cflawed\u201d, as they rely on laws and\nregulations from a specific locale and attempt to enforce them in a\nnon place-based environment. Nonetheless, researchers now make\nfrequent use of data aggregation tools, scraping data from user\nprofiles or transaction logs, harvesting data from Twitter streams, or\nstoring data on cloud servers such as Dropbox only after agreeing to\nthe terms of service that go along with those sites. The use of such\nthird party applications or tools changes fundamental aspects of\nresearch, oftentimes displacing the researcher or research team as the\nsole owner of their data. These unique characteristics implicate\nconcepts and practicalities of privacy, consent, ownership, and\njurisdictional boundaries.\n\nA key moment that typified and called attention to many of these\nconcerns emerged with the 2014 Facebook Emotional Contagion study\n(Booth, 2014). By virtue of agreeing to Facebook\u2019s Terms of\nService, did users consent to participation in research activities?\nShould there have been a debriefing after the experiment? How\nthoroughly did a university research ethics board review the study?\nShould industry-sponsored research undergo internal ethics review? In\nresponse to the outcry of the Contagion study, Ok Cupid\u2019s\nChristian Rudder (2014\n [OIR])\n defended these sorts of experiments, noting\n\n\nWe noticed recently that people didn\u2019t like it when Facebook\n\u201cexperimented\u201d with their news feed. Even the FTC is\ngetting involved. But guess what, everybody: if you use the Internet,\nyou\u2019re the subject of hundreds of experiments at any given time,\non every site. That\u2019s how websites work.\n\n\nThe phenomenon of the social web forces an ongoing negotiation between\nresearchers and their data sources, as seen in the Facebook contagion\nstudy and the subsequent reaction to it. Moreover, with the growing\nuse and concentration of mobile devices, the notion of Internet\nresearch is expanding with a movement away from a\n\u201cplace-based\u201d Internet to a dispersed reality. Data\ncollection from mobile devices has increased exponentially. For\nexample, mobile devices enable the use of synchronous data collection\nand dissemination from non-place based environments. Researchers using\ncloud-enabled applications can send and receive data to and from\nparticipants synchronously. The impact of such research possibilities\nfor epidemiological research is staggering for its scientific\npotential while demanding for the concurrent ethical challenges, as we\nare seeing with mobile-based COVID-19 research (Drew et al., 2020) and\nthe sampling of subjects' current behaviors and experiences in\nreal-time (Hubach et al., forthcoming). As Internet research has grown\nfrom a niche methodology into a nearly ubiquitous and often invisible\npractice, the traditional concepts of human subjects research require\ncareful consideration.\n2. Human Subjects Research\n\nThe practical, professional, and theoretical implications of human\nsubjects protections has been covered extensively in scholarly\nliterature, ranging from medical/biomedical to social sciences to\ncomputing and technical disciplines (see Beauchamp & Childress\n2008; Emanual et al. 2003; PRIM&R et al. 2021; Sieber 1992; Wright\n2006). Relevant protections and regulations continue to receive much\nattention in the face of research ethics violations (see, for example,\nSkloot 2010, on Henrietta Lacks; the U.S. Government\u2019s admission\nand apology to the Guatemalan Government for STD testing in the 1940s\n(BBC 2011); and Gaw & Burns 2011, on how lessons from the past\nmight inform current research ethics and conduct).\n\nThe history of human subjects protections (Sparks 2002 [see\n Other Internet Resources aka OIR])\n grew out of atrocities such as Nazi human experimentation during\nWorld War II, which resulted in the Nuremberg Code (1947);\nsubsequently followed by the Declaration of Helsinki on Ethical\nPrinciples for Medical Research Involving Human Subjects (World\nMedical Association 1964/2008). Partially in response to the Tuskegee\nsyphilis experiment, an infamous clinical study conducted between 1932\nand 1972 by the U.S. Public Health Service studying the natural\nprogression of untreated syphilis in rural African-American men in\nAlabama under the guise of receiving free health care from the\ngovernment, the U.S. Department of Health and Human Services put forth\na set of basic regulations governing the protection of human subjects\n(45 C.F.R. \u00a7 46) (see the links in the Other Internet Resources\nsection, under Laws and Government Documents). This was later followed\nby the publication of the \u201cEthical Principles and Guidelines for\nthe Protection of Human Subjects of Research\u201d by the National\nCommission for the Protection of Human Subjects of Biomedical and\nBehavioral Research, known as the Belmont Report (NCPHSBBR 1979). The\nBelmont Report identifies three fundamental ethical principles for all\nhuman subjects research: Respect for Persons, Beneficence, and\nJustice.\n\nTo ensure consistency across federal agencies in the United States\ncontext in human subjects protections, in 1991, the Federal Policy for\nthe Protection of Human Subjects, also known as the \u201cCommon\nRule\u201d was codified; the Revised Common Rule was released in the\nFederal Register on 19 January 2017, and went into effect 19 July\n2018. Similar regulatory frameworks for the protection of human\nsubjects exist across the world, and include, for example, the\nCanadian Tri-Council, the Australian Research Council, The European\nCommission, The Research Council of Norway and its National Committee\nfor Research Ethics in the Social Sciences and Humanities (NESH 2006;\nNESH 2019), and the U.K.\u2019s NHS National Research Ethics Service\nand the Research Ethics Framework (REF) of the ESRC (Economic and\nSocial Research Council) General Guidelines, and the Forum for Ethical\nReview Committees in Asia and the Western Pacific (FERCAP).\n\nIn the United States, the various regulatory agencies who have signed\non to the Common Rule (45 C.F.R. 46 Subpart A) have not issued formal\nguidance on Internet research (see the links in the Other Internet\nResources section, under Laws and Government Documents). The Preamble\nto the Revised Rule referenced significant changes in the research\nenvironment, recognizing a need to broaden the scope of the Rule.\nHowever, substantial changes to the actual Rule in regards to Internet\nresearch in its broadest context, were minimal.\n\nFor example, the Preamble states:\n\n\nThis final rule recognizes that in the past two decades a paradigm\nshift has occurred in how research is conducted. Evolving\ntechnologies\u2014including imaging, mobile technologies, and the\ngrowth in computing power\u2014have changed the scale and nature of\ninformation collected in many disciplines. Computer scientists,\nengineers, and social scientists are developing techniques to\nintegrate different types of data so they can be combined, mined,\nanalyzed, and shared. The advent of sophisticated computer software\nprograms, the Internet, and mobile technology has created new areas of\nresearch activity, particularly within the social and behavioral\nsciences (Federal Register 2017 and HHS 2017).\n\n\nModest changes to the definition of human subjects included changing\n\u201cdata\u201d to \u201cinformation\u201d and\n\u201cbiospecimens;\u201d the definition now reads:\n\n(e)\n\n\n(1) Human subject means a living individual about\nwhom an investigator (whether professional or student) conducting\nresearch:\n\n\n(i) Obtains information or biospecimens through intervention or\ninteraction with the individual, and uses, studies, or analyzes the\ninformation or biospecimens; or\n(ii) Obtains, uses, studies, analyzes, or generates identifiable\nprivate information or identifiable biospecimens.\n \n(2) Intervention includes both physical\nprocedures by which information or biospecimens are gathered (e.g.,\nvenipuncture) and manipulations of the subject or the subject's\nenvironment that are performed for research purposes.\n(3) Interaction includes communication or\ninterpersonal contact between investigator and subject.\n(4) Private information includes information\nabout behavior that occurs in a context in which an individual can\nreasonably expect that no observation or recording is taking place,\nand information that has been provided for specific purposes by an\nindividual and that the individual can reasonably expect will not be\nmade public (e.g., a medical record).\n(5) Identifiable private information is private\ninformation for which the identity of the subject is or may readily be\nascertained by the investigator or associated with the\ninformation.\n(6) An identifiable biospecimen is a biospecimen\nfor which the identity of the subject is or may readily be ascertained\nby the investigator or associated with the biospecimen (45 C.F.R.\n\u00a7 46.102 (2018)).\n\n\n\nHowever, the Revised Rule does have a provision that stands to be of\nimport in regards to Internet research; the Rule calls for\nimplementing departments or agencies to,\n\n[(e)(7)]\n\n\n(i) Upon consultation with appropriate experts (including experts\nin data matching and re-identification), reexamine the meaning of\n\u201cidentifiable private information\u201d, as defined in\nparagraph (e)(5) of this section, and \u201cidentifiable\nbiospecimen\u201d, as defined in paragraph (e)(6) of this section.\nThis reexamination shall take place within 1 year and regularly\nthereafter (at least every 4 years). This process will be conducted by\ncollaboration among the Federal departments and agencies implementing\nthis policy. If appropriate and permitted by law, such Federal\ndepartments and agencies may alter the interpretation of these terms,\nincluding through the use of guidance.\n(ii) Upon consultation with appropriate experts, assess whether\nthere are analytic technologies or techniques that should be\nconsidered by investigators to generate \u201cidentifiable private\ninformation\u201d, as defined in paragraph (e)(5) of this section, or\nan \u201cidentifiable biospecimen\u201d, as defined in paragraph\n(e)(6) of this section. This assessment shall take place within 1 year\nand regularly thereafter (at least every 4 years). This process will\nbe conducted by collaboration among the Federal departments and\nagencies implementing this policy. Any such technologies or techniques\nwill be included on a list of technologies or techniques that produce\nidentifiable private information or identifiable biospecimens. This\nlist will be published in the Federal Register after notice and an\nopportunity for public comment. The Secretary, HHS, shall maintain the\nlist on a publicly accessible Web site (45 C.F.R. \u00a7 46.102\n(2018)).\n\n\n\nAs of this writing, there has not yet been a reexamination of the\nconcepts of \u201cidentifiable private information\u201d or\n\u201cidentifiable biospecimens\u201d. However, as data analytics,\nAI, and machine learning continue to expose ethical issues in human\nsubjects research, we expect to see engaged discussion at the federal\nlevel and amongst research communities (PRIM&R 2021). Those\ndiscussions may refer to previous conceptual work by Carpenter and\nDittrich (2012) and Aycock et al. (2012) that is concerned with risk\nand identifiability. Secondary uses of identifiable, private data, for\nexample, may pose downstream harms, or unintentional risks, causing\nreputational or informational harms. Reexaminations of\n\u201cidentifiable private information\u201d can not occur without\nserious consideration of risk and \u201chuman harming\nresearch\u201d. Carpenter and Dittrich (2012) encourage\n\n\n\u201cReview boards should transition from an informed consent driven\nreview to a risk analysis review that addresses potential harms\nstemming from research in which a researcher does not directly\ninteract with the at-risk individuals\u201d (p. 4) as \u201c[T]his\ndistance between researcher and affected individual indicates that a\nparadigm shift is necessary in the research arena. We must transition\nour idea of research protection from \u2018human subjects\nresearch\u2019 to \u2018human harming research\u2019\u201d (p.\n 14).[1]\n\n\nSimilarly, Aycock et al. (2012) assert that\n\n\nResearchers and boards must balance presenting risks related to the\nspecific research with risks related to the technologies in use. With\ncomputer security research, major issues around risk arise, for\nsociety at large especially. The risk may not seem evident to an\nindividual but in the scope of security research, larger populations\nmay be vulnerable. There is a significant difficulty in quantifying\nrisks and benefits, in the traditional sense of research\nethics\u2026.An aggregation of surfing behaviors collected by a bot\npresents greater distance between researcher and respondent than an\ninterview done in a virtual world between avatars. This distance leads\nus to suggest that computer security research focus less concern\naround human subjects research in the traditional sense and\nmore concern with human harming research (p. 3, italics\noriginal).\n\n\nThese two conceptual notions are relevant for considering emergent\nforms of identities or personally identifiable information (PII) such\nas avatars, virtual beings, bots, textual and graphical information.\nWithin the Code of Federal Regulations (45 C.F.R. \u00a7 46.102(f)\n2009): New forms of representations are considered human subjects if\nPII about living individuals is obtained. PII can be obtained by\nresearchers through scraping data sources, profiles or avatars, or\nother pieces of data made available by the platform. Fairfield agrees:\n\u201cAn avatar, for example, does not merely represent a collection\nof pixels\u2014it represents the identity of the user\u201d (2012:\n701).\n\nThe multiple academic disciplines already long engaged in human\nsubjects research (medicine, sociology, anthropology, psychology,\ncommunication) have established ethical guidelines intended to assist\nresearchers and those charged with ensuring that research on human\nsubjects follows both legal requirements and ethical practices. But\nwith research involving the Internet\u2014where individuals\nincreasingly share personal information on platforms with porous and\nshifting boundaries, where both the spread and aggregation of data\nfrom disparate sources has become the norm, and where web-based\nservices, and their privacy policies and terms of service statements,\nmorph and evolve rapidly\u2014the ethical frameworks and assumptions\ntraditionally used by researchers and REBs are frequently\nchallenged.\n\nResearch ethics boards themselves are increasingly challenged with the\nunique ethical dimensions of internet-based research protocols. In a\n2008 survey of U.S. IRBs, less than half of the ethical review boards\nidentified internet-based research was \u201can area of concern or\nimportance\u201d at that time, and only 6% had guidelines or\nchecklists in place for reviewing internet-based research protocols\n(Buchanan & Ess 2009). By 2015, 93% of IRBs surveyed acknowledged\nthat are ethical issues unique to research using \u201conline\ndata\u201d, yet only 55% said they felt their IRBs are well versed in\nthe technical aspects of online data collection, and only 57% agreed\nthat their IRB has the expertise to stay abreast of changes in online\ntechnology. IRBs are now further challenged with the growth of big\ndata research (see\n \u00a74.5 below),\n which increasingly relies on large datasets of personal information\ngenerated via social media, digital devices, or other means often\nhidden from users. A 2019 study of IRBs revealed only 25% felt\nprepared to evaluate protocols relying on big data, and only 6% had\ntools sufficient for considering this emerging area of internet\nresearch (Zimmer & Chapman 2020). Further, after being presented\nvarious hypothetical research scenarios utilizing big data and asked\nhow their IRB would likely review such a protocol, numerous viewpoints\ndifferent strongly in many cases. Consider the following scenario:\n\n\nResearchers plan to scrape public comments from online newspaper pages\nto predict election outcomes. They will aggregate their analysis to\ndetermine public sentiment. The researchers don\u2019t plan to inform\ncommenters, and they plan to collect potentially-identifiable user\nnames. Scraping comments violates the newspaper\u2019s terms of\nservice.\n\n\n18% of respondents indicated their IRB would view this as exempt, 21%\nindicated expedited review, 33% suggested it would need full board\nreview, while 28% did not think this was even human subjects research\nthat would fall under their IRB\u2019s purview (Zimmer & Chapman\n2020). This points to potential gaps and inconsistencies in how IRBs\nreview the ethical implications of big data research protocols.\n3. History and Development of IRE as a Discipline\n\nAn extensive body of literature has developed since the 1990s around\nthe use of the Internet for research (S. Jones 1999; Hunsinger,\nKlastrup, & Allen (eds.) 2010; Consalvo & Ess (eds.) 2011;\nZimmer & Kinder-Kurlanda (eds.) 2017), with a growing emphasis on\nthe ethical dimensions of Internet research.\n\nA flurry of Internet research, and explicit concern for the ethical\nissues concurrently at play in it, began in the mid-1990s. In 1996,\nStorm King recognized the growing use of the Internet as a venue for\nresearch. His work explored the American Psychological\nAssociation\u2019s guidelines for human subjects research with\nemergent forms of email, chat, listservs, and virtual communities.\nWith careful attention to risk and benefit to Internet subjects, King\noffered a cautionary note:\n\n\nWhen a field of study is new, the fine points of ethical\nconsiderations involved are undefined. As the field matures and\nresults are compiled, researchers often review earlier studies and\nbecome concerned because of the apparent disregard for the human\nsubjects involved (1996: 119).\n\n\nThe 1996 issue of Information Society dedicated to Internet\nresearch is considered a watershed moment, and included much seminal\nresearch still of impact and relevance today (Allen 1996; Boehlefeld\n1996; Reid 1996).\n\nSherry Turkle\u2019s 1997 Life on the Screen: Identity in the Age\nof the Internet called direct attention to the human element of\nonline game environments. Moving squarely towards person-based versus\ntext-based research, Turkle pushed researchers to consider human\nsubjects implications of Internet research. Similarly, Markham\u2019s\nLife Online: Researching Real Experience in Virtual Space\n(1998) highlighted the methodological complexities of online\nethnographic studies, as did Jacobson\u2019s 1999 methodological\ntreatment of Internet research. The \u201cfield\u201d of study\nchanged the dynamics of researcher-researched roles, identity, and\nrepresentation of participants from virtual spaces. Markham\u2019s\nwork in qualitative online research has been influential across\ndisciplines, as research in nursing, psychology, and medicine has\nfound the potential of this paradigm for online research (Flicker et\nal. 2004; Eysenbach & Till 2001; Seaboldt & Kupier 1997; Sharf\n1997).\n\nThen, in 1999, the American Association for the Advancement of Science\n(AAAS), with a contract from the U.S. Office for Protection from\nResearch Risks (now known as the Office for Human Research\nProtections), convened a workshop, with the goal of assessing the\nalignment of traditional research ethics concepts to Internet\nresearch. The workshop acknowledged\n\n\nThe vast amount of social and behavioral information potentially\navailable on the Internet has made it a prime target for researchers\nwishing to study the dynamics of human interactions and their\nconsequences in this virtual medium. Researchers can potentially\ncollect data from widely dispersed population sat relatively low cost\nand in less time than similar efforts in the physical world. As a\nresult, there has been an increase in the number of Internet studies,\nranging from surveys to naturalistic observation (Frankel & Siang\n1999: 1).\n\n\nIn the medical/biomedical contexts, Internet research has grown\nrapidly. Also in 1999, Gunther Eysenbach wrote the first editorial to\nthe newly formed Journal of Medical Internet Research. There\nwere three driving forces behind the inception of this journal, and\nEysenbach called attention to the growing social and interpersonal\naspects of the Internet:\n\n\nFirst, Internet protocols are used for clinical information and\ncommunication. In the future, Internet technology will be the platform\nfor many telemedical applications. Second, the Internet revolutionizes\nthe gathering, access and dissemination of non-clinical information in\nmedicine: Bibliographic and factual databases are now world-wide\naccessible via graphical user interfaces, epidemiological and public\nhealth information can be gathered using the Internet, and\nincreasingly the Internet is used for interactive medical education\napplications. Third, the Internet plays an important role for consumer\nhealth education, health promotion and teleprevention. (As an aside,\nit should be emphasized that \u201chealth education\u201d on the\nInternet goes beyond the traditional model of health education, where\na medical professional teaches the patient: On the Internet, much\n\u201chealth education\u201d is done\n\u201cconsumer-to-consumer\u201d by means of patient self support\ngroups organizing in cyberspace. These patient-to-patient interchanges\nare becoming an important part of healthcare and are redefining the\ntraditional model of preventive medicine and health promotion).\n\n\nWith scholarly attention growing and with the 1999 AAAS report\n(Frankel & Siang 1999) calling for action, other professional\nassociations took notice and began drafting statements or guidelines,\nor addendum to their extant professional standards. For example, The\nBoard of Scientific Affairs (BSA) of the American Psychological\nAssociation established an Advisory Group on Conducting Research on\nthe Internet in 2001; the American Counseling Association\u2019s 2005\nrevision to its Code of Ethics; the Association of Internet\nResearchers (AoIR) Ethics Working Group Guidelines, the National\nCommittee for Research Ethics in the Social Sciences and the\nHumanities (NESH Norway), among others, have directed researchers and\nreview boards to the ethics of Internet research, with attention to\nthe most common areas of ethical concern (see\n OIR\n for links).\n\nWhile many researchers focus on traditional research ethics\nprinciples, conceptualizations of Internet research ethics depend on\ndisciplinary perspectives. Some disciplines, notably from the arts and\nhumanities, posit that Internet research is more about context and\nrepresentation than about \u201chuman subjects\u201d, suggesting\nthere is no intent, and thus minimal or no harm, to engage in research\nabout actual persons. The debate has continued since the early 2000s.\nWhite (2002) argued against extant regulations that favored or\nprivileged specific ideological, disciplinary and cultural\nprerogatives, which limit the freedoms and creativity of arts and\nhumanities research. For example, she notes that the AAAS report\n\u201cconfuses physical individuals with constructed materials and\nhuman subjects with composite cultural works\u201d, again calling\nattention to the person versus text divide that has permeated Internet\nresearch ethics debates. Another example of disciplinary differences\ncomes from the Oral History Association, which acknowledged the\ngrowing use of the Internet as a site for research:\n\n\nSimply put, oral history collects memories and personal commentaries\nof historical significance through recorded interviews. An oral\nhistory interview generally consists of a well-prepared interviewer\nquestioning an interviewee and recording their exchange in audio or\nvideo format. Recordings of the interview are transcribed, summarized,\nor indexed and then placed in a library or archives. These interviews\nmay be used for research or excerpted in a publication, radio or video\ndocumentary, museum exhibition, dramatization or other form of public\npresentation. Recordings, transcripts, catalogs, photographs and\nrelated documentary materials can also be posted on the Internet\n(Ritchie 2003: 19).\n\n\nWhile the American Historical Association (A. Jones 2008) has argued\nthat such research be \u201cexplicitly exempted\u201d from ethical\nreview board oversight, the use of the Internet could complicate such\na stance if such data became available in public settings or available\n\u201cdownstream\u201d with potential, unforeseeable risks to\nreputation, economic standing, or psychological harm, should\nidentification occur.\n\nUnder the concept of text rather than human subjects, Internet\nresearch rests on arguments of publication and copyright; consider the\nvenue of a blog, which does not meet the definition of human subject\nas in 45 C.F.R. \u00a7 46.102f (2009), as interpreted by most ethical\nreview boards. A researcher need not obtain consent to use text from a\nblog, as it is generally considered publicly available, textual,\npublished material. This argument of the \u201cpublic park\u201d\nanalogy that has been generally accepted by researchers is appropriate\nfor some Internet venues and tools, but not all: Context, intent,\nsensitivity of data, and expectations of Internet participants were\nidentified in 2004 by Sveninngsson as crucial markers in Internet\nresearch ethics considerations.\n\nBy the mid-2000s, with three major anthologies published, and a\ngrowing literature base, there was ample scholarly literature\ndocumenting IRE across disciplines and methodologies, and\nsubsequently, there was anecdotal data emerging from the review boards\nevaluating such research. In search of empirical data regarding the\nactual review board processes of Internet research from a human\nsubjects perspective, Buchanan and Ess surveyed over 700 United States\nethics review boards, and found that boards were primarily concerned\nwith privacy, data security and confidentiality, and ensuring\nappropriate informed consent and recruitment procedures (Buchanan\n& Ess 2009; Buchanan & Hvizdak 2009).\n\nIn 2008, the Canadian Tri-Council\u2019s Social Sciences and\nHumanities Research Ethics Special Working Committee: A Working\nCommittee of the Interagency Advisory Panel on Research Ethics was\nconvened (Blackstone et al. 2008); and in 2010, a meeting at the\nSecretary\u2019s Advisory Committee to the Office for Human Research\nProtections highlighted Internet research (SACHRP 2010). Such\nprominent professional organizations as the Public Responsibility in\nMedicine and Research (PRIM&R) and the American Educational\nResearch Association (AERA) have begun featuring Internet research\nethics regularly at their conferences and related publications.\n\nRecently, disciplines not traditionally involved in human subjects\nresearch have begun their own explorations of IRE. For example,\nresearchers in computer security have actively examined the tenets of\nresearch ethics in CS and ICT (Aycock et al. 2012; Dittrich, Bailey,\n& Dietrich 2011; Carpenter & Dittrich 2012; Buchanan et al.\n2011). Notably, the U.S. Federal Register requested comments on\n\u201cThe Menlo Report\u201d in December 2011, which calls for a\ncommitment by computer science researchers to the three principles of\nrespect for persons, beneficence, and justice, while also adding a\nfourth principle on respect for law and public interest (Homeland\nSecurity 2011). SIGCHI, an international society for professionals,\nacademics, and students interested in human-technology and\nhuman-computer interaction (HCI), has increasingly focused on how IRE\napplies to work in their domain (Frauenberger et al. 2017; Fiesler et\nal. 2018).\n4. Key Ethical Issues in Internet Research\n4.1 Privacy\n\nPrinciples of research ethics dictate that researchers must ensure\nthere are adequate provisions to protect the privacy of subjects and\nto maintain the confidentiality of any data collected. A violation of\nprivacy or breach of confidentiality presents a risk of serious harm\nto participants, ranging from the exposure of personal or sensitive\ninformation, the divulgence of embarrassing or illegal conduct, or the\nrelease of data otherwise protected under law.\n\nResearch ethics concerns around individual privacy is often expressed\nin terms of the level of linkability of data to individuals, and the\npotential harms from disclosure of information As Internet research\nhas grown in complexity and computational sophistication, ethics\nconcerns have focused on current and future uses of data, and the\npotential downstream harms that could occur. Protecting research\nparticipants\u2019 privacy and confidentiality is typically achieved\nthrough a combination of research tactics and practices, including\nengaging in data collection under controlled or anonymous\nenvironments, the scrubbing of data to remove personally identifiable\ninformation (PII), or the use of access restrictions and related data\nsecurity methods. And, the specificity and characteristics of the data\nwill often dictate if there are regulatory considerations, in addition\nto the methodological considerations around privacy and\nconfidentiality. For example, personally identifiable information\n(PII) typically demands the most stringent protections. The National\nInstitutes of Health (NIH), for example, defines PII as:\n\n\nany information about an individual maintained by an agency,\nincluding, but not limited to, education, financial transactions,\nmedical history, and criminal or employment history and information\nwhich can be used to distinguish or trace an individual\u2019s\nidentity, such as their name, SSN, date and place of birth,\nmother\u2019s maiden name, biometric records, etc., including any\nother personal information that is linked or linkable to an individual\n(NIH 2010).\n\n\nTypically, examples of identifying pieces of information have included\npersonal characteristics (such as date of birth, place of birth,\nmother\u2019s maiden name, gender, sexual orientation, and other\ndistinguishing features and biometrics information, such as height,\nweight, physical appearance, fingerprints, DNA and retinal scans),\nunique numbers or identifiers assigned to an individual (such as a\nname, address, phone number, social security number, driver\u2019s\nlicense number, financial account numbers), and descriptions of\nphysical location (GIS/GPS log data, electronic bracelet monitoring\ninformation).\n\nThe 2018 EU General Data Protection Regulation lays out the legal and\nregulatory requirements for data use across the EU. Mondschein &\nMonda (2018) provides a thorough discussion on the different types of\ndata that are considered in the GDPR: Personal data, such as names,\nidentification numbers, location data, and so on; Special categories\nof personal data, such as race or ethic origin, political opinions, or\nreligious beliefs; Pseudonymous data, referring to data that has been\naltered so the subject cannot be directly identified without having\nfurther information; Anonymous data, information which does not relate\nto an identifiable natural person or to personal data rendered\nanonymous in such a manner that the data subject is not or no longer\nidentifiable. They also advise researchers to consider\n\n\ndata protection issues at an early stage of a research project is of\ngreat importance specifically in the context of large-scale research\nendeavours that make use of personal data (2018: 56).\n\n\nInternet research introduces new complications to these longstanding\ndefinitions and regulatory frameworks intended to protect subject\nprivacy. For example, researchers increasingly are able to collect\ndetailed data about individuals from sources such as Facebook,\nTwitter, blogs or public email archives, and these rich data sets can\nmore easily be processed, compared, and combined with other data (and\ndatasets) available online. In numerous cases, both researchers and\nmembers of the general public have been able to re-identify\nindividuals by analyzing and comparing such datasets, using\ndata-fields as benign as one\u2019s zip code (Sweeny 2002), random\nWeb search queries (Barbaro & Zeller 2006), or movie ratings\n(Narayanan & Shmatikov 2008) as the vital key for reidentification\nof a presumed anonymous user. Prior to widespread Internet-based data\ncollection and processing, few would have considered one\u2019s movie\nratings or zipcode as personally-identifiable. Yet, these cases reveal\nthat merely stripping traditional \u201cidentifiable\u201d\ninformation such as a subject\u2019s name, address, or social\nsecurity number is no longer sufficient to ensure data remains\nanonymous (Ohm 2010), and requires the reconsideration of what is\nconsidered \u201cpersonally identifiable information\u201d (Schwartz\n& Solove 2011). This points to the critical distinction between\ndata that is kept confidential versus data that is truly anonymous.\nIncreasingly, data are rarely completely anonymous, as researchers\nhave routinely demonstrated they can often reidentify individuals\nhidden in \u201canonymized\u201d datasets with ease (Ohm 2010). This\nreality places new pressure on ensuring datasets are kept, at the\nleast, suitably confidential through both physical and computational\nsecurity measures. These measures may also include requirements to\nstore data in \u201cclean rooms\u201d, or in non-networked\nenvironments in an effort to control data transmission.\n\nSimilarly, new types of data often collected in Internet research\nmight also be used to identify a subject within a previously-assumed\nanonymous dataset. For example, Internet researchers might collect\nInternet Protocol (IP) addresses when conducting online surveys or\nanalyzing transaction logs. An IP address is a unique identifier that\nis assigned to every device connected to the Internet; in most cases,\nindividual computers are assigned a unique IP address, while in some\ncases the address is assigned to a larger node or Internet gateway for\na collection of computers. Nearly all websites and Internet service\nproviders store activity logs that link activity with IP addresses, in\nmany cases, eventually to specific computers or users. Current U.S.\nlaw does not hold IP addresses to be personally identifiable\ninformation, while other countries and regulatory bodies do. For\nexample, the European Data Privacy Act at Article 29, holds that IP\naddresses do constitute PII. Buchanan et al. (2011), note, however,\nthat under the U.S. Civil Rights Act, for the purposes of the HIPAA\n Act,[2]\n IP addresses are considered a form of PII (45 C.F.R. \u00a7 164.514\n 2002).[3]\n There could potentially be a reconsideration by other federal\nregulatory agencies over IP addresses as PII, and researchers and\nboards will need to be attentive should such change occur.\n\nA similar complication emerges when we consider the meaning of\n\u201cprivate information\u201d within the context of Internet-based\nresearch. U.S. federal regulations define \u201cprivate\ninformation\u201d as:\n\n\n[A]ny information about behavior that occurs in a context in which an\nindividual can reasonably expect that no observation or recording is\ntaking place, and information that has been provided for specific\npurposes by an individual and that the individual can reasonably\nexpect will not be made public (for example, a medical record) (45\nC.F.R. \u00a7 46.102(f) 2009).\n\n\nThis standard definition of \u201cprivate information\u201d has two\nkey components. First, private information is that which subjects\nreasonably expect is not normally monitored or collected. Second,\nprivate information is that which subjects reasonably expect is not\ntypically publicly available. Conversely, the definition also suggests\nthe opposite is true: if users cannot reasonably expect data\nisn\u2019t being observed or recorded, or they cannot expect data\nisn\u2019t publicly available, then the data does not rise to the\nlevel of \u201cprivate information\u201d requiring particular\nprivacy protections. Researchers and REBs have routinely worked with\nthis definition of \u201cprivate information\u201d to ensure the\nprotection of individuals\u2019 privacy.\n\nThese distinctions take on greater weight, however, when considering\nthe data environments and collection practices common with\nInternet-based research. Researchers interested in collecting or\nanalyzing online actions of subjects\u2014perhaps through the mining\nof online server logs, the use of tracking cookies, or the scraping of\nsocial media profiles and feeds\u2014could argue that subjects do not\nhave a reasonable expectation that such online activities are not\nroutinely monitored since nearly all online transactions and\ninteractions are routinely logged by websites and service providers.\nThus, online data trails might not rise to the level of \u201cprivate\ninformation\u201d. However, numerous studies have indicated that\naverage Internet users have incomplete understandings of how their\nactivities are routinely tracked, and the related privacy practices\nand policies of the sites they visit (Hoofnagle & King 2008\n [OIR];\n Milne & Culnan 2004; Tsai et al. 2006). Hudson and Bruckman\n(2005) conducted empirical research on users\u2019 expectations and\nunderstandings of privacy, finding that participants\u2019\nexpectations of privacy within public chatrooms conflicted with what\nwas actually a very public online space. Rosenberg (2010) examined the\npublic/private distinction in the realm of virtual worlds, suggesting\nresearchers must determine what kind of social norms and relations\npredominate an online space before making assumptions about the\n\u201cpublicness\u201d of information shared within. Thus, it\nremains unclear whether Internet users truly understand if and when\ntheir online activity is regularly monitored and tracked, and what\nkind of reasonable expectations truly exist. This ambiguity creates\nnew challenges for researchers and REBs when trying to apply the\ndefinition of \u201cprivate information\u201d to ensure subject\nprivacy is properly addressed (Zimmer 2010).\n\nThis complexity in addressing subject privacy in Internet research is\nfurther compounded with the rise of social networking as a place for\nthe sharing of information, and a site for research. Users\nincreasingly share more and more personal information on platforms\nlike Facebook or Twitter. For researchers, social media platforms\nprovide a rich resource for study, and much of the content is\navailable to be viewed and downloaded with minimal effort. Since much\nof the information posted to social media sites is publicly viewable,\nit thus fails to meet the standard regulatory definition of\n\u201cprivate information\u201d. Therefore, researchers attempting\nto collect and analyze social media postings might not treat the data\nas requiring any particular privacy considerations. Yet, social media\nplatforms represent a complex environment of social interaction where\nusers are often required to place friends, lovers, colleagues, and\nminor acquaintances within the same singular category of\n\u201cfriends\u201d, where privacy policies and terms of service are\nnot fully understood (Madejski et al. 2011), and where the technical\ninfrastructures fail to truly support privacy projections (Bonneau\n& Preibush 2010) and regularly change with little notice (Stone\n2009\n [OIR];\n Zimmer 2009\n [OIR]).\n As a result, it is difficult to understand with any certainty what a\nuser\u2019s intention was when posting an item onto a social media\nplatform (Acquisti & Gross 2006). The user may have intended the\npost for a private group but failed to completely understand how to\nadjust the privacy settings accordingly. Or, the information might\nhave previously been restricted to only certain friends, but a change\nin the technical platform suddenly made the data more visible to\nall.\n\nOhm (2010) warns that\n\n\nthe utility and privacy of data are linked, and so long as data is\nuseful, even in the slightest, then it is also potentially\nreidentifiable (2010: 1751).\n\n\nWith the rapid growth of Internet-based research, Ohm\u2019s concern\nbecomes even more dire. The traditional definitions and approaches to\nunderstanding the nature of privacy, anonymity, and precisely what\nkind of information deserves protection becomes strained, forcing\nresearchers and REBs to consider more nuanced theories of privacy\n(Nissenbaum 2009) and approaches to respecting and projecting subject\nprivacy (Markham 2012; Zimmer 2010).\n4.2 Recruitment\n\nDepending on the type of Internet research being carried out,\nrecruitment of participants may be done in a number of ways. As with\nany form of research, the study population or participants are\nselected for specific purposes (i.e., an ethnographic study of a\nparticular group on online game players), or, can be selected from a\nrange of sampling techniques (i.e., a convenience sample gleaned from\nthe users of Amazon\u2019s Mechanical Turk crowdsourcing\n platform[4]).\n In the U.S. context, a recruitment plan is considered part of the\ninformed consent process, and as such, any recruitment script or\nposting must be reviewed and approved by an REB prior to posting or\nbeginning solicitation (if the project is human subjects research).\nFurther, the selection of participants must be impartial and unbiased,\nand any risks and benefits must be justly distributed. This concept is\nchallenging to apply in Internet contexts, in which populations are\noften self-selected and can be exclusive, depending on membership and\naccess status, as well as the common disparities of online access\nbased on economic and social variables. Researchers also face\nrecruitment challenges due to online subjects\u2019 potential\nanonymity, especially as it relates to the frequent use of pseudonyms\nonline, having multiple or alternative identities online, and the\ngeneral challenges of verifying a subject\u2019s age and demographic\ninformation. Moreover, basic ethical principles for approaching and\nrecruiting participants involve protecting their privacy and\nconfidentiality. Internet research can both maximize these\nprotections, as an individual may never be known beyond a screen name\nor avatar existence; or, conversely, the use of IP addresses,\nplacement of cookies, availability and access to more information than\nnecessary for the research purposes, may minimize the protections of\nprivacy and confidentiality.\n\nMuch recruitment is taking place via social media; examples include\npush technologies, a synchronous approach in which a text or tweet is\nsent from a researcher to potential participants based on profile\ndata, platform activity, or geolocation. Other methods of pull\ntechnologies recruitment include direct email, dedicated web pages,\nYouTube videos, direct solicitation via \u201cstickies\u201d posted\non fora or web sites directing participants to a study site, or data\naggregation or scraping data for potential recruitment. Regardless of\nthe means used, researchers must follow the terms of the\nsite\u2014from the specific norms and nuances governing a site or\nlocale to the legal issues in terms of service agreements. For\nexample, early pro-anorexia web sites (see Overbeke 2008) were often\ntreated as sensitive spaces deserving spcicial consideration, and\nresearchers were asked to respect the privacy of the participants and\nnot engage in research (Walstrom 2004). In the gaming context,\nReynolds and de Zwart (2010) ask:\n\n\nHas the researcher disclosed the fact that he or she is engaged in\nresearch and is observing/interacting with other players for the\npurposes of gathering research data? How does the research project\nimpact upon the community and general game play? Is the research\nproject permitted under the Terms of Service?\n\n\nColvin and Lanigan (2005: 38) suggest researchers\n\n\nSeek permission from Web site owners and group moderators before\nposting recruitment announcements, Then, preface the recruitment\nannouncement with a statement that delineates the permission that has\nbeen granted, including the contact person and date received. Identify\na concluding date (deadline) for the research study and make every\neffort to remove recruitment postings, which often become embedded\nwithin Web site postings.\n\n\nBarratt and Lenton, among others, agree:\n\n\nIt is critical, therefore, to form partnerships with online community\nmoderators by not only asking their permission to post the request,\nbut eliciting their feedback and support as well (2010: 71).\n\n\nMendelson (2007) and Smith and Leigh (1997) note that recruitment\nnotices need to contain more information than the typical flyers or\nadvertisements used for newspaper advertisements. Mentioning the\napproval of moderators is important for establishing authenticity, and\nso is providing detailed information about the study and how to\ncontact both the researchers and the appropriate research ethics\nboard.\n\nGiven the array of techniques possible for recruitment, the concept of\n\u201cresearch spam\u201d requires attention. The Council of\nAmerican Survey Research warns\n\n\nResearch Organizations should take steps to limit the number of survey\ninvitations sent to targeted respondents by email solicitations or\nother methods over the Internet so as to avoid harassment and response\nbias caused by the repeated recruitment and participation by a given\npool (or panel) of data subjects (CASRO 2011: I.B.3).\n\n\nUltimately, researchers using Internet recruitment measures must\nensure that potential participants are getting enough information in\nboth the recruitment materials and any subsequent consent documents.\nResearchers must ensure that recruitment methods do not lead to an\nindividual being identified without their permission, and if such\nidentification is possible, are there significant risks involved?\n4.3 Informed Consent\n\nAs the cornerstone of human subjects protections, informed consent\nmeans that participants are voluntarily participating in the research\nwith adequate knowledge of relevant risks and benefits. Providing\ninformed consent typically includes the researcher explaining the\npurpose of the research, the methods being used, the possible outcomes\nof the research, as well as associated risks or harms that the\nparticipants might face. The process involves providing the recipient\nclear and understandable explanations of these issues in a concise\nway, providing sufficient opportunity to consider them and enquire\nabout any aspect of the research prior to granting consent, and\nensuring the subject has not been coerced into participating. Gaining\nconsent in traditional research is typically done verbally or in\nwriting, either in a face-to-face meeting where the researcher reviews\nthe document, through telephone scripts, through mailed documents,\nfax, or video, and can be obtained with the assistance of an advocate\nin the case of vulnerable populations. Most importantly, informed\nconsent was built on the ideal of \u201cprocess\u201d and the\nverification of understanding, and thus, requires an ongoing\ncommunicative relationship between and among researchers and their\nparticipants. The emergence of the Internet as both a tool and a venue\nfor research has introduced challenges to this traditional approach to\ninformed consent.\n\nIn most regulatory frameworks, there are instances when informed\nconsent might be waived, or the standard processes of obtaining\ninformed consent might be modified, if approved by a research ethics\n board.[5]\n Various forms of Internet research require different approaches to\nthe consent process. Some standards have emerged, depending on venue\n(i.e., an online survey platform versus a private Facebook group).\nHowever, researchers are encouraged to consider waiver of consent\nand/or documentation, if appropriate, by using the flexibilities of\ntheir extant regulations.\n\nWhere consent is required but documentation has been waived by an\nethical review board, a \u201cportal\u201d can be used to provide\nconsent information. For example, a researcher may send an email to\nthe participant with a link a separate portal or site information page\nwhere information on the project is contained. The participant can\nread the documentation and click on an \u201cI agree\u201d\nsubmission. Rosser et al. (2010) recommend using a\n\u201cchunked\u201d consent document, whereby individuals can read\nspecific sections, agree, and then continue onwards to completion of\nthe consent form, until reaching the study site.\n\nIn addition to portals, researchers will often make use of consent\ncards or tokens; this alleviates concerns that unannounced researcher\npresence is unacceptable, or, that a researcher\u2019s presence is\nintrusive to the natural flow and movement of a given locale. Hudson\nand Bruckman (2004, 2005) highlighted the unique challenges in gaining\nconsent in chat rooms, while Lawson (2004) offers an array of consent\npossibilities for synchronous computer-mediated communication. There\nare different practical challenges in the consent process in Internet\nresearch, given the fluidity and temporal nature of Internet\nspaces.\n\nIf documentation of consent is required, some researchers have\nutilized alternatives such as electronic signatures, which can range\nfrom a simple electronic check box to acknowledge acceptance of the\nterms to more robust means of validation using encrypted digital\nsignatures, although the validity of electronic signatures vary by\njurisdiction.\n\nRegardless of venue, informed consent documents are undergoing changes\nin the information provided to research participants. While the basic\nelements of consent remain intact, researchers must now acknowledge\nwith less certainty specific aspects of their data longevity, risks to\nprivacy, confidentiality and anonymity (see\n \u00a74.1 Privacy, above),\n and access to or ownership of data. Research participants must\nunderstand that their terms of service or end user license agreement\nconsent is distinct from their consent to participate in research.\nAnd, researchers must address and inform participants/subjects about\npotential risk of data intrusion or misappropriation of data if\nsubsequently made public or available outside of the confines of the\noriginal research. Statements should be revised to reflect such\nrealities as cloud storage (see\n \u00a74.4 below)\n and data sharing.\n\nFor example, Aycock et al. (2012: 141) describe a continuum of\nsecurity and access statements used in informed consent documents:\n\n\u201cNo others will have access to the data\u201d\n\u201cAnonymous identifiers will be used during all data\ncollection and analysis and the link to the subject identifiers will\nbe stored in a secure manner\u201d\n\u201cData files that contain summaries of chart reviews and\nsurveys will only have study numbers but no data to identify the\nsubject. The key [linking] subject names and these study identifiers\nwill be kept in a locked file\u201d\n\u201cElectronic data will be stored on a password protected and\nsecure computer that will be kept in a locked office. The software\n\u2018File Vault\u2019 will be used to protect all study data loaded\nto portable laptops, flash drives or other storage media. This will\nencode all data\u2026 using Advanced Encryption Standard with\n128-bit keys (AES-128)\u201d\n\n\nThis use of encryption in the last statement may be necessary in\nresearch including sensitive data, such as medical, sexual, health,\nfinancial, and so on. Barratt and Lenton (2010), in their research on\nillicit drug use and online forum behaviors, also provide guidance\nabout use of secure transmission and encryption as part of the consent\nprocess.\n\nIn addition to informing participants about potential risks and\nemploying technological protections, NIH-funded researchers whose work\nincludes projects with identifiable, sensitive information will\nautomatically be issued a Certificate of Confidentiality:\n\n\nCoCs protect the privacy of research subjects by prohibiting\ndisclosure of identifiable, sensitive research information to anyone\nnot connected to the research except when the subject consents or in a\nfew other specific situations (NIH 2021\n [OIR]).\n\n\nHowever, these do not protect against release of data outside of the\nU.S. Given the reality of Internet research itself, which inherently\nspans borders, new models may be in order to ensure confidentiality of\ndata and protections of data. Models of informed consent for\ntraditional international research are fundamentally challenging due\nto cultural specificity and norms (Annas 2009; Boga et al. 2011;\nKrogstad et al. 2010); with Internet research, where researchers may\nbe unaware of the specific location of an individual, consent takes on\nsignificantly higher demands. While current standards of practice show\nthat consent models stem from the jurisdiction of the researcher and\nsponsoring research institution, complications arise in the face of\nage verification, age of majority/consent, reporting of adverse\neffects or complaints with the research process, and authentication of\nidentity. Various jurisdictional laws around privacy are relevant for\nthe consent process; a useful tool is Forrester\u2019s Data Privacy\nHeat Map, which relies on in-depth analyses of the data\nprivacy-related laws and cultures of countries around the world,\nhelping researchers design appropriate approaches to privacy and data\nprotection given the particular context (see\n OIR).\n\nIn addition, as more federal agencies and funding bodies across the\nglobe encourage making research data publicly-available (i.e., NSF,\nNIH, Wellcome Trust, Research Councils U.K.), the language used in\nconsent documents will change accordingly to represent this intended\nlongevity of data and opportunities for future, unanticipated use.\nGiven the ease with which Internet data can flow between and among\nInternet venues, changes in the overall accessibility of data might\noccur (early \u201cprivate\u201d newsgroup conversations were made\n\u201cpublicly searchable\u201d when Google bought DejaNews), and\nreuse and access by others is increasingly possible with shared\ndatasets. Current data sharing mandates must be considered in the\nconsent process. Alignment between a data sharing policy and an\ninformed consent document is imperative. Both should include\nprovisions for appropriate protection of privacy, confidentiality,\nsecurity, and intellectual property.\n\nThere is general agreement in the U.S. that individual consent is not\nnecessary for researchers to use publicly available data, such as\npublic Twitter feeds. Recommendations were made by The National Human\nSubjects Protection Advisory Committee (NHRPAC) in 2002 regarding\npublicly available data sets (see\n OIR).\n Data use or data restriction agreements are commonly used and set the\nparameters of use for researchers.\n\nThe U.K. Data Archive (2011\n [OIR])\n provides guidance on consent and data sharing:\n\n\nWhen research involves obtaining data from people, researchers are\nexpected to maintain high ethical standards such as those recommended\nby professional bodies, institutions and funding organisations, both\nduring research and when sharing data. Research data \u2014 even\nsensitive and confidential data \u2014 can be shared ethically and\nlegally if researchers pay attention, from the beginning of research,\nto three important aspects:\n\n\u2022 when gaining informed consent, include provision for data\nsharing\n\n\u2022 where needed, protect people\u2019s identities by anonymising\ndata\n\n\u2022 consider controlling access to data These measures should be\nconsidered jointly. The same measures form part of good research\npractice and data management, even if data sharing is not envisioned.\nData collected from and about people may hold personal, sensitive or\nconfidential information. This does not mean that all data obtained by\nresearch with participants are personal or confidential.\n\n\nData sharing made public headlines in 2016 when a Danish researcher\nreleased a data set comprised of scraped data from nearly 70,000 users\nof the OkCupid online dating site. The data set was highly\nreidentifiable and included potentially sensitive information,\nincluding usernames, age, gender, geographic location, what kind of\nrelationship (or sex) they\u2019re interested in, personality traits,\nand answers to thousands of profiling questions used by the site. The\nresearcher claimed the data were public and thus, such sharing and use\nwas unproblematic. Zimmer (2016) was among many privacy and ethics\nscholars who critiqued this stance.\n\nThe Danish researchers did not seek any form of consent or debriefing\non the collection and use of the data, nor did they have any ethics\noversight. Many researchers and ethics boards are, however, attempting\nto mitigate some of these ethical concerns by including blanket\nstatements in their consent processes, indicating such precautions for\nresearch participants. For example,\n\n\nI understand that online communications may be at greater risk for\nhacking, intrusions, and other violations. Despite these\npossibilities, I consent to participate.\n\n\nA more specific example comes from the Canadian context when\nresearchers propose to use specific online survey tools hosted in the\nUnited States; REBs commonly recommend the following type language for\nuse in informed consent documents:\n\n\nPlease note that the online survey is hosted by Company ABC which is a\nweb survey company located in the U.S.A. All responses to the survey\nwill be stored and accessed in the U.S.A. This company is subject to\nU.S. Laws, in particular, to the U.S. Patriot Act/Domestic Security\nEnhancement Act that allows authorities access to the records that\nyour responses to the questions will be stored and accessed in the\nU.S.A. The security and private policy for Company ABC can be viewed\nat\n http://\u2026/.[6]\n\n\nResearchers are also encouraged to review the Terms of Use and Terms\nof Service of the application that are being used, demonstrating its\ndetails to the REB in the application and informing participants of\nsuch details in the informed consent form or script. Researchers are\nalso encouraged to consider broader contextual factors of the data\nsource and research goals when weighing the possible violation of a\nplatform\u2019s Terms of Service (Fiesler, Beard, & Keegan\n2020).\n4.3.1 Minors and Consent\n\nInternet research poses particular challenges to age verification,\nassent and consent procedures, and appropriate methodological\napproaches with minors. Age of consent varies across countries,\nstates, communities, and locales of all sorts. For research conducted\nor supported by U.S. federal agencies bound by the Common Rule,\nchildren are\n\n\npersons who have not attained the legal age for consent [18, in the\nU.S.] to treatments or procedures involved in the research, under the\napplicable law of the jurisdiction in which the research will be\nconducted (45 C.F.R. \u00a7 46.402(a) 2009).\n\n\nGoldfarb (2008) provides an exhaustive discussion of age of majority\nacross the U.S. states, with a special focus on clinical\nresearch, noting children must be seven or older to assent to\nparticipation (see 45 C.F.R. \u00a7 46 Subpart D 2009).\n\nSpriggs (2010), from the Australian context, notes that while no\nformal guidance exists on Internet research and minors under the\nNational Statement, she advises:\n\n\nParental consent may be needed when information is potentially\nidentifiable. Identifiable information makes risks to individuals\nhigher and may mean that the safety net of parental consent is\npreferable.\nThere is also a need to consider whether seeking parental consent\nwould make things worse e.g., by putting a young person from a\ndysfunctional home at risk or result in disclosure to the researcher\nof additional identifying information about the identity and location\nof the young person. Parental consent may be \u201ccontrary to the\nbest interests\u201d of the child or young person when it offers no\nprotection or makes matters worse (2010: 30).\n\n\n\nTo assist with the consent process, age verification measures can be\nused. These can range from more technical software applications to\nless formal knowledge checks embedded in an information sheet or\nconsent document. Multiple confirmation points (asking for age, later\nasking for year of birth, etc.) are practical measures for\nresearchers. Depending on the types of data, sensitivity of data, use\nof data, researchers and boards will carefully construct the\nappropriate options for consent, including waiver of consent, waiver\nof documentation, and/or waiver of parental consent.\n4.4 Cloud Computing and Research Ethics\n\nRecent developments in cloud computing platforms have led to unique\nopportunities\u2014and ethical challenges\u2014for researchers.\nCloud computing describes the deployment of computing resources via\nthe Internet, providing on-demand, flexible, and scalable computing\nfrom remote locations. Examples include web-based email and\ncalendaring services provided by Google or Yahoo, online productivity\nplatforms like Google Docs or Microsoft Office 365, online file\nstorage and sharing platforms like Dropbox or Box.net, and large-scale\napplication development and data processing platforms such as Google\nApps, Facebook Developers Platform, and Amazon Web Services.\n\nAlongside businesses and consumers, researchers have begun utilizing\ncloud computing platforms and services to assist in various tasks,\nincluding subject recruitment, data collection and storage,\nlarge-scale data processing, as well as communication and\ncollaboration (Allan 2011\n [OIR];\n X. Chen et al. 2010\n [OIR]);\n Simmhan et al. 2008; Simmhan et al. 2009).\n\nAs reliance on cloud computing increases among researchers, so do the\nethical implications. Among the greatest concerns is ensuring data\nprivacy and security with cloud-based services. For researchers\nsharing datasets online for collaborative processing and analysis,\nsteps must be taken to ensure only authorized personnel have access to\nthe online data that might contain PII, but also that suitable\nencryption is used for data transfer and storage, and that the cloud\nservice provider maintains sufficient security to prevent breaches.\nFurther, once research data is uploaded to a third-party cloud\nprovider, attention must be paid to the terms of service for the\ncontracted provider to determine what level of access to the data, if\nany, might be allowed to advertisers, law enforcement, or other\nexternal agents.\n\nAlongside the privacy and security concerns, researchers also have an\nethical duty of data stewardship which is further complicated when\nresearch data is placed in the cloud for storage or processing. Cloud\nproviders might utilize data centers spread across the globe, meaning\nresearch data might be located outside the United States, and its\nlegal jurisdictions. Terms of service might grant cloud providers a\nlicense to access and use research data for purposes not initially\nintended or approved of by the subjects involved. Stewardship may\nrequire the prompt and complete destruction of research data, a\nmeasure complicated if a cloud provider has distributed and backed-up\nthe data across multiple locations.\n\nA more unique application of cloud computing for research involves the\ncrowdsourcing of data analysis and processing functions, that is,\nleveraging the thousands of users of various online products and\nservices to complete research related tasks remotely. Examples include\nusing a distributed network of video game players to assist in solving\nprotein folding problems (Markoff 2010), and leveraging Amazon\u2019s\nMechanical Turk crowdsourcing marketplace platform to assist with\nlarge scale data processing and coding functions that cannot be\nautomated (Conley & Tosti-Kharas 2014; J. Chen et al. 2011). Using\ncloud-based platforms can raise various critical ethical and\nmethodological issues.\n\nFirst, new concerns over data privacy and security emerge when\nresearch tasks are widely distributed across a global network of\nusers. Researchers must take great care in ensuring research data\ncontaining personal or sensitive information isn\u2019t accessible by\noutsourced labor, or that none of the users providing crowdsourced\nlabor are able to aggregate and store their own copy of the research\ndataset. Second, crowdsourcing presents ethical concerns over trust\nand validity of the research process itself. Rather than a local team\nof research assistants usually under a principal investigator\u2019s\nsupervision and control, crowdsourcing tends to be distributed beyond\nthe direct management or control of the researcher, providing less\nopportunity to ensure sufficient training for the required tasks.\nThus, researchers will need to create additional means of verifying\ndata results to confirm tasks are completed properly and\ncorrectly.\n\nTwo additional ethical concerns with crowdsourcing involve labor\nmanagement and authorship. Mechanical Turk users were not originally\nintended to be research subjects, first and foremost. However,\nresearchers using Mechanical Turks must ensure that the laborers on\nthe other end of the cloud-based relationship are not being exploited,\nthat they are legally eligible to be working for hire, and that the\nincentives provided are real, meaningful, and appropriate (Scholz\n2008; Williams 2010\n [OIR).\n\nFinally, at the end of a successful research project utilizing\ncrowdsourcing, a researcher may be confronted with the ethical\nchallenge of how to properly acknowledge the contributions made by\n(typically anonymous) laborers. Ethical research requires the fair and\naccurate description of authorship. Disciplines vary as to how to\nreport relative contributions made by collaborators and research\nassistants, and this dilemma increases when crowdsourcing is used to\nassist with the research project.\n4.5 Big Data Considerations\n\nAlgorithmic processing is a corollary of big data research, and\nnewfound ethical considerations have emerged. From \u201calgorithmic\nharms\u201d to \u201cpredictive analytics\u201d, the power of\ntoday\u2019s algorithms exceeds long-standing privacy beliefs and\nnorms. Specifically, the National Science and Technology Council\nnote:\n\n\u201cAnalytical algorithms\u201d as algorithms for prioritizing,\nclassifying, filtering, and predicting. Their use can create privacy\nissues when the information used by algorithms is inappropriate or\ninaccurate, when incorrect decisions occur, when there is no\nreasonable means of redress, when an individual\u2019s autonomy is\ndirectly related to algorithmic scoring, or when the use of predictive\nalgorithms chills desirable behavior or encourages other privacy\nharms. (NSTC 2016: 18).\n\n\nWhile the concept of big data is not new, and the term has been in\ntechnical discourses since the 1990s, public awareness and response to\nbig data research is much more recent. Following the rise of social\nmedia-based research, Buchanan (2016) has delineated the emergence of\n\u201cbig data\u201d-based research from 2012 to the present, with\nno signs of an endpoint.\n\nBig data research is challenging for research ethics boards, often\npresenting what the computer ethicist James Moor would call\n\u201cconceptual muddles\u201d: the inability to properly\nconceptualize the ethical values and dilemmas at play in a new\ntechnological context. Subject privacy, for example, is typically\nprotected within the context of research ethics through a combination\nof various tactics and practices, including engaging in data\ncollection under controlled or anonymous environments, limiting the\npersonal information gathered, scrubbing data to remove or obscure\npersonally identifiable information, and using access restrictions and\nrelated data security methods to prevent unauthorized access and use\nof the research data itself. The nature and understanding of privacy\nbecome muddled, however, in the context of big data research, and as a\nresult, ensuring it is respected and protected in this new domain\nbecomes challenging.\n\nFor example, the determination of what constitutes \u201cprivate\ninformation\u201d\u2014and thus triggering particular privacy\nconcerns\u2014becomes difficult within the context of big data\nresearch. Distinctions within the regulatory definition of\n\u201cprivate information\u201d\u2014namely, that it only applies\nto information which subjects reasonably expect is not normally\nmonitored or collected and not normally publicly\navailable\u2014become less clearly applicable when considering the\ndata environments and collection practices that typify big data\nresearch, such as the wholesale scraping of Facebook news feed content\nor public OKCupid accounts.\n\nWhen considered through the lens of the regulatory definition of\n\u201cprivate information\u201d, social media postings are often\nconsidered public, especially when users take no visible, affirmative\nsteps to restrict access. As a result, big data researchers might\nconclude subjects are not deserving of particular privacy\nconsideration. Yet, the social media platforms frequently used for big\ndata research purposes represent a complex environment of\nsocio-technical interactions, where users often fail to understand\nfully how their social activities might be regularly monitored,\nharvested, and shared with third parties, where privacy policies and\nterms of service are not fully understood and change frequently, and\nwhere the technical infrastructures and interfaces are designed to\nmake restricting information flows and protecting one\u2019s privacy\ndifficult.\n\nAs noted\n in \u00a74.1 above\n it becomes difficult to confirm a user\u2019s intention when sharing\ninformation on a social media platform, and whether users recognize\nthat providing information in a social environment also opens it up\nfor widespread harvesting and use by researchers. This uncertainty in\nthe intent and expectations of users of social media and\ninternet-based platforms\u2014often fueled by the design of the\nplatforms themselves\u2014create numerous conceptual muddles in our\nability to properly alleviate potential privacy concerns in big data\nresearch.\n\nThe conceptual gaps that exist regarding privacy and the definition of\npersonally identifiable information in the context of big data\nresearch inevitably lead to similar gaps regarding when informed\nconsent is necessary. Researchers mining Facebook profile information\nor public Twitter streams, for example, typically argue that no\nspecific consent is necessary due to the fact the information was\npublicly available. It remains unknown whether users truly understood\nthe technical conditions under which they made information visible on\nthese social media platforms or if they foresaw their data being\nharvested for research purposes, rather than just appearing onscreen\nfor fleeting glimpses by their friends and followers (Fiesler &\nProferes, 2018). In the case of the Facebook emotional contagion\nexperiment (Kramer, Guillory, & Hancock 2014), the lack of\nobtaining consent was initially rationalized through the notion that\nthe research appeared to have been carried out under Facebook\u2019s\nextensive terms of service, whose data use policy, while more than\n9,000 words long, does make passing mention to \u201cresearch\u201d.\nIt was later revealed, however, that the data use policy in effect\nwhen the experiment was conducted never mentioned\n\u201cresearch\u201d at all (Hill 2014).\n\nAdditional ethical concerns have arisen surrounding the large scale\ndata collection practices connected to machine learning and the\ndevelopment of artificial intelligence. For example, negative public\nattention have surrounded algorithms designed to infer sexual\norientation from photographs and facial recognition algorithms trained\non videos of transgender people. In both cases, ethical concerns have\nbeen raised about both the purpose of these algorithms and the fact\nthat the data that trained them (dating profile photos and YouTube\nvideos, respectively) was \u201cpublic\u201d but collected from\npotentially vulnerable populations without consent (Metcalf 2017;\nKeyes 2019). While those building AI systems cannot always control the\nconditions under which the data they utilize is collected, their\nincreased use of big datasets captured from social media or related\nsources raises a number of concerns beyond what typically is\nconsidered part of the growing focus on AI ethics: fairness,\naccountability and transparency in AI can only be fully possible when\ndata collection is achieved in a fair, ethical, and just manner (Stahl\n& Wright 2018; Kerry 2020).\n4.6 Internet Research and Industry Ethics\n\nThe Facebook emotional contagion experiment, discussed above, is just\none example in a larger trend of big data research conducted outside\nof traditional university-based research ethics oversight mechanisms.\nNearly all online companies and platforms analyze data and test\ntheories that often rely on data from individual users. Industry-based\ndata research, once limited to marketing-oriented \u201cA/B\ntesting\u201d of benign changes in interface designs or corporate\ncommunication messages, now encompasses information about how users\nbehave online, what they click and read, how they move, eat, and\nsleep, the content they consume online, and even how they move about\ntheir homes. Such research produces inferences about\nindividuals\u2019 tastes and preferences, social relations,\ncommunications, movements, and work habits. It implies pervasive\ntesting of products and services that are an integral part of intimate\ndaily life, ranging from connected home products to social networks to\nsmart cars. Except in cases where they are partnering with academic\ninstitutions, companies typically do not put internal research\nactivities through a formal ethical review process, since results are\ntypically never shared publicly and the perceived impact on users is\nminimal.\n\nThe growth of industry-based big data research, however, presents new\nrisks to individuals\u2019 privacy, on the one hand, and to\norganizations\u2019 legal compliance, reputation, and brand, on the\nother hand. When organizations process personal data outside of their\noriginal context, individuals may in some cases greatly benefit, but\nin other cases may be surprised, outraged, or even harmed. Soliciting\nconsent from affected individuals can be impractical: Organizations\nmight collect data indirectly or based on identifiers that do not\ndirectly match individuals\u2019 contact details. Moreover, by\ndefinition, some non-contextual uses\u2014including the retention of\ndata for longer than envisaged for purposes of a newly emergent\nuse\u2014may be unforeseen at the time of collection. As Crawford and\nSchultz (2014) note,\n\n\nhow does one give notice and get consent for innumerable and perhaps\neven yet-to-be-determined queries that one might run that create\n\u201cpersonal data\u201d? (2014: 108)\n\n\nWith corporations developing vast \u201cliving laboratories\u201d\nfor big data research, research ethics has become a critical component\nof the design and oversight of these activities. For example, in\nresponse to the controversy surrounding the emotional contagion\nexperiment, Facebook developed an internal ethical review process\nthat, according to its facilitators,\n\n\nleverages the company\u2019s organizational structure, creating\nmultiple training opportunities and research review checkpoints in the\nexisting organizational flow (Jackman & Kanerva 2016: 444).\n\n\nWhile such efforts are important and laudable, they remain open for\nimprovement. Hoffmann (2016), for example, has criticized Facebook for\nlaunching\n\n\nan ethics review process that innovates on process but tells us little\nabout the ethical values informing their product development.\n\n\nFurther, in their study of employees doing the work of ethics inside\nof numerous Silicon Valley companies, Metcalf and colleagues found\nconsiderable tension between trying to resolve thorny ethical dilemmas\nthat emerge within an organization\u2019s data practices and the\nbroader business model and corporate logic that dominates internal\ndecision-making (Metcalf, Moss, & boyd 2019).\n5. Research Ethics Boards Guidelines\n\nWhile many researchers and review boards across the world work without\nformal guidance, many research ethics boards have developed guidelines\nfor Internet research. While many such guidelines exist, the following\nprovides examples for researchers preparing for an REB review, or for\nboards developing their own policies.\n\nBard College (New York) Guidelines for Internet Research\nLoyola University Chicago Policy for Online Survey Research Involving Human Participants\nPenn State Guidelines for Computer- and Internet-Based Research Involving Human Participants\nU.K. Data Archive Further Resources\nUniversity of California-Berkeley Data Security and Human Research Data Risk Assessment Matrix (pdf)\nUniversity of Connecticut Guidance for Computer and Internet-Based Research Involving Human Participants\n\n\nAdditional resources are found in\n Other Internet Resources\n below.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Acquisti, Alessandro and Ralph Gross, 2006, \u201cImagined\nCommunities: Awareness, Information Sharing, and Privacy on the\nFacebook\u201d, in <em>Privacy Enhancing Technologies: PET 2006</em>,\nGeorge Danezis and Philippe Golle (eds.), (Lecture Notes in Computer\nScience 4258), Berlin, Heidelberg: Springer Berlin Heidelberg, pp.\n36\u201358. doi:10.1007/11957454_3",
                "Allen, Christina, 1996, \u201cWhat\u2019s Wrong with the\n\u2018Golden Rule\u2019? Conundrums of Conducting Ethical Research\nin Cyberspace\u201d, <em>The Information Society</em>, 12(2):\n175\u2013188. doi:10.1080/713856146",
                "Annas, George J., 2009, \u201cGlobalized Clinical Trials and\nInformed Consent\u201d, <em>New England Journal of Medicine</em>,\n360(20): 2050\u20132053. doi:10.1056/NEJMp0901474",
                "Aycock, John, Elizabeth Buchanan, Scott Dexter, and David\nDittrich, 2012, \u201cHuman Subjects, Agents, or Bots: Current Issues\nin Ethics and Computer Security Research\u201d, in <em>Financial\nCryptography and Data Security</em>, George Danezis, Sven Dietrich,\nand Kazue Sako (eds.), (Lecture Notes in Computer Science 7126),\nBerlin, Heidelberg: Springer Berlin Heidelberg, pp. 138\u2013145.\ndoi:10.1007/978-3-642-29889-9_12",
                "Banks, Will and Michelle Eble, 2007, \u201cDigital Spaces, Online\nEnvironments, and Human Participant Research: Interfacing with\nInstitutional Review Boards\u201d, in <em>Digital Writing Research:\nTechnologies, Methodologies, and Ethical Issues</em>, Heidi A. McKee\nand D\u00e0nielle Nicole DeVoss (eds.), Cresskill, NJ: Hampton\nPress, pp. 27\u201347.",
                "Barbaro, Michael and Tom Zeller Jr., 2006, \u201cA Face Is\nExposed for AOL Searcher No. 4417749\u201d, <em>The New York\nTimes</em>, 9 August 2006, pp. A1.",
                "Barratt, Monica Jane and Simon Lenton, 2010, \u201cBeyond\nRecruitment? Participatory Online Research with People Who Use\nDrugs\u201d, <em>International Journal of Internet Research\nEthics</em>, 3(1): 69\u201386.\n [<a href=\"http://hdl.handle.net/20.500.11937/23339\" target=\"other\">Barratt and Lenton 2010 available online</a>]",
                "BBC, 2011, \u201cUS Scientists \u2018Knew Guatemala Syphilis\nTests Unethical\u2019\u201d, BBC News, 30 August 2011, sec. Latin\nAmerica &amp; Caribbean.\n [<a href=\"https://www.bbc.com/news/world-latin-america-14712089\" target=\"other\">BBC 2011 available online</a>]",
                "Beauchamp, Tom L. and James F. Childress, 2008, <em>Principles of\nBiomedical Ethics</em>, Oxford: Oxford University Press.",
                "Blackstone, Mary, Lisa Given, Joseph Levy, Michelle McGinn,\nPatrick O\u2019Neill, Ted Palys, and Will van den Hoonaard, 2008,\n<em>Extending the Spectrum: The TCPS and Ethical Issues Involving\nInternet-Based Research</em>, Interagency Advisory Panel and\nSecretariat on Research Ethics, Ottawa, Canada.\n [<a href=\"https://researchoutput.csu.edu.au/en/publications/extending-the-spectrum-the-tcps-and-ethical-issues-involving-inte\" target=\"other\">Blackstone et al. 2008 available online</a>]",
                "Boehlefeld, Sharon Polancic, 1996, \u201cDoing the Right Thing:\nEthical Cyberspace Research\u201d, <em>The Information Society</em>,\n12(2): 141\u2013152. doi:10.1080/713856136",
                "Boga, Mwanamvua, Alun Davies, Dorcas Kamuya, Samson M. Kinyanjui,\nEster Kivaya, Francis Kombe, Trudie Lang, Vicki Marsh, Bibi Mbete,\nAlbert Mlamba, et al., 2011, \u201cStrengthening the Informed Consent\nProcess in International Health Research through Community Engagement:\nThe KEMRI-Wellcome Trust Research Programme Experience\u201d,\n<em>PLoS Medicine</em>, 8(9): e1001089.\ndoi:10.1371/journal.pmed.1001089",
                "Bonneau, Joseph and S\u00f6ren Preibusch, 2010, \u201cThe Privacy\nJungle: On the Market for Data Protection in Social Networks\u201d,\nin <em>Economics of Information Security and Privacy</em>, Tyler\nMoore, David Pym, and Christos Ioannidis (eds.), Boston: Springer US,\npp. 121\u2013167. doi:10.1007/978-1-4419-6967-5_8",
                "Booth, Robert, 2014, \u201cFacebook reveals news feed experiment\nto control emotions\u201d, <em>The Guardian</em>, 29 June 2014.\n [<a href=\"https://www.theguardian.com/technology/2014/jun/29/facebook-users-emotions-news-feeds\" target=\"other\">Booth 2014 available online</a>]",
                "Bromseth, Janne C. H., 2002, \u201cPublic Places: Public\nActivities? Methodological Approaches and Ethical Dilemmas in Research\non Computer-mediated Communication Contexts\u201d, in <em>Researching\nICTs in Context</em>, Andrew Morrison (ed.), InterMedia Report 3/2002,\nOslo: University of Oslo, pp. 33\u201361.\n [<a href=\"https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.7392&amp;rep=rep1&amp;type=pdf\" target=\"other\">Bromseth 2002 available online</a>]",
                "Brothers, Kyle Bertram and Ellen Wright Clayton, 2010,\n\u201c\u2018Human Non-Subjects Research\u2019: Privacy and\nCompliance\u201d, <em>The American Journal of Bioethics</em>, 10(9):\n15\u201317. doi:10.1080/15265161.2010.492891",
                "Bruckman, Amy, 2006, \u201cTeaching Students to Study Online\nCommunities Ethically\u201d, <em>Journal of Information Ethics</em>,\n15(2): 82\u201398. doi:10.3172/JIE.15.2.82",
                "Buchanan, Elizabeth A. (ed.), 2004, <em>Readings in Virtual\nResearch Ethics: Issues and Controversies</em>, Hershey, PA:\nInformation Science Publishing.",
                "\u2013\u2013\u2013, 2006, \u201cIntroduction: Internet\nResearch Ethics at a Critical Juncture\u201d, <em>Journal of\nInformation Ethics</em>, 15(2): 14\u201317.\ndoi:10.3172/JIE.15.2.14",
                "\u2013\u2013\u2013, 2011, \u201cInternet Research Ethics:\nPast, Present, and Future\u201d, in Consalvo and Ess 2011:\n83\u2013108. doi:10.1002/9781444314861.ch5",
                "\u2013\u2013\u2013, 2016, \u201cEthics in Digital\nResearch\u201d, in <em>Handbuch Soziale Praktiken und Digitale\nAlltagswelten</em>, Heidrun Friese, Gala Rebane, Marcus Nolden, and\nMiriam Schreiter (eds.), Wiesbaden: Springer Fachmedien Wiesbaden, pp.\n1\u20139. doi:10.1007/978-3-658-08460-8_47-1",
                "Buchanan, Elizabeth A. and Charles M. Ess, 2008, \u201cInternet\nResearch Ethics: The Field and Its Critical Issues\u201d, in <em>The\nHandbook of Information and Computer Ethics</em>, Kenneth Einar Himma\nand Herman T. Tavani (eds.), Hoboken, NJ: John Wiley &amp; Sons, Inc.,\npp. 273\u2013292. doi:10.1002/9780470281819.ch11",
                "\u2013\u2013\u2013, 2009, \u201cInternet Research Ethics and\nthe Institutional Review Board: Current Practices and Issues\u201d,\n<em>ACM SIGCAS Computers and Society</em>, 39(3): 43\u201349.\ndoi:10.1145/1713066.1713069",
                "Buchanan, Elizabeth A. and Erin E. Hvizdak, 2009, \u201cOnline\nSurvey Tools: Ethical and Methodological Concerns of Human Research\nEthics Committees\u201d, <em>Journal of Empirical Research on Human\nResearch Ethics</em>, 4(2): 37\u201348.\ndoi:10.1525/jer.2009.4.2.37",
                "Buchanan, Elizabeth, John Aycock, Scott Dexter, David Dittrich,\nand Erin Hvizdak, 2011, \u201cComputer Science Security Research and\nHuman Subjects: Emerging Considerations for Research Ethics\nBoards\u201d, <em>Journal of Empirical Research on Human Research\nEthics</em>, 6(2): 71\u201383. doi:10.1525/jer.2011.6.2.71",
                "Carpenter, Katherine J. and David Dittrich, 2012, \u201cBridging\nthe Distance: Removing the Technology Buffer and Seeking Consistent\nEthical Analysis in Computer Security Research\u201d, in <em>Digital\nEthics: Research &amp; Practice</em> (Digital Formations 85), Don\nHeider and Adrienne Massanari (eds.), New York: Peter Lang, pp.\n1\u201329.",
                "[CASRO] Council of American Survey Research, 2011, \u201cCASRO\nCode of Standards and Ethics for Survey Research\u201d, First adopted\n1977 and revised since.\n [<a href=\"https://www.ftc.gov/sites/default/files/documents/public_comments/preliminary-ftc-staff-report-protecting-consumer-privacy-era-rapid-change-proposed-framework/00356-57963.pdf\" target=\"other\">CASRO code available online</a>]",
                "Chen, Jenny J., Natala J. Menezes, and Adam D. Bradley, 2011,\n\u201cOpportunities for Crowdsourcing Research on Amazon Mechanical\nTurk\u201d, <em>Interfaces</em>, 5(3).\n [<a href=\"https://www.researchgate.net/publication/228954187_Opportunities_for_Crowdsourcing_Research_on_Amazon_Mechanical_Turk\" target=\"other\">J. Chen, Menezes, and Bradley 2011 available online</a>]",
                "Colvin, Jan and Jane Lanigan, 2005, \u201cEthical Issues and Best\nPractice Considerations for Internet Research\u201d, <em>Journal of\nFamily and Consumer Sciences</em>, 97(3): 34\u201339.",
                "Conley, Caryn and Jennifer Tosti-Kharas, 2014,\n\u201cCrowdsourcing Content Analysis for Managerial Research\u201d,\n<em>Management Decision</em>, 52(4): 675\u2013688.\ndoi:10.1108/MD-03-2012-0156",
                "Consalvo, Mia and Charles Ess (eds.), 2011, <em>The Handbook of\nInternet Studies</em>, Oxford: Wiley-Blackwell.\ndoi:10.1002/9781444314861",
                "Crawford, Kate and Jason Schultz, 2014, \u201cBig Data and Due\nProcess: Toward a Framework to Redress Predictive Privacy\nHarms\u201d, <em>Boston College Law Review</em>, 55(1):\n93\u2013128.",
                "Dittrich, David, Michael Bailey, and Sven Dietrich, 2011,\n\u201cBuilding an Active Computer Security Ethics Community\u201d,\n<em>IEEE Security &amp; Privacy Magazine</em>, 9(4): 32\u201340.\ndoi:10.1109/MSP.2010.199",
                "Drew, David A., Long H. Nguyen, Claire J. Steves, Cristina Menni,\nMaxim Freydin, Thomas Varsavsky, Carole H. Sudre, M. Jorge Cardoso,\nSebastien Ourselin, Jonathan Wolf, et al., 2020, \u201cRapid\nImplementation of Mobile Technology for Real-Time Epidemiology of\nCOVID-19\u201d, <em>Science</em>, 368(6497): 1362\u20131367.\ndoi:10.1126/science.abc0473",
                "Elgesem, Dag, 2002, \u201cWhat Is Special about the Ethical\nIssues in Online Research?\u201d, <em>Ethics and Information\nTechnology</em>, 4(3): 195\u2013203. doi:10.1023/A:1021320510186",
                "Emanuel, Ezekiel J., Robert A. Crouch, John D. Arras, Jonathan D.\nMoreno, and Christine Grady (eds.), 2003, <em>Ethical and Regulatory\nAspects of Clinical Research: Readings and Commentary</em>, Baltimore:\nJohns Hopkins University Press.",
                "Ess, Charles, 2016, \u201cPhronesis for machine ethics? Can\nrobots perform ethical judgments?\u201d, <em>Frontiers in Artificial\nIntelligence and Applications</em>, 290: 386\u2013389.\ndoi:10.3233/978-1-61499-708-5-386",
                "Ess, Charles and the Association of Internet Researchers (AoIR)\nEthics Working committee, 2002, \u201cEthical Decision-Making and\nInternet Research: Recommendations from the AoIR Ethics Working\nCommittee\u201d, Approved by the AoIR, 27 November 2002.\n [<a href=\"http://aoir.org/reports/ethics.pdf\" target=\"other\">Ess and AoIR 2002 available online</a>]",
                "Eysenbach, Gunther, 1999, \u201cWelcome to the Journal of Medical\nInternet Research\u201d, <em>Journal of Medical Internet\nResearch</em>, 1(1): e5. doi:10.2196/jmir.1.1.e5",
                "Eysenbach, Gunther and James E. Till, 2001, \u201cEthical Issues\nin Qualitative Research on Internet Communities\u201d, <em>BMJ</em>,\n323(7321): 1103\u20131105. doi:10.1136/bmj.323.7321.1103",
                "Fairfield, Joshua A., 2012, \u201cAvatar Experimentation: Human\nSubjects Research in Virtual Worlds\u201d, <em>U.C. Irvine Law\nReview</em>, 2: 695\u2013772.",
                "Federal Register, 2011, \u201cSubmission for Review and Comment:\n\u2018The Menlo Report: Ethical Principles Guiding Information and\nCommunication Technology Research\u2019\u201d (\u201cMenlo\nReport\u201d) for the Department of Homeland Security (DHS), Science\nand Technology, Cyber Security Division (CSD), Protected Repository\nfor the Defense of Infrastructure Against Cyber Threats\n(PREDICT)\u201d, 28 December 2011, Volume 76, Number 249, Docket No.\nDHS-2011-0074.\n [<a href=\"https://www.federalregister.gov/documents/2011/12/28/2011-33231/submission-for-review-and-comment-the-menlo-report-ethical-principles-guiding-information-and\" target=\"other\">Federal Register 2011 available online</a>]",
                "\u2013\u2013\u2013, 2017, \u201cFederal Policy for the\nProtection of Human Subjects\u201d, 19 January 2017, Volume 82,\nNumber 12\n [<a href=\"https://www.federalregister.gov/documents/2017/01/19/2017-01058/federal-policy-for-the-protection-of-human-subjects\" target=\"other\">Federal Register 2017 available online</a>]",
                "Fiesler, Casey, Nathan Beard, and Brian C. Keegan, 2020, \u201cNo\nRobots, Spiders, or Scrapers: Legal and Ethical Regulation of Data\nCollection Methods in Social Media Terms of Service\u201d,\n<em>Proceedings of the International AAAI Conference on Web and Social\nMedia</em>, 14: 187\u2013196.\n [<a href=\"https://www.aaai.org/ojs/index.php/ICWSM/article/view/7290\" target=\"other\">Fiesler, Beard, and Keegan 2020 available online</a>]",
                "Fiesler, Casey, Jeff Hancock, Amy Bruckman, Michael Muller, Cosmin\nMunteanu, and Melissa Densmore, 2018, \u201cResearch Ethics for HCI:\nA Roundtable Discussion\u201d, in <em>Extended Abstracts of the 2018\nCHI Conference on Human Factors in Computing Systems</em>, , Montreal\nQC Canada: ACM, 1\u20135. doi:10.1145/3170427.3186321",
                "Fiesler, Casey and Nicholas Proferes, 2018,\n\u201c\u2018Participant\u2019 Perceptions of Twitter Research\nEthics\u201d, <em>Social Media + Society</em>, 4(1), first online 10\nMarch 2018. doi:10.1177/2056305118763366",
                "Flicker, Sarah, Dave Haans, and Harvey Skinner, 2004,\n\u201cEthical Dilemmas in Research on Internet Communities\u201d,\n<em>Qualitative Health Research</em>, 14(1): 124\u2013134.\ndoi:10.1177/1049732303259842",
                "Fossheim, Hallvard and Helene Ingierd (eds.), 2016, <em>Internet\nResearch Ethics:</em>, Oslo: Cappelen Damm Akademisk/NOASP.\ndoi:10.17585/noasp.3.1",
                "Frankel, Mark S. and Sanyin Siang, 1999, \u201cEthical and Legal\nAspects of Human Subjects Research in Cyberspace\u201d, A Report of a\nWorkshop, 10\u201311 June 1999, Washington, DC: American Association\nfor the Advancement of Science.\n [<a href=\"https://www.aaas.org/sites/default/files/report2.pdf\" target=\"other\">Frankel and Siang 1999 available online</a>]",
                "Franzke, Aline Shakti, Anja Bechmann, Michael Zimmer, Charles M.\nEss, and the Association of Internet Researchers (AoIR), 2020,\n<em>Internet Research: Ethical Guidelines 3.0</em>, AoIR.\n [<a href=\"https://aoir.org/reports/ethics3.pdf\" target=\"other\">Franzke et al. available online (pdf)</a>]",
                "Frauenberger, Christopher, Amy S. Bruckman, Cosmin Munteanu,\nMelissa Densmore, and Jenny Waycott, 2017, \u201cResearch Ethics in\nHCI: A Town Hall Meeting\u201d, in <em>Proceedings of the 2017 CHI\nConference Extended Abstracts on Human Factors in Computing Systems\n\u2013 CHI EA \u201917</em>, Denver: ACM Press, pp. 1295\u20131299.\ndoi:10.1145/3027063.3051135",
                "Gaw, Allan and Michael H. J. Burns, 2011, <em>On Moral Grounds:\nLessons from the History of Research Ethics</em>, Westerwood, Glasgow:\nSA Press.",
                "[GDPR] General Data Protection Regulation (GDPR), 2016,\n\u201cRegulation (EU) 2016/679 of the European Parliament and of the\nCouncil of 27 April 2016 on the protection of natural persons with\nregard to the processing of personal data and on the free movement of\nsuch data, and repealing Directive 95/46\u201d.\n [<a href=\"https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679&amp;from=EN\">available online</a>]",
                "Gilbert, Brendan James, 2009, \u201cGetting to Conscionable:\nNegotiating Virtual Worlds\u2019 End User License Agreements without\nGetting Externally Regulated\u201d, <em>Journal of International\nCommercial Law and Technology</em>, 4(4): 238\u2013251.\n [<a href=\"https://www.neliti.com/publications/28835/getting-to-conscionable-negotiating-virtual-worlds%C3%A2tm-end-user-license-agreement#cite\" target=\"other\">Gilbert 2009 available online</a>]",
                "Glickman, Seth W., Sam Galhenage, Lindsay McNair, Zachry Barber,\nKeyur Patel, Kevin A. Schulman, and John G. McHutchison, 2012,\n\u201cThe Potential Influence of Internet-Based Social Networking on\nthe Conduct of Clinical Research Studies\u201d, <em>Journal of\nEmpirical Research on Human Research Ethics</em>, 7(1): 71\u201380.\ndoi:10.1525/jer.2012.7.1.71",
                "Goldfarb, Norman M., 2008, \u201cAge of Consent for Clinical\nResearch\u201d, <em>Journal of Clinical Research Best Practices</em>,\n4(6).\n [<a href=\"https://www.magiworld.org/resources/journal/459_Consent_Age.pdf\" target=\"other\">Goldfarb 2008 available online</a>]",
                "[HHS] Health and Human Services, 2017, \u201cExcerpts from the\nJanuary 19, 2017 Revised Common Rule Preamble\u201d.\n [<a href=\"https://www.hhs.gov/ohrp/regulations-and-policy/regulations/2018-req-preamble/\" target=\"other\">HHS 2017 available online</a>]",
                "Hill, Kashmir, 2014, \u201cFacebook Added \u2018Research\u2019\nTo User Agreement 4 Months After Emotion Manipulation Study\u201d,\n<em>Forbes.com.</em>, 30 June 2014.\n [<a href=\"https://www.forbes.com/sites/kashmirhill/2014/06/30/facebook-only-got-permission-to-do-research-on-users-after-emotion-manipulation-study/#23483d1a10c1\" target=\"other\">Hill 2014 available online</a>]",
                "Hoffmann, Anna Lauren, 2016, \u201cFacebook has a New Process for\nDiscussing Ethics. But is It Ethical?\u201d <em>The Guardian</em>, 17\nJune 2016.\n [<a href=\"https://www.theguardian.com/technology/2016/jun/17/facebook-ethics-but-is-it-ethical\" target=\"other\">Hoffmann 2016 available online</a>]",
                "Homeland Security Department, 2011, \u201cSubmission for Review\nand Comment: \u2018The Menlo Report: Ethical Principles Guiding\nInformation and Communication Technology Research\u2019\u201d,\n<em>Federal Register: The Daily Journal of the United States\nGovernment</em>, FR Doc. 2011-3323, 28 December 2011.\n [<a href=\"https://www.federalregister.gov/articles/2011/12/28/2011-33231/submission-for-review-and-comment-the-menlo-report-ethical-principles-guiding-information-and\" target=\"other\">Homeland Security Department 2011 available online</a>].",
                "Hubach, Randolph D., Andrew O\u2019Neil, Mollie Stowe, Zachary\nGiano, Brenda Curtis, and Celia B. Fisher, forthcoming,\n\u201cPerceived Confidentiality Risks of Mobile Technology-Based\nEcologic Momentary Assessment to Assess High-Risk Behaviors Among\nRural Men Who Have Sex with Men\u201d, <em>Archives of Sexual\nBehavior</em>, first online: 20 February 2020.\ndoi:10.1007/s10508-019-01612-x",
                "Hudson, James M. and Amy Bruckman, 2004, \u201c\u2018Go\nAway\u2019: Participant Objections to Being Studied and the Ethics of\nChatroom Research\u201d, <em>The Information Society</em>, 20(2):\n127\u2013139. doi:10.1080/01972240490423030",
                "\u2013\u2013\u2013, 2005, \u201cUsing Empirical Data to Reason\nabout Internet Research Ethics\u201d, in <em>ECSCW 2005: Proceedings\nof the Ninth European Conference on Computer-Supported Cooperative\nWork, 18\u201322 September 2005, Paris, France</em>, Hans Gellersen,\nKjeld Schmidt, Michel Beaudouin-Lafon, and Wendy Mackay (eds.),\nBerlin/Heidelberg: Springer-Verlag, pp. 287\u2013306.\ndoi:10.1007/1-4020-4023-7_15",
                "Hunsinger, Jeremy, Lisbeth Klastrup, and Matthew Allen (eds.),\n2010, <em>International Handbook of Internet Research</em>, Dordrecht:\nSpringer Netherlands. doi:10.1007/978-1-4020-9789-8",
                "Illingworth, Nicola, 2001, \u201cThe Internet Matters: Exploring\nthe Use of the Internet as a Research Tool\u201d, <em>Sociological\nResearch Online</em>, 6(2): 79\u201390. doi:10.5153/sro.600\n [<a href=\"https://www.socresonline.org.uk/6/2/illingworth.html\" target=\"other\">Illingworth 2001 available online</a>]",
                "International Telecommunications Union, 2019, \u201cNew ITU Data\nReveal Growing Internet Uptake but a Widening Digital Gender\nDivide\u201d, <em>ITU Media Centre</em>,\n [<a href=\"https://www.itu.int/en/mediacentre/Pages/2019-PR19.aspx\" target=\"other\">ITU 2019 available online</a>]",
                "Jackman, Molly and Lauri Kanerva, 2016, \u201cEvolving the IRB:\nBuilding Robust Review for Industry Research\u201d, <em>Washington\nand Lee Law Review Online</em>, 72(3): 442\u2013457.",
                "Jacobson, David, 1999, \u201cDoing Research in Cyberspace\u201d,\n<em>Field Methods</em>, 11(2): 127\u2013145.\ndoi:10.1177/1525822X9901100204",
                "Johns, Mark D., Shing-Ling Sarina Chen, and G. Jon Hall (eds.),\n2003, <em>Online Social Research: Methods, Issues, and Ethics</em>,\nNew York: Peter Lang.",
                "Jones, Arnita, 2008, \u201cAHA Statement on IRB\u2019s and Oral\nHistory Research\u201d, <em>American Historical Association\nActivities</em>, 1 February 2008.\n [<a href=\"https://www.historians.org/publications-and-directories/perspectives-on-history/february-2008/aha-statement-on-irbs-and-oral-history-research\" target=\"other\">A. Jones 2008 available online</a>]",
                "Jones, Steve (ed.), 1999, <em>Doing Internet Research: Critical\nIssues and Methods for Examining the Net</em>, Thousand Oaks, CA:\nSage.",
                "Kaplan, Andreas M. and Michael Haenlein, 2010, \u201cUsers of the\nWorld, Unite! The Challenges and Opportunities of Social Media\u201d,\n<em>Business Horizons</em>, 53(1): 59\u201368.\ndoi:10.1016/j.bushor.2009.09.003",
                "Kerry, Cameron F., 2020, \u201cProtecting privacy in an AI-driven\nworld\u201d (AI Governance), 10 February 2020, Center for Technology\nInnovation, Brookings Institute.\n [<a href=\"https://www.brookings.edu/research/protecting-privacy-in-an-ai-driven-world/\" target=\"other\">Kerry 2020 available online</a>]",
                "Keyes, Os, 2019, \u201cCounting the Countless: Why data science\nis a profound threat for queer people\u201d, <em>Real Life</em>, 8\nApril 2019.\n [<a href=\"https://reallifemag.com/counting-the-countless/\" target=\"other\">Keyes 2019 available online</a>]",
                "King, Storm A., 1996, \u201cResearching Internet Communities:\nProposed Ethical Guidelines for the Reporting of Results\u201d,\n<em>The Information Society</em>, 12(2): 119\u2013128.\ndoi:10.1080/713856145",
                "Kitchin, Heather A., 2003, \u201cThe Tri-Council Policy Statement\nand Research in Cyberspace: Research Ethics, the Internet, and\nRevising a \u2018Living Document\u2019\u201d, <em>Journal of\nAcademic Ethics</em>, 1(4): 397\u2013418.\ndoi:10.1023/B:JAET.0000025671.83557.fa",
                "\u2013\u2013\u2013, 2008, <em>Research Ethics and the Internet:\nNegotiating Canada\u2019s Tri-Council\u2019s Policy</em>, Winnipeg,\nManitoba: Fernwood Publishing",
                "Kramer, Adam D. I., James E. Guillory, and Jeffrey T. Hancock,\n2014, \u201cExperimental Evidence of Massive-Scale Emotional\nContagion through Social Networks\u201d, <em>Proceedings of the\nNational Academy of Sciences</em>, 111(24): 8788\u20138790.\ndoi:10.1073/pnas.1320040111",
                "Kraut, Robert, Judith Olson, Mahzarin Banaji, Amy Bruckman,\nJeffrey Cohen, and Mick Couper, 2004, \u201cPsychological Research\nOnline: Report of Board of Scientific Affairs\u2019 Advisory Group on\nthe Conduct of Research on the Internet.\u201d, <em>American\nPsychologist</em>, 59(2): 105\u2013117.\ndoi:10.1037/0003-066X.59.2.105",
                "Krogstad, Donald J., Samba Diop, Amadou Diallo, Fawaz Mzayek,\nJoseph Keating, Ousmane A. Koita, and Y\u00e9ya T. Tour\u00e9,\n2010, \u201cInformed Consent in International Research: The Rationale\nfor Different Approaches\u201d, <em>The American Journal of Tropical\nMedicine and Hygiene</em>, 83(4): 743\u2013747.\ndoi:10.4269/ajtmh.2010.10-0014",
                "Lawson, Danielle, 2004, \u201cBlurring the Boundaries: Ethical\nConsiderations for Online Research Using Synchronous CMC\nForums\u201d, in Buchanan 2004: 80\u2013100.",
                "Leibovici, Didier G., Suchith Anand, Jerry Swan, James Goulding,\nGobe Hobona, Lucy Bastin, Sergiusz Pawlowicz, Mike Jackson, and\nRichard James, 2010, \u201cWorkflow Issues for Health Mapping\n\u2018Mashups\u2019 of OGC\u201d, University of Nottingham, CGS\nTechnical Report, 2010 DL1.\n [<a href=\"https://www.researchgate.net/publication/282698491_Workflow_issues_for_Health-mapping_mashups\" target=\"other\">Leibovici et al. 2010 available online</a>]",
                "Madejski, Michelle, Maritza Lupe Johnson, and Steven Michael\nBellovin, 2011, \u201cThe Failure of Online Social Network Privacy\nSettings\u201d. Columbia Research Report CUCS-010-11, Columbia\nUniversity. doi:10.7916/D8NG4ZJ1",
                "Mann, Chris, 2003, \u201cGenerating Data Online: Ethical Concerns\nand Challenges for the C21 Researcher\u201d, in Thorseth 2003:\n31\u201349.",
                "Markham, Annette N., 1998, <em>Life Online: Researching Real\nExperience in Virtual Space</em>, Walnut Creek, CA: Altamira\nPress.",
                "\u2013\u2013\u2013, 2012, \u201cFabrication as Ethical\nPractice: Qualitative Inquiry in Ambiguous Internet Contexts\u201d,\n<em>Information, Communication &amp; Society</em>, 15(3):\n334\u2013353. doi:10.1080/1369118X.2011.641993",
                "Markham, Annette N. and Nancy K. Baym (eds.), 2008, <em>Internet\nInquiry: Conversations about Method</em>, Thousand Oaks, CA: Sage\nPublications.",
                "Markham, Annette, N. and Elizabeth Buchanan, 2012. : <em>Ethical\ndecision-making and internet research: Version 2.0. recommendations\nfrom the AoIR ethics working committee</em> Association of Internet\nResearchers.\n [<a href=\"https://aoir.org/reports/ethics2.pdf\">Markham and Buchanan 2012 available online</a>]",
                "Markoff, John, 2010, \u201cIn a Video Game, Tackling the\nComplexities of Protein Folding\u201d, <em>New York Times</em>, 4\nAugust 2010.\n [<a href=\"http://www.nytimes.com/2010/08/05/science/05protein.html\" target=\"other\">Markoff 2010 available online</a>]",
                "McKee, Heidi A. and James E. Porter, 2009, <em>The Ethics of\nInternet Research: A Rhetorical, Case-based Process</em>, New York:\nPeter Lang Publishing.",
                "Mendelson, Cindy, 2007, \u201cRecruiting Participants for\nResearch From Online Communities\u201d, <em>CIN: Computers,\nInformatics, Nursing</em>, 25(6): 317\u2013323.\ndoi:10.1097/01.NCN.0000299653.13777.51",
                "Metcalf, Jacob, 2017, \u201c\u2018The Study Has Been Approved by\nthe IRB\u2019: Gayface AI, Research Hype and the Pervasive Data\nEthics Gap\u201d. PERVADE Team: Pervasive Data Ethics for\nComputational Research, Report.\n [<a href=\"https://medium.com/pervade-team/the-study-has-been-approved-by-the-irb-gayface-ai-research-hype-and-the-pervasive-data-ethics-ed76171b882c\" target=\"other\">Metcalf 2017 available online</a>]",
                "Metcalf, Jacob, Emanuel Moss, and danah boyd, 2019, \u201cOwning\nEthics: Corporate Logics, Silicon Valley, and the Institutionalization\nof Ethics\u201d, <em>Social Research: An International\nQuarterly</em>, 86(2): 449\u2013476.",
                "Milne, George R. and Mary J. Culnan, 2004, \u201cStrategies for\nReducing Online Privacy Risks: Why Consumers Read (or Don\u2019t\nRead) Online Privacy Notices\u201d, <em>Journal of Interactive\nMarketing</em>, 18(3): 15\u201329. doi:10.1002/dir.20009",
                "Mondschein, Christopher F. and Cosimo Monda, 2018, \u201cThe\nEU\u2019s General Data Protection Regulation (GDPR) in a Research\nContext\u201d, in <em>Fundamentals of Clinical Data Science</em>,\nPieter Kubben, Michel Dumontier, and Andre Dekker (eds.), Cham:\nSpringer International Publishing, pp. 55\u201371.\ndoi:10.1007/978-3-319-99713-1_5",
                "Moor, James H., 1985, \u201cWhat Is Computer Ethics?\u201d,\n<em>Metaphilosophy</em>, 16(4): 266\u2013275.\ndoi:10.1111/j.1467-9973.1985.tb00173.x",
                "Alexander, Larry and Michael Moore, 2007, \u201cDeontological\nEthics\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2007 Edition), Edward N. Zalta (ed.). URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/win2007/entries/ethics-deontological/\" target=\"other\">https://plato.stanford.edu/archives/win2007/entries/ethics-deontological/</a>&gt;",
                "Narayanan, Arvind and Vitaly Shmatikov, 2008, \u201cRobust\nde-anonymization of Large Sparse Datasets\u201d, <em>Proceedings of\nthe 29<sup>th</sup> IEEE Symposium on Security and Privacy, Oakland,\nCA, May 2008</em>, IEEE, pp. 111\u2013125. doi:10.1109/SP.2008.33\n [<a href=\"http://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf\" target=\"other\">Narayanan and Shmatikov 2008 available online (pdf)</a>]",
                "[NCPHSBBR] The National Commission for the Protection of Human\nSubjects of Biomedical and Behavioral Research, 1979, \u201cThe\nBelmont Report: Ethical Principles and Guidelines for the Protection\nof Human Subjects of Research\u201d, Office for Human Research\nProtections, Department of Health and Human Services, United States.\n [<a href=\"http://www.hhs.gov/ohrp/humansubjects/guidance/belmont.html\" target=\"other\">NCPHSBBR 1979 available online</a>]",
                "[NESH] The National Committee for Research Ethics in the Social\nSciences and the Humanities [Norway], 2006, \u201cGuidelines for\nResearch Ethics in the Social Sciences, Law, and Humanities\u201d,\nPublished September 2006.\n [<a href=\"http://graduateschool.nd.edu/assets/21765/guidelinesresearchethicsinthesocialscienceslawhumanities.pdf\" target=\"other\">NESH 2006 available online</a>].",
                "\u2013\u2013\u2013, 2019, \u201cA Guide to Internet Research\nEthics\u201d.\n [<a href=\"https://www.forskningsetikk.no/en/guidelines/social-sciences-humanities-law-and-theology/a-guide-to-internet-research-ethics/\" target=\"other\">NESH 2019 available online</a>].",
                "Nissenbaum, Helen, 2009, <em>Privacy in Context: Technology,\nPolicy, and the Integrity of Social Life</em>, Stanford, CA: Stanford\nUniversity Press.",
                "[NSTC] National Science and Technology Council, 2016,\n\u201cNational Privacy Research Strategy\u201d, Office of the\nPresident of the United States, June 2016.\n [<a href=\"https://www.nitrd.gov/pubs/NationalPrivacyResearchStrategy.pdf\" target=\"other\">NSTC 2016 available online</a>]",
                "Nuremberg Code, 1947 (1996), \u201cThe Nuremberg Code\u201d,\n<em>BMJ</em>, 313. doi:https://doi.org/10.1136/bmj.313.7070.1448 ",
                "Ohm, Paul, 2010, \u201cBroken Promises of Privacy: Responding to\nthe Surprising Failure of Anonymization\u201d, <em>UCLA Law\nReview</em>, 57: 1701\u20131777.",
                "Overbeke, Grace, 2008, \u201cPro-Anorexia Websites: Content,\nImpact, and Explanations of Popularity\u201d, <em>Mind Matters: The\nWesleyan Journal of Psychology</em>, 3: 49\u201362.\n [<a href=\"https://www.academia.edu/6383345/Pro-Anorexia_Websites_Content_Impact_and_Explanations_of_Popularity\" target=\"other\">Overbeke 2008 available online</a>]",
                "[PRIM&amp;R] Public Responsibility in Medicine and Research,\nBankert, E., Gordon, B., Hurley, E., and Shriver, S. (eds), 2021,\n<em>Institutional Review Board: Management and Function </em>(third\nedition). Burlington, MA: Jones and Bartlett.",
                "Reid, Elizabeth, 1996, \u201cInformed Consent in the Study of\nOn-Line Communities: A Reflection on the Effects of Computer-Mediated\nSocial Research\u201d, <em>The Information Society</em>, 12(2):\n169\u2013174. doi:10.1080/713856138",
                "Reynolds, Ren, and Melissa de Zwart, 2010, \u201cThe Duty to\n\u2018Play\u2019: Ethics, EULAs and MMOs\u201d, <em>International\nJournal of Internet Research Ethics</em>, 3(1): 48\u201368.\n [<a href=\"https://www.globethics.net/gel/4410705\" target=\"other\">Reynolds &amp; de Zwart 2010 available online</a>]",
                "Ritchie, Donald A., 2003, <em>Doing Oral History: A Practical\nGuide</em>, New York: Oxford University Press.",
                "Rosenberg, \u00c5sa, 2010, \u201cVirtual World Research Ethics\nand the Private/Public Distinction\u201d, <em>International Journal\nof Internet Research Ethics</em>, 3(1): 23\u201337.",
                "Rosser, B. R. Simon, J. Michael Oakes, Joseph Konstan, Simon\nHooper, Keith J. Horvath, Gene P. Danilenko, Katherine E. Nygaard, and\nDerek J. Smolenski, 2010, \u201cReducing HIV Risk Behavior of Men Who\nHave Sex with Men through Persuasive Computing: Results of the\nMen\u02bcs INTernet Study-II\u201d, <em>AIDS</em>, 24(13):\n2099\u20132107. doi:10.1097/QAD.0b013e32833c4ac7",
                "[SACHRP] Secretary\u2019s Advisory Committee to the Office for\nHuman Research Protections, Unitd States Department of Health &amp;\nHuman Services, 2010,\n \u201c<a href=\"https://web.archive.org/web/20170209180021/http://archive.hhs.gov/ohrp/sachrp/mtgings/mtg07-10/present.html\" target=\"other\">SACHRP July 20\u201321, 2010 Meeting Presentations</a>\u201d.",
                "\u2013\u2013\u2013, 2013,\n \u201c<a href=\"https://www.hhs.gov/ohrp/sachrp-committee/recommendations/2013-may-20-letter-attachment-b/index.html\" target=\"other\">Attachment B: Considerations and Recommendations concerning Internet Research and Human Subjects Research Regulations, with Revisions</a>\u201d,\n Final document approved 12\u201313 March 2013.\n (<a href=\"https://www.hhs.gov/ohrp/sites/default/files/ohrp/sachrp/mtgings/2013%20March%20Mtg/internet_research.pdf\" target=\"other\">SACHRP 2013 pdf version</a>)",
                "\u2013\u2013\u2013, 2013, \u201cConsiderations and\nRecommendations Concerning Internet Research and Human Subjects\nResearch Regulations, with Revisions\u201d.\n [<a href=\"https://www.hhs.gov/ohrp/sites/default/files/ohrp/sachrp/mtgings/2013%20March%20Mtg/internet_research.pdf\">SACHRP 2013 available online</a>]",
                "\u2013\u2013\u2013, 2015,\n \u201c<a href=\"https://www.hhs.gov/ohrp/sachrp-committee/recommendations/2015-april-24-attachment-a/index.html\" target=\"other\">Attachment A: Human Subjects Research Implications of \u2018Big Data\u2019 Studies</a>\u201d,\n 24 April 2015.",
                "Samuel, Gabrielle and Elizabeth Buchanan, 2020, \u201cGuest\nEditorial: Ethical Issues in Social Media Research\u201d, <em>Journal\nof Empirical Research on Human Research Ethics</em>, 15(1\u20132):\n3\u201311. doi:10.1177/1556264619901215",
                "Scholz, Trebor, 2008, \u201cMarket Ideology and the Myths of Web\n2.0\u201d, <em>First Monday</em>, 13(3): 3 March 2008.\n [<a href=\"https://firstmonday.org/ojs/index.php/fm/article/view/2138\" target=\"other\">Scholz 2008 available online</a>]",
                "Schwartz, Paul M. and Daniel J. Solove, 2011, \u201cThe PII\nProblem: Privacy and a New Concept of Personally Identifiable\nInformation\u201d, <em>New York University Law Review</em>, 86(6):\n1814\u20131893.",
                "Seaboldt, James A. and Randy Kuiper, 1997, \u201cComparison of\nInformation Obtained from a Usenet Newsgroup and from Drug Information\nCenters\u201d, <em>American Journal of Health-System Pharmacy</em>,\n54(15): 1732\u20131735. doi:10.1093/ajhp/54.15.1732",
                "Sharf, Barbara F., 1997, \u201cCommunicating Breast Cancer\nOn-Line: Support and Empowerment on the Internet\u201d, <em>Women\n&amp; Health</em>, 26(1): 65\u201384. doi:10.1300/J013v26n01_05",
                "Sieber, Joan E., 1992, <em>Planning Ethically Responsible\nResearch: A Guide for Students and Internal Review Boards</em>,\nThousand Oaks, CA: Sage.",
                "\u2013\u2013\u2013, 2015, <em>Planning Ethically Responsible\nResearch: A Guide for Students and Internal Review Boards</em>, second\nedition, Thousand Oaks, CA: Sage.",
                "Simmhan, Yogesh, Roger Barga, Catharine van Ingen, Ed Lazowska,\nand Alex Szalay, 2008, \u201cOn Building Scientific Workflow Systems\nfor Data Management in the Cloud\u201d, in <em>2008 IEEE Fourth\nInternational Conference on EScience</em>, Indianapolis, IN: IEEE, pp.\n434\u2013435. doi:10.1109/eScience.2008.150",
                "Simmhan, Yogesh, Catharine van Ingen, Girish Subramanian, and Jie\nLi, 2009, \u201cBridging the Gap between the Cloud and an EScience\nApplication Platform\u201d. Microsoft Research Tech Report\nMSR-TR-2009-2021.\n [<a href=\"https://www.microsoft.com/en-us/research/publication/bridging-the-gap-between-the-cloud-and-an-escience-application-platform/\" target=\"other\">Simmhan et al. 2009 available online</a>]",
                "Skloot, Rebecca, 2010, <em>The Immortal Life of Henrietta\nLacks</em>, New York: Crown Publishers.",
                "Sloan, Luke, Curtis Jessop, Tarek Al Baghal, and Matthew Williams,\n2020, \u201cLinking Survey and Twitter Data: Informed Consent,\nDisclosure, Security, and Archiving\u201d, <em>Journal of Empirical\nResearch on Human Research Ethics,</em> 15(1\u20132):\n63\u201376.",
                "Smith, Michael A. and Brant Leigh, 1997, \u201cVirtual Subjects:\nUsing the Internet as an Alternative Source of Subjects and Research\nEnvironment\u201d, <em>Behavior Research Methods, Instruments, &amp;\nComputers</em>, 29(4): 496\u2013505. doi:10.3758/BF03210601",
                "Spriggs, Merle, 2010, <em>A Handbook for Human Research Ethics\nCommittees and Researchers: Understanding Consent in Research\nInvolving Children: The Ethical Issues</em>, Melbourne: The University\nof Melbourne/Murdoch Childrens Research Institute/The Royal\nChildren\u2019s Hospital Melbourne, version 4.\n <a href=\"https://web.archive.org/web/20120324133800/http://www.mcri.edu.au/media/62539/handbook.pdf\" target=\"other\">Spriggs 2010 available online</a>]",
                "Stahl, Bernd Carsten and David Wright, 2018, \u201cEthics and\nPrivacy in AI and Big Data: Implementing Responsible Research and\nInnovation\u201d, <em>IEEE Security &amp; Privacy</em>, 16(3):\n26\u201333. doi:10.1109/MSP.2018.2701164",
                "Sveningsson, Malin, 2004, \u201cEthics in Internet\nEthnography\u201d in Buchanan 2004: 45\u201361.",
                "Sweeney, Latanya, 2002, \u201cK-Anonymity: A Model for Protecting\nPrivacy\u201d, <em>International Journal of Uncertainty, Fuzziness\nand Knowledge-Based Systems</em>, 10(5): 557\u2013570.\ndoi:10.1142/S0218488502001648",
                "Thomas, Jim, 2004, \u201cReexamining the Ethics of Internet\nresearch: Facing the Challenge of Overzealous Oversight\u201d, in\nJohns, Chen, and Hall 2004: 187\u2013201.",
                "Thorseth, May (ed.), 2003, <em>Applied Ethics in Internet\nResearch</em> (Programme for Applied Ethics Publication Series No. 1),\nTrondheim, Norway: NTNU University Press.",
                "Tsai, Janice, Lorrie Faith Cranor, Alessandro Acquisti, and\nChristina M. Fong, 2006, \u201cWhat\u2019s It To You? A Survey of\nOnline Privacy Concerns and Risks\u201d. NET Institute Working Paper\nNo. 06\u201329. doi:10.2139/ssrn.941708",
                "Turkle, Sherry,1997, <em>Life on the Screen: Identity in the Age\nof the Internet</em>, New York: Touchstone.",
                "Van Heerden, Alastair, Doug Wassenaar, Zaynab Essack, Khanya\nVilakazi, and Brandon A. Kohrt, 2020, \u201cIn-Home Passive Sensor\nData Collection and Its Implications for Social Media Research:\nPerspectives of Community Women in Rural South Africa\u201d,\n<em>Journal of Empirical Research on Human Research Ethics</em>,\n15(1\u20132): 97\u2013107. doi:10.1177/1556264619881334",
                "Vitak, Jessica, Nicholas Proferes, Katie Shilton, and Zahra\nAshktorab, 2017, \u201cEthics Regulation in Social Computing\nResearch: Examining the Role of Institutional Review Boards\u201d,\n<em>Journal of Empirical Research on Human Research Ethics</em>,\n12(5): 372\u2013382. doi:10.1177/1556264617725200",
                "Walstrom, Mary K., 2004, \u201cEthics and Engagement in\nCommunication Scholarship: Analyzing Public, Online Support Groups as\nResearcher/Participant-Experiencer\u201d, in Buchanan 2004:\n174\u2013202.",
                "Walther, Joseph B., 2002, \u201cResearch Ethics in\nInternet-Enabled Research: Human Subjects Issues and Methodological\nMyopia\u201d, <em>Ethics and Information Technology</em>, 4(3):\n205\u2013216. doi:10.1023/A:1021368426115",
                "White, Michele, 2002, \u201cRepresentations or People?\u201d,\n<em>Ethics and Information Technology</em>, 4(3): 249\u2013266.\ndoi:10.1023/A:1021376727933",
                "World Medical Association, 1964/2008, \u201cDeclaration of\nHelsinki: Ethical Principles for Medical Research Involving Human\nSubjects\u201d. Adopted by the 18<sup>th</sup> World Medical\nAssembly. Amended 1975, 1983, 1989, 1996, 2000, 2002, 2004, 2008.\n [<a href=\"https://www.wma.net/what-we-do/medical-ethics/declaration-of-helsinki/\" target=\"other\">Declaration of Helsinki available online</a>]",
                "Wright, David R., 2006, \u201cResearch Ethics and Computer\nScience: An Unconsummated Marriage\u201d, in <em>Proceedings of the\n24th Annual Conference on Design of Communication: SIGDOC\n\u201906</em>, Myrtle Beach, SC: ACM Press, pp. 196\u2013201.\ndoi:10.1145/1166324.1166369",
                "Zimmer, Michael T., 2010, \u201c\u2018But the Data Is Already\nPublic\u2019: On the Ethics of Research in Facebook\u201d,\n<em>Ethics and Information Technology</em>, 12(4): 313\u2013325.\ndoi:10.1007/s10676-010-9227-5",
                "\u2013\u2013\u2013, 2016, \u201cOkCupid Study Reveals the\nPerils of Big-Data Science\u201d, <em>Wired.com</em>, 14 May 2016.\n [<a href=\"https://www.wired.com/2016/05/okcupid-study-reveals-perils-big-data-science/\" target=\"other\">Zimmer 2016 available online</a>]",
                "Zimmer, Michael and Edward Chapman, 2020, \u201cEthical Review\nBoards and Pervasive Data Research: Gaps and Opportunities\u201d,\nPaper presented at AoIR 2020: The 21st Annual Conference of the\nAssociation of Internet Researchers.\n [<a href=\"https://spir.aoir.org/ojs/index.php/spir/article/download/11369/9983\" target=\"other\">Zimmer and Chapman 2020 extended abstract available online (pdf)</a>]",
                "Zimmer, Michael T. and Katharina Kinder-Kurlanda (eds.), 2017,\n<em>Internet Research Ethics for the Social Age: New Challenges,\nCases, and Contexts</em>, New York: Peter Lang Publishing."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Acquisti, Alessandro and Ralph Gross, 2006, \u201cImagined\nCommunities: Awareness, Information Sharing, and Privacy on the\nFacebook\u201d, in <em>Privacy Enhancing Technologies: PET 2006</em>,\nGeorge Danezis and Philippe Golle (eds.), (Lecture Notes in Computer\nScience 4258), Berlin, Heidelberg: Springer Berlin Heidelberg, pp.\n36\u201358. doi:10.1007/11957454_3</li>\n<li>Allen, Christina, 1996, \u201cWhat\u2019s Wrong with the\n\u2018Golden Rule\u2019? Conundrums of Conducting Ethical Research\nin Cyberspace\u201d, <em>The Information Society</em>, 12(2):\n175\u2013188. doi:10.1080/713856146</li>\n<li>Annas, George J., 2009, \u201cGlobalized Clinical Trials and\nInformed Consent\u201d, <em>New England Journal of Medicine</em>,\n360(20): 2050\u20132053. doi:10.1056/NEJMp0901474</li>\n<li>Aycock, John, Elizabeth Buchanan, Scott Dexter, and David\nDittrich, 2012, \u201cHuman Subjects, Agents, or Bots: Current Issues\nin Ethics and Computer Security Research\u201d, in <em>Financial\nCryptography and Data Security</em>, George Danezis, Sven Dietrich,\nand Kazue Sako (eds.), (Lecture Notes in Computer Science 7126),\nBerlin, Heidelberg: Springer Berlin Heidelberg, pp. 138\u2013145.\ndoi:10.1007/978-3-642-29889-9_12</li>\n<li>Banks, Will and Michelle Eble, 2007, \u201cDigital Spaces, Online\nEnvironments, and Human Participant Research: Interfacing with\nInstitutional Review Boards\u201d, in <em>Digital Writing Research:\nTechnologies, Methodologies, and Ethical Issues</em>, Heidi A. McKee\nand D\u00e0nielle Nicole DeVoss (eds.), Cresskill, NJ: Hampton\nPress, pp. 27\u201347.</li>\n<li>Barbaro, Michael and Tom Zeller Jr., 2006, \u201cA Face Is\nExposed for AOL Searcher No. 4417749\u201d, <em>The New York\nTimes</em>, 9 August 2006, pp. A1.</li>\n<li>Barratt, Monica Jane and Simon Lenton, 2010, \u201cBeyond\nRecruitment? Participatory Online Research with People Who Use\nDrugs\u201d, <em>International Journal of Internet Research\nEthics</em>, 3(1): 69\u201386.\n [<a href=\"http://hdl.handle.net/20.500.11937/23339\" target=\"other\">Barratt and Lenton 2010 available online</a>]</li>\n<li>BBC, 2011, \u201cUS Scientists \u2018Knew Guatemala Syphilis\nTests Unethical\u2019\u201d, BBC News, 30 August 2011, sec. Latin\nAmerica &amp; Caribbean.\n [<a href=\"https://www.bbc.com/news/world-latin-america-14712089\" target=\"other\">BBC 2011 available online</a>]</li>\n<li>Beauchamp, Tom L. and James F. Childress, 2008, <em>Principles of\nBiomedical Ethics</em>, Oxford: Oxford University Press.</li>\n<li>Blackstone, Mary, Lisa Given, Joseph Levy, Michelle McGinn,\nPatrick O\u2019Neill, Ted Palys, and Will van den Hoonaard, 2008,\n<em>Extending the Spectrum: The TCPS and Ethical Issues Involving\nInternet-Based Research</em>, Interagency Advisory Panel and\nSecretariat on Research Ethics, Ottawa, Canada.\n [<a href=\"https://researchoutput.csu.edu.au/en/publications/extending-the-spectrum-the-tcps-and-ethical-issues-involving-inte\" target=\"other\">Blackstone et al. 2008 available online</a>]</li>\n<li>Boehlefeld, Sharon Polancic, 1996, \u201cDoing the Right Thing:\nEthical Cyberspace Research\u201d, <em>The Information Society</em>,\n12(2): 141\u2013152. doi:10.1080/713856136</li>\n<li>Boga, Mwanamvua, Alun Davies, Dorcas Kamuya, Samson M. Kinyanjui,\nEster Kivaya, Francis Kombe, Trudie Lang, Vicki Marsh, Bibi Mbete,\nAlbert Mlamba, et al., 2011, \u201cStrengthening the Informed Consent\nProcess in International Health Research through Community Engagement:\nThe KEMRI-Wellcome Trust Research Programme Experience\u201d,\n<em>PLoS Medicine</em>, 8(9): e1001089.\ndoi:10.1371/journal.pmed.1001089</li>\n<li>Bonneau, Joseph and S\u00f6ren Preibusch, 2010, \u201cThe Privacy\nJungle: On the Market for Data Protection in Social Networks\u201d,\nin <em>Economics of Information Security and Privacy</em>, Tyler\nMoore, David Pym, and Christos Ioannidis (eds.), Boston: Springer US,\npp. 121\u2013167. doi:10.1007/978-1-4419-6967-5_8</li>\n<li>Booth, Robert, 2014, \u201cFacebook reveals news feed experiment\nto control emotions\u201d, <em>The Guardian</em>, 29 June 2014.\n [<a href=\"https://www.theguardian.com/technology/2014/jun/29/facebook-users-emotions-news-feeds\" target=\"other\">Booth 2014 available online</a>]</li>\n<li>Bromseth, Janne C. H., 2002, \u201cPublic Places: Public\nActivities? Methodological Approaches and Ethical Dilemmas in Research\non Computer-mediated Communication Contexts\u201d, in <em>Researching\nICTs in Context</em>, Andrew Morrison (ed.), InterMedia Report 3/2002,\nOslo: University of Oslo, pp. 33\u201361.\n [<a href=\"https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.7392&amp;rep=rep1&amp;type=pdf\" target=\"other\">Bromseth 2002 available online</a>]</li>\n<li>Brothers, Kyle Bertram and Ellen Wright Clayton, 2010,\n\u201c\u2018Human Non-Subjects Research\u2019: Privacy and\nCompliance\u201d, <em>The American Journal of Bioethics</em>, 10(9):\n15\u201317. doi:10.1080/15265161.2010.492891</li>\n<li>Bruckman, Amy, 2006, \u201cTeaching Students to Study Online\nCommunities Ethically\u201d, <em>Journal of Information Ethics</em>,\n15(2): 82\u201398. doi:10.3172/JIE.15.2.82</li>\n<li>Buchanan, Elizabeth A. (ed.), 2004, <em>Readings in Virtual\nResearch Ethics: Issues and Controversies</em>, Hershey, PA:\nInformation Science Publishing.</li>\n<li>\u2013\u2013\u2013, 2006, \u201cIntroduction: Internet\nResearch Ethics at a Critical Juncture\u201d, <em>Journal of\nInformation Ethics</em>, 15(2): 14\u201317.\ndoi:10.3172/JIE.15.2.14</li>\n<li>\u2013\u2013\u2013, 2011, \u201cInternet Research Ethics:\nPast, Present, and Future\u201d, in Consalvo and Ess 2011:\n83\u2013108. doi:10.1002/9781444314861.ch5</li>\n<li>\u2013\u2013\u2013, 2016, \u201cEthics in Digital\nResearch\u201d, in <em>Handbuch Soziale Praktiken und Digitale\nAlltagswelten</em>, Heidrun Friese, Gala Rebane, Marcus Nolden, and\nMiriam Schreiter (eds.), Wiesbaden: Springer Fachmedien Wiesbaden, pp.\n1\u20139. doi:10.1007/978-3-658-08460-8_47-1</li>\n<li>Buchanan, Elizabeth A. and Charles M. Ess, 2008, \u201cInternet\nResearch Ethics: The Field and Its Critical Issues\u201d, in <em>The\nHandbook of Information and Computer Ethics</em>, Kenneth Einar Himma\nand Herman T. Tavani (eds.), Hoboken, NJ: John Wiley &amp; Sons, Inc.,\npp. 273\u2013292. doi:10.1002/9780470281819.ch11</li>\n<li>\u2013\u2013\u2013, 2009, \u201cInternet Research Ethics and\nthe Institutional Review Board: Current Practices and Issues\u201d,\n<em>ACM SIGCAS Computers and Society</em>, 39(3): 43\u201349.\ndoi:10.1145/1713066.1713069</li>\n<li>Buchanan, Elizabeth A. and Erin E. Hvizdak, 2009, \u201cOnline\nSurvey Tools: Ethical and Methodological Concerns of Human Research\nEthics Committees\u201d, <em>Journal of Empirical Research on Human\nResearch Ethics</em>, 4(2): 37\u201348.\ndoi:10.1525/jer.2009.4.2.37</li>\n<li>Buchanan, Elizabeth, John Aycock, Scott Dexter, David Dittrich,\nand Erin Hvizdak, 2011, \u201cComputer Science Security Research and\nHuman Subjects: Emerging Considerations for Research Ethics\nBoards\u201d, <em>Journal of Empirical Research on Human Research\nEthics</em>, 6(2): 71\u201383. doi:10.1525/jer.2011.6.2.71</li>\n<li>Carpenter, Katherine J. and David Dittrich, 2012, \u201cBridging\nthe Distance: Removing the Technology Buffer and Seeking Consistent\nEthical Analysis in Computer Security Research\u201d, in <em>Digital\nEthics: Research &amp; Practice</em> (Digital Formations 85), Don\nHeider and Adrienne Massanari (eds.), New York: Peter Lang, pp.\n1\u201329.</li>\n<li>[CASRO] Council of American Survey Research, 2011, \u201cCASRO\nCode of Standards and Ethics for Survey Research\u201d, First adopted\n1977 and revised since.\n [<a href=\"https://www.ftc.gov/sites/default/files/documents/public_comments/preliminary-ftc-staff-report-protecting-consumer-privacy-era-rapid-change-proposed-framework/00356-57963.pdf\" target=\"other\">CASRO code available online</a>]</li>\n<li>Chen, Jenny J., Natala J. Menezes, and Adam D. Bradley, 2011,\n\u201cOpportunities for Crowdsourcing Research on Amazon Mechanical\nTurk\u201d, <em>Interfaces</em>, 5(3).\n [<a href=\"https://www.researchgate.net/publication/228954187_Opportunities_for_Crowdsourcing_Research_on_Amazon_Mechanical_Turk\" target=\"other\">J. Chen, Menezes, and Bradley 2011 available online</a>]</li>\n<li>Colvin, Jan and Jane Lanigan, 2005, \u201cEthical Issues and Best\nPractice Considerations for Internet Research\u201d, <em>Journal of\nFamily and Consumer Sciences</em>, 97(3): 34\u201339.</li>\n<li>Conley, Caryn and Jennifer Tosti-Kharas, 2014,\n\u201cCrowdsourcing Content Analysis for Managerial Research\u201d,\n<em>Management Decision</em>, 52(4): 675\u2013688.\ndoi:10.1108/MD-03-2012-0156</li>\n<li>Consalvo, Mia and Charles Ess (eds.), 2011, <em>The Handbook of\nInternet Studies</em>, Oxford: Wiley-Blackwell.\ndoi:10.1002/9781444314861</li>\n<li>Crawford, Kate and Jason Schultz, 2014, \u201cBig Data and Due\nProcess: Toward a Framework to Redress Predictive Privacy\nHarms\u201d, <em>Boston College Law Review</em>, 55(1):\n93\u2013128.</li>\n<li>Dittrich, David, Michael Bailey, and Sven Dietrich, 2011,\n\u201cBuilding an Active Computer Security Ethics Community\u201d,\n<em>IEEE Security &amp; Privacy Magazine</em>, 9(4): 32\u201340.\ndoi:10.1109/MSP.2010.199</li>\n<li>Drew, David A., Long H. Nguyen, Claire J. Steves, Cristina Menni,\nMaxim Freydin, Thomas Varsavsky, Carole H. Sudre, M. Jorge Cardoso,\nSebastien Ourselin, Jonathan Wolf, et al., 2020, \u201cRapid\nImplementation of Mobile Technology for Real-Time Epidemiology of\nCOVID-19\u201d, <em>Science</em>, 368(6497): 1362\u20131367.\ndoi:10.1126/science.abc0473</li>\n<li>Elgesem, Dag, 2002, \u201cWhat Is Special about the Ethical\nIssues in Online Research?\u201d, <em>Ethics and Information\nTechnology</em>, 4(3): 195\u2013203. doi:10.1023/A:1021320510186</li>\n<li>Emanuel, Ezekiel J., Robert A. Crouch, John D. Arras, Jonathan D.\nMoreno, and Christine Grady (eds.), 2003, <em>Ethical and Regulatory\nAspects of Clinical Research: Readings and Commentary</em>, Baltimore:\nJohns Hopkins University Press.</li>\n<li>Ess, Charles, 2016, \u201cPhronesis for machine ethics? Can\nrobots perform ethical judgments?\u201d, <em>Frontiers in Artificial\nIntelligence and Applications</em>, 290: 386\u2013389.\ndoi:10.3233/978-1-61499-708-5-386</li>\n<li>Ess, Charles and the Association of Internet Researchers (AoIR)\nEthics Working committee, 2002, \u201cEthical Decision-Making and\nInternet Research: Recommendations from the AoIR Ethics Working\nCommittee\u201d, Approved by the AoIR, 27 November 2002.\n [<a href=\"http://aoir.org/reports/ethics.pdf\" target=\"other\">Ess and AoIR 2002 available online</a>]</li>\n<li>Eysenbach, Gunther, 1999, \u201cWelcome to the Journal of Medical\nInternet Research\u201d, <em>Journal of Medical Internet\nResearch</em>, 1(1): e5. doi:10.2196/jmir.1.1.e5</li>\n<li>Eysenbach, Gunther and James E. Till, 2001, \u201cEthical Issues\nin Qualitative Research on Internet Communities\u201d, <em>BMJ</em>,\n323(7321): 1103\u20131105. doi:10.1136/bmj.323.7321.1103</li>\n<li>Fairfield, Joshua A., 2012, \u201cAvatar Experimentation: Human\nSubjects Research in Virtual Worlds\u201d, <em>U.C. Irvine Law\nReview</em>, 2: 695\u2013772.</li>\n<li>Federal Register, 2011, \u201cSubmission for Review and Comment:\n\u2018The Menlo Report: Ethical Principles Guiding Information and\nCommunication Technology Research\u2019\u201d (\u201cMenlo\nReport\u201d) for the Department of Homeland Security (DHS), Science\nand Technology, Cyber Security Division (CSD), Protected Repository\nfor the Defense of Infrastructure Against Cyber Threats\n(PREDICT)\u201d, 28 December 2011, Volume 76, Number 249, Docket No.\nDHS-2011-0074.\n [<a href=\"https://www.federalregister.gov/documents/2011/12/28/2011-33231/submission-for-review-and-comment-the-menlo-report-ethical-principles-guiding-information-and\" target=\"other\">Federal Register 2011 available online</a>]</li>\n<li>\u2013\u2013\u2013, 2017, \u201cFederal Policy for the\nProtection of Human Subjects\u201d, 19 January 2017, Volume 82,\nNumber 12\n [<a href=\"https://www.federalregister.gov/documents/2017/01/19/2017-01058/federal-policy-for-the-protection-of-human-subjects\" target=\"other\">Federal Register 2017 available online</a>]</li>\n<li>Fiesler, Casey, Nathan Beard, and Brian C. Keegan, 2020, \u201cNo\nRobots, Spiders, or Scrapers: Legal and Ethical Regulation of Data\nCollection Methods in Social Media Terms of Service\u201d,\n<em>Proceedings of the International AAAI Conference on Web and Social\nMedia</em>, 14: 187\u2013196.\n [<a href=\"https://www.aaai.org/ojs/index.php/ICWSM/article/view/7290\" target=\"other\">Fiesler, Beard, and Keegan 2020 available online</a>]</li>\n<li>Fiesler, Casey, Jeff Hancock, Amy Bruckman, Michael Muller, Cosmin\nMunteanu, and Melissa Densmore, 2018, \u201cResearch Ethics for HCI:\nA Roundtable Discussion\u201d, in <em>Extended Abstracts of the 2018\nCHI Conference on Human Factors in Computing Systems</em>, , Montreal\nQC Canada: ACM, 1\u20135. doi:10.1145/3170427.3186321</li>\n<li>Fiesler, Casey and Nicholas Proferes, 2018,\n\u201c\u2018Participant\u2019 Perceptions of Twitter Research\nEthics\u201d, <em>Social Media + Society</em>, 4(1), first online 10\nMarch 2018. doi:10.1177/2056305118763366</li>\n<li>Flicker, Sarah, Dave Haans, and Harvey Skinner, 2004,\n\u201cEthical Dilemmas in Research on Internet Communities\u201d,\n<em>Qualitative Health Research</em>, 14(1): 124\u2013134.\ndoi:10.1177/1049732303259842</li>\n<li>Fossheim, Hallvard and Helene Ingierd (eds.), 2016, <em>Internet\nResearch Ethics:</em>, Oslo: Cappelen Damm Akademisk/NOASP.\ndoi:10.17585/noasp.3.1</li>\n<li>Frankel, Mark S. and Sanyin Siang, 1999, \u201cEthical and Legal\nAspects of Human Subjects Research in Cyberspace\u201d, A Report of a\nWorkshop, 10\u201311 June 1999, Washington, DC: American Association\nfor the Advancement of Science.\n [<a href=\"https://www.aaas.org/sites/default/files/report2.pdf\" target=\"other\">Frankel and Siang 1999 available online</a>]</li>\n<li>Franzke, Aline Shakti, Anja Bechmann, Michael Zimmer, Charles M.\nEss, and the Association of Internet Researchers (AoIR), 2020,\n<em>Internet Research: Ethical Guidelines 3.0</em>, AoIR.\n [<a href=\"https://aoir.org/reports/ethics3.pdf\" target=\"other\">Franzke et al. available online (pdf)</a>]</li>\n<li>Frauenberger, Christopher, Amy S. Bruckman, Cosmin Munteanu,\nMelissa Densmore, and Jenny Waycott, 2017, \u201cResearch Ethics in\nHCI: A Town Hall Meeting\u201d, in <em>Proceedings of the 2017 CHI\nConference Extended Abstracts on Human Factors in Computing Systems\n\u2013 CHI EA \u201917</em>, Denver: ACM Press, pp. 1295\u20131299.\ndoi:10.1145/3027063.3051135</li>\n<li>Gaw, Allan and Michael H. J. Burns, 2011, <em>On Moral Grounds:\nLessons from the History of Research Ethics</em>, Westerwood, Glasgow:\nSA Press.</li>\n<li>[GDPR] General Data Protection Regulation (GDPR), 2016,\n\u201cRegulation (EU) 2016/679 of the European Parliament and of the\nCouncil of 27 April 2016 on the protection of natural persons with\nregard to the processing of personal data and on the free movement of\nsuch data, and repealing Directive 95/46\u201d.\n [<a href=\"https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679&amp;from=EN\">available online</a>]</li>\n<li>Gilbert, Brendan James, 2009, \u201cGetting to Conscionable:\nNegotiating Virtual Worlds\u2019 End User License Agreements without\nGetting Externally Regulated\u201d, <em>Journal of International\nCommercial Law and Technology</em>, 4(4): 238\u2013251.\n [<a href=\"https://www.neliti.com/publications/28835/getting-to-conscionable-negotiating-virtual-worlds%C3%A2tm-end-user-license-agreement#cite\" target=\"other\">Gilbert 2009 available online</a>]</li>\n<li>Glickman, Seth W., Sam Galhenage, Lindsay McNair, Zachry Barber,\nKeyur Patel, Kevin A. Schulman, and John G. McHutchison, 2012,\n\u201cThe Potential Influence of Internet-Based Social Networking on\nthe Conduct of Clinical Research Studies\u201d, <em>Journal of\nEmpirical Research on Human Research Ethics</em>, 7(1): 71\u201380.\ndoi:10.1525/jer.2012.7.1.71</li>\n<li>Goldfarb, Norman M., 2008, \u201cAge of Consent for Clinical\nResearch\u201d, <em>Journal of Clinical Research Best Practices</em>,\n4(6).\n [<a href=\"https://www.magiworld.org/resources/journal/459_Consent_Age.pdf\" target=\"other\">Goldfarb 2008 available online</a>]</li>\n<li>[HHS] Health and Human Services, 2017, \u201cExcerpts from the\nJanuary 19, 2017 Revised Common Rule Preamble\u201d.\n [<a href=\"https://www.hhs.gov/ohrp/regulations-and-policy/regulations/2018-req-preamble/\" target=\"other\">HHS 2017 available online</a>]</li>\n<li>Hill, Kashmir, 2014, \u201cFacebook Added \u2018Research\u2019\nTo User Agreement 4 Months After Emotion Manipulation Study\u201d,\n<em>Forbes.com.</em>, 30 June 2014.\n [<a href=\"https://www.forbes.com/sites/kashmirhill/2014/06/30/facebook-only-got-permission-to-do-research-on-users-after-emotion-manipulation-study/#23483d1a10c1\" target=\"other\">Hill 2014 available online</a>]</li>\n<li>Hoffmann, Anna Lauren, 2016, \u201cFacebook has a New Process for\nDiscussing Ethics. But is It Ethical?\u201d <em>The Guardian</em>, 17\nJune 2016.\n [<a href=\"https://www.theguardian.com/technology/2016/jun/17/facebook-ethics-but-is-it-ethical\" target=\"other\">Hoffmann 2016 available online</a>]</li>\n<li>Homeland Security Department, 2011, \u201cSubmission for Review\nand Comment: \u2018The Menlo Report: Ethical Principles Guiding\nInformation and Communication Technology Research\u2019\u201d,\n<em>Federal Register: The Daily Journal of the United States\nGovernment</em>, FR Doc. 2011-3323, 28 December 2011.\n [<a href=\"https://www.federalregister.gov/articles/2011/12/28/2011-33231/submission-for-review-and-comment-the-menlo-report-ethical-principles-guiding-information-and\" target=\"other\">Homeland Security Department 2011 available online</a>].</li>\n<li>Hubach, Randolph D., Andrew O\u2019Neil, Mollie Stowe, Zachary\nGiano, Brenda Curtis, and Celia B. Fisher, forthcoming,\n\u201cPerceived Confidentiality Risks of Mobile Technology-Based\nEcologic Momentary Assessment to Assess High-Risk Behaviors Among\nRural Men Who Have Sex with Men\u201d, <em>Archives of Sexual\nBehavior</em>, first online: 20 February 2020.\ndoi:10.1007/s10508-019-01612-x</li>\n<li>Hudson, James M. and Amy Bruckman, 2004, \u201c\u2018Go\nAway\u2019: Participant Objections to Being Studied and the Ethics of\nChatroom Research\u201d, <em>The Information Society</em>, 20(2):\n127\u2013139. doi:10.1080/01972240490423030</li>\n<li>\u2013\u2013\u2013, 2005, \u201cUsing Empirical Data to Reason\nabout Internet Research Ethics\u201d, in <em>ECSCW 2005: Proceedings\nof the Ninth European Conference on Computer-Supported Cooperative\nWork, 18\u201322 September 2005, Paris, France</em>, Hans Gellersen,\nKjeld Schmidt, Michel Beaudouin-Lafon, and Wendy Mackay (eds.),\nBerlin/Heidelberg: Springer-Verlag, pp. 287\u2013306.\ndoi:10.1007/1-4020-4023-7_15</li>\n<li>Hunsinger, Jeremy, Lisbeth Klastrup, and Matthew Allen (eds.),\n2010, <em>International Handbook of Internet Research</em>, Dordrecht:\nSpringer Netherlands. doi:10.1007/978-1-4020-9789-8</li>\n<li>Illingworth, Nicola, 2001, \u201cThe Internet Matters: Exploring\nthe Use of the Internet as a Research Tool\u201d, <em>Sociological\nResearch Online</em>, 6(2): 79\u201390. doi:10.5153/sro.600\n [<a href=\"https://www.socresonline.org.uk/6/2/illingworth.html\" target=\"other\">Illingworth 2001 available online</a>]</li>\n<li>International Telecommunications Union, 2019, \u201cNew ITU Data\nReveal Growing Internet Uptake but a Widening Digital Gender\nDivide\u201d, <em>ITU Media Centre</em>,\n [<a href=\"https://www.itu.int/en/mediacentre/Pages/2019-PR19.aspx\" target=\"other\">ITU 2019 available online</a>]</li>\n<li>Jackman, Molly and Lauri Kanerva, 2016, \u201cEvolving the IRB:\nBuilding Robust Review for Industry Research\u201d, <em>Washington\nand Lee Law Review Online</em>, 72(3): 442\u2013457.</li>\n<li>Jacobson, David, 1999, \u201cDoing Research in Cyberspace\u201d,\n<em>Field Methods</em>, 11(2): 127\u2013145.\ndoi:10.1177/1525822X9901100204</li>\n<li>Johns, Mark D., Shing-Ling Sarina Chen, and G. Jon Hall (eds.),\n2003, <em>Online Social Research: Methods, Issues, and Ethics</em>,\nNew York: Peter Lang.</li>\n<li>Jones, Arnita, 2008, \u201cAHA Statement on IRB\u2019s and Oral\nHistory Research\u201d, <em>American Historical Association\nActivities</em>, 1 February 2008.\n [<a href=\"https://www.historians.org/publications-and-directories/perspectives-on-history/february-2008/aha-statement-on-irbs-and-oral-history-research\" target=\"other\">A. Jones 2008 available online</a>]</li>\n<li>Jones, Steve (ed.), 1999, <em>Doing Internet Research: Critical\nIssues and Methods for Examining the Net</em>, Thousand Oaks, CA:\nSage.</li>\n<li>Kaplan, Andreas M. and Michael Haenlein, 2010, \u201cUsers of the\nWorld, Unite! The Challenges and Opportunities of Social Media\u201d,\n<em>Business Horizons</em>, 53(1): 59\u201368.\ndoi:10.1016/j.bushor.2009.09.003</li>\n<li>Kerry, Cameron F., 2020, \u201cProtecting privacy in an AI-driven\nworld\u201d (AI Governance), 10 February 2020, Center for Technology\nInnovation, Brookings Institute.\n [<a href=\"https://www.brookings.edu/research/protecting-privacy-in-an-ai-driven-world/\" target=\"other\">Kerry 2020 available online</a>]</li>\n<li>Keyes, Os, 2019, \u201cCounting the Countless: Why data science\nis a profound threat for queer people\u201d, <em>Real Life</em>, 8\nApril 2019.\n [<a href=\"https://reallifemag.com/counting-the-countless/\" target=\"other\">Keyes 2019 available online</a>]</li>\n<li>King, Storm A., 1996, \u201cResearching Internet Communities:\nProposed Ethical Guidelines for the Reporting of Results\u201d,\n<em>The Information Society</em>, 12(2): 119\u2013128.\ndoi:10.1080/713856145</li>\n<li>Kitchin, Heather A., 2003, \u201cThe Tri-Council Policy Statement\nand Research in Cyberspace: Research Ethics, the Internet, and\nRevising a \u2018Living Document\u2019\u201d, <em>Journal of\nAcademic Ethics</em>, 1(4): 397\u2013418.\ndoi:10.1023/B:JAET.0000025671.83557.fa</li>\n<li>\u2013\u2013\u2013, 2008, <em>Research Ethics and the Internet:\nNegotiating Canada\u2019s Tri-Council\u2019s Policy</em>, Winnipeg,\nManitoba: Fernwood Publishing</li>\n<li>Kramer, Adam D. I., James E. Guillory, and Jeffrey T. Hancock,\n2014, \u201cExperimental Evidence of Massive-Scale Emotional\nContagion through Social Networks\u201d, <em>Proceedings of the\nNational Academy of Sciences</em>, 111(24): 8788\u20138790.\ndoi:10.1073/pnas.1320040111</li>\n<li>Kraut, Robert, Judith Olson, Mahzarin Banaji, Amy Bruckman,\nJeffrey Cohen, and Mick Couper, 2004, \u201cPsychological Research\nOnline: Report of Board of Scientific Affairs\u2019 Advisory Group on\nthe Conduct of Research on the Internet.\u201d, <em>American\nPsychologist</em>, 59(2): 105\u2013117.\ndoi:10.1037/0003-066X.59.2.105</li>\n<li>Krogstad, Donald J., Samba Diop, Amadou Diallo, Fawaz Mzayek,\nJoseph Keating, Ousmane A. Koita, and Y\u00e9ya T. Tour\u00e9,\n2010, \u201cInformed Consent in International Research: The Rationale\nfor Different Approaches\u201d, <em>The American Journal of Tropical\nMedicine and Hygiene</em>, 83(4): 743\u2013747.\ndoi:10.4269/ajtmh.2010.10-0014</li>\n<li>Lawson, Danielle, 2004, \u201cBlurring the Boundaries: Ethical\nConsiderations for Online Research Using Synchronous CMC\nForums\u201d, in Buchanan 2004: 80\u2013100.</li>\n<li>Leibovici, Didier G., Suchith Anand, Jerry Swan, James Goulding,\nGobe Hobona, Lucy Bastin, Sergiusz Pawlowicz, Mike Jackson, and\nRichard James, 2010, \u201cWorkflow Issues for Health Mapping\n\u2018Mashups\u2019 of OGC\u201d, University of Nottingham, CGS\nTechnical Report, 2010 DL1.\n [<a href=\"https://www.researchgate.net/publication/282698491_Workflow_issues_for_Health-mapping_mashups\" target=\"other\">Leibovici et al. 2010 available online</a>]</li>\n<li>Madejski, Michelle, Maritza Lupe Johnson, and Steven Michael\nBellovin, 2011, \u201cThe Failure of Online Social Network Privacy\nSettings\u201d. Columbia Research Report CUCS-010-11, Columbia\nUniversity. doi:10.7916/D8NG4ZJ1</li>\n<li>Mann, Chris, 2003, \u201cGenerating Data Online: Ethical Concerns\nand Challenges for the C21 Researcher\u201d, in Thorseth 2003:\n31\u201349.</li>\n<li>Markham, Annette N., 1998, <em>Life Online: Researching Real\nExperience in Virtual Space</em>, Walnut Creek, CA: Altamira\nPress.</li>\n<li>\u2013\u2013\u2013, 2012, \u201cFabrication as Ethical\nPractice: Qualitative Inquiry in Ambiguous Internet Contexts\u201d,\n<em>Information, Communication &amp; Society</em>, 15(3):\n334\u2013353. doi:10.1080/1369118X.2011.641993</li>\n<li>Markham, Annette N. and Nancy K. Baym (eds.), 2008, <em>Internet\nInquiry: Conversations about Method</em>, Thousand Oaks, CA: Sage\nPublications.</li>\n<li>Markham, Annette, N. and Elizabeth Buchanan, 2012. : <em>Ethical\ndecision-making and internet research: Version 2.0. recommendations\nfrom the AoIR ethics working committee</em> Association of Internet\nResearchers.\n [<a href=\"https://aoir.org/reports/ethics2.pdf\">Markham and Buchanan 2012 available online</a>]</li>\n<li>Markoff, John, 2010, \u201cIn a Video Game, Tackling the\nComplexities of Protein Folding\u201d, <em>New York Times</em>, 4\nAugust 2010.\n [<a href=\"http://www.nytimes.com/2010/08/05/science/05protein.html\" target=\"other\">Markoff 2010 available online</a>]</li>\n<li>McKee, Heidi A. and James E. Porter, 2009, <em>The Ethics of\nInternet Research: A Rhetorical, Case-based Process</em>, New York:\nPeter Lang Publishing.</li>\n<li>Mendelson, Cindy, 2007, \u201cRecruiting Participants for\nResearch From Online Communities\u201d, <em>CIN: Computers,\nInformatics, Nursing</em>, 25(6): 317\u2013323.\ndoi:10.1097/01.NCN.0000299653.13777.51</li>\n<li>Metcalf, Jacob, 2017, \u201c\u2018The Study Has Been Approved by\nthe IRB\u2019: Gayface AI, Research Hype and the Pervasive Data\nEthics Gap\u201d. PERVADE Team: Pervasive Data Ethics for\nComputational Research, Report.\n [<a href=\"https://medium.com/pervade-team/the-study-has-been-approved-by-the-irb-gayface-ai-research-hype-and-the-pervasive-data-ethics-ed76171b882c\" target=\"other\">Metcalf 2017 available online</a>]</li>\n<li>Metcalf, Jacob, Emanuel Moss, and danah boyd, 2019, \u201cOwning\nEthics: Corporate Logics, Silicon Valley, and the Institutionalization\nof Ethics\u201d, <em>Social Research: An International\nQuarterly</em>, 86(2): 449\u2013476.</li>\n<li>Milne, George R. and Mary J. Culnan, 2004, \u201cStrategies for\nReducing Online Privacy Risks: Why Consumers Read (or Don\u2019t\nRead) Online Privacy Notices\u201d, <em>Journal of Interactive\nMarketing</em>, 18(3): 15\u201329. doi:10.1002/dir.20009</li>\n<li>Mondschein, Christopher F. and Cosimo Monda, 2018, \u201cThe\nEU\u2019s General Data Protection Regulation (GDPR) in a Research\nContext\u201d, in <em>Fundamentals of Clinical Data Science</em>,\nPieter Kubben, Michel Dumontier, and Andre Dekker (eds.), Cham:\nSpringer International Publishing, pp. 55\u201371.\ndoi:10.1007/978-3-319-99713-1_5</li>\n<li>Moor, James H., 1985, \u201cWhat Is Computer Ethics?\u201d,\n<em>Metaphilosophy</em>, 16(4): 266\u2013275.\ndoi:10.1111/j.1467-9973.1985.tb00173.x</li>\n<li>Alexander, Larry and Michael Moore, 2007, \u201cDeontological\nEthics\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2007 Edition), Edward N. Zalta (ed.). URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/win2007/entries/ethics-deontological/\" target=\"other\">https://plato.stanford.edu/archives/win2007/entries/ethics-deontological/</a>&gt;</li>\n<li>Narayanan, Arvind and Vitaly Shmatikov, 2008, \u201cRobust\nde-anonymization of Large Sparse Datasets\u201d, <em>Proceedings of\nthe 29<sup>th</sup> IEEE Symposium on Security and Privacy, Oakland,\nCA, May 2008</em>, IEEE, pp. 111\u2013125. doi:10.1109/SP.2008.33\n [<a href=\"http://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf\" target=\"other\">Narayanan and Shmatikov 2008 available online (pdf)</a>]</li>\n<li>[NCPHSBBR] The National Commission for the Protection of Human\nSubjects of Biomedical and Behavioral Research, 1979, \u201cThe\nBelmont Report: Ethical Principles and Guidelines for the Protection\nof Human Subjects of Research\u201d, Office for Human Research\nProtections, Department of Health and Human Services, United States.\n [<a href=\"http://www.hhs.gov/ohrp/humansubjects/guidance/belmont.html\" target=\"other\">NCPHSBBR 1979 available online</a>]</li>\n<li>[NESH] The National Committee for Research Ethics in the Social\nSciences and the Humanities [Norway], 2006, \u201cGuidelines for\nResearch Ethics in the Social Sciences, Law, and Humanities\u201d,\nPublished September 2006.\n [<a href=\"http://graduateschool.nd.edu/assets/21765/guidelinesresearchethicsinthesocialscienceslawhumanities.pdf\" target=\"other\">NESH 2006 available online</a>].</li>\n<li>\u2013\u2013\u2013, 2019, \u201cA Guide to Internet Research\nEthics\u201d.\n [<a href=\"https://www.forskningsetikk.no/en/guidelines/social-sciences-humanities-law-and-theology/a-guide-to-internet-research-ethics/\" target=\"other\">NESH 2019 available online</a>].</li>\n<li>Nissenbaum, Helen, 2009, <em>Privacy in Context: Technology,\nPolicy, and the Integrity of Social Life</em>, Stanford, CA: Stanford\nUniversity Press.</li>\n<li>[NSTC] National Science and Technology Council, 2016,\n\u201cNational Privacy Research Strategy\u201d, Office of the\nPresident of the United States, June 2016.\n [<a href=\"https://www.nitrd.gov/pubs/NationalPrivacyResearchStrategy.pdf\" target=\"other\">NSTC 2016 available online</a>]</li>\n<li>Nuremberg Code, 1947 (1996), \u201cThe Nuremberg Code\u201d,\n<em>BMJ</em>, 313. doi:https://doi.org/10.1136/bmj.313.7070.1448 </li>\n<li>Ohm, Paul, 2010, \u201cBroken Promises of Privacy: Responding to\nthe Surprising Failure of Anonymization\u201d, <em>UCLA Law\nReview</em>, 57: 1701\u20131777.</li>\n<li>Overbeke, Grace, 2008, \u201cPro-Anorexia Websites: Content,\nImpact, and Explanations of Popularity\u201d, <em>Mind Matters: The\nWesleyan Journal of Psychology</em>, 3: 49\u201362.\n [<a href=\"https://www.academia.edu/6383345/Pro-Anorexia_Websites_Content_Impact_and_Explanations_of_Popularity\" target=\"other\">Overbeke 2008 available online</a>]</li>\n<li>[PRIM&amp;R] Public Responsibility in Medicine and Research,\nBankert, E., Gordon, B., Hurley, E., and Shriver, S. (eds), 2021,\n<em>Institutional Review Board: Management and Function </em>(third\nedition). Burlington, MA: Jones and Bartlett.</li>\n<li>Reid, Elizabeth, 1996, \u201cInformed Consent in the Study of\nOn-Line Communities: A Reflection on the Effects of Computer-Mediated\nSocial Research\u201d, <em>The Information Society</em>, 12(2):\n169\u2013174. doi:10.1080/713856138</li>\n<li>Reynolds, Ren, and Melissa de Zwart, 2010, \u201cThe Duty to\n\u2018Play\u2019: Ethics, EULAs and MMOs\u201d, <em>International\nJournal of Internet Research Ethics</em>, 3(1): 48\u201368.\n [<a href=\"https://www.globethics.net/gel/4410705\" target=\"other\">Reynolds &amp; de Zwart 2010 available online</a>]</li>\n<li>Ritchie, Donald A., 2003, <em>Doing Oral History: A Practical\nGuide</em>, New York: Oxford University Press.</li>\n<li>Rosenberg, \u00c5sa, 2010, \u201cVirtual World Research Ethics\nand the Private/Public Distinction\u201d, <em>International Journal\nof Internet Research Ethics</em>, 3(1): 23\u201337.</li>\n<li>Rosser, B. R. Simon, J. Michael Oakes, Joseph Konstan, Simon\nHooper, Keith J. Horvath, Gene P. Danilenko, Katherine E. Nygaard, and\nDerek J. Smolenski, 2010, \u201cReducing HIV Risk Behavior of Men Who\nHave Sex with Men through Persuasive Computing: Results of the\nMen\u02bcs INTernet Study-II\u201d, <em>AIDS</em>, 24(13):\n2099\u20132107. doi:10.1097/QAD.0b013e32833c4ac7</li>\n<li>[SACHRP] Secretary\u2019s Advisory Committee to the Office for\nHuman Research Protections, Unitd States Department of Health &amp;\nHuman Services, 2010,\n \u201c<a href=\"https://web.archive.org/web/20170209180021/http://archive.hhs.gov/ohrp/sachrp/mtgings/mtg07-10/present.html\" target=\"other\">SACHRP July 20\u201321, 2010 Meeting Presentations</a>\u201d.</li>\n<li>\u2013\u2013\u2013, 2013,\n \u201c<a href=\"https://www.hhs.gov/ohrp/sachrp-committee/recommendations/2013-may-20-letter-attachment-b/index.html\" target=\"other\">Attachment B: Considerations and Recommendations concerning Internet Research and Human Subjects Research Regulations, with Revisions</a>\u201d,\n Final document approved 12\u201313 March 2013.\n (<a href=\"https://www.hhs.gov/ohrp/sites/default/files/ohrp/sachrp/mtgings/2013%20March%20Mtg/internet_research.pdf\" target=\"other\">SACHRP 2013 pdf version</a>)</li>\n<li>\u2013\u2013\u2013, 2013, \u201cConsiderations and\nRecommendations Concerning Internet Research and Human Subjects\nResearch Regulations, with Revisions\u201d.\n [<a href=\"https://www.hhs.gov/ohrp/sites/default/files/ohrp/sachrp/mtgings/2013%20March%20Mtg/internet_research.pdf\">SACHRP 2013 available online</a>]</li>\n<li>\u2013\u2013\u2013, 2015,\n \u201c<a href=\"https://www.hhs.gov/ohrp/sachrp-committee/recommendations/2015-april-24-attachment-a/index.html\" target=\"other\">Attachment A: Human Subjects Research Implications of \u2018Big Data\u2019 Studies</a>\u201d,\n 24 April 2015.</li>\n<li>Samuel, Gabrielle and Elizabeth Buchanan, 2020, \u201cGuest\nEditorial: Ethical Issues in Social Media Research\u201d, <em>Journal\nof Empirical Research on Human Research Ethics</em>, 15(1\u20132):\n3\u201311. doi:10.1177/1556264619901215</li>\n<li>Scholz, Trebor, 2008, \u201cMarket Ideology and the Myths of Web\n2.0\u201d, <em>First Monday</em>, 13(3): 3 March 2008.\n [<a href=\"https://firstmonday.org/ojs/index.php/fm/article/view/2138\" target=\"other\">Scholz 2008 available online</a>]</li>\n<li>Schwartz, Paul M. and Daniel J. Solove, 2011, \u201cThe PII\nProblem: Privacy and a New Concept of Personally Identifiable\nInformation\u201d, <em>New York University Law Review</em>, 86(6):\n1814\u20131893.</li>\n<li>Seaboldt, James A. and Randy Kuiper, 1997, \u201cComparison of\nInformation Obtained from a Usenet Newsgroup and from Drug Information\nCenters\u201d, <em>American Journal of Health-System Pharmacy</em>,\n54(15): 1732\u20131735. doi:10.1093/ajhp/54.15.1732</li>\n<li>Sharf, Barbara F., 1997, \u201cCommunicating Breast Cancer\nOn-Line: Support and Empowerment on the Internet\u201d, <em>Women\n&amp; Health</em>, 26(1): 65\u201384. doi:10.1300/J013v26n01_05</li>\n<li>Sieber, Joan E., 1992, <em>Planning Ethically Responsible\nResearch: A Guide for Students and Internal Review Boards</em>,\nThousand Oaks, CA: Sage.</li>\n<li>\u2013\u2013\u2013, 2015, <em>Planning Ethically Responsible\nResearch: A Guide for Students and Internal Review Boards</em>, second\nedition, Thousand Oaks, CA: Sage.</li>\n<li>Simmhan, Yogesh, Roger Barga, Catharine van Ingen, Ed Lazowska,\nand Alex Szalay, 2008, \u201cOn Building Scientific Workflow Systems\nfor Data Management in the Cloud\u201d, in <em>2008 IEEE Fourth\nInternational Conference on EScience</em>, Indianapolis, IN: IEEE, pp.\n434\u2013435. doi:10.1109/eScience.2008.150</li>\n<li>Simmhan, Yogesh, Catharine van Ingen, Girish Subramanian, and Jie\nLi, 2009, \u201cBridging the Gap between the Cloud and an EScience\nApplication Platform\u201d. Microsoft Research Tech Report\nMSR-TR-2009-2021.\n [<a href=\"https://www.microsoft.com/en-us/research/publication/bridging-the-gap-between-the-cloud-and-an-escience-application-platform/\" target=\"other\">Simmhan et al. 2009 available online</a>]</li>\n<li>Skloot, Rebecca, 2010, <em>The Immortal Life of Henrietta\nLacks</em>, New York: Crown Publishers.</li>\n<li>Sloan, Luke, Curtis Jessop, Tarek Al Baghal, and Matthew Williams,\n2020, \u201cLinking Survey and Twitter Data: Informed Consent,\nDisclosure, Security, and Archiving\u201d, <em>Journal of Empirical\nResearch on Human Research Ethics,</em> 15(1\u20132):\n63\u201376.</li>\n<li>Smith, Michael A. and Brant Leigh, 1997, \u201cVirtual Subjects:\nUsing the Internet as an Alternative Source of Subjects and Research\nEnvironment\u201d, <em>Behavior Research Methods, Instruments, &amp;\nComputers</em>, 29(4): 496\u2013505. doi:10.3758/BF03210601</li>\n<li>Spriggs, Merle, 2010, <em>A Handbook for Human Research Ethics\nCommittees and Researchers: Understanding Consent in Research\nInvolving Children: The Ethical Issues</em>, Melbourne: The University\nof Melbourne/Murdoch Childrens Research Institute/The Royal\nChildren\u2019s Hospital Melbourne, version 4.\n <a href=\"https://web.archive.org/web/20120324133800/http://www.mcri.edu.au/media/62539/handbook.pdf\" target=\"other\">Spriggs 2010 available online</a>]</li>\n<li>Stahl, Bernd Carsten and David Wright, 2018, \u201cEthics and\nPrivacy in AI and Big Data: Implementing Responsible Research and\nInnovation\u201d, <em>IEEE Security &amp; Privacy</em>, 16(3):\n26\u201333. doi:10.1109/MSP.2018.2701164</li>\n<li>Sveningsson, Malin, 2004, \u201cEthics in Internet\nEthnography\u201d in Buchanan 2004: 45\u201361.</li>\n<li>Sweeney, Latanya, 2002, \u201cK-Anonymity: A Model for Protecting\nPrivacy\u201d, <em>International Journal of Uncertainty, Fuzziness\nand Knowledge-Based Systems</em>, 10(5): 557\u2013570.\ndoi:10.1142/S0218488502001648</li>\n<li>Thomas, Jim, 2004, \u201cReexamining the Ethics of Internet\nresearch: Facing the Challenge of Overzealous Oversight\u201d, in\nJohns, Chen, and Hall 2004: 187\u2013201.</li>\n<li>Thorseth, May (ed.), 2003, <em>Applied Ethics in Internet\nResearch</em> (Programme for Applied Ethics Publication Series No. 1),\nTrondheim, Norway: NTNU University Press.</li>\n<li>Tsai, Janice, Lorrie Faith Cranor, Alessandro Acquisti, and\nChristina M. Fong, 2006, \u201cWhat\u2019s It To You? A Survey of\nOnline Privacy Concerns and Risks\u201d. NET Institute Working Paper\nNo. 06\u201329. doi:10.2139/ssrn.941708</li>\n<li>Turkle, Sherry,1997, <em>Life on the Screen: Identity in the Age\nof the Internet</em>, New York: Touchstone.</li>\n<li>Van Heerden, Alastair, Doug Wassenaar, Zaynab Essack, Khanya\nVilakazi, and Brandon A. Kohrt, 2020, \u201cIn-Home Passive Sensor\nData Collection and Its Implications for Social Media Research:\nPerspectives of Community Women in Rural South Africa\u201d,\n<em>Journal of Empirical Research on Human Research Ethics</em>,\n15(1\u20132): 97\u2013107. doi:10.1177/1556264619881334</li>\n<li>Vitak, Jessica, Nicholas Proferes, Katie Shilton, and Zahra\nAshktorab, 2017, \u201cEthics Regulation in Social Computing\nResearch: Examining the Role of Institutional Review Boards\u201d,\n<em>Journal of Empirical Research on Human Research Ethics</em>,\n12(5): 372\u2013382. doi:10.1177/1556264617725200</li>\n<li>Walstrom, Mary K., 2004, \u201cEthics and Engagement in\nCommunication Scholarship: Analyzing Public, Online Support Groups as\nResearcher/Participant-Experiencer\u201d, in Buchanan 2004:\n174\u2013202.</li>\n<li>Walther, Joseph B., 2002, \u201cResearch Ethics in\nInternet-Enabled Research: Human Subjects Issues and Methodological\nMyopia\u201d, <em>Ethics and Information Technology</em>, 4(3):\n205\u2013216. doi:10.1023/A:1021368426115</li>\n<li>White, Michele, 2002, \u201cRepresentations or People?\u201d,\n<em>Ethics and Information Technology</em>, 4(3): 249\u2013266.\ndoi:10.1023/A:1021376727933</li>\n<li>World Medical Association, 1964/2008, \u201cDeclaration of\nHelsinki: Ethical Principles for Medical Research Involving Human\nSubjects\u201d. Adopted by the 18<sup>th</sup> World Medical\nAssembly. Amended 1975, 1983, 1989, 1996, 2000, 2002, 2004, 2008.\n [<a href=\"https://www.wma.net/what-we-do/medical-ethics/declaration-of-helsinki/\" target=\"other\">Declaration of Helsinki available online</a>]</li>\n<li>Wright, David R., 2006, \u201cResearch Ethics and Computer\nScience: An Unconsummated Marriage\u201d, in <em>Proceedings of the\n24th Annual Conference on Design of Communication: SIGDOC\n\u201906</em>, Myrtle Beach, SC: ACM Press, pp. 196\u2013201.\ndoi:10.1145/1166324.1166369</li>\n<li>Zimmer, Michael T., 2010, \u201c\u2018But the Data Is Already\nPublic\u2019: On the Ethics of Research in Facebook\u201d,\n<em>Ethics and Information Technology</em>, 12(4): 313\u2013325.\ndoi:10.1007/s10676-010-9227-5</li>\n<li>\u2013\u2013\u2013, 2016, \u201cOkCupid Study Reveals the\nPerils of Big-Data Science\u201d, <em>Wired.com</em>, 14 May 2016.\n [<a href=\"https://www.wired.com/2016/05/okcupid-study-reveals-perils-big-data-science/\" target=\"other\">Zimmer 2016 available online</a>]</li>\n<li>Zimmer, Michael and Edward Chapman, 2020, \u201cEthical Review\nBoards and Pervasive Data Research: Gaps and Opportunities\u201d,\nPaper presented at AoIR 2020: The 21st Annual Conference of the\nAssociation of Internet Researchers.\n [<a href=\"https://spir.aoir.org/ojs/index.php/spir/article/download/11369/9983\" target=\"other\">Zimmer and Chapman 2020 extended abstract available online (pdf)</a>]</li>\n<li>Zimmer, Michael T. and Katharina Kinder-Kurlanda (eds.), 2017,\n<em>Internet Research Ethics for the Social Age: New Challenges,\nCases, and Contexts</em>, New York: Peter Lang Publishing.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "ethics, biomedical: clinical research",
            "ethics: deontological",
            "informed consent",
            "privacy"
        ],
        "entry_link": [
            {
                "../clinical-research/": "ethics, biomedical: clinical research"
            },
            {
                "../ethics-deontological/": "ethics: deontological"
            },
            {
                "../informed-consent/": "informed consent"
            },
            {
                "../privacy/": "privacy"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=ethics-internet-research\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/ethics-internet-research/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=ethics-internet-research&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/ethics-internet-research/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=ethics-internet-research": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/ethics-internet-research/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=ethics-internet-research&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/ethics-internet-research/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "Allan, Rob, 2012,\n \u201c<a href=\"https://epubs.stfc.ac.uk/work/54691\" target=\"other\">Cloud and Web 2.0 Services for Supporting Research</a>\u201d.",
            "Chen, Xiaoyu, Gary Wills, Lester Gilbert, and David Bacigalupo,\n2010, \u201cUsing Cloud for Research: A Technical Review\u201d, JISC\nFinal Report for the TeciRes project.\n [<a href=\"https://www.researchgate.net/publication/44298273_Using_Cloud_for_Research_A_Technical_Review\" target=\"other\">X. Chen et al. 2010 available online</a>]",
            "Dittrich, David and Erin Kenneally, 2012,\n <a href=\"https://www.caida.org/publications/papers/2012/menlo_report_actual_formatted/\" target=\"other\">The Menlo Report: Ethical Principles Guiding Information and Communication Technology Research</a>,\n Homeland Security, United States Government.",
            "Hoofnagle, Chris Jay and Jennifer King, 2008, \u201cWhat\nCalifornians Understand About Privacy Online\u201d, Research Report\nfrom Samuelson Law Technology &amp; Public Policy Clinic, UC Berkeley\nLaw: Berkeley, CA. doi:10.2139/ssrn.1262130\n [<a href=\"https://www.law.berkeley.edu/wp-content/uploads/2016/06/Californians.pdf\" target=\"other\">Hoofnagle and King 2008 available online</a>]",
            "[NHRPAC] National Human Subjects Protection Advisory Committee,\n2002,\n \u201c<a href=\"https://web.archive.org/web/20161221060957/http://archive.hhs.gov/ohrp/nhrpac/documents/dataltr.pdf\" target=\"other\">Recommendations on Public Use Data Files</a>\u201d.",
            "[NIH] National Institutes of Health, 2010,\n \u201c<a href=\"https://oma.od.nih.gov/DMS/Documents/Privacy/Guide%20for%20Handling%20Sensitive%20Information%20at%20NIH.pdf\">Guide for Identifying and Handling Sensitive Information at the NIH</a>\u201d",
            "\u2013\u2013\u2013, 2021, \u201cCertificates of\nConfidentiality (CoC)\u201d, National Institutes of Health\n [<a href=\"https://grants.nih.gov/policy/humansubjects/coc.htm\" target=\"other\">NIH 2021 available online</a>]",
            "Rudder, Christian, 2014, \u201cWe Experiment on Humans!\u201d,\nOkTrends, 28 July 2014.\n [<a href=\"https://web.archive.org/web/20140801010636/http://blog.okcupid.com/index.php/we-experiment-on-human-beings/\" target=\"other\">Rudder 2014 available online</a>]",
            "Sparks, Joel, 2002,\n <a href=\"https://history.nih.gov/display/history/Human+Subjects+Timeline\" target=\"other\">Timeline of Laws Related to the Protection of Human Subjects</a>,\n National Institutes of Health.",
            "Stone, Brad, 2009, \u201cFacebook Rolls Out New Privacy\nSettings\u201d, <em>New York Times</em>, 9 December 2009.\n [<a href=\"https://bits.blogs.nytimes.com/2009/12/09/facebook-rolls-out-new-privacy-settings/\" target=\"other\">Stone 2009 available online</a>]",
            "U.K. Data Archive, 2011, \u201cManaging and Sharing Data: Best\nPractices for Researchers\u201d.\n [<a href=\"https://ukdataservice.ac.uk/media/622417/managingsharing.pdf\" target=\"other\">UK Data Archive available online</a>]",
            "Williams, George, 2010,\n \u201c<a href=\"https://web.archive.org/web/20101110165848/http://chronicle.com/blogs/profhacker/the-ethics-of-amazons-mechanical-turk/23010\" target=\"other\">The Ethics of Amazon\u2019s Mechanical Turk</a>\u201d,\n ProfHacker Blog, The Chronicle of Higher Education, 1 March\n2010.",
            "Zimmer, Michael, 2009, \u201cFacebook\u2019s Privacy Upgrade is\na Downgrade for User Privacy\u201d, MichaelZimmer.Org.\n [<a href=\"http://michaelzimmer.org/2009/12/10/facebooks-privacy-upgrade-is-a-downgrade-for-user-privacy/\" target=\"other\">Zimmer 2009 available online</a>]",
            "Department of Health and Human Services, Code of Federal\nRegulations [C.F.R.], United States\n\n<ul class=\"hanging\">\n<a href=\"https://www.hhs.gov/ohrp/regulations-and-policy/regulations/45-cfr-46/\" target=\"other\">45 C.F.R. \u00a7 46, \u201cProtection of Human Subjects\u201d,</a>\n and in particular the Common Rule,\n <a href=\"https://www.ecfr.gov/cgi-bin/text-idx?SID=816f9365da32c2c218a0321077b7f4c2&amp;node=se45.1.46_1102\" target=\"other\">45 C.F.R. 46 Subpart A</a>\n<a href=\"https://www.law.cornell.edu/cfr/text/45/164.514\" target=\"other\">45 C.F.R. \u00a7 164.514, \u201cOther requirements relating to uses and disclosures of protected health information\u201d</a>\n</ul> ",
            "<a href=\"https://www.hhs.gov/ohrp/regulations-and-policy/regulations/45-cfr-46/\" target=\"other\">45 C.F.R. \u00a7 46, \u201cProtection of Human Subjects\u201d,</a>\n and in particular the Common Rule,\n <a href=\"https://www.ecfr.gov/cgi-bin/text-idx?SID=816f9365da32c2c218a0321077b7f4c2&amp;node=se45.1.46_1102\" target=\"other\">45 C.F.R. 46 Subpart A</a>",
            "<a href=\"https://www.law.cornell.edu/cfr/text/45/164.514\" target=\"other\">45 C.F.R. \u00a7 164.514, \u201cOther requirements relating to uses and disclosures of protected health information\u201d</a>",
            "[OHRP] U.S Department of Health and Human Services, 2008,\n\u201cOffice for Human Research Protections\u201d,\n [<a href=\"https://www.hhs.gov/ohrp/\" target=\"other\">Office for Human Research Protection</a>]",
            "<a href=\"http://videocast.nih.gov/pdf/ohrp_belmont_report.pdf\" target=\"other\">The Belmont Report: Ethical Principles and Guidelines for the Protection of Human Subjects of Research</a>",
            "<a href=\"http://answers.hhs.gov/ohrp/questions/7260\" target=\"other\">U.S. Department of Health and Human Services: Can an electronic signature be used to document consent on parental permission?</a>",
            "<a href=\"http://answers.hhs.gov/ohrp/questions/7247\" target=\"other\">U.S. Department of Health and Human Services: What are the basic elements of informed consent?</a>",
            "<a href=\"http://publications.gc.ca/pub?id=9.693924&amp;sl=0\" target=\"other\">Tri-Council Policy Statement: Ethical Conduct for Research Involving Humans</a>,\n Canada",
            "European Parliament and Council of European Union (2016)\nRegulation (EU) 2016/679. ... Data Protection Act 2018, c. 12\n [<a href=\"https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679&amp;from=EN\" target=\"other\">Data Protection Act 2018 available online</a>]",
            "<a href=\"https://www.counseling.org/resources/aca-code-of-ethics.pdf\" target=\"other\">American Counseling Association: Ethics and Professional Standards</a>,\n 2014 revision",
            "<a href=\"https://www.apa.org/science/leadership/bsa/internet/\" target=\"other\">American Psychological Association: Advisory Group on Conduction Research on the Internet</a>",
            "<a href=\"https://aoir.org/ethics/\" target=\"other\">Association of Internet Researchers Ethics Guidelines</a>",
            "<a href=\"http://journals.sagepub.com/home/jre\" target=\"other\">Journal of Empirical Research on Human Research Ethics</a>",
            "<a href=\"http://www.jmir.org/\" target=\"other\">Journal of Medical Internet Research</a>",
            "<a href=\"https://www.methodspace.com/\" target=\"other\">MethodSpace</a>,\n SAGE Publishing hosted.",
            "<a href=\"https://researchethicsblog.com/\" target=\"other\">Research Ethics Blog</a>,\n run by Nancy Walton.",
            "<a href=\"https://www.cddc.vt.edu/aoir/ethics/public/norway.pdf\" target=\"other\">Research Ethics Guidelines for Internet Research (pdf)</a>,\n The (Norwegian) National Committee for Research Ethics in the Social\nSciences and the Humanities, 2003.",
            "<a href=\"https://heatmap.forrestertools.com/\" target=\"other\">Forrester\u2019s Global Data Protection and Privacy Heatmap</a>",
            "<a href=\"https://www.cessda.org/\" target=\"other\">Council of European Social Science Data Archives (CESSDA)</a>",
            "<a href=\"https://ccnmtl.columbia.edu/projects/cire/pac/foundation/\" target=\"other\">Foundation Texts</a>\n of the learning module, <em>Current Issues in Research Ethics:\nPrivacy and Confidentiality</em>, Joyce Plaza and Ruth Fischbach,\nColumbia University, New York: Columbia Center for New Media Teaching\n&amp; Learning.",
            "<a href=\"https://www.aaas.org/resources/ethical-and-legal-aspects-human-subjects-research-cyberspace\" target=\"other\">Ethical and Legal Aspects of Human Subjects Research in Cyberspace</a>,\n American Association for the Advancement of Science."
        ],
        "listed_links": [
            {
                "https://epubs.stfc.ac.uk/work/54691": "Cloud and Web 2.0 Services for Supporting Research"
            },
            {
                "https://www.researchgate.net/publication/44298273_Using_Cloud_for_Research_A_Technical_Review": "X. Chen et al. 2010 available online"
            },
            {
                "https://www.caida.org/publications/papers/2012/menlo_report_actual_formatted/": "The Menlo Report: Ethical Principles Guiding Information and Communication Technology Research"
            },
            {
                "https://www.law.berkeley.edu/wp-content/uploads/2016/06/Californians.pdf": "Hoofnagle and King 2008 available online"
            },
            {
                "https://web.archive.org/web/20161221060957/http://archive.hhs.gov/ohrp/nhrpac/documents/dataltr.pdf": "Recommendations on Public Use Data Files"
            },
            {
                "https://oma.od.nih.gov/DMS/Documents/Privacy/Guide%20for%20Handling%20Sensitive%20Information%20at%20NIH.pdf": "Guide for Identifying and Handling Sensitive Information at the NIH"
            },
            {
                "https://grants.nih.gov/policy/humansubjects/coc.htm": "NIH 2021 available online"
            },
            {
                "https://web.archive.org/web/20140801010636/http://blog.okcupid.com/index.php/we-experiment-on-human-beings/": "Rudder 2014 available online"
            },
            {
                "https://history.nih.gov/display/history/Human+Subjects+Timeline": "Timeline of Laws Related to the Protection of Human Subjects"
            },
            {
                "https://bits.blogs.nytimes.com/2009/12/09/facebook-rolls-out-new-privacy-settings/": "Stone 2009 available online"
            },
            {
                "https://ukdataservice.ac.uk/media/622417/managingsharing.pdf": "UK Data Archive available online"
            },
            {
                "https://web.archive.org/web/20101110165848/http://chronicle.com/blogs/profhacker/the-ethics-of-amazons-mechanical-turk/23010": "The Ethics of Amazon\u2019s Mechanical Turk"
            },
            {
                "http://michaelzimmer.org/2009/12/10/facebooks-privacy-upgrade-is-a-downgrade-for-user-privacy/": "Zimmer 2009 available online"
            },
            {
                "https://www.hhs.gov/ohrp/regulations-and-policy/regulations/45-cfr-46/": "45 C.F.R. \u00a7 46, \u201cProtection of Human Subjects\u201d,"
            },
            {
                "https://www.ecfr.gov/cgi-bin/text-idx?SID=816f9365da32c2c218a0321077b7f4c2&node=se45.1.46_1102": "45 C.F.R. 46 Subpart A"
            },
            {
                "https://www.law.cornell.edu/cfr/text/45/164.514": "45 C.F.R. \u00a7 164.514, \u201cOther requirements relating to uses and disclosures of protected health information\u201d"
            },
            {
                "https://www.hhs.gov/ohrp/": "Office for Human Research Protection"
            },
            {
                "http://videocast.nih.gov/pdf/ohrp_belmont_report.pdf": "The Belmont Report: Ethical Principles and Guidelines for the Protection of Human Subjects of Research"
            },
            {
                "http://answers.hhs.gov/ohrp/questions/7260": "U.S. Department of Health and Human Services: Can an electronic signature be used to document consent on parental permission?"
            },
            {
                "http://answers.hhs.gov/ohrp/questions/7247": "U.S. Department of Health and Human Services: What are the basic elements of informed consent?"
            },
            {
                "http://publications.gc.ca/pub?id=9.693924&sl=0": "Tri-Council Policy Statement: Ethical Conduct for Research Involving Humans"
            },
            {
                "https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679&from=EN": "Data Protection Act 2018 available online"
            },
            {
                "https://www.counseling.org/resources/aca-code-of-ethics.pdf": "American Counseling Association: Ethics and Professional Standards"
            },
            {
                "https://www.apa.org/science/leadership/bsa/internet/": "American Psychological Association: Advisory Group on Conduction Research on the Internet"
            },
            {
                "https://aoir.org/ethics/": "Association of Internet Researchers Ethics Guidelines"
            },
            {
                "http://journals.sagepub.com/home/jre": "Journal of Empirical Research on Human Research Ethics"
            },
            {
                "http://www.jmir.org/": "Journal of Medical Internet Research"
            },
            {
                "https://www.methodspace.com/": "MethodSpace"
            },
            {
                "https://researchethicsblog.com/": "Research Ethics Blog"
            },
            {
                "https://www.cddc.vt.edu/aoir/ethics/public/norway.pdf": "Research Ethics Guidelines for Internet Research (pdf)"
            },
            {
                "https://heatmap.forrestertools.com/": "Forrester\u2019s Global Data Protection and Privacy Heatmap"
            },
            {
                "https://www.cessda.org/": "Council of European Social Science Data Archives (CESSDA)"
            },
            {
                "https://ccnmtl.columbia.edu/projects/cire/pac/foundation/": "Foundation Texts"
            },
            {
                "https://www.aaas.org/resources/ethical-and-legal-aspects-human-subjects-research-cyberspace": "Ethical and Legal Aspects of Human Subjects Research in Cyberspace"
            }
        ]
    }
}