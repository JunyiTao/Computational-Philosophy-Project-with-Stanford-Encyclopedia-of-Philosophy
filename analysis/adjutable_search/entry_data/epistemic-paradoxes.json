{
    "url": "epistemic-paradoxes",
    "title": "Epistemic Paradoxes",
    "authorship": {
        "year": "Copyright \u00a9 2022",
        "author_text": "Roy Sorensen\n<roy.sorensen@austin.utexas.edu>",
        "author_links": [
            {
                "mailto:roy%2esorensen%40austin%2eutexas%2eedu": "roy.sorensen@austin.utexas.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2022</a> by\n\n<br/>\nRoy Sorensen\n&lt;<a href=\"mailto:roy%2esorensen%40austin%2eutexas%2eedu\"><em>roy<abbr title=\" dot \">.</abbr>sorensen<abbr title=\" at \">@</abbr>austin<abbr title=\" dot \">.</abbr>utexas<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Wed Jun 21, 2006",
        "substantive revision Thu Mar 3, 2022"
    ],
    "preamble": "\n\nEpistemic paradoxes are riddles that turn on the concept of knowledge\n(episteme is Greek for knowledge). Typically, there are\nconflicting, well-credentialed answers to these questions (or\npseudo-questions). Thus the riddle immediately poses an inconsistency.\nIn the long run, the riddle goads and guides us into correcting at\nleast one deep error \u2013 if not directly about knowledge, then\nabout its kindred concepts such as justification, rational belief, and\nevidence.\n\nSuch corrections are of interest to epistemologists. Historians date\nthe origin of epistemology to the appearance of skeptics. As manifest\nin Plato\u2019s dialogues featuring Socrates, epistemic paradoxes\nhave been discussed for twenty five hundred years. Given their\nhardiness, some of these riddles about knowledge may well be discussed\nfor the next twenty five hundred years.\n",
    "toc": [
        {
            "#SurTesPar": "1. The Surprise Test Paradox"
        },
        {
            "#SelDefProPraPar": "1.1 Self-defeating prophecies and pragmatic paradoxes"
        },
        {
            "#PreDet": "1.2 Predictive determinism"
        },
        {
            "#ProFor": "1.3 The Problem of Foreknowledge"
        },
        {
            "#IntSui": "2. Intellectual suicide"
        },
        {
            "#LotLotPar": "3. Lotteries and the Lottery Paradox"
        },
        {
            "#PrePar": "4. Preface Paradox"
        },
        {
            "#AntExp": "5. Anti-expertise"
        },
        {
            "#KnoPar": "5.1 The Knower Paradox"
        },
        {
            "#KnowPar": "5.2 The \u201cKnowability Paradox\u201d"
        },
        {
            "#MooPro": "5.3 Moore\u2019s problem"
        },
        {
            "#Bli": "5.4 Blindspots"
        },
        {
            "#DynEpiPar": "6. Dynamic Epistemic Paradoxes"
        },
        {
            "#MenParInqPuzAboGaiKno": "6.1 Meno\u2019s Paradox of Inquiry: A puzzle about gaining knowledge"
        },
        {
            "#DogParPuzAboLosKno": "6.2 Dogmatism paradox: A puzzle about losing knowledge"
        },
        {
            "#FutEpiPar": "6.3 The Future of Epistemic Paradoxes"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. The Surprise Test Paradox\n\nA teacher announces that there will be a surprise test next week. It\nwill be a surprise in that the students will not be able to know in\nadvance on which day the exam will be given. A student objects that\nthis is impossible: \u201cThe class meets on Monday, Wednesday, and\nFriday. If the test is given on Friday, then on Thursday I would be\nable to predict that the test is on Friday. It would not be a\nsurprise. Can the test be given on Wednesday? No, because on Tuesday I\nwould know that the test will not be on Friday (thanks to the previous\nreasoning) and know that the test was not on Monday (thanks to\nmemory). Therefore, on Tuesday I could foresee that the test will be\non Wednesday. A test on Wednesday would not be a surprise. Could the\nsurprise test be on Monday? On Sunday, the previous two eliminations\nwould be available to me. Consequently, I would know that the test\nmust be on Monday. So a Monday test would also fail to be a surprise.\nTherefore, it is impossible for there to be a surprise\ntest.\u201d\n\nCan the teacher fulfill her announcement? We have an embarrassment of\nriches. On the one hand, we have the student\u2019s elimination\nargument. (For a formalization, see Holliday 2017.) On the other hand,\ncommon sense says that surprise tests are possible even when we have\nhad advance warning that one will occur at some point. Either of the\nanswers would be decisive were it not for the credentials of the rival\nanswer. Thus we have a paradox. But a paradox of what kind?\n\u2018Surprise test\u2019 is being defined in terms of what can be\nknown. Specifically, a test is a surprise if and only if the student\ncannot know beforehand which day the test will occur.\nTherefore the riddle of the surprise test qualifies as an\nepistemic paradox.\n\nParadoxes are more than edifying surprises. Here is an\nedifying surprise that does not pose a paradox. Professor Statistics\nannounces she will give random quizzes: \u201cClass meets every day\nof the week. Each day I will open by rolling a die. When the roll\nyields a six, I will immediately give a quiz.\u201d Today, Monday, a\nsix came up. So you are taking a quiz. The last question of her quiz\nis: \u201cWhich of the subsequent days is most likely to be the day\nof the next random test?\u201d Most people answer that each of the\nsubsequent days has the same probability of being the next quiz. But\nthe correct answer is: Tomorrow (Tuesday).\n\nUncontroversial facts about probability reveal the mistake and\nestablish the correct answer. For the next test to be on Wednesday,\nthere would have to be a conjunction of two events: no test\non Tuesday (a 5/6 chance of that) and a test on Wednesday (a\n1/6 chance). The probability for each subsequent day becomes less and\nless. (It would be astounding if the next quiz day were a hundred days\nfrom now!) The question is not whether a six will be rolled on any\ngiven day, but when the next six will be rolled. Which day is\nthe next one depends partly on what happens meanwhile, as well as\ndepending partly on the roll of the die on that day.\n\nThis probability riddle is instructive and will be referenced\nthroughout this entry. But the existence of quick, decisive solution\nshows that only a mild revision of our prior beliefs was needed. In\ncontrast, when our deep beliefs conflict, proposed amendments\nreverberate unpredictably. Attempts to throw away a deep belief\nboomerang. For the malfunctions that ensue from distancing ourselves\nfrom the belief demonstrate its centrality. Often, the belief winds up\neven more entrenched. \u201cProblems worthy of attack prove their\nworth by fighting back\u201d (Hein 1966).\n\nOne sign of depth (or at least desperation) is that commentators begin\nrejecting highly credible inference rules. The surprise test has been\nclaimed to invalidate the law of bivalence, the KK principle (if one\nis in a position to know that \\(p\\), then one is also in\na position to know that one knows that \\(p\\)), and the\nclosure principle (if one knows \\(p\\) while also competently deducing q\nfrom \\(p\\), one knows \\(q\\)) (Immerman 2017).\n\nThe surprise test paradox also has ties to issues that are not clearly\nparadoxes \u2013 or to issues whose status as paradoxes is at least\ncontested. Consider the Monty Hall problem. There is a prize behind\nexactly one of three doors. After you pick, Monty Hall will reveal\nwhat is behind one of the doors that lacks the prize. He will then\ngive you an option to switch your choice to another closed door.\nShould you switch to have the best chance to win the prize? When Marylin vos Savant answered yes in a 1990\nParade magazine she was mistakenly scolded by many readers\n\u2014 including some scholars. The correct solution was provided by\nthe original poser of the puzzle decades earlier and was never\nforgotten or effectively criticized. \n\nWhat makes the Monty Hall Problem interesting is that it is not\na paradox. There has always been expert consensus on its\nsolution. Yet it has many of the psychological and sociological features\nof a paradox. The Monty Hall Problem is merely a cognitive\nillusion. Paradox status is also withheld by those who find only\nirony in self-defeating predictions and only an\nembarrassment in the \u201cknowability paradox\u201d\n(discussed below). Calling a problem a \u2018paradox\u2019 tends to quarantine\nit from the rest of our inquiries. Those who wish to rely on the\nsurprising result will therefore deny that there is any paradox. At\nmost, they concede there was a paradox. Dead paradoxes are\nbenign fertilizer for the tree of knowledge.\n\nWe can look forward to future philosophers drawing edifying historical\nconnections. The backward elimination argument underlying the surprise\ntest paradox can be discerned in German folktales dating back to 1756\n(Sorensen 2003a, 267). Perhaps, medieval scholars explored these\nslippery slopes. But let us turn to commentary to which we presently\nhave access.\n1.1 Self-defeating prophecies and pragmatic paradoxes\n\nIn the twentieth century, the first published reaction to the surprise\ntext paradox was to endorse the student\u2019s elimination argument.\nD. J. O\u2019Connor (1948) regarded the teacher\u2019s announcement\nas self-defeating. If the teacher had not announced that there would\nbe a surprise test, the teacher would have been able to give the\nsurprise test. The pedagogical moral of the paradox would then be that\nif you want to give a surprise test do not announce your intention to\nyour students!\n\nMore precisely, O\u2019Connor compared the teacher\u2019s\nannouncement to utterances such as \u2018I am not speaking\nnow\u2019. Although these utterances are consistent, they\n\u201ccould not conceivably be true in any circumstances\u201d\n(O\u2019Connor 1948, 358). L. Jonathan Cohen (1950) agreed and\nclassified the announcement as a pragmatic paradox. He defined a\npragmatic paradox to be a statement that is falsified by its own\nutterance. The teacher overlooked how the manner in which a statement\nis disseminated can doom it to falsehood.\n\nCohen\u2019s classification is too monolithic. True, the\nteacher\u2019s announcement does compromise one aspect of the\nsurprise: Students now know that there will be a test. But this\ncompromise is not itself enough to make the announcement\nself-falsifying. The existence of a surprise test has been\nrevealed but that allows surviving uncertainty as to which\nday the test will occur. The announcement of a forthcoming surprise\naims at changing uninformed ignorance into action-guiding awareness of\nignorance. A student who misses the announcement does not realize that\nthere is a test. If no one passes on the news about the surprise test,\nthe student with simple ignorance will be less prepared than\nclassmates who know they do not know the day of the test.\n\nAnnouncements are made to serve different goals simultaneously.\nCompetition between accuracy and helpfulness makes it possible for an\nannouncement to be self-fulfilling by being self-defeating. Consider a\nweatherman who warns \u2018The midnight tsunami will cause fatalities\nalong the shore\u2019. Because of the warning, spectacle-seekers make\na special trip to witness the wave. Some drown. The weatherman\u2019s\nannouncement succeeds as a prediction by backfiring as a warning.\n1.2 Predictive determinism\n\nInstead of viewing self-defeating predictions as showing how the\nteacher is refuted, some philosophers construe self-defeating\npredictions as showing how the student is refuted. The\nstudent\u2019s elimination argument embodies hypothetical predictions\nabout which day the teacher will give a test. Isn\u2019t the student\noverlooking the teacher\u2019s ability and desire to thwart those\nexpectations? Some game theorists suggest that the teacher could\ndefeat this strategy by choosing the test date at random.\n\nStudents can certainly be kept uncertain if the teacher is willing to\nbe faithfully random. She will need to prepare a quiz each day. She\nwill need to brace for the possibility that she will give too many\nquizzes or too few or have an unrepresentative distribution of\nquizzes.\n\nIf the instructor finds these costs onerous, then she may be tempted\nby an alternative: at the beginning of the week, randomly select a\nsingle day. Keep the identity of that day secret. Since the student\nwill only know that the quiz is on some day or other, pupils will not\nbe able to predict the day of the quiz.\n\nThis plan is risky. If, through the chance process, the last day\nhappens to be selected, then abiding by the outcome means giving an\nunsurprising test. For as in the original scenario, the student has\nknowledge of the teacher\u2019s announcement and awareness of past\ntestless days. So the teacher must exclude random selection of the\nlast day. The student is astute. He will replicate this reasoning that\nexcludes a test on the last day. Can the teacher abide by the random\nselection of the next to last day? Now the reasoning becomes all too\nfamiliar.\n\nAnother critique of the student\u2019s replication of the\nteacher\u2019s reasoning adapts a thought experiment from Michael\nScriven (1964). To refute predictive determinism (the thesis that all\nevents are foreseeable), Scriven conjures an agent\n\u201cPredictor\u201d who has all the data, laws, and calculating\ncapacity needed to predict the choices of others. Scriven goes on to\nimagine, \u201cAvoider\u201d, whose dominant motivation is to avoid\nprediction. Therefore, Predictor must conceal his prediction. The\ncatch is that Avoider has access to the same data, laws, and\ncalculating capacity as Predictor. Thus Avoider can duplicate\nPredictor\u2019s reasoning. Consequently, the optimal predictor\ncannot predict Avoider. Let the teacher be Avoider and the student be\nPredictor. Avoider must win. Therefore, it is possible to give a\nsurprise test.\n\nScriven\u2019s original argument assumes that Predictor and Avoider\ncan simultaneously have all the needed data, laws, and calculating\ncapacity. David Lewis and Jane Richardson object:\n\n\u2026 the amount of calculation required to let the predictor\nfinish his prediction depends on the amount of calculation done by the\navoider, and the amount required to let the avoider finish duplicating\nthe predictor\u2019s calculation depends on the amount done by the\npredictor. Scriven takes for granted that the requirement-functions\nare compatible: i.e., that there is some pair of amounts of\ncalculation available to the predictor and the avoider such that each\nhas enough to finish, given the amount the other has. (Lewis and\nRichardson 1966, 70\u201371)\n\n\nAccording to Lewis and Richardson, Scriven equivocates on \u2018Both\nPredictor and Avoider have enough time to finish their\ncalculations\u2019. Reading the sentence one way yields a truth:\nagainst any given avoider, Predictor can finish and against any given\npredictor, Avoider can finish. However, the compatibility premise\nrequires the false reading in which Predictor and Avoider can finish\nagainst each other.\n\nIdealizing the teacher and student along the lines of Avoider and\nPredictor would fail to disarm the student\u2019s elimination\nargument. We would have merely formulated a riddle that falsely\npresupposes that the two types of agent are co-possible. It would be\nlike asking \u2018If Bill is smarter than anyone else and Hillary is\nsmarter than anyone else, which of the two is the\nsmartest?\u2019.\n\nPredictive determinism states that everything is foreseeable.\nMetaphysical determinism states that there is only one way the future\ncould be given the way the past is. Simon Laplace used metaphysical\ndeterminism as a premise for predictive determinism. He reasoned that\nsince every event has a cause, a complete description of any stage of\nhistory combined with the laws of nature implies what happens at any\nother stage of the universe. Scriven was only challenging predictive\ndeterminism in his thought experiment. The next approach challenges\nmetaphysical determinism.\n1.3 The Problem of Foreknowledge\n\nPrior knowledge of an action seems incompatible with it being a free\naction. If I know that you will finish reading this article tomorrow,\nthen you will finish tomorrow (because knowledge implies truth). But\nthat means you will finish the article even if you resolve not to.\nAfter all, given that you will finish, nothing can stop you from\nfinishing. So if I know that you will finish reading this article\ntomorrow, you are not free to do otherwise.\n\nMaybe all of your reading is compulsory. If God exists, then He knows\neverything. So the threat to freedom becomes total for the theist. The\nproblem of divine foreknowledge raises the possibility that theism\n(rather than atheism) precludes free choice and thereby precludes our having any moral responsibility.\n\nIn response to the apparent conflict between freedom and\nforeknowledge, medieval philosophers denied that future contingent\npropositions have a truth-value. They took themselves to be extending\na solution Aristotle discusses in De Interpretatione to the\nproblem of logical fatalism. According to this truth-value gap\napproach, \u2018You will finish this article tomorrow\u2019 is not\ntrue now. The prediction will become true tomorrow.\nA morally serious theist can agree with the Rubaiyat of Omar\nKhayyam:\n\nThe Moving Finger writes; and, having writ,\n\nMoves on: nor all your Piety nor Wit\n\nShall lure it back to cancel half a Line,\n\nNor all your Tears wash out a Word of it.\n\n\nGod\u2019s omniscience only requires that He knows every true\nproposition. God will know \u2018You will finish this article\ntomorrow\u2019 as soon it becomes true \u2013 but not before.\n\nThe teacher has freewill. Therefore, predictions about what he will do\nare not true (prior to the examination). The metaphysician Paul Weiss\n(1952) concludes that the student\u2019s argument falsely assumes he\nknows that the announcement is true. The student can know that the\nannouncement is true after it becomes true \u2013 but not\nbefore.\n\nThe logician W. V. O. Quine (1953) agrees with Weiss\u2019 conclusion\nthat the teacher\u2019s announcement of a surprise test fails to give\nthe student knowledge that there will be a surprise test. Yet Quine\nabominates Weiss\u2019 reasoning. Weiss breeches the law of bivalence\n(which states that every proposition has a truth-value, true or\nfalse). Quine believes that the riddle of the surprise test should not\nbe answered by surrendering classical logic.\n2. Intellectual suicide\n\nQuine insists that the student\u2019s elimination argument is only a\nreductio ad absurdum of the supposition that the student\nknows that the announcement is true (rather than a\nreductio of the announcement itself). He accepts this\nepistemic reductio but rejects the metaphysical\nreductio. Given the student\u2019s ignorance of the\nannouncement, Quine concludes that a test on any day would be\nunforeseen. That is, Quine accepts that the student has no advance\nknowledge of the time of the test, but he rejects that there is no\ntruth in advance as to when the test will be given.\n\nCommon sense suggests that the students are informed by the\nannouncement. The teacher is assuming that the announcement will\nenlighten the students. She seems right to assume that the\nannouncement of this intention produces the same sort of knowledge as\nher other declarations of intentions (about which topics will be\nselected for lecture, the grading scale, and so on).\n\nThere are skeptical premises that could yield Quine\u2019s conclusion\nthat the students do not know the announcement is true. If no one can\nknow anything about the future, as alleged by David Hume\u2019s\nproblem of induction, then the student cannot know that the\nteacher\u2019s announcement is true. (See the entry on\n the problem of induction.)\n But denying all knowledge of the future in order to deny the\nstudent\u2019s knowledge of the teacher\u2019s announcement is\ndisproportionate and indiscriminate. Do not kill a fly with cannon \u2014\nunless it is killer fly and only a cannon will work!\n\nIn later writings, Quine evinces general reservations about the\nconcept of knowledge. One of his favorite objections is that\n\u2018know\u2019 is vague. If knowledge entails certainty, then too\nlittle will count as known. Quine infers that we must equate knowledge\nwith firmly held true belief. Asking just how firm that belief must be\nis akin to asking just how big something has to be to count as being\nbig. There is no answer to the question because \u2018big\u2019\nlacks the sort of boundary enjoyed by precise words.\n\nThere is no place in science for bigness, because of this lack of\nboundary; but there is a place for the relation of biggerness. Here we\nsee the familiar and widely applicable rectification of vagueness:\ndisclaim the vague positive and cleave to the precise comparative. But\nit is inapplicable to the verb \u2018know\u2019, even grammatically.\nVerbs have no comparative and superlative inflections \u2026 . I\nthink that for scientific or philosophical purposes the best we can do\nis give up the notion of knowledge as a bad job and make do rather\nwith its separate ingredients. We can still speak of a belief as true,\nand of one belief as firmer or more certain, to the believer\u2019s\nmind, than another (1987, 109).\n\n\nQuine is alluding to Rudolf Carnap\u2019s (1950) generalization that\nscientists replace qualitative terms (tall) with comparatives\n(taller than) and then replace the comparatives with\nquantitative terms (being n millimeters in height).\n\nIt is true that some borderline cases of a qualitative term are not\nborderline cases for the corresponding comparative. But the reverse\nholds as well. A tall man who stoops may stand less high than another\ntall man who is not as lengthy but better postured. Both men are\nclearly tall. It is unclear that \u2018The lengthier man is\ntaller\u2019. Qualitative terms can be applied when a vague quota is\nsatisfied without the need to sort out the details. Only comparative\nterms are bedeviled by tie-breaking issues.\n\nScience is about what is the case rather than what ought to be case.\nThis seems to imply that science does not tell us what we ought to\nbelieve. The traditional way to fill the normative gap is to delegate\nissues of justification to epistemologists. However, Quine is\nuncomfortable with delegating such authority to philosophers. He\nprefers the thesis that psychology is enough to handle the issues\ntraditionally addressed by epistemologists (or at least the issues\nstill worth addressing in an Age of Science). This \u201cnaturalistic\nepistemology\u201d seems to imply that \u2018know\u2019 and\n\u2018justified\u2019 are antiquated terms \u2013 as empty as\n\u2018phlogiston\u2019 or \u2018soul\u2019.\n\nThose willing to abandon the concept of knowledge can dissolve the\nsurprise test paradox. But to epistemologists who find promise in less\ndrastic responses this is like using a suicide bomb to kill a fly.\n\nOur suicide bomber may protest that the flies have been undercounted.\nEpistemic eliminativism dissolves all epistemic paradoxes.\nAccording to the eliminativist, epistemic paradoxes are symptoms of a\nproblem with the very concept of knowledge.\n\nNotice that the eliminativist is more radical than the skeptic. The\nskeptic thinks the concept of knowledge is coherent and definite in\nits requirements. We just fall short of being knowers. The skeptic\ntreats \u2018No man is a knower\u2019 like \u2018No man is an\nimmortal\u2019. There is nothing wrong with the concept of\nimmortality. Biology just winds up guaranteeing that every man falls\nshort of being immortal. Universal absence of knowledge would be\nshocking. But the potential to shock us should not lead us to kill the\nmessenger (the skeptic) or declare unintelligible the vocabulary\ncomprising the message (specifically, the word\n\u2018know\u2019).\n\nUnlike the messenger telling us \u2018No man is an immortal\u2019,\nthe skeptic has trouble telling us, \u2018There is no\nknowledge\u2019. According to Sextus Empiricus, assertion expresses\nbelief that one knows what is asserted (Outlines of\nPyrrhonism, I., 3, 226). He condemns the assertion\n\u2018There is no knowledge\u2019 (though not the proposition\nexpressed by the assertion) as dogmatic skepticism. Sextus\nprefers agnosticism about knowledge rather than skepticism (considered\nas \u201catheism\u201d about knowledge). Yet it is just as\ninconsistent to assert \u2018No one can know whether anything is\nknown\u2019. For that conveys the belief that one knows that no one\ncan know whether anything is known.\n\nThe eliminativist has even more severe difficulties in stating his\nposition than the skeptic. Some eliminativists dismiss the threat of\nself-defeat by drawing an analogy. Those who denied the existence of\nsouls were accused of undermining a necessary condition for asserting\nanything. However, the soul theorist\u2019s account of what is needed\ngives no reason to deny that a healthy brain suffices for mental\nstates.\n\nIf the eliminativist thinks that assertion only imposes the aim of\nexpressing a truth, then he can consistently assert that\n\u2018know\u2019 is a defective term. However, an epistemologist can\nrevive the charge of self-defeat by showing that assertion does indeed\nrequire the speaker to attribute knowledge to himself. This\nknowledge-based account of assertion has recently been supported by\nwork on our next paradox.\n3. Lotteries and the Lottery Paradox\n\nLotteries pose a problem for the theory that a high probability for a\ntrue belief suffices for knowledge. Given that there are a million\ntickets and only one winner, the probability of \u2018This ticket is\na losing ticket\u2019 is very high. Yet we are reluctant to say this\nmakes the proposition known.\n\nWe overcome the inhibition after the winning ticket is announced. Now\nthe ticket is known to be a loser and tossed in the trash. But wait!\nTestimony does not furnish certainty. Nor does perception or\nrecollection . When pressed, we admit there is a small chance that we\nmisperceived the drawing or that the newscaster misread the winning\nnumber or that we are misremembering. While in this concessive mood,\nwe are apt to relinquish our claim to know. The skeptic syllogizes\nfrom this surrender: For any contingent proposition, there is a\nlottery statement that is more probable and which is unknown. A known\nproposition cannot be less probable than an unknown proposition. So no\ncontingent proposition is known (Hawthorne 2004). That is too\nmuch to give up! Yet the skeptic\u2019s statistics seem impeccable.\n\nThis skeptical paradox was noticed by Gilbert Harman (1968, 166). But\nhis views about the role of causation in inferential knowledge seemed\nto solve the problem (DeRose 2017, chapter 5). The baby paradox was\ndismissed as stillborn. Since the new arrival did not get the\ncustomary baptism of attention, epistemologists did not notice that\nthe demise of the causal theory of knowledge meant new life for\nHarman\u2019s lottery paradox.\n\nThe probability skeptic\u2019s ordinary suggestions about how we\nmight be mistaken contrast with the extraordinary possibilities\nconjured by Ren\u00e9 Descartes\u2019 skeptic. The Cartesian\nskeptic tries to undermine vast swaths of knowledge with a single\nuntestable counter-explanation of the evidence (such as the hypothesis\nthat you are dreaming or the hypothesis that an evil demon is\ndeceiving you). These comprehensive alternatives are designed to evade\nany empirical refutation. The probabilistic skeptic, in contrast,\npoints to a plethora of pedestrian counter-explanations. Each is easy\nto test: maybe you transposed the digits of a phone number, maybe the\nticket agent thought you wanted to fly to Moscow, Russia rather than\nMoscow, Idaho, etc. You can check for errors, but any check itself has\na small chance of being wrong. So there is always something to check,\ngiven that the issues cannot be ignored on grounds of\nimprobability.\n\nYou can check any of these possible errors but you cannot\ncheck them all. You cannot discount these pedestrian\npossibilities as science fiction. These are exactly the sorts of\npossibilities we check when plans go awry. For instance, you think you\nknow that you have an appointment to meet a prospective employer for\nlunch at noon. When she fails to show at the expected time, you\nbackpedal through your premises: Is your watch slow? Are you\nremembering the right restaurant? Could there be another restaurant in\nthe city with the same name? Is she just detained? Could she have just\nforgotten? Could there have been a miscommunication?\n\nProbabilistic skepticism dates back to Arcesilaus who took over the\nAcademy two generations after Plato\u2019s death. This moderate kind\nof skepticism, recounted by Cicero (Academica 2.74, 1.46)\nfrom his days as a student at the Academy, allows for justified\nbelief. Many scientists feel they should only assign probabilities.\nThey dismiss the epistemologist\u2019s preoccupation with knowledge\nas old-fashioned.\n\nDespite the early start of the qualitative theory of probability, the\nquantitative theory did not develop until Blaise Pascal\u2019s study\nof gambling in the seventeenth century (Hacking 1975). Only in the\neighteenth century did it penetrate the insurance industry (even\nthough insurers realized that a fortune could be made by accurately\ncalculating risk). Only in the nineteenth century did probability make\na mark in physics. And only in the twentieth century do probabilists\nmake important advances over Arcesilaus.\n\nMost of these philosophical advances are reactions to the use of\nprobability by scientists. In the twentieth century, editors of\nscience journals began to demand that the author\u2019s hypothesis\nshould be accepted only when it was sufficiently probable \u2013 as\nmeasured by statistical tests. The threshold for acceptance was\nacknowledged to be somewhat arbitrary. And it was also conceded that\nthe acceptance rule might vary with one\u2019s purposes. For\ninstance, we demand a higher probability when the cost of accepting a\nfalse hypothesis is high.\n\nIn 1961 Henry Kyburg pointed out that this policy conflicted with a\nprinciple of agglomeration: If you rationally believe \\(p\\)\nand rationally believe \\(q\\) then you\nrationally believe both \\(p\\) and \\(q\\).\nLittle pictures of the same scene should sum to a bigger picture of\nthe same scene. If rational belief can be based on an acceptance rule\nthat only requires a high probability, there will be rational belief\nin a contradiction! To see why, suppose the acceptance rule permits\nbelief in any proposition that has a probability of at least .99.\nGiven a lottery with 100 tickets and exactly one winner, the\nprobability of \u2018Ticket \\(n\\) is a loser\u2019\nlicenses belief. Symbolize propositions about ticket \\(n\\)\nbeing a loser as \\(p_n\\). Symbolize \u2018I\nrationally believe\u2019 as \\(B\\). Belief in a\ncontradiction follows:\n\n\\(B{\\sim}(p_1 \\amp p_2 \\amp \\ldots \\amp p_{100})\\),\n\nby the probabilistic acceptance rule.\n\\(Bp_1 \\amp Bp_2 \\amp \\ldots \\amp Bp_{100}\\),\n\nby the probabilistic acceptance rule.\n\\(B(p_1 \\amp p_2 \\amp \\ldots \\amp p_{100})\\),\n\nfrom (2) and the principle that rational belief agglomerates.\n\\(B[(p_1 \\amp p_2 \\amp \\ldots \\amp p_{100}) \\amp{\\sim}(p_1 \\amp\np_2 \\amp \\ldots \\amp p_{100})]\\),\n\nfrom (1) and (3) by the principle that rational belief\nagglomerates.\n\n\nMore informally, the acceptance rule implies this: each belief that a particular ticket will lose is probable enough to justify believing it. By repeated\napplications of the agglomeration principle, conjoining all of these\njustified beliefs together gives a justified belief. Finally,\nconjoining that belief with the justified belief that one of tickets\nis a winner gives the contradictory belief to the to the effect that\neach will lose and one will win. Yet by agglomeration that too is\njustified.\n\nSince belief in an obvious contradiction is a paradigm example of\nirrationality, Kyburg poses a dilemma: either reject agglomeration or\nreject rules that license belief for a probability of less than one.\n(Martin Smith 2016, 186\u2013196) warns that even a probability of\none leads to joint inconsistency for a lottery that has infinitely\nmany tickets.) Kyburg rejects agglomeration. He promotes toleration of\njoint inconsistency (having beliefs that cannot all be true\ntogether) to avoid belief in contradictions. Reason forbids us from\nbelieving a proposition that is necessarily false but permits us to\nhave a set of beliefs that necessarily contains a falsehood. Henry\nKyburg\u2019s choice was soon supported by the discovery of a\ncompanion paradox.\n4. Preface Paradox\n\nIn the preface of Introduction to the Foundations of\nMathematics, Raymond Wilder (1952, iv) apologizes for the errors\nin the text. The 1982 reprint has three pages of errata that vindicate\nWilder\u2019s humility. D. C. Makinson (1965, 205) quotes Wilder\u2019s\n1952 apology and extracts a paradox: Wilder rationally believes each\nof the assertions in his book. But since Wilder regards himself as\nfallible, he rationally believes the conjunction of all his assertions\nis false. If the agglomeration principle holds, \\((Bp \\amp Bq)\n\\rightarrow B(p \\amp q)\\), Wilder would rationally believe the\nconjunction of all assertions in his book and also rationally\ndisbelieve the same thing!\n\nThe preface paradox does not rely on a probabilistic acceptance rule.\nThe preface belief is organically generated in a qualitative fashion.\nThe author is merely reflecting on his humbling resemblance to other\nauthors who are fallible, his own past failing that he subsequently\ndiscovered, his imperfection in fact checking, and so on.\n\nAt this juncture many philosophers join Kyburg in rejecting\nagglomeration and conclude that it can be rational to have jointly\ninconsistent beliefs. Kyburg\u2019s solution to the preface paradox\nraises a methodological question about the nature of paradox. How can\nparadoxes change our minds if joint inconsistency is permitted? A\nparadox is commonly defined as a set of propositions that are\nindividually plausible but jointly inconsistent. The inconsistency is\nthe itch that directs us to scratch out a member of the set (or the\npain that leads us to withdraw from the stimulus). For instance, much\nepistemology orbits an ancient riddle posed by the regress of\njustification, namely, which of the following is false?\n\nA belief can only be justified by another justified belief.\nThere are no circular chains of justification.\nAll justificatory chains have a finite length.\nSome beliefs are justified.\n\n\nFoundationalists reject (1). They take some propositions to be\nself-evident or they permit beliefs to be justified by non-beliefs (such as perceptions or intuitions).\nCoherentists reject (2). They tolerate some forms of circular\nreasoning. For instance, Nelson Goodman (1965) has characterized the\nmethod of reflective equilibrium as virtuously circular.\nCharles Saunders Peirce (1933\u201335, 5.250) may have rejected (3).\nThe first clear rejector is Peter Klein (2007). For a book-length\ndefense, read Scott F. Aikin (2011). Infinitists believe that\ninfinitely long chains of justification are no more impossible than\ninfinitely long chains of causation. Finally, the epistemological\nanarchist rejects (4). As Paul Feyerabend refrains in Against\nMethod, \u201cAnything goes\u201d (1988, vii, 5, 14, 19,\n159).\n\nFormulating a paradox as a set of individually plausible but jointly\ninconsistent beliefs is a feat of data compression. But if joint\ninconsistency is rationally tolerable, why do these philosophers\nbother to offer solutions to paradoxes such as the regress of\njustification? Why is it irrational to believe each of (1)\u2013(4),\ndespite their joint inconsistency?\n\nKyburg might answer that there is a scale effect. Although the\nsensation of joint inconsistency is tolerable when diffusely\ndistributed over a large body of propositions, the sensation becomes\nan itch when the inconsistency localizes (Knight 2002). That is why\nparadoxes are always represented as a small set of\npropositions. A paradox is improved by reducing its membership \u2014\nas when a member of the set is exposed as superfluous to the\ninconsistency. (Strictly speaking, a set can only change size in the\nmetaphorical way that a number grows or shrinks.)\n\nIf you know that your beliefs are jointly inconsistent but deny this\nmakes for a giant paradox, then you should reject R. M.\nSainsbury\u2019s definition of a paradox as \u201can apparently\nunacceptable conclusion derived by apparently acceptable reasoning\nfrom apparently acceptable premises\u201d (1995, 1). Take the\nnegation of any of your beliefs as a conclusion and your remaining\nbeliefs as the premises. You should judge this jumble argument as\nvalid, and as having premises that you accept, and yet as having a\nconclusion you reject (Sorensen 2003b, 104\u2013110). If the\nconclusion of this argument counts as a paradox, then the negation of\nany of your beliefs counts as a paradox.\n\nThe resemblance between the preface paradox and the surprise test\nparadox becomes more visible through an intermediate case. The preface\nof Siddhartha Mukherjee\u2019s The Emperor of All Maladies: A\nBiography of Cancer warns: \u201cIn cases where there was no\nprior public knowledge, or when interviewees requested privacy, I have\nused a false name, and deliberately confounded identities to make it\ndifficult to track.\u201d (2010, xiv) Those who refuse consent to be\nlied to are free to close Doctor Mukherjee\u2019s chronicle. But\nnearly all readers think the physician\u2019s trade-off between lies\nand new information is acceptable. They rationally anticipate being\nrationally misled. Nevertheless, these readers learn much about the\nhistory of cancer. Similarly, students who are warned that they will\nreceive a surprise test rationally expect to be rationally misled\nabout the day of the test. The prospect of being misled does not lead\nthem to drop the course.\n\nThe preface paradox pressures Kyburg to extend his tolerance of joint\ninconsistency to the acceptance of contradictions. For\nMakinson\u2019s original specimen is a logician\u2019s regret at\naffirming contradictions rather than false contingent\nstatements. Consider a logic student who is required to pick one\nhundred truths from a mixed list of tautologies and contradictions\n(Sorensen 2001, 156\u2013158). Although the modest student believes\neach of his answers, \\(A_1, A_2, \\ldots, A_{100}\\), he also believes\nthat at least of one these answers is false. This ensures he believes\na contradiction. If any of his answers is false, then the student\nbelieves a contradiction (because the only falsehoods on the question\nlist are contradictions). If all of his test answers are true, then\nthe student believes the following contradiction: \\({\\sim}(A_1 \\amp\nA_2 \\amp \\ldots \\amp A_{100})\\). After all, a conjunction of\ntautologies is itself a tautology and the negation of any tautology is\na contradiction.\n\nIf paradoxes were always sets of propositions or arguments or\nconclusions, then they would always be meaningful. But some paradoxes\nare semantically flawed (Sorensen 2003b, 352) and some have answers\nthat are backed by a pseudo-argument employing a defective\n\u201clemma\u201d that lacks a truth-value. Kurt Grelling\u2019s\nparadox, for instance, opens with a distinction between autological\nand heterological words. An autological word describes itself, e.g.,\n\u2018polysyllabic\u2019 is polysllabic, \u2018English\u2019 is\nEnglish, \u2018noun\u2019 is a noun, etc. A heterological word does\nnot describe itself, e.g., \u2018monosyllabic\u2019 is not\nmonosyllabic, \u2018Chinese\u2019 is not Chinese, \u2018verb\u2019\nis not a verb, etc. Now for the riddle: Is \u2018heterological\u2019\nheterological or autological? If \u2018heterological\u2019 is\nheterological, then since it describes itself, it is autological. But\nif \u2018heterological\u2019 is autological, then since it is a word\nthat does not describe itself, it is heterological. The common\nsolution to this puzzle is that \u2018heterological\u2019, as\ndefined by Grelling, is not a well-defined predicate (Thomson 1962).\nIn other words, \u201cIs \u2018heterological\u2019\nheterological?\u201d is without meaning. There can be no predicate\nthat applies to all and only those predicates it does not apply to for\nthe same reason that there can be no barber who shaves all and only\nthose people who do not shave themselves.\n\nThe eliminativist, who thinks that \u2018know\u2019 or\n\u2018justified\u2019 is meaningless, will diagnose the epistemic\nparadoxes as questions that only appear to be well-formed.\nFor instance, the eliminativist about justification would not accept\nproposition (4) in the regress paradox: \u2018Some beliefs are\njustified\u2019. His point is not that no beliefs meet the high\nstandards for justification, as an anarchist might deny that any\nostensible authorities meet the high standards for legitimacy.\nInstead, the eliminativist unromantically diagnoses\n\u2018justified\u2019 as a pathological term. Just as the astronomer\nignores \u2018Are there a zillion stars?\u2019 on the grounds that\n\u2018zillion\u2019 is not a genuine numeral, the eliminativist\nignores \u2018Are some beliefs justified?\u2019 on the grounds that\n\u2018justified\u2019 is not a genuine adjective.\n\nIn the twentieth century, suspicions about conceptual pathology were\nstrongest for the liar paradox: Is \u2018This sentence is\nfalse\u2019 true? Philosophers who thought that there was something\ndeeply defective with the surprise test paradox assimilated it to the\nliar paradox. Let us review the assimilation process.\n5. Anti-expertise\n\nIn the surprise test paradox, the student\u2019s premises are\nself-defeating. Any reason the student has for predicting a test date\nor a non-test date is available to the teacher. Thus the teacher can\nsimulate the student\u2019s forecast and know what the student\nexpects.\n\nThe student\u2019s overall conclusion, that the test is impossible,\nis also self-defeating. If the student believes his conclusion then he\nwill not expect the test. So if he receives a test, it will be a\nsurprise. The event will be all the more unexpected because the\nstudent has deluded himself into thinking the test is impossible.\n\nJust as someone\u2019s awareness of a prediction can affect the\nlikelihood of it being true, awareness of that sensitivity to his\nawareness can also affect its truth. If each cycle of awareness is\nself-defeating, then there is no stable resting place for a\nconclusion.\n\nSuppose a psychologist offers you a red box and a blue box (Skyrms\n1982). The psychologist can predict which box you will choose with 90%\naccuracy. He has put one dollar in the box he predicts you will choose\nand ten dollars in the other box. Should you choose the red box or the\nblue box? You cannot decide. For any choice becomes a reason to\nreverse your decision.\n\nEpistemic paradoxes affect decision theory because rational choices\nare based on beliefs and desires. If the agent cannot form a\nrational belief, it is difficult to interpret his behavior as a\nchoice. In decision theory, the whole point of attributing\nbeliefs and desires is to set up practical syllogisms that make sense\nof actions as means to ends. Subtracting rationality from the agent\nmakes the framework useless. Given this commitment to charitable\ninterpretation, there is no possibility of you rationally choosing an\noption that you believe to be inferior. So if you choose, you cannot\nreally believe you were operating as an anti-expert, that is, someone\nwhose opinions on a topic are reliably wrong (Egan and Elga 2005).\n\nThe medieval philosopher John Buridan (Sophismata, Sophism\n13) gave a starkly minimal example of such instability:\n\n(B)\nYou do not believe this sentence. \n\n\nIf you believe (B) it is false. If you do not believe (B) it is true.\nYou are an anti-expert about (B); your opinion is reliably wrong. An\noutsider who monitors your opinion can reckon whether (B) is true. But\nyou are not able to exploit your anti-expertise.\n\nOn the bright side, you are able to exploit the anti-expertise of\nothers. Four out of five anti-experts recommend against reading any\nfurther!\n5.1 The Knower Paradox\n\nDavid Kaplan and Richard Montague (1960) think the announcement by the\nteacher in our surprise exam example is equivalent to the\nself-referential\n\n(K-3)\n Either the test is on Monday but you do not know it before\nMonday, or the test is on Wednesday but you do not know it before\nWednesday, or the test is on Friday but you do not know it before\nFriday, or this announcement is known to be false. \n\n\nKaplan and Montague note that the number of alternative test dates can\nbe increased indefinitely. Shockingly, they claim the number of\nalternatives can be reduced to zero! The announcement is then\nequivalent to\n\n(K-0)\nThis sentence is known to be false. \n\n\nIf (K-0) is true then it known to be false. Whatever is known to be\nfalse, is false. Since no proposition can be both true and false, we\nhave proven that (K-0) is false. Given that proof produces knowledge,\n(K-0) is known to be false. But wait! That is exactly what (K-0) says\n\u2013 so (K-0) must be true.\n\nThe (K-0) argument bears a suspicious resemblance to the liar paradox.\nSubsequent commentators sloppily switch the negation sign in the\nformal presentations of the reasoning from \\(K{\\sim}p\\) to\n\\({\\sim}Kp\\) (that is, from \u2018It is known that not-\\(p\\)\u2019,\nto \u2018It is not the case that it is known\nthat \\(p\\)\u2019). Ironically, this garbled\ntransmission results in a cleaner variation of the knower:\n\n(K)\nNo one knows this very sentence. \n\n\nIs (K) true? On the one hand, if (K) is true, then what it says is\ntrue, so no one knows it. On the other hand, that very reasoning seems\nto be a proof of (K). Believing a proposition by seeing it to be\nproved is a sufficient for knowledge of it, so someone must know (K).\nBut then (K) is false! Since no one can know a proposition that is\nfalse, (K) is not known.\n\nThe skeptic could hope to solve (K-0) by denying that anything is\nknown. This remedy does not cure (K). If nothing is known then (K) is\ntrue. Can the skeptic instead challenge the premise that proven is a\nsufficient for knowing it? This solution would be particularly\nembarrassing to the skeptic. The skeptic presents himself as a\nstickler for proof. If it turns out that even proof will not sway him,\nhe bears a damning resemblance to the dogmatist he so frequently\nchides.\n\nBut the skeptic should not lose his nerve. Proof does not always yield\nknowledge. Consider a student who correctly guesses that a step in his\nproof is valid. The student does not know the conclusion but did prove\nthe theorem. His instructor might have trouble getting the student to\nunderstand why his answer constitutes a valid proof. The intransigence\nmay stem from the prover\u2019s intelligence rather than his\nstupidity. L. E. J. Brouwer is best known in mathematics for his\nbrilliant fixed point theorem. But a doubtful reading of Immanuel\nKant\u2019s philosophy of mathematics led Brouwer retract his proof.\nBrouwer also had philosophical doubts about the Axiom of Choice and the\nLaw of Excluded Middle. Brouwer persuaded a minority of mathematicians\nand philosophers, known as intuitionists, to emulate his abstention\nfrom non-constructive proofs. This led them to develop constructive\nproofs of theorems that were earlier proved by less informative means.\nEverybody agrees that there is more to learn from a proof of an\nexistential generalization that proceeds from a proved instance than\nfrom an unspecific reductio ad absurdum of the corresponding\nuniversal generalization. But this does not vindicate the\nintuitionists\u2019s refusal to be persuaded by the reductio ad\nabsurdum. The intuitionist, even in the eyes of the skeptic, has\ntoo high a standard of proof. An excessively high standard of proof\ncan prevent knowledge by proof. \n\nThe logical myth that \u201cYou cannot prove a universal\nnegative\u201d is itself a universal negative. So it implies its own\nunprovability. This implication of unprovability is correct but only\nbecause the principle is false. For instance, exhaustive inspection\nproves the universal negative \u2018No adverbs appear in this\nsentence\u2019. A reductio ad absurdum proves the universal\nnegative \u2018There is no largest prime number\u2019.\n\nTrivially, false propositions cannot be proved true. Are\nthere any true propositions that cannot be proved true?\n\nYes, there are infinitely many. Kurt G\u00f6del\u2019s incompleteness\ntheorem demonstrated that any system that is strong enough to express\narithmetic is also strong enough to express a formal counterpart of\nthe self-referential proposition in the surprise test example\n\u2018This statement cannot be proved in this system\u2019. If the\nsystem cannot prove its \u201cG\u00f6del sentence\u201d, then this\nsentence is true. If the system can prove its G\u00f6del sentence, the\nsystem is inconsistent. So either the system is incomplete or\ninconsistent. (See the entry on\n Kurt G\u00f6del.)\n\nOf course, this result concerns provability relative to a system. One\nsystem can prove another system\u2019s G\u00f6del sentence. Kurt\nG\u00f6del (1983, 271) thought that proof was not needed for knowledge\nthat arithmetic is consistent.\n\nJ. R. Lucas (1964) claims that this reveals human beings are not\nmachines. A computer is a concrete instantiation of a formal system.\nHence, its \u201cknowledge\u201d is restricted to what it can prove.\nBy G\u00f6del\u2019s theorem, the computer will be either\ninconsistent or incomplete. However, any human being could\nhave consistent and complete knowledge of arithmetic. Therefore, necessarily, no\nhuman being is a computer.\n\nCritics of Lucas defend the parity between people and computers. They\nthink we have our own G\u00f6del sentences (Lewis 1999,\n166\u2013173). In this egalitarian spirit, G. C. Nerlich (1961)\nmodels the student\u2019s beliefs in the surprise test example as a\nlogical system. The teacher\u2019s announcement is then a G\u00f6del\nsentence about the student: There will be a test next week but you\nwill not be able to prove which day it will occur on the basis of this\nannouncement and memory of what has happened on previous exam days.\nWhen the number of exam days equals zero the announcement is\nequivalent to sentence K.\n\nSeveral commentators on the surprise test paradox object that\ninterpreting surprise as unprovability changes the topic. Instead of\nposing the surprise test paradox, it poses a variation of the liar\nparadox. Other concepts can be blended with the liar. For instance,\nmixing in alethic notions generates the possible liar: Is \u2018This\nstatement is possibly false\u2019 true? (Post 1970) (If it is false,\nthen it is false that it is possibly false. What cannot possibly be\nfalse is necessarily true. But if it is necessarily true, then it\ncannot be possibly false.) Since the semantic concept of validity\ninvolves the notion of possibility, one can also derive validity liars\nsuch as Pseudo-Scotus\u2019 paradox: \u2018Squares are squares,\ntherefore, this argument is invalid\u2019 (Read 1979). Suppose\nPseudo-Scotus\u2019 argument is valid. Since the premise is\nnecessarily true, the conclusion would be necessarily true. But the\nconclusion contradicts the supposition that argument is valid.\nTherefore, by reductio, the argument is necessarily invalid. Wait! The\nargument can be invalid only if it is possible for the premise to be\ntrue and the conclusion to be false. But we have already proved that\nthe conclusion of \u2018Squares are squares, therefore, this argument\nis invalid\u2019 is necessarily true. There is no consistent judgment\nof the argument\u2019s validity. A similar predicament follows from\n\u2018The test is on Friday but this prediction cannot be soundly\ndeduced from this announcement\u2019.\n\nOne can mock up a complicated liar paradox that resembles the surprise\ntest paradox. But this complex variant of the liar is not an\nepistemic paradox. For the paradoxes turn on the semantic\nconcept of truth rather than an epistemic concept.\n5.2 The \u201cKnowability Paradox\u201d\n\nFrederic Fitch (1963) reports that in 1945 he first learned of this\nproof of unknowable truths from a referee report on a manuscript he\nnever published. Thanks to Joe Salerno\u2019s (2009) archival\nresearch, we now know that referee was Alonzo Church.\n\nAssume there is a true sentence of the form \u2018\\(p\\)\nbut \\(p\\) is not known\u2019.\nAlthough this sentence is consistent, modest principles of epistemic\nlogic imply that sentences of this form are unknowable.\n\n\n\n1.\n\\(K(p \\amp{\\sim}Kp)\\)\n(Assumption) \n\n2.\n\\(Kp \\amp K{\\sim}Kp\\)\n1, Knowledge distributes over conjunction \n\n3.\n\\({\\sim}Kp\\)\n2, Knowledge implies truth (from the second conjunct) \n\n4.\n\\(Kp \\amp{\\sim}Kp\\)\n2, 3 by conjunction elimination of the first conjunct and then\nconjunction introduction \n\n5.\n\\({\\sim}K(p \\amp{\\sim}Kp)\\)\n1, 4 Reductio ad absurdum  \n\n\nSince all the assumptions are discharged, the conclusion is a\nnecessary truth. So it is a necessary truth that \\(p \\amp{\\sim}Kp\\) is\nnot known. In other words, \\(p \\amp{\\sim}Kp\\) is unknowable.\n\nThe cautious draw a conditional moral: If there are actual unknown\ntruths, there are unknowable truths. After all, some philosophers will\nreject the antecedent because they believe there is an omniscient\nbeing.\n\nBut secular idealists and logical positivists concede that there are\nsome actual unknown truths. How can they continue to believe that all\ntruths are knowable? Astonishingly, these eminent philosophers seem\nrefuted by the pinch of epistemic logic we have just seen. Also\ninjured are those who limit their claims of universal knowability to a\nlimited domain. For instance, Immanuel Kant (A223/B272) asserts that\nall empirical propositions are knowable. This pocket of optimism would\nbe enough to ignite the contradiction (Stephenson 2015).\n\nTimothy Williamson doubts that this casualty list is enough for the\nresult to qualify as a paradox:\n\nThe conclusion that there are unknowable truths is an affront to\nvarious philosophical theories, but not to common sense. If proponents\n(and opponents) of those theories long overlooked a simple\ncounterexample, that is an embarrassment, not a paradox. (2000, 271)\n\n\nThose who believe that the Church-Fitch result is a genuine paradox\ncan respond to Williamson with paradoxes that accord with common sense\n(and science \u2013and religious orthodoxy). For instance, common\nsense heartily agrees with the conclusion that something exists. But\nit is surprising that this can be proved without empirical premises.\nSince the quantifiers of standard logic (first order predicate logic\nwith identity) have existential import, the logician can deduce that\nsomething exists from the principle that everything is identical to\nitself. Most philosophers balk at this simple proof because they feel\nthat the existence of something cannot be proved by sheer logic. They\nare not balking at the statement that is in accord in common sense\n(that something exists). They are only balking at the statement that\nit can be proved by sheer logic. Likewise, many philosophers who agree\nthat there are unknowables balk solely on the grounds that such a\nprofound result cannot be obtained from such limited means.\n5.3 Moore\u2019s problem\n\nChurch\u2019s referee report was composed in 1945. The timing and\nstructure of his argument for unknowables suggests that Church may\nhave been inspired by G. E. Moore\u2019s (1942, 543) sentence:\n\n(M)\nI went to the pictures last Tuesday, but I don\u2019t believe that I did.\n\n\n\nMoore\u2019s problem is to explain what is odd about declarative\nutterances such as (M). This explanation needs to encompass both\nreadings of (M): \u2018\\(p \\amp B{\\sim}p\\)\u2019 and \u2018\\(p\n\\amp{\\sim}Bp\\)\u2019. (This scope ambiguity is exploited by a popular\njoke: Ren\u00e9 Descartes sits in a bar, having a drink. The\nbartender asks him if he would care for another. \u201cI think\nnot,\u201d he says, and disappears. The joke is commonly criticized\nas fallacious. But it is not given Descartes\u2019 belief that he is\nessentially a thinking being.)\n\nThe common explanation of Moore\u2019s absurdity is that the speaker\nhas managed to contradict himself without uttering a contradiction. So\nthe sentence is odd because it is a counterexample to the\ngeneralization that anyone who contradicts himself utters a\ncontradiction.\n\nThere is no problem with third person counterparts of (M). Anyone else\ncan say about Moore, with no paradox, \u2018G. E. Moore went to the\npictures last Tuesday but he does not believe it\u2019. (M) can also\nbe embedded unparadoxically in conditionals: \u2018If I went to the\npictures last Tuesday but I do not believe it, then I am suffering\nfrom a worrisome lapse of memory\u2019. The past tense is fine:\n\u2018I went to the picture shows last Tuesday but I did not believe\nit\u2019. The future tense, \u2018I went to the picture shows last\nTuesday but I will not believe it\u2019, is a bit more of a stretch\n(Bovens 1995). We tend to picture our future selves as better\ninformed. Later selves are, as it were, experts to whom earlier selves\nshould defer. When an earlier self foresees that his later self\nbelieves \\(p\\), then the prediction is a reason to\nbelieve \\(p\\). Bas van Fraassen (1984, 244) dubs this\n\u201cthe principle of reflection\u201d: I ought to believe a\nproposition given that I will believe it at some future time.\n\nRobert Binkley (1968) anticipates van Fraassen by applying the\nreflection principle to the surprise test paradox. The student can\nforesee that he will not believe the announcement if no test is given\nby Thursday. The conjunction of the history of testless days\nand the announcement will imply the Moorean sentence:\n\n(A\u2032)\n The test is on Friday but you do not believe it.\n\n\nSince the less evident member of the conjunction is the announcement,\nthe student will choose not to believe the announcement. At the\nbeginning of the week, the student foresees that his future self may\nnot believe the announcement. So the student on Sunday will not\nbelieve the announcement when it is first uttered.\n\nBinkley illuminates this reasoning with doxastic logic (\u2018doxa\u2019 is\nGreek for belief). The inference rules for this logic of belief can be\nunderstood as idealizing the student into an ideal reasoner. In\ngeneral terms, an ideal reasoner is someone who infers what he ought\nand refrains from inferring any more than he ought. Since there is no\nconstraint on his premises, we may disagree with the ideal reasoner.\nBut if we agree with the ideal reasoner\u2019s premises, we appear\nbound to agree with his conclusion. Binkley specifies some\nrequirements to give teeth to the student\u2019s status as an ideal\nreasoner: the student is perfectly consistent, believes all the\nlogical consequences of his beliefs, and does not forget. Binkley\nfurther assumes that the ideal reasoner is aware that he is an ideal\nreasoner. According to Binkley, this ensures that if the ideal\nreasoner believes p, then he believes that he will believe \\(p\\)\nthereafter.\n\nBinkley\u2019s account of the student\u2019s hypothetical epistemic\nstate on Thursday is compelling. But his argument for spreading the\nincredulity from the future to the past is open to three\nchallenges.\n\nThe first objection is that it delivers the wrong result. The student\n\\(is\\) informed by the teacher\u2019s announcement, so Binkley ought\nnot to use a model in which the announcement is as absurd as the\nconjunction \u2018I went to the pictures last Tuesday but I do not\nbelieve it\u2019.\n\nSecond, the future mental state envisaged by Binkley is only\nhypothetical: \\(If\\) no test is given by Thursday, the student will\nfind the announcement incredible. At the beginning of the week, the\nstudent does not know (or believe) that the teacher will wait that\nlong. The principle of reflection \u2018Defer to the opinions of my future\nself \u2019 does not imply that I should defer to the opinions of my\nhypothetical future self. For my hypothetical future self is\nresponding to propositions that need not be actually true.\n\nThird, the principle of reflection may need more qualifications than\nBinkley anticipates. Binkley realizes that an ordinary agent foresees\nthat he will forget details. That is why we write reminders for our\nown benefit. An ordinary agent foresees periods of impaired judgment.\nThat is why we limit how much money we bring to the bar.\n\nBinkley stipulates that the students do not forget. He needs to add\nthat the students know that they will not forget. For the mere threat\nof a memory lapse sometimes suffices to undermine knowledge. Consider\nProfessor Anesthesiology\u2019s scheme for surprise tests: \u201cA\nsurprise test will be given either Wednesday or Friday with the help\nof an amnesia drug. If the test occurs on Wednesday, then the drug\nwill be administered five minutes after Wednesday\u2019s class. The\ndrug will instantly erase memory of the test and the students will\nfill in the gap by confabulation.\u201d You have just completed\nWednesday\u2019s class and so temporarily know that the test will be\non Friday. Ten minutes after the class, you lose this knowledge. No\ndrug was administered and there is nothing wrong with your memory. You\nare correctly remembering that no test was given on Wednesday.\nHowever, you do not know your memory is accurate because you also know\nthat if the test was given Wednesday then you would have a\npseudo-memory indistinguishable from your present memory. Despite not\ngaining any new evidence, you change your mind about the test\noccurring on Wednesday and lose your knowledge that the test is on\nFriday. (The change of belief is not crucial; you would still lack\nforeknowledge of the test even if you dogmatically persisted\nin believing that the test will be on Friday.)\n\nIf the students know that they will not forget and know there will be\nno undermining by outside evidence, then we may be inclined to agree\nwith Binkley\u2019s summary that his idealized student never loses\nthe knowledge he accumulates. As we shall see, however, this overlooks\nother ways in which rational agents may lose knowledge.\n5.4 Blindspots\n\n\u2018I am a poet but I do not know it\u2019 expresses a proposition\nI cannot know.  But I can reach the proposition by other attitudes\nsuch as hoping and wishing. A blindspot for a propositional attitude\nis a consistent proposition that cannot be accessed by that\nattitude. Blindspots are relative to the means of reaching the\nproposition, the person making the attempt, and time at which he\ntries. Although \\(I\\) cannot rationally believe \u2018Polar bears\nhave black skin but I believe they do not\u2019 you can\nbelieve that I mistakenly believe polar bears do not have black\nskin. The evidence that persuades you I am currently making that\nmistake cannot persuade me that I am currently making that\nmistake. This is an asymmetry imposed by rationality rather than\nirrationality. Attributions of specific errors are personal blindspots\nfor the person who is alleged to have erred.\n\nThe anthropologist Gontran de Poncins begins his chapter on the arctic\nmissionary, Father Henry, with a prediction:\n\nI am going to say to you that a human being can live without complaint\nin an ice-house built for seals at a temperature of fifty-five degrees\nbelow zero, and you are going to doubt my word. Yet what I say is\ntrue, for this was how Father Henry lived; \u2026. (Poncins 1941\n[1988], 240])\n\n\nGontran de Poncins\u2019 subsequent testimony might lead the reader\nto believe someone can indeed be content to live in an ice-house. The\nsame testimony might lead another reader to believe that Poncins is\nnot telling the truth. But no reader ought to believe \u2018Someone\ncan be content to live in an ice house and everybody believes that is\nnot so\u2019. That is a universal blindspot.\n\nIf Gontran believes a proposition that is a blindspot to his reader,\nthen he cannot furnish good grounds for his reader to share his\nbelief. This holds even if they are ideal reasoners. So one\nimplication of personal blindspots is that there can be disagreement\namong ideal reasoners because they differ in their blindspots. \n\nThis is relevant to the surprise test paradox. The students are the\nsurprisees. Since the announcement entails that the date of the\nsurprise test a blindspot for them, non-surprisees cannot persuade\nthem.\n\nThe same point holds for intra-personal disagreement over time.\nEvidence that persuaded me on Sunday that \u2018This security code is\n390524 but on Friday I will not believe it\u2019 should no longer\npersuade me on Friday (given my belief that the day is Friday). For\nthat proposition is a blindspot to my Friday self.\n\nAlthough each blindspot is inaccessible, a disjunction of blindspots\nis normally not a blindspot. I can rationally believe that\n\u2018Either the number of stars is even and I do not believe it, or\nthe number of stars is odd and I do not believe it\u2019. The\nauthor\u2019s preface statement that there is some mistake in his\nbook is equivalent to a very long disjunction of blindspots. The\nauthor is saying he either falsely believes his first statement or\nfalsely believes his second statement or \u2026 or falsely believes\nhis last statement.\n\nThe teacher\u2019s announcement that there will be a surprise test is\nequivalent to a disjunction of future mistakes: \u2018Either there\nwill be a test on Monday and the student will not believe it\nbeforehand or there will be a test Wednesday and the student will not\nbelieve it beforehand or the test is on Friday and the student will\nnot believe it beforehand.\u2019\n\nThe points made so far suggest a solution to the surprise test paradox\n(Sorensen 1988, 328\u2013343). As Binkley (1968) asserts, the test\nwould be a surprise even if the teacher waited until the last day. Yet\nit can still be true that the teacher\u2019s announcement is\ninformative. At the beginning of the week, the students are justified\nin believing the teacher\u2019s announcement that there will be a\nsurprise test. This announcement is equivalent to:\n\n(A)\nEither\n \ni.\nthe test is on Monday and the student does not know it\nbefore Monday, or\nii.\nthe test is on Wednesday and the student does not know\nit before Wednesday, or\niii.\nthe test is on Friday and the student does not know it before\nFriday.\n\n\n\nConsider the student\u2019s predicament on Thursday (given that the\ntest has not been on Monday or Wednesday). If he knows that no test\nhas been given, he cannot also know that (A) is true. Because that\nwould imply\n\nThe test is on Friday and the student does not know it before\nFriday.\n\n\nAlthough (iii) is consistent and might be knowable by others, (iii)\ncannot be known by the student before Friday. (iii) is a blindspot for\nthe students but not for, say, the teacher\u2019s colleagues. Hence,\nthe teacher can give a surprise test on Friday because that would\nforce the students to lose their knowledge of the original\nannouncement (A). Knowledge can be lost without forgetting\nanything.\n\nThis solution makes who you are relevant to what you can know. In\naddition to compromising the impersonality of knowledge, there will be\ncompromise on its temporal neutrality.\n\nSince the surprise test paradox can also be formulated in terms of\nrational belief, there will be parallel adjustments for what we ought\nto believe. We are criticized for failures to believe the logical\nconsequences of what we believe and criticized for believing\npropositions that conflict with each other. Anyone who meets these\nideals of completeness and consistency will be unable to believe a\nrange of consistent propositions that are accessible to other complete\nand consistent thinkers. In particular, they will not be able to\nbelieve propositions attributing specific errors to them, and\npropositions that entail these off-limit propositions.\n\nSome people wear T-shirts with Question Authority! written on\nthem. Questioning authority is generally regarded as a matter of\nindividual discretion. The surprise test paradox shows that it is\nsometimes mandatory. The student is rationally required to doubt the\nteacher\u2019s announcement even though the teacher has not given any\nnew evidence of being unreliable. For when only one day remains, the\nannouncement entails (iii), a statement is that is impossible for the student to know.\nThe student can foresee that this forced loss of knowledge opens an\nopportunity for the teacher to give the surprise test. This\nforeknowledge is available at the time the announcement.\n\nThis solution implies there can be disagreement amongst ideal\nreasoners who agree on the same impersonal data. Consider the\ncolleagues of the teachers. They are not amongst those that the\nteacher targets for surprise. Since \u2018surprise\u2019 here means\n\u2018surprise to the students\u2019, the teacher\u2019s colleagues\ncan consistently infer that the test will be on the last day from the\npremise that it has not been given on any previous day. But these\ncolleagues are useless to the students as informants.\n6. Dynamic Epistemic Paradoxes\n\nThe above anomalies (losing knowledge without forgetting, disagreement\namongst equally well-informed ideal reasoners, rationally changing\nyour mind without the acquisition of counter-evidence) would be more\ntolerable if reinforced by separate lines of reasoning. The most\nfertile source of this collateral support is in puzzles about updating\nbeliefs.\n\nThe natural strategy is to focus on the knower when he is stationary.\nHowever, just as it is easier for an Eskimo to observe an arctic fox\nwhen it moves, we often get a better understanding of the knower\ndynamically, when he is in the process of gaining or losing\nknowledge.\n6.1 Meno\u2019s Paradox of Inquiry: A puzzle about gaining knowledge\n\nWhen on trial for impiety, Socrates traced his inquisitiveness to the\nOracle at Delphi (Apology 21d in Cooper 1997). Prior to\nbeginning his mission of inquiry, Chaerephon asked the Oracle:\n\u201cWho is the wisest of men?\u201d The Oracle answered \u201cNo\none is wiser than Socrates.\u201d This astounded Socrates because he\nbelieved he knew nothing. Whereas a less pious philosopher might have\nquestioned the reliability of the Delphic Oracle, Socrates followed\nthe general practice of treating the Oracle as infallible. The only\ncogitation appropriate to an infallible answer is interpretation.\nAccordingly, Socrates resolved his puzzlement by inferring that his\nwisdom lay in recognizing his own ignorance. While others may know\nnothing, Socrates knows that he knows nothing.\n\nSocrates continues to be praised for his insight. But his\n\u201cdiscovery\u201d is a contradiction. If Socrates knows that he\nknows nothing, then he knows something (the proposition that he knows\nnothing) and yet does not know anything (because knowledge implies\ntruth).\n\nSocrates could regain consistency by downgrading his meta-knowledge to\nthe status of a belief. If he believes he knows nothing, then he\nnaturally wishes to remedy his ignorance by asking about everything.\nThis rationale is accepted throughout the early dialogues. But when we\nreach the Meno, one of his interlocutors has an epiphany.\nAfter Meno receives the standard treatment from Socrates about the\nnature of virtue, Meno discerns a conflict between Socratic ignorance\nand Socratic inquiry (Meno 80d, in Cooper 1997). How would\nSocrates recognize the correct answer even if Meno gave it?\n\nThe general structure of Meno\u2019s paradox is a dilemma: If you\nknow the answer to the question you are asking, then nothing can be\nlearned by asking. If you do not know the answer, then you cannot\nrecognize a correct answer even if it is given to you. Therefore, one\ncannot learn anything by asking questions.\n\nThe natural solution to Meno\u2019s paradox is to characterize the\ninquirer as only partially ignorant. He knows enough to recognize a\ncorrect answer but not enough to answer on his own. For instance,\nspelling dictionaries are useless to six year old children because\nthey seldom know more than the first letter of the word in question.\nTen year old children have enough partial knowledge of the\nword\u2019s spelling to narrow the field of candidates. Spelling\ndictionaries are also useless to those with full knowledge of spelling\nand those with total ignorance of spelling. But most of us have an\nintermediate amount of knowledge.\n\nIt is natural to analyze partial knowledge as knowledge of\nconditionals. The ten year old child knows the spoken version of\n\u2018If the spelling dictionary spells the month after January as\nF-e-b-r-u-a-r-y, then that spelling is correct\u2019. Consulting the\nspelling dictionary gives him knowledge of the antecedent of the\nconditional.\n\nMuch of our learning from conditionals runs as smoothly as this\nexample suggests. Since we know the conditional, we are poised learn\nthe consequent merely by learning the antecedent (and by applying the\ninference rule modus ponens: If \\(P\\) then \\(Q\\),\n\\(P\\), therefore \\(Q\\)).\nBut the next section is devoted to some known\nconditionals that are repudiated when we learn their antecedents.\n6.2 Dogmatism paradox: A puzzle about losing knowledge\n\nSaul Kripke\u2019s ruminations on the surprise test paradox led him\nto a paradox about dogmatism. He lectured on both paradoxes at\nCambridge University to the Moral Sciences Club in 1972. (A descendent\nof this lecture now appears as Kripke 2011.) Gilbert Harman transmitted\nKripke\u2019s new paradox as follows:\n\nIf I know that \\(h\\) is true, I know that any evidence\nagainst \\(h\\) is evidence against something that is\ntrue; I know that such evidence is misleading. But I should disregard\nevidence that I know is misleading. So, once I know that \\(h\\)\nis true, I am in a position to disregard any future\nevidence that seems to tell against \\(h\\). (1973, 148)\n\n\nDogmatists accept this reasoning. For them, knowledge closes inquiry.\nAny \u201cevidence\u201d that conflicts with what is known can be\ndismissed as misleading evidence. Forewarned is forearmed.\n\nThis conservativeness crosses the line from confidence to\nintransigence. To illustrate the excessive inflexibility, here is a\nchain argument for the dogmatic conclusion that my reliable colleague\nDoug has given me a misleading report (corrected from Sorensen\n1988b):\n\n(C\\(_1\\))\nMy car is in the parking lot.\n(C\\(_2\\))\n If my car is in the parking lot and Doug provides evidence that\nmy car is not in the parking lot, then Doug\u2019s evidence is\nmisleading.\n(C\\(_3\\))\n If Doug reports he saw a car just like mine towed from the\nparking lot, then his report is misleading evidence.\n(C\\(_4\\))\n Doug reports that a car just like mine was towed from the parking\nlot.\n(C\\(_5\\))\n Doug\u2019s report is misleading evidence.\n\n\nBy hypothesis, I am justified in believing (C\\(_1)\\). Premise\n(C\\(_2)\\) is a certainty because it is analytically true. The argument\nfrom (C\\(_1)\\) and (C\\(_2)\\) to (C\\(_3)\\) is valid. Therefore, my\ndegree of confidence in (C\\(_3)\\) must equal my degree of confidence\nin (C\\(_1)\\). Since we are also assuming that I gain sufficient\njustification for (C\\(_4)\\), it seems to follow that I am justified in\nbelieving (C\\(_5)\\) by modus ponens. Similar arguments will lead me to\ndismiss further evidence such as a phone call from the towing service\nand my failure to see my car when I confidently stride over to the\nparking lot.\n\nGilbert Harman diagnoses the paradox as follows:\n\nThe argument for paradox overlooks the way actually having evidence\ncan make a difference. Since I now know [my car is in the parking\nlot], I now know that any evidence that appears to indicate something\nelse is misleading. That does not warrant me in simply disregarding\nany further evidence, since getting that further evidence can change\nwhat I know. In particular, after I get such further evidence I may no\nlonger know that it is misleading. For having the new evidence can\nmake it true that I no longer know that new evidence is misleading.\n(1973, 149)\n\n\nIn effect, Harman denies the hardiness of knowledge. The hardiness\nprinciple states that one knows only if there is no evidence such that\nif one knew about the evidence one would not be justified in believing\none\u2019s conclusion.\n\nHarman\u2019s conclusion that new knowledge can undermine old\nknowledge can be applied to the surprise test paradox: The students\nlose knowledge of the test announcement even though they do not forget\nthe announcement or do anything else incompatible with their\ncredentials as ideal reasoners. A student on Thursday is better\ninformed about the outcomes of test days than he was on Sunday. He\nknows the test was not on Monday and not on Wednesday. But he can only\npredict that the test is on Friday if he continues to know the\nannouncement. The extra knowledge of the testless days undermines\nknowledge of the announcement.\n\nMost epistemologists accepted Harman\u2019s appeal to defeaters. Some\nhave tried to make it more precise with details about updating\nindicative conditionals (Sorensen 1988b). This may vindicate and\ngeneralize Harman\u2019s prediction that the future evidence will\nchange your mind about what is misleading evidence. Knowledge of such\nconditionals is useless for a future modus ponens. The\ndogmatist correctly says we know the conditional \u201cIf I know\nthat \\(p\\), then any evidence conflicting with \\(p\\) is\nmisleading evidence\u201d. Indeed, it is a tautology! But the\ndogmatist fails to recognize this known tautology is useless\nknowledge. Acquiring the misleading evidence will make me stop knowing\np. If an auditor foresees being presented with a biased list of facts,\nhe may utter the tautology to his assistant to convey another\nproposition for which he has empirical support. That empirical\nproposition need not be useless knowledge. When the predicted list is\npresented, the forearmed auditor ignores the facts. But the basis is\nnot his a priori knowledge of the dogmatist\u2019s tautology.\n\nKripke notes that this solution will not stop the quick thinking\ndogmatist who takes measures to prevent his acquisition of the\nevidence that he now deems misleading (Kripke 2011, 43\u201344). A\nsecond worry is that the dogmatist can still ignore weak evidence. If\nI know a coin is fair then I know that if the first twenty tosses\ncomes out heads, then that is misleading evidence that the coin is not\nfair. Such a run does not defeat my knowledge claim. (Substitute a\nshorter run if you think it does defeat.) So Harman\u2019s solution does\nnot apply. Yet it is dogmatic to ignore this evidence. \n\nIn addition to this problem of weak dogmatism, Rachel Fraser (2022)\nadds a third problem of dogmatic bootstrapping. When Robert Millikan\nand Harvey Fletcher measured elementary electric charge with tiny\ncharged droplets, they discounted some of the drops as misleadingly\nwide of the plausible interval for the true value. Drops centrally located\nwithin the interval were \u201cbeauties\u201d. Editing out the\noutliers give Millikan a more precise measurement and a Nobel Prize in\n1923. In 1978, the physicist Gerald Holton went through the notebooks\nand was shocked by how much contrary data had gone unreported by\nMillikan. Fraser thinks there is a vicious circularity in data purification. \n\nBut the bootstrapping dogmatist will regard the circularity as virtuous. When the evidence is a mix of strong evidence and weak\ncounterevidence, the stronger body of evidence exposes the weaker body\nas misleading evidence. Think of a jigsaw puzzle that has been polluted with stray pieces from another puzzle. When you manage to get a complete fit with a subset of the pieces, the remaining pieces are removed from view. Dimming the misleading evidence allows the leading evidence to shine more visibly. Therefore, we can indeed be more confident than\nwe were before dismissing the weak evidence. Millikan was being\nresponsible gatekeeper rather than a wishful thinker. Just as data\nshould control theory, theory should control data.  The experimenter must strike a delicate balance between discounting too much contrary data and discounting too little. Proposed solutions to the dogmatism paradox have trouble sustaining this balance. \n\nI. J. Good (1967) demonstrated that gathering evidence maximizes\nexpected value given that the cost of the evidence is\nnegligible. Under this simplifying assumption, Good shows that\ndepartures from the principle of total evidence is at least imprudent.\nGiven epistemic utilitarianism, this practical irrationality becomes\ntheoretical irrationality. Bob Beddor (2019) now adds the premise that\nit is irrational to intend to do what one foresees to be irrational.\nFor instance, if you offered a million dollars to drink toxin tomorrow\nthat will make you ill for a day, you could profit from the offer\n(Kavka 1983). But if the million would be earned immediately upon you\nintending to drink the toxin, then you could not profit because you\nknow there would be no reason to follow through. By analogy, Beddor\nconcludes that it would be irrational to intend to avoid\ncounterevidence (Beddor 2019, 738). One is never entitled to discard\nevidence, even after it has been foreseen as misleading evidence.\n\nBut if the cost of evidence is significant, the connection between\npractical rationality and theoretical rationality favors\nignoring counterevidence. Judging that p embodies a resolution not to\ninquire further into the question of whether p is true. Or so answers\nthe volitionist (Fraser 2022).\n6.3 The Future of Epistemic Paradoxes\n\nWe cannot predict that any specific new epistemic paradox awaits\ndiscovery. To see why, consider the prediction Jon Wynne-Tyson\nattributes to Leonardo Da Vinci: \u201cI have learned from an early\nage to abjure the use of meat, and the time will come when men such as\nI will look upon the murder of animals as they now look upon the\nmurder of men.\u201d (1985, 65) By predicting this progress, Leonardo\ninadvertently reveals he already believes that the murder of\nanimals is the same as the murder of men. If you believe that a\nproposition is true but will be first believed at a later time, then\nyou already believe it \u2013 and so are inconsistent. (The actual\ntruth is irrelevant.)\n\nSpecific regress can be anticipated. When I try to predict my first\nacquisition of a specific truth, I pre-empt myself. When I try to\npredict my first acquisition of a specific falsehood, there is no\npre-emption.\n\nThere would be no problem with predicting progress if Leonardo thinks\nthe moral progress lies in the moral preferability of the vegetarian\nbelief rather than the truth of the matter. One might admire\nvegetarianism without accepting the correctness of vegetarianism. But\nLeonardo is endorsing the correctness of the belief. This sentence\nembodies a Moorean absurdity. It is like saying \u2018Leonardo took\ntwenty five years to complete The Virgin on the Rocks but I\nwill first believe so tomorrow\u2019. (This absurdity will prompt\nsome to object that I have uncharitably interpreted Leonardo; he must\nhave intended to make an exception for himself and only be referring\nto men of his kind.)\n\nI cannot specifically anticipate the first acquisition of the true\nbelief that \\(p\\). For that prediction would show that\nI already have the true belief that \\(p\\). The truth\ncannot wait. The impatience of the truth imposes a limit on the\nprediction of discoveries.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Aikin, K. Scott, 2011, <em>Epistemology and the Regress\nProblem</em>, London: Routledge.",
                "Anderson, C. Anthony, 1983, \u201cThe Paradox of the\nKnower\u201d, <em>The Journal of Philosophy</em>, 80:\n338\u2013355.",
                "Binkley, Robert, 1968, \u201cThe Surprise Examination in Modal\nLogic\u201d, <em>Journal of Philosophy</em>, 65/2:\n127\u2013136.",
                "Bommarito, Nicolas, 2010, \u201cRationally Self-Ascribed\nAnti-Expertise\u201d, <em>Philosophical Studies</em>, 151:\n413\u2013419.",
                "Bovens, Luc, 1995, \u201c\u2018P and I will believe that\nnot-P\u2019: Diachronic Constraints on Rational Belief\u201d,\n<em>Mind</em>, 104(416): 737\u2013760.",
                "Burge, Tyler, 1984, \u201cEpistemic Paradox\u201d, <em>Journal\nof Philosophy</em>, 81/1: 5\u201329.",
                "\u2013\u2013\u2013, 1978a, \u201cBuridan and Epistemic\nParadox\u201d, <em>Philosophical Studies</em>, 34: 21\u201335.",
                "Buridan, John, 1982, <em>John Buridan on Self-Reference: Chapter\nEight of Buridan\u2019s \u2018Sophismata\u2019</em>, G. E. Hughes\n(ed. &amp; tr.), Cambridge: Cambridge University Press.",
                "Carnap, Rudolf, 1950, <em>The Logical Foundations of\nProbability</em>, Chicago: University of Chicago Press.",
                "Christensen, David, 2010, \u201cHigher Order Evidence\u201d,\n<em>Philosophy and Phenomenological Research</em>, 81:\n185\u2013215.",
                "Cicero, <em>On the Nature of the Gods, Academica </em>, H. Rackham\n(trans.) Cambridge, MA: Loeb Classical Library, 1933.",
                "Collins, Arthur, 1979, \u201cCould our beliefs be representations\nin our brains?\u201d, <em>Journal of Philosophy</em>, 74(5):\n225\u201343.",
                "Conee, Earl, 2004, \u201cHeeding Misleading Evidence\u201d,\n<em>Philosophical Studies</em>, 103: 99\u2013120.",
                "Cooper, John (ed.), 1997, <em>Plato: The Complete Works</em>,\nIndianapolis: Hackett.",
                "DeRose, Keith, 2017, <em>The Appearance of Ignorance: Knowledge,\nSkepticism, and Context</em> (Volume 2), Oxford: Oxford University\nPress.",
                "Egan, Andy and Adam Elga, 2005, \u201cI Can\u2019t Believe\nI\u2019m Stupid\u201d, <em>Philosophical Perspectives</em>, 19/1:\n77\u201393.",
                "Feyerabend, Paul, 1988, <em>Against Method</em>, London:\nVerso.",
                "Fitch, Frederic, 1963, \u201cA Logical Analysis of Some Value\nConcepts\u201d, <em>Journal of Symbolic Logic</em>, 28/2:\n135\u2013142.",
                "Fraser, Rachel, 2022, \u201cThe Will in Belief\u201d, <em>Oxford\nStudies in Epistemology.</em>",
                "G\u00f6del, Kurt, 1983, \u201cWhat is Cantor\u2019s Continuum\nProblem?\u201d, <em>Philosophy of Mathematics</em>, Paul Benacerraf\nand Hilary Putnam (eds.), Cambridge: Cambridge University Press,\npp. 258\u2013273.",
                "Good, I. J., 1967, \u201cOn the Principle of Total\nEvidence\u201d, <em>British Journal for the Philosophy of\nScience</em>, 17(4): 319\u2013321.",
                "Hacking, Ian, 1975, <em>The Emergence of Probability</em>,\nCambridge: Cambridge University Press.",
                "Hajek, Alan, 2005, \u201cThe Cable Guy paradox\u201d,\n<em>Analysis</em>, 65(2): 112\u2013119.",
                "Harman, Gilbert, 1968, \u201cKnowledge, Inference, and\nExplanation\u201d, <em>American Philosophical Quarterly</em>, 5/3:\n164\u2013173.",
                "\u2013\u2013\u2013, 1973, <em>Thought</em>, Princeton:\nPrinceton University Press.",
                "Hawthorne, John, 2004, <em>Knowledge and Lotteries</em>, Oxford:\nClarendon Press.",
                "Hein, Piet, 1966, <em>Grooks</em>, Cambridge, MA: MIT Press.",
                "Hintikka, Jaakko, 1962, <em>Knowledge and Belief</em>, Ithaca, NY:\nCornell University Press.",
                "Holliday, Wesley, 2016, \u201cOn Being in an Undiscoverable\nPosition\u201d, <em>Thought</em>, 5(1): 33\u201340.",
                "\u2013\u2013\u2013, 2017, \u201cEpistemic Logic and\nEpistemology\u201d, <em>The Handbook of Formal Philosophy</em>, Sven\nOve Hansson and Vincent F. Hendricks (eds.), Dordercht: Springer.",
                "Hughes, G. E., 1982, <em>John Buridan on Self-Reference</em>,\nCambridge: Cambridge University Press.",
                "Immerman, Daniel, 2017, \u201cQuestion Closure to Solve the\nSurprise Test Paradox\u201d, <em>Synthese</em>, 194(11):\n4583\u20134596.",
                "Kaplan, David and Richard Montague, 1960, \u201cA Paradox\nRegained\u201d, <em>Notre Dame Journal of Formal Logic</em>, 1:\n79\u201390.",
                "Klein, Peter, 2007, \u201cHow to be an Infinitist about Doxastic\nJustification\u201d, <em> Philosophical Studies</em>, 134:\n77\u201325\u201329.",
                "Knight, Kevin, 2002, \u201cMeasuring Inconsistency\u201d,\n<em>Journal of Philosophical Logic</em>, 31/1: 77\u201398.",
                "Kripke, Saul, 2011, \u201cTwo Paradoxes of Knowledge\u201d, in\nS. Kripke, <em>Philosophical Troubles: Collected Papers</em> (Volume\n1), New York: Oxford University Press, pp. 27\u201351.",
                "Kvanvig, Jonathan L., 1998, \u201cThe Epistemic Paradoxes\u201d,\n<em>Routledge Encyclopedia of Philosophy</em>, London: Routledge.",
                "Kyburg, Henry, 1961, <em>Probability and the Logic of Rational\nBelief</em>, Middletown: Wesleyan University Press.",
                "Lewis, David, 1998, \u201cLucas against Mechanism\u201d,\n<em>Papers in Philosophical Logic</em>, Cambridge: Cambridge\nUniversity Press, pp. 166\u20139.",
                "Lewis, David and Jane Richardson, 1966, \u201cScriven on Human\nUnpredictability\u201d, <em>Philosophical Studies</em>, 17(5):\n69\u201374.",
                "Lucas, J. R., 1964, \u201cMinds, Machines and G\u00f6del\u201d,\nin <em>Minds and Machines</em>, Alan Ross Anderson (ed.), Englewood\nCliffs, N.J.: Prentice Hall, pp. 112\u20137.",
                "Makinson, D. C., 1965, \u201cThe Paradox of the Preface\u201d,\n<em>Analysis</em>, 25: 205\u2013207.",
                "Malcolm, Norman, 1963, <em>Knowledge and Certainty</em>, Englewood\nCliffs, NJ: Prentice Hall.",
                "Moore, G. E., 1942, \u201cA Reply to My Critics\u201d, <em>The\nPhilosophy of G. E. Moore</em>, edited by P. A. Schilpp. Evanston, IL:\nNorthwestern University.",
                "Nerlich, G. C., 1961, \u201cUnexpected Examinations and\nUnprovable Statements\u201d, <em>Mind</em>, 70(280):\n503\u2013514.",
                "Peirce, Charles Sanders, 1931\u20131935, <em>The Collected Works\nof Charles Sanders Peirce</em>, Charles Hartshorne and Paul Weiss\n(eds.), Cambridge, MA: Harvard University Press.",
                "Plato, <em>Plato: The Complete Works</em>, John M. Cooper (ed.),\nIndianapolis: Hackett, 1997.",
                "Poncins, Gontran de, 1941 [1988], <em>Kabloona</em> in\ncollaboration with Lewis Galantiere, New York: Carroll &amp; Graff\nPublishers, 1988.",
                "Post, John F., 1970, \u201cThe Possible Liar\u201d,\n<em>No\u00fbs</em>, 4: 405\u2013409.",
                "Quine, W. V. O, 1953, \u201cOn a so-called Paradox\u201d,\n<em>Mind</em>, 62(245): 65\u20137.",
                "\u2013\u2013\u2013, 1969, \u201cEpistemology\nNaturalized\u201d, in <em>Ontological Relativity and Other\nEssays</em>, New York: Columbia University Press, pp. 69\u201390.",
                "\u2013\u2013\u2013, 1987, <em>Quiddities</em>, Cambridge, MA:\nHarvard University Press.",
                "Read, Stephen, 1979, \u201cSelf-Reference and Validity\u201d,\n<em>Synthese</em>, 42(2): 265\u201374.",
                "Sainsbury, R. M., 1995, <em>Paradoxes</em>, Cambridge: Cambridge\nUniversity Press.",
                "Salerno, Joseph, 2009, <em>New Essays on the Knowability\nParadox</em>, New York: Oxford University Press.",
                "Scriven, Michael, 1964, \u201cAn Essential Unpredictability in\nHuman Behavior\u201d, in <em>Scientific Psychology: Principles and\nApproaches</em>, Benjamin B. Wolman and Ernest Nagel (eds.), New York:\nBasic Books, pp. 411\u201325.",
                "Sextus Empiricus, <em>Outlines of Pyrrhonism</em>, R. G. Bury\n(trans.), Cambridge, MA: Harvard University Press, 1933.",
                "Skyrms, Brian, 1982, \u201cCausal Decision Theory\u201d,\n<em>Journal of Philosophy</em>, 79(11): 695\u2013711.",
                "Smith, Martin, 2016, <em>Between Probability and Certainty</em>,\nClarendon: Oxford University Press.",
                "Sorensen, Roy, 1988a, <em>Blindspots</em>, Oxford: Clarendon\nPress.",
                "\u2013\u2013\u2013, 1988b, \u201cDogmatism, Junk Knowledge,\nand Conditionals\u201d, <em>Philosophical Quarterly</em>, 38:\n433\u2013 454.",
                "\u2013\u2013\u2013, 2001, <em>Vagueness and Contradiction</em>,\nOxford: Clarendon Press.",
                "\u2013\u2013\u2013, 2003a, \u201cParadoxes of\nRationality\u201d, in <em>The Handbook of Rationality</em>, Al Mele\n(ed.), Oxford: Oxford University Press, pp. 257\u201375.",
                "\u2013\u2013\u2013, 2003b, <em>A Brief History of the\nParadox</em>, New York: Oxford University Press.",
                "Stephenson, Andrew, 2015, \u201cKant, the Paradox of Knowability,\nand the Meaning of Experience\u201d, <em>Philosophers Imprint</em>,\n15(17), 1\u201319.",
                "Thomson, J. F., 1962, \u201cOn Some Paradoxes\u201d, in\n<em>Analytical Philosophy</em>, R. J. Butler (ed.), New York: Barnes\n&amp; Noble, pp. 104\u2013119.",
                "Tymoczko, Thomas, 1984, \u201cAn Unsolved Puzzle about\nKnowledge\u201d, <em>The Philosophical Quarterly</em>, 34:\n437\u201358.",
                "van Fraassen, Bas, 1984, \u201cBelief and the Will\u201d,\n<em>Journal of Philosophy</em>, 81: 235\u2013256",
                "\u2013\u2013\u2013, 1995, \u201cBelief and the Problem of\nUlysses and the Sirens\u201d, <em>Philosophical Studies</em>, 77:\n7\u201337",
                "Weiss, Paul, 1952, \u201cThe Prediction Paradox\u201d,\n<em>Mind</em>, 61(242): 265\u20139.",
                "Williamson, Timothy, 2000, <em>Knowledge and its Limits</em>,\nOxford: Oxford University Press.",
                "Wynne-Tyson, Jon, 1985, <em>The Extended Circle</em>, Fontwell,\nSussex: Centaur Press."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2><a name=\"Bib\">Bibliography</a></h2>\n<ul class=\"hanging\">\n<li>Aikin, K. Scott, 2011, <em>Epistemology and the Regress\nProblem</em>, London: Routledge.</li>\n<li>Anderson, C. Anthony, 1983, \u201cThe Paradox of the\nKnower\u201d, <em>The Journal of Philosophy</em>, 80:\n338\u2013355.</li>\n<li>Binkley, Robert, 1968, \u201cThe Surprise Examination in Modal\nLogic\u201d, <em>Journal of Philosophy</em>, 65/2:\n127\u2013136.</li>\n<li>Bommarito, Nicolas, 2010, \u201cRationally Self-Ascribed\nAnti-Expertise\u201d, <em>Philosophical Studies</em>, 151:\n413\u2013419.</li>\n<li>Bovens, Luc, 1995, \u201c\u2018P and I will believe that\nnot-P\u2019: Diachronic Constraints on Rational Belief\u201d,\n<em>Mind</em>, 104(416): 737\u2013760.</li>\n<li>Burge, Tyler, 1984, \u201cEpistemic Paradox\u201d, <em>Journal\nof Philosophy</em>, 81/1: 5\u201329.</li>\n<li>\u2013\u2013\u2013, 1978a, \u201cBuridan and Epistemic\nParadox\u201d, <em>Philosophical Studies</em>, 34: 21\u201335.</li>\n<li>Buridan, John, 1982, <em>John Buridan on Self-Reference: Chapter\nEight of Buridan\u2019s \u2018Sophismata\u2019</em>, G. E. Hughes\n(ed. &amp; tr.), Cambridge: Cambridge University Press.</li>\n<li>Carnap, Rudolf, 1950, <em>The Logical Foundations of\nProbability</em>, Chicago: University of Chicago Press.</li>\n<li>Christensen, David, 2010, \u201cHigher Order Evidence\u201d,\n<em>Philosophy and Phenomenological Research</em>, 81:\n185\u2013215.</li>\n<li>Cicero, <em>On the Nature of the Gods, Academica </em>, H. Rackham\n(trans.) Cambridge, MA: Loeb Classical Library, 1933.</li>\n<li>Collins, Arthur, 1979, \u201cCould our beliefs be representations\nin our brains?\u201d, <em>Journal of Philosophy</em>, 74(5):\n225\u201343.</li>\n<li>Conee, Earl, 2004, \u201cHeeding Misleading Evidence\u201d,\n<em>Philosophical Studies</em>, 103: 99\u2013120.</li>\n<li>Cooper, John (ed.), 1997, <em>Plato: The Complete Works</em>,\nIndianapolis: Hackett.</li>\n<li>DeRose, Keith, 2017, <em>The Appearance of Ignorance: Knowledge,\nSkepticism, and Context</em> (Volume 2), Oxford: Oxford University\nPress.</li>\n<li>Egan, Andy and Adam Elga, 2005, \u201cI Can\u2019t Believe\nI\u2019m Stupid\u201d, <em>Philosophical Perspectives</em>, 19/1:\n77\u201393.</li>\n<li>Feyerabend, Paul, 1988, <em>Against Method</em>, London:\nVerso.</li>\n<li>Fitch, Frederic, 1963, \u201cA Logical Analysis of Some Value\nConcepts\u201d, <em>Journal of Symbolic Logic</em>, 28/2:\n135\u2013142.</li>\n<li>Fraser, Rachel, 2022, \u201cThe Will in Belief\u201d, <em>Oxford\nStudies in Epistemology.</em></li>\n<li>G\u00f6del, Kurt, 1983, \u201cWhat is Cantor\u2019s Continuum\nProblem?\u201d, <em>Philosophy of Mathematics</em>, Paul Benacerraf\nand Hilary Putnam (eds.), Cambridge: Cambridge University Press,\npp. 258\u2013273.</li>\n<li>Good, I. J., 1967, \u201cOn the Principle of Total\nEvidence\u201d, <em>British Journal for the Philosophy of\nScience</em>, 17(4): 319\u2013321.</li>\n<li>Hacking, Ian, 1975, <em>The Emergence of Probability</em>,\nCambridge: Cambridge University Press.</li>\n<li>Hajek, Alan, 2005, \u201cThe Cable Guy paradox\u201d,\n<em>Analysis</em>, 65(2): 112\u2013119.</li>\n<li>Harman, Gilbert, 1968, \u201cKnowledge, Inference, and\nExplanation\u201d, <em>American Philosophical Quarterly</em>, 5/3:\n164\u2013173.</li>\n<li>\u2013\u2013\u2013, 1973, <em>Thought</em>, Princeton:\nPrinceton University Press.</li>\n<li>Hawthorne, John, 2004, <em>Knowledge and Lotteries</em>, Oxford:\nClarendon Press.</li>\n<li>Hein, Piet, 1966, <em>Grooks</em>, Cambridge, MA: MIT Press.</li>\n<li>Hintikka, Jaakko, 1962, <em>Knowledge and Belief</em>, Ithaca, NY:\nCornell University Press.</li>\n<li>Holliday, Wesley, 2016, \u201cOn Being in an Undiscoverable\nPosition\u201d, <em>Thought</em>, 5(1): 33\u201340.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cEpistemic Logic and\nEpistemology\u201d, <em>The Handbook of Formal Philosophy</em>, Sven\nOve Hansson and Vincent F. Hendricks (eds.), Dordercht: Springer.</li>\n<li>Hughes, G. E., 1982, <em>John Buridan on Self-Reference</em>,\nCambridge: Cambridge University Press.</li>\n<li>Immerman, Daniel, 2017, \u201cQuestion Closure to Solve the\nSurprise Test Paradox\u201d, <em>Synthese</em>, 194(11):\n4583\u20134596.</li>\n<li>Kaplan, David and Richard Montague, 1960, \u201cA Paradox\nRegained\u201d, <em>Notre Dame Journal of Formal Logic</em>, 1:\n79\u201390.</li>\n<li>Klein, Peter, 2007, \u201cHow to be an Infinitist about Doxastic\nJustification\u201d, <em> Philosophical Studies</em>, 134:\n77\u201325\u201329.</li>\n<li>Knight, Kevin, 2002, \u201cMeasuring Inconsistency\u201d,\n<em>Journal of Philosophical Logic</em>, 31/1: 77\u201398.</li>\n<li>Kripke, Saul, 2011, \u201cTwo Paradoxes of Knowledge\u201d, in\nS. Kripke, <em>Philosophical Troubles: Collected Papers</em> (Volume\n1), New York: Oxford University Press, pp. 27\u201351.</li>\n<li>Kvanvig, Jonathan L., 1998, \u201cThe Epistemic Paradoxes\u201d,\n<em>Routledge Encyclopedia of Philosophy</em>, London: Routledge.</li>\n<li>Kyburg, Henry, 1961, <em>Probability and the Logic of Rational\nBelief</em>, Middletown: Wesleyan University Press.</li>\n<li>Lewis, David, 1998, \u201cLucas against Mechanism\u201d,\n<em>Papers in Philosophical Logic</em>, Cambridge: Cambridge\nUniversity Press, pp. 166\u20139.</li>\n<li>Lewis, David and Jane Richardson, 1966, \u201cScriven on Human\nUnpredictability\u201d, <em>Philosophical Studies</em>, 17(5):\n69\u201374.</li>\n<li>Lucas, J. R., 1964, \u201cMinds, Machines and G\u00f6del\u201d,\nin <em>Minds and Machines</em>, Alan Ross Anderson (ed.), Englewood\nCliffs, N.J.: Prentice Hall, pp. 112\u20137.</li>\n<li>Makinson, D. C., 1965, \u201cThe Paradox of the Preface\u201d,\n<em>Analysis</em>, 25: 205\u2013207.</li>\n<li>Malcolm, Norman, 1963, <em>Knowledge and Certainty</em>, Englewood\nCliffs, NJ: Prentice Hall.</li>\n<li>Moore, G. E., 1942, \u201cA Reply to My Critics\u201d, <em>The\nPhilosophy of G. E. Moore</em>, edited by P. A. Schilpp. Evanston, IL:\nNorthwestern University.</li>\n<li>Nerlich, G. C., 1961, \u201cUnexpected Examinations and\nUnprovable Statements\u201d, <em>Mind</em>, 70(280):\n503\u2013514.</li>\n<li>Peirce, Charles Sanders, 1931\u20131935, <em>The Collected Works\nof Charles Sanders Peirce</em>, Charles Hartshorne and Paul Weiss\n(eds.), Cambridge, MA: Harvard University Press.</li>\n<li>Plato, <em>Plato: The Complete Works</em>, John M. Cooper (ed.),\nIndianapolis: Hackett, 1997.</li>\n<li>Poncins, Gontran de, 1941 [1988], <em>Kabloona</em> in\ncollaboration with Lewis Galantiere, New York: Carroll &amp; Graff\nPublishers, 1988.</li>\n<li>Post, John F., 1970, \u201cThe Possible Liar\u201d,\n<em>No\u00fbs</em>, 4: 405\u2013409.</li>\n<li>Quine, W. V. O, 1953, \u201cOn a so-called Paradox\u201d,\n<em>Mind</em>, 62(245): 65\u20137.</li>\n<li>\u2013\u2013\u2013, 1969, \u201cEpistemology\nNaturalized\u201d, in <em>Ontological Relativity and Other\nEssays</em>, New York: Columbia University Press, pp. 69\u201390.</li>\n<li>\u2013\u2013\u2013, 1987, <em>Quiddities</em>, Cambridge, MA:\nHarvard University Press.</li>\n<li>Read, Stephen, 1979, \u201cSelf-Reference and Validity\u201d,\n<em>Synthese</em>, 42(2): 265\u201374.</li>\n<li>Sainsbury, R. M., 1995, <em>Paradoxes</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li>Salerno, Joseph, 2009, <em>New Essays on the Knowability\nParadox</em>, New York: Oxford University Press.</li>\n<li>Scriven, Michael, 1964, \u201cAn Essential Unpredictability in\nHuman Behavior\u201d, in <em>Scientific Psychology: Principles and\nApproaches</em>, Benjamin B. Wolman and Ernest Nagel (eds.), New York:\nBasic Books, pp. 411\u201325.</li>\n<li>Sextus Empiricus, <em>Outlines of Pyrrhonism</em>, R. G. Bury\n(trans.), Cambridge, MA: Harvard University Press, 1933.</li>\n<li>Skyrms, Brian, 1982, \u201cCausal Decision Theory\u201d,\n<em>Journal of Philosophy</em>, 79(11): 695\u2013711.</li>\n<li>Smith, Martin, 2016, <em>Between Probability and Certainty</em>,\nClarendon: Oxford University Press.</li>\n<li>Sorensen, Roy, 1988a, <em>Blindspots</em>, Oxford: Clarendon\nPress.</li>\n<li>\u2013\u2013\u2013, 1988b, \u201cDogmatism, Junk Knowledge,\nand Conditionals\u201d, <em>Philosophical Quarterly</em>, 38:\n433\u2013 454.</li>\n<li>\u2013\u2013\u2013, 2001, <em>Vagueness and Contradiction</em>,\nOxford: Clarendon Press.</li>\n<li>\u2013\u2013\u2013, 2003a, \u201cParadoxes of\nRationality\u201d, in <em>The Handbook of Rationality</em>, Al Mele\n(ed.), Oxford: Oxford University Press, pp. 257\u201375.</li>\n<li>\u2013\u2013\u2013, 2003b, <em>A Brief History of the\nParadox</em>, New York: Oxford University Press.</li>\n<li>Stephenson, Andrew, 2015, \u201cKant, the Paradox of Knowability,\nand the Meaning of Experience\u201d, <em>Philosophers Imprint</em>,\n15(17), 1\u201319.</li>\n<li>Thomson, J. F., 1962, \u201cOn Some Paradoxes\u201d, in\n<em>Analytical Philosophy</em>, R. J. Butler (ed.), New York: Barnes\n&amp; Noble, pp. 104\u2013119.</li>\n<li>Tymoczko, Thomas, 1984, \u201cAn Unsolved Puzzle about\nKnowledge\u201d, <em>The Philosophical Quarterly</em>, 34:\n437\u201358.</li>\n<li>van Fraassen, Bas, 1984, \u201cBelief and the Will\u201d,\n<em>Journal of Philosophy</em>, 81: 235\u2013256</li>\n<li>\u2013\u2013\u2013, 1995, \u201cBelief and the Problem of\nUlysses and the Sirens\u201d, <em>Philosophical Studies</em>, 77:\n7\u201337</li>\n<li>Weiss, Paul, 1952, \u201cThe Prediction Paradox\u201d,\n<em>Mind</em>, 61(242): 265\u20139.</li>\n<li>Williamson, Timothy, 2000, <em>Knowledge and its Limits</em>,\nOxford: Oxford University Press.</li>\n<li>Wynne-Tyson, Jon, 1985, <em>The Extended Circle</em>, Fontwell,\nSussex: Centaur Press.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "fatalism",
            "Fitch\u2019s paradox of knowability",
            "logic: epistemic",
            "logic: of belief revision",
            "probability, interpretations of",
            "prophecy",
            "self-reference",
            "skepticism",
            "suspense, paradox of",
            "vagueness"
        ],
        "entry_link": [
            {
                "../fatalism/": "fatalism"
            },
            {
                "../fitch-paradox/": "Fitch\u2019s paradox of knowability"
            },
            {
                "../logic-epistemic/": "logic: epistemic"
            },
            {
                "../logic-belief-revision/": "logic: of belief revision"
            },
            {
                "../probability-interpret/": "probability, interpretations of"
            },
            {
                "../prophecy/": "prophecy"
            },
            {
                "../self-reference/": "self-reference"
            },
            {
                "../skepticism/": "skepticism"
            },
            {
                "../paradox-suspense/": "suspense, paradox of"
            },
            {
                "../vagueness/": "vagueness"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemic-paradoxes\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/epistemic-paradoxes/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=epistemic-paradoxes&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/epistemic-paradoxes/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemic-paradoxes": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/epistemic-paradoxes/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=epistemic-paradoxes&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/epistemic-paradoxes/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "<a href=\"http://campuspress.yale.edu/keithderose/the-epistemology-page/\" target=\"other\">Epistemology Page</a>,\n maintained by Keith De Rose (Yale University).",
            "<a href=\"http://www.ucs.louisiana.edu/~kak7409/EpistemologicalResearch.htm\" target=\"other\">The Epistemology Research Guide</a>,\n maintained by Keith Korcz (University of Louisiana/Lafayette).",
            "<a href=\"http://barryispuzzled.com/zbeauty.htm\" target=\"other\">The Sleeping Beauty Problem</a>,\n maintained by Barry R. Clarke."
        ],
        "listed_links": [
            {
                "http://campuspress.yale.edu/keithderose/the-epistemology-page/": "Epistemology Page"
            },
            {
                "http://www.ucs.louisiana.edu/~kak7409/EpistemologicalResearch.htm": "The Epistemology Research Guide"
            },
            {
                "http://barryispuzzled.com/zbeauty.htm": "The Sleeping Beauty Problem"
            }
        ]
    }
}