{
    "url": "logic-information",
    "title": "Logic and Information",
    "authorship": {
        "year": "Copyright \u00a9 2023",
        "author_text": "Maricarmen Martinez\n<m.martinez@uniandes.edu.co>\nSebastian Sequoiah-Grayson\n<sequoiah@gmail.com>",
        "author_links": [
            {
                "mailto:m%2emartinez%40uniandes%2eedu%2eco": "m.martinez@uniandes.edu.co"
            },
            {
                "mailto:sequoiah%40gmail%2ecom": "sequoiah@gmail.com"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2023</a> by\n\n<br/>\nMaricarmen Martinez\n&lt;<a href=\"mailto:m%2emartinez%40uniandes%2eedu%2eco\"><em>m<abbr title=\" dot \">.</abbr>martinez<abbr title=\" at \">@</abbr>uniandes<abbr title=\" dot \">.</abbr>edu<abbr title=\" dot \">.</abbr>co</em></a>&gt;<br/>\nSebastian Sequoiah-Grayson\n&lt;<a href=\"mailto:sequoiah%40gmail%2ecom\"><em>sequoiah<abbr title=\" at \">@</abbr>gmail<abbr title=\" dot \">.</abbr>com</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Mon Feb 3, 2014",
        "substantive revision Thu Aug 3, 2023"
    ],
    "preamble": "\n\nAt their most basic, logic is the study of consequence, and\ninformation is a commodity. Given this, the interrelationship between\nlogic and information will centre on the informational consequences of\nlogical actions or operations conceived broadly. The explicit\ninclusion of the notion of information as an object of\nlogical study is a recent development. It was by the beginning of the\npresent century that a sizable body of existing technical and\nphilosophical work (with precursors that can be traced back to the\n1930s) coalesced into the new emerging field of logic and information\n(see Dunn 2001). This entry is organised thematically, rather than\nchronologically. We survey major logical approaches to the study of\ninformation, as well as informational understandings of logics\nthemselves. We proceed via three interrelated and complementary\nstances: information-as-range, information-as-correlation, and\ninformation-as-code.\n\nThe core intuition motivating the Information-as-range\nstance, is that an\ninformational state may be characterised by the range of possibilities\nor configurations that are compatible with the information available\nat that state. Acquiring new information corresponds to a reduction of\nthat range, thus reducing uncertainty about the actual configuration\nof affairs. With this understanding, the setting of possible-world\nsemantics for epistemic modal logics proves to be rewarding for the\nstudy of various semantic aspects of information. A prominent\nphenomenon here is information update, which may occur in\nboth individual and social settings, due to the interaction between\nboth agents and their environment via different types of epistemic\nactions. We will see that an epistemic action is any action that\nfacilitates the flow of information, hence we will return to epistemic\nactions themselves throughout.\n\nThe Information-as-correlation stance focuses\non information flow as it is licensed within structured systems formed\nby systematically correlated components. For example: the number of\nrings of a tree trunk can give you information about the time when the\ntree was born, in virtue of certain regularities of nature that\n\u2018connect\u2019 the past and present of trees. Central themes of\nthis stance include the aboutness, situatedness, and accessibility\nof information in structured information environments.\n\nThe key concern of the third stance, Information-as-code,\nis the syntax-like\nstructure of information pieces (their encoding) and the\ninference and computation processes that are licensed by\nvirtue (among other things) of that structure. A most natural logical\nsetting to study these informational aspects is the algebraic proof\ntheory underpinned by a range of substructural logics.\nSubstructural logics have always been a natural home for informational\nanalysis, and the recent developments in the area enrich the\ninformation-as-code stance.\n\nThe three stances are by no means incompatible, but neither are they\nnecessarily reducible to each other. This will be expanded on later in\nthe entry, and some further topics of research will be illustrated,\nbut for a preview of how the three stances can live together, take the\ncase of a structured information system composed of several parts.\nFirstly, the correlations between the parts naturally allow for\n\u2018information flow\u2019 in the sense of the\ninformation-as-correlation stance. Secondly, they also give rise to a\nlocal ranges of possibilities, since the local information available\nat one part will be compatible with a certain range of global states\nof the system. Thirdly, the combinatorial, syntax-like,\nproof-theoretical aspects of information can be brought to this\nsetting in various ways. One of them is treating the correlational\nflow of information as a sort of combinatorial system by which local\ninformation states are combined in syntactic-like ways, fitting a\nparticular interpretation of substructural logic. One could also add\ncode-like-structure to the modelling explicitly, for example by\nassigning local deductive calculi to either the components or local\nstates of the system. We begin however with information as\nrange\n",
    "toc": [
        {
            "#SemInfRan": "1. Information as Range"
        },
        {
            "#EpiLog": "1.1 Epistemic logic"
        },
        {
            "#DynEpiLogInfCha": "1.2 Dynamic epistemic logic, information change"
        },
        {
            "#QuaApp": "1.3 Quantitative Approaches"
        },
        {
            "#InfCorSitThe": "2. Information as Correlation: Situation Theory"
        },
        {
            "#SitSupInf": "2.1 Situations and Supporting Information"
        },
        {
            "#InfFloCon": "2.2 Information flow and constraints"
        },
        {
            "#DisInfSysChaThe": "2.3 Distributed information systems and channel theory"
        },
        {
            "#InfCod": "3. Information as Code"
        },
        {
            "#CatInfThe": "3.1 Categorial Information Theory"
        },
        {
            "#SubLogInfFlo": "3.2 Substructural logics and information flow"
        },
        {
            "#RelApp": "3.3 Related Approaches"
        },
        {
            "#ConBetApp": "4. Connections Between the Approaches"
        },
        {
            "#RanCor": "4.1 Ranges and correlations"
        },
        {
            "#CodCor": "4.2 Code and correlations"
        },
        {
            "#CodRan": "4.3 Code and ranges"
        },
        {
            "#SpeTop": "5. Special topics"
        },
        {
            "#InfStrEqu": "5.1 Information Structures and Equivalence"
        },
        {
            "#NegInf": "5.2 Negative information"
        },
        {
            "#Con": "6. Conclusion"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. Information as Range\n\nThe understanding of information as range has its origins in\nBar-Hillel and Carnap\u2019s theory of semantic information,\nBar-Hillel and Carnap\n (1952).[1]\n It is here that the inverse range principle is given its\nfirst articulation with regard to the informational content of a\nproposition. The inverse range principle states that there is an\ninverse relationship between the information contained by a\nproposition on the one hand, and the likelihood of that proposition\nbeing true on the other. That is, the more information carried by a\nproposition, the less likely it is that the proposition is true.\nSimilarly, the more likely the truth of a proposition, the less\ninformation it carries.\n\nThe likelihood of the truth of a proposition connects with information\nas range via a possible worlds semantics. For any contingent\nproposition, it will be supported by some possibilities (those where\nit is true) and not supported by others (those where it is false).\nHence a proposition will be supported by a range of possibilities, an\n\u201cinformation range\u201d. Now suppose that there is a\nprobability distribution across the space of possibilities, and for\nthe sake of simplicity suppose that the distribution is uniform. In\nthis case, the more worlds that support a proposition, the likelier\nthe proposition\u2019s truth, and, via the inverse relationship\nprinciple, the less information it carries. Although information as\nrange has its origins in quantitative information theory, its role in\ncontemporary qualitative logics of information cannot be\noverstated.\n\nConsider the following example due to Johan van Benthem (2011). A\nwaiter in a cafe receives an order for your table\u2014an espresso\nand a soda. When the waiter arrives at your table, he asks \u201cFor\nwhom is the soda?\u201d. After your telling him that the soda is for\nyou and his giving you your soda, the waiter does not need to ask\nabout the espresso, he can just give it to your cafe-partner. This is\nbecause the information gained by the waiter from your telling him\nthat you ordered the soda allows him to eliminate certain open\npossibilities from the total range of possibilities such that only one\nis left\u2014your friend ordered the espresso.\n\nThe waiter case brings several facts about logic and information to\nthe fore. For one, language is used often to refine informational\noptions in the very way explained in the paragraph above. More subtly\nhowever, and perhaps even prior to this, language is used to\nexchange information, and we bring with us sometimes many\nscenarios\u2014specified informationally. These scenarios might be\nneither known nor believed, but merely\nentertained\u2014those about which we wonder.\nRecent work on inquisitive semantics (Ciardelli et\nal. 2018) provides a logic of such information exchange based on\ninformational specifications of such wonderings.\n\nLogics of information distinguish regularly between hard\ninformation and soft information. The terminology is a\nslight misnomer, as this distinction is not one between different\ntypes of information per se. Rather it is one between\ndifferent types of information storage. Hard information is\nfactive, and unrevisable. Hard information is often taken to\ncorrespond to knowledge. In contrast to hard information,\nsoft information is non-necessarily-factive, hence revisable\nin the presence of new information. Soft information, in virtue of its\nrevisability, corresponds very closely to belief. The terms\nknowledge and belief are conventional, but on the context of\ninformation flow, the hard/soft information reading is convenient on\naccount of it bringing the informational phenomena to the foreground.\nAt the very least the terminology is increasingly popular, so being\nclear on the distinction being one between types of information\nstorage as opposed to types of information is important. Although both\nhard and soft information are important for our epistemic and doxastic\nsuccess, in this section we will concentrate mainly on logics of hard\ninformation\n flow.[2]\n\nIn\n section 1.1\n we will see how it is that classic epistemic logics exemplify the\nflow of hard information within the information as range framework. In\n section 1.2\n we will extend our exposition from logics of hard information-gain to\nlogics of the actions that facilitate the gain of such hard\ninformation, dynamic epistemic logics. At the end of Section 1.2, we\nwill expound the important phenomenon of private information,\nbefore examining how it is that information as range is captured in\nvarious quantitative frameworks.\n1.1 Epistemic logic\n\nIn this section we will explore how it is that the elimination of\npossibilities corresponding to information-gain is the starting point\nfor research on logics of knowledge and belief that fall under the\nheading of epistemic logics. We will begin with classic\nsingle-agent epistemic logic, before exploring multi-agent epistemic\nlogics. In both cases, since we will be concentrating on logics of\nknowledge as opposed to logics of belief, the information-gained will\nbe hard information.\n\nConsider the waiter example in more detail. Before receiving the hard\ninformation that the soda is for you (and for the sake of the example\nwe are assuming that the waiting is dealing with hard information\nhere), the waiter\u2019s knowledge-base is modelled by a pair of\nworlds (hereafter information states) \\(x\\) and \\(y\\) such\nthat in \\(x\\) you ordered the soda and your friend the espresso, and\nin \\(y\\) you ordered the espresso and your friend the soda. After\nreceiving the hard information that the soda is for you, \\(y\\) is\neliminated from the waiter\u2019s knowledge-base, leaving only \\(x\\).\nAs such, the reduction of the range of possibilities corresponds to an\ninformation-gain for the waiter. Consider the truth condition for\nagent \\(\\alpha\\) knows that \\(\\phi\\), written\n\\(K_{\\alpha}\\phi\\): \n\\[\\tag{1} x \\Vdash K_{\\alpha}\\phi \\text{ iff\nfor all } y \\text{ s.t. (such that) } R_{\\alpha}xy, y \\Vdash \\phi \\]\n\n\nThe accessibility relation \\(R_{\\alpha}\\) is an equivalence relation\nconnecting \\(x\\) to all information states \\(y\\) such that \\(y\\) is\nindistinguishable from \\(x\\), given \\(\\alpha\\)\u2019s\nhard information at that state \\(x\\). That is, given what the\nwaiter knows when he is in that state. So, if \\(x\\) was the\nwaiter\u2019s information state before being informed that you\nordered the soda, \\(y\\) would have included the information that you\nordered the espresso, as each option was as good as the other until\nthe waiter was informed otherwise. There is an implicit assumption at\nwork here\u2014that some state \\(z\\) say, where you ordered both the\nsoda and the espresso, is not in the waiter\u2019s information-range.\nThat is, the waiter knows that \\(z\\) is not a possibility. Once\ninformed however, the information states supporting your ordering the\nespresso are eliminated from the range of information corresponding to\nthe waiter\u2019s knowledge.\n\nBasic modal logic extends propositional formulas with modal operators\nsuch as \\(K_{\\alpha}\\). If \\(\\mathbf{K}\\) is the set of all Kripke\nmodels then we have the following: \n\\[\\begin{align} \\tag{A1} &\\mathbf{K} \\Vdash K_{\\alpha}\\phi \\wedge\nK_{\\alpha}(\\phi \\rightarrow \\psi) \\rightarrow K_{\\alpha}\\psi \\\\\n\\tag{A2} & \\mathbf{K} \\Vdash \\phi \\Rightarrow \\mathbf{K} \\Vdash\nK_{\\alpha}\\phi \\end{align}\\]\n\n\nIn hard information terms, (A1) states that hard information is closed\nunder (known) implications. Since the first conjunct states that all\nstates accessible by \\(\\alpha\\) are \\(\\phi\\) states, \\(\\alpha\\)\npossesses the hard information that \\(\\phi\\), hence \\(\\alpha\\) also\npossesses the hard information that \\(\\psi\\). (A2) states that if\n\\(\\phi\\) holds in the set of all models, then \\(\\alpha\\) possesses the\nhard information that \\(\\phi\\). In other words, (A2) states that all\ntautologies are known/hard stored by the agent, and (A1) states that\n\\(\\alpha\\) knows the logical consequences of all propositions that\n\\(\\alpha\\) knows (be they tautologies or otherwise). That is, the\naxioms state that the agent is logical omniscient, or an ideal\nreasoner, a property of agents that we will return to in detail\nin the sections\n below.[3]\n\nThe framework explored so far concerns single-agent epistemic logic,\nbut reasoning and information flow are very often multi-agent\naffairs. Consider again the waiter example. Importantly, the\nwaiter is only able to execute the relevant reasoning procedure\ncorresponding to a restriction of the range of information states\non account of your announcement to him with regard to the\nespresso. That is, it is the verbal interaction between several agents\nthat facilitates the information flow that enabled the logical\nreasoning to be undertaken.\n\nIt is at this point that multi-agent epistemic logic raises new\nquestions regarding the information in a group. \u201cEverybody in\n\\(G\\) possesses the hard information that \\(\\phi\\)\u201d (where \\(G\\)\nis any group of agents from a finite set of agents \\(G^*)\\) written as\n\\(E_G\\phi . E_G\\) is defined for each \\(G \\subseteq G^*\\) in the\nfollowing manner: \n\\[\\tag{2} E_G\\phi = \\bigwedge_{\\alpha \\in G} K_{\\alpha}\\phi \\]\n\n\nGroup knowledge is importantly different from common\nknowledge (Lewis 1969; Fagin et al. 1995). Common knowledge is\nthe condition of the group where everybody knows that everybody\nknows that everybody knows \u2026 that \\(\\phi\\). In other\nwords, common knowledge concerns the hard information that each agent\nin the group possesses about the hard information possessed by the\nother members of the group. That everybody in \\(G\\) possesses the hard\ninformation that \\(\\phi\\) does not imply that \\(\\phi\\) is common\nknowledge. With group knowledge each agent in the group may possess\nthe same hard information (hence achieving group knowledge) without\nnecessarily possessing hard information about the hard information\npossessed by the other agents in the group. As noted by van Ditmarsh,\nvan der Hoek, and Kooi (2008: 30), \u201cthe number of iterations of\nthe \\(E\\)-operator makes a real difference in practice\u201d.\n\\(C_G\\phi\\)\u2014the common knowledge that \\(\\phi\\) for\nmembers of \\(G\\), is defined as follows: \n\\[\\tag{3} C_G\\phi = \\bigwedge_{n=0}^{\\infty} E^n_G \\phi \\]\n\n\nTo appreciate the difference between \\(E\\) and \\(C\\), consider the\nfollowing \u201cspy example\u201d (originally Barwise 1988 with the\nenvelope details due to Johan van Benthem).\n\nThere are a group of competing spies at a formal dinner. All of them\nare tasked with the mission of acquiring some secret information from\ninside the restaurant. Furthermore, it is common knowledge amongst\nthem that they want the information. Given this much, compare the\nfollowing:\n\nEach spy knows that the information is in an envelope on one of\nthe other tables, but they don\u2019t know that the other spies know\nthis (i.e., it is not common knowledge).\nIt is common knowledge amongst the spies that the information is\nin the envelope.\n\n\nVery obviously, the two scenarios will elicit very different types of\nbehaviour from the spies. The first would be relatively subtle, the\nlatter dramatically less so. See Vanderschraaf and Sillari (2009) for\nfurther details.\n\nA still more fine-grained use of S5 based epistemic logics is that of\nZhou (2016). Zhou demonstrates that S5 based epistemic logic may be\nused to model the epistemic states of the agent from the perspective\nof the agent themselves. Hence Zhou refers to such an epistemic logic\nas internally epistemic. Zhou then uses a multi-valued logic\nto model the relationship between the agent\u2019s internal knowledge\nbase and their external informational environment. In his (2019), van\nBenthem argues for an understanding of modal logics in general (both\nepistemic and otherwise) as ariing from an explicit approach\nto increasing a logic\u2019s conceptual nuance \u2014 in the sense\nthat they are explicit extensions of classical logic. They wear their\nnew conceptual architechture on their sleaves, so to speak. This is in\ncontrast to those logics to which van Benthem refers as resulting from\nan implicit approach. This implicit approach invloves a\nreinterpretation of the meaning of logical vocabulary, as is the case\nwith intuitionistic logic and relevant logic as conceived of\ntraditionally. van Benthem\u2019s method of translating between\nequivalient (in a sense) implicit and explicit approaches has as an\ninstance that between Kit Fine\u2019s (2017) hyperintensional\ntruth-maker semantics and informationalised modal logic. This is a\npromising foray into such translations between a range of information\nlogics such as those addressed in this entry. \n1.2 Dynamic epistemic logic, information change\n\nSee the full entry on\n Dynamic Epistemic Logic.\n As noted above, the waiter example from the beginning of this section\nis as much about information-gain via announcements, epistemic\nactions, as it is about information structures. In this section,\nwe will outline how it is that the expressive power of multi-agent\nepistemic logic can be extended so as to capture epistemic\nactions.\n\nHard information flow, that is, the flow of information between the\nknowledge states of two or more agents, can be facilitated by more\nthan one epistemic action. Two canonical examples are\nannouncements and observations. When\n\u201cannouncement\u201d is restricted to true and public\nannouncement, its result on the receiving agent\u2019s\nknowledge-base is similar to that of an observation (on the assumption\nthat the agent believes the content of the announcement). The public\nannouncement that \\(\\phi\\) will restrict the model of the\nagent\u2019s knowledge-base to the information states where \\(\\phi\\)\nis true, hence \u201cannounce \\(\\phi\\)\u201d is an epistemic\nstate transformer in the sense that it transforms the epistemic\nstates of the agents in the group, (see van Ditmarsh, van der Hoek,\nand Kooi 2008:\n 74).[4]\n\nDynamic epistemic logics extend the language of non-dynamic epistemic\nlogics with dynamic operators. In particular, public announcement\nlogic (PAL) extends the language of epistemic logics with the\ndynamic announcement operator [\\(\\phi\\)], where [\\(\\phi]\\psi\\) is read\n\u201cafter announcement \\(\\phi\\), it is the case that\n\\(\\psi\\)\u201d. The key reduction axioms of PAL are as\nfollows: \n\\[\\begin{alignat}{2}\n\\tag{RA1} &[\\phi]p &\\text{ iff } &\\phi \\rightarrow p \\text{ (where \\(p\\) is atomic)} \\\\\n \\tag{RA2} &[\\phi]\\neg \\psi &\\text{ iff } &\\phi \\rightarrow \\neg[\\phi]\\psi \\\\\n \\tag{RA3} &[\\phi](\\psi \\wedge \\chi) &\\text{ iff } &[\\phi]\\psi \\wedge[\\phi]\\chi \\\\\n \\tag{RA4} &[\\phi][\\psi]\\chi &\\text{ iff } &[\\phi \\wedge[\\phi]\\psi]\\chi \\\\\n \\tag{RA5} &[\\phi]K_{\\alpha}\\psi &\\text{ iff } &\\phi \\rightarrow K_{\\alpha}(\\phi \\rightarrow [\\phi]\\psi) \n\\end{alignat}\\]\n\n\nRA1\u2013RA5 capture the properties of the announcement operator by\nconnecting what is true before the announcement with what is true\nafter the announcement. The axioms are named \u2018reduction\u2019\naxioms because the left-to-right hand direction reduces either the\nnumber of announcement operators or the complexity of the formulas\nwithin their scope. For an in depth discussion see Pacuit (2011). RA1\nstates that announcements are truthful. RA5 specifies the\nepistemic-state-transforming properties of the announcement operator.\nIt states that \\(\\alpha\\) knows that \\(\\psi\\) after the announcement\nthat \\(\\phi\\) iff \\(\\phi\\) implies that \\(\\alpha\\) knows that\n\\(\\psi\\) will be true after \\(\\phi\\) is announced in all\n\\(\\phi\\)-states. The \u201cafter \\(\\phi\\) is announced\u201d\ncondition is there to account for the fact that \\(\\psi\\) might change\nits truth-value after the announcement. The interaction between the\ndynamic announcement operator and the knowledge operator is described\ncompletely by RA5 (see van Benthem, van Eijck, and Kooi 2006).\n\nJust as adding the common knowledge operator \\(C\\) to\nmulti-agent epistemic logic extends the expressive capabilities of\nmulti-agent epistemic logic, adding \\(C\\) to PAL results in the more\nexpressive public announcement logic with common knowledge,\n(PAC). The exact relationship between public announcements and common\nknowledge is captured by the announcement and common knowledge\nrule of the logic PAC as the following: \n\\[\\tag{4} \\text{From } \\chi \\rightarrow[\\phi]\\psi \\text{ and } (\\chi \\wedge \\phi) \\rightarrow E_G\\chi, \\text{ infer } \\chi \\rightarrow [\\phi]C_G\\psi. \\]\n\n\nAgain, PAC is the dynamic logic of hard information. The epistemic\nlogics dealing with soft information fall within the scope of\nbelief revision theory (van Benthem 2004; Segerberg 1998).\nRecall that hard and soft information are not distinct types of\ninformation per se, rather they are distinct types of\ninformation storage. Hard-stored information is unrevisable,\nwhereas soft-stored information is revisable. Variants of PAL that\nmodel soft information augment their models with\nplausibility-orderings on information-states (Baltag and Smets 2008).\nThese orderings are known as preferential models in\nnon-monotonic logic and belief-revision theory. The logics can be made\ndynamic in virtue of the orderings changing in the face of new\ninformation (which is the mark of soft information as opposed to hard\ninformation). Such plausibility-orderings may be modelled\nqualitatively via partial orders etc., or modelled quantitatively via\nprobability-measures. Such quantitative measures provide a connection\nto a broader family of quantitative approaches to semantic information\nthat we will examine below. Recent work by Allo (2017) ties the soft\ninformation of dynamic epistemic logic to non-monotonic logics. This\nis an intuitive move. Soft information is information that has been\nstored in a revisable way, hence the revisable nature of conclusions\nin non-monotonic arguments makes non-monotonic logics a natural fit.\nOn this very topic, see also Chapter 13.7 of van Benthem (2011).\n\nPrivate information. Private information is\nan equally important aspect of our social interaction. Consider\nscenarios where the announcing agent is aware of the private\ncommunication whilst other members of the group are not, such as\nemails in Bcc. Consider also scenarios where the sending agent is\nnot aware of the private communication, such as a\nsurveillance operation. The system of dynamic epistemic logic\n(DEL) models events that turn on private (and public) information by\nmodelling the agents\u2019 information concerning the events\ntaking place in a given communicative scenario (see Baltag et\nal. 2008; van Ditmarsh et al. 2008; and Pacuit 2011). For an excellent\noverview and integration of all of the issues above, see the recent\nwork of van Benthem (2016), where the author discusses multiple\ninterrelated levels of logical dynamics, one level of update, and\nanother of representation. For an extensive collection of papers\nextending this and related approaches, see Baltag and Smets (2014).\nAlthough research into public and private information, most especially\nwith regard to information crossing the threshold from one to the\nother, has been carried out within the framework of dynamic epistemic\nlogics, recent work explores public and private information and\nannouncements within the framework of multi-valued logics.\nSee Yang et al. (2021).\n\nThe modal information theory approach to multi-agent information flow\nis the subject of a great amount of research. The semantics is not\nalways carried out in relational terms (i.e., with Kripke Frames) but\nis done often algebraically (see Blackburn et al. 2001 for details of\nthe algebraic approach to modal logic). For more details on algebraic\nas well as type-theoretic approaches, see the subsection on algebraic\nand other approaches to modal information theory in the supplementary\ndocument\n Abstract Approaches to Information Structure.\n1.3 Quantitative Approaches\n\nQuantitative approaches to information as range also have\ntheir origins in the inverse relationship principle. To\nrestate\u2014the motivation being that the less likely the truth of a\nproposition as expressed in a logical language with respect to a\nparticular domain, the greater the amount of information encoded by\nthe relevant formula. This is in contrast to the information measures\nin the mathematical theory of communication (Shannon 1953\n[1950]) where such measures are gotten via an inverse relationship on\nthe expectation of the receiver \\(R\\) of the receipt of a signal from\nsome source \\(S\\).\n\nAnother important aspect of the classical theory of information, is\nthat it is an entirely static theory\u2014it is concerned\nwith the informational content and measure of particular formulas, and\nnot with information flow in any way at all.\n\nThe formal details of classical information theory turn on the\nprobability calculus. These details may be left aside here, as the\nobvious conceptual point is that logical truths have a\ntruth-likelihood of 1, and therefore an information measure of 0.\nBar-Hillel and Carnap did not take this to mean that logical truths,\nor deductions, were without information yield, only that their theory\nof semantic information was not designed to capture such a property.\nThey referred to such a property with the term psychological\ninformation. See Floridi (2013) for further details.\n\nA quantitative attempt at specifying the information yield of\ndeductions was undertaken by Jaakko Hintikka with his theory of\nsurface information and depth information (Hintikka\n1970, 1973). The theory of surface and depth information extends\nBar-Hillel and Carnap\u2019s theory of semantic information from the\nmonadic predicate calculus all the way up to the full polyadic\npredicate calculus. This itself is a considerable achievement, but\nalthough technically astounding, a serious restriction of this\napproach is that it is only a fragment of the deductions carried out\nwithin full first-order logic that yield a non-zero information\nmeasure. The rest of the deductions in the full polyadic predicate\ncalculus, as well as all of those in the monadic predicate calculus\nand propositional calculus, measure 0, (see Sequoiah-Grayson 2008).\nFor recent elaborations upon Hintikka\u2019s distinction between\nsuface and depth information, both formal and philosophical, see\nPanahy (2023), Hernandez and Quiroz (2022 [Other Internet Resources]),\nNegro (2022), and Ramos Mendon\u00e7a (2022).\n\nThe obvious inverse situation with the theory of classical semantic\ninformation is that logical contradictions, having a truth-likelihood\nof 0, will deliver a maximal information measure of 1. Referred to in\nthe literature as the Bar-Hillel-Carnap Semantic Paradox, the\nmost developed quantitative approach to addressing it is the theory of\nstrongly semantic information (Floridi 2004). The conceptual\nmotivation behind strongly semantic information is that for a\nstatement to yield information, it must help us to narrow down the set\nof possible worlds. That is, it must assist us in the search for the\nactual world, so to speak (Sequoiah-Grayson 2007). Such a\ncontingency requirement on informativeness is violated by\nboth logical truths and logical contradictions, both of which measure\n0 on the theory of strongly semantic information. See Floridi (2013)\nfor further details. See also Brady (2016) for recent work on the\nrelationship between quantitative accounts of information and\nanalyticity. For a new approach to connecting quantitative and\nqualitative measures of information, see Harrison-Trainor et\nal. (2018)\n2. Information as Correlation: Situation Theory\n\nThe correlational take on information looks at how the existence of\nsystematic connections between the parts of a structured\ninformation environment permits that one part may carry\ninformation about another. For example: the pattern of pixels\nthat appear on the screen of a computer gives information (not\nnecessarily complete) about the sequence of keys that were\npressed by the person who is typing a document, and even a partial\nsnapshot of the clear starred sky your friend is looking at now will\ngive you information about his possible locations on Earth at\nthis moment. The focus on structured environments and the aboutness of\ninformation goes hand in hand with a third main topic of the\ninformation-as correlation approach, namely the situatedness of\ninformation, that is, its dependence on the particular setting on\nwhich an informational signal occurs. Take the starry sky as an\nexample again: the same pattern of stars, at different moments in time\nand locations in space will in general convey different information\nabout the location of your friend.\n\nHistorically, the first paradigmatic setting of correlated information\nwas Shannon\u2019s work on communication (1948), which we already\nmentioned in the last section. Shannon considered a communication\nsystem formed by two information sites, a source and a receiver,\nconnected via a noisy channel. He gave conclusive and extremely useful\nanswers to questions having to do with the construction of\ncommunication codes that help maximising the effectiveness of\ncommunication (in terms of bits of information that can be\ntransmitted) while minimizing the possibility of errors caused by\nchannel noise. As we previously said, Shannon\u2019s concern was\npurely quantitative. The logical approach to information as\ncorrelation builds on Shannon\u2019s ideas, but is concerned with\nqualitative aspects of information flow, like the ones we highlighted\nbefore: what information about a\n\u2018remote\u2019 site (remote in terms of space, time,\nperspective, etc.) can be drawn out of information that is directly\navailable at a \u2018proximal\u2019 site?\n\nSituation theory (Barwise and Perry 1983; Devlin 1991) is the\nmajor logical framework so far that has made these ideas its starting\npoint for an analysis of information. Its origin and some of its\ncentral insights can be found in the project of naturalization of mind\nand the possibility of knowledge initiated by Fred Dretske (1981),\nwhich soon influenced the inception of situation semantics in the\ncontext of natural language (see Kratzer 2011).\n\nTechnically, there are two kinds of developments in situation\ntheory:\n\nSet-theoretic and model-theoretic frameworks based on detailed\nontologies, suitable for modelling informational phenomena in concrete\napplications.\nA mathematical theory of information flow as enabled by lawful\nchannels that connect parts of a whole. This theory takes a\nmore abstract view on information as correlation, which is applicable\n(in principle) to all sorts of systems that can be decomposed into\ninterrelated parts.\n\n\nThe next three subsections survey some of the basic notions from this\ntradition: the basic sites of information in situation theory (called\nsituations), the basic notion of information flow based on\ncorrelations between situations, and the mathematical theory of\nclassifications and channels mentioned in (b).\n2.1 Situations and Supporting Information\n\nThe ontologies in (a) span a wide spectrum of entities. They are meant\nto reflect a particular way in which an agent may carve up a system.\nHere \u201ca system\u201d can be the world, or a part or aspect of\nit, while the agent (or kind of agent) can be an animal species, a\ndevice, a theorist, etc. The list of basic entities includes\nindividuals, relations (which come with roles attached to them),\ntemporal and spacial locations, and various other things. Distinctive\namong them are the situations and infons.\n\nRoughly speaking, situations are highly structured parts of a system,\nsuch as a class session, a scene as seen from a certain perspective, a\nwar, etc. Situations are the basic supporters of information. Infons,\non the other hand, are the informational issues that situations may or\nmay not support. The simplest kind of informational issue is whether\nsome entities \\(a_1 , \\ldots ,a_n\\) stand (or do not stand) in a\nrelation \\(R\\) when playing the roles \\(r_1 , \\ldots ,r_n\\),\nrespectively. Such basic infon is usually denoted as \n\\[ \\llangle R, r_1 : a_1 , \\ldots ,r_n : a_n, i\\rrangle. \\]\n\n\nwhere \\(i\\) is 1 or 0, according to whether the issue is positive or\nnegative.\n\nInfons are not intrinsic bearers of truth, and they are not claims\neither. They are simply informational issues that may or may not be\nsupported by particular situations. We\u2019ll write \\(s \\models\n\\sigma\\) to mean that the situation \\(s\\) supports the infon\n\\(\\sigma\\). As an example, a successful transaction whereby Mary\nbought a piece of cheese in the local market is a situation that\nsupports the infon \n\\[ \\sigma = \\llangle bought, what : cheese, who : Mary, 1\\rrangle. \\]\n\n\nThis situation does not support the infon \n\\[ \\llangle bought, what : cheese, who : Mary, 0\\rrangle \\]\n\n\nbecause Mary did buy cheese. Nor does the situation support the\ninfon \n\\[ \\llangle landed, who : Armstrong, where : Moon, 1\\rrangle, \\]\n\n\nbecause Armstrong is not part of the situation in question at all.\n\nThe discrimination or individuation of a situation by an agent does\nnot entail that the agent has full information about it: when we\nwonder whether the local market is open, we have individuated a\nsituation about which we actually lack some information. See\nTextor (2012) for a detailed discussion on the nature of\nsituation-like entities and their relation with other ontological\ncategories such as the possible worlds used in modal logic.\n\nBesides individuals, relations, locations, situations and basic\ninfons, there are various kinds of parametric and abstract entities.\nFor example, there is a mechanism of type abstraction.\nAccording to it, if \\(y\\) is a parameter for situations, then\n\n\\[ T_y = [y \\mid y \\models \\llangle bought, what : cheese, who : x, 1\\rrangle] \\]\n\n\nis the type of situations where somebody buys cheese. There will be\nsome basic types in an ontology, and many other types obtained via\nabstraction, as just described.\n\nThe collection of ontology entities also includes propositions and\nconstraints. They are key in the formulation of the basic principles\nof information content in situation theory, to be introduced next.\n2.2 Information flow and constraints\n\nThe following are typical statements about \u201cinformation\nflow\u201d as studied in situation theory:\n\n[E1] \nThe fact that the dot in the radar screen is moving upward indicates\nthat flight A123 is moving northward. \n[E2] \nThe presence of footprints of pattern \\(P\\) in Zhucheng indicates that\na dinosaur lived in the region millions of years ago. \n\n\nThe general scheme has the form\n\n[IC] \nThat \\(s : T\\) indicates that \\(p\\). \n\n\nwhere \\(s : T\\) is notation for \u201c\\(s\\) is of type \\(T\\)\u201d.\nThe idea is that it is concrete parts of the world that act as\ncarriers of information (the concrete dot in the radar or the\nfootprints in Zhucheng), and that they do so by virtue of being of a\ncertain type (the dot moving upward or the footprints showing a\ncertain pattern). What each of these concrete instances indicates is a\nfact about another correlated part of the world. For the issues to be\ndiscussed below it will suffice to consider cases where the indicated\nfact\u2014 \\(p\\) in the formulation of [IC]\u2014is\nof the form \\(s' : T '\\), as in the radar example.\n\nThe conditions needed to verify informational signalling in the sense\nof [\\(\\mathbf{IC}\\)] rely on the existence of law-like\nconstraints such as natural laws, necessary laws such as\nthose of math, or conventions, thanks to which (in part) one situation\nmay serve as carrier of information about another one. Constraints\nspecify the correlations that exist between situations of\nvarious types, in the following sense: if two types \\(T\\) and \\(T '\\)\nare subject to the constraint \\(T \\Rightarrow T '\\), then for every\nsituation \\(s\\) of type \\(T\\) there is a relevantly connected\nsituation \\(s'\\) of type \\(T '\\). In the radar example, the relevant\ncorrelation would be captured by the constraint GoingUpward\n\\(\\Rightarrow\\) GoingNorth,\nwhich says that each situation where a\nradar point moves upward is connected with another situation where a\nplane is moving to the north. It is the existence of this constraint\nthat allows a particular situation where the dot moves to indicate\nsomething about the connected plane situation.\n\nWith this background, the verification principle for information\nsignalling in situation theory can be formulated as follows:\n\n[IS Verification] \\(s : T\\) indicates that \\(s' :\nT'\\) if \\(T \\Rightarrow T '\\) and \\(s\\) is relevantly\nconnected to \\(s'\\).\n\nThe relation \\(\\Rightarrow\\) is transitive. This ensures that\nDretske\u2019s Xerox principle holds in this account of information\ntransfer, that is, there can be no loss of semantic information\nthrough information transfer chains.\n\n[Xerox Principle]: If \\(s_1 : T_1\\) indicates that\n\\(s_2 : T_2\\) and \\(s_2 : T_2\\) indicates that \\(s_3 : T_3\\), then\n\\(s_1 : T_1\\) indicates that \\(s_3 : T_3\\).\n\nThe [IS Verification] principle deals with\ninformation that in principle could be acquired by an agent.\nThe access to some of this information will be blocked, for example,\nif the agent is oblivious to the correlation that exists between two\nkinds of situations. In addition, most correlations are not absolute,\nthey admit exceptions. Thus, for the signalling described in\n[E1] to be really informational, the extra\ncondition that the radar system is working properly must be\nmet. Conditional versions of the [IS Verification]\nprinciple may be used to insist that the carrier situation must meet\ncertain background conditions. The inability of an agent to keep track\nof changes on these background conditions may lead to errors. So, if\nthe radar is broken, the dot on the screen may end up moving upward\nwhile the plane is moving south. Unless the air controller is able to\nrecognise the problem, that is, unless she realises that the\nbackground conditions have changed, she may end up giving absurd\ninstructions to the pilot. Now, instructions are tied to actions. For\na treatment of actions from the situation-theoretical view, we refer\nthe reader to Israel and Perry (1991).\n2.3 Distributed information systems and channel theory\n\nThe basic notion of information flow sketched in the previous section\ncan be lifted to a more abstract setting in which the supporters of\ninformation are not necessarily situations as concrete parts of the\nworld, but rather any entity which, as in the case of situations, can\nbe classified as being of or not of certain types. The mathematical\ntheory of distributed systems (Barwise and Seligman 1997) to be\ndescribed next takes this abstract approach by focusing on information\ntransfer within distributed systems in general.\n\nA model of a distributed system in this framework will actually be a\nmodel of a kind of distributed system. Accordingly, the model\nof the radar-airplane system that we will use as a running example\nhere will actually be a model of radar-airplane systems (in\nplural). Setting such a model requires describing the architecture of\nthe system in terms of its parts and the way they are put together\ninto a whole. Once that is done, one can proceed to see how that\narchitecture enables the flow of information among its parts.\n\nA part of a system (again, really its kind) is modelled by saying how\nparticular instances of it are classified according to a given set of\ntypes. In other words, for each part of a system one has a\nclassification \n\\[ \\mathbf{A} = \\langle Instances, Types, \\models \\rangle, \\]\n\n\nwhere \\(\\models\\) is a binary relation such that \\(a \\models T\\) if\nthe instance \\(a\\) is of type \\(T\\). In a simplistic analysis of the\nradar example, one could posit at least three classifications, one for\nthe monitor screen, one for the flying plane, and one for the whole\nmonitoring system:\n\n\n\\[\\begin{align}\n\\mathbf{Screens} &= \\langle Monitor-Screens, Types\\: of\\: Screen\\: Configurations, \\models_M\\rangle \\\\\n \\mathbf{Planes} &= \\langle Flying\\: Planes, Types\\: of\\: Flying\\: Planes, \\models_P\\rangle \\\\\n \\mathbf{MonitSit} &= \\langle Monitoring\\: Situations, Types\\: of\\: Monitoring\\: Situations, \\models_M\\rangle \n\\end{align}\\]\n\n\n\nA general version of a \u2018part-of\u2019 relation between\nclassifications is needed in order to model the way parts of a system\nare assembled together. Consider the case of the monitoring systems.\nThat each one of them has a screen as one of its parts means that\nthere is a function that assigns to each instance of the\nclassification MonitSit an instance of\nScreens. On the other hand, all the ways in which a\nscreen can be classified (the types of Screens)\nintuitively correspond to ways in which the whole screening system\ncould be classified: if a screen is part of a monitoring system and\nthe screen is blinking, say, then the whole monitoring situation is\nintuitively one of the type \u2018its screen is blinking\u2019.\nAccordingly, a generalised \u2018part-of\u2019 relation between any\ntwo arbitrary classifications \\(\\mathbf{A}, \\mathbf{C}\\) can be\nmodelled via two functions \n\\[\\begin{align}\nf^{\\wedge} &: \\textit{Types}_A \\rightarrow \\textit{Types}_C \\\\\n f^{\\vee} &: \\textit{Instances}_C \\rightarrow \\textit{Instances}_A, \n\\end{align}\\]\n\n\nthe first of which takes every type in \\(\\mathbf{A}\\) to its\ncounterpart in \\(\\mathbf{C}\\), and the second of which takes every\ninstance \\(c\\) of \\(\\mathbf{C}\\) to its\n \\(\\mathbf{A}\\)-component.[5]\n\nIf \\(f : \\mathbf{A} \\rightarrow \\mathbf{C}\\) is shortcut notation for\nthe existence of the two functions above (the pair \\(f\\) of functions\nis called an infomorphism), then an arbitrary distributed\nsystem will consist of various classifications related by\ninfomorphisms. For our purposes, it will suffice here to consider\nthree classifications \\(\\mathbf{A}, \\mathbf{B}, \\mathbf{C}\\) together\nwith two infomorphisms \n\\[\\begin{align}\nf &: \\mathbf{A} \\rightarrow \\mathbf{C} \\\\\n g &: \\mathbf{B} \\rightarrow \\mathbf{C}. \n\\end{align}\\]\n\n\nThen, in our example, a simple way to model the radar monitoring\nsystem would consist of the pair \n\\[\\begin{align}\nf &: \\mathbf{Screens} \\rightarrow \\mathbf{MonitSit} \\\\\n g &: \\mathbf{Planes} \\rightarrow \\mathbf{MonitSit}. \n\\end{align}\\]\n\n\nThe common codomain in these cases \\((\\mathbf{C}\\) in the general case\nand MonitSit in the example) works as a the core of a\nchannel that connects two parts of the system. The core\ndetermines the correlations that obtain between the two parts, thus\nenabling information flow of the kind discussed in\n section 2.2.\n This is achieved via two kinds of links. On the one hand, two\ninstances \\(a\\) from \\(\\mathbf{A}\\) and \\(b\\) from \\(\\mathbf{B}\\) can\nbe thought to be connected via the channel if they are components of\nthe same instance in \\(\\mathbf{C}\\), so the instances of\n\\(\\mathbf{C}\\) act as connections between components. Thus, in the\nradar example, a particular screen will be connected to a particular\nplane if they belong to the same monitoring situation.\n\nOn the other hand, suppose that every instance in \\(\\mathbf{C}\\)\nverifies some relation between types that happen to be counterparts of\ntypes from \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\). Then such relation\ncaptures a constraint on how the parts of the system are\ncorrelated. In the radar example, the theory of the core\nclassification MonitSit would include constraints\nsuch as PlainMovingNorth \\(\\Rightarrow\\) DotGoingUp.\nThis regularity of monitoring\nsituations, which act as connections between radar screen-shots and\nplanes, reveals a way in which radar screens and monitored planes\ncorrelate with each other. All this leads to the following version of\ninformation transfer.\n\n\nChannel-enabled signalling: Suppose that\n\n\\[\\begin{align}\nf &: \\mathbf{A} \\rightarrow \\mathbf{C} \\\\\n g &: \\mathbf{B} \\rightarrow \\mathbf{C}. \n\\end{align}\\]\n\n\nThen instance \\(a\\) being of type \\(T\\) in \\(\\mathbf{A}\\) indicates\nthat instance \\(b\\) is of type \\(T'\\) in \\(\\mathbf{C}\\) if \\(a\\) and\n\\(b\\) are connected by a instance from \\(\\mathbf{C}\\) and the relation\n\\(f^{\\wedge}(T) \\Rightarrow g^{\\wedge}(T')\\) between the counterpart\ninterpreted types is satisfied by all instances of \\(\\mathbf{C}\\).\n\n\nNow, for each classification \\(\\mathbf{A}\\), the collection\n\n\\[ L_A = \\{T \\Rightarrow T' \\mid \\text{ every instance of } \\mathbf{A} \\text{ of type } T \\text{ is also of type } T'\\} \\]\n\n\nformed by all the global constraints of the classification\ncan be thought of as a logic that is intrinsic to \\(\\mathbf{A}\\). Then\na distributed system consisting of various classifications and\ninfomorphisms will have a logic of constraints attached to each part\nof\n it,[6]\n and more sophisticated questions about information flow within the\nsystem can be formulated.\n\nFor example, suppose an infomorfism \\(f : \\mathbf{A} \\rightarrow\n\\mathbf{C}\\) is part of the distributed system under study. Then \\(f\\)\nnaturally transforms each global constraint \\(T \\Rightarrow T'\\) of\n\\(L_{\\mathbf{A}}\\) into \\(f^{\\wedge}(T) \\Rightarrow f^{\\wedge}(T')\\),\nwhich can always be shown to be an element of \\(L_{\\mathbf{C}}\\). This\nmeans that one can reason within \\(\\mathbf{A}\\) and then\nreliably draw conclusions about \\(\\mathbf{C}\\). On the other\nhand, it can be shown that using preimages under \\(f^{\\wedge}\\) in\norder to translate global constraints of \\(\\mathbf{C}\\) does\nnot always guarantee the result to be a global constraint of\n\\(\\mathbf{A}\\). It is then desirable to identify extra conditions\nunder which the reliability of the inverse translation can be\nguaranteed, or at least improved. In a sense, these questions are\nqualitatively close to the concerns Shannon originally had about noise\nand reliability.\n\nAnother issue one may want to model is reasoning about a system from\nthe perspective of an agent that has only partial knowledge\nabout the parts of a system. As an example, think of a plane\ncontroller who has only worked with ACME monitors and knows nothing\nabout electronics. The logic such an agent might use to reason about\npart \\(\\mathbf{A}\\) of a system (actually part\nScreens in the case of the controller) will in\ngeneral consist of some constraints that may not even be global, but\nsatisfied only by some subset of instances (the ACME monitors). The\nagent\u2019s logic may be incomplete in the sense that it\nmight miss some of the global constraints of the classification (like\nthe ones involving inner components of the monitor). The agent\u2019s\nlogic may also be unsound, in the sense that there might be\ninstances out of the awareness of the agent (say monitors of\nunfamiliar brands) that falsify some of the agent\u2019s constraints\n(which do hold of all ACME monitors). A local logic \\(L\\) in\n\\(\\mathbf{A}\\) can be \u201cmoved\u201d along an infomorphism \\(f :\n\\mathbf{A} \\rightarrow \\mathbf{C}\\) in the expected way, that is, its\nconstraints are transformed via \\(f^{\\wedge}\\), while its instances\nare transformed via \\(f^{\\vee}\\). Natural questions studied in channel\ntheory concerning these notions include the preservation (or not),\nunder translation, of some desirable properties of local logics, such\nas soundness.\n\nA recent development in channel theory (Seligman 2014) uses a more\ngeneral definition of local logic, in which not all instances in the\nlogic need to satisfy all its constraints. This version of channel\ntheory is put to use in two important ways. Firstly, by using local\nlogics to stand for situations, and with a natural interpretation of\nwhat an infon should then be, a reconstruction is produced of the core\nmachinery of situation theory (barely presented in\n sections 2.1\n and\n section 2.2).\n Secondly, it is shown that this version of channel theory can deal\nwith probabilistic constraints. The rough idea is that any\npair of a classification plus a probability measure over the set of\ninstances induces an extended classification with the same set of\ntypes, and where a constraint holds if and only if the set of\ncounterexample instances has measure 0. Notice that this set of\ncounterexamples might not be empty. Having probabilistic constraints\nis a crucial step towards the effort of formally relating channel\ntheory to Shannon\u2019s theory of communication.\n\nFor an extensive development of the theory of channels sketched here,\nplus several explorations towards applications, see Barwise and\nSeligman (1997). See van Benthem (2000) for a study of conditions\nunder which constraint satisfiability is preserved under\ninfomorphisms, and Allo (2009) for an application of this framework to\nan analysis of the distinction between cognitive states and\ncognitive commodities. Finally, it must be mentioned that the\nnotion of classification has been around for some years now in the\nliterature, having being independently studied and introduced under\nnames such as Chu spaces (Pratt 1995) or Formal Contexts (Ganter and\nWille 1999).\n3. Information as Code\n\nFor information to be computed, it must be handled by the\ncomputational mechanism in question, and for such a handling to take\nplace, the information must be encoded. Information as\ncode is a stance that takes this encoding-condition very\nseriously. The result is the development of fine-grained models of\ninformation flow that turn on the syntactic properties of the encoding\nitself.\n\nTo see how this is so, consider again cases involving information flow\nvia observations. Such observations are informative because we are not\nomniscient in the normal, God-like sense of the term. We have to go\nand observe that the cat is on the mat, for example, precisely because\nwe are not automatically aware of every fact in the universe.\nInferences work in an analogous manner. Deductions are informative for\nus precisely because we are not logically omniscient. We have\nto reason about matters, sometimes at great length, because we are not\nautomatically aware of the logical consequences of the body of\ninformation with which we are reasoning.\n\nTo come full circle\u2014reasoning explicitly with information\nrequires handling it, where in this case such handling is cognitive\nact. Hence the information in question is encoded in some manner,\nhence Information as code underpins the development of fine-grained\nmodels of information flow that turn on the syntactic properties of\nthe encoding itself, as well as the properties of the actions that\nunderpin the various information-processing contexts involved.\n\nSuch information-processing contexts are not restricted to explicit\nacts of inferential reasoning by human agents, but include\nautomated reasoning and theorem proving, as well as\nmachine-based computational procedures in general. Approaches to\nmodelling the properties of these latter information-processing\nscenarios fall under algorithmic information theory.\n\nIn\n section 3.1,\n we will explore a major approach to modelling the properties of\ninformation-processing within the information as code framework via\ncategorial information theory. In\n section 3.2,\n we will examine the more general approach to modelling information as\ncode of which categorial information theory is an instance, the\nmodelling of information as code via substructural logics. In\n section 3.3\n we will lay out the details of several other notable examples of\nlogics of information flow motivated by the information as code\napproach.\n3.1 Categorial Information Theory\n\nCategorial information theory is a theory of fine-grained\ninformation flow whose models are based upon those specified by the\ncategorial grammars underpinned by the Lambek Calculi, due originally\nto Lambek (1958, 1961). The motivation for categorial information\ntheory is to provide a logical framework for modelling the properties\nof the very cognitive procedures that underpin deductive\nreasoning.\n\nThe conceptual origin of categorial information theory is found in van\nBenthem (1995: 186). Understanding van Benthem\u2019s use of\n\u201cprocedural\u201d to be synonymous with\n\u201cdynamic\u201d:\n\n\n[I]t turns out that, in particular, the Lambek Calculus itself permits\nof procedural re-interpretation, and thus, categorial calculi may turn\nout to describe cognitive procedures just as much as the syntactic or\nsemantic structures which provided their original motivation.\n\n\nThe motivation for categorial information theory is to model the\ncognitive procedures constituting deductive reasoning. Consider as an\nanalogy the following example. You arrive home from IKEA with an\nunassembled table that is still flat-packed in its box. Now the\nquestion here is this, do you have your table? Well, there is a sense\nin which you do, and a sense in which you do not. You have your table\nin the sense that you have all of the pieces required to construct or\ngenerate the table, but this is not to say that you have the table in\nthe sense that you are able to use it. That is, you do not\nhave the table in any useful form, you have merely pieces of a table.\nIndeed, getting these table-pieces into their useful form, namely a\ntable, may be a long and arduous process\u2026\n\nThe analogy between the table-example above and deductive reasoning is\nthis. It is said often that the information encoded by (or\n\u201ccontained in\u201d or \u201cexpressed by\u201d) the\nconclusion of a deductive argument is encoded by the premises. So,\nwhen you possess the information encoded by the premises of some\ninstance of deductive reasoning, do you possess the information\nencoded by the conclusion? Just as with the table-pieces, you do not\npossess the information encoded by the conclusion in any useful form,\nnot until you have put the \u201cinformation-pieces\u201d\nconstituting the premises together in the correct manner. To be sure,\nwhen you possess the information-pieces encoded by the premises, you\npossess some of the information required for the construction or\ngeneration of the information encoded by the conclusion. As with the\ntable-pieces however, getting the information encoded by the\nconclusion from the information encoded by the premises may be a long\nand arduous process. You need also the instructional information that\ntells you how to combine the information encoded by the premises in\nthe right way. This information-generation via deductive inference may\nbe thought of also as the movement of information from implicit to\nexplicit storage in the mind of the reasoning agent, and it is the\ncognitive procedures facilitating this storage transfer that motivate\ncategorial information theory.\n\nCategorial information theory is a theory of dynamic information\nprocessing based on the merge/fusion \\((\\otimes)\\) and\ntyped function \\((\\rightarrow , \\leftarrow)\\) operations from\ncategorial grammar. The conceptual motivation is to understand the\ninformation in the mind of an agent as the agent reasons deductively\nto be a database in much the same way as a natural language lexicon is\na database (see Sequoiah-Grayson (2013), (2016)). In this case, a\ngrammar will be understood as a set of processing constraints\nso imposed as to guarantee information flow, or well-formed strings as\noutputs. Recent research on proofs as events from a very\nsimilar conceptual starting point may by found in Stefaneas and\nVandoulakis (2014).\n\nCategorial information theory is strongly algebraic in flavour. Fusion\n\u2018\\(\\otimes\\)\u2019 corresponds to the binary composition\noperator \u2018.\u2019, and \u2018\\(\\vdash\\)\u2019 to the partial\norder \u2018\\(\\le\\)\u2019 (see Dunn 1993). The merge and function\noperations are related to each other via the familiar residuation\nconditions: \n\\[\\begin{align}\n\\tag{5} A \\otimes B \\vdash C &\\text{ iff } B \\vdash A \\rightarrow C \\\\\n \\tag{6} A \\otimes B \\vdash C &\\text{ iff } A \\vdash C \\leftarrow B \n\\end{align}\\]\n\n\nIn general, applications for directional function application will be\nrestricted to algebraic analyses of grammatical structures, where\ncommuted lexical items will result in non-well-formed strings.\n\nDespite its algebraic nature, the operations can be given their\nevaluation conditions via \u201cinformationalised\u201d Kripke\nframes (Kripke 1963, 1965). An information frame (Restall 1994)\n\\(\\mathbf{F}\\) is a triple \\(\\langle S, \\sqsubseteq, \\bullet\\rangle\\).\n\\(S\\) is a set of information states \\(x, y, z\\ldots\\) .\n\\(\\sqsubseteq\\) is a partial order of informational\ndevelopment/inclusion such that \\(x \\sqsubseteq y\\) is taken to mean\nthat the information carried by \\(y\\) is a development of the\ninformation carried by \\(x\\), and \\(\\bullet\\) is an operation for\ncombining information states. In other words, we have a domain with a\ncombination operation. The operation of information combination and\nthe partial order of information inclusion interrelate as follows:\n\n\\[\\tag{7} x \\sqsubseteq y \\text{ iff } x \\bullet y \\sqsubseteq y \\]\n\n\nReading \\(x \\Vdash A\\) as state \\(x\\) carries information of type\n\\(A\\), we have it that: \n\\[\\begin{align}\n\\tag{8} x \\Vdash A \\otimes B &\\text{ iff for some } y, z, \\in \\mathbf{F} \\text{ s.t. } y \\bullet z \\sqsubseteq x, y \\Vdash A \\text{ and } z \\Vdash B. \\\\\n \\tag{9} x \\Vdash A \\rightarrow B &\\text{ iff for all } y, z \\in \\mathbf{F} \\text{ s.t. } x \\bullet y \\sqsubseteq z, \\text{ if } y \\Vdash A \\text{ then } z \\Vdash B. \\\\\n \\tag{10} x \\Vdash B \\leftarrow A &\\text{ iff for all } y, z \\in \\mathbf{F} \\text{ s.t. } y \\bullet x \\sqsubseteq z, \\text{ if } y \\Vdash A \\text{ then } z \\Vdash B. \n\\end{align}\\]\n\n\nAt the syntactic level, we read \\(X \\vdash A\\) as processing on\n\\(X\\) generates information of type A. In this case we are\nunderstanding \\(\\vdash\\) as an information processing mechanism as\nsuggested by Wansing (1993: 16), such that \\(\\vdash\\) encodes not just\nthe output of an information processing procedure, but the properties\nof the procedure itself. Just what this processing consists of will\ndepend on the processing constraints that we set up on our database.\nThese processing constraints will be imposed in order to guarantee an\noutput from the processing itself, or to put this another way, in\norder to preserve information flow. Such processing constraints are\nfixed by the presence or absence of various structural rules,\nand structural rules are the business of substructural\nlogics.\n3.2 Substructural logics and information flow\n\nCategorial information theory is precipitated by giving the Lambek\ncalculi an informational semantics. At a suitable level of\nabstraction, the Lambek calculi is seen to be a highly expressive\nsubstructural logic. Unsurprisingly, by giving an\ninformational semantics for substructural logics in general, we get a\nfamily of logics that exemplify the information as code approach. This\nlogical family is organised by expressive power, with the expressive\npower of the logics in question being captured by the presence of\nvarious structural rules.\n\nA structural rule is of the following general form: \n\\[\\tag{11} X \\Leftarrow Y \\]\n\n\nWe may read (11) as any information generated by processing on\n\\(X\\) is generated by processing on \\(Y\\) also. Hence the\nlong-form of (11) is as follows: \n\\[\\tag{12} \\frac{X \\vdash A}{Y \\vdash A} \\]\n\n\nHence \\(X\\) is a structured body of information, or \u201cdata\nstructure\u201d as Gabbay (1996: 423) puts it, where the actual\narrangement of the information plays a crucial role. The\nstructural rules will fix the structure of the information encoded by\n\\(X\\), and as such impact upon the granularity of the information\nbeing processed.\n\nConsider Weakening, the most familiar of the structural rules\n(followed by its corresponding frame condition: \n\\[\\begin{align}\n\\tag{Weakening} &A \\Leftarrow A \\otimes B \\\\\n &x\\bullet y \\sqsubseteq z \\rightarrow x \\sqsubseteq z \n\\end{align}\\]\n\n\nWith Weakening present, we loose track of which pieces of information\nwere actually used in an inference. This is precisely why it is that\nthe rejection of Weakening is the mark of relevant logics, where the\npreservation of bodies of information relevant to the derivation of\nthe conclusion is the motivation. By rejecting Weakening, we highlight\na certain type of informational taxonomy, in the sense that\nwe know which bodies of information were used. To preserve\nmore structural detail than simply which bodies of information were\nused, we need to consider rejecting further structural rules.\n\nSuppose that we want to record not only which pieces of information\nwere used in an inference, but also how often they were used. In this\ncase we would reject Contraction: \n\\[\\begin{align}\n\\tag{Contraction} &A \\otimes A \\Leftarrow A \\\\\n &x \\bullet x \\sqsubseteq x \n\\end{align}\\]\n\n\nContraction allows the multiple use, without restriction, of a piece\nof information. So if keeping a record of the \u201cinformational\ncost\u201d of the execution of some information processing is a\nconcern, Contraction will be rejected. The rejection of Contraction is\nthe mark of linear logics, which were designed for modelling just such\nprocessing costs (see Troelstra 1992).\n\nIf we wish to preserve the order of use of pieces of\ninformation, then we will reject the structural rule of\nCommutation: \n\\[\\begin{align}\n\\tag{Commutation} &A \\otimes B \\Leftarrow B \\otimes A \\\\\n &x \\bullet y \\sqsubseteq z \\rightarrow y \\bullet x \\sqsubseteq z \n\\end{align}\\]\n\n\nInformation-order will be of particular concern in temporal settings\n(consider action-composition) and natural language semantics (Lambek\n1958), where non-commuting logics first appeared. Commutation comes\nalso in a more familiar strong form: \n\\[\\begin{align}\n\\tag{Strong Commutation} &(A \\otimes B) \\otimes D \\Leftarrow(A \\otimes D) \\otimes B \\\\\n &\\exists u(x \\bullet z \\sqsubseteq u \\wedge u \\bullet y \\sqsubseteq w) \\rightarrow\\\\\n &\\qquad \\exists u(x \\bullet y \\sqsubseteq u \\wedge u \\bullet z \\sqsubseteq w) \n\\end{align}\\]\n\n\nThe strong form of Commutation results from its combination with the\nstructural rule of\n Association:[7]\n \n\\[\\begin{align}\n\\tag{Association} &A \\otimes(B \\otimes C) \\Leftarrow(A \\otimes B) \\otimes C \\\\\n &\\exists u(x \\bullet y \\sqsubseteq u \\wedge u \\bullet z \\sqsubseteq w) \\rightarrow \\\\\n &\\qquad \\exists u(y \\bullet z \\sqsubseteq u \\wedge x \\bullet u \\sqsubseteq w) \n\\end{align}\\]\n\n\nRejecting Association will preserve the precise fine-grained\nproperties of the combination of pieces of information.\nNon-associative logics were introduced originally to capture the\ncombinatorial properties of language syntax (see Lambek 1961).\n\nIn the presence of Commutation, a double implication pair\n\\((\\rightarrow , \\leftarrow)\\) collapses into single implication\n\\(\\rightarrow\\). In the presence of all of the structural rules,\nfusion, \\(\\otimes\\), collapses into Boolean conjunction, \\(\\wedge\\).\nIn this case, the residuation conditions outlined in (5) and (6)\ncollapse into a mono-directional function.\n\nThe choice of which structural rules to retain obviously depends on\njust what informational phenomena is being modelled, so there is a\nstrong pluralism at work. By rejecting Weakening say, we are\nspeaking of which data were relevant to the process, but are\nsaying nothing about its multiplicity (in which case we would reject\nContraction), its order (in which case we would reject Commutation),\nor the actual patterns of use (in which case we would reject\nAssociation). By allowing Association, Commutation, and Contraction,\nwe have the taxonomy locked down. We might not know the order or\nmultiplicity of the data that were used, but we do know what types,\nand exactly what types, were relevant to the successful processing.\nThe canonical contemporary exposition of such an information-based\ninterpretation of propositional relevant logic is Mares (2004). Such\nan interpretation allows for an elegant treatment of the\ncontradictions encoded by relevant logics. By distinguishing between\ntruth conditions and information conditions, we\nallow for an interpretation of \\(x \\Vdash A \\wedge \\neg A\\) as\n\\(x\\) carries the information that \\(A\\) and not \\(A\\). For\nan exploration of the distinction between truth-conditions and\ninformation-conditions within quantified relevant logic, see\nMares (2009).\n\nAt such a stage, things are still fairly static. By shifting\nour attention from static bodies of information, to the manipulation\nof these bodies, we will reject structural rules beyond\nWeakening, arriving ultimately at categorial information theory, as it\nis encoded by the very weakest substructural logics. Hence the weaker\nwe go, the more \u201cprocedural\u201d the flavour of the logics\ninvolved. From a dynamic/procedural perspective, linear logics might\nbe thought of as a \u201chalf way point\u201d between static\nclassical logic, and fully procedural categorial information theory.\nFor a detailed exposition of the relationship between linear logic and\nother formal frameworks in the context of modelling information flow,\nsee Abramsky (2008).\n\nRecent important work by Dunn (2015) ties substructural logics and\nstructural rules together with informational relevance in the\nfollowing way. Dunn makes a distinction between programs and\ndata, with the former being dynamic and the latter static. We\nmay think of programs as conditional statements of the form \\(A\n\\rightarrow B\\), and of data as atomic propositions \\(A, B\\) etc.\nGiven these two types of information artefacts, we have three possible\ncombinations, program to data combination, program to program\ncombination, and data to data combination. For program to data\ncombination, commutation will hold whilst weakening and association\nwill fail, and contraction not applying. For program to program\ncombination association will hold, whilst commutation, weakening fail.\nAs demonstrated in Sequoiah-Grayson (2016), the case of contraction\nfor program to program combination is more complicated. The exact\nproperties of data to data combination remain an interesting open\nissue. The connection with informational relevance is made by\ninterpreting the partial order relation \\(\\sqsubseteq\\) as marking\ninformation relevance itself. In this case, \\(x \\sqsubseteq y\\) is\nread as the information x is relevant to the\ninformation y. To what it is exactly that informational relevance\namounts will depend on the precise context of information processing\nin question. Sequoiah-Grayson (2016) extends the framework about to\ncontexts of information processing by an agent as the agent reasons\nexplicitly. Given that the combination of information states \\(x\n\\bullet y\\) may sit on the left hand side of the partial order\nrelation, the extension is an account of the epistemic relevance of\nepistemic actions. For a collection of recent papers exploring the\ninformation as code approach in depth, see Bimb\u00f3 (2016). See\nBimb\u00f3 (2022) for a wide collection of recent papers on\ninformational relevance and reasoning.\n3.3 Related Approaches\n\nThe information as code approach is a very natural perspective on\ninformation flow, hence there are a number of related frameworks that\nexemplify it.\n\nOne such approach to analysing information as code is to carry out\nsuch an analysis in terms of the computational complexity of various\npropositional logics. Such an approach may propose a hierarchy of\npropositional logics that are all decidable in polynomial time, with\nthis hierarchy being structured by the increasing computational\nresources required for the proofs in the various logics.\nD\u2019Agostino and Floridi (2009) carry out just such an analysis,\nwith their central claim being that this hierarchy may be used to\nrepresent the increasing levels of informativeness of propositional\ndeductive reasoning.\n\nGabbay\u2019s (1993, 1996) framework of labelled deductive\nsystems exemplifies the information as code approach in manner\nvery similar to the informationalised substructural logics of\n section 3.1.\n An item of data (note that Gabbay refers to both atomic and\nconditional information as data, in contrast to Dunn and\nSequoiah-Grayson in the section above) is given as a pair of the form\n\\(x : A\\), where \\(A\\) is a piece of declarative information, and\n\\(x\\) is a label for \\(A. x\\) is a representation of information that\nis needed operate on or alter the information encoded by \\(A\\).\nSuppose that we have also the data-pair \\(y : A \\rightarrow B\\). We\nmay apply \\(x\\) to \\(y\\), resulting in the data-pair \\(x + y : B\\) In\nthis case, a database is a configuration of labelled formulas, or\ndata-pairs (Gabbay 1993: 72). The labels and their corresponding\napplication operation are organised by an algebra, and the properties\nof this algebra will impose constraints on the applications operation.\nDifferent constraints, of \u201cmeta-conditions\u201d as Gabbay\ncalls them (Gabbay 1993: 77), will correspond to different logics. For\nexample, if we were to ignore the labels, then we would have classical\nlogic, if we were to accept only the derivations which used all of the\nlabelled assumptions, then we would have relevance logic, and if we\naccepted only the derivations which used the labelled assumptions\nexactly once, then we would have linear logic. Labels are behaving\nvery much like possible worlds here, and the short step from possible\nworlds to information states makes it obvious how it is that the\nmeta-conditions on labels may be captured by structural rules.\n\nArtemov\u2019s (2008) framework of justification logic\nshares many surface similarities with Gabbay\u2019s system of\nlabelled deduction. The logic is composed of justification\nassertions of the form \\(x : A\\), read as \\(x\\) is a\njustification for \\(A\\). Justifications themselves are evidential\nbases of varying sorts that will vary depending on the context. They\nmight be mathematical proofs, sets of causes or counterfactuals, or\nsomething else that fulfils the justificatory role. What it means for\n\\(x\\) to justify \\(A\\) is not analysed directly in justification\nlogic. Rather, attempts are made to characterise the justification\nrelation \\(x : A\\) itself, via various operations and their axioms.\nThe application operation, \u2018.\u2019 mimics the application\noperation \u2018+\u2019 from labelled deduction, or the fusion\n\u2018\\(\\otimes\\)\u2019 operation from categorial information\ntheory. In justification logic, the symbol \u2018+\u2019 is reserved\nfor the representation of joint evidence. Hence \u2018\\(x +\ny\\)\u2019 is read as \u2018the joint evidence of \\(x\\) and\n\\(y\\)\u2019. Application and join are characterised in\njustification logic by the following axioms respectively:\n\n\\[\\begin{align}\n\\tag{13} &x : (A \\rightarrow B) \\rightarrow(y : A \\rightarrow(x{.}y) : B) \\\\\n \\tag{14} &x : A \\rightarrow(x + y) : A, \\text{ and } x : A \\rightarrow(y + x) : A \n\\end{align}\\]\n\n\nThe latter axiom characterises the monotonicity of joint evidential\nbases. Apart from the commutativity of +, the structural properties of\nthe justification operations are currently unexplored, although the\npotential for such an exploration is exciting. Justification logic is\nused to analyse notoriously difficult epistemic problems such as the\nGettier cases and more. If we take our epistemology to be\ninformationalised, then the constitution of evidential bases as\ninformation states places justification logics within the information\nas code approach in a straightforward manner. For further details, see\nArtemov and Fitting (2012).\n\nZalta\u2019s work on object theory (Zalta 1983, 1993) provides a\ndifferent way to analyse informational content\u2014understood as\npropositional content\u2014and its structure. Motivated by\nmetaphysical considerations, object theory starts by proposing a\ntheory of objects and relations (usually formulated in a second order\nquantified modal language). This theory can then be used to define and\ncharacterise states of affairs, propositions, situations, possible\nworlds, and other related notions. The resulting picture is one where\nall these things have internal structure, their algebraic properties\nare axiomatized, and one can therefore reason about them in a\nclassical proof-theoretical way.\n\nA philosophical point touched by this approach concerns the link\nbetween the propositional content (information) expressed by sentences\nand the idea of predication. Relevant to this entry is Zalta\u2019s\n(1993) development of a version of situation theory that follows this\napproach, and where a key element is the usage of two forms of\npredication. Briefly, the formula \u2018\\(Px\\)\u2019 corresponds to\nthe usual form of predication by exemplification (as in \u201cObama\nis American\u201d), while \u2018\\(xP\\)\u2019 corresponds to\npredication via encoding. Abstract objects are then defined\nto be (essentially) encodings of properties, in combinations which\nmight not even be made factual. These provisions enable the existence\nof information about abstract, possible, or fictional entities. For\ndetails on the tradition to which object theory belongs see Textor\n(2012), McGrath (2012), and King (2012).\n4. Connections Between the Approaches\n\nWhile the three approaches discussed above (range, correlations, code)\ndiffer in that they emphasise different informational themes, the\nunderlying notion they aim to clarify is the same (information). It is\nthen natural to find that the similarities and synergies between the\napproaches invite the exploration of ways to combine them. Each one of\nthe next subsections illustrates how one could bring together two out\nof the three approaches.\n Section 4.1\n exemplifies the interface between the info-as-range and\ninfo-as-correlation views. Sections\n 4.2\n and\n 4.3\n do the same with the other two pairs of combinations, namely code and\ncorrelations, and code and ranges.\n4.1 Ranges and correlations\n\nA central intuition in the information-as-range view is the\ncorrespondence that exists between information at hand (where this can\nbe qualified in various ways) and the range of possibilities which are\ncompatible with such information. On the other hand, a key feature of\nthe correlational approach to information is its reliance on a\nstructured information system formed by components that are\nsystematically connected. In general, many properties of a structured\nsystem will actually be local properties, in that they are\ndetermined by only some of the components (the fact that there is a\ndot moving upwards in a radar can be determined only by looking at the\nscreen, even if this behaviour is correlated with the motion of a\nremote plane, which is another component of the system). If one has\naccess to information pertaining to only a few of the many components\nof a system, a natural notion of range of possibilities arises,\nconsisting of all the possible global configurations of the system\nthat are compatible with such local information. This subsection\nexpands on this particular way to link the two approaches, but as it\nwill be noted at the end, this is not the only one and the search for\nother ways lies ahead as an open area of inquiry.\n\nFormally, the link between ranges and correlations described above may\nbe approached by using a restricted product state space as a\nmodel of the architecture of the system (van Benthem 2006, van Benthem\nand Martinez 2008). The basic structures are constraint\nmodels, versions of which have been around in the literature for\nsome years (for example Fagin et al. 1995 in the study of epistemic\nlogic, and Ghidini and Giunchiglia 2001 in the study of context\ndependent reasoning). Constraint models have the form \n\\[ \\mathscr{M} = \\langle Comp, States, C, Pred\\rangle. \\]\n\n\nHere, the basic component spaces are indexed by Comp, the\nstates of each component are taken from States (with\ndifferent components using maybe only a few of the elements of\nStates), and the global states of the system are global\nvaluations, that is, functions that assign a state to each basic\ncomponent Comp. Not all such functions are allowed, only\nthose in \\(C\\). Finally, Pred is a labelled family of\npredicates (sets of global states).\n\nTo see how this fits with the information-as-correlation view,\nconsider again the example of planes being monitored by radars. As\nbefore, each monitoring situation will be modelled as having only two\nparts, now indexed by the members of \\(Comp = \\{ screen, plane\\}\\).\nThe actual instances of screening situations would correspond to\nglobal states, which in this case \u2014 where we have only two\ncomponents \u2014 can be thought of as pairs \\((s, b)\\) where \\(s\\)\nis a particular screen and \\(b\\) a particular plane. Hence, global\nstates connect instances of parts, so representing instances of a\nwhole system. But then a crucial restriction comes into play, because\nnot all screens are connected with all planes, only with those\nbelonging to the same monitoring situation. The set \\(C\\) selects only\nsuch permissible pairs, thus playing a role similar to that of a\nchannel in\n section 1.\n Finally, Pred classifies global states into types, similar\nto the classification relations of\n section 2.3.\n\n\nAs we said before, some properties of systems are local properties,\nwith only some of the components of the systems being relevant in\ndetermining whether they hold or not. That a monitoring situation is\none where the plane is moving North depends only on the plane, not on\nthe screen. In general, if a property is completely determined by\nsubset of components \\(\\mathbf{x}\\) then, in what concerns that\nproperty, any two global states that agree on \\(\\mathbf{x}\\) should be\nindistinguishable. In fact, each such \\(\\mathbf{x}\\) induces an\nequivalence relation of local property determination so that for every\ntwo global states \\(\\mathbf{s}, \\mathbf{t}\\):\n\n\\(\\mathbf{s} \\sim_{\\mathbf{x}}\\mathbf{t}\\) if and only if the values\nof \\(\\mathbf{s}\\) and \\(\\mathbf{t}\\) at each one of the components in\n\\(\\mathbf{x}\\) are the same.\n\nIn this way one gets not only a conceptual but also formal link to the\ninformation-as-range approach, because constraint models can be used\nto interpret a basic modal language with atomic formulas of the form\n\\(P\\)\u2014where \\(P\\) is one of the labels of predicates in\nPred\u2014and with complex formulas of the form \\(\\neg \\phi,\n\\phi \\vee \\psi, U\\phi\\), and \\(\\Box_{\\mathbf{x}}\\phi\\), where\n\\(\\mathbf{x}\\) is a partial tuple of components and \\(U\\) is the\nuniversal modality. More concretely, given a constraint model\n\\(\\mathscr{M}\\) and a global state \\(s\\), the crucial satisfaction\nconditions are given by: \n\\[\\begin{alignat}{3}\n\\mathscr{M}, \\mathbf{s} &\\models P &\\text{ iff } &\\mathbf{s} \\in P \\\\\n \\mathscr{M}, \\mathbf{s} &\\models U \\phi &\\text{ iff } &\\mathscr{M}, \\mathbf{t} \\models \\phi \\text{ for all } \\mathbf{t} \\\\\n \\mathscr{M}, \\mathbf{s} &\\models \\Box_{\\mathbf{x}} \\phi &\\text{ iff } &\\mathscr{M}, \\mathbf{t} \\models \\phi \\text{ for all } \\mathbf{t} \\sim_{\\mathbf{x}} \\mathbf{s} \n\\end{alignat}\\]\n\n\nThe resulting logic is axiomatised by the fusion of \\(S_5\\) modal\nlogics for the universal modality \\(U\\) and each one of the\n\\(\\Box_{\\mathbf{x}}\\) modalities, plus the addition of axioms of the\nform \\(U \\phi \\rightarrow \\Box_{\\mathbf{x}}\\phi\\), and\n\\(\\Box_{\\mathbf{x}}\\phi \\rightarrow \\Box_{\\mathbf{y}}\\phi\\) whenever\n\\(\\sim_{\\mathbf{y}} \\subseteq \\sim_{\\mathbf{x}}\\).\n\nThe information-as-range research agenda includes other topics, such\nas agency and the dynamics of information update, which can in\nprinciple be incorporated to the constraint models setting. For\nexample, in the case of agency, to the architectural structure of a\nstate system captured by a constraint model one could add epistemic\naccessibility relations for a group of agents \\(\\mathcal{A}\\), so to\nobtain epistemic constraint models of the form\n\n\\[ \\mathscr{M} = \\langle Comp, States, C, Pred, \\{\\approx_{a}\\}_{a\\in \\mathcal{A}}\\rangle. \\]\n\n\nwhere \\(\\approx_a\\) is the equivalence accessibility relation of agent\n\\(a\\). Here one could refine the planes and radar example above by\nadding some agents, say the controller and the pilot. By relying only\non the controls each agent can see, the controller will not be able to\ndistinguish states that agree on the direction of the plane but\ndiffer, say, on the metereological conditions around the plane. Those\nstates will be related by the controller\u2019s relation in the\nmodel, but not by the pilot\u2019s relation. In principle, this merge\nof modal epistemic models and constraint models allows one to study,\nin a single setting, aspects of both the information-as-range and\ninformation-as-correlation points of view. The corresponding logical\nlanguage for epistemic constraint models is the same as for basic\nconstraint models, expanded with the \\(K_i\\) modal operators, one per\nagent. The logic is the fusion of the constraint logic from above and\na \\(S_5\\) logic per each agent \\(a\\).\n\nThere are some newer, different approaches to information modelling\nthat sit at the intersection of the information as range and\ninformation as correlation perspectives. One is van Benthem\u2019s\nwork on information tracking (van Benthem 2016). Tracking is a new\nperspective that addresses both the connections between different\nrepresentations of information on the one hand, and the updates on\nthese connections on the other.\n\nAnother development (Baltag 2016) comes from a line of work that\nstudies how to capture, in the style of epistemic logics such as those\ndescribed in\n section 1,\n the properties and dynamics of knowledge de re (Wang and Fan\n2014). Identifying this kind of knowledge with knowledge of the value\nof a variable, Baltag\u2019s insight is to add, to the language of\nbasic epistemic logic, the usual first-order resources for\nconstructing terms and basic formulas (that is, symbols of constants,\nfunctions, relations, and variables), plus, crucially, a generalised\nconditional knowledge operator \\(K_{a}^{t_1 ,\\ldots ,t_n}\\). The\nextended language has now formulas \\(K_{a}^{t_1 ,\\ldots ,t_n} t\\) and\n\\(K_{a}^{t_1 ,\\ldots ,t_n} \\phi\\), with the intended meaning that\nagent \\(a\\) knows the value of term \\(t\\) (or knows that \\(\\phi\\), for\nthe second formula), provided it knows the values of terms \\(t_1\n,\\ldots ,t_n\\). To be able to capture this idea on the semantic side,\nKripke models are enriched so that, in addition to the usual set of\ninformation states, interpretations for propositional letters, and\nagents relations, we will also have a domain of objects over which\nterms and basic relational formulas are locally interpreted at each\nstate (that is, the interpretations can vary from state to state, but\nthe underlying domain is the same across states). A sound and complete\naxiomatisation exists, and the resulting logical system is a sort of a\ngeneral, yet decidable, dependence logic where information about\ncorrelations can be captured via the conditional knowledge operators.\nDynamic versions are also obtained where, in addition to the public\nannouncement operator \\([\\phi]\\), one has value announcement operators\n\\([t_1,\\ldots ,t_n]\\), with formula \\([t_1,\\ldots ,t_n] \\phi\\) being\nread as \u201cafter the simultaneous announcement of the values of\nterms \\(t_1,\\ldots ,t_n\\), it is the case that \\(\\phi\\)\u201d.\nThere is recent work (Baltag and van Benthem 2021) that achieves a\ngeneral logic of local dependence that recruits semantic\ninsights like the ones just described so far in this subsection\n(constraint models and a enriched modal semantics), and shows that\nthey can be seen as two faces of the same coin.\n\n\nYet other links between the approaches have also be found, which are\nmotivated by other kind of questions and use formalisms that are\ncloser to the situation-theoretic ones. For example, consider a\nsetting in which agents have incomplete information about an\nintended subset of a set of epistemic states. How can a relation of\naccessibility arise from such a setting? (Notice that this is\ndifferent to the setting of epistemic constraint models described\nabove, where agents do have complete information about what holds true\nof all the epistemically accessible worlds). One way to address this\nquestion (Barwise 1997) is to consider a fixed classification \\(A\\),\nthe instances of which are the epistemic states, plus a local logic\nper agent attached to each state. For some states these local logics\nmay be incomplete (see\n section 2.3),\n so agents may not have information about everything that holds true\nof the intended range of states. Then, roughly, the states accessible\nfrom a given state \\(s\\) and agent \\(a\\) will be those whose\nproperties (types) do not contradict the local logic of \\(a\\) in\n\\(s\\). With these epistemic relations in place, classification \\(A\\)\ncan be used to interpret a basic modal language.\n4.2 Code and correlations\n\nLogical frameworks that crossover information as code and information\nas correlation get their most explicit representation in work that\ndoes just this\u2014model the crossover between the two frameworks.\nRestall (1994) and Mares (1996) give independent proofs of the\nrepresentability of Barwise\u2019s information as correlation\nchannel-theoretic framework within the information as code approach as\nexemplified by the substructural logics framework. In this section we\nwill trace the motivations and the main details of the proof, before\ndemonstrating the connection with category theory.\n\nThe basic steps are these\u2014if we understand information channels\nto be information states of a special sort, namely the sort of\ninformation state that carries information of conditional types, then\nthere is an obvious meeting point between information as correlation\nas exemplified by channel theory, and information as code as\nexemplified by informationalised substructural logics. The\nintermediate step is to reveal the connection between channel\nsemantics for conditional types, and the frame semantics for\nconditionals given by relevance logics.\n\nStarting with the channel theoretic analysis of conditionals, as noted\nalready, the running motivation behind Barwise\u2019s\nchannel-theoretic framework is that information flow is underpinned by\nan information channel. Barwise understood conditionals as\nconstraints in the sense that \\(A \\rightarrow B\\) is a\nconstraint from \\(A\\) to \\(B\\) in the sense of \\(A \\Rightarrow B\\)\nfrom\n section 2.2\n above. If the information that \\(A\\) is combined with the information\nencoded by the constraint, then the result or output is the\ninformation that \\(B\\).\n\nThe information that \\(A\\) and that \\(B\\) is carried by the situations\n\\(s_1, s_2\\ldots\\). and the information encoded by the constraint is\ncarried by an information channel \\(c\\). Given this, Barwise\u2019s\nevaluation condition for a constraint is as follows (the condition is\ngiven here in Barwise\u2019s notation from his later work on\nconditionals, although in earlier writings such conditions appeared in\nthe notation given in\n section 2.2\n above): \n\\[\\tag{15} c \\models A \\rightarrow B \\text{ iff for all } s_1, s_2, \\text{ if } s_1 \\stackrel{c}{\\mapsto} s_2 \\text{ and } s_1 \\models A, \\text{ then } s_2 \\models B, \\]\n\n\nwhere \\(s_1 \\stackrel{c}{\\mapsto} s_2\\) is read as\n\nthe information carried by the channel \\(c\\), when combined with the\ninformation carried by the situation \\(s_1\\), results in the\ninformation carried by the situation \\(s_2\\).\n\nObviously enough, this is very close in spirit to (9) in the section\non information as code above.\n\nAs noted above, the intermediate step concerns the ternary relation\n\\(R\\) from the early semantics for relevance logic. The semantic\nclause for the conditional from relevance logic is: \n\\[\\tag{16} x \\Vdash A \\rightarrow B \\text{ iff for all } y, z \\in \\mathbf{F} \\text{ s.t. } Rxyz, \\text{ if } y \\Vdash A \\text{ then } z \\Vdash B. \\]\n\n\n\\(Rxyz\\) is, by itself, simply an abstract mathematical entity. One\nway or reading it, the way that became popular in relevance logic\ncircles, is\n\n\\(Rxyz\\) iff the result of combining \\(x\\) with \\(y\\) is true at\n\\(z\\).\n\nGiven that the points of evaluation in relevance logics were\nunderstood originally as impossible situations (since they may be both\ninconsistent and incomplete), the main conceptual move was to\nunderstand channels to be special types of situations. The full proofs\nmay be found in Restall (1994) and Mares (1996), and these demonstrate\nthat the expressive power of Barwise\u2019s system may be captured by\nthe frame semantics of relevance logic. What it is that such\n\u201ccombining\u201d of \\(x\\) and \\(y\\) amounts to depends on, of\ncourse, which structural rules are operating on the frame in question.\nAs explained in the previous section above, the choice of which rules\nto include will depend on the properties of the phenomena being\nmodelled.\n\nThe final step required for locating the meeting point between\ninformation as code and information as correlation is as follows.\nContemporary approaches to relevance and other substructural logics\nunderstand the points of evaluation (impossible situations) to be\ninformation states. There is certainly no constraint on information\nthat it be complete or consistent, so the expressibility of impossible\nsituations it not sacrificed. Such an informational reading (Paoli\n2002; Restall 2000; Mares 2004) lends itself to multiple applications\nof various substructural frameworks, and also does away with the\nontological baggage brought by questions like \u201cwhat are\nimpossible situations?\u201d in the \u201cWhat are possible\nworlds?\u201d spirit. An information-state reading of \\(Rxyz\\) will\nbe something like\n\nthe result of combining the information carried by \\(x\\) and \\(y\\)\ngenerates the informations carried by \\(z\\).\n\nMaking this explicit results in \\(Rxyz\\) being written down as \\(x\n\\bullet y \\sqsubseteq z\\), in which case (15) is, via (16), equivalent\nto (9).\n\nAn important structural rule for the composition operation on\ninformation channels, that is, on information states that carry\ninformation of conditional types, is that it is associative. What this\nmeans is that: \n\\[\\tag{17} z \\stackrel{x \\bullet (y \\bullet v)}{\\longmapsto} w = z \\stackrel{(x \\bullet y) \\bullet v}{\\longmapsto} w. \\]\n\n\nWhere \\(z \\Vdash A\\) and \\(w \\Vdash D\\), this will be the case for all\n\\(x, y, v\\) s.t. \\(x \\Vdash A \\rightarrow\\), \\(y \\Vdash B \\rightarrow\nC\\), \\(v \\Vdash C \\rightarrow D\\). This is just the first step\nrequired to demonstrate that channel theory, and its underlying\nsubstructural logic, form a category.\n\nCategory theory is an extremely powerful tool in its own right. For a\nthorough introduction see Awodey (2006). For more work on the\nrelationship between various substructural logics and channel theory,\nsee Restall (1994a, 1997, 2006). Further category-theoretic work on\ninformation flow may be found in Goguen (2004\u2014see Other Internet\nResources). Recent important work on category-theoretic frameworks for\ninformation flow that extend to quantifiable/probabilistic\nframeworks is due to Seligman (2009). Perhaps the most in depth\ntreatment of information flow in category theoretic terms is to be\nfound in the work of Samson Abramsky, and an excellent overview may be\nfound in his \u201cInformation, Processes, and Games\u201d (2008).\nRecent work on the intersection between information as code and\ninformation as correlation uses substructural logics (relevance and\nlinear logics in particular) to model logical proofs as information\nsources themselves. A proof is a source of information par\nexcellence, and the contributions in the area by Mares (2016) are\nvital.\n4.3 Code and ranges\n\nExcitingly, there has been a recent surge in the recent development of\ninformation logics that combine the flexibility of categorial\ninformation theory with the subject matter of dynamic epistemic logics\nin order to design substructural epistemic logics. Sedlar\n(2015) combines the modal epistemic logics of implicit knowledge and\nbelief with substructural logics in order to capture the availability\nof evidence for the agent. Aucher (2015, 2014) redefines dynamic\nepistemic logic as a substructural logic corresponding to the Lambek\nCalculi of categorial information theory. Aucher shows also that the\nsemantics for DEL can be understood as providing a conceptual\nfoundation for the semantics of substructural logics in general. See\nHjortland and Roy (2016) for an extension of Aucher\u2019s approach\nto soft information.\n\nIn general, information logic approaches to dynamic epistemic\nphenomena that combine the DEL of section 1.2 and the substructural\nlogics of section 3.2 above have grown in popularity considerably. See\nfor example Aucher (2016, 2014), Tedder and Bilkov\u00e1\n(forthcoming), Tedder (2021, 2017), Sedl\u00e1r,\nPun\u010doch\u00e1\u0159, and Tedder (2023),\nPun\u010doch\u00e1\u0159, and Sedl\u00e1r (2021), and\nSedl\u00e1r (2021, 2019).\n\nOther logical frameworks that model information as code and range\nalong with information about encoding have been developed by\nVel\u00e1zquez-Quesada (2009), Liu (2009), Jago (2006), and others.\nThe key element to all of these approaches is the introduction of some\nsyntactic code to the conceptual architecture of the information as\nrange approach.\n\nTaking Vel\u00e1zquez-Quesada (2009) as a working example, start\nwith a modal-access model \\(M =\\langle S, R, V, Y, Z\\rangle\\)\nwhere \\(\\langle S, R, V \\rangle\\) is a Kripke Model, \\(Y\\) is the\naccess set function, and \\(Z\\) is the rule set\nfunction s.t. (where \\(I\\) is the set of classical propositional\nlanguage based on a set of atomic propositions):\n\n\\(Y : W \\rightarrow \\wp(I)\\) assigns a set of formulas of \\(I\\) to\neach \\(x \\in S\\).\n\\(Z : W \\rightarrow \\wp(R)\\) assigns a set of rules based on \\(I\\)\nto each \\(x \\in S\\).\n\n\nA modal-access model is a member of the class of modal access models\n\\(\\mathbf{MA}\\) iff it satisfies truth for formulas and truth\npreservation for rules. \\(\\mathbf{MA}_k\\) models are those\n\\(\\mathbf{MA}\\) models such that \\(R\\) is an equivalence relation.\n\nFrom here, inference is represented as a modal operation adding the\nrule\u2019s conclusion to the access set of information states of the\nof the agent such that the agent can access both the rule and its\npremises. Where \\(Y(x)\\) is the access set at \\(x\\), and \\(Z(x)\\) is\nthe rule set at \\(x\\):\n\nInference on knowledge: Where \\(M = \\langle S, R, V,\nY, Z\\rangle \\in \\mathbf{MA}_k\\), and \\(\\sigma\\) is a rule, \\(M_k\\sigma\n= \\langle S, R, V, Y', Z\\rangle\\) differs from \\(M\\) in \\(Y'\\), given\nby \\(Y'(x) := Y(x) \\cup \\{\\)conc\\((\\sigma)\\}\\) if\n\\(\\text{prem}(\\sigma) \\subseteq Y(x)\\) and \\(\\sigma \\in Z(x)\\), and by\n\\(Y'(x) := Y(x)\\) otherwise.\n\nThe dynamic logic for inference on knowledge then incorporates the\nability to represent \u201cthere is a knowledge inference\nwith \\(\\sigma\\) after which \\(\\phi\\)\nholds\u201d (Vel\u00e1zquez-Quesada 2009). It is in just\nthis sense that such modal information theoretical approaches model\nthe outputs of inferential processes, as opposed to the properties of\nthe inferential processes that generate such outputs (see the section\non categorial information theory for models of such dynamic\nproperties).\n\nJago (2009) proposes a rather different approach based upon the\nelimination of worlds considered possible by the agent as the\nagent reasons deductively. Such epistemic (doxastic) possibilities\nstructure an epistemic (doxastic) space under bounded rationality. The\nconnection with information as code is that the modal space is\nindividuated syntactically, with the worlds corresponding to possible\nresults of step-wise rule-governed inferences. The connection with\ninformation as range is that the rules that he agent does or does not\nhave access to will impact upon the range of discrimination for the\nagent. For example, if the agent\u2019s epistemic-base contains two\nworlds, a \\(\\neg \\phi\\) world and a \\(\\phi \\vee \\psi\\) world say, then\ncan refine their epistemic base only if they have access to the\ndisjunctive syllogism rule.\n\nA subtle but important contribution of Jago\u2019s is the following:\nthe modal space in question will contain only those epistemic options\nwhich are not obviously impossible. However, what is or is\nnot obviously impossible will vary from both agent to agent, as well\nas for a single agent over time as that agent refines its logical\nacumen. This being the case, the modal space in question has\nfuzzy boundaries.\n5. Special topics\n\nThere is a varied list of special topics pertaining to the logical\napproach to information. This section briefly illustrates just a\ncouple of them, which are important regardless of the particular\nstance one takes (information as range, as correlation, as code). The\nfirst topic is the issue of informational equivalence: when are two\nstructures in the logical approach one is using indistinguishable in\nterms of the information they are meant to encode, convey, or carry?\nAnd, when should two pieces of information be taken as equivalent or\nnot? The answers to this last question touch on the issue of how\ninformation (or information carriers, or information supporters) can\nbe combined or structured. This, in turn, has an impact on the\nproperties logical connectives are expected to behave. The second\ntopic in this section focuses on one of the connectives. Namely, it\nconcerns the various ways in which the idea of negative\ninformation can be understood conceptually, and properly dealt with\nformally.\n5.1 Information Structures and Equivalence\n\nEvery logical approach to information comes with its own kind of\ninformation structures. Depending on the particular stance and the\naspect of information to be stressed, these structures may stand for\ninformational states, structured syntactic representations, pieces of\ninformation understood as commodities, or global structures made up\nfrom local interrelated informational states or stages. Under which\nconditions can two informational structures be considered to be\ninformationally equivalent?\n\nAddressing this question brings out the need to have it clear at which\nlevel of granularity one is testing for equivalence. The\nclassical extensional notion of logical equivalence is a coarse, in\nthat informationally different claims such as 2 is even and 2\nis prime cannot be distinguished, as their extensions will\ncoincide. Equivalence given by identity at the level of\nrepresentations (say syntactic equality) is, on the contrary, too\nfine-grained in some cases: to a bilingual speaker, the information\nthat the shop is closed would be equally conveyed by a sign saying\n\u201cClosed\u201d as by a sign saying\n\u201cGeschlossen\u201d, even if the two words are\ndifferent.\n\nAn intermediate notion of equivalence that has proved central to the\nrange, correlational, and code views on information is the relation of\nbisimulation between structures. A bisimulation relation between two\ngraphs \\(G\\) and \\(H\\) (where both the arrows and nodes of the graphs\nare labelled) is a binary relation \\(R\\) between the nodes of the\ngraphs with the property that whenever a node \\(g\\) of \\(G\\) is\nrelated to a node \\(h\\) of \\(H\\), then:\n\n\\(g\\) and \\(h\\) have the same labels, and\nFor every relation label \\(L\\) and every L-child \\(g'\\) of \\(g\\),\nthere must be a L-child \\(h'\\) of \\(h\\) such that \\(h\\) and \\(h'\\) are\nrelated by \\(R\\). The analogous condition must hold for every\n\\(L\\)-child of \\(h\\).\n\n\nA simple example would be the relation between the following two\ngraphs (empty set of labels) that relates the point \\(x\\) with \\(a\\)\nand the point \\(y\\) with the points \\(b, c, d\\). \n\\[\\genfrac{}{}{0}{1}{x \\longrightarrow y}{\\phantom{x \\longrightarrow}\\circlearrowright} \\qquad \\text{ and } \\qquad \\genfrac{}{}{0}{1}{a \\longrightarrow b \\longrightarrow c \\longrightarrow d}{\\phantom{a \\longrightarrow b \\longrightarrow c \\longrightarrow} \\circlearrowright} \\]\n\n\nBisimulation is naturally a central notion for the\ninformation-as-range perspective because the Kripke models of\n section 1\n are precisely labelled graphs. It is a classical result of modal\nlogic that if two states of two models are related by a bisimulation,\nthen the states will satisfy exactly the same modal formulas, and in\naddition a first order property of states is definable in the basic\nmodal language if and only if the property is preserved under\nbisimulation.\n\nAs for the correlational stance, in situation theory bisimulation\nturns out to be the right notion in determining whether two infons\nthat might look structurally different are actually the same as pieces\nof information. For example, one possible analysis of Liar-like claims\nleads to infons that are nested in themselves, such as\n\n\\[ \\sigma = \\llangle \\text{True}, \\text{what} : \\sigma , 0\\rrangle. \\]\n\n\nOne can naturally depict the structure of \\(\\sigma\\) as a labelled\ngraph, which will be bisimilar to the graph associated with the\napparently different infon \n\\[ \\psi = \\llangle \\text{True}, \\text{what} : \\llangle \\text{True}, \\text{what} : \\psi , 0\\rrangle , 0\\rrangle. \\]\n\n\nThe notion of bisimulation appeared independently in computer science,\nso it so no surprise that it also features in matters related to the\ninformation-as-code approach, with its focus on representation and\ncomputation. In particular, several versions of bisimulation have been\napplied to classes of automata to determine when two of them are\nbehaviourally equivalent, and data encodings such as \n\\[ L =\\langle 0, L\\rangle \\text{ and } L = \\langle 0, \\langle 0, L\\rangle \\rangle, \\]\n\n\nboth of which represent the same object (an infinite list of zeroes),\ncan be identified as such by noticing that the graphs that depict the\nstructure of these two expressions are bisimilar. See Aczel (1988),\nBarwise and Moss (1996), and Moss (2009) for more information about\nbisimulation an circularity, connections with modal logic, data\nstructures, and coalgebras.\n\nBut there is much more to be said about informational equivalence and\nthe right level of granularity. To reiterate, the themes highlighted\nby the various stances on information (partiality, aboutness,\nencoding, range, dynamics, agency) pose many challenges. For another\nexample: \u20183 is prime\u2019, and \u2018the sum of the angles of\na triangle is 180 degrees\u2019 are logically equivalent in the\nstandard sense, as they are both mathematical truths. But they should\nnot be always taken to be informationally equivalent in general.\nFirst, they are about different topics. Second, an agent might know\nthat 3 is prime, and yet not know that 180 is the sum of the angles of\na triangle, due to its having only partial knowledge about triangles.\nThird, even if the agent had enough current knowledge to eventually\ninfer that the sum of the angles of a triangle is 180 degrees, the\ninference might be hard for this agent, so being told that the sum of\nthe angle is 180 would be informative in a way that being told that 3\nis prime would not.\n\nInformation, just as content, meaning, knowledge, belief, and many\nagent attitudes (seeing that, suspecting that\u2026) exhibit\nhyperintensional properties. There is an active line of research that\nstudies how formal systems can capture these phenomena (see the entry\non\n hyperintensionality).\n Here, we just note that the formal approaches to hyperintensionality\nmost closely related to this entry follow some of these\nstrategies:\n\nExtending possible-world semantics by allowing impossible worlds\nand adding a notion of topics. Given a formula, one does not consider\nonly its truth conditions (the range of words that make it true) but a\npair , so formulas with the same truth conditions may be told apart by\nvirtue of being associated to different topics. See Yablo (2014), Jago\n(2015), Berto and Jago (2019).\nDefining models based on states (not worlds) that can be partial\nand/or inconsistent with respect to the information they validate. The\nmodels give a relation of \u201cparthood\u201d between states, and a\nbinary fusion operation on states. The truth conditions of a formula\nis a pair \\(\\langle \\textit{truthmakers}, \\textit{falsifiers}\n\\rangle\\) of subsets of states that make a formula true and false,\nrespectively. There is also a formal way to define the topic of a\nformula. As before, topics give a way to differentiate formulas with\nthe same truth conditions. The partiality of states and the definition\nof truth conditions allow for another way to make differences, because\ntwo formulas may have the same set of verifiers but a different set of\nfalsifiers. This approach is close in spirit to the situation theory\ntradition. See Fine (2017) and Fine and Jago (2020).\nUsing relevant logics to take advantage of the particularities of\nits semantics (see Mares 2004).\n From the formal point of view, approaches (1), (2), (3) are\ncloser to the formal systems used in the information-as-range,\ninformation-as-correlation, and information-as-code stances,\nrespectively. Most of the work has been on hyperintensionality in\ngeneral, not specifically about information. However, see Berto and\nHawke (2021) for a semantics for an operator of knowability relative\nto information, where the construction \\(K_\\phi \\psi\\) is understood\nas saying that \\(\\psi\\) is knowable on the basis of information\n\\(\\psi\\), and Berto and Jago (2019) for a discussion on the use\nof impossibilities to treat issues such as informative sentences and\ninferences. In section 4.2 we already referred to Mares (2004) and the\ninformational interpretation of relevant logic. Jago (2020), on the\nother hand, presents a truthmaker semantics for relevant logic. There\nare also some proposals of more general frameworks for\nhyperintensionality for which (1) and (2) above can be seen as\nparticular cases or applications (see Sedlar 2021 and Leitbeg 2018),\nand van Benthem (2019) exemplifies how truthmaker semantics may be\ntranslated into a modal information logic. The more general point (van\nBenthem 2019) illustrates is that there are, roughly speaking, two\nnatural and complementary styles of logical systems one can use to\nanalyse a new notion. Some systems are more explicit, in that they\nextend an existing system (e.g. modal logic) with laws for new\nvocabulary that is directly related to the new notion one wants to\nanalyze, without changing the previously existing logical notions. In\ncontrast, a more implicit way of dealing with a new notion is to use a\nnonstandard reasoning system, so making changes on what the allowed\nreasoning patterns are, rather than adding new vocabulary. The use of\none or other style, as well as the existence or not of translations\nbetween them, may help shed light on what philosophical claims may or\nmay not be made about the notion one is studying. An example of a\nrelevant question, in our context, is to what extent\nhyperintensionality may or may not be captured by the explicit style\nof classical modal informational logics.\n\n5.2 Negative information\n\nThis entry has focused mostly on positive information.\nFormally speaking, negative information is simply the\nextension-via-negation of the positive fragment of any logic built\naround information-states. Different negation-types will constrain the\nbehaviour of negative information in various ways. Informally,\nnegative information may be thought of variously as what is\ncanonically expressed with sentential negation, process exclusion\n(both propositional and sub-propositional) and more. Even when we\nrestrict ourselves to a single conceptual notion, there may be\nvigorous philosophical debate as to which formal construction best\ncaptures the notion in question. In this section, we run though\nseveral formal analyses of negative information, we examine some of\nthe philosophical debates surrounding the suitability of various\nformal constructions with respect to particular applications, and\nexamine the related topic of failure of information flow in the\nsituation-theoretic sense, which may give raise to misinformation or\nlack of information in particular settings.\n\nNon-constructive intuitionistic negation, is aimed towards accounting\nfor negative information in the context of information flow via\nobservation. For more details on this point, see the subsection\nintuitionistic logics and Beth and Kripke models in the supplementary\ndocument:\n Abstract Approaches to Information Structure.\n\nWorking with the frames from\n section 3.1,\n non-constructive intuitionistic negation is defined in terms of the\nconstructive implication, (21), which is combined with bottom,\n\\(\\mathbf{0}\\), which holds nowhere, as specified by its frame\ncondition: \n\\[\\tag{18} x \\Vdash \\mathbf{0} \\text{ for no } x \\in \\mathbf{F} \\]\n\n\nHence intuitionistic negation is defined as follows: \n\\[\\tag{19} -A := A \\rightarrow \\mathbf{0} \\]\n\n\nHence the frame condition for \\(-A\\) is as follows: \n\\[\\tag{20} x \\Vdash -A [A \\rightarrow 0] \\text{ iff for all } y \\in \\mathbf{F}, \\text{ s.t. } x \\sqsubseteq y, \\text{ if } y \\Vdash A \\text{ then } y \\Vdash 0 \\]\n\n\n(20) states that if \\(x\\) carries the information that \\(-A\\), then\nthere no state \\(y\\) such that \\(y\\) is an informational development\nof \\(x\\) where \\(y\\) carries the information that \\(A\\).\n\nThe definition of \\(-A\\) in terms of \\(A \\rightarrow \\mathbf{0}\\)\nthrows up an asymmetry between positive and negative information. In\nan information model \\(-A\\) holds at \\(x \\in \\mathbf{F}\\) iff \\(A\\)\ndoes not hold at any \\(y \\in \\mathbf{F}\\) such that \\(x \\sqsubseteq\ny\\). Whilst the verification of \\(A\\) at \\(x \\in \\mathbf{F}\\) only\ninvolves checking \\(x\\), verifying \\(-A\\) at \\(x \\in \\mathbf{F}\\)\ninvolves checking all \\(y \\in \\mathbf{F}\\) such that \\(x \\sqsubseteq\ny\\). According to Gurevich (1977) and Wansing (1993), this asymmetry\nmeans that intuitionistic logic does not provide an adequate treatment\nof negative information, since, unlike the verification of \\(A\\),\nthere is no way of verifying \\(-A\\) \u201con the spot\u201d so to\nspeak. Gurevich and Wansing\u2019s objection to this asymmetry is a\ncritical response to Grzegorczyk (1964). For arguments in support of\nGrzegorczyk\u2019s asymmetry between positive and negative\ninformation, see Sequoiah-Grayson (2009). A fully constructive\nnegation that allows for falsification \u201con the spot\u201d is\nknown also as Nelson Negation on account of it being embedded\nwithin Nelson\u2019s constructive systems (Nelson 1949, 1959). For a\ncontemporary development of these constructive systems, see section\n2.4.1 of Wansing (1993).\n\nIn a static logic setting, negation is, at the very least, used to\nrule out truth (if not to express explicit falsity). In a dynamic\nsetting, negation will be used to rule out particular\nprocesses. For a development negative information as process\nexclusion in the context of categorial information theory see\nSequoiah-Grayson (2013). This idea has its origins in the Dynamic\nPredicate Logic of Groenendijk and Stokhof (1991), in particular with\ntheir development of negative information via negation as\ntest-failure. For an exploration between the conceptions of\nnegative information as process exclusion and test-failure, see\nSequoiah-Grayson (2010).\n\nIn any logic for negation as process-exclusion, the process-exclusion\nwill be non-directional if the logic in question is\ncommutative. Directional process-exclusion will result when we remove\nthe structural rule of commutation. For a discussion of the\nrelationship between the formalisation of directional process\nexclusion as commutation-failure along with symmetry-failure on\ncompatibility and incompatibility relations on information states, see\nSequoiah-Grayson (2011). For an extended discussion of negative\ninformation in the context of categorial grammars, see Buszkowski\n(1995). Wansing (2016) uses the informational interpretation of\nsubstructural logics to launch a thorough investigation of the issues\nsurrounding negative information outlined above. Wansing\u2019s\nconclusion is that the symmetry between positive and negative\ninformation survives all existent arguments to the contrary. At the\ntime of writing, this debate is lively and ongoing.\n\n6. Conclusion\n\nThere is a bi-directional relation between logic and information. On\nthe one hand, information underlies the intuitive understanding of\nstandard logical notions such as inference (which may be thought of as\nthe process that turns implicit information into explicit informaiton)\nand computation. On the other hand, logic provides a formal framework\nfor the study of information itself.\n\nThe logical study of information focuses on some of the most\nfundamental qualitative aspects of information. Different stances on\ninformation naturally highlight some of these aspects more than\nothers. Thus, the information-as-range stance most naturally\nhighlights agency and the dynamics of information in settings with\nmultiple agents that can interact with each other. The aboutness of\ninformation (information is always about something) is a central theme\nin the information-as-correlation stance. The topic of encoding\ninformation and its processing (as in the case of formal inference) is\nat the core of the information-as-code stance. None of these\nqualitative aspects of information is exclusive to just one of the\nstances, even if some stress certain topics more than others. Some\nthemes such as the structure of information and its relation with\ninformation content are equally pertinent regardless of the stance.\nThe ways in which information is studied in this entry differs from\nother important formal frameworks that study information\nquantitatively. For example, Shannon\u2019s statistical theory of\ninformation is concerned with things such as optimizing the amount of\ndata that can be transmitted via a noisy channel, and the\nKolmogorov\u2019s complexity theory quantifies the informational\ncomplexity of a string as the length of the shortest program that\noutputs it when executed by a fixed universal Turing machine.\n\nThe logical analysis of information includes fruitful\nreinterpretations of known logical systems (such as epistemic logic or\nrelevance logic), and new systems that result from attempts to capture\nfurther aspects of information. Still other logical approaches to the\nanalysis of information result from combining aspects of two different\nstances, as with the constraint systems of\n section 4.\n New frameworks (situation theory in the 80s) have also resulted from\nexploring from scratch what sort of inferences \u2014 including those\nthat are novel and non-classical \u2014 one should allow in order to\nmodel certain aspects of information.\n\nLooking for interfaces between the three stances is still a nascent\ndirection of inquiry, discussed here in\n section 4.\n A complementary issue is whether the stances can be unified. There\nare several formal frameworks that, beyond serving as potential\nsettings for exploring the issue of unification, are abstract\nmathematical theories of information in their own right. Each of these\ngoes well beyond the scope of this entry:\n\nDomain Theory (Abramsky and Jung 1994): it has been used to study\nthe processes of unraveling or \u201cimprovement\u201d of\ninformational states in terms of partial orderings of information\nstates that naturally arise across the stances.\nPoint-free topology: it has deep connections with computer science\nand it can actually be motivated as a logic of information (Vickers\n1996).\nChu Spaces (Pratt 1995): in category theory they are presented as\ngeneralizations of topologies. The immediate link with things\ndiscussed in this entry is that the classifications used in situation\ntheory are simply Chu spaces, discovered independently and with\ndifferent aims.\nCoalgebra: another branch of category theory that has also been\npresented as the \u201cmathematics of sets and observations\u201d\n(Jacobs 2012, Other Internet Resources). This framework has strong\nlinks with many notions discussed in this entry, in particular modal\nlogic\n (section 1)\n and bisimulation\n (section 5.1).\nProbability Theory: it is clearly at the center of abstract\nquantitative approaches to information. Various versions of\nthe inverse relationship principle that lead to measures of\nsemantic information (see\n section 1.3\n and Floridi 2013) descend from the version used by Shannon (1953\n[1950]): in a communication setting via noisy channels, the less\nexpected a received message is, the more informative it is.\n\n\nThe logical study of information resembles in spirit other more\ntraditional endeavours, such as the logical study of the concept of\ntruth or computation: in all these cases the object of logical study\nplays a central role in the intuitive understanding of logic itself.\nThe three perspectives on qualitative information presented in this\nentry (ranges, correlations, and code) portrait the diverse state of\nthe art in this field, where many directions of research are open,\nboth as a way of searching for unifying or interfacing settings for\nthe different stances, and of deepening the understanding of the main\nqualitative features of information (dynamics, aboutness, encoding,\ninteraction, etc.) within each stance itself.\n\nInterested readers may wish to pursue the topics in the supplementary\ndocument\n\nAbstract Approaches to Information Structure\n\n\nwhich covers the topics\n intuitionistic logic, Beth and Kripke models,\n and\n algebraic and other approaches to modal information theory and related areas.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Abramsky, S., 2008, \u201cInformation, Processes, and\nGames\u201d, in Adriaans and van Benthem 2008, 483\u2013550.",
                "Abramsky, S. and A. Jung, 1994, \u201cDomain Theory\u201d, in\n<em>Handbook of Logic in Computer Science</em>, S. Abramsky, D.\nGabbat, and T. S. E. Maibaum (eds.), Oxford: Oxford University Press,\n1\u2013168.",
                "Aczel, P., 1988, <em>Non-well-founded Sets</em>, (CSLI Lecture\nNotes 14), Stanford: CSLI Publications.",
                "Adriaans, P. and J. F. A. K. van Benthem (eds.), 2008,\n<em>Philosophy of Information</em> (Handbook of the Philosophy of\nScience: Volume 8), Amsterdam: North Holland.",
                "Allo, P., 2009, \u201cReasoning about Data and\nInformation\u201d, <em>Synthese</em>, 167: 231\u2013249.",
                "\u2013\u2013\u2013, 2017, \u201cHard and Soft Logical\nInformation\u201d, <em>Logic and Computation</em>, 27(8):\n2505\u20132524.",
                "Artemov, S., 2008, \u201cThe Logic of Justification\u201d,\n<em>Review of Symbolic Logic</em>, 1(4): 477\u2013513.",
                "Artemov, S. and M. Fitting, 2012, \u201cJustification\nLogic\u201d, <em>The Stanford Encyclopedia of Philosophy</em> (Fall\n2012 Edition), Edward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2012/entries/logic-justification/\">https://plato.stanford.edu/archives/fall2012/entries/logic-justification/</a>&gt;",
                "Aucher, G. 2014, \u201cDynamic Epistemic Logic as a Substructural\nLogic\u201d, in A. Baltag and S. Smets (eds.) 2014:\n855\u2013880.",
                "\u2013\u2013\u2013, 2015, \u201cWhen Conditional Logic and\nBelief Revision meet Substructural Logics\u201d, <em>Proceedings of\nthe International Workshop on Defeasible and Ampliative Reasoning</em>\n(DARe-15),\n <a href=\"http://ceur-ws.org/Vol-1423/DARe-15_1.pdf\" target=\"other\">available online</a>.",
                "\u2013\u2013\u2013, 2016, \u201cDynamic Epistemic Logic in\nUpdate Logic\u201d, <em>Journal of Logic and Computation</em>, 26(6):\n1913\u20131960.",
                "Awodey, S., 2006, <em>Category Theory</em> (Oxford Logic Guides:\nVolume 49), Oxford: Clarendon Press.",
                "Baltag, A., 2016, \u201cTo Know is to Know the Value of a\nVariable\u201d, <em>Advances in Modal Logic</em>, 11:\n135\u2013155.",
                "Baltag, A., and J. van Benthem, 2021, \u201cA Simple Logic of\nFunctional Dependence\u201d, <em>Journal of Philosophical Logic</em>,\n50: 939\u20131005.",
                "Baltag, A., B. Coecke, and M. Sadrzadeh, 2007, \u201cEpistemic\nActions as Resources\u201d, <em>Journal of Logic and\nComputation</em>, 17(3): 555\u2013585.",
                "Baltag A., H. P. van Ditmarsch, and L. S. Moss, 2008,\n\u201cEpistemic Logic and Information Update\u201d, in Adriaans and\nvan Benthem, 2008: 361\u2013456.",
                "Baltag, A., and S. Smets, 2008, \u201cA Qualitative Theory of\nDynamic Interactive Belief Revision\u201d, in <em>Logic and the\nFoundation of Game and Decision Theory</em> (LOFT7), G. Bonanno, W.\nvan der Hoek, and M. Wooldridge (Eds.), Volume 3 of <em>Texts in Logic\nand Games</em>, 13\u201360. Amsterdam: Amsterdam University\nPress.",
                "\u2013\u2013\u2013 (eds.), 2014, <em>Johan van Benthem on Logic\nand Information Dynamics</em> (Outstanding Contributions to Logic 5),\nCham: Springer.",
                "Bar-Hillel, Y. and R. Carnap, 1952, \u201cAn Outline of a Theory\nof Semantic Information\u201d, Technical Report No. 247, Research\nLaboratory of Electronics, Cambridge, MA: MIT. Reprinted in\n<em>Language and Information: Selected Essays on their Theory and\nApplication</em>, Y. Bar-Hillel, <em>Addison-Wesley Series in\nLogic</em>, Israel: Jerusalem Academic Press and Addison-Wesley, 1964,\n221\u201374.",
                "Barwise, J., 1988, \u201cThree Views of Common Knowledge\u201d,\n<em>TARK \u201988 Proceedings of the 2nd conference on Theoretical\naspects of reasoning about knowledge</em>, San Francisco: Morgan\nKaufmann, p. 365\u2013379.",
                "\u2013\u2013\u2013, 1993, \u201cConstraints, Channels, and the\nFlow of Information\u201d, in <em>Situation Theory and its\nApplications, 3</em>, (CSLI Lecture Notes 37), Aczel et al. (eds.),\nStanford: CSLI Publications.",
                "\u2013\u2013\u2013, 1997, \u201cInformation and\nImpossibilities\u201d, <em>Notre Dame Journal of Formal Logic</em>\n38(4): 488\u2013515.",
                "Barwise, J. and J. Etchemendy, 1987, <em>The Liar</em>, Oxford:\nOxford University Press.",
                "Barwise, J. and L. Moss, 1996, <em>Vicious Circles</em>, (CSLI\nLecture Notes 60), Stanford: CSLI Publication.",
                "Barwise, J. and J. Perry, 1983, <em>Situations and Attitudes</em>,\nCambridge, MA: MIT Press.",
                "\u2013\u2013\u2013, 1985, \u201cShifting Situations and Shaken\nAttitudes\u201d, <em>Linguistics and Philosophy</em>, 8:\n105\u2013161.",
                "Barwise J. and J. Seligman, 1997, <em>Information Flow: The Logic\nof Distributed Systems</em>, Cambridge Tracts in Theoretical Computer\nScience 44, New York: Cambridge University Press.",
                "Beal, J. C. and G. Restall, 2006, <em>Logical Pluralism</em>,\nOxford: Clarendon Press.",
                "van Benthem, J., 1995, <em>Language in Action: Categories,\nLambdas, and Dynamic Logic</em>, Cambridge, MA: MIT Press.",
                "\u2013\u2013\u2013, 2000, \u201cInformation Transfer Across\nChu Spaces\u201d, <em>Logic Journal of the IGPL</em>, 8(6):\n719\u2013731.",
                "\u2013\u2013\u2013, 2003, \u201cLogic and Dynamics of\nInformation\u201d, <em>Minds and Machines</em>, 13(4):\n503\u2013519.",
                "\u2013\u2013\u2013, 2004, \u201cDynamic Logic for Belief\nRevision\u201d, <em>Journal of Applied Non-Classical Logics</em>,\n14(2): 129\u2013155.",
                "\u2013\u2013\u2013, 2006, \u201cInformation as Correlation\nversus Information as Range\u201d, Technical Report PP-2006-07,\nAmsterdam: ILLC (University of Amsterdam).",
                "\u2013\u2013\u2013, 2009, \u201cThe Information in\nIntuitionistic Logic\u201d, <em>Synthese</em>, 167:\n251\u2013270.",
                "\u2013\u2013\u2013, 2010, \u201cCategorial versus Modal\nInformation Theory\u201d, <em>Linguistic Analysis</em>, 36: 533",
                "\u2013\u2013\u2013, 2011, <em>Logical Dynamics of Information\nand Interaction</em>, Cambridge: Cambridge University Press.",
                "\u2013\u2013\u2013, 2016, \u201cTracking Information\u201d,\nin K. Bimb\u00f3 (ed.) 2016, 363\u2013390.",
                "\u2013\u2013\u2013, 2019, \u201cImplicit and Explicit Stances\nin Logic\u201d, <em>Journal of Philosphical Logic</em>, 48:\n571\u2013601.",
                "van Benthem, J., J. van Eijck, and B. Kooi, 2006, \u201cLogics of\nCommunication and Change\u201d, <em>Information and Computation</em>,\n204(11): 1620\u20131662.",
                "van Benthem, J. and M. Martinez, 2008, \u201cThe Stories of Logic\nand Information\u201d. in <em>Philosophy of Information</em>, in\nAdriaans and van Benthem, 2008, p. 217\u2013280.",
                "Berto, F. and Hawke, P., 2021, \u201cKnowability Relative to\nInformation\u201d, <em>Mind</em>, 130(517): 1\u201333,\ndoi:10.1093/mind/fzy045",
                "Berto, F. and Jago M., 2019, <em>Impossible Worlds</em>, Oxford:\nOxford University Press. doi:10.1093/oso/9780198812791.001.0001",
                "Bertomeu, J. and Marinovic, I., 2016, \u201cA Theory of Hard and\nSoft Information\u201d, <em>The Accounting Review</em>, 91(1):\n1\u201320.",
                "Beth, E. W., 1955, \u201cSemantic Entailment and Formal\nDerivability\u201d, <em>Koninklijke Nederlandse Akademie van\nWentenschappen, Proceedings of the Section of Sciences</em>, 18:\n309\u2013342).",
                "\u2013\u2013\u2013, 1956, \u201cSemantic Construction of\nIntuitionistic Logic\u201d, <em>Koninklijke Nederlandse Akademie van\nWentenschappen, Proceedings of the Section of Sciences</em>, 19:\n357\u2013388.",
                "Bimb\u00f3, K. (ed.), 2016, <em>J. Michael Dunn on Information\nBased Logics</em> (Outstanding Contributions to Logic 8), Cham:\nSpringer.",
                "Bimb\u00f3, K. (ed.), 2022, <em>Relevance Logics and other Tools\nfor Reasoning. Essays in Honor of J. Michael Dunn</em> (Tributes:\nVolume 46), London: College Publications.",
                "Blackburn, P., M. de Rijke, and Y. Venema, 2001, <em>Modal\nLogic</em>, Cambridge tracts in theoretical computer science 53,\nCambridge: Cambridge University Press.",
                "Brady, R. T., 2016, \u201cComparing Contents with\nInformation\u201d, in K. Bimbo (ed.) 2016, 147\u2013159.",
                "Buszkowski, W., 1995, \u201cCategorical Grammars with Negative\nInformation\u201d, in <em>Negation, A Notion in Focus</em>, H.\nWansing (ed.), Berlin: Gruyter, 107\u2013126.",
                "Ciardelli, I., Groenendijk, J., Roelofsen, F., 2018,\n<em>Inquisitive Semantics</em>, Oxford: Oxford University Press.",
                "D\u2019Agostino, M. and L. Floridi, 2009, \u201cThe Enduring\nScandal of Deduction\u201d, <em>Synthese</em> 167:\n317\u2013315.",
                "Devlin, K., 1991, <em>Logic and Information</em>, Cambridge:\nCambridge University Press.",
                "van Ditmarsh, H., W. van der Hoek, and B. Kooi, 2008, <em>Dynamic\nEpistemic Logic</em>, Dordrecht: Springer.",
                "Dretske, F., 1981, <em>Knowledge and the Flow of Information</em>,\nCambridge: Cambridge University Press.",
                "Dunn, J. M., 1993, \u201cPartial Gaggles Applied to Logics with\nRestricted Structural Rules\u201d, in <em>Substructural Logics</em>,\nP. Schroeder-Heister and K. Dosen (eds.), Oxford: Oxford Science\nPublications, Clarendon Press, 63\u2013108.",
                "\u2013\u2013\u2013, 2001, The Concept of Informaiton and the\nDevelopment of Modern Logic, in W. Stelzner and M. Stoeckler (eds.)\n<em>Zwischen traditioneller und moderner Logik: Nichtklassiche\nAns\u00e4tze</em>, Paderborn: Mentis Verlag GmbH, 423\u2013447.",
                "\u2013\u2013\u2013, 2015, The Relevance of Relevance to\nRelevance Logic, <em>Logic and its Applications</em> (Lecture Notes in\nComputer Science: Vol. 8923), Berlin Heidelberg: Springer-Verlag,\n11\u201329.",
                "Duzi, M., 2010, \u201cThe Paradox of Inference and the\nNon-Triviality of Analytic Information\u201d, <em>Journal of\nPhilosophical Logic</em>, 38(5): 473\u2013510.",
                "Duzi, M., B. Jespersen, and P. Materna, 2010, <em>Procedural\nSemantics for Hyperintensional Logic: Foundations and Applications of\nTIL</em> (Logic, Epistemology, and the Unity of Science: Volume 17),\nDordrecht, London: Springer.",
                "Dyckhoff, R. and M. Sadrzadeh, 2010, \u201cA Cut-Free Sequent\nCalculus for Algebraic Dynamic Epistemic Logic\u201d, Computer\nScience Research Report, University of Oxford, CS-RR-10-11.",
                "van Eijck, J. and A. Visser, 2012, \u201cDynamic\nSemantics\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2012 Edition), Edward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/win2012/entries/dynamic-semantics/\">https://plato.stanford.edu/archives/win2012/entries/dynamic-semantics/</a>&gt;.",
                "Fagin R., J. Halpern, and M. Vardi, 1995, \u201cReasoning about\nKnowledge\u201d. Cambridge, MA: MIT Press.",
                "Fine, K., 2017, \u201cTruthmaker Semantics\u201d, in <em>A\nCompanion to the Philosophy of Language</em> (Volume 2), Bob Hale,\nCrispin Wright, and Alexander Miller (eds.), 2nd edition, Chichester:\nWiley Blackwell, 556\u2013577. doi:10.1002/9781118972090.ch22",
                "Fine, K. and Jago, M., 2019, \u201cLogic for Exact\nEntailment\u201d, <em>Review of Symbolic Logic</em>, 12(3):\n536\u2013555. doi:10.1017/S1755020318000151",
                "Floridi, L., 2004, \u201cOutline of a Theory of Strongly Semantic\nInformation\u201d, <em>Minds and Machines</em>, 14(2):\n197\u201322.",
                "\u2013\u2013\u2013, 2006, \u201cThe Logic of Being\nInformed\u201d, <em>Logique et Analyse</em>, 49(196):\n433\u2013460.",
                "\u2013\u2013\u2013, 2013, \u201cSemantic Conceptions of\nInformation\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Spring 2013 Edition), Edward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/spr2013/entries/information-semantic/\">https://plato.stanford.edu/archives/spr2013/entries/information-semantic/</a>&gt;.",
                "Gabbay, D. M., 1993, \u201cLabelled Deductive Systems: A Position\nPaper\u201d, in <em>Logic Colloquium \u201990: ASL Summer Meeting in\nHelsinki</em>, J. Oikkonen and J. Vaananen (eds.), Berlin:\nSpringer-Verlag, 66\u201388.",
                "\u2013\u2013\u2013, 1996, <em>Labelled Deductive Systems:\nVolume 1</em> (Oxford Logic Guides 35), New York: Oxford University\nPress.",
                "Ganter, B. and R. Wille, 1999, <em>Formal Concept Analysis,\nFoundations and Applications</em> (LNCS 3626), Berlin, Heidelberg:\nSpringer.",
                "Ghidini, C. and F. Giunchiglia, 2001, \u201cLocal Model\nSemantics, or Contextual Reasoning = Locality + Compatibility\u201d.\n<em>Artificial Intelligence</em>, 127: 221\u2013259.",
                "Groenendijk, J. and M. Stokoff, 1991, \u201cDynamic Predicate\nLogic\u201d, <em>Linguistics and Philosophy</em>, 14:\n33\u2013100.",
                "Gurevich, Y., 1977, \u201cIntuitionistic Logic with Strong\nNegation\u201d, <em>Studia Logica</em>, 36: 49\u201359.",
                "Grzegorczyk, A., 1964, \u201cA Philosophically Plausible\nInterpretation of Intuitionistic Logic\u201d, <em>Indagnationes\nMathematicae</em>, 26: 596\u2013601.",
                "Harrison-Trainor, M., Holliday, W. H., Icard, T. F., forthcoming,\n\u201cInferring Probability Comparisons\u201d, <em>Mathematical\nSocial Sciences</em>.",
                "Hintikka, J., 1970, \u201cSurface Information and Depth\nInformation\u201d, in <em>Information and Inference</em>, J. Hintikka\nand P. Suppes (eds.), Dordrecht: Reidel, 263\u201397.",
                "\u2013\u2013\u2013, 1973, <em>Logic, Language Games, and\nInformation</em>, Oxford: Clarendon Press.",
                "\u2013\u2013\u2013, 2007, <em>Socratic Epistemology:\nExplorations of Knowledge\u2014Seeking by Questions</em>, Cambridge:\nCambridge University Press.",
                "Hjortland, O., Roy, O., 2016, \u201cDynamic consequence for soft\ninformation\u201d, <em>Journal of Logic and Computation</em>, 26(6):\n1843\u20131864.",
                "Israel, D. and J. Perry, 1990, \u201cWhat is Information?\u201d,\nin <em>Information, Language and Cognition</em>, P. Hanson, (ed.),\nVancouver: University of British Columbia.",
                "\u2013\u2013\u2013, 1991, \u201cInformation and\nArchitecture\u201d, in <em>Situation Theory and its Applications</em>\nVol 2, J. Barwise, J.M. Gawron, G. Plotkin, and S. Tutiya, (eds.),\nStanford: CSLI Publications.",
                "Jago, M., 2006, \u201cRule-based and Resource-Bounded: A New Look\nat Epistemic Logic\u201d, in <em>Proceedings on the Workshop on\nLogics for Resource\u2014Bounded Agents, as part of ESSLLI 2006</em>,\nT. Agotnes and N. Alechina (eds.), 63\u201377, 2006.",
                "\u2013\u2013\u2013, 2009, \u201cLogical Information and\nEpistemic Space\u201d, <em>Synthese</em>, 167: 327\u2013341.",
                "\u2013\u2013\u2013, 2015, \u201cImpossible Worlds\u201d,\n<em>No\u00fbs</em>, 49(4): 713\u2013728. doi:10.1111/nous.12051",
                "\u2013\u2013\u2013, 2020, \u201cTruthmaker Semantics for\nRelevant Logic\u201d, <em>Journal of Philosophical Logic</em>, 49:\n681\u2013702. doi:10.1007/s10992-019-09533-9",
                "King, J. C., 2012, \u201cStructured Propositions\u201d, <em>The\nStanford Encyclopedia of Philosophy</em> (Winter 2012 Edition), Edward\nN. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/win2012/entries/propositions-structured/\">https://plato.stanford.edu/archives/win2012/entries/propositions-structured/</a>&gt;.",
                "Kratzer, A., 2011, \u201cSituations in Natural Language\nSemantics\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Fall 2011 Edition), Edward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2011/entries/situations-semantics/\">https://plato.stanford.edu/archives/fall2011/entries/situations-semantics/</a>&gt;.",
                "Kripke, S. A., 1963, \u201cSemantical Analysis of Modal\nLogic\u201d, <em>Zeitschrift fur Mathematichs Logik und Grundlagen\nder Mathematik</em>, 9: 67\u201396.",
                "\u2013\u2013\u2013, 1965, \u201cSemantical Analysis of\nIntuitionistic Logic I\u2018\u201d, in <em>Formal Systems and\nRecursive Functions</em>, J. Crossley and M. Dummett (eds.),\nAmsterdam: North Holland, 92\u2013129.",
                "Lambek, J., 1958, \u201cThe Mathematics of Sentence\nStructure\u201d, <em>American Mathematical Monthly</em>, 65:\n154\u2013170.",
                "\u2013\u2013\u2013, 1961, On the Calculus of Syntactic Types,\nin <em>Structure of Language and its Mathematical Aspects</em>, R.\nJakobson (ed.), Providence: American Mathematical Society,\n166\u2013178.",
                "Leitgeb, H., 2019, \u201cHYPE: A System of Hyperintensional\nLogic\u201d, <em>Journal of Philosophical Logic</em> 48(2):\n305\u2013405. doi:10.1007/s10992-018-9467-0",
                "Lewis, D., 1969, <em>Convention: A Philosophical Study</em>,\nCambridge: Harvard University Press.",
                "Liu, F., 2009, \u201cDiversity of Agents and Their\nInteraction\u201d, <em>Journal of Logic, Language, and\nInformation</em>, 18(1): 23\u201353.",
                "Mares, E., 1996, \u201cRelevant Logic and the Theory of\nInformation\u201d, <em>Synthese</em> 109: 345\u2013370.",
                "\u2013\u2013\u2013, 2016, \u201cManipulating Sources of\nInformation: Towards and Interpretation of Linear Logic and Strong\nRelevance Logic\u201d, in K. Bimbo (ed.) 2016: 107\u2013132.",
                "\u2013\u2013\u2013, 2004, <em>Relevant Logic: A Philosophical\nInterpretation</em>, Cambridge: Cambridge University Press.",
                "\u2013\u2013\u2013, 2009, \u201cGeneral Information in\nRelevant Logic\u201d, <em>Synthese</em>, 167: 343\u2013362.",
                "McGrath, M., 2012, \u201cPropositions\u201d, <em>The Stanford\nEncyclopedia of Philosophy</em> (Summer 2012 Edition), Edward N. Zalta\n(ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/sum2012/entries/propositions/\">https://plato.stanford.edu/archives/sum2012/entries/propositions/</a>&gt;.",
                "Moss, L. S., 2009, \u201cNon-wellfounded Set Theory\u201d,\n<em>The Stanford Encyclopedia of Philosophy</em> (Fall 2009 Edition),\nEdward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2009/entries/nonwellfounded-set-theory/\">https://plato.stanford.edu/archives/fall2009/entries/nonwellfounded-set-theory/</a>&gt;.",
                "Moss, L. and J. Seligman, 1996, \u201cSituation Theory\u201d, in\n<em>Handbook of Logic and Language</em>, J. van Benthem and A. ter\nMeulen, (eds.), Amsterdam: Elsiever.",
                "Negro, Niccol\u00f2, 2022, \u201cCan the Integrated Information\nTheory Explain Consciousness from Consciousness Itself?\u201d\n<em>Review of Philosophy and Psychology</em>, first online 03 August\n2022. doi:10.1007/s13164-022-00653-x",
                "Nelson, D., 1949, \u201cConstructible Falsity\u201d, <em>Journal\nof Philosophical Logic</em>, 14: 16\u201326.",
                "\u2013\u2013\u2013, 1959, \u201cNegation and the Separation of\nConcepts in Constructive Systems\u201d, in <em>Constructivity in\nMathematics</em>, A. Heyting (ed.), Amsterdam: North-Holland,\n208\u2013255.",
                "Pacuit, E., 2011, \u201cLogics of Informational Attitudes and\nInformative Actions\u201d, <em>Journal of the Council of Indian\nPhilosophy</em>, 27(2): 341\u2013378.",
                "Panahy, S., 2023, \u201cSynthetic Proofs\u201d,\n<em>Synthese</em>, 201(38), first online 21 January 2023.\ndoi:10.1007/s11229-022-04026-w",
                "Paoli, F., 2002, <em>Substructural Logics: A Primer</em>,\nDordrecht, Boston: Kluwer.",
                "Pratt, V., 1995, \u201cChu Spaces and Their Interpretation as\nConcurrent Objects\u201d, <em>Computer Science Today</em> (Lecture\nNotes in Computer Science: Volume 1000), Berlin Heidelberg:\nSpringer-Verlag, 392\u2013405.",
                "Primiero, G., 2006, \u201cAn Epistemic Constructive Definition of\nInformation\u201d, <em>Logique et Analyse</em>, 50(200):\n391\u2013416.",
                "\u2013\u2013\u2013, 2008, <em>Information and Knowledge: A\nConstructive Type-Theoretical Approach</em> (Logic, Epistemology, and\nthe Unity of Science Series: Volume 10), Dordrecht: Springer.",
                "Pun\u010doch\u00e1\u0159, V., and Sedl\u00e1r, I., 2021,\nEpistemic Extensions of Substructural Inquisitive Logics, <em>Journal\nof Logic and Computation</em>, 31(7): 1820\u20131844.",
                "Ramos Mendon\u00e7a, Bruno, 2022, \u201cGame Semantics,\nQuantifiers and Logical Omniscience\u201d, <em>Logic and Logical\nPhilosophy</em>, 31(4): 557\u201378. doi:10.12775/LLP.2022.021.",
                "Restall, G., 1994, \u201cInformation Flow and Relevant\nLogics\u201d, in <em>Logic, Language, and Computation</em>, Jerry\nSeligman and Dag Wester\u00e5hl (eds.), Stanford: CSLI Publications,\n1995, 139\u2013160.",
                "\u2013\u2013\u2013, 1994a, \u201cA Useful Substructural\nLogic\u201d, <em>Bulletin of the Interest Group in Pure and Applied\nLogics</em>, 2: 137\u2013148.",
                "\u2013\u2013\u2013, 1997, \u201cWays Things Can\u2019t\nBe\u201d, <em>Notre Dame Journal of Formal Logic</em>, 38:\n583\u2013596.",
                "\u2013\u2013\u2013, 2000, <em>Substructural Logics, and\nIntroduction</em>, London: Routledge.",
                "\u2013\u2013\u2013, 2006, \u201cLogics, Situations, and\nChannels\u201d, <em>Journal of Cognitive Science</em>, 6:\n125\u2013150.",
                "Sadrzadeh, M., 2009, \u201cOckham\u2019s Razor for Reasoning\nabout Information Flow\u201d, <em>Synthese</em>, 167:\n391\u2013408.",
                "Sedlar, I., 2015, \u201cSubstructural Epistemic Logics\u201d,\n<em>Journal of Applied Non-Classical Logics</em>, 25(3):\n256\u2013285.",
                "\u2013\u2013\u2013, 2019, \u201cSubstructural Propositional\nDynamic Logics\u201d, in R. Iemhoff, M. Moortgat, and R. De Queiroz\n(eds.), <em>Logic, Language, Information, and Computation</em> (WoLLIC\n2019), 594\u2013609, Cham: Springer.",
                "\u2013\u2013\u2013, 2021, \u201cHyperintensional logics for\nEveryone\u201d, <em>Synthese</em>, 198: 933\u2013956.",
                "Sedl\u00e1r, I, Pun\u010doch\u00e1\u0159 V., Tedder, A., 2023,\n\u201cRelevant Epistemic Logic with Public Announcements and Common\nKnowledge\u201d, <em>Journal of Logic and Computation</em>, 33(2):\n436\u2013461.",
                "Segerberg, K., 1998, \u201cIrrevocable Belief Revision in Dynamic\nDoxastic Logic\u201d, <em>Notre Dame Journal of Formal Logic</em>,\n39(3): 287\u2013306.",
                "Seligman, J., 1990, \u201cPerspectives in Situation\nTheory\u201d, in <em>Situation Theory and its Applications</em>, Vol\n1, R. Cooper, K. Mukai, and J. Perry, (eds.), Stanford: CSLI\nPublications, 147\u2013191.",
                "\u2013\u2013\u2013, 2009, \u201cChannels: From Logic to\nProbability\u201d, in <em>Formal Theories of Information: From\nShannon to Semantic Information Theory and General Concepts of\nInformation</em>, G. Sommaruga (ed.), LNCS 5363, Berlin: Springer\nVerlag, 193\u2013233.",
                "\u2013\u2013\u2013, 2014, \u201cSituation Theory\nReconsidered\u201d, in A. Baltag and S. Smets (eds.) 2014:\n895\u2013932.",
                "Sequoiah-Grayson, S., 2007, \u201cThe Metaphilosophy of\nInformation\u201d, <em>Minds and Machines</em>, 17:\n331\u201344.",
                "\u2013\u2013\u2013, 2008, \u201cThe Scandal of Deduction:\nHintikka on the Information Yield of Deductive Inferences\u201d,\n<em>Journal of Philosophical Logic</em>, 37: 67\u201394.",
                "\u2013\u2013\u2013, 2009, \u201cDynamic Negation and Negative\nInformation\u201d, <em>Review of Symbolic Logic</em> 2(1):\n233\u2013248.",
                "\u2013\u2013\u2013, 2010, \u201cLambek Calculi with 0 and\nTest-Failure in DPL\u201d, <em>Linguistic Analysis</em>, 36:\n517\u2013532.",
                "\u2013\u2013\u2013, 2011, \u201cNon-Symmetric\n(In)Compatibility Relations and Non-Commuting Types\u201d, <em>The\nLogica Yearbook 2010</em>, Michael Peli\u0161 and Vit\nPun\u010doch\u00e1\u0159 (eds.) London: College Publications.",
                "\u2013\u2013\u2013, 2013, \u201cEpistemic Closure and\nCommuting, Nonassociating Residuated Structures\u201d,\n<em>Synthese</em>, 190(1): 113\u2013128.",
                "\u2013\u2013\u2013, 2016, \u201cEpistemic Relevance and\nEpistemic Actions\u201d, in K. Bimbo (ed.) 2016, 133\u2013146.",
                "Shannon, C. E., 1948, \u201cA Mathematical Theory of\nCommunication\u201d, <em>Bell System Technical Journal</em> 27:\n379\u2013423 and 623\u2013656.",
                "\u2013\u2013\u2013, 1953 [1950], \u201cThe Lattice Theory of\nInformation\u201d, in <em>IEEE Transactions on Information\nTheory</em>, 1 (Proceedings of the Symposium on Information Theory,\nLondon, September 1950): 105\u2013107; reprinted in <em>Claude Elwood\nShannon Collected Papers</em>, N. J. A. Sloan and A. D. Wyner (eds.),\nLos Alamos, CA: IEEE Computer Science Press, 1993.",
                "Stefaneas P. and Vandoulakis, I. M., 2014, \u201cA Proofs as\nSpatio-temporal Processes\u201d, <em>Philosophia Scientiae</em>,\n18(3): 111\u2013125.",
                "Tedder, A., 2017, \u201cChannel Composition and Ternary Relation\nSemantics\u201d, in K. Bimb\u00f3 and J.M. Dunn (eds.), <em>IFCoLog\nJournal of Logics and Their Applications</em> (Special Issue:\nProceedings of the Third Workshop), 4(3): 731\u2013753.",
                "\u2013\u2013\u2013, 2021, \u201cInformation Flow in Logics in\nthe Vicinity of BB\u201d, <em>Australasian Journal of Logic</em>,\n18(1): 1\u201324.",
                "Tedder, A., and Bilkov\u00e1, M., <em>forthcoming</em>,\n\u201cRelevant Propositional Dynamic Logic\u201d,\n<em>Synthese</em>.",
                "Textor, M., 2012, \u201cStates of Affairs\u201d, <em>The\nStanford Encyclopedia of Philosophy</em> (Summer 2012 Edition), Edward\nN. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/sum2012/entries/states-of-affairs/\">https://plato.stanford.edu/archives/sum2012/entries/states-of-affairs/</a>&gt;.",
                "Troelstra, A. S., 1992, <em>Lecture Notes on Linear Logic</em>\n(CSLI Lecture Notes 29), Stanford: CSLI Publications.",
                "Vanderschraaf, P. and G. Sillari, 2009, \u201cCommon\nKnowledge\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Spring 2009 Edition), Edward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/spr2009/entries/common-knowledge/\">http:/plato.stanford.edu/archives/spr2009/entries/common-knowledge/</a>&gt;.",
                "Vel\u00e1zquez-Quesada, F. R., 2009, \u201cDynamic Logics for\nExplicit and Implicit Information\u201d, in Xiangdong He and John F.\nHorty and Eric Pacuit (eds.), <em>Logic, Rationality, and Interaction:\nSecond International Workshop, LORI 2009</em>, Chongqing, China,\nOctober 8\u201311, 2009, Berlin: Springer, 325\u2013326.",
                "Vickers, S., 1996, <em>Topology via Logic</em>, Cambridge:\nCambridge University Press.",
                "Wang, Y., and J. Fan, 2014, \u201cConditionally Knowing\nWhat\u201d, <em>Advances in Modal Logic</em>, 10: 569\u2013587.",
                "Wansing, H., 1993, <em>The Logic of Information Structures</em>,\n(Lecture Notes in Artificial Intelligence no. 681, Subseries of\nLecture Notes in Computer Science), Berlin: Springer-Verlag.",
                "\u2013\u2013\u2013, 2016, \u201cOn Split Negation, Strong\nNegation, Information, Falsification, and Verification\u201d, in K.\nBimbo (ed.) 2016: 161\u2013190.",
                "Yablo, S., 2014, <em>Aboutness</em>, Princeton, NJ: Princeton\nUniversity Press.",
                "Yang, S., Taniguchi, M., Tojo, S., 2019, \u201c4-valued Logic for\nAgent Communication with Private/Public Information Passing\u201d,\n<em>Proceedings of the 11th International Conference on Agents and\nArtificial Intelligence</em> (ICAART 2019) (Volume 1), Set\u00fabal:\nScience and Technology Publications, 54\u201361.\ndoi:10.5220/0007400000540061",
                "Zalta, Edward N., 1983, <em>Abstract Objects: An Introduction to\nAxiomatic Metaphysics</em>, Dordrecht: D. Reidel.",
                "\u2013\u2013\u2013, 1993, \u201cTwenty-Five Basic Theorems in\nSituation and World Theory\u201d, <em>Journal of Philosophical\nLogic</em>, 22(4): 385\u2013428.",
                "Zhou, C., 2016, \u201cLogical Foundations of Evidential reasoning\nwith Contradictory Information\u201d, in K. Bimbo (ed.) 2016:\n213\u2013246."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2><a id=\"Bib\">Bibliography</a></h2>\n<ul class=\"hanging\">\n<li>Abramsky, S., 2008, \u201cInformation, Processes, and\nGames\u201d, in Adriaans and van Benthem 2008, 483\u2013550.</li>\n<li>Abramsky, S. and A. Jung, 1994, \u201cDomain Theory\u201d, in\n<em>Handbook of Logic in Computer Science</em>, S. Abramsky, D.\nGabbat, and T. S. E. Maibaum (eds.), Oxford: Oxford University Press,\n1\u2013168.</li>\n<li>Aczel, P., 1988, <em>Non-well-founded Sets</em>, (CSLI Lecture\nNotes 14), Stanford: CSLI Publications.</li>\n<li>Adriaans, P. and J. F. A. K. van Benthem (eds.), 2008,\n<em>Philosophy of Information</em> (Handbook of the Philosophy of\nScience: Volume 8), Amsterdam: North Holland.</li>\n<li>Allo, P., 2009, \u201cReasoning about Data and\nInformation\u201d, <em>Synthese</em>, 167: 231\u2013249.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cHard and Soft Logical\nInformation\u201d, <em>Logic and Computation</em>, 27(8):\n2505\u20132524.</li>\n<li>Artemov, S., 2008, \u201cThe Logic of Justification\u201d,\n<em>Review of Symbolic Logic</em>, 1(4): 477\u2013513.</li>\n<li>Artemov, S. and M. Fitting, 2012, \u201cJustification\nLogic\u201d, <em>The Stanford Encyclopedia of Philosophy</em> (Fall\n2012 Edition), Edward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2012/entries/logic-justification/\">https://plato.stanford.edu/archives/fall2012/entries/logic-justification/</a>&gt;</li>\n<li>Aucher, G. 2014, \u201cDynamic Epistemic Logic as a Substructural\nLogic\u201d, in A. Baltag and S. Smets (eds.) 2014:\n855\u2013880.</li>\n<li>\u2013\u2013\u2013, 2015, \u201cWhen Conditional Logic and\nBelief Revision meet Substructural Logics\u201d, <em>Proceedings of\nthe International Workshop on Defeasible and Ampliative Reasoning</em>\n(DARe-15),\n <a href=\"http://ceur-ws.org/Vol-1423/DARe-15_1.pdf\" target=\"other\">available online</a>.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cDynamic Epistemic Logic in\nUpdate Logic\u201d, <em>Journal of Logic and Computation</em>, 26(6):\n1913\u20131960.</li>\n<li>Awodey, S., 2006, <em>Category Theory</em> (Oxford Logic Guides:\nVolume 49), Oxford: Clarendon Press.</li>\n<li>Baltag, A., 2016, \u201cTo Know is to Know the Value of a\nVariable\u201d, <em>Advances in Modal Logic</em>, 11:\n135\u2013155.</li>\n<li>Baltag, A., and J. van Benthem, 2021, \u201cA Simple Logic of\nFunctional Dependence\u201d, <em>Journal of Philosophical Logic</em>,\n50: 939\u20131005.</li>\n<li>Baltag, A., B. Coecke, and M. Sadrzadeh, 2007, \u201cEpistemic\nActions as Resources\u201d, <em>Journal of Logic and\nComputation</em>, 17(3): 555\u2013585.</li>\n<li>Baltag A., H. P. van Ditmarsch, and L. S. Moss, 2008,\n\u201cEpistemic Logic and Information Update\u201d, in Adriaans and\nvan Benthem, 2008: 361\u2013456.</li>\n<li>Baltag, A., and S. Smets, 2008, \u201cA Qualitative Theory of\nDynamic Interactive Belief Revision\u201d, in <em>Logic and the\nFoundation of Game and Decision Theory</em> (LOFT7), G. Bonanno, W.\nvan der Hoek, and M. Wooldridge (Eds.), Volume 3 of <em>Texts in Logic\nand Games</em>, 13\u201360. Amsterdam: Amsterdam University\nPress.</li>\n<li>\u2013\u2013\u2013 (eds.), 2014, <em>Johan van Benthem on Logic\nand Information Dynamics</em> (Outstanding Contributions to Logic 5),\nCham: Springer.</li>\n<li>Bar-Hillel, Y. and R. Carnap, 1952, \u201cAn Outline of a Theory\nof Semantic Information\u201d, Technical Report No. 247, Research\nLaboratory of Electronics, Cambridge, MA: MIT. Reprinted in\n<em>Language and Information: Selected Essays on their Theory and\nApplication</em>, Y. Bar-Hillel, <em>Addison-Wesley Series in\nLogic</em>, Israel: Jerusalem Academic Press and Addison-Wesley, 1964,\n221\u201374.</li>\n<li>Barwise, J., 1988, \u201cThree Views of Common Knowledge\u201d,\n<em>TARK \u201988 Proceedings of the 2nd conference on Theoretical\naspects of reasoning about knowledge</em>, San Francisco: Morgan\nKaufmann, p. 365\u2013379.</li>\n<li>\u2013\u2013\u2013, 1993, \u201cConstraints, Channels, and the\nFlow of Information\u201d, in <em>Situation Theory and its\nApplications, 3</em>, (CSLI Lecture Notes 37), Aczel et al. (eds.),\nStanford: CSLI Publications.</li>\n<li>\u2013\u2013\u2013, 1997, \u201cInformation and\nImpossibilities\u201d, <em>Notre Dame Journal of Formal Logic</em>\n38(4): 488\u2013515.</li>\n<li>Barwise, J. and J. Etchemendy, 1987, <em>The Liar</em>, Oxford:\nOxford University Press.</li>\n<li>Barwise, J. and L. Moss, 1996, <em>Vicious Circles</em>, (CSLI\nLecture Notes 60), Stanford: CSLI Publication.</li>\n<li>Barwise, J. and J. Perry, 1983, <em>Situations and Attitudes</em>,\nCambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 1985, \u201cShifting Situations and Shaken\nAttitudes\u201d, <em>Linguistics and Philosophy</em>, 8:\n105\u2013161.</li>\n<li>Barwise J. and J. Seligman, 1997, <em>Information Flow: The Logic\nof Distributed Systems</em>, Cambridge Tracts in Theoretical Computer\nScience 44, New York: Cambridge University Press.</li>\n<li>Beal, J. C. and G. Restall, 2006, <em>Logical Pluralism</em>,\nOxford: Clarendon Press.</li>\n<li>van Benthem, J., 1995, <em>Language in Action: Categories,\nLambdas, and Dynamic Logic</em>, Cambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 2000, \u201cInformation Transfer Across\nChu Spaces\u201d, <em>Logic Journal of the IGPL</em>, 8(6):\n719\u2013731.</li>\n<li>\u2013\u2013\u2013, 2003, \u201cLogic and Dynamics of\nInformation\u201d, <em>Minds and Machines</em>, 13(4):\n503\u2013519.</li>\n<li>\u2013\u2013\u2013, 2004, \u201cDynamic Logic for Belief\nRevision\u201d, <em>Journal of Applied Non-Classical Logics</em>,\n14(2): 129\u2013155.</li>\n<li>\u2013\u2013\u2013, 2006, \u201cInformation as Correlation\nversus Information as Range\u201d, Technical Report PP-2006-07,\nAmsterdam: ILLC (University of Amsterdam).</li>\n<li>\u2013\u2013\u2013, 2009, \u201cThe Information in\nIntuitionistic Logic\u201d, <em>Synthese</em>, 167:\n251\u2013270.</li>\n<li>\u2013\u2013\u2013, 2010, \u201cCategorial versus Modal\nInformation Theory\u201d, <em>Linguistic Analysis</em>, 36: 533</li>\n<li>\u2013\u2013\u2013, 2011, <em>Logical Dynamics of Information\nand Interaction</em>, Cambridge: Cambridge University Press.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cTracking Information\u201d,\nin K. Bimb\u00f3 (ed.) 2016, 363\u2013390.</li>\n<li>\u2013\u2013\u2013, 2019, \u201cImplicit and Explicit Stances\nin Logic\u201d, <em>Journal of Philosphical Logic</em>, 48:\n571\u2013601.</li>\n<li>van Benthem, J., J. van Eijck, and B. Kooi, 2006, \u201cLogics of\nCommunication and Change\u201d, <em>Information and Computation</em>,\n204(11): 1620\u20131662.</li>\n<li>van Benthem, J. and M. Martinez, 2008, \u201cThe Stories of Logic\nand Information\u201d. in <em>Philosophy of Information</em>, in\nAdriaans and van Benthem, 2008, p. 217\u2013280.</li>\n<li>Berto, F. and Hawke, P., 2021, \u201cKnowability Relative to\nInformation\u201d, <em>Mind</em>, 130(517): 1\u201333,\ndoi:10.1093/mind/fzy045</li>\n<li>Berto, F. and Jago M., 2019, <em>Impossible Worlds</em>, Oxford:\nOxford University Press. doi:10.1093/oso/9780198812791.001.0001</li>\n<li>Bertomeu, J. and Marinovic, I., 2016, \u201cA Theory of Hard and\nSoft Information\u201d, <em>The Accounting Review</em>, 91(1):\n1\u201320.</li>\n<li>Beth, E. W., 1955, \u201cSemantic Entailment and Formal\nDerivability\u201d, <em>Koninklijke Nederlandse Akademie van\nWentenschappen, Proceedings of the Section of Sciences</em>, 18:\n309\u2013342).</li>\n<li>\u2013\u2013\u2013, 1956, \u201cSemantic Construction of\nIntuitionistic Logic\u201d, <em>Koninklijke Nederlandse Akademie van\nWentenschappen, Proceedings of the Section of Sciences</em>, 19:\n357\u2013388.</li>\n<li>Bimb\u00f3, K. (ed.), 2016, <em>J. Michael Dunn on Information\nBased Logics</em> (Outstanding Contributions to Logic 8), Cham:\nSpringer.</li>\n<li>Bimb\u00f3, K. (ed.), 2022, <em>Relevance Logics and other Tools\nfor Reasoning. Essays in Honor of J. Michael Dunn</em> (Tributes:\nVolume 46), London: College Publications.</li>\n<li>Blackburn, P., M. de Rijke, and Y. Venema, 2001, <em>Modal\nLogic</em>, Cambridge tracts in theoretical computer science 53,\nCambridge: Cambridge University Press.</li>\n<li>Brady, R. T., 2016, \u201cComparing Contents with\nInformation\u201d, in K. Bimbo (ed.) 2016, 147\u2013159.</li>\n<li>Buszkowski, W., 1995, \u201cCategorical Grammars with Negative\nInformation\u201d, in <em>Negation, A Notion in Focus</em>, H.\nWansing (ed.), Berlin: Gruyter, 107\u2013126.</li>\n<li>Ciardelli, I., Groenendijk, J., Roelofsen, F., 2018,\n<em>Inquisitive Semantics</em>, Oxford: Oxford University Press.</li>\n<li>D\u2019Agostino, M. and L. Floridi, 2009, \u201cThe Enduring\nScandal of Deduction\u201d, <em>Synthese</em> 167:\n317\u2013315.</li>\n<li>Devlin, K., 1991, <em>Logic and Information</em>, Cambridge:\nCambridge University Press.</li>\n<li>van Ditmarsh, H., W. van der Hoek, and B. Kooi, 2008, <em>Dynamic\nEpistemic Logic</em>, Dordrecht: Springer.</li>\n<li>Dretske, F., 1981, <em>Knowledge and the Flow of Information</em>,\nCambridge: Cambridge University Press.</li>\n<li>Dunn, J. M., 1993, \u201cPartial Gaggles Applied to Logics with\nRestricted Structural Rules\u201d, in <em>Substructural Logics</em>,\nP. Schroeder-Heister and K. Dosen (eds.), Oxford: Oxford Science\nPublications, Clarendon Press, 63\u2013108.</li>\n<li>\u2013\u2013\u2013, 2001, The Concept of Informaiton and the\nDevelopment of Modern Logic, in W. Stelzner and M. Stoeckler (eds.)\n<em>Zwischen traditioneller und moderner Logik: Nichtklassiche\nAns\u00e4tze</em>, Paderborn: Mentis Verlag GmbH, 423\u2013447.</li>\n<li>\u2013\u2013\u2013, 2015, The Relevance of Relevance to\nRelevance Logic, <em>Logic and its Applications</em> (Lecture Notes in\nComputer Science: Vol. 8923), Berlin Heidelberg: Springer-Verlag,\n11\u201329.</li>\n<li>Duzi, M., 2010, \u201cThe Paradox of Inference and the\nNon-Triviality of Analytic Information\u201d, <em>Journal of\nPhilosophical Logic</em>, 38(5): 473\u2013510.</li>\n<li>Duzi, M., B. Jespersen, and P. Materna, 2010, <em>Procedural\nSemantics for Hyperintensional Logic: Foundations and Applications of\nTIL</em> (Logic, Epistemology, and the Unity of Science: Volume 17),\nDordrecht, London: Springer.</li>\n<li>Dyckhoff, R. and M. Sadrzadeh, 2010, \u201cA Cut-Free Sequent\nCalculus for Algebraic Dynamic Epistemic Logic\u201d, Computer\nScience Research Report, University of Oxford, CS-RR-10-11.</li>\n<li>van Eijck, J. and A. Visser, 2012, \u201cDynamic\nSemantics\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2012 Edition), Edward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/win2012/entries/dynamic-semantics/\">https://plato.stanford.edu/archives/win2012/entries/dynamic-semantics/</a>&gt;.</li>\n<li>Fagin R., J. Halpern, and M. Vardi, 1995, \u201cReasoning about\nKnowledge\u201d. Cambridge, MA: MIT Press.</li>\n<li>Fine, K., 2017, \u201cTruthmaker Semantics\u201d, in <em>A\nCompanion to the Philosophy of Language</em> (Volume 2), Bob Hale,\nCrispin Wright, and Alexander Miller (eds.), 2nd edition, Chichester:\nWiley Blackwell, 556\u2013577. doi:10.1002/9781118972090.ch22</li>\n<li>Fine, K. and Jago, M., 2019, \u201cLogic for Exact\nEntailment\u201d, <em>Review of Symbolic Logic</em>, 12(3):\n536\u2013555. doi:10.1017/S1755020318000151</li>\n<li>Floridi, L., 2004, \u201cOutline of a Theory of Strongly Semantic\nInformation\u201d, <em>Minds and Machines</em>, 14(2):\n197\u201322.</li>\n<li>\u2013\u2013\u2013, 2006, \u201cThe Logic of Being\nInformed\u201d, <em>Logique et Analyse</em>, 49(196):\n433\u2013460.</li>\n<li>\u2013\u2013\u2013, 2013, \u201cSemantic Conceptions of\nInformation\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Spring 2013 Edition), Edward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/spr2013/entries/information-semantic/\">https://plato.stanford.edu/archives/spr2013/entries/information-semantic/</a>&gt;.</li>\n<li>Gabbay, D. M., 1993, \u201cLabelled Deductive Systems: A Position\nPaper\u201d, in <em>Logic Colloquium \u201990: ASL Summer Meeting in\nHelsinki</em>, J. Oikkonen and J. Vaananen (eds.), Berlin:\nSpringer-Verlag, 66\u201388.</li>\n<li>\u2013\u2013\u2013, 1996, <em>Labelled Deductive Systems:\nVolume 1</em> (Oxford Logic Guides 35), New York: Oxford University\nPress.</li>\n<li>Ganter, B. and R. Wille, 1999, <em>Formal Concept Analysis,\nFoundations and Applications</em> (LNCS 3626), Berlin, Heidelberg:\nSpringer.</li>\n<li>Ghidini, C. and F. Giunchiglia, 2001, \u201cLocal Model\nSemantics, or Contextual Reasoning = Locality + Compatibility\u201d.\n<em>Artificial Intelligence</em>, 127: 221\u2013259.</li>\n<li>Groenendijk, J. and M. Stokoff, 1991, \u201cDynamic Predicate\nLogic\u201d, <em>Linguistics and Philosophy</em>, 14:\n33\u2013100.</li>\n<li>Gurevich, Y., 1977, \u201cIntuitionistic Logic with Strong\nNegation\u201d, <em>Studia Logica</em>, 36: 49\u201359.</li>\n<li>Grzegorczyk, A., 1964, \u201cA Philosophically Plausible\nInterpretation of Intuitionistic Logic\u201d, <em>Indagnationes\nMathematicae</em>, 26: 596\u2013601.</li>\n<li>Harrison-Trainor, M., Holliday, W. H., Icard, T. F., forthcoming,\n\u201cInferring Probability Comparisons\u201d, <em>Mathematical\nSocial Sciences</em>.</li>\n<li>Hintikka, J., 1970, \u201cSurface Information and Depth\nInformation\u201d, in <em>Information and Inference</em>, J. Hintikka\nand P. Suppes (eds.), Dordrecht: Reidel, 263\u201397.</li>\n<li>\u2013\u2013\u2013, 1973, <em>Logic, Language Games, and\nInformation</em>, Oxford: Clarendon Press.</li>\n<li>\u2013\u2013\u2013, 2007, <em>Socratic Epistemology:\nExplorations of Knowledge\u2014Seeking by Questions</em>, Cambridge:\nCambridge University Press.</li>\n<li>Hjortland, O., Roy, O., 2016, \u201cDynamic consequence for soft\ninformation\u201d, <em>Journal of Logic and Computation</em>, 26(6):\n1843\u20131864.</li>\n<li>Israel, D. and J. Perry, 1990, \u201cWhat is Information?\u201d,\nin <em>Information, Language and Cognition</em>, P. Hanson, (ed.),\nVancouver: University of British Columbia.</li>\n<li>\u2013\u2013\u2013, 1991, \u201cInformation and\nArchitecture\u201d, in <em>Situation Theory and its Applications</em>\nVol 2, J. Barwise, J.M. Gawron, G. Plotkin, and S. Tutiya, (eds.),\nStanford: CSLI Publications.</li>\n<li>Jago, M., 2006, \u201cRule-based and Resource-Bounded: A New Look\nat Epistemic Logic\u201d, in <em>Proceedings on the Workshop on\nLogics for Resource\u2014Bounded Agents, as part of ESSLLI 2006</em>,\nT. Agotnes and N. Alechina (eds.), 63\u201377, 2006.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cLogical Information and\nEpistemic Space\u201d, <em>Synthese</em>, 167: 327\u2013341.</li>\n<li>\u2013\u2013\u2013, 2015, \u201cImpossible Worlds\u201d,\n<em>No\u00fbs</em>, 49(4): 713\u2013728. doi:10.1111/nous.12051</li>\n<li>\u2013\u2013\u2013, 2020, \u201cTruthmaker Semantics for\nRelevant Logic\u201d, <em>Journal of Philosophical Logic</em>, 49:\n681\u2013702. doi:10.1007/s10992-019-09533-9</li>\n<li>King, J. C., 2012, \u201cStructured Propositions\u201d, <em>The\nStanford Encyclopedia of Philosophy</em> (Winter 2012 Edition), Edward\nN. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/win2012/entries/propositions-structured/\">https://plato.stanford.edu/archives/win2012/entries/propositions-structured/</a>&gt;.</li>\n<li>Kratzer, A., 2011, \u201cSituations in Natural Language\nSemantics\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Fall 2011 Edition), Edward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2011/entries/situations-semantics/\">https://plato.stanford.edu/archives/fall2011/entries/situations-semantics/</a>&gt;.</li>\n<li>Kripke, S. A., 1963, \u201cSemantical Analysis of Modal\nLogic\u201d, <em>Zeitschrift fur Mathematichs Logik und Grundlagen\nder Mathematik</em>, 9: 67\u201396.</li>\n<li>\u2013\u2013\u2013, 1965, \u201cSemantical Analysis of\nIntuitionistic Logic I\u2018\u201d, in <em>Formal Systems and\nRecursive Functions</em>, J. Crossley and M. Dummett (eds.),\nAmsterdam: North Holland, 92\u2013129.</li>\n<li>Lambek, J., 1958, \u201cThe Mathematics of Sentence\nStructure\u201d, <em>American Mathematical Monthly</em>, 65:\n154\u2013170.</li>\n<li>\u2013\u2013\u2013, 1961, On the Calculus of Syntactic Types,\nin <em>Structure of Language and its Mathematical Aspects</em>, R.\nJakobson (ed.), Providence: American Mathematical Society,\n166\u2013178.</li>\n<li>Leitgeb, H., 2019, \u201cHYPE: A System of Hyperintensional\nLogic\u201d, <em>Journal of Philosophical Logic</em> 48(2):\n305\u2013405. doi:10.1007/s10992-018-9467-0</li>\n<li>Lewis, D., 1969, <em>Convention: A Philosophical Study</em>,\nCambridge: Harvard University Press.</li>\n<li>Liu, F., 2009, \u201cDiversity of Agents and Their\nInteraction\u201d, <em>Journal of Logic, Language, and\nInformation</em>, 18(1): 23\u201353.</li>\n<li>Mares, E., 1996, \u201cRelevant Logic and the Theory of\nInformation\u201d, <em>Synthese</em> 109: 345\u2013370.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cManipulating Sources of\nInformation: Towards and Interpretation of Linear Logic and Strong\nRelevance Logic\u201d, in K. Bimbo (ed.) 2016: 107\u2013132.</li>\n<li>\u2013\u2013\u2013, 2004, <em>Relevant Logic: A Philosophical\nInterpretation</em>, Cambridge: Cambridge University Press.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cGeneral Information in\nRelevant Logic\u201d, <em>Synthese</em>, 167: 343\u2013362.</li>\n<li>McGrath, M., 2012, \u201cPropositions\u201d, <em>The Stanford\nEncyclopedia of Philosophy</em> (Summer 2012 Edition), Edward N. Zalta\n(ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/sum2012/entries/propositions/\">https://plato.stanford.edu/archives/sum2012/entries/propositions/</a>&gt;.</li>\n<li>Moss, L. S., 2009, \u201cNon-wellfounded Set Theory\u201d,\n<em>The Stanford Encyclopedia of Philosophy</em> (Fall 2009 Edition),\nEdward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2009/entries/nonwellfounded-set-theory/\">https://plato.stanford.edu/archives/fall2009/entries/nonwellfounded-set-theory/</a>&gt;.</li>\n<li>Moss, L. and J. Seligman, 1996, \u201cSituation Theory\u201d, in\n<em>Handbook of Logic and Language</em>, J. van Benthem and A. ter\nMeulen, (eds.), Amsterdam: Elsiever.</li>\n<li>Negro, Niccol\u00f2, 2022, \u201cCan the Integrated Information\nTheory Explain Consciousness from Consciousness Itself?\u201d\n<em>Review of Philosophy and Psychology</em>, first online 03 August\n2022. doi:10.1007/s13164-022-00653-x</li>\n<li>Nelson, D., 1949, \u201cConstructible Falsity\u201d, <em>Journal\nof Philosophical Logic</em>, 14: 16\u201326.</li>\n<li>\u2013\u2013\u2013, 1959, \u201cNegation and the Separation of\nConcepts in Constructive Systems\u201d, in <em>Constructivity in\nMathematics</em>, A. Heyting (ed.), Amsterdam: North-Holland,\n208\u2013255.</li>\n<li>Pacuit, E., 2011, \u201cLogics of Informational Attitudes and\nInformative Actions\u201d, <em>Journal of the Council of Indian\nPhilosophy</em>, 27(2): 341\u2013378.</li>\n<li>Panahy, S., 2023, \u201cSynthetic Proofs\u201d,\n<em>Synthese</em>, 201(38), first online 21 January 2023.\ndoi:10.1007/s11229-022-04026-w</li>\n<li>Paoli, F., 2002, <em>Substructural Logics: A Primer</em>,\nDordrecht, Boston: Kluwer.</li>\n<li>Pratt, V., 1995, \u201cChu Spaces and Their Interpretation as\nConcurrent Objects\u201d, <em>Computer Science Today</em> (Lecture\nNotes in Computer Science: Volume 1000), Berlin Heidelberg:\nSpringer-Verlag, 392\u2013405.</li>\n<li>Primiero, G., 2006, \u201cAn Epistemic Constructive Definition of\nInformation\u201d, <em>Logique et Analyse</em>, 50(200):\n391\u2013416.</li>\n<li>\u2013\u2013\u2013, 2008, <em>Information and Knowledge: A\nConstructive Type-Theoretical Approach</em> (Logic, Epistemology, and\nthe Unity of Science Series: Volume 10), Dordrecht: Springer.</li>\n<li>Pun\u010doch\u00e1\u0159, V., and Sedl\u00e1r, I., 2021,\nEpistemic Extensions of Substructural Inquisitive Logics, <em>Journal\nof Logic and Computation</em>, 31(7): 1820\u20131844.</li>\n<li>Ramos Mendon\u00e7a, Bruno, 2022, \u201cGame Semantics,\nQuantifiers and Logical Omniscience\u201d, <em>Logic and Logical\nPhilosophy</em>, 31(4): 557\u201378. doi:10.12775/LLP.2022.021.</li>\n<li>Restall, G., 1994, \u201cInformation Flow and Relevant\nLogics\u201d, in <em>Logic, Language, and Computation</em>, Jerry\nSeligman and Dag Wester\u00e5hl (eds.), Stanford: CSLI Publications,\n1995, 139\u2013160.</li>\n<li>\u2013\u2013\u2013, 1994a, \u201cA Useful Substructural\nLogic\u201d, <em>Bulletin of the Interest Group in Pure and Applied\nLogics</em>, 2: 137\u2013148.</li>\n<li>\u2013\u2013\u2013, 1997, \u201cWays Things Can\u2019t\nBe\u201d, <em>Notre Dame Journal of Formal Logic</em>, 38:\n583\u2013596.</li>\n<li>\u2013\u2013\u2013, 2000, <em>Substructural Logics, and\nIntroduction</em>, London: Routledge.</li>\n<li>\u2013\u2013\u2013, 2006, \u201cLogics, Situations, and\nChannels\u201d, <em>Journal of Cognitive Science</em>, 6:\n125\u2013150.</li>\n<li>Sadrzadeh, M., 2009, \u201cOckham\u2019s Razor for Reasoning\nabout Information Flow\u201d, <em>Synthese</em>, 167:\n391\u2013408.</li>\n<li>Sedlar, I., 2015, \u201cSubstructural Epistemic Logics\u201d,\n<em>Journal of Applied Non-Classical Logics</em>, 25(3):\n256\u2013285.</li>\n<li>\u2013\u2013\u2013, 2019, \u201cSubstructural Propositional\nDynamic Logics\u201d, in R. Iemhoff, M. Moortgat, and R. De Queiroz\n(eds.), <em>Logic, Language, Information, and Computation</em> (WoLLIC\n2019), 594\u2013609, Cham: Springer.</li>\n<li>\u2013\u2013\u2013, 2021, \u201cHyperintensional logics for\nEveryone\u201d, <em>Synthese</em>, 198: 933\u2013956.</li>\n<li>Sedl\u00e1r, I, Pun\u010doch\u00e1\u0159 V., Tedder, A., 2023,\n\u201cRelevant Epistemic Logic with Public Announcements and Common\nKnowledge\u201d, <em>Journal of Logic and Computation</em>, 33(2):\n436\u2013461.</li>\n<li>Segerberg, K., 1998, \u201cIrrevocable Belief Revision in Dynamic\nDoxastic Logic\u201d, <em>Notre Dame Journal of Formal Logic</em>,\n39(3): 287\u2013306.</li>\n<li>Seligman, J., 1990, \u201cPerspectives in Situation\nTheory\u201d, in <em>Situation Theory and its Applications</em>, Vol\n1, R. Cooper, K. Mukai, and J. Perry, (eds.), Stanford: CSLI\nPublications, 147\u2013191.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cChannels: From Logic to\nProbability\u201d, in <em>Formal Theories of Information: From\nShannon to Semantic Information Theory and General Concepts of\nInformation</em>, G. Sommaruga (ed.), LNCS 5363, Berlin: Springer\nVerlag, 193\u2013233.</li>\n<li>\u2013\u2013\u2013, 2014, \u201cSituation Theory\nReconsidered\u201d, in A. Baltag and S. Smets (eds.) 2014:\n895\u2013932.</li>\n<li>Sequoiah-Grayson, S., 2007, \u201cThe Metaphilosophy of\nInformation\u201d, <em>Minds and Machines</em>, 17:\n331\u201344.</li>\n<li>\u2013\u2013\u2013, 2008, \u201cThe Scandal of Deduction:\nHintikka on the Information Yield of Deductive Inferences\u201d,\n<em>Journal of Philosophical Logic</em>, 37: 67\u201394.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cDynamic Negation and Negative\nInformation\u201d, <em>Review of Symbolic Logic</em> 2(1):\n233\u2013248.</li>\n<li>\u2013\u2013\u2013, 2010, \u201cLambek Calculi with 0 and\nTest-Failure in DPL\u201d, <em>Linguistic Analysis</em>, 36:\n517\u2013532.</li>\n<li>\u2013\u2013\u2013, 2011, \u201cNon-Symmetric\n(In)Compatibility Relations and Non-Commuting Types\u201d, <em>The\nLogica Yearbook 2010</em>, Michael Peli\u0161 and Vit\nPun\u010doch\u00e1\u0159 (eds.) London: College Publications.</li>\n<li>\u2013\u2013\u2013, 2013, \u201cEpistemic Closure and\nCommuting, Nonassociating Residuated Structures\u201d,\n<em>Synthese</em>, 190(1): 113\u2013128.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cEpistemic Relevance and\nEpistemic Actions\u201d, in K. Bimbo (ed.) 2016, 133\u2013146.</li>\n<li>Shannon, C. E., 1948, \u201cA Mathematical Theory of\nCommunication\u201d, <em>Bell System Technical Journal</em> 27:\n379\u2013423 and 623\u2013656.</li>\n<li>\u2013\u2013\u2013, 1953 [1950], \u201cThe Lattice Theory of\nInformation\u201d, in <em>IEEE Transactions on Information\nTheory</em>, 1 (Proceedings of the Symposium on Information Theory,\nLondon, September 1950): 105\u2013107; reprinted in <em>Claude Elwood\nShannon Collected Papers</em>, N. J. A. Sloan and A. D. Wyner (eds.),\nLos Alamos, CA: IEEE Computer Science Press, 1993.</li>\n<li>Stefaneas P. and Vandoulakis, I. M., 2014, \u201cA Proofs as\nSpatio-temporal Processes\u201d, <em>Philosophia Scientiae</em>,\n18(3): 111\u2013125.</li>\n<li>Tedder, A., 2017, \u201cChannel Composition and Ternary Relation\nSemantics\u201d, in K. Bimb\u00f3 and J.M. Dunn (eds.), <em>IFCoLog\nJournal of Logics and Their Applications</em> (Special Issue:\nProceedings of the Third Workshop), 4(3): 731\u2013753.</li>\n<li>\u2013\u2013\u2013, 2021, \u201cInformation Flow in Logics in\nthe Vicinity of BB\u201d, <em>Australasian Journal of Logic</em>,\n18(1): 1\u201324.</li>\n<li>Tedder, A., and Bilkov\u00e1, M., <em>forthcoming</em>,\n\u201cRelevant Propositional Dynamic Logic\u201d,\n<em>Synthese</em>.</li>\n<li>Textor, M., 2012, \u201cStates of Affairs\u201d, <em>The\nStanford Encyclopedia of Philosophy</em> (Summer 2012 Edition), Edward\nN. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/sum2012/entries/states-of-affairs/\">https://plato.stanford.edu/archives/sum2012/entries/states-of-affairs/</a>&gt;.</li>\n<li>Troelstra, A. S., 1992, <em>Lecture Notes on Linear Logic</em>\n(CSLI Lecture Notes 29), Stanford: CSLI Publications.</li>\n<li>Vanderschraaf, P. and G. Sillari, 2009, \u201cCommon\nKnowledge\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Spring 2009 Edition), Edward N. Zalta (ed.),\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/spr2009/entries/common-knowledge/\">http:/plato.stanford.edu/archives/spr2009/entries/common-knowledge/</a>&gt;.</li>\n<li>Vel\u00e1zquez-Quesada, F. R., 2009, \u201cDynamic Logics for\nExplicit and Implicit Information\u201d, in Xiangdong He and John F.\nHorty and Eric Pacuit (eds.), <em>Logic, Rationality, and Interaction:\nSecond International Workshop, LORI 2009</em>, Chongqing, China,\nOctober 8\u201311, 2009, Berlin: Springer, 325\u2013326.</li>\n<li>Vickers, S., 1996, <em>Topology via Logic</em>, Cambridge:\nCambridge University Press.</li>\n<li>Wang, Y., and J. Fan, 2014, \u201cConditionally Knowing\nWhat\u201d, <em>Advances in Modal Logic</em>, 10: 569\u2013587.</li>\n<li>Wansing, H., 1993, <em>The Logic of Information Structures</em>,\n(Lecture Notes in Artificial Intelligence no. 681, Subseries of\nLecture Notes in Computer Science), Berlin: Springer-Verlag.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cOn Split Negation, Strong\nNegation, Information, Falsification, and Verification\u201d, in K.\nBimbo (ed.) 2016: 161\u2013190.</li>\n<li>Yablo, S., 2014, <em>Aboutness</em>, Princeton, NJ: Princeton\nUniversity Press.</li>\n<li>Yang, S., Taniguchi, M., Tojo, S., 2019, \u201c4-valued Logic for\nAgent Communication with Private/Public Information Passing\u201d,\n<em>Proceedings of the 11th International Conference on Agents and\nArtificial Intelligence</em> (ICAART 2019) (Volume 1), Set\u00fabal:\nScience and Technology Publications, 54\u201361.\ndoi:10.5220/0007400000540061</li>\n<li>Zalta, Edward N., 1983, <em>Abstract Objects: An Introduction to\nAxiomatic Metaphysics</em>, Dordrecht: D. Reidel.</li>\n<li>\u2013\u2013\u2013, 1993, \u201cTwenty-Five Basic Theorems in\nSituation and World Theory\u201d, <em>Journal of Philosophical\nLogic</em>, 22(4): 385\u2013428.</li>\n<li>Zhou, C., 2016, \u201cLogical Foundations of Evidential reasoning\nwith Contradictory Information\u201d, in K. Bimbo (ed.) 2016:\n213\u2013246.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "common knowledge",
            "information",
            "information: semantic conceptions of",
            "logic: dynamic epistemic",
            "propositions: structured",
            "set theory: non-wellfounded",
            "situations: in natural language semantics",
            "states of affairs"
        ],
        "entry_link": [
            {
                "../common-knowledge/": "common knowledge"
            },
            {
                "../information/": "information"
            },
            {
                "../information-semantic/": "information: semantic conceptions of"
            },
            {
                "../dynamic-epistemic/": "logic: dynamic epistemic"
            },
            {
                "../propositions-structured/": "propositions: structured"
            },
            {
                "../nonwellfounded-set-theory/": "set theory: non-wellfounded"
            },
            {
                "../situations-semantics/": "situations: in natural language semantics"
            },
            {
                "../states-of-affairs/": "states of affairs"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=logic-information\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/logic-information/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=logic-information&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/logic-information/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=logic-information": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/logic-information/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=logic-information&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/logic-information/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "Goguen, J., 2004,\n \u201c<a href=\"http://cseweb.ucsd.edu/users/goguen/pps/ifi04.pdf\" target=\"other\">Information Integration in Institutions</a>,\u201d\n online manuscript.",
            "Hernandez, N. A. N., and Quiroz, F. H., 2022,\n \u201c<a href=\"https://arxiv.org/pdf/2212.14463.pdf\" target=\"other\">Justification Logic and the Epistemic Contribution of Deduction</a>\u201d,\n online manuscript, 29 December 2022",
            "Jacobs, B., 2012\n <a href=\"http://www.cs.ru.nl/B.Jacobs/PAPERS/\" target=\"other\"><em>Introduction to Coalgebra. Towards Mathematics of States and Observations</em></a>,\n online manuscript, Version 2.0.",
            "Ma, S., Wu, Y., Qi, H., Li, H., Shi, G., Liang, Y., Al-Dhahir, N.\n2023\n <a href=\"https://arxiv.org/abs/2303.05181\" target=\"other\"> \u201cA Theory of Semantic Communications\u201d</a>,\n online manuscript."
        ],
        "listed_links": [
            {
                "http://cseweb.ucsd.edu/users/goguen/pps/ifi04.pdf": "Information Integration in Institutions"
            },
            {
                "https://arxiv.org/pdf/2212.14463.pdf": "Justification Logic and the Epistemic Contribution of Deduction"
            },
            {
                "http://www.cs.ru.nl/B.Jacobs/PAPERS/": "Introduction to Coalgebra. Towards Mathematics of States and Observations"
            },
            {
                "https://arxiv.org/abs/2303.05181": " \u201cA Theory of Semantic Communications\u201d"
            }
        ]
    }
}