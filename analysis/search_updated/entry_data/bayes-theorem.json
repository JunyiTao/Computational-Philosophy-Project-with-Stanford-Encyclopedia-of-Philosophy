{
    "url": "bayes-theorem",
    "title": "Bayes\u2019 Theorem",
    "authorship": {
        "year": "Copyright \u00a9 2003",
        "author_text": "James Joyce\n<jjoyce@umich.edu>",
        "author_links": [
            {
                "http://www-personal.umich.edu/~jjoyce/": "James Joyce"
            },
            {
                "mailto:jjoyce%40umich%2eedu": "jjoyce@umich.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2003</a> by\n\n<br/>\n<a href=\"http://www-personal.umich.edu/~jjoyce/\" target=\"other\">James Joyce</a>\n&lt;<a href=\"mailto:jjoyce%40umich%2eedu\"><em>jjoyce<abbr title=\" at \">@</abbr>umich<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Sat Jun 28, 2003",
        "substantive revision Tue Sep 30, 2003"
    ],
    "preamble": "\n\n\nBayes' Theorem is a simple mathematical formula used for calculating\nconditional probabilities.  It figures prominently in\nsubjectivist or Bayesian approaches to epistemology,\nstatistics, and inductive logic. Subjectivists, who maintain that\nrational belief is governed by the laws of probability, lean heavily\non conditional probabilities in their theories of evidence and their\nmodels of empirical learning.  Bayes' Theorem is central to these\nenterprises both because it simplifies the calculation of conditional\nprobabilities and because it clarifies significant features of\nsubjectivist position.  Indeed, the Theorem's central insight \u2014\nthat a hypothesis is confirmed by any body of data that its truth\nrenders probable \u2014 is the cornerstone of all subjectivist\nmethodology.  \n",
    "toc": [
        {
            "#1": "1. Conditional Probabilities and Bayes' Theorem"
        },
        {
            "#2": "2. Special Forms of Bayes' Theorem"
        },
        {
            "#3": "3. The Role of Bayes' Theorem in Subjectivist Accounts of Evidence"
        },
        {
            "#4": "4. The Role of Bayes' Theorem in Subjectivist Models of Learning"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. Conditional Probabilities and Bayes' Theorem\n\n The probability of a hypothesis H conditional on a given\nbody of data E is the ratio of the unconditional probability\nof the conjunction of the hypothesis with the data to the\nunconditional probability of the data alone.\n\n\n\n(1.1)\u00a0\nDefinition.\n\n\n\nThe probability of H conditional on E is\ndefined as PE(H) =\nP(H & E)/P(E),\nprovided that both terms of this ratio exist and P(E)\n >  \n 0.[1]\n\n\n\n\n To illustrate, suppose J. Doe is a randomly chosen American who was alive\non January 1, 2000.  According to the United States Center for Disease\nControl, roughly 2.4 million of the 275 million Americans alive on that\ndate died during the 2000 calendar year.  Among the approximately 16.6\nmillion senior citizens (age 75 or greater) about 1.36 million died.  The\nunconditional probability of the hypothesis that our J. Doe died during\n2000, H, is just the population-wide mortality rate\nP(H) = 2.4M/275M = 0.00873.  To find the probability\nof J.  Doe's death conditional on the information, E, that he\nor she was a senior citizen, we divide the probability that he or she was\na senior who died, P(H & E) \n= 1.36M/275M = 0.00495, by the probability that he or she was a senior citizen, \nP(E) = 16.6M/275M = 0.06036.  Thus, the probability of J. Doe's \ndeath given that he or she was a senior is\nPE(H) = P(H &\nE)/P(E) = 0.00495/0.06036 = 0.082.  Notice how the\nsize of the total population factors out of this equation, so that\nPE(H) is just the proportion of seniors\nwho died.  One should contrast this quantity, which gives the mortality\nrate among senior citizens, with the \"inverse\" probability of E\nconditional on H, PH(E) =\nP(H & E)/P(H) =\n0.00495/0.00873 = 0.57, which is the proportion of deaths in the\ntotal population that occurred among seniors.\n\n Here are some straightforward consequences of (1.1):\n\nProbability. PE is a\nprobability\n function.[2]\nLogical Consequence. If E entails H,\nthen PE(H) = 1.\nPreservation of Certainties. If P(H) = 1,\nthen PE(H) = 1.\nMixing. P(H) =\nP(E)PE(H) +\n P(~E)P~E(H).[3]\n\n\n\nThe most important fact about conditional probabilities is undoubtedly\nBayes' Theorem, whose significance was first appreciated by\nthe British cleric Thomas Bayes in his posthumously published\nmasterwork, \"An Essay Toward Solving a Problem in the Doctrine of\nChances\" (Bayes 1764).  Bayes' Theorem relates the \"direct\"\nprobability of a hypothesis conditional on a given body of data,\nPE(H), to the \"inverse\"\nprobability of the data conditional on the hypothesis,\nPH(E).\n\n\n\n(1.2)\nBayes' Theorem.\n\n\n\nPE(H) =\n [P(H)/P(E)]\n PH(E)\n\n\n\n\n In an unfortunate, but now unavoidable, choice of terminology,\nstatisticians refer to the inverse probability\nPH(E) as the \"likelihood\" of\nH on E.  It expresses the degree to which the\nhypothesis predicts the data given the background information\ncodified in the probability P.\n\n In the example discussed above, the condition that J. Doe died during 2000\nis a fairly strong predictor of senior citizenship.  Indeed, the equation\nPH(E) = 0.57 tells us that 57% of the\ntotal deaths occurred among seniors that year.  Bayes' theorem lets\nus use this information to compute the \"direct\" probability of J. Doe\ndying given that he or she was a senior citizen.  We do this by\nmultiplying the \"prediction term\"\nPH(E) by the ratio of the total number\nof deaths in the population to the number of senior citizens in the\npopulation, P(H)/P(E) = 2.4M/16.6M =\n0.144.  The result is PE(H) = 0.57 \u00d7\n0.144 = 0.082, just as expected.\n\n Though a mathematical triviality, Bayes' Theorem is of great value\nin calculating conditional probabilities because inverse probabilities\nare typically both easier to ascertain and less subjective than direct\nprobabilities. People with different views about the unconditional\nprobabilities of E and H often disagree about\nE's value as an indicator of H.  Even so, they can\nagree about the degree to which the hypothesis predicts the data if\nthey know any of the following intersubjectively available facts: (a)\nE's objective probability given H, (b) the\nfrequency with which events like E will occur if H\nis true, or (c) the fact that H logically entails\nE. Scientists often design experiments so that likelihoods\ncan be known in one of these \"objective\" ways.  Bayes' Theorem then\nensures that any dispute about the significance of the experimental\nresults can be traced to \"subjective\" disagreements about the\nunconditional probabilities of H and E.\n\n When both PH(E) and\nP~H(E) are known an experimenter\nneed not even know E's probability to determine a value for\nPE(H) using Bayes' Theorem.\n\n\n\n(1.3)\nBayes' Theorem (2nd\n form).[4]\n\n\n\nPE(H) = \nP(H)PH(E)\n / [P(H)PH(E)\n+ P(~H)P~H(E)]\n\n\n\n\n In this guise Bayes' theorem is particularly useful for inferring\ncauses from their effects since it is often fairly easy to discern the\nprobability of an effect given the presence or absence of a putative\ncause. For instance, physicians often screen for diseases of known\nprevalence using diagnostic tests of recognized sensitivity\nand specificity.  The sensitivity of a test, its \"true\npositive\" rate, is the fraction of times that patients with the\ndisease test positive for it. The test's specificity, its \"true\nnegative\" rate, is the proportion of healthy patients who test\nnegative. If we let H be the event of a given patient having\nthe disease, and E be the event of her testing positive for\nit, then the test's sensitivity and specificity are given by the\nlikelihoods PH(E) and\nP~H(~E), respectively,\nand the \"baseline\" prevalence of the disease in the population is\nP(H).  Given these inputs about the effects of the\ndisease on the outcome of the test, one can use (1.3) to determine the\nprobability of disease given a positive test.  For a more\ndetailed illustration of this process, see \n Example 1 in the \nSupplementary Document \"Examples, Tables, and Proof Sketches\".\n2. Special Forms of Bayes' Theorem\n\n\nBayes' Theorem can be expressed in a variety of forms that are useful\nfor different purposes. One version employs what Rudolf Carnap called\nthe relevance quotient or probability ratio (Carnap\n1962, 466).  This is the factor PR(H,\nE) =\nPE(H)/P(H)\nby which H's unconditional probability must be multiplied to\nget its probability conditional on E. Bayes' Theorem is\nequivalent to a simple symmetry principle for probability ratios.\n\n\n\n(1.4)\nProbability Ratio Rule.\n\n\n\nPR(H, E) = \nPR(E, H)\n\n\n\n\n The term on the right provides one measure of the degree to which\nH predicts E.  If we think of P(E) as\nexpressing the \"baseline\" predictability of E given the\nbackground information codified in P, and of\nPH(E) as E's\npredictability when H is added to this background, then\nPR(E, H) captures the degree to\nwhich knowing H makes E more or less predictable\nrelative to the baseline: PR(E, H) =\n0 means that H categorically predicts ~E;\nPR(E, H) = 1 means that adding\nH does not alter the baseline prediction at all;\nPR(E, H) =\n1/P(E) means that H categorically\npredicts E.  Since P(E)) =\nPT(E)) where\nT is any truth of logic, we can think of (1.4) as\ntelling us that\n\nThe probability of a hypothesis conditional on a body of data is\nequal to the unconditional probability of the hypothesis multiplied by\nthe degree to which the hypothesis surpasses a tautology as a\npredictor of the data.\n\n\n In our J. Doe example, PR(H, E) is\nobtained by comparing the predictability of senior status given that\nJ. Doe died in 2000 to its predictability given no information\nwhatever about his or her mortality.  Dividing the former \"prediction\nterm\" by the latter yields PR(H, E) =\nPH(E)/P(E) =\n0.57/0.06036 = 9.44.  Thus, as a predictor of senior status in 2000,\nknowing that J. Doe died is more than nine times better than not\nknowing whether she lived or died.\n\n Another useful form of Bayes' Theorem is the Odds Rule.  In\nthe jargon of bookies, the \"odds\" of a hypothesis is its probability\ndivided by the probability of its negation: O(H) =\nP(H)/P(~H). So, for example, a\nracehorse whose odds of winning a particular race are 7-to-5 has a\n7/12 chance of winning and a 5/12 chance of losing. To\nunderstand the difference between odds and probabilities it helps to\nthink of probabilities as fractions of the distance between\nthe probability of a contradiction and that of a tautology, so that\nP(H) = p means that H is p\ntimes as likely to be true as a tautology. In contrast, writing\nO(H) = [P(H) \u2212\nP(F)]/[P(T)\n\u2212 P(H)]  (where F is some\nlogical contradiction) makes it clear that O(H)\nexpresses this same quantity as the ratio of the amount by which\nH's probability exceeds that of a contradiction to the\namount by which it is exceeded by that of a tautology. Thus, the\ndifference between \"probability talk\" and \"odds talk\" corresponds to\nthe difference between saying \"we are two thirds of the way there\" and\nsaying \"we have gone twice as far as we have yet to go.\"\n\n The analogue of the probability ratio is the odds ratio\nOR(H, E) =\nOE(H)/O(H),\nthe factor by which H's unconditional odds must be multiplied\nto obtain its odds conditional on E. Bayes' Theorem is\nequivalent to the following fact about odds ratios:\n\n\n\n(1.5)\nOdds Ratio Rule.\n\n\n \nOR(H, E) =\nPH(E)/P~H(E)\n\n\n\n\n Notice the similarity between (1.4) and (1.5). While each employs a\ndifferent way of expressing probabilities, each shows how\nits expression for H's probability conditional on\nE can be obtained by multiplying its expression for\nH's unconditional probability by a factor involving inverse\nprobabilities.\n\n The quantity LR(H, E) =\nPH(E)/P~H(E)\nthat appears in (1.5) is the likelihood ratio of H\ngiven E. In testing situations like the one described in\nExample 1, the likelihood ratio is the test's true positive rate\ndivided by its false positive rate: LR =\nsensitivity/(1 \u2212 specificity). As with the probability\nratio, we can construe the likelihood ratio as a measure of the degree\nto which H predicts E. Instead of comparing\nE's probability given H with its unconditional\nprobability, however, we now compare it with its probability\nconditional on ~H.  LR(H,\nE) is thus the degree to which the hypothesis surpasses its\nnegation as a predictor of the data.  Once more, Bayes' Theorem tells\nus how to factor conditional probabilities into unconditional\nprobabilities and measures of predictive power.\n\nThe odds of a hypothesis conditional on a body of data is equal\nto the unconditional odds of the hypothesis multiplied by the degree\nto which it surpasses its negation as a predictor of the data.\n\n\n In our running J. Doe example, LR(H,\nE) is obtained by comparing the predictability of senior\nstatus given that J.  Doe died in 2000 to its predictability given\nthat he or she lived out the year.  Dividing the former \"prediction\nterm\" by the latter yields LR(H, E)\n=\nPH(E)/P~H(E)\n= 0.57/0.056 = 10.12.  Thus, as a predictor of senior status in 2000,\nknowing that J. Doe died is more than ten times better than knowing\nthat he or she lived.  \n\n The similarities between the \"probability ratio\" and \"odds ratio\"\nversions of Bayes' Theorem can be developed further if we express\nH's probability as a multiple of the probability of some\nother hypothesis H* using the relative probability\nfunction B(H, H*) =\nP(H)/P(H*).  It should be clear\nthat B generalizes both P and O since\nP(H) = B(H, T) and\nO(H) = B(H, ~H). By comparing\nthe conditional and unconditional values of B we obtain the\nBayes' Factor:\n\nBR(H, H*; E) =\nBE(H,\nH*)/B(H, H*) =\n[PE(H)/PE(H*)]/\n[P(H)/P(H*)].\n \n\n We can also generalize the likelihood ratio by setting\nLR(H, H*; E) =\nPH(E)/PH*(E).\nThis compares E's predictability on the basis of H\nwith its predictability on the basis of H*.  We can use these\ntwo quantities to formulate an even more general form of Bayes'\nTheorem.\n\n\n\n(1.6)\nBayes' Theorem (General Form)\n\n\n \nBR(H, H*; E) =\nLR(H, H*; E)\n\n\n\n\n The message of (1.6) is this:\n\nThe ratio of probabilities for two hypotheses conditional on a\nbody of data is equal to the ratio their unconditional probabilities\nmultiplied by the degree to which the first hypothesis surpasses the\nsecond as a predictor of the data.\n\n\n The various versions of Bayes' Theorem differ only with respect to\nthe functions used to express unconditional probabilities\n(P(H), O(H), B(H)) and\nin the likelihood term used to represent predictive power\n(PR(E, H),\nLR(H, E),\nLR(H, H*; E)).  In each\ncase, though, the underlying message is the same:\n\nconditional probability = unconditional probability \u00d7\n predictive power\n\n\n (1.2) \u2013 (1.6) are multiplicative forms of Bayes' Theorem that use\ndivision to compare the disparities between unconditional and\nconditional probabilities.  Sometimes these comparisons are best\nexpressed additively by replacing ratios with differences.\nThe following table gives the additive analogue of each ratio measure.\n\n\nTable 1\n\nRatio\nDifference\n\n\nProbability Ratio\u00a0\n\nPR(H, E)\n= PE(H)/P(H)\nProbability Difference\n\nPD(H, E) =\nPE(H) \u2212\nP(H) \n\nOdds Ratio\u00a0\n\nOR(H, E) =\nOE(H)/O(H)\nOdds Difference\u00a0\n\nOD(H, E) =\nOE(H) \u2212\nO(H)\n\n\nBayes' Factor\u00a0\n\nBR(H, H*; E) =\nBE(H,\nH*)/B(H, H*)\nBayes' Difference\u00a0\n\nBD(H, H*; E) =\nBE(H, H*) \u2212\nB(H, H*)\n\n\n\n\n We can use Bayes' theorem to obtain additive analogues of (1.4) \u2013\n(1.6), which are here displayed along with their multiplicative\ncounterparts:\n\n\nTable 2\n\n\nRatio\nDifference\n\n\n(1.4)\n\n\u00a0PR(H, E)\n= PR(E, H)\n= PH(E)/P(E)\n\n\u00a0PD(H, E)\n= P(H) [PR(E, H) \u2212 1]\n\n\n\n(1.5)\n\n\u00a0OR(H, E)\n= LR(H, E)\n= PH(E)/P~H(E)\n\n\u00a0OD(H, E) = O(H)\n[OR(H, E) \u2212 1]\n\n\n(1.6)\n\n \u00a0BR(H, H*; E) =\nLR(H, H*; E) =\nPH(E)/PH*(E)\n\n\u00a0BD(H, H*; E) =\nB(H, H*) [BR(H,\nH*; E) \u2212 1]\n\n\n\n\n Notice how each additive measure is obtained by multiplying\nH's unconditional probability, expressed on the relevant\nscale, P, O or B, by the associated\nmultiplicative measure diminished by 1.\n\n While the results of this section are useful to anyone who employs\nthe probability calculus, they have a special relevance for\nsubjectivist or \"Bayesian\" approaches to statistics,\nepistemology, and inductive\n inference.[5]\n Subjectivists lean heavily on conditional probabilities in their\ntheory of evidential support and their account of empirical\nlearning. Given that Bayes' Theorem is the single most important fact\nabout conditional probabilities, it is not at all surprising that it\nshould figure prominently in subjectivist methodology.\n3. The Role of Bayes' Theorem in Subjectivist Accounts of Evidence\n\n\nSubjectivists maintain that beliefs come in varying gradations of\nstrength, and that an ideally rational person's graded beliefs can be\nrepresented by a subjective probability function\nP. For each hypothesis H about which the person has a\nfirm opinion, P(H) measures her level of confidence\n(or \"degree of belief\") in H's\n truth.[6]\n Conditional beliefs are represented by conditional probabilities, so\nthat PE(H) measures the person's\nconfidence in H on the supposition that E is a\n fact.[7]\n\n One of the most influential features of the subjectivist program is\nits account of evidential support. The guiding ideas of this\nBayesian confirmation theory are these:\n\nConfirmational Relativity.  Evidential relationships must\nbe relativized to individuals and their degrees of belief.\nEvidence\n Proportionism.[8]\n A rational believer will proportion her confidence in a hypothesis\nH to her total evidence for H, so that her\nsubjective probability for H reflects the overall balance of\nher reasons for or against its truth.\nIncremental\n Confirmation.[9]\n A body of data provides incremental evidence for H\nto the extent that conditioning on the data raises H's\nprobability.\n\n The first principle says that statements about evidentiary\nrelationships always make implicit reference to people and their\ndegrees of belief, so that, e.g., \"E is evidence for\nH\" should really be read as \"E is evidence for\nH relative to the information encoded in the subjective\nprobability P\".\n\n According to evidence proportionism, a subject's level of confidence\nin H should vary directly with the strength of her evidence\nin favor of H's truth.  Likewise, her level of confidence in\nH conditional on E should vary directly with the\nstrength of her evidence for H's truth when this evidence is\naugmented by the supposition of E.  It is a matter of some\ndelicacy to say precisely what constitutes a person's\n evidence,[10]\n and to explain how her beliefs should be \"proportioned\" to it.\nNevertheless, the idea that incremental evidence is reflected in\ndisparities between conditional and unconditional probabilities only\nmakes sense if differences in subjective probability mirror\ndifferences in total evidence.\n\n An item of data provides a subject with incremental evidence\nfor or against a hypothesis to the extent that receiving the data\nincreases or decreases her total evidence for the truth of the\nhypothesis.  When probabilities measure total evidence, the increment\nof evidence that E provides for H is a matter of the\ndisparity between PE(H) and\nP(H).  When odds are used it is a matter of the\ndisparity between OE(H) and\nO(H). See\n Example 2 in the\nsupplementary document \"Examples, Tables, and Proof Sketches\", which\nillustrates the difference between total and incremental evidence, and\nexplains the \"baserate fallacy\" that can result from failing to\nproperly distinguish the two.\n\n It will be useful to distinguish two subsidiary concepts related to\ntotal evidence.\n\nThe net evidence in favor of H is the degree to which a\nsubject's total evidence in favor of H exceeds her total\nevidence in favor of ~H.\nThe balance of total evidence for H over H* is the degree\nto which a subject's total evidence in favor of H exceeds her\ntotal evidence in favor of H*.\n\n\n The precise content of these notions will depend on how total\nevidence is understood and measured, and on how disparities in total\nevidence are characterized.  For example, if total evidence is given\nin terms of probabilities and disparities are treated as ratios, then\nthe net evidence for H is\nP(H)/P(~H).  If total evidence\nis expressed in terms of odds and differences are used to express\ndisparities, then the net evidence for H will be\nO(H) \u2212 O(~H). Readers may\nconsult Table 3 (in \nthe supplementary document) for a complete list of the possibilities.\n\n As these remarks make clear, one can interpret O(H)\neither as a measure of net evidence or as a measure of total evidence.\nTo see the difference, imagine that 750 red balls and 250 black balls\nhave been drawn at random and with replacement from an urn known to\ncontain 10,000 red or black balls.  Assuming that this is our only\nevidence about the urn's contents, it is reasonable to set\nP(Red) = 0.75 and P(~Red) = 0.25.  On\na probability-as-total-evidence reading, these assignments reflect\nboth the fact that we have a great deal of evidence in favor of\nRed (namely, that 750 of 1,000 draws were red) and the fact\nthat we have also have some evidence against it (namely, that 250 of\nthe draws were black).  The net evidence for Red is\nthen the disparity between our total evidence for Red and our\ntotal evidence against Red.  This can be expressed\nmultiplicatively by saying that we have seen three times as many red\ndraws as black draws, which is just to say that O(Red)\n= 3.  Alternatively, we can use O(Red) as a measure of\nthe total evidence by taking our evidence for Red to be the\nratio of red to black draws, rather than the total number of red\ndraws, and our evidence for ~Red to be the ratio of black\nballs to red balls, rather than the total number of black draws.\nWhile the decision whether to use O as a measure total or net\nevidence makes little difference to questions about the\nabsolute amount of total evidence for a hypothesis (since\nO(H) is an increasing function of\nP(H)), it can make a major difference when one is\nconsidering the incremental changes in total evidence brought\nabout by conditioning on new information.\n\n Philosophers interested in characterizing correct patterns of\ninductive reasoning and in providing \"rational reconstructions\" of\nscientific methodology have tended to focus on incremental evidence as\ncrucial to their enterprise.  When scientists (or ordinary folk) say\nthat E supports or confirms H what they generally\nmean is that learning of E's truth will increase the total\namount of evidence for H's truth.  Since subjectivists\ncharacterize total evidence in terms of subjective probabilities or\nodds, they analyze incremental evidence in terms of changes in these\nquantities.  On such views, the simplest way to characterize the\nstrength of incremental evidence is by making ordinal comparisons of\nconditional and unconditional probabilities or odds.\n\n\n\n(2.1)\nA Comparative Account of Incremental Evidence.\n\n\n \nRelative to a subjective probability function P,\n \nE incrementally confirms (disconfirms, is irrelevant to)\nH if and only if PE(H) is\ngreater than (less than, equal to) P(H).\nH receives a greater increment (or lesser decrement) of\nevidential support from E than from E* if and only\nif PE(H) exceeds\nPE*(H).\n\n\n\n\n\n Both these equivalences continue to hold with probabilities replaced\nby odds.  So, this part of the subjectivist theory of evidence does\nnot depend on how total evidence is measured.\n\n Bayes' Theorem helps to illuminate the content of (2.1) by making it\nclear that E's status as incremental evidence for H\nis enhanced to the extent that H predicts E.  This\nobservation serves as the basis for the following conclusions about\nincremental confirmation (which hold so long as 1  > \nP(H), P(E)  >  0).\n\n\n\n(2.1a)\u00a0\n\u00a0If E incrementally confirms\nH, then H incrementally confirms E.\n\n\n(2.1b)\u00a0\n\u00a0If E incrementally confirms\nH, then E incrementally disconfirms\n~H.\n\n\n(2.1c)\u00a0 \u00a0If H entails E, then E\nincrementally confirms H.\n\n\n(2.1d)\u00a0\n\u00a0If PH(E) =\nPH(E*), then H receives\nmore incremental support from E than from E* if and\nonly if E is unconditionally less probable than\nE*.\n\n\n(2.1e)\u00a0\n\u00a0Weak Likelihood Principle.\nE provides incremental evidence for H if and only if\nPH(E) >\nP~H(E).  More generally, if\nPH(E) >\nPH*(E) and\nP~H(~E) \u2265\nP~H*(~E), then E provides\nmore incremental evidence for H than for H*.\n\n\n\n\n (2.1a) tells us that incremental confirmation is a matter of\nmutual reinforcement: a person who sees E as\nevidence for H invests more confidence in the possibility\nthat both propositions are true than in either possibility in which\nonly one obtains.\n\n (2.1b) says that relevant evidence must be capable of discriminating\nbetween the truth and falsity of the hypothesis under test.\n\n (2.1c) provides a subjectivist rationale for the\nhypothetico-deductive model of confirmation. According to\nthis model, hypotheses are incrementally confirmed by any evidence\nthey entail.  While subjectivists reject the idea that evidentiary\nrelations can be characterized in a belief-independent manner \u2014\nBayesian confirmation is always relativized to a person and\nher subjective probabilities \u2014 they seek to preserve the basic\ninsight of the H-D model by pointing out that hypotheses are\nincrementally supported by evidence they entail for anyone who has\nnot already made up her mind about the hypothesis or the\nevidence.  More precisely, if H entails E, then\nPE(H) =\nP(H)/P(E), which exceeds\nP(H) whenever 1 > P(E),\nP(H) > 0.  This explains why scientists so often\nseek to design experiments that fit the H-D paradigm.  Even when\nevidentiary relations are relativized to subjective probabilities,\nexperiments in which the hypothesis under test entails the data will\nbe regarded as evidentially relevant by anyone who has not\nyet made up his mind about the hypothesis or the data. The\ndegree of incremental confirmation will vary among people\ndepending on their prior levels of confidence in H and\nE , but everyone will agree that the data incrementally\nsupports the hypothesis to at least some degree.\n \n Subjectivists invoke (2.1d) to explain why scientists so often regard\nimprobable or surprising evidence as having more confirmatory\npotential than evidence that is antecedently known. While it is not\ntrue in general that improbable evidence has more confirming\npotential, it is true that E's incremental confirming power\nrelative to H varies inversely with E's\nunconditional probability when the value of the inverse\nprobability PH(E) is held\nfixed.  If H entails both E and E*,\nsay, then Bayes' Theorem entails that the least probable of the two\nsupports H more strongly.  For example, even if heart attacks\nare invariably accompanied by severe chest pain and shortness of\nbreath, the former symptom is far better evidence for a heart attack\nthan the latter simply because severe chest pain is so much less\ncommon than shortness of breath.\n\n (2.1e) captures one core message of Bayes' Theorem for theories of\nconfirmation.  Let's say that H is uniformly better\nthan H* as predictor of E's truth-value when (a)\nH predicts E more strongly than H* does,\nand (b) ~H predicts ~E more strongly than\n~H* does.  According to the weak likelihood principle,\nhypotheses that are uniformly better predictors of the data are better\nsupported by the data.  For example, the fact that little Johnny is a\nChristian is better evidence for thinking that his parents are\nChristian than for thinking that they are Hindu because (a) a far\nhigher proportion of Christian parents than Hindu have Christian\nchildren, and (b) a far higher proportion of non-Christian parents\nthan non-Hindu parents have non-Christian children.\n\n Bayes' Theorem can also be used as the basis for developing and\nevaluating quantitative measures of evidential support. The\nresults listed in Table 2 entail that all four of the functions\nPR, OR, PD and\nOD agree with one another on the simplest question of\nconfirmation: Does E provide incremental evidence for\nH?\n\n\n\n(2.2)\nCorollary.\n\n\n \nEach of the following is equivalent to the assertion\nthat E provides incremental evidence in favor of H:\nPR(H, E) > 1,\nOR(H, E) > 1,\nPD(H, E) > 0,\nOD(H, E) > 0.\n\n\n\n\n Thus, all four measures agree with the comparative account of\nincremental evidence given in (2.1).\n\n Given all this agreement it should not be surprising that\nPR(H, E),\nOR(H, E) and\nPD(H, E), have all been proposed as\nmeasures of the degree of incremental support that E\nprovides for\n H.[11]\n While OD(H, E) has not been\nsuggested for this purpose, we will consider it for reasons of\nsymmetry.  Some authors maintain that one or another of these\nfunctions is the unique correct measure of incremental evidence;\nothers think it best to use a variety of measures that capture\ndifferent evidential relationships.  While this is not the place to\nadjudicate these issues, we can look to Bayes' Theorem for help in\nunderstanding what the various functions measure and in characterizing\nthe formal relationships among them.\n\n All four measures agree in their conclusions about the\ncomparative amount of incremental evidence that different\nitems of data provide for a fixed hypothesis.  In particular,\nthey agree ordinally about the following concepts derived from\nincremental evidence:\n\nThe effective increment of\n evidence[12]\n that E provides for H is the amount by which the\nincremental evidence that E provides for H exceeds\nthe incremental evidence that ~E provides for H.\n\nThe differential in the incremental evidence that\nE and E* provide for H is the amount by\nwhich the incremental evidence that E provides for H\nexceeds the incremental evidence that E* provides for\nH.\n\n\n Effective evidence is a matter of the degree to which a person's\ntotal evidence for H depends on her opinion about E.\nWhen PE(H) and\nP~E(H) (or\nOE(H) and\nO~E(H)) are far apart the person's\nbelief about E has a great effect on her belief about\nH: from her point of view, a great deal hangs on E's\ntruth-value when it comes to questions about H's truth-value.\nA large differential in incremental evidence between E and\nE* tells us that learning E increases the subject's\ntotal evidence for H by a larger amount than learning\nE* does.  Readers may consult\n Table 4 (in the\nsupplement) for quantitative measures of effective and\ndifferential evidence.\n\n The second clause of (2.1) tells us that E provides more\nincremental evidence than E* does for H just in case\nthe probability of H conditional on E exceeds the\nprobability of H conditional on E*.  It is then a\nsimple step to show that all four measures of incremental support\nagree ordinally on questions of effective evidence and of\ndifferentials in incremental evidence.\n\n\n\n(2.3)\nCorollary.\n\n\n \nFor any H, E* and E with\npositive probability, the following are equivalent:\n \nE provides more incremental evidence than E*\ndoes for H\nPR(H, E) >\nPR(H, E*)\nOR(H, E) >\nOR(H, E*)\nPD(H, E) >\nPD(H, E*)\nOD(H, E) >\nOD(H, E*)\n\n\n\n\n\n\n The four measures of incremental support can disagree over the\ncomparative degree to which a single item of data\nincrementally confirms two distinct hypotheses. \n Example 3,\n Example 4, and\n Example 5\n (in the supplement) show the various ways in which this\ncan happen.\n\n All the differences between the measures have ultimately to do with\n(a) whether the total evidence in favor of a hypothesis\nshould be measured in terms of probabilities or in terms of odds, and\n(b) whether disparities in total evidence are best captured\nas ratios or as differences.  Rows in the following table correspond\nto different measures of total evidence.  Columns correspond to\ndifferent ways of treating disparities.\n\n\nTable 5: Four measures of incremental evidence\n\n\n\nRatio\n\n\nDifference\n\n\n\nP = Total\n\nPR(H, E) =\n PE(H)/P(H)\n\n\nPD(H, E)\n= PE(H) \u2212\nP(H)\n\n\n\nO = Total\n\nOR(H, E) =\n OE(H)/O(H)\n\n\nOD(H, E)\n= OE(H) \u2212\nO(H)\n\n\n\n\n Similar tables can be constructed for measures of net evidence and\nmeasures of balances in total evidence.  See\n Table 5A in the supplement.\n\n We can use the various forms of Bayes' Theorem to clarify the\nsimilarities and differences among these measures by rewriting each of\nthem in terms of likelihood ratios.\n\n\nTable 6: The four measures expressed in terms of\nlikelihood ratios\n\n\n\nRatio\n\n\nDifference\n\n\n\nP = Total\n\nPR(H, E) =\nLR(H, T;\nE)\n\nPD(H, E) =\nP(H)[LR(H, T;\nE) \u2212 1]\n\n\nO = Total\n\nOR(H, E) =\nLR(H, ~H; E)\n\nOD(H, E)=\nO(H)[LR(H, ~H;\nE) \u2212 1]\n\n\n\n\n This table shows that there are two differences between each\nmultiplicative measure and its additive counterpart.  First, the\nlikelihood term that appears in a given multiplicative measure is\ndiminished by 1 in its associated additive measure.  Second, in each\nadditive measure the diminished likelihood term is multiplied by an\nexpression for H's probability: P(H) or\nO(H), as the case may be.  The first difference\nmarks no distinction; it is due solely to the fact that the\nmultiplicative and additive measures employ a different zero point\nfrom which to measure evidence.  If we settle on the point of\nprobabilistic independence PE(H) =\nP(H) as a natural common zero, and so subtract 1 from\neach multiplicative\n measure,[13]\n then equivalent likelihood terms appear in both columns.\n\n The real difference between the measures in a given row concerns the\neffect of unconditional probabilities on relations of incremental\nconfirmation.  Down the right column, the degree to which E\nprovides incremental evidence for H is directly proportional\nto H's probability expressed in units of\nP(T) or P(~H).  In the left\ncolumn, H's probability makes no difference to the amount of\nincremental evidence that E provides for H once\nPH(E) and either\nP(E) or P~H(E) are\n fixed.[14]\n In light of Bayes' Theorem, then, the difference between the ratio\nmeasures and then difference measures boils down to one question:\n\nDoes a given piece of data provide a greater increment of\nevidential support for a more probable hypothesis than it does for a\nless probable hypothesis when both hypotheses predict the data equally\nwell?\n\nThe difference measures answer yes, the ratio measures answer no.\n\n Bayes' Theorem can also help us understand the difference between\nrows.  The measures within a given row agree about the role of\npredictability in incremental confirmation.  In the top row\nthe incremental evidence that E provides for H\nincreases linearly with\nPH(E)/P(E),\nwhereas in the bottom row it increases linearly with\nPH(E)/P~H(E).\nThus, when probabilities measure total evidence what matters is the\ndegree to which H exceeds T as a predictor of\nE, but when odds measure total evidence it is the degree to\nwhich H exceeds ~H as a predictor of E that\nmatters.\n\n The central issue here concerns the status of the likelihood ratio.\nWhile everyone agrees that it should play a leading role in any\nquantitative theory of evidence, there are conflicting views about\nprecisely what evidential relationship it captures.  There are three\npossible interpretations.\n\n\nTable 7: Three interpretations of the likelihood\nratio\n\nProbability as total evidence reading\n\n\nPR(H, E) measures incremental\nchange in total evidence.\nLR(H, E) measures incremental\nchange in net evidence.\nLR(H, H*, E) measures\nincremental change in the balance of evidence that E provides\nfor H over H*\n\n\n\n\nOdds as total evidence reading\n\n\nLR(H, E) measures incremental\nchanges in total evidence.\nLR(H, E)2 measures\nincremental change in net evidence.\nLR(H, H*;\nE)/LR(~H, ~H*;\nE) measures incremental change in the balance of evidence\nthat E provides for H over H*.\n\n\n\n\n\"Likelihoodist\" reading\n\n\nNeither P nor O measures total evidence because\nevidential relations are essentially comparative; they always\ninvolve the balance of evidence.\nLR(H, E) measures the balance\nof evidence that E provides for H over\nH*.\nLR(H, H*; E) measures\nthe balance of evidence that E provides for H over\nH*.\n\n\n\n\n\n\n On the first reading there is no conflict whatsoever between using\nprobability ratios and using likelihood ratios to measure evidence.\nOnce we get clear on the distinctions between total evidence, net\nevidence and the balance of evidence, we see that each of\nPR(H, E),\nLR(H, E) and\nLR(H, H*; E) measures an\nimportant evidential relationship, but that the relationships they\nmeasure are importantly different.\n\n When odds measure total evidence neither\nPR(H, E) nor\nLR(H, H*; E) plays a\nfundamental role in the theory of evidence.  Changes in the\nprobability ratio for H given E only indicate\nchanges in incremental evidence in the presence of information about\nchanges in the probability ratio for ~H given E.\nLikewise, changes in the likelihood ratio for H and\nH* given E only indicate changes in the balance of\nevidence in light of information about changes in the likelihood ratio\nfor ~H and ~H* given E.  Thus, while each\nof the two functions can figure as one component in a meaningful\nmeasure of confirmation, neither tells us anything about incremental\nevidence when taken by itself.\n\n The third view, \"likelihoodism,\" is popular among non-Bayesian\nstatisticians.  Its proponents deny evidence proportionism.  They\nmaintain that a person's subjective probability for a hypothesis\nmerely reflects her degree of uncertainty about its truth; it need not\nbe tied in any way to the amount of evidence she has in its\n favor.[15]\n It is likelihood ratios, not subjective probabilities, which capture\nthe \"scientifically meaningful\" evidential relations.  Here are two\nclassic statements of the position.\n\n All the information which the data provide concerning the relative\nmerits of two hypotheses is contained in the likelihood ratio of the\nhypotheses on the data.  (Edwards 1972, 30)\n\n\n The \u2018evidential meaning\u2019 of experimental results is characterized\nfully by the likelihood function\u2026 Reports of experimental results in\nscientific journals should in principle be descriptions of likelihood\nfunctions. (Brinbaum 1962, 272)\n\n\n On this view, everything that can be said about the evidential import\nof E for H is embodied in the following\ngeneralization of the weak likelihood principle:\n\nThe \"Law of Likelihood\".  If H implies that the\nprobability of E is x, while H* implies\nthat the probability of E is x*, then E is\nevidence supporting H over H* if and only if\nx exceeds x*, and the likelihood ratio,\nx/x*, measures the strength of this support.\n(Hacking 1965, 106-109), (Royall 1997, 3)\n \n\n The biostatistician Richard Royall is a particularly lucid defender\nof likelihoodism (Royall 1997).  He maintains that any scientifically\nrespectable concept of evidence must analyze the evidential impact of\nE on H solely in terms of likelihoods; it should not\nadvert to anyone's unconditional probabilities for E or\nH.  This is supposed to be because likelihoods are both\nbetter known and more objective than unconditional probabilities.\nRoyall argues strenuously against the idea that incremental evidence\ncan be measured in terms of the disparity between unconditional and\nconditional probabilities.  Here is the gist of his complaint:\n\n Whereas [LR(H, H*; E)]\nmeasures the support for one hypothesis H relative to a\nspecific alternative H*, without regard either to the prior\nprobabilities of the two hypotheses or to what other hypotheses might\nalso be considered, the law of changing probability [as measured by\nPR(H, E)] measures support for\nH relative to a specific prior distribution over H\nand its alternatives... The law of changing probability is of limited\nusefulness in scientific discourse because of its dependence on the\nprior probability distribution, which is generally unknown and/or\npersonal.  Although you and I agree (on the basis of the law of\nlikelihood) that given evidence supports H over H*,\nand H** over both H and H*, we might\ndisagree about whether it is evidence supporting H (on the\nbasis of the law of changing probability) purely on the basis of our\ndifferent judgments of the priori probability of H,\nH*, and H**.  (Royall 1997, 10-11, with slight\nchanges in notation)\n \n Royall's point is that neither the probability ratio nor probability\ndifference will capture the sort of objective evidence required by\nscience because their values depend on the \"subjective\" terms\nP(E) and P(H), and not just on the\n\"objective\" likelihoods PH(E) and\nP~H(E).\n\n Whether one agrees with this assessment will be a matter of\nphilosophical temperament, in particular of one's willingness to\ntolerate subjective probabilities in one's account of evidential\nrelations.  It will also depend crucially on the extent to which one\nis convinced that likelihoods are better known and more objective than\nordinary subjective probabilities.  Cases like the one envisioned in\nthe law of likelihood, where hypotheses deductively entails a\ndefinite probability for the data, are relatively rare.  So, unless\none is willing to adopt a theory of evidence with a very restricted\nrange of application, a great deal will turn on how easy it is to\ndetermine objective likelihoods in situations where the predictive\nconnection from hypothesis to data is itself the result of\ninductive inferences.  However one comes down on these\nissues, though, there is no denying that likelihood ratios will play a\ncentral role in any probabilistic account of evidence.\n\n In fact, the weak likelihood principle (2.1e) encapsulates a minimal\nform of Bayesianism to which all parties can agree.  This is clearest\nwhen it is restated in terms of likelihoods.\n\n\n\n(2.1e)\u00a0\nThe Weak Likelihood Principle. (expressed in\nterms of likelihood ratios)\n\n\n \nIf LR(H, H*; E)\n\u2265 1 and LR(~H, ~H*;\n~E) \u2265 1, with one inequality strict, then E\nprovides more incremental evidence for H than for H*\nand ~E provides more incremental evidence for ~H\nthan for ~H*.\n\n\n\n\n Likelihoodists will endorse (2.1e) because the relationships\ndescribed in its antecedent depend only on inverse probabilities.\nProponents of both the \"probability\" and \"odds\" interpretations of\ntotal evidence will accept (2.1e) because satisfaction of its\nantecedent ensures that conditioning on E increases\nH's probability and its odds strictly more than those of\nH*.  Indeed, the weak likelihood principle must be an\nintegral part of any account of evidential relevance that deserves the\ntitle \"Bayesian\".  To deny it is to misunderstand the central message\nof Bayes' Theorem for questions of evidence: namely, that hypotheses\nare confirmed by data they predict.  As we shall see in the next\nsection, this \"minimal\" form of Bayesianism figures importantly into\nsubjectivist models of learning from experience.\n4. The Role of Bayes' Theorem in Subjectivist Models of Learning\n\n\nSubjectivists think of learning as a process of belief\nrevision in which a \"prior\" subjective probability P is\nreplaced by a \"posterior\" probability Q that incorporates newly\nacquired information.  This process proceeds in two stages. First,\nsome of the subject's probabilities are directly altered by\nexperience, intuition, memory, or some other non-inferential\nlearning process. Second, the subject \"updates\" the rest of her\nopinions to bring them into line with her newly acquired knowledge.\n\n Many subjectivists are content to regard the initial belief changes\nas sui generis and independent of the believer's prior state\nof opinion.  However, as long as the first phase of the learning\nprocess is understood to be non-inferential, subjectivism can be made\ncompatible with an \"externalist\" epistemology that allows for\ncriticism of belief changes in terms the reliability of the causal\nprocesses that generate them. It can even accommodate the thought that\nthe direct effect of experience might depend causally on the\nbeliever's prior probability.\n\n Subjectivists have studied the second, inferential phase of the\nlearning process in great detail. Here immediate belief changes are\nseen as imposing constraints of the form \"the posterior probability\nQ has such-and-such properties.\" The objective is to discover\nwhat sorts of constraints experience tends to impose, and to explain\nhow the person's prior opinions can be used to justify the\nchoice of a posterior probability from among the many that might\nsatisfy a given constraint. Subjectivists approach the latter problem\nby assuming that the agent is justified in adopting whatever eligible\nposterior departs minimally from her prior opinions. This is\na kind of \"no jumping to conclusions\" requirement. We explain it here\nas a natural result of the idea that rational learners should\nproportion their beliefs to the strength of the evidence they acquire.\n\n The simplest learning experiences are those in which the learner\nbecomes certain of the truth of some proposition E about\nwhich she was previously uncertain. Here the constraint is that all\nhypotheses inconsistent with E must be assigned probability\nzero. Subjectivists model this sort of learning as simple\nconditioning, the process in which the prior probability of each\nproposition H is replaced by a posterior that coincides with\nthe prior probability of H conditional on E.\n\n\n\n(3.1)\nSimple Conditioning\n\n\n \nIf a person with a \"prior\" such that 0 < P(E) < 1\nhas a learning experience whose sole immediate effect is to raise her\nsubjective probability for E to 1, then her post-learning\n\"posterior\" for any proposition H should be\nQ(H) = PE(H).\n\n\n\n\n In short, a rational believer who learns for certain that E\nis true should factor this information into her doxastic system by\nconditioning on it.\n\n Though useful as an ideal, simple conditioning is not widely\napplicable because it requires the learner to become absolutely\ncertain of E's truth. As Richard Jeffrey has argued\n(Jeffrey 1987), the evidence we receive is often too vague or\nambiguous to justify such \"dogmatism.\"  On more realistic models, the\ndirect effect of a learning experience will be to alter the\nsubjective probability of some proposition without raising it to 1 or\nlowering it to 0. Experiences of this sort are appropriately modeled\nby what has come to be called Jeffrey conditioning (though\nJeffrey's preferred term is \"probability kinematics\").\n\n\n\n(3.2)\nJeffrey Conditioning\n\n\n \nIf a person with a prior such that 0 < P(E) < 1\nhas a learning experience whose sole immediate effect is to change her\nsubjective probability for E to q, then her\npost-learning posterior for any H should be\nQ(H) =\nqPE(H) + (1 \u2212\nq)P~E(H).\n\n\n\n\n Obviously, Jeffrey conditioning reduces to simple conditioning when\nq = 1.\n\n A variety of arguments for conditioning (simple or Jeffrey-style) can\nbe found in the literature, but we cannot consider them\n here.[16]\n There is, however, one sort of justification in which Bayes' Theorem\nfigures prominently. It exploits connections between belief revision\nand the notion of incremental evidence to show that conditioning is\nthe only belief revision rule that allows learners to\ncorrectly proportion their posterior beliefs to the new evidence they\nreceive.\n\n The key to the argument lies in marrying the \"minimal\" version of\nBayesian expressed in the (2.1e) to a very modest \"proportioning\"\nrequirement for belief revision rules.\n\n\n\n(3.3)\nThe Weak Evidence Principle\n\n\n \n If, relative to a prior P, E provides at least\nas much incremental evidence for H as for H*, and if\nH is antecedently more probable than H*, then\nH should remain more probable than H* after any\nlearning experience whose sole immediate effect is to increase the\nprobability of E.\n\n\n\n\n This requires an agent to retain his views about the relative\nprobability of two hypotheses when he acquires evidence that supports\nthe more probable hypothesis more strongly. It rules out obviously\nirrational belief revisions such as this: George is more confident\nthat the New York Yankees will win the American League Pennant than he\nis that the Boston Rex Sox will win it, but he reverses himself when\nhe learns (only) that the Yankees beat the Red Sox in last night's\ngame.\n\n Combining (3.3) with minimal Bayesianism yields the following:\n\n\n\n(3.4)\nConsequence\n\n\n \nIf a person's prior is such that LR(H,\nH*; E) \u2265 1, LR(~H,\n~H*; ~E) \u2265 1, and P(H) >\nP(H*), then any learning experience whose sole\nimmediate effect is to raise her subjective probability for E\nshould result in a posterior such that Q(H) >\nQ(H*).\n\n\n\n\n On the reasonable assumption that Q is defined on the same set\nof propositions over which P is defined, this condition\nsuffices to pick out simple conditioning as the unique\ncorrect method of belief revision for learning experiences that make\nE certain.  It picks out Jeffrey conditioning as the\nunique correct method when learning merely alters one's\nsubjective probability for E.  The argument for these\nconclusions makes use of the following two facts about probabilities.\n\n\n\n(3.5)\nLemma\n\n\n \nIf H and H* both entail E when\nP(H) > P(H*), then\nLR(H, H*; E) = 1 and\nLR(~H, ~H*; ~E) >\n1.\n\n\n\nProof Sketch\n\n\n\n\n(3.6)\nLemma\n\n\n \nSimple conditioning on E is the only rule for revising\nsubjective probabilities that yields a posterior with the following\nproperties for any prior such that P(E) >\n0:\n\nQ(E) = 1.\nOrdinal Similarity.  If H and H* both\nentail E, then P(H) \u2265\nP(H*) if and only if Q(H) \u2265\nQ(H*).\n\n\n\n\n\nProof Sketch\n\n\n\n\n From here the argument for simple conditioning is a matter of using\n(3.4) and (3.5) to establish ordinal similarity.  Suppose that\nH and H* entail E and that\nP(H) > P(H*).  It follows from\n(3.5) that LR(H, H*; E) = 1\nand LR(~H, ~H*; ~E) >\n1. (3.4) then entails that any learning experience that raises\nE's probability must result in a posterior with\nQ(H) > Q(H*).  Thus, Q and\nP are ordinally similar with respect to hypotheses that entail\nH.  If we go on to suppose that the learning experience\nraises E's probability to 1, then (3.6) then guarantees that\nQ arises from P by simple conditioning on E.\n\n The case for Jeffrey conditioning is similarly direct.  Since the\nargument for ordinal similarity did not depend at all on the\nassumption that Q(E) = 1, we have really established\n\n\n\n(3.7)\nCorollary\n\n\n \n\u2022 If H and H* entail E, then\nP(H) > P(H*) if and only if\nQ(H) > Q(H*).\n\n\n\n\u2022 If H and H* entail ~E, then\nP(H) > P(H*) if and only if\nQ(H) > Q(H*).\n\n\n\n\n So, Q is ordinally similar to P both when restricted to\nhypotheses that entail E and when restricted to hypotheses\nthan entail ~E. Moreover, since dividing by positive numbers\ndoes not disturb ordinal relationships, it also follows that that\nQE is ordinally similar to P when\nrestricted to hypotheses that entail E, and that\nQ~E is ordinally similar to P when\nrestricted to hypotheses than entail ~E. Since\nQE(E) = 1 =\nQ~E(E), (3.6) then entails:\n\n\n\n(3.8)\nConsequence\n\n\n \n\n For every proposition H,\nQE(H) =\nPE(H) and\nQ~E(H) =\nP~E(H)\n \n\n\n\n\n It is easy to show that (3.8) is necessary and sufficient for\nQ to arise from P by Jeffrey conditioning on E.\nSubject to the constraint Q(E) = q, it\nguarantees that Q(H) =\nqPE(H) + (1\n\u2212q)P~E(H).\n\n The general moral is clear.\n\nThe basic Bayesian insight embodied in the weak likelihood\nprinciple (2.1e) entails that simple and Jeffrey conditioning on\nE are the only rational ways to revise beliefs in\nresponse to a learning experience whose sole immediate effect is to\nalter E's probability.\n\n\n While much more can be said about simple conditioning, Jeffrey\nconditioning and other forms of belief revision, these remarks should\ngive the reader a sense of the importance of Bayes' Theorem in\nsubjectivist accounts of learning and evidential support. Though a\nmathematical triviality, the Theorem's central insight \u2014 that a\nhypothesis is supported by any body of data it renders probable \u2014 lies at the heart of all subjectivist approaches to epistemology, statistics, and inductive logic.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Armendt, B. 1980. \"Is There a Dutch Book Argument for Probability\nKinematics?\", <em>Philosophy of Science</em> <b>47</b>, 583-588.",
                "Bayes, T. 1764. \"An Essay Toward Solving a Problem in the Doctrine\nof Chances\", <em>Philosophical Transactions of the Royal Society of\nLondon</em> <b>53</b>, 370-418. \n [<a href=\"https://web.archive.org/web/20190126111142/http://www.stat.ucla.edu/history/essay.pdf\" target=\"other\">Fascimile available online</a>: the original essay with an introduction by\n his friend Richard Price]",
                "Birnbaum A. 1962. \"On the Foundations of Statistical Inference\",\n<em>Journal of the American Statistical Association</em> <b>53</b>,\n259-326.",
                "Carnap, R. 1962. <em>Logical Foundations of Probability</em>, 2nd\nedition. Chicago: University of Chicago Press.",
                "Chihara, C. 1987. \"Some Problems for Bayesian Confirmation\nTheory\", <em>British Journal for the Philosophy of Science</em>\n<b>38</b>, 551-560.",
                "Christensen, D. 1999. \"Measuring Evidence\", <em>Journal of\nPhilosophy</em> <b>96</b>, 437-61.",
                "Dale, A. I. 1989. \"Thomas Bayes: A Memorial\", <em>The Mathematical\nIntelligencer</em> <b>11</b>, 18-19.",
                "----- 1999. <em>A History of Inverse Probability</em>, 2nd\nedition. New York: Springer-Verlag.",
                "Earman, J. 1992. <em>Bayes or Bust?</em> Cambridge, MA: MIT\nPress.",
                "Edwards, A. W. F. 1972. <em>Likelihood</em>. Cambridge: Cambridge\nUniversity Press.",
                "Glymour, Clark. 1980. <em>Theory and Evidence</em>. Princeton:\nPrinceton University Press.",
                "Hacking, Ian. 1965. <em>Logic of Statistical\nInference</em>. Cambridge: Cambridge University Press.",
                "H\u00e1jek, A. 2003. \"Interpretations of the Probability Calculus\",\n in the <em>Stanford Encyclopedia of Philosophy</em>, (Summer 2003\nEdition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/sum2003/entries/probability-interpret/\">https://plato.stanford.edu/archives/sum2003/entries/probability-interpret/</a>&gt;",
                "Hammond, P. 1994. \"Elementary non-Archimedean Representations for\nof Probability for Decision Theory and Games,\" in P. Humphreys, ed.,\n<em>Patrick Suppes: Scientific Philosopher, vol. 1</em>., Dordrecht:\nKluwer Publishers, 25-62.",
                "Harper, W. 1976. \"Rational Belief Change, Popper Functions and\nCounterfactuals,\" in W. Harper and C. Hooker, eds., <em>Foundations of\nProbability Theory, Statistical Inference, and Statistical Theories of\nScience, vol. I</em>. Dordrecht: Reidel, 73-115.",
                "Hartigan, J. A. 1983. <em>Bayes Theory</em>. New York:\nSpringer-Verlag.",
                "Howson, Colin. 1985. \"Some Recent Objections to the Bayesian\nTheory of Support\", <em>British Journal for the Philosophy of\nScience</em>, <b>36</b>, 305-309.",
                "Jeffrey, R. 1987. \"Alias Smith and Jones: The Testimony of the\nSenses\", <em>Erkenntnis</em> <b>26</b>, 391-399.",
                "----- 1992. <em>Probability and the Art of Judgment</em>. New\nYork: Cambridge University Press.",
                "Joyce, J. M. 1999. <em>The Foundations of Causal Decision\nTheory</em>. New York: Cambridge University Press.",
                "Kahneman, D. and Tversky, A. 1973. \"On the psychology of\nprediction\", <em>Psychological Review</em> <b>80</b>, 237-251.",
                "Kaplan, M. 1996. <em>Decision Theory as\nPhilosophy</em>. Cambridge: Cambridge University Press.",
                "Levi, I. 1985. \"Imprecision and Indeterminacy in Probability\nJudgment\", <em>Philosophy of Science</em> <b>53</b>, 390-409.",
                "Maher, P. 1996. \"Subjective and Objective Confirmation\",\n<em>Philosophy of Science</em> <b>63</b>, 149-174.",
                "McGee, V. 1994. \"Learning the Impossible,\" in E. Eells and\nB. Skyrms, eds., <em>Probability and Conditionals</em>. New York:\nCambridge University Press, 179-200.",
                "Mortimer, Halina. 1988. <em>The logic of induction</em>, Ellis Horwood \nSeries in Artificial Intelligence, New York; Halsted Press.",
                "Nozick, R. 1981. <em>Philosophical Explanations</em>. Cambridge:\nHarvard University Press.\n",
                "Renyi, A. 1955. \"On a New Axiomatic Theory of Probability\",\n<em>Acta Mathematica Academiae Scientiarium Hungaricae</em> <b>6</b>,\n285-335.",
                "Royall, R. 1997. <em>Statistical Evidence: A Likelihood\nParadigm</em>. New York: Chapman &amp; Hall/CRC.",
                "Skyrms, B. 1987. \"Dynamic Coherence and Probability\nKinematics\". <em>Philosophy of Science</em> <b>54</b>, 1-20.\n",
                "Sober, E. 2002. \"Bayesianism \u2014 its Scope and Limits\", in\nSwinburne (2002), 21-38.",
                "Sphon, W. 1986. \"The Representation of Popper Measures\",\n<em>Topoi</em> <b>5</b>, 69-74.",
                "Stigler, S. M. 1982. \"Thomas Bayes' Bayesian Inference\",\n<em>Journal of the Royal Statistical Society, series A</em>\n<b>145</b>, 250-258.",
                "Swinburne, R. 2002. <em>Bayes' Theorem</em>. Oxford: Oxford\nUniversity Press (published for the British Academy).",
                "Talbot, W. 2001. \"Bayesian Epistemology\",\n <em>Stanford Encyclopedia of Philosophy</em> (Fall\n2001 Edition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/fall2001/entries/epistemology-bayesian/\">https://plato.stanford.edu/archives/fall2001/entries/epistemology-bayesian/</a>&gt;",
                "Teller, P. 1976. \"Conditionalization, Observation, and Change of\nPreference\", in W. Harper and C.A. Hooker, eds., <em>Foundations of\nProbability Theory, Statistical Inference, and Statistical Theories of\nScience</em>. Dordrecht: D. Reidel.\n",
                "Williamson, T. 2000. <em>Knowledge and its Limits</em>. Oxford:\nOxford University Press.",
                "Van Fraassen, B.  1999. \"A New Argument for\nConditionalization\". <em>Topoi</em> <b>18</b>, 93-96."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2><a name=\"Bib\">Bibliography</a></h2>\n<ul>\n<li>Armendt, B. 1980. \"Is There a Dutch Book Argument for Probability\nKinematics?\", <em>Philosophy of Science</em> <b>47</b>, 583-588.</li>\n<li>Bayes, T. 1764. \"An Essay Toward Solving a Problem in the Doctrine\nof Chances\", <em>Philosophical Transactions of the Royal Society of\nLondon</em> <b>53</b>, 370-418. \n [<a href=\"https://web.archive.org/web/20190126111142/http://www.stat.ucla.edu/history/essay.pdf\" target=\"other\">Fascimile available online</a>: the original essay with an introduction by\n his friend Richard Price]</li>\n<li>Birnbaum A. 1962. \"On the Foundations of Statistical Inference\",\n<em>Journal of the American Statistical Association</em> <b>53</b>,\n259-326.</li>\n<li>Carnap, R. 1962. <em>Logical Foundations of Probability</em>, 2nd\nedition. Chicago: University of Chicago Press.</li>\n<li>Chihara, C. 1987. \"Some Problems for Bayesian Confirmation\nTheory\", <em>British Journal for the Philosophy of Science</em>\n<b>38</b>, 551-560.</li>\n<li>Christensen, D. 1999. \"Measuring Evidence\", <em>Journal of\nPhilosophy</em> <b>96</b>, 437-61.</li>\n<li>Dale, A. I. 1989. \"Thomas Bayes: A Memorial\", <em>The Mathematical\nIntelligencer</em> <b>11</b>, 18-19.</li>\n<li>----- 1999. <em>A History of Inverse Probability</em>, 2nd\nedition. New York: Springer-Verlag.</li>\n<li>Earman, J. 1992. <em>Bayes or Bust?</em> Cambridge, MA: MIT\nPress.</li>\n<li>Edwards, A. W. F. 1972. <em>Likelihood</em>. Cambridge: Cambridge\nUniversity Press.</li>\n<li>Glymour, Clark. 1980. <em>Theory and Evidence</em>. Princeton:\nPrinceton University Press.</li>\n<li>Hacking, Ian. 1965. <em>Logic of Statistical\nInference</em>. Cambridge: Cambridge University Press.</li>\n<li>H\u00e1jek, A. 2003. \"Interpretations of the Probability Calculus\",\n in the <em>Stanford Encyclopedia of Philosophy</em>, (Summer 2003\nEdition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/sum2003/entries/probability-interpret/\">https://plato.stanford.edu/archives/sum2003/entries/probability-interpret/</a>&gt;</li>\n<li>Hammond, P. 1994. \"Elementary non-Archimedean Representations for\nof Probability for Decision Theory and Games,\" in P. Humphreys, ed.,\n<em>Patrick Suppes: Scientific Philosopher, vol. 1</em>., Dordrecht:\nKluwer Publishers, 25-62.</li>\n<li>Harper, W. 1976. \"Rational Belief Change, Popper Functions and\nCounterfactuals,\" in W. Harper and C. Hooker, eds., <em>Foundations of\nProbability Theory, Statistical Inference, and Statistical Theories of\nScience, vol. I</em>. Dordrecht: Reidel, 73-115.</li>\n<li>Hartigan, J. A. 1983. <em>Bayes Theory</em>. New York:\nSpringer-Verlag.</li>\n<li>Howson, Colin. 1985. \"Some Recent Objections to the Bayesian\nTheory of Support\", <em>British Journal for the Philosophy of\nScience</em>, <b>36</b>, 305-309.</li>\n<li>Jeffrey, R. 1987. \"Alias Smith and Jones: The Testimony of the\nSenses\", <em>Erkenntnis</em> <b>26</b>, 391-399.</li>\n<li>----- 1992. <em>Probability and the Art of Judgment</em>. New\nYork: Cambridge University Press.</li>\n<li>Joyce, J. M. 1999. <em>The Foundations of Causal Decision\nTheory</em>. New York: Cambridge University Press.</li>\n<li>Kahneman, D. and Tversky, A. 1973. \"On the psychology of\nprediction\", <em>Psychological Review</em> <b>80</b>, 237-251.</li>\n<li>Kaplan, M. 1996. <em>Decision Theory as\nPhilosophy</em>. Cambridge: Cambridge University Press.</li>\n<li>Levi, I. 1985. \"Imprecision and Indeterminacy in Probability\nJudgment\", <em>Philosophy of Science</em> <b>53</b>, 390-409.</li>\n<li>Maher, P. 1996. \"Subjective and Objective Confirmation\",\n<em>Philosophy of Science</em> <b>63</b>, 149-174.</li>\n<li>McGee, V. 1994. \"Learning the Impossible,\" in E. Eells and\nB. Skyrms, eds., <em>Probability and Conditionals</em>. New York:\nCambridge University Press, 179-200.</li>\n<li>Mortimer, Halina. 1988. <em>The logic of induction</em>, Ellis Horwood \nSeries in Artificial Intelligence, New York; Halsted Press.</li>\n<li>Nozick, R. 1981. <em>Philosophical Explanations</em>. Cambridge:\nHarvard University Press.\n</li>\n<li>Renyi, A. 1955. \"On a New Axiomatic Theory of Probability\",\n<em>Acta Mathematica Academiae Scientiarium Hungaricae</em> <b>6</b>,\n285-335.</li>\n<li>Royall, R. 1997. <em>Statistical Evidence: A Likelihood\nParadigm</em>. New York: Chapman &amp; Hall/CRC.</li>\n<li>Skyrms, B. 1987. \"Dynamic Coherence and Probability\nKinematics\". <em>Philosophy of Science</em> <b>54</b>, 1-20.\n</li>\n<li>Sober, E. 2002. \"Bayesianism \u2014 its Scope and Limits\", in\nSwinburne (2002), 21-38.</li>\n<li>Sphon, W. 1986. \"The Representation of Popper Measures\",\n<em>Topoi</em> <b>5</b>, 69-74.</li>\n<li>Stigler, S. M. 1982. \"Thomas Bayes' Bayesian Inference\",\n<em>Journal of the Royal Statistical Society, series A</em>\n<b>145</b>, 250-258.</li>\n<li>Swinburne, R. 2002. <em>Bayes' Theorem</em>. Oxford: Oxford\nUniversity Press (published for the British Academy).</li>\n<li>Talbot, W. 2001. \"Bayesian Epistemology\",\n <em>Stanford Encyclopedia of Philosophy</em> (Fall\n2001 Edition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/fall2001/entries/epistemology-bayesian/\">https://plato.stanford.edu/archives/fall2001/entries/epistemology-bayesian/</a>&gt;</li>\n<li>Teller, P. 1976. \"Conditionalization, Observation, and Change of\nPreference\", in W. Harper and C.A. Hooker, eds., <em>Foundations of\nProbability Theory, Statistical Inference, and Statistical Theories of\nScience</em>. Dordrecht: D. Reidel.\n</li>\n<li>Williamson, T. 2000. <em>Knowledge and its Limits</em>. Oxford:\nOxford University Press.</li>\n<li>Van Fraassen, B.  1999. \"A New Argument for\nConditionalization\". <em>Topoi</em> <b>18</b>, 93-96.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "epistemology: Bayesian",
            "probability, interpretations of"
        ],
        "entry_link": [
            {
                "../epistemology-bayesian/": "epistemology: Bayesian"
            },
            {
                "../probability-interpret/": "probability, interpretations of"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<td valign=\"top\"><img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=bayes-theorem\" target=\"other\">How to cite this entry</a>.",
            "<td valign=\"top\"><img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/bayes-theorem/\" target=\"other\">Preview the PDF version of this entry</a> at the <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<td valign=\"top\"><img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=bayes-theorem&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<td valign=\"top\"><img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"http://philpapers.org/sep/bayes-theorem/\" target=\"other\">Enhanced bibliography for this entry</a> at <a href=\"http://philpapers.org\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=bayes-theorem": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/bayes-theorem/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=bayes-theorem&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "http://philpapers.org/sep/bayes-theorem/": "Enhanced bibliography for this entry"
            },
            {
                "http://philpapers.org": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "Fitelson, B. 2001. <em>Studies in Bayesian Confirmation\nTheory</em>, Ph.D. Dissertation, University of Wisconsin.  \n[<a href=\"http://fitelson.org/thesis.pdf\" target=\"other\">Preprint in PDF available online</a>] (750K download)",
            "<a href=\"http://www-groups.dcs.st-andrews.ac.uk/%7Ehistory/Mathematicians/Bayes.html\" target=\"other\">A Short Biography of Thomas Bayes</a>\n (University of St. Andrews, MacTutor History of Mathematics Archive)",
            "<a href=\"http://www.bayesian.org/\" target=\"other\">The International Society for Bayesian Analysis (ISBA)</a>"
        ],
        "listed_links": [
            {
                "http://fitelson.org/thesis.pdf": "Preprint in PDF available online"
            },
            {
                "http://www-groups.dcs.st-andrews.ac.uk/%7Ehistory/Mathematicians/Bayes.html": "A Short Biography of Thomas Bayes"
            },
            {
                "http://www.bayesian.org/": "The International Society for Bayesian Analysis (ISBA)"
            }
        ]
    }
}