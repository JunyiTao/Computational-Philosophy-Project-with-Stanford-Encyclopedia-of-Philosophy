{
    "url": "modularity-mind",
    "title": "Modularity of Mind",
    "authorship": {
        "year": "Copyright \u00a9 2017",
        "author_text": "Philip Robbins\n<robbinsp@missouri.edu>",
        "author_links": [
            {
                "http://philosophy.missouri.edu/index.php/people/15-/40-philip-robbins": "Philip Robbins"
            },
            {
                "mailto:robbinsp%40missouri%2eedu": "robbinsp@missouri.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2017</a> by\n\n<br/>\n<a href=\"http://philosophy.missouri.edu/index.php/people/15-/40-philip-robbins\" target=\"other\">Philip Robbins</a>\n&lt;<a href=\"mailto:robbinsp%40missouri%2eedu\"><em>robbinsp<abbr title=\" at \">@</abbr>missouri<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Wed Apr 1, 2009",
        "substantive revision Mon Aug 21, 2017"
    ],
    "preamble": "\n\nThe concept of modularity has loomed large in philosophy of psychology\nsince the early 1980s, following the publication of Fodor\u2019s\nlandmark book The Modularity of Mind (1983). In the decades\nsince the term \u2018module\u2019 and its cognates first entered the\nlexicon of cognitive science, the conceptual and theoretical landscape\nin this area has changed dramatically. Especially noteworthy in this\nrespect has been the development of evolutionary psychology, whose\nproponents adopt a less stringent conception of modularity than the\none advanced by Fodor, and who argue that the architecture of the mind\nis more pervasively modular than Fodor claimed. Where Fodor (1983,\n2000) draws the line of modularity at the relatively low-level systems\nunderlying perception and language, post-Fodorian theorists such as\nSperber (2002) and Carruthers (2006) contend that the mind is modular\nthrough and through, up to and including the high-level systems\nresponsible for reasoning, planning, decision making, and the like.\nThe concept of modularity has also figured in recent debates in\nphilosophy of science, epistemology, ethics, and philosophy of\nlanguage\u2014further evidence of its utility as a tool for\ntheorizing about mental architecture.\n",
    "toc": [
        {
            "#WhatMentModu": "1. What is a mental module?"
        },
        {
            "#ModuFodoStylModeProp": "2. Modularity, Fodor-style: A modest proposal"
        },
        {
            "#ChalLowLeveModu": "2.1. Challenges to low-level modularity"
        },
        {
            "#FodoArguAgaiHighLeveModu": "2.2. Fodor\u2019s argument against high-level modularity"
        },
        {
            "#PostFodoModu": "3. Post-Fodorian modularity"
        },
        {
            "#CaseForMassModu": "3.1. The case for massive modularity"
        },
        {
            "#DoubAbouMassModu": "3.2. Doubts about massive modularity"
        },
        {
            "#ModuPhil": "4. Modularity and philosophy"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. What is a mental module?\n\nIn his classic introduction to modularity, Fodor (1983) lists nine\nfeatures that collectively characterize the type of system that\ninterests him. In original order of presentation, they are: \n\nDomain specificity\nMandatory operation\nLimited central accessibility\nFast processing\nInformational encapsulation\n\u2018Shallow\u2019 outputs\nFixed neural architecture\nCharacteristic and specific breakdown patterns\nCharacteristic ontogenetic pace and sequencing\n\n\nA cognitive system counts as modular in Fodor\u2019s sense if it is\nmodular \u201cto some interesting extent,\u201d meaning that it has\nmost of these features to an appreciable degree (Fodor, 1983, p. 37).\nThis is a weighted most, since some marks of modularity are more\nimportant than others. Information encapsulation, for example, is more\nor less essential for modularity, as well as explanatorily prior to\nseveral of the other features on the list (Fodor, 1983, 2000). \n\nEach of the items on the list calls for explication. To streamline the\nexposition, we will cluster most of the features thematically and\nexamine them on a cluster-by-cluster basis, along the lines of Prinz\n(2006).\n\nEncapsulation and inaccessibility. Informational\nencapsulation and limited central accessibility are two sides of the\nsame coin. Both features pertain to the character of information flow\nacross computational mechanisms, albeit in opposite directions.\nEncapsulation involves restriction on the flow of information into a\nmechanism, whereas inaccessibility involves restriction on the flow of\ninformation out of it.\n\nA cognitive system is informationally encapsulated to the extent that\nin the course of processing a given set of inputs it cannot access\ninformation stored elsewhere; all it has to go on is the information\ncontained in those inputs plus whatever information might be stored\nwithin the system itself, for example, in a proprietary database. In\nthe case of language, for example:\n\nA parser for [a language] L contains a grammar of L.\nWhat it does when it does its thing is, it infers from certain\nacoustic properties of a token to a characterization of certain of the\ndistal causes of the token (e.g., to the speaker\u2019s intention\nthat the utterance should be a token of a certain linguistic type).\nPremises of this inference can include whatever information about the\nacoustics of the token the mechanisms of sensory transduction provide,\nwhatever information about the linguistic types in L the\ninternally represented grammar provides, and nothing else.\n(Fodor, 1984, pp. 245\u2013246; italics in original)\n\n\nSimilarly, in the case of perception\u2014understood as a kind of\nnon-demonstrative (i.e., defeasible, or non-monotonic) inference from\nsensory \u2018premises\u2019 to perceptual\n\u2018conclusions\u2019\u2014the claim that perceptual systems are\ninformationally encapsulated is equivalent to the claim that\n\u201cthe data that can bear on the confirmation of perceptual\nhypotheses includes, in the general case, considerably less than the\norganism may know\u201d (Fodor, 1983, p. 69). The classic\nillustration of this property comes from the study of visual\nillusions, which tend to persist even after the viewer is explicitly\ninformed about the character of the stimulus. In the M\u00fcller-Lyer\nillusion, for example, the two lines continue to look as if they were\nof unequal length even after one has convinced oneself otherwise,\ne.g., by measuring them with a ruler (see Figure 1, below). \n\n\nFigure 1. The M\u00fcller-Lyer illusion.\n\n\nInformational encapsulation is related to what Pylyshyn (1984, 1999)\ncalls cognitive impenetrability. But the two properties are not the\nsame; instead, they are related as genus to species. Cognitive\nimpenetrability is a matter of encapsulation relative to information\nstored in central memory, paradigmatically in the form of beliefs and\nutilities. But a system could be encapsulated in this respect without\nbeing encapsulated across the board. For example, auditory speech\nperception might be encapsulated relative to beliefs and utilities but\nunencapsulated relative to vision, as suggested by the McGurk effect\n(see below, \u00a72.1). Likewise, a system could be unencapsulated\nrelative to beliefs and utilities yet encapsulated relative to\nperception; it\u2019s plausible that central systems have this\ncharacter, insofar as their operations are sensitive only to\npost-perceptual, propositionally encoded information. Strictly\nspeaking, then, cognitive impenetrability is a specific type of\ninformational encapsulation, albeit a type with special architectural\nsignificance. Lacking this feature means failing the encapsulation\ntest, the litmus test of modularity. But systems with this feature\nmight still fail the test, due to information seepage of a different\n(i.e., non-central) sort.\n\nThe flip side of informational encapsulation is inaccessibility to\ncentral monitoring. A system is inaccessible in this sense if the\nintermediate-level representations that it computes prior to producing\nits output are inaccessible to consciousness, and hence unavailable\nfor explicit report. In effect, centrally inaccessible systems are\nthose whose internal processing is opaque to introspection. Though the\noutputs of such systems may be phenomenologically salient, their\nprecursor states are not. Speech comprehension, for example, likely\ninvolves the successive elaboration of myriad representations (of\nvarious types: phonological, lexical, syntactic, etc.) of the\nstimulus, but of these only the final product\u2014the representation\nof the meaning of what was said\u2014is consciously available.\n\nMandatoriness, speed, and superficiality. In addition to\nbeing informationally encapsulated and centrally inaccessible, modular\nsystems and processes are \u201cfast, cheap, and out of\ncontrol\u201d (to borrow a phrase by roboticist Rodney Brooks). These\nfeatures form a natural trio, as we\u2019ll see.\n\nThe operation of a cognitive system is mandatory just in case it is\nautomatic, that is, not under conscious control (Bargh &\nChartrand, 1999). This means that, like it or not, the system\u2019s\noperations are switched on by presentation of the relevant stimuli and\nthose operations run to completion. For example, native speakers of\nEnglish cannot hear the sounds of English being spoken as mere noise:\nif they hear those sounds at all, they hear them as English. Likewise,\nit\u2019s impossible to see a 3D array of objects in space as 2D\npatches of color, however hard one may try.\n\nSpeed is arguably the mark of modularity that requires least in the\nway of explication. But speed is relative, so the best way to proceed\nhere is by way of examples. Speech shadowing is generally considered\nto be very fast, with typical lag times on the order of about 250 ms.\nSince the syllabic rate of normal speech is about 4 syllables per\nsecond, this suggests that shadowers are processing the stimulus in\nsyllabus-length bits\u2014probably the smallest bits that can be\nidentified in the speech stream, given that \u201conly at the level\nof the syllable do we begin to find stretches of wave form whose\nacoustic properties are at all reliably related to their linguistic\nvalues\u201d (Fodor, 1983, p. 62). Similarly impressive results are\navailable for vision: in a rapid serial visual presentation task\n(matching picture to description), subjects were 70% accurate at 125\nms. exposure per picture and 96% accurate at 167 ms. (Fodor, 1983, p.\n63). In general, a cognitive process counts as fast in Fodor\u2019s\nbook if it takes place in a half second or less.\n\nA further feature of modular systems is that their outputs are\nrelatively \u2018shallow\u2019. Exactly what this means is unclear.\nBut the depth of an output seems to be a function of at least two\nproperties: first, how much computation is required to produce it\n(i.e., shallow means computationally cheap); second, how constrained\nor specific its informational content is (i.e., shallow means\ninformationally general) (Fodor, 1983, p. 87). These two properties\nare correlated, in that outputs with more specific content tend to be\nmore costly for a system to compute, and vice versa. Some writers have\ninterpreted shallowness to require non-conceptual character (e.g.,\nCarruthers, 2006, p. 4). But this conflicts with Fodor\u2019s own\ngloss on the term, in which he suggests that the output of a plausibly\nmodular system such as visual object recognition might be encoded at\nthe level of \u2018basic-level\u2019 concepts, like DOG and CHAIR\n(Rosch et al., 1976). What\u2019s ruled out here is not concepts\nper se, then, but highly theoretical concepts like PROTON,\nwhich are too informationally specific and too computationally\nexpensive to meet the shallowness criterion.\n\nAll three of the features just discussed\u2014mandatoriness, speed,\nand shallowness\u2014are associated with, and to some extent\nexplicable in terms of, informational encapsulation. In each case,\nless is more, informationally speaking. Mandatoriness flows from the\ninsensitivity of the system to the organism\u2019s utilities, which\nis one dimension of cognitive impenetrability. Speed depends upon the\nefficiency of processing, which positively correlates with\nencapsulation in so far as encapsulation tends to reduce the\nsystem\u2019s informational load. Shallowness is a similar story:\nshallow outputs are computationally cheap, and computational expense\nis negatively correlated with encapsulation. In short, the more\ninformationally encapsulated a system is, the more likely it is to be\nfast, cheap, and out of control.\n\nDissociability and localizability. To say that a system is\nfunctionally dissociable is to say that it can be selectively\nimpaired, that is, damaged or disabled with little or no effect on the\noperation of other systems. As the neuropsychological record\nindicates, selective impairments of this sort have frequently been\nobserved as a consequence of circumscribed brain lesions. Standard\nexamples from the study of vision include prosopagnosia (impaired face\nrecognition), achromatopsia (total color blindness), and akinetopsia\n(motion blindness); examples from the study of language include\nagrammatism (loss of complex syntax), jargon aphasia (loss of complex\nsemantics), alexia (loss of object words), and dyslexia (impaired\nreading and writing). Each of these disorders have been found in\notherwise cognitively normal individuals, suggesting that the lost\ncapacities are subserved by functionally dissociable mechanisms.\n\nFunctional dissociability is associated with neural localizability in\na strong sense. A system is strongly localized just in case it is (a)\nimplemented in neural circuitry that is both relatively circumscribed\nin extent (though not necessarily in contiguous areas) and (b)\ndedicated to the realization of that system alone. Localization in\nthis sense goes beyond mere implementation in local neural circuitry,\nsince a given bit of circuitry could subserve more than one cognitive\nfunction (Anderson, 2010). Proposed candidates for strong localization\ninclude systems for color vision (V4), motion detection (MT), face\nrecognition (fusiform gyrus), and spatial scene recognition\n(parahippocampal gyrus).\n\nDomain specificity. A system is domain specific to the extent\nthat it has a restricted subject matter, that is, the class of objects\nand properties that it processes information about is circumscribed in\na relatively narrow way. As Fodor (1983) puts it, \u201cdomain\nspecificity has to do with the range of questions for which a device\nprovides answers (the range of inputs for which it computes\nanalyses)\u201d (p. 103): the narrower the range of inputs a system\ncan compute, the narrower the range of problems the system can\nsolve\u2014and the narrower the range of such problems, the more\ndomain specific the device. Alternatively, the degree of a\nsystem\u2019s domain specificity can be understood as a function of\nthe range of inputs that turn the system on, where the size of that\nrange determines the informational reach of the system (Carruthers,\n2006; Samuels, 2000).\n\nDomains (and by extension, modules) are typically more fine-grained\nthan sensory modalities like vision and audition. This seems clear\nfrom Fodor\u2019s list of plausibly domain-specific mechanisms, which\nincludes systems for color perception, visual shape analysis, sentence\nparsing, and face and voice recognition (Fodor, 1983, p.\n47)\u2014none of which correspond to perceptual or linguistic\nfaculties in an intuitive sense. It also seems plausible, however,\nthat the traditional sense modalities (vision, audition, olfaction,\netc.), and the language faculty as a whole, are sufficiently domain\nspecific to count as displaying this particular mark of modularity\n(McCauley & Henrich, 2006).\n\nInnateness. The final feature of modular systems on\nFodor\u2019s roster is innateness, understood as the property of\n\u201cdevelop[ing] according to specific, endogenously determined\npatterns under the impact of environmental releasers\u201d (Fodor,\n1983, p. 100). On this view, modular systems come on-line chiefly as\nthe result of a brute-causal process like triggering, rather than an\nintentional-causal process like learning. (For more on this\ndistinction, see Cowie, 1999; for an alternative analysis of\ninnateness, based on the notion of canalization, see Ariew, 1999.) The\nmost familiar example here is language, the acquisition of which\noccurs in all normal individuals in all cultures on more or less the\nsame schedule: single words at 12 months, telegraphic speech at 18\nmonths, complex grammar at 24 months, and so on (Stromswold, 1999).\nOther candidates include visual object perception (Spelke, 1994) and\nlow-level mindreading (Scholl & Leslie, 1999).\n2. Modularity, Fodor-style: A modest proposal\n\nThe hypothesis of modest modularity, as we shall call it, has two\nstrands. The first strand of the hypothesis is positive. It says that\ninput systems, such as systems involved in perception and language,\nare modular. The second strand is negative. It says that central\nsystems, such as systems involved in belief fixation and practical\nreasoning, are not modular. \n\nIn this section, we assess the case for modest modularity. The next\nsection (\u00a73) will be devoted to discussion of the hypothesis of\nmassive modularity, which retains the positive strand of Fodor\u2019s\nhypothesis while reversing the polarity of the second strand from\nnegative to positive\u2014revising the concept of modularity in the\nprocess.\n\nThe positive part of the modest modularity hypothesis is that input\nsystems are modular. By \u2018input system\u2019 Fodor (1983) means\na computational mechanism that \u201cpresents the world to\nthought\u201d (p. 40) by processing the outputs of sensory\ntransducers. A sensory transducer is a device that converts the energy\nimpinging on the body\u2019s sensory surfaces, such as the retina and\ncochlea, into a computationally usable form, without adding or\nsubtracting information. Roughly speaking, the product of sensory\ntransduction is raw sensory data. Input processing involves\nnon-demonstrative inferences from this raw data to hypotheses about\nthe layout of objects in the world. These hypotheses are then passed\non to central systems for the purpose of belief fixation, and those\nsystems in turn pass their outputs to systems responsible for the\nproduction of behavior.\n\nFodor argues that input systems constitute a natural kind, defined as\n\u201ca class of phenomena that have many scientifically interesting\nproperties over and above whatever properties define the class\u201d\n(Fodor, 1983, p. 46). He argues for this by presenting evidence that\ninput systems are modular, where modularity is marked by a cluster of\npsychologically interesting properties\u2014the most interesting and\nimportant of these being informational encapsulation, as discussed in\n\u00a71. In the course of that discussion, we reviewed a\nrepresentative sample of this evidence, and for present purposes that\nshould suffice. (Readers interested in further details should consult\nFodor, 1983, pp. 47\u2013101.)\n2.1. Challenges to low-level modularity\n\nFodor\u2019s claim about the modularity of input systems has been\ndisputed by a number of philosophers and psychologists (Churchland,\n1988; Arbib, 1987; Marslen-Wilson & Tyler, 1987; McCauley &\nHenrich, 2006). The most wide-ranging philosophical critique is due to\nPrinz (2006), who argues that perceptual and linguistic systems rarely\nexhibit the features characteristic of modularity. In particular, he\nargues that such systems are not informationally encapsulated. To this\nend, Prinz adduces two types of evidence. First, there appear to be\ncross-modal effects in perception, which would tell against\nencapsulation at the level of input systems. The classic example of\nthis, also from the speech perception literature, is the McGurk effect\n(McGurk & MacDonald, 1976). Here, subjects watching a video of one\nphoneme being spoken (e.g., /ga/) dubbed with a sound recording of a\ndifferent phoneme (/ba/) hear a third, altogether different phoneme\n(/da/). Second, he points to what look to be top-down effects on\nvisual and linguistic processing, the existence of which would tell\nagainst cognitive impenetrability, i.e., encapsulation relative to\ncentral systems. Some of the most striking examples of such effects\ncome from research on speech perception. Probably the best-known is\nthe phoneme restoration effect, as in the case where listeners\n\u2018fill in\u2019 a missing phoneme in a spoken sentence (The\nstate governors met with their respective legi*latures convening in\nthe capital city) from which the missing phoneme (the /s/ sound\nin legislatures) has been deleted and replaced with the sound\nof a cough (Warren, 1970). By hypothesis, this filling-in is driven by\nlisteners\u2019 understanding of the linguistic context. \n\nHow convincing one finds this part of Prinz\u2019s critique, however,\ndepends on how convincing one finds his explanation of these effects.\nThe McGurk effect, for example, seems consistent with the claim that\nspeech perception is an informationally encapsulated system, albeit a\nsystem that is multi-modal in character (cf. Fodor, 1983, p.132n.13).\nIf speech perception is a multi-modal system, the fact that its\noperations draw on both auditory and visual information need not\nundermine the claim that speech perception is encapsulated. Other\ncross-modal effects, however, resist this type of explanation. In the\ndouble flash illusion, for example, viewers shown a single flash\naccompanied by two beeps report seeing two flashes (Shams et al.,\n2000). The same goes for the rubber hand illusion, in which\nsynchronous brushing of a hand hidden from view and a\nrealistic-looking rubber hand seen at the usual location of the hand\nthat was hidden gives rise to the impression that the fake hand is\nreal (Botvinick & Cohen, 1998). With respect to phenomena of this\nsort, unlike the McGurk effect, there is no plausible candidate for a\nsingle, domain-specific system whose operations draw on multiple\nsources of sensory information.\n\nRegarding phoneme restoration, it could be that the effect is driven\nby listeners\u2019 drawing on information stored in a\nlanguage-proprietary database (specifically, information about the\nlinguistic types in the lexicon of English), rather than higher-level\ncontextual information. Hence, it\u2019s unclear whether the case of\nphoneme restoration described above counts as a top-down effect. But\nnot all cases of phoneme restoration can be accommodated so readily,\nsince the phenomenon also occurs when there are multiple lexical items\navailable for filling in (Warren & Warren, 1970). For example,\nlisteners fill the gap in the sentences The *eel is on the\naxle and The *eel is on the orange\ndifferently\u2014with a /wh/ sound and a /p/ sound,\nrespectively\u2014suggesting that speech perception is sensitive to\ncontextual information after all.\n\nA further challenge to modest modularity, not addressed by Prinz\n(2006), comes from evidence that susceptibility to the\nM\u00fcller-Lyer illusion varies by both culture and age. For example,\nit appears that adults in Western cultures are more susceptible to the\nillusion than their non-Western counterparts; that adults in some\nnon-Western cultures, such as hunter-gatherers from the Kalahari\nDesert, are nearly immune to the illusion; and that within (but not\nalways across) Western and non-Western cultures, pre-adolescent\nchildren are more susceptible to the illusion than adults are (Segall,\nCampbell, & Herskovits, 1966). McCawley and Henrich (2006) take\nthese findings as showing that the visual system is diachronically (as\nopposed to synchronically) penetrable, in that how one experiences the\nillusion-inducing stimulus changes as a result of one\u2019s wider\nperceptual experience over an extended period of time. They also argue\nthat the aforementioned evidence of cultural and developmental\nvariability in perception militates against the idea that vision is an\ninnate capacity, that is, the idea that vision is among the\n\u201cendogenous features of the human cognitive system that are, if\nnot largely fixed at birth, then, at least, genetically\npre-programmed\u201d and \u201ctriggered, rather than shaped, by the\nnewborn\u2019s subsequent experience\u201d (p. 83). However, they\nalso issue the following caveat:\n\n[N]othing about any of the findings we have discussed establishes the\nsynchronic cognitive penetrability of the M\u00fcller-Lyer\nstimuli. Nor do the Segall et al. (1966) findings provide evidence\nthat adults\u2019 visual input systems are\ndiachronically penetrable. They suggest that it is only\nduring a critical developmental stage that human beings\u2019\nsusceptibility to the M\u00fcller-Lyer illusion varies considerably\nand that that variation substantially depends on cultural\nvariables. (McCauley & Henrich, 2006, p. 99; italics in original)\n\n\nAs such, the evidence cited can be accommodated by friends of modest\nmodularity, provided that allowance is made for the potential impact\nof environmental, including cultural, variables on\ndevelopment\u2014something that most accounts of innateness make room\nfor.\n\nA useful way of making this point invokes Segal\u2019s (1996) idea of\ndiachronic modularity (see also Scholl & Leslie, 1999). Diachronic\nmodules are systems that exhibit parametric variation over the course\nof their development. For example, in the case of language, different\nindividuals learn to speak different languages depending on the\nlinguistic environment in which they grew up, but they nonetheless\nshare the same underlying linguistic competence in virtue of their\n(plausibly innate) knowledge of Universal Grammar. Given the observed\nvariation in how people see the M\u00fcller-Lyer illusion, it may be\nthat the visual system is modular in much the same way, with its\ndevelopment is constrained by features of the visual environment. Such\na possibility seems consistent with the claim that input systems are\nmodular in Fodor\u2019s sense.\n\nAnother source of difficulty for proponents of input-level modularity\nis neuroscientific evidence against the claim that perceptual and\nlinguistic systems are strongly localized. Recall that for a system to\nbe strongly localized, it must be realized in dedicated neural\ncircuitry. Strong localization at the level of input systems, then,\nentails the existence of a one-to-one mapping between input systems\nand brain structures. As Anderson (2010, 2014) argues, however, there\nis no such mapping, since most cortical regions of any size are\ndeployed in different tasks across different domains. For instance,\nactivation of the fusiform face area, once thought to be dedicated to\nthe perception of faces, is also recruited for the perception of cars\nand birds (Gauthier et al., 2000). Likewise, Broca\u2019s area, once\nthought to be dedicated to speech production, also plays a role in\naction recognition, action sequencing, and motor imagery (Tettamanti\n& Weniger, 2006). Functional neuroimaging studies generally\nsuggest that cognitive systems are at best weakly localized, that is,\nimplemented in distributed networks of the brain that overlap, rather\nthan discrete and disjoint regions.\n\nArguably the most serious challenge to modularity at the level of\ninput systems, however, comes from evidence that vision is cognitively\npenetrable, and hence, not informationally encapsulated. The concept\nof cognitive penetrability, originally introduced by Pylyshyn (1984),\nhas been characterized in a variety of non-equivalent ways (Stokes,\n2013), but the core idea is this: A perceptual system is cognitively\npenetrable if and only if its operations are directly causally\nsensitive to the agent\u2019s beliefs, desires, intentions, or other\nnonperceptual states. Behavioral studies purporting to show that\nvision is cognitively penetrable date back to the early days of New\nLook psychology (Bruner and Goodman, 1947) and continue to the present\nday, with renewed interest in the topic emerging in the early 2000s\n(Firestone & Scholl, 2016). It appears, for example, that vision\nis influenced by an agent\u2019s motivational states, with\nexperimental subjects reporting that desirable objects look closer\n(Balcetis & Dunning, 2010) and ambiguous figures look like the\ninterpretation associated with a more rewarding outcome (Balcetis\n& Dunning, 2006). In addition, vision seems to be influenced by\nsubjects\u2019 beliefs, with racial categorization affecting reports\nof the perceived skin tone of faces even when the stimuli are\nequiluminant (Levin & Banaji, 2006), and categorization of objects\naffecting reports of the perceived color of grayscale images of those\nobjects (Hansen et al., 2006). \n\nSkeptics of cognitive penetrability point out, however, that\nexperimental evidence for top-down effects on perception can be\nexplained in terms of effects of judgment, memory, and relatively\nperipheral forms of attention (Firestone & Scholl, 2016; Machery,\n2015). Consider, for example, the claim that throwing a heavy ball\n(vs. a light ball) at a target makes the target look farther away,\nevidence for which consists of subjects\u2019 visual estimates of the\ndistance to the target (Witt, Proffitt, & Epstein, 2004). While it\nis possible that the greater effort involved in throwing the heavy\nball caused the target to look farther away, it is also possible that\nthe increased estimate of distance reflected the fact that subjects in\nthe heavy ball condition judged the target to be farther away because\nthey found it harder to hit (Firestone & Scholl, 2016). Indeed,\nreports by subjects in a follow-up study who were explicitly\ninstructed to make their estimates on the basis of visual appearances\nonly did not show the effect of effort, suggesting that the effect was\npost-perceptual (Woods, Philbeck, & Danoff, 2009). Other purported\ntop-down effects on perception, such as the effect of golfing\nperformance on size and distance estimates of golf holes (Witt et al.,\n2008), can be explained as effects of spatial attention, such as the\nfact that visually attended objects tend to appear larger and closer\n(Firestone & Scholl, 2016). These and related considerations\nsuggest that the case for cognitive penetrability\u2014and by\nextension, the case against low-level modularity\u2014is weaker than\nits proponents make it out to be. \n2.2. Fodor\u2019s argument against high-level modularity\n\nI turn now to the dark side of Fodor\u2019s hypothesis: the claim\nthat central systems are not modular.\n\nAmong the principal jobs of central systems is the fixation of belief,\nperceptual belief included, via non-demonstrative inference. Fodor\n(1983) argues that this sort of process cannot be realized in an\ninformationally encapsulated system, and hence that central systems\ncannot be modular. Spelled out a bit further, his reasoning goes like\nthis:\n\nCentral systems are responsible for belief fixation.\nBelief fixation is isotropic and Quinean.\nIsotropic and Quinean processes cannot be carried out by\ninformationally encapsulated systems.\nBelief fixation cannot be carried out by an informationally\nencapsulated system. [from 2 and 3]\nModular systems are informationally\nencapsulated.\nBelief fixation is not modular. [from 4 and 5]\n\nHence:\n\nCentral systems are not modular. [from 1 and 6]\n\n\nThe argument here contains two terms that call for explication, both\nof which relate to the notion of confirmation holism in the philosophy\nof science. The term \u2018isotropic\u2019 refers to the epistemic\ninterconnectedness of beliefs in the sense that \u201ceverything that\nthe scientist knows is, in principle, relevant to determining what\nelse he ought to believe. In principle, our botany constrains our\nastronomy, if only we could think of ways to make them connect\u201d\n(Fodor, 1983, p. 105). Antony (2003) presents a striking case of this\nsort of long-range interdisciplinary cross-talk in the sciences,\nbetween astronomy and archaeology; Carruthers (2006, pp.\n356\u2013357) furnishes another example, linking solar physics and\nevolutionary theory. On Fodor\u2019s view, since scientific\nconfirmation is akin to belief fixation, the fact that scientific\nconfirmation is isotropic suggests that belief fixation in general has\nthis property. \n\nA second dimension of confirmation holism is that confirmation is\n\u2018Quinean\u2019, meaning that:\n\n[T]he degree of confirmation assigned to any given hypothesis is\nsensitive to properties of the entire belief system \u2026\nsimplicity, plausibility, and conservatism are properties that\ntheories have in virtue of their relation to the whole structure of\nscientific beliefs taken collectively. A measure of\nconservatism or simplicity would be a metric over global\nproperties of belief systems. (Fodor, 1983, pp. 107\u2013108; italics\nin original).\n\n\nHere again, the analogy between scientific thinking and thinking in\ngeneral underwrites the supposition that belief fixation is Quinean.\n\n\nBoth isotropy and Quineanness are features that preclude\nencapsulation, since their possession by a system would require\nextensive access to the contents of central memory, and hence a high\ndegree of cognitive penetrability. Put in slightly different terms:\nisotropic and Quinean processes are \u2018global\u2019 rather than\n\u2018local\u2019, and since globality precludes encapsulation,\nisotropy and Quineanness preclude encapsulation as well. \n\nBy Fodor\u2019s lights, the upshot of this argument\u2014namely, the\nnonmodular character of central systems\u2014is bad news for the\nscientific study of higher cognitive functions. This is neatly\nexpressed by his \u201cFirst Law of the Non-Existence of Cognitive\nScience,\u201d according to which \u201c[t]he more global (e.g., the\nmore isotropic) a cognitive process is, the less anybody understands\nit\u201d (Fodor, 1983, p. 107). His grounds for pessimism on this\nscore are twofold. First, global systems are unlikely to be associated\nwith local brain architecture, thereby rendering them unpromising\nobjects of neuroscientific study:\n\nWe have seen that isotropic systems are unlikely to exhibit\narticulated neuroarchitecture. If, as seems plausible,\nneuroarchitecture is often a concomitant of constraints on information\nflow, then neural equipotentiality is what you would expect in systems\nin which every process has more or less uninhibited access to all the\navailable data. The moral is that, to the extent that the existence of\nform/function correspondence is a precondition for successful\nneuropsychological research, there is not much to be expected in the\nway of a neuropsychology of thought (Fodor, 1983, pp. 127).\n\n\nSecond, and more importantly, global processes are resistant to\ncomputational explanation, making them unpromising objects of\npsychological study:\n\nThe fact is that\u2014considerations of their neural realization to\none side\u2014global systems are per se bad domains for computational\nmodels, at least of the sort that cognitive scientists are accustomed\nto employ. The condition for successful science (in physics, by the\nway, as well as psychology) is that nature should have joints to carve\nit at: relatively simple subsystems which can be artificially isolated\nand which behave, in isolation, in something like the way that they\nbehave in situ. Modules satisfy this condition;\nQuinean/isotropic-wholistic-systems by definition do not. If, as I\nhave supposed, the central cognitive processes are nonmodular, that is\nvery bad news for cognitive science (Fodor, 1983, pp. 128).\n\n\nBy Fodor\u2019s lights, then, considerations that militate against\nhigh-level modularity also militate against the possibility of a\nrobust science of higher cognition\u2014not a happy result, as far as\nmost cognitive scientists and philosophers of mind are concerned.\n\nGloomy implications aside, Fodor\u2019s argument against high-level\nmodularity is difficult to resist. The main sticking points are these:\nfirst, the negative correlation between globality and encapsulation;\nsecond, the positive correlation between encapsulation and modularity.\nPutting these points together, we get a negative correlation between\nglobality and modularity: the more global the process, the less\nmodular the system that executes it. As such, there seem to be only\nthree ways to block the conclusion of the argument:\n\nDeny that central processes are global.\nDeny that globality and encapsulation are negatively\ncorrelated.\nDeny that encapsulation and modularity are positively\ncorrelated.\n\n\nOf these three options, the second seems least attractive, as it seems\nsomething like a conceptual truth that globality and encapsulation\npull in opposite directions. The first option is slightly more\nappealing, but only slightly. The idea that central processes are\nrelatively global, even if not as global as the process of\nconfirmation in science suggests, is hard to deny. And that is all the\nargument really requires. \n\nThat leaves the third option: denying that modularity requires\nencapsulation. This is, in effect, the strategy pursued by Carruthers\n(2006). More specifically, Carruthers draws a distinction between two\nkinds of encapsulation: \u2018narrow-scope\u2019 and\n\u2018wide-scope\u2019. A system is narrow-scope encapsulated if it\ncannot draw on any information held outside of it in the course\nof its processing. This corresponds to encapsulation as Fodor uses the\nterm. By contrast, a system that is wide-scope encapsulated can draw\non exogenous information during the course of its operations\u2014it\njust cannot draw on all of that information. (Compare:\n\u201cNo exogenous information is accessible\u201d vs. \u201cSome\nexogenous information is not accessible.\u201d) This is encapsulation\nin a weaker sense of the term than Fodor\u2019s. Indeed,\nCarruthers\u2019s use of the term \u2018encapsulation\u2019 in this\ncontext is a bit misleading, insofar as wide-scope encapsulated\nsystems count as unencapsulated in Fodor\u2019s sense (Prinz,\n2006).\n\nDropping the (narrow-scope) encapsulation requirement on modules\nraises a number of issues, not the least of which being that it\nreduces the power of modularity hypotheses to explain functional\ndissociations at the system level (Stokes & Bergeron, 2015). That\nsaid, if modularity requires only wide-scope encapsulation, then\nFodor\u2019s argument against central modularity no longer goes\nthrough. But given the importance of narrow-scope encapsulation to\nFodorian modularity, all this shows is that central systems might be\nmodular in a non-Fodorian way. The original argument that central\nsystems are not Fodor-modular\u2014and with it, the motivation for\nthe negative strand of the modest modularity\nhypothesis\u2014stands.\n3. Post-Fodorian modularity\n\nAccording to the massive modularity hypothesis, the mind is modular\nthrough and through, including the parts responsible for high-level\ncognition functions like belief fixation, problem-solving, planning,\nand the like. Originally articulated and advocated by proponents of\nevolutionary psychology (Sperber, 1994, 2002; Cosmides & Tooby,\n1992; Pinker, 1997; Barrett, 2005; Barrett & Kurzban, 2006), the\nhypothesis has received its most comprehensive and sophisticated\ndefense at the hands of Carruthers (2006). Before proceeding to the\ndetails of that defense, however, we need to consider briefly what\nconcept of modularity is in play. \n\nThe main thing to note here is that the operative notion of modularity\ndiffers significantly from the traditional Fodorian one. Carruthers is\nexplicit on this point:\n\n[If] a thesis of massive mental modularity is to be remotely\nplausible, then by \u2018module\u2019 we cannot mean\n\u2018Fodor-module\u2019. In particular, the properties of having\nproprietary transducers, shallow outputs, fast processing, significant\ninnateness or innate channeling, and encapsulation will very likely\nhave to be struck out. That leaves us with the idea that modules might\nbe isolable function-specific processing systems, all or almost all of\nwhich are domain specific (in the content sense), whose operations\naren\u2019t subject to the will, which are associated with specific\nneural structures (albeit sometimes spatially dispersed ones), and\nwhose internal operations may be inaccessible to the remainder of\ncognition. (Carruthers, 2006, p. 12)\n\n\nOf the original set of nine features associated with Fodor-modules,\nthen, Carruthers-modules retain at most only five: dissociability,\ndomain specificity, automaticity, neural localizability, and central\ninaccessibility. Conspicuously absent from the list is informational\nencapsulation, the feature most central to modularity in Fodor\u2019s\naccount. What\u2019s more, Carruthers goes on to drop domain\nspecificity, automaticity, and strong localizability (which rules out\nthe sharing of parts between modules) from his initial list of five\nfeatures, making his conception of modularity even more sparse\n(Carruthers, 2006, p. 62). Other proposals in the literature are\nsimilarly permissive in terms of the requirements a system must meet\nin order to count as modular (Coltheart, 1999; Barrett & Kurzban,\n2006). \n\nA second point, related to the first, is that defenders of massive\nmodularity have chiefly been concerned to defend the modularity of\ncentral cognition, taking for granted that the mind is modular at the\nlevel of input systems. Thus, the hypothesis at issue for theorists\nlike Carruthers might be best understood as the conjunction of two\nclaims: first, that input systems are modular in a way that requires\nnarrow-scope encapsulation; second, that central systems are modular,\nbut only in a way that does not require this feature. In defending\nmassive modularity, Carruthers focuses on the second of these claims,\nand so will we.\n3.1. The case for massive modularity\n\nThe centerpiece of Carruthers (2006) consists of three arguments for\nmassive modularity: the Argument from Design, the Argument from\nAnimals, and the Argument from Computational Tractability. Let\u2019s\nbriefly consider each of them in turn.\n\nThe Argument from Design is as follows:\n\nBiological systems are designed systems, constructed\nincrementally.\nSuch systems, when complex, need to be organized in a pervasively\nmodular way, that is, as a hierarchical assembly of separately\nmodifiable, functionally autonomous components.\nThe human mind is a biological system, and is complex.\nTherefore, the human mind is (probably) massively modular in its\norganization. (Carruthers, 2006, p. 25)\n\n\nThe crux of this argument is the idea that complex biological systems\ncannot evolve unless they are organized in a modular way, where\nmodular organization entails that each component of the system (that\nis, each module) can be selected for change independently of the\nothers. In other words, the evolvability of the system as a whole\nrequires the independent evolvability of its parts. The problem with\nthis assumption is twofold (Woodward & Cowie, 2004). First, not\nall biological traits are independently modifiable. Having two lungs,\nfor example, is a trait that cannot be changed without changing other\ntraits of an organism, because the genetic and developmental\nmechanisms underlying lung numerosity causally depend on the genetic\nand developmental mechanisms underlying bilateral symmetry. Second,\nthere appear to be developmental constraints on neurogenesis which\nrule out changing the size of one brain area independently of the\nothers. This in turn suggests that natural selection cannot modify\ncognitive traits in isolation from one another, given that evolving\nthe neural circuitry for one cognitive trait is likely to result in\nchanges to the neural circuitry for other traits. \n\nA further worry about the Argument from Design concerns the gap\nbetween its conclusion (the claim that the mind is massively modular\nin organization) and the hypothesis at issue (the claim that\nthe mind is massively modular simpliciter). The worry is this.\nAccording to Carruthers, the modularity of a system implies the\npossession of just two properties: functional dissociability and\ninaccessibility of processing to external monitoring. Suppose that a\nsystem is massively modular in organization. It follows from the\ndefinition of modular organization that the components of the system\nare functionally autonomous and separately modifiable. Though\nfunctional autonomy guarantees dissociability, it\u2019s not clear\nwhy separate modifiability guarantees inaccessibility to external\nmonitoring. According to Carruthers, the reason is that \u201cif the\ninternal operations of a system (e.g., the details of the algorithm\nbeing executed) were available elsewhere, then they couldn\u2019t be\naltered without some corresponding alteration being made in the system\nto which they are accessible\u201d (Carruthers, 2006, p. 61). But\nthis is a questionable assumption. On the contrary, it seems plausible\nthat the internal operations of one system could be accessible to a\nsecond system in virtue of a monitoring mechanism that functions the\nsame way regardless of the details of the processing being monitored.\nAt a minimum, the claim that separate modifiability entails\ninaccessibility to external monitoring calls for more justification than\nCarruthers offers. \n\nIn short, the Argument from Design is susceptible to a number of\nobjections. Fortunately, there\u2019s a slightly stronger argument in\nthe vicinity of this one, due to Cosmides and Tooby (1992). It goes\nlike this: \n\nThe human mind is a product of natural selection.\nIn order to survive and reproduce, our human ancestors had to\nsolve a number of recurrent adaptive problems (finding food, shelter,\nmates, etc.).\nSince adaptive problems are solved more quickly, efficiently, and\nreliably by modular systems than by non-modular ones, natural\nselection would have favored the evolution of a massively modular\narchitecture.\nTherefore, the human mind is (probably) massively modular.\n\n\nThe force of this argument depends chiefly on the strength of the\nthird premise. Not everyone is convinced, to put it mildly (Fodor,\n2000; Samuels, 2000; Woodward & Cowie, 2004). First, the premise\nexemplifies adaptationist reasoning, and adaptationism in the\nphilosophy of biology has more than its share of critics. Second, it\nis doubtful whether adaptive problem-solving in general is easier to\naccomplish with a large collection of specialized problem-solving\ndevices than with a smaller collection of general problem-solving\ndevices with access to a library of specialized programs (Samuels,\n2000). Hence, insofar as the massive modularity hypothesis postulates\nan architecture of the first sort\u2014as evolutionary\npsychologists\u2019 \u2018Swiss Army knife\u2019 metaphor of the\nmind implies (Cosmides & Tooby, 1992)\u2014the premise seems\nshaky. \n\nA related argument is the Argument from Animals. Unlike the Argument\nfrom Design, this argument is never explicitly stated in Carruthers\n(2006). But here is a plausible reconstruction of it, due to Wilson\n(2008):\n\nAnimal minds are massively modular.\nHuman minds are incremental extensions of animal minds.\nTherefore, the human mind is (probably) massively modular.\n\n\nUnfortunately for friends of massive modularity, this argument, like\nthe argument from design, is vulnerable to a number of objections\n(Wilson, 2008). We\u2019ll mention two of them here. First,\nit\u2019s not easy to motivate the claim that animal minds are\nmassively modular in the operative sense. Though\nCarruthers (2006) goes to heroic lengths to do so, the evidence he\ncites\u2014e.g., for the domain specificity of animal learning\nmechanisms, \u00e0 la Gallistel, 1990\u2014adds up to less than\nwhat\u2019s needed. The problem is that domain specificity is not sufficient for Carruthers-style modularity; indeed, it is not even one of the central characteristics of modularity in Carruthers\u2019 account. So the argument falters at the first step. Second, even if animal minds are\nmassively modular, and even if single incremental extensions of the\nanimal mind preserve that feature, it\u2019s quite possible that a\nseries of such extensions of animal minds might have led to its loss.\nIn other words, as Wilson (2008) puts it, it can\u2019t be assumed\nthat the conservation of massive modularity is transitive. And without\nthis assumption, the argument from animals can\u2019t go through.\n\nFinally, we have the Argument from Computational Tractability\n(Carruthers, 2006, pp. 44\u201359). For the purposes of this\nargument, we assume that a mental process is computationally tractable\nif it can be specified at the algorithmic level in such a way that the\nexecution of the process is feasible given time, energy, and other\nresource constraints on human cognition (Samuels, 2005). We also\nassume that a system is encapsulated if in the course of its\noperations the system lacks access to at least some information\nexogenous to it.\n\nThe mind is computationally realized.\nAll computational mental processes must be tractable.\nTractable processing is possible only in encapsulated systems.\n\nHence, the mind must consist entirely of encapsulated\nsystems.\nHence, the mind is (probably) massively modular.\n\n\nThere are two problems with this argument, however. The first problem\nhas to do with the third premise, which states that tractability\nrequires encapsulation, that is, the inaccessibility of at least some\nexogenous information to processing. What tractability actually\nrequires is something weaker, namely, that not all information is\naccessed by the mechanism in the course of its operations (Samuels,\n2005). In other words, it is possible for a system to have unlimited\naccess to a database without actually accessing all of its contents.\nThough tractable computation rules out exhaustive search, for example,\nunencapsulated mechanisms need not engage in exhaustive search, so\ntractability does not require encapsulation. The second problem with\nthe argument concerns the last step. Though one might reasonably\nsuppose that modular systems must be encapsulated, the converse\ndoesn\u2019t follow. Indeed, Carruthers (2006) makes no mention of\nencapsulation in his characterization of modularity, so it\u2019s\nunclear how one is supposed to get from a claim about pervasive\nencapsulation to a claim about pervasive modularity. \n\nAll in all, then, compelling general arguments for massive modularity\nare hard to come by. This is not yet to dismiss the possibility of\nmodularity in high-level cognition, but it invites skepticism,\nespecially given the paucity of empirical evidence directly supporting\nthe hypothesis (Robbins, 2013). For example, it has been suggested\nthat the capacity to think about social exchanges is subserved by a\ndomain-specific, functionally dissociable, and innate mechanism (Stone\net al., 2002; Sugiyama et al., 2002). However, it appears that\ndeficits in social exchange reasoning do not occur in isolation, but\nare accompanied by other social-cognitive impairments (Prinz, 2006).\nSkepticism about modularity in other areas of central cognition, such\nas high-level mindreading, also seems to be the order of the day\n(Currie & Sterelny, 2000). The type of mindreading impairments\ncharacteristic of Asperger syndrome and high-functioning autism, for\nexample, co-occur with sensory processing and executive function\ndeficits (Frith, 2003). In general, there is little in the way of\nneuropsychological evidence to support the idea of high-level\nmodularity. \n3.2. Doubts about massive modularity\n\nJust as there are general theoretical arguments for massive\nmodularity, there are general theoretical arguments against it. One\nargument takes the form of what Fodor (2000) calls the \u2018Input\nProblem\u2019. The problem is this. Suppose that the architecture of\nthe mind is modular from top to bottom, and the mind consists entirely\nof domain-specific mechanisms. In that case, the outputs of each\nlow-level (input) system will need to be routed to the appropriately\nspecialized high-level (central) system for processing. But that\nrouting can only be accomplished by a domain-general, non-modular\nmechanism\u2014contradicting the initial supposition. In response to\nthis problem, Barrett (2005) argues that processing in a massively\nmodular architecture does not require a domain-general routing device\nof the sort envisaged by Fodor. An alternative solution, Barrett\nsuggests, involves what he calls \u2018enzymatic computation\u2019.\nIn this model, low-level systems pool their outputs together in a\ncentrally accessible workspace where each central system is\nselectively activated by outputs that match its domain, in much the\nsame way that enzymes selectively bind with substrates that match\ntheir specific templates. Like enzymes, specialized computational\ndevices at the central level of the architecture accept a restricted\nrange of inputs (analogous to biochemical substrates), perform\nspecialized operations on that input (analogous to biochemical\nreactions), and produce outputs in a format useable by other\ncomputational devices (analogous to biochemical products). This\nobviates the need for a domain-general (hence,\nnon-modular) mechanism to mediate between low-level and high-level\nsystems. \n\nA second challenge to massive modularity is posed by the \u2018Domain\nIntegration Problem\u2019 (Carruthers, 2006). The problem here is\nthat reasoning, planning, decision making, and other types of\nhigh-level cognition routinely involve the production of conceptually\nstructured representations whose content crosses domains. This means\nthat there must be some mechanism for integrating representations from\nmultiple domains. But such a mechanism would be domain general rather\nthan domain specific, and hence, non-modular. Like the Input Problem,\nhowever, the Domain Integration Problem is not insurmountable. One\npossible solution is that the language system has the capacity to play\nthe role of content integrator in virtue of its capacity to transform\nconceptual representations that have been linguistically encoded\n(Hermer & Spelke, 1996; Carruthers, 2002, 2006). On this view,\nlanguage is the vehicle of domain-general thought. \n\nEmpirical objections to massive modularity take a variety of forms. To\nstart with, there is neurobiological evidence of developmental\nplasticity, a phenomenon that tells against the idea that brain\nstructure is innately specified (Buller, 2005; Buller and Hardcastle,\n2000). However, not all proponents of massive modularity insist that\nmodules are innately specified (Carruthers, 2006; Kurzban, Tooby, and\nCosmides, 2001). Furthermore, it\u2019s unclear to what extent the\nneurobiological record is at odds with nativism, given the evidence\nthat specific genes are linked to the normal development of cortical\nstructures in both humans and animals (Machery & Barrett, 2008;\nRamus, 2006). \n\nAnother source of evidence against massive modularity comes from\nresearch on individual differences in high-level cognition (Rabaglia,\nMarcus, & Lane, 2011). Such differences tend to be strongly\npositively correlated across domains\u2014a phenomenon known as the\n\u2018positive manifold\u2019\u2014suggesting that high-level\ncognitive abilities are subserved by a domain-general mechanism,\nrather than by a suite of specialized modules. There is, however, an\nalternative explanation of the positive manifold. Since post-Fodorian\nmodules are allowed to share parts (Carruthers, 2006), the\ncorrelations observed may stem from individual differences in the\nfunctioning of components spanning multiple domain-specific\nmechanisms. \n4. Modularity and philosophy\n\nInterest in modularity is not confined to cognitive science and the\nphilosophy of mind; it extends well into a number of allied fields. In\nepistemology, modularity has been invoked to defend the legitimacy of\na theory-neutral type of observation, and hence the possibility of\nsome degree of consensus among scientists with divergent theoretical\ncommitments (Fodor, 1984). The ensuing debate on this issue\n(Churchland, 1988; Fodor, 1988; McCauley & Henrich, 2006) holds\nlasting significance for the general philosophy of science,\nparticularly for controversies regarding the status of scientific\nrealism. Relatedly, evidence of the cognitive penetrability of\nperception has given rise to worries about the justification of\nperceptual beliefs (Siegel, 2012; Stokes, 2012). In ethics, evidence\nof this sort has been used to cast doubt on ethical intuitionism as an\naccount of moral epistemology (Cowan, 2014). In philosophy of\nlanguage, modularity has figured in theorizing about linguistic\ncommunication, for example, in relevance theorists\u2019 suggestion\nthat speech interpretation, pragmatic warts and all, is a modular\nprocess (Sperber & Wilson, 2002). It has also been used demarcate\nthe boundary between semantics and pragmatics, and to defend a notably\naustere version of semantic minimalism (Borg, 2004). Though the\nsuccess of these deployments of modularity theory is subject to\ndispute (e.g., see Robbins, 2007, for doubts about the modularity of\nsemantics), their existence testifies to the relevance of the concept\nof modularity to philosophical inquiry in a variety of domains.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Anderson, M. L., 2010. Neural reuse: A fundamental organizational\nprinciple of the brain. <em>Behavioral and Brain Sciences</em>, 33:\n245\u2013313.",
                " \u2013\u2013\u2013, 2014. <em>After phrenology: Neural reuse\nand the interactive brain</em>, Cambridge, MA: MIT Press.",
                "Antony, L. M., 2003. Rabbit-pots and supernovas: On the relevance\nof psychological data to linguistic theory. In A. Barber (ed.),\n<em>Epistemology of Language</em>, Oxford: Oxford University Press,\npp. 47\u201368.",
                "Arbib, M., 1987. Modularity and interaction of brain regions\nunderlying visuomotor coordination. In J. L. Garfield (ed.),\n<em>Modularity in Knowledge Representation and Natural-Language\nUnderstanding</em>, Cambridge, MA: MIT Press, pp. 333\u2013363.",
                "Ariew, A., 1999. Innateness is canalization: In defense of a\ndevelopmental account of innateness. In V. G. Hardcastle (ed.),\n<em>Where Biology Meets Psychology</em>, Cambridge, MA: MIT Press, pp.\n117\u2013138.",
                "Balcetis, E. and Dunning, D., 2006. See what you want to see:\nMotivational influences on visual perception. <em>Journal of\nPersonality and Social Psychology</em>, 91: 612\u2013625.",
                "\u2013\u2013\u2013, 2010. Wishful seeing: More desired objects\nare seen as closer. <em>Psychological Science</em>, 21:\n147\u2013152.",
                "Bargh, J. A. and Chartrand, T. L., 1999. The unbearable\nautomaticity of being. <em>American Psychologist</em>, 54:\n462\u2013479.",
                "Barrett, H. C., 2005. Enzymatic computation and cognitive\nmodularity. <em>Mind &amp; Language</em>, 20: 259\u2013287.",
                "Barrett, H. C. and Kurzban, R., 2006. Modularity in cognition:\nFraming the debate. <em>Psychological Review</em>, 113:\n628\u2013647.",
                "Borg, E., 2004. <em>Minimal Semantics</em>, Oxford: Oxford\nUniversity Press.",
                "Bruner, J. and Goodman, C. C., 1947. Value and need as organizing\nfactors in perception. <em>Journal of Abnormal and Social\nPsychology</em>, 42: 33\u201344.",
                "Barrett, H. C. and Kurzban, R., 2006. Modularity in cognition:\nFraming the debate. <em>Psychological Review</em>, 113:\n628\u2013647.",
                "Buller, D., 2005. <em>Adapting Minds</em>, Cambridge, MA: MIT\nPress.",
                "Buller, D. and Hardcastle, V. G., 2000. Evolutionary psychology,\nmeet developmental neurobiology: Against promiscuous modularity.\n<em>Brain and Mind</em>, 1: 302\u2013325.",
                "Carruthers, P., 2002. The cognitive functions of language.\n<em>Behavioral and Brain Sciences</em>, 25: 657\u2013725.",
                "\u2013\u2013\u2013, 2006. <em>The Architecture of the\nMind</em>, Oxford: Oxford University Press.",
                "Churchland, P., 1988. Perceptual plasticity and theoretical\nneutrality: A reply to Jerry Fodor. <em>Philosophy of Science</em>,\n55: 167\u2013187. ",
                "Coltheart, M., 1999. Modularity and cognition. <em>Trends in\nCognitive Sciences</em>, 3: 115\u2013120.",
                "Cosmides, L. and Tooby, J., 1992. Cognitive adaptations for social\nexchange. In J. Barkow, L. Cosmides, and J. Tooby, eds., <em>The\nAdapted Mind</em>, Oxford: Oxford University Press, pp.\n163\u2013228.",
                "Cowan, R., 2014. Cognitive penetrability and ethical perception.\n<em>Review of Philosophy and Psychology</em>, 6: 665\u2013682.",
                "Cowie, F., 1999. <em>What\u2019s Within? Nativism\nReconsidered</em>, Oxford: Oxford University Press.",
                "Currie, G. and Sterelny, K., 2000. How to think about the\nmodularity of mind-reading. <em>Philosophical Quarterly</em>, 50:\n145\u2013160.",
                "Firestone, C. and Scholl, B. J., 2016. Cognition does not affect\nperception: Evaluating the evidence for \u201ctop-down\u201d\neffects. <em>Behavioral and Brain Sciences</em>, 39.",
                "Fodor, J. A., 1983. <em>The Modularity of Mind</em>, Cambridge,\nMA: MIT Press.",
                "\u2013\u2013\u2013, 1984. Observation reconsidered.\n<em>Philosophy of Science</em>, 51: 23\u201343.",
                "\u2013\u2013\u2013, 1988. A reply to Churchland\u2019s\n\u201cPerceptual plasticity and theoretical neutrality.\u201d\n<em>Philosophy of Science</em>, 55: 188\u2013198.",
                "\u2013\u2013\u2013, 2000. <em>The Mind Doesn\u2019t Work That\nWay</em>, Cambridge, MA: MIT Press.",
                "Frith, U., 2003. <em>Autism: Explaining the enigma</em>, 2nd\nedition, Malden, MA: Wiley-Blackwell.",
                "Gauthier, I., Skudlarski, P., Gore, J.C., and Anderson, A. W.,\n2000. Expertise for cars and birds recruits brain areas involved in\nface recognition. <em>Nature Neuroscience</em>, 3: 191\u2013197.",
                "Hansen, T., Olkkonen, M., Walter, S., and Gegenfurtner, K. R.,\n2006. Memory modulates color appearance. <em>Nature Neuroscience</em>,\n9: 1367\u20131368.",
                "Hermer, L. and Spelke, E. S., 1996. Modularity and development:\nThe case of spatial reorientation. <em>Cognition</em>, 61:\n195\u2013232.",
                "Kurzban, R., Tooby, J., and Cosmides, L., 2001. Can race be\nerased? Coalitional computation and social categorization.\n<em>Proceedings of the National Academy of Sciences</em>, 98:\n15387\u201315392.",
                "Levin, D. and Banaji, M., 2006. Distortions in the perceived\nlightness of faces: The role of race categories. <em>Journal of\nExperimental Psychology: General</em>, 135: 501\u2013512.",
                "Machery, E., 2015. Cognitive penetrability: A no-progress report.\nIn J. Zeimbekis and A. Raftopoulos (eds.), <em>The Cognitive\nPenetrability of Perception: New Philosophical Perspectives</em>,\nOxford: Oxford University Press.",
                "Machery, E. and Barrett, H. C., 2006. Debunking <em>Adapting\nMinds</em>. <em>Philosophy of Science</em>, 73: 232\u2013246.",
                "Marslen-Wilson, W. and Tyler, L. K., 1987. Against modularity. In\nJ. L. Garfield (ed.), <em>Modularity in Knowledge Representation and\nNatural-Language Understanding</em>, Cambridge, MA: MIT Press.",
                "McCauley, R. N. and Henrich, J., 2006. Susceptibility to the\nM\u00fcller-Lyer illusion, theory-neutral observation, and the\ndiachronic penetrability of the visual input system. <em>Philosophical\nPsychology</em>, 19: 79\u2013101.",
                "McGurk, H. and Macdonald, J., 1976. Hearing lips and seeing\nvoices. <em>Nature</em>, 391: 756.",
                "Pinker, S., 1997. <em>How the Mind Works</em>, New York: W. W.\nNorton &amp; Company.",
                "Prinz, J. J., 2006. Is the mind really modular? In R. Stainton\n(ed.), <em>Contemporary Debates in Cognitive Science</em>, Oxford:\nBlackwell, pp. 22\u201336.",
                "Pylyshyn, Z., 1984. <em>Computation and Cognition</em>, Cambridge,\nMA: MIT Press.",
                "\u2013\u2013\u2013, 1999. Is vision continuous with cognition?\nThe case for cognitive penetrability of vision. <em>Behavioral and\nBrain Sciences</em>, 22: 341\u2013423.",
                "Rabaglia, C. D., Marcus, G. F., and Lane, S. P., 2011. What can\nindividual differences tell us about the specialization of function?\n<em>Cognitive Neuropsychology</em>, 28: 288\u2013303.",
                "Ramus, F., 2006. Genes, brain, and cognition: A roadmap for the\ncognitive scientist. <em>Cognition</em>, 101: 247\u2013269.",
                "Robbins, P., 2007. Minimalism and modularity. In G. Preyer and G.\nPeter, eds., <em>Context-Sensitivity and Semantic Minimalism</em>,\nOxford: Oxford University Press, pp. 303\u2013319.",
                "\u2013\u2013\u2013, 2013. Modularity and mental architecture.\n<em>WIREs Cognitive Science</em>, 4: 641\u2013649.",
                "Rosch, E., Mervis, C., Gray, W., Johnson, D., and Boyes-Braem, P.\n(1976). Basic objects in natural categories. <em>Cognitive\nPsychology</em>, 8: 382\u2013439.",
                "Samuels, R., 2000. Massively modular minds: Evolutionary\npsychology and cognitive architecture. In P. Carruthers and A.\nChamberlain, eds., <em>Evolution and the Human Mind</em>, Cambridge:\nCambridge University Press, pp. 13\u201346.",
                "\u2013\u2013\u2013, 2005. The complexity of cognition:\nTractability arguments for massive modularity. In P. Carruthers, S.\nLaurence, and S. Stich, eds., <em>The Innate Mind: Structure and\nContents</em>, Oxford: Oxford University Press, pp.\n107\u2013121.",
                "Scholl, B. J. and Leslie, A. M., 1999. Modularity, development and\n\u2018theory of mind\u2019. <em>Mind &amp; Language</em>, 14:\n131\u2013153.",
                "Segal, G., 1996. The modularity of theory of mind. In P.\nCarruthers and P. K. Smith, eds., <em>Theories of Theories of\nMind</em>, Cambridge: Cambridge University Press, pp.\n141\u2013157.",
                "Segall, M., Campbell, D. and Herskovits, M. J., 1966. <em>The\nInfluence of Culture on Visual Perception</em>, New York:\nBobbs-Merrill.",
                "Shams, L., Kamitani, Y., and Shimojo, S., 2000. Illusions: What\nyou see is what you hear. <em>Nature</em>, 408: 788.",
                "Siegel, S., 2011. Cognitive penetrability and perceptual\njustification. <em>Nous</em>, 46: 201\u2013222.",
                "Spelke, E., 1994. Initial knowledge: Six suggestions.\n<em>Cognition</em>, 50: 435\u2013445.",
                "Sperber, D., 1994. The modularity of thought and the epidemiology\nof representations. In L. A. Hirschfeld and S. A. Gelman (eds.),\n<em>Mapping the Mind</em>, Cambridge: Cambridge University Press, pp.\n39\u201367.",
                "\u2013\u2013\u2013, 2002. In defense of massive modularity. In\nI. Dupoux (ed.), <em>Language, Brain, and Cognitive Development</em>,\nCambridge, MA: MIT Press, pp. 47\u201357.",
                "Sperber, D. and Wilson, D., 2002. Pragmatics, modularity and\nmind-reading. <em>Mind &amp; Language</em>, 17: 3\u201323.",
                "Stokes, D., 2012. Perceiving and desiring: A new look at the\ncognitive penetrability of experience. <em>Philosophical Studies</em>,\n158: 479\u2013492.",
                "\u2013\u2013\u2013, 2013. Cognitive penetrability of\nperception. <em>Philosophy Compass</em>, 8: 646\u2013663.",
                "Stokes, D. and Bergeron, V., 2015. Modular architectures and\ninformational encapsulation: A dilemma. <em>European Journal for the\nPhilosophy of Science</em>, 5: 315\u2013338.",
                "Stone, V. E., Cosmides, L., Tooby, J., Kroll, N., and Knight, R.\nT., 2002. Selective impairment of reasoning about social exchange in a\npatient with bilateral limbic system damage. <em>Proceedings of the\nNational Academy of Sciences</em>, 99: 11531\u201311536.",
                "Stromswold, K., 1999. Cognitive and neural aspects of language\nacquisition. In E. Lepore and Z. Pylyshyn, eds., <em>What Is Cognitive\nScience?</em>, Oxford: Blackwell, pp. 356\u2013400.",
                "Sugiyama, L. S., Tooby, J., and Cosmides, L., 2002. Cross-cultural\nevidence of cognitive adaptations for social exchange among the\nShiwiar of Ecuadorian Amazonia. <em>Proceedings of the National\nAcademy of Sciences</em>, 99: 11537\u201311542.",
                "Tettamanti, M. and Weniger, D., 2006. Broca\u2019s area: A\nsupramodal hierarchical processor? <em>Cortex</em>, 42:\n491\u2013494.",
                "Warren, R. M., 1970. Perceptual restoration of missing speech\nsounds. <em>Science</em>, 167: 392\u2013393.",
                "Warren, R. M. and Warren, R. P., 1970. Auditory illusions and\nconfusions. <em>Scientific American</em>, 223: 30\u201336.",
                "Wilson, R. A., 2008. The drink you\u2019re having when\nyou\u2019re not having a drink. <em>Mind &amp; Language</em>, 23:\n273\u2013283.",
                "Witt, J. K., Linkenauger, S. A., Bakdash, J. Z. and Proffitt, D.\nR., 2008. Putting to a bigger hole: Golf performance relates to\nperceived size. <em>Psychonomic Bulletin and Review</em>, 15:\n581\u2013585.",
                "Witt, J. K., Proffitt, D. R. and Epstein, W., 2004. Perceiving\ndistances: A role of effort and intent. <em>Perception</em>, 33:\n577\u2013590. ",
                " Woods, A. J., Philbeck, J. W., and Danoff, J. V., 2009. The\nvarious perceptions of distance: An alternative view of how effort\naffects distance judgments. <em>Journal of Experimental Psychology:\nHuman Perception and Performance</em>, 35: 1104\u20131117.",
                "Woodward, J. F. and Cowie, F., 2004. The mind is not (just) a\nsystem of modules shaped (just) by natural selection. In C. Hitchcock,\ned., <em>Contemporary Debates in Philosophy of Science</em>, Malden,\nMA: Blackwell, pp. 312\u2013334."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Anderson, M. L., 2010. Neural reuse: A fundamental organizational\nprinciple of the brain. <em>Behavioral and Brain Sciences</em>, 33:\n245\u2013313.</li>\n<li> \u2013\u2013\u2013, 2014. <em>After phrenology: Neural reuse\nand the interactive brain</em>, Cambridge, MA: MIT Press.</li>\n<li>Antony, L. M., 2003. Rabbit-pots and supernovas: On the relevance\nof psychological data to linguistic theory. In A. Barber (ed.),\n<em>Epistemology of Language</em>, Oxford: Oxford University Press,\npp. 47\u201368.</li>\n<li>Arbib, M., 1987. Modularity and interaction of brain regions\nunderlying visuomotor coordination. In J. L. Garfield (ed.),\n<em>Modularity in Knowledge Representation and Natural-Language\nUnderstanding</em>, Cambridge, MA: MIT Press, pp. 333\u2013363.</li>\n<li>Ariew, A., 1999. Innateness is canalization: In defense of a\ndevelopmental account of innateness. In V. G. Hardcastle (ed.),\n<em>Where Biology Meets Psychology</em>, Cambridge, MA: MIT Press, pp.\n117\u2013138.</li>\n<li>Balcetis, E. and Dunning, D., 2006. See what you want to see:\nMotivational influences on visual perception. <em>Journal of\nPersonality and Social Psychology</em>, 91: 612\u2013625.</li>\n<li>\u2013\u2013\u2013, 2010. Wishful seeing: More desired objects\nare seen as closer. <em>Psychological Science</em>, 21:\n147\u2013152.</li>\n<li>Bargh, J. A. and Chartrand, T. L., 1999. The unbearable\nautomaticity of being. <em>American Psychologist</em>, 54:\n462\u2013479.</li>\n<li>Barrett, H. C., 2005. Enzymatic computation and cognitive\nmodularity. <em>Mind &amp; Language</em>, 20: 259\u2013287.</li>\n<li>Barrett, H. C. and Kurzban, R., 2006. Modularity in cognition:\nFraming the debate. <em>Psychological Review</em>, 113:\n628\u2013647.</li>\n<li>Borg, E., 2004. <em>Minimal Semantics</em>, Oxford: Oxford\nUniversity Press.</li>\n<li>Bruner, J. and Goodman, C. C., 1947. Value and need as organizing\nfactors in perception. <em>Journal of Abnormal and Social\nPsychology</em>, 42: 33\u201344.</li>\n<li>Barrett, H. C. and Kurzban, R., 2006. Modularity in cognition:\nFraming the debate. <em>Psychological Review</em>, 113:\n628\u2013647.</li>\n<li>Buller, D., 2005. <em>Adapting Minds</em>, Cambridge, MA: MIT\nPress.</li>\n<li>Buller, D. and Hardcastle, V. G., 2000. Evolutionary psychology,\nmeet developmental neurobiology: Against promiscuous modularity.\n<em>Brain and Mind</em>, 1: 302\u2013325.</li>\n<li>Carruthers, P., 2002. The cognitive functions of language.\n<em>Behavioral and Brain Sciences</em>, 25: 657\u2013725.</li>\n<li>\u2013\u2013\u2013, 2006. <em>The Architecture of the\nMind</em>, Oxford: Oxford University Press.</li>\n<li>Churchland, P., 1988. Perceptual plasticity and theoretical\nneutrality: A reply to Jerry Fodor. <em>Philosophy of Science</em>,\n55: 167\u2013187. </li>\n<li>Coltheart, M., 1999. Modularity and cognition. <em>Trends in\nCognitive Sciences</em>, 3: 115\u2013120.</li>\n<li>Cosmides, L. and Tooby, J., 1992. Cognitive adaptations for social\nexchange. In J. Barkow, L. Cosmides, and J. Tooby, eds., <em>The\nAdapted Mind</em>, Oxford: Oxford University Press, pp.\n163\u2013228.</li>\n<li>Cowan, R., 2014. Cognitive penetrability and ethical perception.\n<em>Review of Philosophy and Psychology</em>, 6: 665\u2013682.</li>\n<li>Cowie, F., 1999. <em>What\u2019s Within? Nativism\nReconsidered</em>, Oxford: Oxford University Press.</li>\n<li>Currie, G. and Sterelny, K., 2000. How to think about the\nmodularity of mind-reading. <em>Philosophical Quarterly</em>, 50:\n145\u2013160.</li>\n<li>Firestone, C. and Scholl, B. J., 2016. Cognition does not affect\nperception: Evaluating the evidence for \u201ctop-down\u201d\neffects. <em>Behavioral and Brain Sciences</em>, 39.</li>\n<li>Fodor, J. A., 1983. <em>The Modularity of Mind</em>, Cambridge,\nMA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 1984. Observation reconsidered.\n<em>Philosophy of Science</em>, 51: 23\u201343.</li>\n<li>\u2013\u2013\u2013, 1988. A reply to Churchland\u2019s\n\u201cPerceptual plasticity and theoretical neutrality.\u201d\n<em>Philosophy of Science</em>, 55: 188\u2013198.</li>\n<li>\u2013\u2013\u2013, 2000. <em>The Mind Doesn\u2019t Work That\nWay</em>, Cambridge, MA: MIT Press.</li>\n<li>Frith, U., 2003. <em>Autism: Explaining the enigma</em>, 2nd\nedition, Malden, MA: Wiley-Blackwell.</li>\n<li>Gauthier, I., Skudlarski, P., Gore, J.C., and Anderson, A. W.,\n2000. Expertise for cars and birds recruits brain areas involved in\nface recognition. <em>Nature Neuroscience</em>, 3: 191\u2013197.</li>\n<li>Hansen, T., Olkkonen, M., Walter, S., and Gegenfurtner, K. R.,\n2006. Memory modulates color appearance. <em>Nature Neuroscience</em>,\n9: 1367\u20131368.</li>\n<li>Hermer, L. and Spelke, E. S., 1996. Modularity and development:\nThe case of spatial reorientation. <em>Cognition</em>, 61:\n195\u2013232.</li>\n<li>Kurzban, R., Tooby, J., and Cosmides, L., 2001. Can race be\nerased? Coalitional computation and social categorization.\n<em>Proceedings of the National Academy of Sciences</em>, 98:\n15387\u201315392.</li>\n<li>Levin, D. and Banaji, M., 2006. Distortions in the perceived\nlightness of faces: The role of race categories. <em>Journal of\nExperimental Psychology: General</em>, 135: 501\u2013512.</li>\n<li>Machery, E., 2015. Cognitive penetrability: A no-progress report.\nIn J. Zeimbekis and A. Raftopoulos (eds.), <em>The Cognitive\nPenetrability of Perception: New Philosophical Perspectives</em>,\nOxford: Oxford University Press.</li>\n<li>Machery, E. and Barrett, H. C., 2006. Debunking <em>Adapting\nMinds</em>. <em>Philosophy of Science</em>, 73: 232\u2013246.</li>\n<li>Marslen-Wilson, W. and Tyler, L. K., 1987. Against modularity. In\nJ. L. Garfield (ed.), <em>Modularity in Knowledge Representation and\nNatural-Language Understanding</em>, Cambridge, MA: MIT Press.</li>\n<li>McCauley, R. N. and Henrich, J., 2006. Susceptibility to the\nM\u00fcller-Lyer illusion, theory-neutral observation, and the\ndiachronic penetrability of the visual input system. <em>Philosophical\nPsychology</em>, 19: 79\u2013101.</li>\n<li>McGurk, H. and Macdonald, J., 1976. Hearing lips and seeing\nvoices. <em>Nature</em>, 391: 756.</li>\n<li>Pinker, S., 1997. <em>How the Mind Works</em>, New York: W. W.\nNorton &amp; Company.</li>\n<li>Prinz, J. J., 2006. Is the mind really modular? In R. Stainton\n(ed.), <em>Contemporary Debates in Cognitive Science</em>, Oxford:\nBlackwell, pp. 22\u201336.</li>\n<li>Pylyshyn, Z., 1984. <em>Computation and Cognition</em>, Cambridge,\nMA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 1999. Is vision continuous with cognition?\nThe case for cognitive penetrability of vision. <em>Behavioral and\nBrain Sciences</em>, 22: 341\u2013423.</li>\n<li>Rabaglia, C. D., Marcus, G. F., and Lane, S. P., 2011. What can\nindividual differences tell us about the specialization of function?\n<em>Cognitive Neuropsychology</em>, 28: 288\u2013303.</li>\n<li>Ramus, F., 2006. Genes, brain, and cognition: A roadmap for the\ncognitive scientist. <em>Cognition</em>, 101: 247\u2013269.</li>\n<li>Robbins, P., 2007. Minimalism and modularity. In G. Preyer and G.\nPeter, eds., <em>Context-Sensitivity and Semantic Minimalism</em>,\nOxford: Oxford University Press, pp. 303\u2013319.</li>\n<li>\u2013\u2013\u2013, 2013. Modularity and mental architecture.\n<em>WIREs Cognitive Science</em>, 4: 641\u2013649.</li>\n<li>Rosch, E., Mervis, C., Gray, W., Johnson, D., and Boyes-Braem, P.\n(1976). Basic objects in natural categories. <em>Cognitive\nPsychology</em>, 8: 382\u2013439.</li>\n<li>Samuels, R., 2000. Massively modular minds: Evolutionary\npsychology and cognitive architecture. In P. Carruthers and A.\nChamberlain, eds., <em>Evolution and the Human Mind</em>, Cambridge:\nCambridge University Press, pp. 13\u201346.</li>\n<li>\u2013\u2013\u2013, 2005. The complexity of cognition:\nTractability arguments for massive modularity. In P. Carruthers, S.\nLaurence, and S. Stich, eds., <em>The Innate Mind: Structure and\nContents</em>, Oxford: Oxford University Press, pp.\n107\u2013121.</li>\n<li>Scholl, B. J. and Leslie, A. M., 1999. Modularity, development and\n\u2018theory of mind\u2019. <em>Mind &amp; Language</em>, 14:\n131\u2013153.</li>\n<li>Segal, G., 1996. The modularity of theory of mind. In P.\nCarruthers and P. K. Smith, eds., <em>Theories of Theories of\nMind</em>, Cambridge: Cambridge University Press, pp.\n141\u2013157.</li>\n<li>Segall, M., Campbell, D. and Herskovits, M. J., 1966. <em>The\nInfluence of Culture on Visual Perception</em>, New York:\nBobbs-Merrill.</li>\n<li>Shams, L., Kamitani, Y., and Shimojo, S., 2000. Illusions: What\nyou see is what you hear. <em>Nature</em>, 408: 788.</li>\n<li>Siegel, S., 2011. Cognitive penetrability and perceptual\njustification. <em>Nous</em>, 46: 201\u2013222.</li>\n<li>Spelke, E., 1994. Initial knowledge: Six suggestions.\n<em>Cognition</em>, 50: 435\u2013445.</li>\n<li>Sperber, D., 1994. The modularity of thought and the epidemiology\nof representations. In L. A. Hirschfeld and S. A. Gelman (eds.),\n<em>Mapping the Mind</em>, Cambridge: Cambridge University Press, pp.\n39\u201367.</li>\n<li>\u2013\u2013\u2013, 2002. In defense of massive modularity. In\nI. Dupoux (ed.), <em>Language, Brain, and Cognitive Development</em>,\nCambridge, MA: MIT Press, pp. 47\u201357.</li>\n<li>Sperber, D. and Wilson, D., 2002. Pragmatics, modularity and\nmind-reading. <em>Mind &amp; Language</em>, 17: 3\u201323.</li>\n<li>Stokes, D., 2012. Perceiving and desiring: A new look at the\ncognitive penetrability of experience. <em>Philosophical Studies</em>,\n158: 479\u2013492.</li>\n<li>\u2013\u2013\u2013, 2013. Cognitive penetrability of\nperception. <em>Philosophy Compass</em>, 8: 646\u2013663.</li>\n<li>Stokes, D. and Bergeron, V., 2015. Modular architectures and\ninformational encapsulation: A dilemma. <em>European Journal for the\nPhilosophy of Science</em>, 5: 315\u2013338.</li>\n<li>Stone, V. E., Cosmides, L., Tooby, J., Kroll, N., and Knight, R.\nT., 2002. Selective impairment of reasoning about social exchange in a\npatient with bilateral limbic system damage. <em>Proceedings of the\nNational Academy of Sciences</em>, 99: 11531\u201311536.</li>\n<li>Stromswold, K., 1999. Cognitive and neural aspects of language\nacquisition. In E. Lepore and Z. Pylyshyn, eds., <em>What Is Cognitive\nScience?</em>, Oxford: Blackwell, pp. 356\u2013400.</li>\n<li>Sugiyama, L. S., Tooby, J., and Cosmides, L., 2002. Cross-cultural\nevidence of cognitive adaptations for social exchange among the\nShiwiar of Ecuadorian Amazonia. <em>Proceedings of the National\nAcademy of Sciences</em>, 99: 11537\u201311542.</li>\n<li>Tettamanti, M. and Weniger, D., 2006. Broca\u2019s area: A\nsupramodal hierarchical processor? <em>Cortex</em>, 42:\n491\u2013494.</li>\n<li>Warren, R. M., 1970. Perceptual restoration of missing speech\nsounds. <em>Science</em>, 167: 392\u2013393.</li>\n<li>Warren, R. M. and Warren, R. P., 1970. Auditory illusions and\nconfusions. <em>Scientific American</em>, 223: 30\u201336.</li>\n<li>Wilson, R. A., 2008. The drink you\u2019re having when\nyou\u2019re not having a drink. <em>Mind &amp; Language</em>, 23:\n273\u2013283.</li>\n<li>Witt, J. K., Linkenauger, S. A., Bakdash, J. Z. and Proffitt, D.\nR., 2008. Putting to a bigger hole: Golf performance relates to\nperceived size. <em>Psychonomic Bulletin and Review</em>, 15:\n581\u2013585.</li>\n<li>Witt, J. K., Proffitt, D. R. and Epstein, W., 2004. Perceiving\ndistances: A role of effort and intent. <em>Perception</em>, 33:\n577\u2013590. </li>\n<li> Woods, A. J., Philbeck, J. W., and Danoff, J. V., 2009. The\nvarious perceptions of distance: An alternative view of how effort\naffects distance judgments. <em>Journal of Experimental Psychology:\nHuman Perception and Performance</em>, 35: 1104\u20131117.</li>\n<li>Woodward, J. F. and Cowie, F., 2004. The mind is not (just) a\nsystem of modules shaped (just) by natural selection. In C. Hitchcock,\ned., <em>Contemporary Debates in Philosophy of Science</em>, Malden,\nMA: Blackwell, pp. 312\u2013334.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "cognitive science",
            "mind: computational theory of",
            "neuroscience, philosophy of",
            "psychology: evolutionary"
        ],
        "entry_link": [
            {
                "../cognitive-science/": "cognitive science"
            },
            {
                "../computational-mind/": "mind: computational theory of"
            },
            {
                "../neuroscience/": "neuroscience, philosophy of"
            },
            {
                "../evolutionary-psychology/": "psychology: evolutionary"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=modularity-mind\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/modularity-mind/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=modularity-mind&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"http://philpapers.org/sep/modularity-mind/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"http://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=modularity-mind": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/modularity-mind/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=modularity-mind&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "http://philpapers.org/sep/modularity-mind/": "Enhanced bibliography for this entry"
            },
            {
                "http://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "<a href=\"https://philpapers.org/browse/modularity-in-cognitive-science\" target=\"other\">Modularity in Cognitive Science</a>,\n bibliography category at philpapers.org.",
            "<a href=\"http://gral.ip.rm.cnr.it/rcalabretta/modularity.html\" target=\"other\">The Modularity Home Page</a>,\n maintained by Raffaele Calabretta (Institute of Cognitive Sciences\nand Technologies, Italian National Research Council)."
        ],
        "listed_links": [
            {
                "https://philpapers.org/browse/modularity-in-cognitive-science": "Modularity in Cognitive Science"
            },
            {
                "http://gral.ip.rm.cnr.it/rcalabretta/modularity.html": "The Modularity Home Page"
            }
        ]
    }
}