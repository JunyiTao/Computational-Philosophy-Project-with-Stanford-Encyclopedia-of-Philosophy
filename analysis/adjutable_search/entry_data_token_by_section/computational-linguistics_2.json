{
    "main_text": "Syntax and parsing || The structural hierarchy\n2.1 The structural hierarchy\nLanguage is structured at multiple levels, beginning in the case of\nspoken language with patterns in the acoustic signal that can be\nmapped to phones (the distinguishable successive sounds of\nwhich languages are built up). Groups of phones that are equivalent\nfor a given language (not affecting the words recognized by a hearer,\nif interchanged) are the phonemes of the language. The\nphonemes in turn are the constituents of morphemes (minimal\nmeaningful word segments), and these provide the constituents of\nwords. (In written language one speaks instead of characters,\ngraphemes, syllables, and words.) Words are grouped\ninto phrases, such as noun phrases, verb phrases, adjective\nphrases and prepositional phrases, which are the structural components\nof sentences, expressing complete thoughts. At still higher levels we\nhave various types of discourse structure, though this is generally\nlooser than lower-level structure.\nTechniques have been developed for language analysis at all of these\nstructural levels, though space limitations will not permit a serious\ndiscussion of methods used below the word level. It should be noted,\nhowever, that the techniques developed for speech recognition in the\n1980s and 1990s were very influential in turning NLP research towards\nthe new corpus-based, statistical approach referred to above.  One\nkey idea was that of hidden Markov\nmodels (HMMs), which model \u201cnoisy\u201d sequences (e.g.,\nphone sequences, phoneme sequences, or word sequences) as if generated\nprobabilistically by \u201chidden\u201d underlying states and their transitions.\nIndividually or in groups, successive hidden states model the more\nabstract, higher-level constituents to be extracted from observed noisy\nsequences, such as phonemes from phones, words from phonemes, or parts\nof speech from words. The generation probabilities and the state\ntransition probabilities are the parameters of such models, and\nimportantly these can be learned from training data. Subsequently the\nmodels can be efficiently applied to the analysis of new data, using\nfast dynamic programming algorithms such as the Viterbi algorithm.\nThese quite successful techniques were subsequently generalized to\nhigher-level structure, soon influencing all aspects on NLP.\n",
    "section_title": "2.1 The structural hierarchy",
    "entry_title": "Computational Linguistics",
    "hierarchy_title": "Computational Linguistics || Syntax and parsing || The structural hierarchy",
    "tokenized_text": [
        "syntax",
        "parsing",
        "structural",
        "hierarchy",
        "structural",
        "hierarchy",
        "language",
        "structured",
        "multiple",
        "level",
        "beginning",
        "case",
        "spoken",
        "language",
        "pattern",
        "acoustic",
        "signal",
        "mapped",
        "phone",
        "distinguishable",
        "successive",
        "sound",
        "language",
        "built",
        "group",
        "phone",
        "equivalent",
        "given",
        "language",
        "affecting",
        "word",
        "recognized",
        "hearer",
        "interchanged",
        "phoneme",
        "language",
        "phoneme",
        "turn",
        "constituent",
        "morpheme",
        "minimal",
        "meaningful",
        "word",
        "segment",
        "provide",
        "constituent",
        "word",
        "written",
        "language",
        "one",
        "speaks",
        "instead",
        "character",
        "grapheme",
        "syllable",
        "word",
        "word",
        "grouped",
        "phrase",
        "noun",
        "phrase",
        "verb",
        "phrase",
        "adjective",
        "phrase",
        "prepositional",
        "phrase",
        "structural",
        "component",
        "sentence",
        "expressing",
        "complete",
        "thought",
        "still",
        "higher",
        "level",
        "various",
        "type",
        "discourse",
        "structure",
        "though",
        "generally",
        "looser",
        "lowerlevel",
        "structure",
        "technique",
        "developed",
        "language",
        "analysis",
        "structural",
        "level",
        "though",
        "space",
        "limitation",
        "permit",
        "serious",
        "discussion",
        "method",
        "used",
        "word",
        "level",
        "noted",
        "however",
        "technique",
        "developed",
        "speech",
        "recognition",
        "s",
        "s",
        "influential",
        "turning",
        "nlp",
        "research",
        "towards",
        "new",
        "corpusbased",
        "statistical",
        "approach",
        "referred",
        "one",
        "key",
        "idea",
        "hidden",
        "markov",
        "model",
        "hmms",
        "model",
        "noisy",
        "sequence",
        "eg",
        "phone",
        "sequence",
        "phoneme",
        "sequence",
        "word",
        "sequence",
        "generated",
        "probabilistically",
        "hidden",
        "underlying",
        "state",
        "transition",
        "individually",
        "group",
        "successive",
        "hidden",
        "state",
        "model",
        "abstract",
        "higherlevel",
        "constituent",
        "extracted",
        "observed",
        "noisy",
        "sequence",
        "phoneme",
        "phone",
        "word",
        "phoneme",
        "part",
        "speech",
        "word",
        "generation",
        "probability",
        "state",
        "transition",
        "probability",
        "parameter",
        "model",
        "importantly",
        "learned",
        "training",
        "data",
        "subsequently",
        "model",
        "efficiently",
        "applied",
        "analysis",
        "new",
        "data",
        "using",
        "fast",
        "dynamic",
        "programming",
        "algorithm",
        "viterbi",
        "algorithm",
        "quite",
        "successful",
        "technique",
        "subsequently",
        "generalized",
        "higherlevel",
        "structure",
        "soon",
        "influencing",
        "aspect",
        "nlp"
    ]
}