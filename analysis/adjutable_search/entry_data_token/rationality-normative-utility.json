{"url": "rationality-normative-utility", "title": "Normative Theories of Rational Choice: Expected Utility", "authorship": {"year": "Copyright \u00a9 2023", "author_text": "R. A. Briggs\n<formal.epistemology@gmail.com>", "author_links": [{"https://philosophy.stanford.edu/people/ray-briggs": "R. A. Briggs"}, {"mailto:formal%2eepistemology%40gmail%2ecom": "formal.epistemology@gmail.com"}], "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2023</a> by\n\n<br/>\n<a href=\"https://philosophy.stanford.edu/people/ray-briggs\" target=\"other\">R. A. Briggs</a>\n&lt;<a href=\"mailto:formal%2eepistemology%40gmail%2ecom\"><em>formal<abbr title=\" dot \">.</abbr>epistemology<abbr title=\" at \">@</abbr>gmail<abbr title=\" dot \">.</abbr>com</em></a>&gt;\n    </p>\n</div>"}, "pubinfo": ["First published Fri Aug 8, 2014", "substantive revision Mon Sep 18, 2023"], "preamble": "\n\n\nWe must often make decisions under conditions of uncertainty.\nPursuing a degree in biology may lead to lucrative employment, or to\nunemployment and crushing debt. A doctor\u2019s appointment may result in\nthe early detection and treatment of a disease, or it may be a waste\nof money. Expected utility theory is an account of how to choose\nrationally when you are not sure which outcome will result from your\nacts. Its basic slogan is: choose the act with the highest expected\nutility.\n\n\nThis article discusses expected utility theory as a normative\ntheory\u2014that is, a theory of how people should make\ndecisions. In classical economics, expected utility theory is often\nused as a descriptive theory\u2014that is, a theory of how\npeople do make decisions\u2014or as a predictive\ntheory\u2014that is, a theory that, while it may not accurately model\nthe psychological mechanisms of decision-making, correctly predicts\npeople\u2019s choices. Expected utility theory makes faulty predictions\nabout people\u2019s decisions in many real-life choice situations (see\nKahneman & Tversky 1982); however, this does not settle whether\npeople should make decisions on the basis of expected utility\nconsiderations.\n\n\nThe expected utility of an act is a weighted average of the\nutilities of each of its possible outcomes, where the utility\nof an outcome measures the extent to which that outcome is preferred,\nor preferable, to the alternatives. The utility of each outcome is\nweighted according to the probability that the act will lead to that\noutcome. Section 1 fleshes out this basic definition of expected\nutility in more rigorous terms, and discusses its relationship to\nchoice. Section 2 discusses two types of arguments for expected\nutility theory: representation theorems, and long-run statistical\narguments. Section 3 considers objections to expected utility\ntheory; section 4 discusses its applications in philosophy of\nreligion, economics, ethics, and epistemology.\n", "toc": [{"#DefExpUti": "1. Defining Expected Utility"}, {"#ConPro": "1.1 Conditional Probabilities"}, {"#OutUti": "1.2 Outcome Utilities"}, {"#ArgForExpUtiThe": "2. Arguments for Expected Utility Theory"}, {"#LonRunArg": "2.1 Long-Run Arguments"}, {"#RepThe": "2.2 Representation Theorems"}, {"#ObjExpUtiThe": "3. Objections to Expected Utility Theory"}, {"#MaxExpUtiImp": "3.1 Maximizing Expected Utility is Impossible"}, {"#MaxExpUtiIrr": "3.2 Maximizing Expected Utility is Irrational"}, {"#App": "4. Applications"}, {"#EcoPubPol": "4.1 Economics and Public Policy"}, {"#Eth": "4.2 Ethics"}, {"#Epi": "4.3 Epistemology"}, {"#Law": "4.4 Law"}, {"#Bib": "Bibliography"}, {"#Aca": "Academic Tools"}, {"#Oth": "Other Internet Resources"}, {"#Rel": "Related Entries"}], "main_text": "\n1. Defining Expected Utility\n\n\nThe concept of expected utility is best illustrated by\nexample. Suppose I am planning a long walk, and need to decide whether\nto bring my umbrella. I would rather not tote the umbrella on a sunny\nday, but I would rather face rain with the umbrella than without\nit. There are two acts available to me: taking my umbrella, and\nleaving it at home. Which of these acts should I choose?\n\n\nThis informal problem description can be recast, slightly more\nformally, in terms of three sorts of entities. First, there are\noutcomes\u2014objects of non-instrumental preferences.  In\nthe example, we might distinguish three outcomes: either I end up dry\nand unencumbered; I end up dry and encumbered by an unwieldy umbrella;\nor I end up wet. Second, there are states\u2014things\noutside the decision-maker\u2019s control which influence the outcome of\nthe decision. In the example, there are two states: either it is\nraining, or it is not.  Finally, there are acts\u2014objects\nof the decision-maker\u2019s instrumental preferences, and in some sense,\nthings that she can do. In the example, there are two acts: I may\neither bring the umbrella; or leave it at home. Expected utility\ntheory provides a way of ranking the acts according to how\nchoiceworthy they are: the higher the expected utility, the\nbetter it is to choose the act. (It is therefore best to choose the\nact with the highest expected utility\u2014or one of them, in the\nevent that several acts are tied.)\n\n\nFollowing general convention, I will make the following assumptions\nabout the relationships between acts, states, and outcomes.\n\nStates, acts, and outcomes are propositions, i.e., sets of\npossibilities. There is a maximal set of possibilities, \\(\\Omega\\), of\nwhich each state, act, or outcome is a subset.\nThe set of acts, the set of states, and the set of outcomes are\nall partitions on \\(\\Omega\\). In other words, acts and states are\nindividuated so that every possibility in \\(\\Omega\\) is one where exactly\none state obtains, the agent performs exactly one act, and exactly one\noutcome ensues. \nActs and states are logically independent, so that no state rules\nout the performance of any act.\nI will assume for the moment that, given a state of the world,\neach act has exactly one possible outcome. (Section 1.1 briefly\ndiscusses how one might weaken this assumption.)\n\n\n\nSo the example of the umbrella can be depicted in the following\nmatrix, where each column corresponds to a state of the world; each row\ncorresponds to an act; and each entry corresponds to the outcome that\nresults when the act is performed in the state of the world.\n\n\n\nstates\n\n\nit rains\nit does not rain\n\n\nacts\ntake umbrella\nencumbered, dry\nencumbered, dry\n\n\nleave umbrella\nwet\nfree, dry\n\n\n\n\nHaving set up the basic framework, I can now rigorously define\nexpected utility. The expected utility of an act \\(A\\) (for\ninstance, taking my umbrella) depends on two features of the\nproblem:\n\nThe value of each outcome, measured by a real number called a\nutility.\nThe probability of each outcome conditional on \\(A\\).\n\n\n\nGiven these three pieces of information, \\(A\\)\u2019s expected\nutility is defined as:\n\n\\[\nEU(A) = \\sum_{o \\in O} P_{A}(o) U(o)\n\\]\n\n\n\nwhere \\(O\\) is is the set of outcomes,\n\\(P_{A}(o)\\) is the probability of outcome \\(o\\) conditional on \\(A\\), and \n\\(U(o)\\) is the utility of \\(o\\).\n\n\nThe next two subsections will unpack the conditional probability\nfunction \\(P_A\\) and the utility function \\(U\\).\n1.1 Conditional Probabilities\n\n\nThe term \\(P_{A}(o)\\) represents the probability\nof \\(o\\) given \\(A\\)\u2014roughly, how likely it is that\noutcome \\(o\\) will occur, on the supposition that the agent\nchooses act \\(A\\). (For the axioms of probability, see the entry\non \n interpretations of probability.)\n To understand what this means, we\nmust answer two questions. First, which interpretation of probability\nis appropriate? And second, what does it mean to assign a probability\non the supposition that the agent chooses act \\(A\\)?\n\n\nExpected utility theorists often interpret probability as measuring\nindividual degree of belief, so that a proposition \\(E\\) is likely\n(for an agent) to the extent that that agent is confident of \\(E\\)\n(see, for instance, Ramsey 1926, Savage 1972, Jeffrey 1983). But\nnothing in the formalism of expected utility theory forces this\ninterpretation on us. We could instead interpret probabilities as\nobjective chances (as in von Neumann and Morgenstern 1944), or as the\ndegrees of belief that are warranted by the evidence, if we thought\nthese were a better guide to rational action. (See the entry on\n interpretations of probability\n for discussion of these and other options.)\n\n\nWhat is it to have a probability on the supposition that the agent\nchooses \\(A\\)? Here, there are two basic types of answer,\ncorresponding to evidential decision theory and causal decision\ntheory.\n\n\nAccording to evidential decision theory, endorsed by Jeffrey (1983),\nthe relevant suppositional probability \\(P_{A}(o)\\)\nis the conditional probability \n\\(P(o \\mid A)\\), \ndefined as the ratio of two unconditional probabilities:\n\\(P(A \\amp o) / P(A)\\).\n\n\nAgainst Jeffrey\u2019s definition of expected utility, Spohn (1977)\nand Levi (1991) object that a decision-maker should not assign\nprobabilities to the very acts under deliberation: when freely deciding\nwhether to perform an act \\(A\\), you shouldn\u2019t take into\naccount your beliefs about whether you will perform \\(A\\). \nIf Spohn and Levi are right, then Jeffrey\u2019s ratio is undefined\n(since its denominator is undefined).\n\n\nNozick (1969) raises another objection: Jeffrey\u2019s definition gives\nstrange results in the Newcomb Problem. A predictor\nhands you a closed box, containing either $0 or $1 million, and offers\nyou an open box, containing an additional $1,000. You can either\nrefuse the open box (\u201cone-box\u201d) or take the open box\n(\u201ctwo-box\u201d). But there\u2019s a catch: the predictor\nhas predicted your choice beforehand, and all her predictions are 90%\naccurate. In other words, the probability that you one-box, given\nthat she predicts you one-box, is 90%, and the probability that you\ntwo-box, given that she predicts you two-box, is 90%. Finally,\nthe contents of the closed box depend on the prediction: if the\npredictor thought you would two-box, she put nothing in the closed box,\nwhile if she thought you would one-box, she put $1 million in the\nclosed box. The matrix for your decision looks like this:\n\n\n\nstates\n\n\n$1 million in closed box\n$0 in closed box\n\n\nacts\none-box\n$1,000,000\n$0\n\n\ntwo-box\n$1,001,000\n$1,000\n\n\n\n\nTwo-boxing dominates one-boxing: in every state, two-boxing\nyields a better outcome. Yet on Jeffrey\u2019s definition of conditional\nprobability, one-boxing has a higher expected utility than\ntwo-boxing. There is a high conditional probability of finding $1\nmillion is in the closed box, given that you one-box, so one-boxing\nhas a high expected utility. Likewise, there is a high conditional\nprobability of finding nothing in the closed box, given that you\ntwo-box, so two-boxing has a low expected utility.\n\nCausal decision theory is an\nalternative proposal that gets around these problems. It does not\nrequire (but still permits) acts to have probabilities, and it\nrecommends two-boxing in the Newcomb problem.\n\n\nCausal decision theory comes in many varieties, but I\u2019ll consider a\nrepresentative version proposed by Savage (1972), which calculates\n\\(P_{A}(o)\\) by summing the probabilities of states that, when\ncombined with the act \\(A\\), lead to the outcome \\(o\\). Let\n\\(f_{A,s}(o)\\) be a of outcomes, which maps \\(o\\) to 1 if \\(o\\)\nresults from performing \\(A\\) in state s, maps \\(o\\) to 0\notherwise. Then\n\n\\[\nP_{A}(o) = \\sum_{s\\in S}P(s)f_{A,s}(o)\n\\]\n\n\n\nOn Savage\u2019s proposal, two-boxing comes out with a higher\nexpected utility than one-boxing. This result holds no matter\nwhich probabilities you assign to the states prior to your\ndecision. Let \\(x\\) be the probability you assign to the\nstate that the closed box contains $1 million. According to\nSavage, the expected utilities of one-boxing and two-boxing,\nrespectively, are:\n\n\\[\nx {\\cdot} U({$1,000,000}) + (1 - x) {\\cdot} U($0)\n\\]\n\n\n\nand\n\n\\[\nx {\\cdot} U({$1,001,000}) + (1 - x) {\\cdot} U({$1,000})\n\\]\n\n\n\nAs long as the larger monetary amounts are assigned strictly larger\nutilities, the second sum (the utility of two-boxing) is guaranteed to\nbe larger than the first (the utility of one-boxing).\n\n\n\nSavage assumes that each act and state are enough to uniquely\ndetermine an outcome. But there are cases where this assumption\nbreaks down. Suppose you offer to sell me the following gamble:\nyou will toss a coin; if the coin lands heads, I win $100; and if the\ncoin lands tails, I lose $100. But I refuse the gamble, and the\ncoin is never tossed. There is no outcome that would\nhave resulted, had the coin been tossed\u2014I might have won $100,\nand I might have lost $100.\n\n\nWe can generalze Savage\u2019s proposal by letting \\(f_{A,s}\\) be a\nprobability function that maps outcomes to real numbers in the \\([0,\n1]\\) interval. Lewis (1981), Skyrms (1980), and Sobel (1994) equate\n\\(f_{A,s}\\) with the objective chance that \\(o\\) would be the outcome\nif state \\(s\\) obtained and the agent chose action \\(A\\).\n\n\nIn some cases\u2014most famously the Newcomb problem\u2014the\nJeffrey definition and the Savage definition of expected utility come\napart. But whenever the following two conditions are satisfied,\nthey agree.\n\nActs are\nprobabilistically independent of states. In formal terms, for all\nacts \\(A\\) and states \\(s\\), \n\\[\nP(s) = P(s \\mid A) = \\frac{P(s \\amp A)}{P(A)}.\n\\]\n(This is the condition that is violated in the Newcomb problem.)\nFor all outcomes\n\\(o\\), acts \\(A\\), and states \\(s\\),\n\\(f_{A,s}(o)\\) is equal to the conditional\nprobability of \\(o\\) given \\(A\\) and \\(s\\); in formal\nterms, \n\\[\nf_{A,s}(o) = P(o \\mid A \\amp s) = \\frac{P(o \\amp A \\amp s)}{P(A \\amp s)}.\\]\n\n(The need for this condition arises when acts and states fail to\nuniquely determine an outcome; see Lewis 1981.)\n\n1.2 Outcome Utilities\n\n\nThe term \\(U(o)\\) represents the utility of the outcome\n\\(o\\)\u2014roughly, how valuable \\(o\\) is.  Formally, \\(U\\) is a\nfunction that assigns a real number to each of the outcomes. (The\nunits associated with \\(U\\) are typically called utiles,\nso that if \\(U(o) = 2\\), we say that \\(o\\) is worth 2 utiles.) The greater\nthe utility, the more valuable the outcome.\n\n\nWhat kind of value is measured in utiles? Utiles are typically\nnot taken to be units of currency, like dollars, pounds, or\nyen. Bernoulli (1738) argued that money and other goods have\ndiminishing marginal utility: as an agent gets richer, every successive\ndollar (or gold watch, or apple) is less valuable to her than the\nlast. He gives the following example: It makes rational sense for\na rich man, but not for a pauper, to pay 9,000 ducats in exchange for a\nlottery ticket that yields a 50% chance at 20,000 ducats and a 50%\nchance at nothing. Since the lottery gives the two men the same\nchance at each monetary prize, the prizes must have different values\ndepending on whether the player is poor or rich.\n\n\nClassic utilitarians such as Bentham (1789), Mill (1861), and Sidgwick\n(1907) interpreted utility as a measure of pleasure or happiness. For\nthese authors, to say \\(A\\) has greater utility than \\(B\\) (for an\nagent or a group of agents) is to say that \\(A\\) results in more\npleasure or happiness than \\(B\\) (for that agent or group of\nagents).\n\n\nOne objection to this interpretation of utility is that there may\nnot be a single good (or indeed any good) which rationality requires us\nto seek. But if we understand \u201cutility\u201d broadly\nenough to include all potentially desirable ends\u2014pleasure,\nknowledge, friendship, health and so on\u2014it\u2019s not clear that\nthere is a unique correct way to make the tradeoffs between different\ngoods so that each outcome receives a utility. There may be no\ngood answer to the question of whether the life of an ascetic monk\ncontains more or less good than the life of a happy libertine\u2014but\nassigning utilities to these options forces us to compare them.\n\n\nContemporary decision theorists typically interpret utility as a\nmeasure of preference, so that to say that \\(A\\) has greater\nutility than \\(B\\) (for an agent) is simply to say that the agent\nprefers \\(A\\) to \\(B\\). It is crucial to this approach\nthat preferences hold not just between outcomes (such as amounts of\npleasure, or combinations of pleasure and knowledge), but also between\nuncertain prospects (such as a lottery that pays $1 million dollars if\na particular coin lands heads, and results in an hour of painful\nelectric shocks if the coin lands tails). Section 2 of this\narticle addresses the formal relationship between preference and choice\nin detail.\n\n\nExpected utility theory does not require that preferences\nbe selfish or self-interested. Someone can prefer giving money to\ncharity over spending the money on lavish dinners, or prefer\nsacrificing his own life over allowing his child to die. Sen\n(1977) suggests that each person\u2019s psychology is best represented\nusing three rankings: one representing the person\u2019s narrow\nself-interest, a second representing the person\u2019s self-interest\nconstrued more broadly to account for feelings of sympathy (e.g.,\nsuffering when watching another person suffer), and a third\nrepresenting the person\u2019s commitments, which may require her to\nact against her self-interest broadly construed.\n\n\nBroome (1991, Ch. 6) interprets utilities as measuring comparisons of\nobjective betterness and worseness, rather than personal preferences:\nto say that \\(A\\) has a greater utility than \\(B\\) is to say that\n\\(A\\) is objectively better than \\(B\\), or that a rational person\nwould prefer \\(A\\) to \\(B\\). Just as there is nothing in the formalism\nof probability theory that requires us to use subjective rather than\nobjective probabilities, so there is nothing in the formalism of\nexpected utility theory that requires us to use subjective rather than\nobjective values.\n\n\nThose who interpret utilities in terms of personal preference face a\nspecial challenge: the so-called problem of interpersonal utility\ncomparisons. When making decisions about how to distribute\nshared resources, we often want to know if our acts would make Alice\nbetter off than Bob\u2014and if so, how much better off. But if\nutility is a measure of individual preference, there is no clear,\nmeaningful way of making these comparisons. Alice\u2019s\nutilities are constituted by Alice\u2019s preferences, Bob\u2019s\nutilities are constituted by Bob\u2019s preferences, and there are no\npreferences spanning Alice and Bob. We can\u2019t assume that\nAlice\u2019s utility 10 is equivalent to Bob\u2019s utility 10, any\nmore than we can assume that getting an A grade in differential\nequations is equivalent to getting an A grade in basket weaving.\n\n\nNow is a good time to consider which features of the utility\nfunction carry meaningful information. Comparisons are\ninformative: if \\(U(o_1) \\gt U(o_2)\\) (for a person), then\n\\(o_1\\) is better than (or preferred to)\n\\(o_2\\). But it is not only comparisons\nthat are informative\u2014the utility function must carry other\ninformation, if expected utility theory is to give meaningful\nresults.\n\n\nTo see why, consider the umbrella example again. This time,\nI\u2019ve filled in a probability for each state, and a utility for each\noutcome.\n\n\n\nstates\n\n\nit rains \\((P = 0.6)\\)\nit does not rain \\((P = 0.4)\\)\n\n\nacts\ntake umbrella\nencumbered, dry \\((U = 5)\\)\nencumbered, dry \\((U = 5)\\)\n\n\nleave umbrella\nwet \\((U = 0)\\)\nfree, dry \\((U =10)\\)\n\n\n\n\nThe expected utility of taking the umbrella is\n\n\\[\n\\begin{align}\nEU(\\take)&= P_{\\take}(\\encumbered, \\dry) \\cdot 5  \\\\\n         & \\quad + P_{\\take}(\\wet) \\cdot 0        \\\\\n         & \\quad + P_{\\take}(\\free, dry) \\cdot 10 \\\\\n         &=5\n\\end{align}\n\\]\n\n\n\nwhile the expected utility of leaving the umbrella is\n\n\\[\n\\begin{align}\nEU(\\leave)&= P_{\\leave}(\\encumbered, \\dry) \\cdot 5  \\\\\n         & \\quad + P_{\\leave}(\\wet) \\cdot 0        \\\\\n         & \\quad + P_{\\leave}(\\free, dry) \\cdot 10 \\\\\n         &=4\n\\end{align}\n\\]\n\n\n\nSince \\(EU(\\take) \\gt EU(\\leave)\\), expected utility theory tells me\nthat taking the umbrella is better than leaving it.\n\n\nBut now, suppose we change the utilities of the outcomes: instead of\nusing \\(U\\), we use \\(U'\\).\n\n\n\nstates\n\n\nit rains \\((P=0.6)\\)\nit does not rain \\((P=0.4)\\)\n\n\nacts\ntake umbrella\nencumbered, dry \\((U'=4)\\)\nencumbered, dry \\((U'=4)\\)\n\n\nleave umbrella\nwet \\((U'=2)\\)\nfree, dry \\((U'=8)\\)\n\n\n\n\nThe new expected utility of taking the umbrella is\n\n\\[\n\\begin{align}\nEU'(\\take)&= P_{\\take}(\\encumbered, \\dry) \\cdot 4  \\\\\n         & \\quad + P_{\\take}(\\wet) \\cdot 2        \\\\\n         & \\quad + P_{\\take}(\\free, dry) \\cdot 8 \\\\\n         &= 4\n\\end{align}\n\\]\n\n\n\nwhile the new expected utility of leaving the umbrella is\n\n\\[\n\\begin{align}\nEU'(\\leave)&= P_{\\leave}(\\encumbered, \\dry) \\cdot 4  \\\\\n         & \\quad + P_{\\leave}(\\wet) \\cdot 2        \\\\\n         & \\quad + P_{\\leave}(\\free, dry) \\cdot 8 \\\\\n         &= 4.4\n\\end{align}\n\\]\n\n\n\nSince \\(EU'(\\take) \\lt EU'(\\leave)\\), expected utility theory tells me\nthat leaving the umbrella is better than taking it.\n\n\nThe utility functions \\(U\\) and \\(U'\\) rank the outcomes\nin exactly the same way: free, dry is best;\nencumbered, dry ranks in the middle; and wet\nis worst. Yet expected utility theory gives different advice in\nthe two versions of the problem. So there must be some\nsubstantive difference between preferences appropriately described by\n\\(U\\), and preferences appropriately described by\n\\(U'\\). Otherwise, expected utility theory is fickle, and\nliable to change its advice when fed different descriptions of the same\nproblem.\n\n\nWhen do two utility functions represent the same basic state of\naffairs? Measurement theory answers the question by characterizing the\nallowable transformations of a utility function\u2014ways of\nchanging it that leave all of its meaningful features intact. If we\ncharacterize the allowable transformations of a utility function, we\nhave thereby specified which of its features are meaningful.\n\n\nDefenders of expected utility theory typically require that utility\nbe measured by a linear scale, where the\nallowable transformations are all and only the positive linear\ntransformations, i.e., functions \\(f\\) of the form\n\n\\[\nf(U(o))=x {\\cdot} U(o)+y\n\\]\n\n\n\nfor real numbers \\(x \\gt 0\\) and \\(y\\).\n\n\nPositive linear transformations of outcome utilities will never\naffect the verdicts of expected utility theory: if \\(A\\) has\ngreater expected utility than \\(B\\) where utility is measured by\nfunction \\(U\\), then \\(A\\) will also have greater expected\nutility than \\(B\\) where utility is measured by any positive\nlinear transformation of \\(U\\). \n2. Arguments for Expected Utility Theory\n\n\nWhy choose acts that maximize expected utility? One possible\nanswer is that expected utility theory is rational bedrock\u2014that\nmeans-end rationality essentially involves maximizing expected\nutility. For those who find this answer unsatisfying, however,\nthere are two further sources of justification. First, there are\nlong-run arguments, which rely on evidence that expected-utility\nmaximization is a profitable policy in the long term. \nSecond, there are arguments based on representation theorems, which\nsuggest that certain rational constraints on preference entail that all\nrational agents maximize expected utility.\n2.1 Long-Run Arguments\n\n\nOne reason for maximizing expected utility is that it makes for good\npolicy in the long run. Feller (1968) gives a version of this\nargument. He relies on two mathematical facts about\nprobabilities: the strong and weak laws of large\nnumbers. Both these facts concern sequences of independent,\nidentically distributed trials\u2014the sort of setup that results\nfrom repeatedly betting the same way on a sequence of roulette spins or\ncraps games. Both the weak and strong laws of large numbers\nsay, roughly, that over the long run, the average amount of utility\ngained per trial is overwhelmingly likely to be close to the expected\nvalue of an individual trial.\n\n\nThe weak law of large numbers states that where each trial has an\nexpected value of \\(\\mu\\), for any arbitrarily small real numbers\n\\(\\epsilon \\gt 0\\) and \\(\\delta \\gt 0\\), there is some finite number of\ntrials \\(n\\), such that for all \\(m\\) greater than or equal\nto \\(n\\), with probability at least \\(1-\\delta\\), the gambler\u2019s\naverage gains for the first \\(m\\) trials will fall within\n\\(\\epsilon\\) of \\(\\mu\\). In other words, in a long run of similar\ngamble, the average gain per trial is highly likely to become\narbitrarily close to the gamble\u2019s expected value within a finite\namount of time. So in the finite long run, the average value\nassociated with a gamble is overwhelmingly likely to be close to its\nexpected value.\n\n\nThe strong law of large numbers states that where each trial has an\nexpected value of \\(\\mu\\), with probability 1, for any arbitrarily small real number \\(\\epsilon \\gt 0\\),as the number of trials increases, the gambler\u2019s average winnings per trial will fall within \\(\\epsilon\\) of\n\\(\\mu\\). In other words, as the number of repetitions of a\ngamble approaches infinity, the average gain per trial will become\narbitrarily close to the gamble\u2019s expected value with probability\n1. So in the long run, the average value associated with a gamble is\nvirtually certain to equal its expected value.\n\n\nThere are several objections to these long run arguments. \nFirst, many decisions cannot be repeated over indefinitely\nmany similar trials. Decisions about which career to pursue, whom\nto marry, and where to live, for instance, are made at best a small\nfinite number of times. Furthermore, where these decisions are\nmade more than once, different trials involve different possible\noutcomes, with different probabilities. It is not clear why\nlong-run considerations about repeated gambles should bear on these\nsingle-case choices.\n\n\nSecond, the argument relies on two independence assumptions, one or\nboth of which may fail. One assumption holds that the\nprobabilities of the different trials are independent. This is\ntrue of casino gambles, but not true of other choices where we wish to\nuse decision theory\u2014e.g., choices about medical treatment. \nMy remaining sick after one course of antibiotics makes it more likely\nI will remain sick after the next course, since it increases the chance\nthat antibiotic-resistant bacteria will spread through my body. The\nargument also requires that the utilities of different trials be\nindependent, so that winning a prize on one trial makes the same\ncontribution to the decision-maker\u2019s overall utility no matter\nwhat she wins on other trials. But this assumption is violated in\nmany real-world cases. Due to the diminishing marginal utility of\nmoney, winning $10 million on ten games of roulette is not worth ten times as\nmuch as winning $1 million on one game of roulette.\n\n\nA third problem is that the strong and weak laws of large numbers are\nmodally weak. Neither law entails that if a gamble were repeated\nindefinitely (under the appropriate assumptions), the average utility\ngain per trial would be close to the game\u2019s expected\nutility. They establish only that the average utility gain per trial\nwould with high probability be close to the game\u2019s expected\nutility. But high probability\u2014even probability 1\u2014is not\ncertainty. (Standard probability theory rejects Cournot\u2019s\nPrinciple, which says events with low or zero probability will\nnot happen.  But see Shafer (2005) for a defense of Cournot\u2019s\nPrinciple.) For any sequence of independent, identically distributed\ntrials, it is possible for the average utility payoff per trial to\ndiverge arbitrarily far from the expected utility of an individual\ntrial.\n2.2 Representation Theorems\n \n\nA second type of argument for expected utility theory relies on\nso-called representation theorems. We follow Zynda\u2019s (2000) formulation\nof this argument\u2014slightly modified to reflect the role of\nutilities as well as probabilities. The argument has three\npremises:\n\nThe Rationality Condition. The axioms of expected\nutility theory are the axioms of rational preference.\n\nRepresentability. If a person\u2019s preferences obey the\naxioms of expected utility theory, then she can be represented as\nhaving degrees of belief that obey the laws of the probability\ncalculus [and a utility function such that she prefers acts with\nhigher expected utility].\n\nThe Reality Condition. If a person can be\nrepresented as having degrees of belief that obey the probability\ncalculus [and a utility function such that she prefers acts with higher\nexpected utility], then the person really has degrees of belief that\nobey the laws of the probability calculus [and really does prefer acts\nwith higher expected utility].\n\n\nThese premises entail the following conclusion.\n\n\nIf a person [fails to prefer acts with higher expected utility], then\nthat person violates at least one of the axioms of rational\npreference.\n\n\nIf the premises are true, the argument shows that there is something\nwrong with people whose preferences are at odds with expected utility\ntheory\u2014they violate the axioms of rational preference. Let\nus consider each of the premises in greater detail, beginning with the\nkey premise, Representability.\n\n\nA probability function and a utility function together\nrepresent a set of preferences just in case the following\nformula holds for all values of \\(A\\) and \\(B\\) in the domain\nof the preference relation\n\n\\[\nEU(A) \\gt EU(B) \\text{ if and only if } A \\text{ is preferred to } B.\n\\]\n\n\n\nMathematical proofs of Representability are called\nrepresentation theorems. Section 2.1 surveys three of\nthe most influential representation theorems, each of which relies on a\ndifferent set of axioms.\n\n\nNo matter which set of axioms we use, the Rationality Condition is\ncontroversial. In some cases, preferences that seem rationally\npermissible\u2014perhaps even rationally required\u2014violate the\naxioms of expected utility theory. Section 3 discusses such cases\nin detail.\n\n\nThe Reality Condition is also controversial. Hampton (1994), Zynda\n(2000), and Meacham and Weisberg (2011) all point out that to be\nrepresentable using a probability and utility function is not\nto have a probability and utility function. After all,\nan agent who can be represented as an expected utility maximizer with\ndegrees of belief that obey the probability calculus, can also be\nrepresented as someone who fails to maximize expected utility with\ndegrees of belief that violate the probability calculus. \nWhy think the expected utility representation is the right one?\n\n\nThere are several options. Perhaps the defender of\nrepresentation theorems can stipulate that what it is to have\nparticular degrees of belief and utilities is just to have the\ncorresponding preferences. The main challenge for defenders of\nthis response is to explain why representations in terms of expected\nutility are explanatorily useful, and why they are better than\nalternative representations. Or perhaps probabilities and utilities are\na good cleaned-up theoretical substitutes for our folk notions of\nbelief and desire\u2014precise scientific substitutes for our folk\nconcepts. Meacham and Weisberg challenge this response, arguing\nthat probabilities and utilities are poor stand-ins for our folk\nnotions. A third possibility, suggested by Zynda, is that facts\nabout degrees of belief are made true independently of the\nagent\u2019s preferences, and provide a principled way to restrict the\nrange of acceptable representations. The challenge for defenders\nof this type of response is to specify what these additional facts\nare.\n\n\nI now turn to consider three influential representation\ntheorems. These representation theorems differ from each other in\nthree of philosophically significant ways. \n\n\nFirst, different representation theorems disagree about the objects\nof preference and utility.  Are they repeatable? Must they be wholly within the agent\u2019s control\n\n\nSecond, representation theorems differ in their treatment of\nprobability. They disagree about which entities have\nprobabilities, and about whether the same objects can have both\nprobabilities and utilities.\n\n\nThird, while every representation theorem proves that for a suitable\npreference ordering, there exist a probability and utility\nfunction representing the preference ordering, they differ how\nunique this probability and utility function are. In\nother words, they differ as to which transformations of the probability\nand utility functions are allowable.\n2.2.1 Ramsey\n\n\nThe idea of a representation theorem for expected utility dates back\nto Ramsey (1926).  (His sketch of a representation theorem is\nsubsequently filled in by Bradley (2004) and Elliott (2017).) Ramsey\nassumes that preferences are defined over a domain of gambles, which\nyield one prize on the condition that a proposition \\(P\\) is true, and\na different prize on the condition that \\(P\\) is false.  (Examples of\ngambles: you receive a onesie if you\u2019re having a baby and a bottle of\nscotch otherwise; you receive twenty dollars if Bojack wins the\nKentucky Derby and lose a dollar otherwise.) \n\n\nRamsey calls a proposition ethically neutral when \u201ctwo possible\nworlds differing only in regard to [its truth] are always of equal\nvalue\u201d.  For an ethically neutral proposition, probability 1/2\ncan be defined in terms of preference: such a proposition has\nprobability 1/2 just in case you are indifferent as to which side of\nit you bet on.  (So if Bojack wins the Kentucky Derby is an\nethically neutral proposition, it has probability 1/2 just in case you\nare indifferent between winning twenty dollars if it\u2019s true and losing\na dollar otherwise, and winning twenty dollars if it\u2019s false and\nlosing a dollar otherwise.) \n\n\nBy positing an ethically neutral proposition with probability 1/2,\ntogether with a rich space of prizes, Ramsey defines numerical\nutilities for prizes.  (The rough idea is that if you are indifferent\nbetween receiving a middling prize \\(m\\) for certain, and a gamble\nthat yields a better prize \\(b\\) if the ethically neutral proposition\nis true and a worse prize \\(w\\) if it is falls, then the utility of\n\\(m\\) is halfway between the utilities of \\(b\\) and \\(w\\).)  Using\nthese numerical utilities, he then exploits the definition of expected\nutility to define probabilities for all other propositions.\n\nThe rough idea is to exploit the richness of the space of prizes,\nwhich ensures that for any gamble \\(g\\) that yields better prize \\(b\\)\nif \\(E\\) is true and worse prize \\(w\\) if \\(E\\) is false, the agent is\nindifferent between \\(g\\) and some middling prize \\(m\\).  This means\nthat \\(EU(g) = EU(m)\\).  Using some algebra, plus the fact that\n\\(EU(g) = P(E)U(b) + (1-P(E))U(w)\\), Ramsey shows that\n\n\\[\nP(E) = \\frac{(1 - U(m)}{(U(b) - U(w))}\n\\]\n\n2.2.2 Von Neumann and Morgenstern\n\n\nVon Neumann and Morgenstern (1944) claim that preferences are defined\nover a domain of lotteries. Some of these lotteries are\nconstant, and yield a single prize with certainty. (Prizes\nmight include a banana, a million dollars, a million dollars\u2019 worth of\ndebt, death, or a new car.)  Lotteries can also have other lotteries\nas prizes, so that one can have a lottery with a 40% chance of\nyielding a banana, and a 60% chance of yielding a 50-50 gamble between\na million dollars and death.) The domain of lotteries is closed under\na mixing operation, so that if \\(L\\) and \\(L'\\) are lotteries and \\(x\\) is a\nreal number in the \\([0, 1]\\) interval, then there is a lottery \\(x L +\n(1-x) L'\\) that yields \\(L\\) with probability \\(x\\) and \\(L'\\) with\nprobability \\(1-x\\). They show that every preference relation obeying\ncertain axioms can be represented by the probabilities used to define\nthe lotteries, together with a utility function which is unique up to\npositive linear transformation.\n2.2.3 Savage\n\n\nInstead of taking probabilities for granted, as von Neumann and\nMorgenstern do, Savage (1972) defines them in terms of preferences\nover acts.  Savage posits three separate domains. Probability attaches\nto events, which we can think of as disjunctions of states,\nwhile utility and intrinsic preference attach to outcomes.\nExpected utility and non-intrinsic preference attach\nto acts. \n\n\nFor Savage, acts, states, and outcomes must satisfy certain\nconstraints.  Acts must be wholly under the agent\u2019s control (so\npublishing my paper in Mind is not an act, since it depends\npartly on the editor\u2019s decision, which I do not control). Outcomes\nmust have the same utility regardless of which state obtains (so \"I\nwin a fancy car\" is not an outcome, since the utility of the fancy car\nwill be greater in states where the person I most want to impress\nwishes I had a fancy car, and less in states where I lose my driver\u2019s\nlicense). No state can rule out the performance of any act, and an act\nand a state together must determine an outcome with certainty. For\neach outcome \\(o\\), there is a constant act which yields \\(o\\) in\nevery state. (Thus, if world peace is an outcome, there is an act that\nresults in world peace, no matter what the state of the world.)\nFinally, he assumes for any two acts \\(A\\) and \\(B\\) and any event\n\\(E\\), there is a mixed act \\(A_E \\amp B_{\\sim E}\\) that yields the\nsame outcome as \\(A\\) if \\(E\\) is true, and the same outcome as \\(B\\)\notherwise. (Thus, if world peace and the end of the world are both\noutcomes, then there is a mixed act that results in world peace if a\ncertain coin lands heads, and the end of the world otherwise.)\n\n\nSavage postulates a preference relation over acts, and gives axioms\ngoverning that preference relation. He then defines subjective\nprobabilities, or degrees of belief, in terms of preferences. The key\nmove is to define an \u201cat least as likely as\u201d relation\nbetween events; I paraphrase here. \n\n\nSuppose \\(A\\) and \\(B\\) are constant acts such that \\(A\\) is preferred\nto \\(B\\). Then \\(E\\) is at least as likely as \\(F\\) just in case the\nagent either prefers \\(A_E \\amp B_{\\sim E}\\) (the act that yields\n\\(A\\) if \\(E\\) obtains, and \\(B\\) otherwise) to \\(A_F \\amp B_{\\sim\nF}\\) (the act that yields \\(A\\) if \\(F\\) obtains, and \\(B\\)\notherwise), or else is indifferent between \\(A_E \\amp B_{\\sim E}\\) and\n\\(A_F \\amp B_{\\sim F}\\).\n\n\n\nThe thought behind the definition is that the agent considers \\(E\\) at\nleast as likely as \\(F\\) just in case she would not rather\nbet on \\(F\\) than on \\(E\\)).\n\n\nSavage then gives axioms constraining rational preference, and shows\nthat any set of preferences satisfying those axioms yields an\n\u201cat least as likely\u201d relation that can be uniquely\nrepresented by a probability function. In other words, there is one\nand only one probability function \\(P\\) such that for all \\(E\\) and \\(F\\),\n\\(P(E) \\ge P(F)\\) if and only if \\(E\\) is at least as likely as \\(F\\). Every\npreference relation obeying Savage\u2019s axioms is represented by this\nprobability function \\(P\\), together with a utility function which is\nunique up to positive linear transformation.\n\n\nSavage\u2019s representation theorem gives strong results: starting\nwith a preference ordering alone, we can find a single probability\nfunction, and a narrow class of utility functions, which represent that\npreference ordering. The downside, however, is that Savage has to\nbuild implausibly strong assumptions about the domain of acts.\n\n\nLuce and Suppes (1965) point out that Savage\u2019s constant acts\nare implausible. (Recall that constant acts yield the same\noutcome and the same amount of value in every state.) Take some\nvery good outcome\u2014total bliss for everyone. Is there really\na constant act that has this outcome in every possible state, including\nstates where the human race is wiped out by a meteor? \nSavage\u2019s reliance on a rich space of mixed acts is also\nproblematic. Savage has had to assume that any two outcomes and\nany event, there is a mixed act that yields the first outcome if the\nevent occurs, and the second outcome otherwise? Is there really an act\nthat yields total bliss if everyone is killed by an\nantibiotic-resistant plague, and total misery otherwise? Luce and\nKrantz (1971) suggest ways of reformulating Savage\u2019s\nrepresentation theorem that weaken these assumptions, but Joyce (1999)\nargues that even on the weakened assumptions, the domain of acts\nremains implausibly rich.\n2.2.4 Bolker and Jeffrey\n\n\nBolker (1966) proves a general representation theorem about\nmathematical expectations, which Jeffrey (1983) uses as the basis for a\nphilosophical account of expected utility theory. Bolker\u2019s\ntheorem assumes a single domain of propositions, which are objects of\npreference, utility, and probability alike. Thus, the proposition that\nit will rain today has a utility, as well as a probability. \nJeffrey interprets this utility as the proposition\u2019s news\nvalue\u2014a measure of how happy or disappointed I would be to\nlearn that the proposition was true. By convention, he sets the\nvalue of the necessary proposition at 0\u2014the necessary proposition\nis no news at all! Likewise, the proposition that I take my\numbrella to work, which is an act, has a probability as well as a\nutility. Jeffrey interprets this to mean that I have degrees of\nbelief about what I will do.\n\n\nBolker gives axioms constraining preference, and shows that any\npreferences satisfying his axioms can be represented by a probability\nmeasure \\(P\\) and a utility measure \\(U\\). However,\nBolker\u2019s axioms do not ensure that \\(P\\) is unique, or that\n\\(U\\) is unique up to positive linear transformation. Nor do\nthey allow us to define comparative probability in terms of\npreference. Instead, where \\(P\\) and \\(U\\) jointly\nrepresent a preference ordering, Bolker shows that the pair\n\\(\\langle P, U \\rangle\\) is unique up to a fractional linear\ntransformation. \n\n\nIn technical terms, where \\(U\\) is a utility function\nnormalized so that \\(U(\\Omega) = 0\\), \\(inf\\) is the\ngreatest lower bound of the values assigned by \\(U\\), \\(sup\\)\nis the least upper bound of the values assigned by by \\(U\\), and\n\\(\\lambda\\) is a parameter falling between \\(-1/inf\\) and\n\\(-1/sup\\), the fractional linear transformation\n\\(\\langle P_{\\lambda}, U_{\\lambda} \\rangle\\) of\n\\(\\langle P, U \\rangle\\) corresponding to \\(\\lambda\\) is given\nby:\n\n\\[\n\\begin{align}\n P_{\\lambda} &= P(x)(1 + \\lambda U(x)) \\\\\n U_{\\lambda} &= U(x)((1+\\lambda)/(1 + \\lambda U(x))\n\\end{align}\n\\]\n\n\n\nNotice that fractional linear transformations of a\nprobability-utility pair can disagree with the original pair about\nwhich propositions are likelier than which others.\n\n\nJoyce (1999) shows that with additional resources, Bolker\u2019s\ntheorem can be modified to pin down a unique \\(P\\), and a\n\\(U\\) that is unique up to positive linear transformation. \nWe need only supplement the preference ordering with a primitive\n\u201cmore likely than\u201d relation, governed by its own set of\naxioms, and linked to belief by several additional axioms. Joyce\nmodifies Bolker\u2019s result to show that given these additional\naxioms, the \u201cmore likely than\u201d relation is represented by a\nunique \\(P\\), and the preference ordering is represented by\n\\(P\\) together with a utility function that is unique up to\npositive linear transformation.\n2.2.5 Summary\n\n\nTogether, these four representation theorems above can be summed up\nin the following table.\n\n\nTheorem\nObjects ofpreference\nOrder ofconstruction\nAllowabletransformations:probability\nAllowabletransformations: utility\n\n\nRamsey\ngambles\npreference \u2192 utility \u2192 probability\nidentity\npositive linear\n\n\nvon\u00a0Neumann/Morgenstern\nlotteries\n(preference & probability) \u2192 utility\nN/A\npositive linear\n\n\nSavage\nacts\npreference \u2192 probability \u2192 utility\nidentity\npositive linear\n\n\nJeffrey/Bolker\npropositions\npreference \u2192 (probability & utility)\n\u2014\u00a0fractional\u00a0linear\u00a0\u2014\n\n\n\n\nNotice that the order of construction differs between theorems: Ramsey\nconstructs a representation of probability using utility, while von\nNeumann and Morgenstern begin with probabilities and construct a\nrepresentation of utility. Thus, although the arrows represent a\nmathematical relationship of representation, they cannot represent a\nmetaphysical relationship of grounding. The Reality Condition needs to\nbe justified independently of any representation theorem.\n\n\nSuitably structured ordinal probabilities (the relations picked out\nby \u201cat least as likely as\u201d, \u201cmore likely than\u201d,\nand \u201cequally likely\u201d) stand in one-to-one correspondence\nwith the cardinal probability functions. Finally, the grey line\nfrom preferences to ordinal probabilities indicates that every\nprobability function satisfying Savage\u2019s axioms is represented by\na unique cardinal probability\u2014but this result does not hold for\nJeffrey\u2019s axioms.\n\n\nNotice that it is often possible to follow the arrows in\ncircles\u2014from preference to ordinal probability, from ordinal\nprobability to cardinal probability, from cardinal probability and\npreference to expected utility, and from expected utility back to\npreference. Thus, although the arrows represent a mathematical\nrelationship of representation, they do not represent a metaphysical\nrelationship of grounding. This fact drives home the importance\n\nof independently justifying the Reality Condition\u2014representation\ntheorems cannot justify expected utility theory without additional\nassumptions.\n3. Objections to Expected Utility Theory\n3.1 Maximizing Expected Utility is Impossible\n\n\nOught implies can, but is it humanly possible to maximize expected\nutility?  March and Simon (1958) point out that in order to compute\nexpected utilities, an agent needs a dauntingly complex understanding\nof the available acts, the possible outcomes, and the values of those\noutcomes, and that choosing the best act is much more demanding than\nchoosing an act that is merely good enough.  Similar points appear in\nLindblom (1959), Feldman (2006), and Smith (2010).\n\n\nMcGee (1991) argues that maximizing expected utility is not\nmathematically possible even for an ideal computer with limitless\nmemory.  In order to maximize expected utility, we would have to\naccept any bet we were offered on the truths of arithmetic, and reject\nany bet we were offered on false sentences in the language of\narithmetic.  But arithmetic is undecidable, so no Turing machine can\ndetermine whether a given arithmetical sentence is true or false.\n\n\nOne response to these difficulties is the\n bounded rationality approach, which\naims to replace expected utility theory with some more tractable\nrules.  Another is to argue that the demands of expected utility\ntheory are more tractable than they appear (Burch-Brown 2014; see also\nGreaves 2016), or that the relevant \u201cought implies can\u201d\nprinciple is false (Srinivasan 2015).\n3.2 Maximizing Expected Utility is Irrational\n\n\nA variety of authors have given examples in which expected utility\ntheory seems to give the wrong prescriptions. Sections 3.2.1 and 3.2.2 discuss\nexamples where rationality seems to permit preferences inconsistent\nwith expected utility theory. These examples suggest that\nmaximizing expected utility is not necessary for\nrationality. Section 3.2.3 discusses examples where expected\nutility theory permits preferences that seem irrational. These\nexamples suggest that maximizing expected utility is not\nsufficient for rationality. Section 3.2.4 discusses an\nexample where expected utility theory requires preferences that seem\nrationally forbidden\u2014a challenge to both the necessity and the\nsufficiency of expected utility for rationality.\n3.2.1 Counterexamples Involving Transitivity and Completeness\n\n\nExpected utility theory implies that the structure of preferences\nmirrors the structure of the greater-than relation between real\nnumbers. Thus, according to expected utility theory, preferences\nmust be transitive: If \\(A\\) is preferred to \\(B\\)\n(so that \\(U(A) \\gt U(B)\\)), and\n\\(B\\) is preferred to \\(C\\) (so that \\(U(B)\n\\gt U(C)\\)), then \\(A\\) must be preferred to\n\\(C\\) (since it must be that \\(U(A) \\gt U(C)\\)).\nLikewise, preferences must be\ncomplete: for any two options, either one must be preferred to\nthe other, or the agent must be indifferent between them (since of\ntheir two utilities, either one must be greater or the two must be\nequal). But there are cases where rationality seems to permit (or\nperhaps even require) failures of transitivity and failures of\ncompleteness.\n\n\nAn example of preferences that are not transitive, but nonetheless\nseem rationally permissible, is Quinn\u2019s puzzle of the\nself-torturer (1990). The self-torturer is hooked up to a machine\nwith a dial with settings labeled 0 to 1,000, where setting 0 does\nnothing, and each successive setting delivers a slightly more powerful\nelectric shock. Setting 0 is painless, while setting 1,000 causes\nexcruciating agony, but the difference between any two adjacent\nsettings is so small as to be imperceptible. The dial is fitted\nwith a ratchet, so that it can be turned up but never down. \nSuppose that at each setting, the self-torturer is offered $10,000 to\nmove up to the next, so that for tolerating setting \\(n\\), he\nreceives a payoff of \\(n {\\cdot} {$10,000}\\). It is permissible for the\nself-torturer to prefer setting \\(n+1\\) to setting \\(n\\) for\neach \\(n\\) between 0 and 999 (since the difference in pain is\nimperceptible, while the difference in monetary payoffs is\nsignificant), but not to prefer setting 1,000 to setting 0\n(since the pain of setting 1,000 may be so unbearable that no amount of\nmoney will make up for it.\n\n\nIt also seems rationally permissible to have incomplete\npreferences. For some pairs of actions, an agent may have no\nconsidered view about which she prefers. Consider Jane, an\nelectrician who has never given much thought to becoming a professional\nsinger or a professional astronaut. (Perhaps both of these\noptions are infeasible, or perhaps she considers both of them much\nworse than her steady job as an electrician). It is false that\nJane prefers becoming a singer to becoming an astronaut, and it is\nfalse that she prefers becoming an astronaut to becoming a\nsinger. But it is also false that she is indifferent between\nbecoming a singer and becoming an astronaut. She prefers becoming\na singer and receiving a $100 bonus to becoming a singer, and if she\nwere indifferent between becoming a singer and becoming an astronaut,\nshe would be rationally compelled to prefer being a singer and\nreceiving a $100 bonus to becoming an astronaut.\n\n\nThere is one key difference between the two examples considered\nabove. Jane\u2019s preferences can be extended, by\nadding new preferences without removing any of the ones she has, in a\nway that lets us represent her as an expected utility maximizer. \nOn the other hand, there is no way of extended the\nself-torturer\u2019s preferences so that he can be represented as an\nexpected utility maximizer. Some of his preferences would have to\nbe altered. One popular response to incomplete preferences is to\nclaim that, while rational preferences need not satisfy the axioms of a\ngiven representation theorem (see section 2.2), it must be possible to\nextend them so that they satisfy the axioms. From this weaker\nrequirement on preferences\u2014that they be extendible to a\npreference ordering that satisfies the relevant axioms\u2014one can\nprove the existence halves of the relevant representation\ntheorems. However, one can no longer establish that each\npreference ordering has a representation which is unique up to\nallowable transformations.\n\n\nNo such response is available in the case of the self-torturer,\nwhose preferences cannot be extended to satisfy the axioms of expected\nutility theory. See the entry on\n preferences\n for a more extended discussion of the self-torturer case.\n3.2.2 Counterexamples Involving Independence\n\n\nAllais (1953) and Ellsberg (1961) propose examples of preferences that\ncannot be represented by an expected utility function, but that\nnonetheless seem rational. Both examples involve violations of\nSavage\u2019s Independence axiom:\n\n\nIndependence. Suppose that \\(A\\) and \\(A^*\\) are two\nacts that produce the same outcomes in the event that \\(E\\) is\nfalse. Then, for any act \\(B\\), one must have\n\n\n\n\\(A\\) is preferred\nto \\(A^*\\) if and only if \\(A_E \\amp B_{\\sim E}\\)\nis preferred to \\(A^*_E \\amp B_{\\sim E}\\)\n\n\nThe agent is\nindifferent between \\(A\\) and \\(A^*\\) if and only if she is\nindifferent between \n\\(A_E \\amp B_{\\sim E}\\) and \\(A^*_E \\amp B_{\\sim E}\\)\n\n\n\n\n\nIn other words, if two acts have the same consequences whenever\n\\(E\\) is false, then the agent\u2019s preferences between those\ntwo acts should depend only on their consequences when \\(E\\) is\ntrue. On Savage\u2019s definition of expected utility, expected\nutility theory entails Independence. And on Jeffrey\u2019s\ndefinition, expected utility theory entails Independence in the\npresence of the assumption that the states are probabilistically\nindependent of the acts.\n\n\nThe first counterexample, the Allais Paradox, involves two separate\ndecision problems in which a ticket with a number between 1 and 100 is\ndrawn at random. In the first problem, the agent must choose\nbetween these two lotteries:\n\n\nLottery \\(A\\)\n\n\u2022\n$100 million with certainty\n\n\n\n\nLottery \\(B\\)\n\n\n\u2022\n$500 million if one of tickets 1\u201310 is drawn\n\n\n\n\u2022\n$100 million if one of tickets 12\u2013100 is drawn\n\n\n\n\u2022\nNothing if ticket 11 is drawn\n\n\n\nIn the second decision problem, the agent must choose between these\ntwo lotteries:\n\n\nLottery \\(C\\)\n\n\u2022\n$100 million if one of tickets 1\u201311 is drawn\n\n\n\u2022\nNothing otherwise\n\n\n\n\nLottery \\(D\\)\n\n\u2022\n$500 million if one of tickets 1\u201310 is drawn\n\n\n\u2022\nNothing otherwise\n\n\n\n\nIt seems reasonable to prefer \\(A\\) (which offers a sure $100\nmillion) to \\(B\\) (where the added 10% chance at $500 million is\nmore than offset by the risk of getting nothing). It also seems\nreasonable to prefer \\(D\\) (an 10% chance at a $500 million prize)\nto \\(C\\) (a slightly larger 11% chance at a much smaller $100\nmillion prize). But together, these preferences (call them the\nAllais preferences) violate Independence. Lotteries\n\\(A\\) and \\(C\\) yield the same $100 million prize for\ntickets 12\u2013100. They can be converted into lotteries \\(B\\)\nand \\(D\\) by replacing this $100 million prize with $0.\n\n\nBecause they violate Independence, the Allais preferences are\nincompatible with expected utility theory. This incompatibility does\nnot require any assumptions about the relative utilities of the $0,\nthe $100 million, and the $500 million. Where $500 million has\nutility \\(x\\), $100 million has utility \\(y\\), and $0 has utility \\(z\\),\nthe expected utilities of the lotteries are as follows.\n\n\\[\n\\begin{align}\n EU(A) &= 0.11y + 0.89y \\\\\n EU(B) &= 0.10x + 0.01z + 0.89y \\\\\n EU(C) &= 0.11y + 0.89z \\\\\n EU(D) &= 0.10x + 0.01z + 0.89z\n\\end{align}\n\\]\n\n\n\nIt is easy to see that the condition under which \\(EU(A) \\gt EU(B)\\) is\nexactly the same as the condition under which \\(EU(C) \\gt EU(D)\\): both\ninequalities obtain just in case \\(0.11y \\gt 0.10x +\n0.01z\\) \n\n\nThe Ellsberg Paradox also involves two decision problems that generate\na violation of the sure-thing principle. In each of them, a ball is\ndrawn from an urn containing 30 red balls, and 60 balls that are\neither white or yellow in unknown proportions. In the first decision\nproblem, the agent must choose between the following lotteries:\n\n\nLottery \\(R\\)\n\n\u2022\nWin $100 if a red ball is drawn\n\n\n\u2022\nLose $100 otherwise\n\n\n\n\nLottery \\(W\\)\n\n\u2022\nWin $100 if a white ball is drawn\n\n\n\u2022\nLose $100 otherwise\n\n\n\nIn the second decision problem, the agent must choose between the\nfollowing lotteries:\n\n\nLottery \\(RY\\)\n\n\u2022\nWin $100 if a red or yellow ball is drawn\n\n\n\u2022\nLose $100 otherwise\n\n\n\n\nLottery \\(WY\\)\n\n\u2022\nWin $100 if a white or yellow ball is drawn\n\n\n\u2022\nLose $100 otherwise\n\n\n\n\nIt seems reasonable to prefer \\(R\\) to \\(W\\), but at the same time prefer\n\\(WY\\) to \\(RY\\). (Call this combination of preferences the Ellsberg\npreferences.)  Like the Allais preferences, the Ellsberg\npreferences violate Independence. Lotteries\n\\(W\\) and \\(R\\) yield a $100 loss if a yellow ball is\ndrawn; they can be converted to lotteries \\(RY\\) and \\(WY\\)\nsimply by replacing this $100 loss with a sure $100 gain.\n\n\nBecause they violate independence, the Ellsberg preferences are\nincompatible with expected utility theory. Again, this incompatibility\ndoes not require any assumptions about the relative utilities of\nwinning $100 and losing $100. Nor do we need any assumptions about where\nbetween 0 and 1/3 the probability of drawing a yellow ball\nfalls. Where winning $100 has utility \\(w\\) and losing $100 has\nutility \\(l\\),\n\n\\[\n\\begin{align}\n EU(R) &= \\tfrac{1}{3} w + P(W)l + P(Y)l \\\\\n EU(W) &= \\tfrac{1}{3} l + P(W)w + P(Y)l \\\\\n EU(RY)&= \\tfrac{1}{3} w + P(W)l + P(Y)w \\\\\n EU(WY)&= \\tfrac{1}{3} l + P(W)w + P(Y)w\n\\end{align}\n\\]\n\n\n\nIt is easy to see that the condition in which \n\\(EU(R) \\gt EU(W)\\) is exactly the same as the condition\nunder which \n\\(EU(RY) \\gt EU(WY)\\):\nboth inequalities obtain just in case \n\\(1/3\\,w + P(W)l \\gt 1/3\\,l + P(W)w\\).\n\n \n\nThere are three notable responses to the Allais and Ellsberg\nparadoxes. First, one might follow Savage (101 ff) and Raiffa (1968,\n80\u201386), and defend expected utility theory on the grounds that\nthe Allais and Ellsberg preferences are irrational. \n \n\nSecond, one might follow Buchak (2013) and claim that that the\nAllais and Ellsberg preferences are rationally permissible, so that\nexpected utility theory fails as a normative theory of\nrationality. Buchak develops an a more permissive theory of\nrationality, with an extra parameter representing the decision-maker\u2019s\nattitude toward risk. This risk parameter interacts with the utilities\nof outcomes and their conditional probabilities on acts to determine\nthe values of acts. One setting of the risk parameter yields expected\nutility theory as a special case, but other, \u201crisk-averse\u201d\nsettings rationalise the Allais preferences.\n\n\nThird, one might follow Loomes and Sugden (1986), Weirich (1986),\nand Pope (1995) and argue that the outcomes in the Allais and Ellsberg\nparadoxes can be re-described to accommodate the Allais and Ellsberg\npreferences. The alleged conflict between the Allais and Ellsberg\npreferences on the one hand, and expected utility theory on the other,\nwas based on the assumption that a given sum of money has the same\nutility no matter how it is obtained. Some authors challenge this\nassumption. Loomes and Sugden suggest that in addition to monetary\namounts, the outcomes of the gambles include feelings of disappointment\n(or elation) at getting less (or more) than expected. Pope\ndistinguishes \u201cpost-outcome\u201d feelings of elation or\ndisappointment from \u201cpre-outcome\u201d feelings of excitement,\nfear, boredom, or safety, and points out that both may affect outcome\nutilities. Weirich suggests that the value of a monetary sum\ndepends partly on the risks that went into obtaining it, irrespective\nof the gambler\u2019s feelings, so that (for instance) $100 million as\nthe result of a sure bet is more than $100 million from a gamble that\nmight have paid nothing. \n\n\nBroome (1991, Ch. 5) raises a worry about this re-description\nsolution. Any preferences can be justified by re-describing\nthe space of outcomes, thus rendering the axioms of expected utility\ntheory devoid of content. Broome rebuts this objection by suggesting\nan additional constraint on preference: if \\(A\\) is preferred to\n\\(B\\), then \\(A\\) and \\(B\\) must differ in some way that justifies\npreferring one to the other. An expected utility theorist can then\ncount the Allais and Ellsberg preferences as rational if, and only if,\nthere is a non-monetary difference that justifies placing outcomes of\nequal monetary value at different spots in one\u2019s preference\nordering.\n3.2.3 Counterexamples Involving Probability 0 Events\n\n\nAbove, we\u2019ve seen purported examples of rational preferences\nthat violate expected utility theory. There are also\npurported examples of irrational preferences that satisfy expected\nutility theory.\n\n\nOn a typical understanding of expected utility theory, when two acts\nare tied for having the highest expected utility, agents are required\nto be indifferent between them. Skyrms (1980, p. 74) points out\nthat this view lets us derive strange conclusions about events with\nprobability 0. For instance, suppose you are about to throw a\npoint-sized dart at a round dartboard. Classical probability\ntheory countenances situations in which the dart has probability 0 of\nhitting any particular point. You offer me the following lousy\ndeal: if the dart hits the board at its exact center, then you will\ncharge me $100; otherwise, no money will change hands. My\ndecision problem can be captured with the following matrix:\n\n\n\nstates\n\n\nhit center (\\(P=0\\))\nmiss center (\\(P=1\\))\n\n\nacts\naccept deal\n\\(-100\\)\n\\(0\\)\n\n\nrefuse deal\n\\(0\\)\n\\(0\\)\n\n\n\n\nExpected utility theory says that it is permissible for me to accept\nthe deal\u2014accepting has expected utility of 0. (This is so on\nboth the Jeffrey definition and the Savage definition, if we assume\nthat how the dart lands is probabilistically independent of how you\nbet.) But common sense says it is not permissible for me to accept the\ndeal. Refusing weakly dominates accepting: it yields a better\noutcome in some states, and a worse outcome in no state. \n\n\nSkyrms suggests augmenting the laws of classical probability with an\nextra requirement that only impossibilities are assigned probability 0.\nEaswaran (2014) argues that we should instead reject the view that\nexpected utility theory commands indifference between acts with equal\nexpected utility. Instead, expected utility theory is not a\ncomplete theory of rationality: when two acts have the same expected\nutility, it does not tell us which to prefer. We can use\nnon-expected-utility considerations like weak dominance as\ntiebreakers.\n3.2.4 Counterexamples Involving Unbounded Utility\n\n\nA utility function \\(U\\) is bounded above if there is a limit to how\ngood things can be according to \\(U\\), or more formally, if there is\nsome least natural number \\(sup\\) such that for every \\(A\\) in \\(U\\)\u2019s\ndomain, \\(U(A) \\le sup\\). Likewise, \\(U\\) is bounded below if there is a\nlimit to how bad things can be according to \\(U\\), or more formally, if\nthere is some greatest natural number \\(inf\\) such that for every\n\\(A\\) in \\(U\\)\u2019s domain, \\(U(A) \\ge inf\\). Expected utility\ntheory can run into trouble when utility functions are unbounded\nabove, below, or both.\n\n\nOne problematic example is the St. Petersburg game, originally\npublished by Bernoulli. Suppose that a coin is tossed until it lands\ntails for the first time. If it lands tails on the first toss, you win\n$2; if it lands tails on the second toss, you win $4; if it lands\ntails on the third toss, you win $8, and if it lands tails on the\n\\(n\\)th toss, you win $\\(2^n\\). Assuming each dollar is worth one\nutile, the expected value of the St Petersburg game is\n\n\\[\n(\\tfrac{1}{2} \\cdot 2) + (\\tfrac{1}{4} \\cdot 4) + (\\tfrac{1}{8} \\cdot 8) + \\cdots \n  + (\\tfrac{1}{2^n} \\cdot 2^n) + \\cdots\n\\]\n\nor\n\n\\[\n 1 + 1 + 1 + \\cdots = \\infty\n\\]\n\n\n\nIt turns out that this sum diverges; the St Petersburg game has\ninfinite expected utility. Thus, according to expected utility\ntheory, you should prefer the opportunity to play the St Petersburg\ngame to any finite sum of money, no matter how large. \nFurthermore, since an infinite expected utility multiplied by any\nnonzero chance is still infinite, anything that has a positive\nprobability of yielding the St Petersburg game has infinite expected\nutility. Thus, according to expected utility theory, you should\nprefer any chance at playing the St Petersburg game, however\nslim, to any finite sum of money, however large.\n\n\nNover and H\u00e1jek (2004) argue that in addition to the\nSt. Petersburg game, which has infinite expected utility, there are\nother infinitary games whose expected utilities are undefined, even\nthough rationality mandates certain preferences among them.\n\n\nOne response to these problematic infinitary games is to argue that\nthe decision problems themselves are ill-posed (Jeffrey (1983, 154);\nanother is to adopt a modified version of expected utility theory that\nagrees with its verdicts in the ordinary case, but yields intuitively\nreasonable verdicts about the infinitary games (Thalos and Richardson\n2013) (Fine 2008) (Colyvan 2006, 2008) (Easwaran 2008).\n4. Applications\n4.1 Economics and Public Policy\n\n\nIn the 1940s and 50s, expected utility theory gained currency in the\nUS for its potential to provide a mechanism that would explain the\nbehavior of macro-economic variables.  As it became apparent that\nexpected utility theory did not accurately predict the behaviors of\nreal people, its proponents instead advanced the view that it might\nserve instead as a theory of how rational people should respond to\nuncertainty (see Herfeld 2017).\n\n\nExpected utility theory has a variety of applications in public\npolicy. In welfare economics, Harsanyi (1953) reasons from expected\nutility theory to the claim that the most socially just arrangement is\nthe one that maximizes total welfare distributed across a society\nsociety.  The theory of expected utility also has more direct\napplications.  Howard (1980) introduces the concept of\na micromort, or a one-in-a-million chance of death, and uses\nexpected utility calculations to gauge which mortality risks are\nacceptable.  In health policy, quality-adjusted life years, or QALYs,\nare measures of the expected utilities of different health\ninterventions used to guide health policy (see Weinstein et al\n2009). McAskill (2015) uses expected utility theory to address the\ncentral question of effective altruism: \u201cHow can I do\nthe most good?\u201d (Utilties in these applications are most\nnaturally interpreted as measuring something like happiness or\nwellbeing, rather than subjective preference satisfaction for an\nindividual agent.)\n\n\nAnother area where expected utility theory finds applications is in\ninsurance sales. Like casinos, insurance companies take on\ncalculated risks with the aim of long-term financial gain, and must\ntake into account the chance of going broke in the short run.\n4.2 Ethics\n\n\nUtilitarians, along with their descendants contemporary\nconsequentialists, hold that the rightness or wrongness of an act is\ndetermined by the moral goodness or badness of its consequences.  Some\nconsequentialists, such as (Railton 1984), interpret this to mean that\nwe ought to do whatever will in fact have the best consequences. But\nit is difficult\u2014perhaps impossible\u2014to know the long-term\nconsequences of our acts (Lenman 2000, Howard-Snyder 2007).  In light\nof this observation, Jackson (1991) argues that the right act is the\none with the greatest expected moral value, not the one that will in\nfact yield the best consequences.\n\n\nAs Jackson notes, the expected moral value of an act depends on\nwhich probability function we work with. Jackson argues that,\nwhile every probability function is associated with an\n\u201cought\u201d, the \u201cought\u201d that matters most to\naction is the one associated with the decision-maker\u2019s degrees of\nbelief at the time of action. Other authors claim priority for\nother \u201coughts\u201d: Mason (2013) favors the probability\nfunction that is most reasonable for the agent to adopt in response to\nher evidence, given her epistemic limitations, while Oddie and Menzies\n(1992) favor the objective chance function as a measure of objective\nrightness. (They appeal to a more complicated probability\nfunction to define a notion of \u201csubjective rightness\u201d for\ndecisionmakers who are ignorant of the objective chances.)\n\n\nStill others (Smart 1973, Timmons 2002) argue that even if that we\nought to do whatever will have the best consequences, expected utility\ntheory can play the role of a decision procedure when we are uncertain\nwhat consequences our acts will have. Feldman (2006) objects that\nexpected utility calculations are horribly impractical. In most\nreal life decisions, the steps required to compute expected utilities\nare beyond our ken: listing the possible outcomes of our acts,\nassigning each outcome a utility and a conditional probability given\neach act, and performing the arithmetic necessary to expected utility\ncalculations.\n\nThe expected-utility-maximizing version of consequentialism is not\nstrictly speaking a theory of rational choice. It is a theory\nof moral choice, but whether rationality requires us to do what is\nmorally best is up for debate.\n\n4.3 Epistemology\n\n\nExpected utility theory can be used to address practical questions\nin epistemology. One such question is when to accept a\nhypothesis. In typical cases, the evidence is logically\ncompatible with multiple hypotheses, including hypotheses to which it\nlends little inductive support. Furthermore, scientists do not\ntypically accept only those hypotheses that are most probable given\ntheir data. When is a hypothesis likely enough to deserve\nacceptance?\n\n\nBayesians, such as Maher (1993), suggest that this decision be made\non expected utility grounds. Whether to accept a hypothesis is a\ndecision problem, with acceptance and rejection as acts. It can\nbe captured by the following decision matrix:\n\n\n\nstates\n\n\nhypothesis is true\nhypothesis is false\n\n\nacts\naccept\ncorrectly accept\nerroneously accept\n\n\nreject\nerroneously reject\ncorrectly reject\n\n\n\n\nOn Savage\u2019s definition, the expected utility of accepting the\nhypothesis is determined by the probability of the hypothesis, together\nwith the utilities of each of the four outcomes. (We can expect\nJeffrey\u2019s definition to agree with Savage\u2019s on the\nplausible assumption that, given the evidence in our possession, the\nhypothesis is probabilistically independent of whether we accept or\nreject it.) Here, the utilities can be understood as purely\nepistemic values, since it is epistemically valuable to believe\ninteresting truths, and to reject falsehoods.\n\n\nCritics of the Bayesian approach, such as Mayo (1996), object that\nscientific hypotheses cannot sensibly be given probabilities. \nMayo argues that in order to assign a useful probability to an event,\nwe need statistical evidence about the frequencies of similar\nevents. But scientific hypotheses are either true once and for\nall, or false once and for all\u2014there is no population of worlds\nlike ours from which we can meaningfully draw statistics. Nor can\nwe use subjective probabilities for scientific purposes, since this\nwould be unacceptably arbitrary. Therefore, the expected\nutilities of acceptance and rejection are undefined, and we ought to\nuse the methods of traditional statistics, which rely on comparing the\nprobabilities of our evidence conditional on each of the\nhypotheses.\n\n\nExpected utility theory also provides guidance about when to gather\nevidence. Good (1967) argues on expected utility grounds that it is\nalways rational to gather evidence before acting, provided that\nevidence is free of cost. The act with the highest expected utility\nafter the extra evidence is in will always be always at least as good\nas the act with the highest expected utility beforehand. \n\n\nIn epistemic decision theory, expected utilities are used to\nassess belief states as rational or irrational. If we think of belief\nformation as a mental act, facts about the contents of the agent\u2019s\nbeliefs as events, and closeness to truth as a desirable feature of\noutcomes, then we can use expected utility theory to evaluate degrees\nof belief in terms of their expected closeness to truth.  The entry\non epistemic utility arguments for\nprobabilism includes an overview of expected utility arguments for\na variety of epistemic norms, including conditionalization and the\nPrincipal Principle.\n\n4.4 Law\n\n\nKaplan (1968), argues that expected utility considerations can be used\nto fix a standard of proof in legal trials.  A jury deciding whether\nto acquit or convict faces the following decision problem:\n\n\n\nstates\n\n\nguilty\ninnocent\n\n\nacts\nconvict\ntrue conviction\nfalse conviction\n\n\nacquit\nfalse acquittal\ntrue acquittal\n\n\n\nKaplan shows that \\(EU(convict) > EU(acquit)\\) whenever \n\n\\[ P(guilty) > \\frac{1}{1+\n\\frac{U(\\mathrm{true~conviction})-U(\\mathrm{false~acquittal})}{U(\\mathrm{true~acquittal})-U(\\mathrm{false~conviction})}}\n\\]\n\n\n\nQualitatively, this means that the standard of proof increases as the\ndisutility of convicting an innocent person\n\\((U(\\mathrm{true~conviction})-U(\\mathrm{false~acquittal}))\\)\nincreases, or as the disutility of acquitting a guilty person\n\\((U(\\mathrm{true~acquittal})-U(\\mathrm{false~conviction}))\\)\ndecreases.\n\n\nCritics of this decision-theoretic approach, such as Laudan (2006),\nargue that it\u2019s difficult or impossible to bridge the gap between the\nevidence admissible in court, and the real probability of the\ndefendant\u2019s guilt. The probability guilt depends on three factors: the\ndistribution of apparent guilt among the genuinely guilty, the\ndistribution of apparent guilt among the genuinely innocent, and the\nratio of genuinely guilty to genuinely innocent defendants who go to\ntrial (see Bell 1987).  Obstacles to calculating any of these factors\nwill block the inference from a judge or jury\u2019s perception of apparent\nguilt to a true probability of guilt.\n", "bibliography": {"categories": [], "cat_ref_text": {"ref_list": ["Allais M., 1953, \u201cLe Comportement de l\u2019Homme Rationnel devant\nle Risque: Critique des Postulats et Axiomes de l\u2019\u00c9cole\nAmericaine\u201d, <em>Econometrica</em>, 21: 503\u2013546.", "Bell, R., 1987, \u201cDecision Theory and Due Process: A Critique\nof the Supreme Court\u2019s Lawmaking for Burdens of\nProof\u201d, <em>Journal of Criminal Law and Criminology</em>, 78:\n557-585.", "Bentham, J., 1961. An Introduction to the Principles of Morals and\nLegislation, Garden City: Doubleday. Originally published in 1789.", "Bernoulli, D., 1738, \u201cSpecimen theoriae novae de mensura\nsortis\u201d, <em>Commentarii Academiae Scientiarum Imperialis\nPetropolitanae</em> 5. Translated by Louise Somer and reprinted\nas \u201cExposition of a New Theory on the Measurement of Risk\u201d\n1954, <em>Econometrica</em>, 22: 23\u201336.", "Bolker, E., 1966, \u201cFunctions Resembling Quotients of\nMeasures\u201d, <em>Transactions of the American Mathematical\nSociety</em>, 2: 292\u2013312.", "Bradley, R., 2004, \u201cRamsey\u2019s representation\ntheorem\u201d, <em>Dialectica</em>, 58: 483\u2013497.", "Broome, J., 1991, <em>Weighing Goods: Equality, Uncertainty and\nTime</em>, Oxford: Blackwell, doi:10.1002/9781119451266", "Burch-Brown, J.M., 2014, \u201cClues for\nConsequentialists\u201d, <em>Utilitas</em>, 26: 105-119.", "Buchak, L., 2013, <em>Risk and Rationality</em>, Oxford: Oxford\nUniversity Press.", "Colyvan, M., 2006, \u201cNo Expectations\u201d, <em>Mind</em>,\n116: 695\u2013702.", "Colyvan, M., 2008, \u201cRelative Expectation Theory\u201d,\n<em>Journal of Philosophy</em>, 105: 37\u201344.", "Easwaran, K., 2014, \u201cRegularity and Hyperreal\nCredences\u201d, <em>The Philosophical Review</em>, 123:\n1\u201341.", "Easwaran, K., 2008, \u201cStrong and Weak Expectations\u201d,\n<em>Mind</em>, 117: 633\u2013641.", "Elliott, E., 2017, \u201cRamsey without Ethical Neutrality: A New\nRepresentation Theorem\u201d, <em>Mind</em>, 126: 1-51.", "Ellsberg, D., 1961, \u201cRisk, Ambiguity, and the Savage\nAxioms\u201d, <em>Quarterly Journal of Economics</em>, 75:\n643\u2013669.", "Feldman, F. 2006, \u201cActual utility, the objection from\nimpracticality, and the move to expected utility\u201d,\n<em>Philosophical Studies</em>, 129 : 49\u201379.", "Fine, T., 2008, \u201cEvaluating the Pasadena, Altadena, and St\nPetersburg Gambles\u201d, <em>Mind</em>, 117: 613\u2013632.", "Good, I.J., 1967, \u201cOn the Principle of Total Evidence\u201d,\n<em>The British Journal for the Philosophy of Science</em>, 17:\n319\u2013321", "Greaves, H. 2016, \u201cCluelessness\u201d, <em>Proceedings of\nthe Aristotelian Society</em>, 116: 311-339.", "Hampton, J., \u201cThe Failure of Expected-Utility Theory as a\nTheory of Reason\u201d, <em>Economics and Philosophy</em>, 10:\n195\u2013242.", "Harsanyi, J.C., 1953, \u201cCardinal utility in welfare economics\nand in the theory of risk-taking\u201d, <em>Journal of Political\nEconomy</em>, 61: 434\u2013435.", "Herfeld, C., \u201cFrom Theories of Human Behavior to Rules of\nRational Choice: Tracing a Normative Turn at the Cowles Commission,\n1943-1954\u201d, <em>History of Political Economy</em>, 50:\n1-48.", "Howard, R.A., 1980, \u201cOn Making Life and Death\nDecisions\u201d, in R.C. Schwing and W.A. Albers, <em>Societal Risk\nAssessment: How Safe is Safe Enough?</em>, New York: Plenum\nPress.", " Howard-Snyder, F., 1997, \u201cThe Rejection of Objective\nConsequentialism\u201d, <em>Utilitas</em>, 9: 241\u2013248.", "Jackson, F., 1991, \u201cDecision-theoretic consequentialism and\nthe nearest and dearest objection\u201d, <em>Ethics</em>, 101:\n461\u2013482.", "Jeffrey, R., 1983, <em>The Logic of Decision</em>, 2<sup>nd</sup>\nedition, Chicago: University of Chicago Press.", "Jevons, W.S., 1866, \u201cA General Mathematical Theory of\nPolitical Economy\u201d, <em>Journal of the Royal Statistical\nSociety</em>, 29: 282\u2013287.", "Joyce, J., 1999, <em>The Foundations of Causal Decision\nTheory</em>, Cambridge: Cambridge University Press.", "Kahneman, D. &amp; Tversky A., <em>Judgment Under Uncertainty:\nHeuristics and Biases</em>, New York: Cambridge University Press.", "Kaplan, J., 1968, \u201cDecision Theory and the Factfinding\nProcess\u201d, <em>Stanford Law Review</em>, 20: 1065-1092. ", "Kolmogorov, A. N., 1933, <em>Grundbegriffe der\nWahrscheinlichkeitrechnung, Ergebnisse Der Mathematik</em>; translated\nas <em>Foundations of Probability</em>, New York: Chelsea Publishing\nCompany, 1950.", "Laudan, L., 2006, <em>Truth, Error, and Criminal Law</em>,\nCambridge: Cambridge University Press.", "Lenman, J., 2000. \u201cConsequentialism and\ncluelessness\u201d, <em>Philosophy and Public Affairs</em>, 29(4):\n342\u2013370.", "Lewis, D., 1981, \u201cCausal Decision Theory\u201d,\n<em>Australasian Journal of Philosophy</em>, 59: 5\u201330.", "Levi, I., 1991, \u201cConsequentialism and Sequential\nChoice\u201d, in M. Bacharach and S. Hurley (eds.), <em>Foundations of\nDecision Theory</em>, Oxford: Basil Blackwell Ltd, 92\u201312.", "Lindblom, C.E., 1959, \u201cThe Science of \u2018Muddling\nThrough\u2019\u201d, <em>Public Administration Review</em>, 19:\n79\u201388.", "Loomes, G. And Sugden, R., 1986, \u201cDisappointment and Dynamic\nConsistency in Choice Under Uncertainty\u201d, <em>The Review of\nEconomic Studies</em>, 53(2): 271\u2013282.", "Maher, P., 1993, <em>Betting on Theories</em>, Cambridge: Cambridge\nUniversity Press.", "March, J.G. and Simon, H., 1958, <em>Organizations</em>, New York:\nWiley.", "Mason, E., 2013, \u201cObjectivism and Prospectivism About\nRightness\u201d, <em>Journal of Ethics and Social Philosophy</em>, 7:\n1\u201321.", "Mayo, D., 1996, <em>Error and the Growth of Experimental\nKnowledge</em>, Chicago: University of Chicago Press.", "McAskill, W., 2015, <em>Doing Good Better</em>, New York: Gotham\nBooks.", "McGee, V., 1991, \u201cWe Turing Machines Aren\u2019t Expected-Utility\nMaximizers (Even Ideally)\u201d, <em>Philosophical Studies</em>, 64:\n115-123.", "Meacham, C. and Weisberg, J., 2011, \u201cRepresentation Theorems\nand the Foundations of Decision Theory\u201d, <em>Australasian Journal\nof Philosophy</em>, 89: 641\u2013663.", "Menger, K., 1871, <em>Grunds\u00e4tze der\nVolkswirtschaftslehre</em>, translated by James Dingwall and Bert F.\nHoselitz as <em>Principles of Economics</em>, New York: New York\nUniversity Press, 1976;\n <a href=\"http://mises.org/Books/Mengerprinciples.pdf\" target=\"other\">reprinted online</a>,\nLudwig von Mises Institute, 2007.", "Mill, J. S., 1861. <em>Utilitarianism.</em> Edited with an\nintroduction by Roger Crisp. New York: Oxford University Press,\n1998.", "von Neumann, J., and Morgenstern, O., 1944, <em>Theory of Games and\nEconomic Behavior</em>, Princeton: Princeton University Press.", "Nover, H. &amp; H\u00e1jek, A., 2004, \u201cVexing\nexpectations\u201d, <em>Mind</em>, 113: 237\u2013249.", "Nozick, R., 1969, \u201cNewcomb\u2019s Problem and Two Principles of\nChoice,\u201d in Nicholas Rescher (ed.), <em>Essays in Honor of Carl\nG. Hempel</em>, Dordrecht: Reidel, 114\u2013115.", "Oliver, A., 2003, \u201cA quantitative and qualitative test of the\nAllais paradox using health outcomes\u201d, <em>Journal of Economic\nPsychology</em>, 24: 35\u201348.", "Pope, R., 1995, \u201cTowards a More Precise Decision Framework: A\nSeparation of the Negative Utility of Chance from Diminishing Marginal\nUtility and the Preference for Safety\u201d, <em>Theory and\nDecision</em>, 39: 241\u2013265.", "Raiffa, H., 1968, <em>Decision analysis: Introductory lectures on\nchoices under uncertainty</em>, Reading, MA: Addison-Wesley.", "Ramsey, F. P., 1926, \u201cTruth and Probability\u201d, in\n<em>Foundations of Mathematics and other Essays, R. B. Braithwaite</em>\n(ed.), London: Kegan, Paul, Trench, Trubner, &amp; Co., 1931,\n156\u2013198; reprinted in <em>Studies in Subjective Probability</em>,\nH. E. Kyburg, Jr. and H. E. Smokler (eds.), 2nd edition, New York: R.\nE. Krieger Publishing Company, 1980, 23\u201352; reprinted in\n<em>Philosophical Papers</em>, D. H. Mellor (ed.), Cambridge: Cambridge\nUniversity Press, 1990.", "Savage, L.J., 1972, <em>The Foundations of Statistics</em>,\n2<sup>nd</sup> edition, New York: Dover Publications, Inc.", "Sen, A., 1977, \u201cRational Fools: A Critique of the Behavioral\nFoundations of Economic Theory\u201d, <em>Philosophy and Public\nAffairs</em>, 6: 317\u2013344.", "Shafer, G., 2007, \u201cFrom Cournot\u2019s principle to market\nefficiency\u201d, in <em>Augustin Cournot: Modelling Economics</em>,\nJean-Philippe Touffut (ed.), Cheltenham: Edward Elgar, 55\u201395.", "Sidgwick, H., 1907. <em>The Methods of Ethics,</em> Seventh\nEdition. London: Macmillan; first edition, 1874.", "Simon, H., 1956, \u201cA Behavioral Model of Rational\nChoice\u201d, <em>The Quarterly Journal of Economics</em>, 69:\n99\u2013118.", "Skyrms, B., 1980. <em>Causal Necessity: A Pragmatic Investigation\nof the Necessity of Laws</em>, New Haven, CT: Yale University\nPress.", "Smith, H.M., \u201cSubjective Rightness\u201d, <em>Social and\nPolitical Philosophy</em>, 27: 64-110.", "Sobel, J.H., 1994, <em>Taking Chances: Essays on Rational\nChoice</em>, Cambridge: Cambridge University Press.", "Spohn, W., 1977, \u201cWhere Luce and Krantz do really generalize\nSavage\u2019s decision model\u201d, <em>Erkenntnis</em>, 11:\n113\u2013134.", "Srinivasan, A., 2015, \u201cNormativity Without Cartesian\nPrivilege\u201d, <em>No\u00fbs</em>, 25: 273-299.", "Suppes, P., 2002, <em>Representation and Invariance of Scientific\nStructures</em>, Stanford: CSLI Publications.", "Thalos, M. and Richardson, O., 2013, \u201cCapitalization in the\nSt. Petersburg game: Why statistical distributions matter\u201d,\n<em>Politics, Philosophy &amp; Economics</em>, 13: 292-313.", "Weinstein, M.C., Torrence, G., and McGuire, A., 2009 \u201cQALYs:\nthe basics\u201d, <em>Value in Health</em>, 12: S5\u2013S9.", "Weirich, P., 1986, \u201cExpected Utility and Risk\u201d,\n<em>British Journal for the Philosophy of Science</em>, 37:\n419\u2013442.", "Zynda, L., 2000, \u201cRepresentation Theorems and Realism about\nDegrees of Belief\u201d, <em>Philosophy of Science</em>, 67:\n45\u201369."]}, "raw_text": "<div id=\"bibliography\">\n<h2><a id=\"Bib\">Bibliography</a></h2>\n<ul class=\"hanging\">\n<li>Allais M., 1953, \u201cLe Comportement de l\u2019Homme Rationnel devant\nle Risque: Critique des Postulats et Axiomes de l\u2019\u00c9cole\nAmericaine\u201d, <em>Econometrica</em>, 21: 503\u2013546.</li>\n<li>Bell, R., 1987, \u201cDecision Theory and Due Process: A Critique\nof the Supreme Court\u2019s Lawmaking for Burdens of\nProof\u201d, <em>Journal of Criminal Law and Criminology</em>, 78:\n557-585.</li>\n<li>Bentham, J., 1961. An Introduction to the Principles of Morals and\nLegislation, Garden City: Doubleday. Originally published in 1789.</li>\n<li>Bernoulli, D., 1738, \u201cSpecimen theoriae novae de mensura\nsortis\u201d, <em>Commentarii Academiae Scientiarum Imperialis\nPetropolitanae</em> 5. Translated by Louise Somer and reprinted\nas \u201cExposition of a New Theory on the Measurement of Risk\u201d\n1954, <em>Econometrica</em>, 22: 23\u201336.</li>\n<li>Bolker, E., 1966, \u201cFunctions Resembling Quotients of\nMeasures\u201d, <em>Transactions of the American Mathematical\nSociety</em>, 2: 292\u2013312.</li>\n<li>Bradley, R., 2004, \u201cRamsey\u2019s representation\ntheorem\u201d, <em>Dialectica</em>, 58: 483\u2013497.</li>\n<li>Broome, J., 1991, <em>Weighing Goods: Equality, Uncertainty and\nTime</em>, Oxford: Blackwell, doi:10.1002/9781119451266</li>\n<li>Burch-Brown, J.M., 2014, \u201cClues for\nConsequentialists\u201d, <em>Utilitas</em>, 26: 105-119.</li>\n<li>Buchak, L., 2013, <em>Risk and Rationality</em>, Oxford: Oxford\nUniversity Press.</li>\n<li>Colyvan, M., 2006, \u201cNo Expectations\u201d, <em>Mind</em>,\n116: 695\u2013702.</li>\n<li>Colyvan, M., 2008, \u201cRelative Expectation Theory\u201d,\n<em>Journal of Philosophy</em>, 105: 37\u201344.</li>\n<li>Easwaran, K., 2014, \u201cRegularity and Hyperreal\nCredences\u201d, <em>The Philosophical Review</em>, 123:\n1\u201341.</li>\n<li>Easwaran, K., 2008, \u201cStrong and Weak Expectations\u201d,\n<em>Mind</em>, 117: 633\u2013641.</li>\n<li>Elliott, E., 2017, \u201cRamsey without Ethical Neutrality: A New\nRepresentation Theorem\u201d, <em>Mind</em>, 126: 1-51.</li>\n<li>Ellsberg, D., 1961, \u201cRisk, Ambiguity, and the Savage\nAxioms\u201d, <em>Quarterly Journal of Economics</em>, 75:\n643\u2013669.</li>\n<li>Feldman, F. 2006, \u201cActual utility, the objection from\nimpracticality, and the move to expected utility\u201d,\n<em>Philosophical Studies</em>, 129 : 49\u201379.</li>\n<li>Fine, T., 2008, \u201cEvaluating the Pasadena, Altadena, and St\nPetersburg Gambles\u201d, <em>Mind</em>, 117: 613\u2013632.</li>\n<li>Good, I.J., 1967, \u201cOn the Principle of Total Evidence\u201d,\n<em>The British Journal for the Philosophy of Science</em>, 17:\n319\u2013321</li>\n<li>Greaves, H. 2016, \u201cCluelessness\u201d, <em>Proceedings of\nthe Aristotelian Society</em>, 116: 311-339.</li>\n<li>Hampton, J., \u201cThe Failure of Expected-Utility Theory as a\nTheory of Reason\u201d, <em>Economics and Philosophy</em>, 10:\n195\u2013242.</li>\n<li>Harsanyi, J.C., 1953, \u201cCardinal utility in welfare economics\nand in the theory of risk-taking\u201d, <em>Journal of Political\nEconomy</em>, 61: 434\u2013435.</li>\n<li>Herfeld, C., \u201cFrom Theories of Human Behavior to Rules of\nRational Choice: Tracing a Normative Turn at the Cowles Commission,\n1943-1954\u201d, <em>History of Political Economy</em>, 50:\n1-48.</li>\n<li>Howard, R.A., 1980, \u201cOn Making Life and Death\nDecisions\u201d, in R.C. Schwing and W.A. Albers, <em>Societal Risk\nAssessment: How Safe is Safe Enough?</em>, New York: Plenum\nPress.</li>\n<li> Howard-Snyder, F., 1997, \u201cThe Rejection of Objective\nConsequentialism\u201d, <em>Utilitas</em>, 9: 241\u2013248.</li>\n<li>Jackson, F., 1991, \u201cDecision-theoretic consequentialism and\nthe nearest and dearest objection\u201d, <em>Ethics</em>, 101:\n461\u2013482.</li>\n<li>Jeffrey, R., 1983, <em>The Logic of Decision</em>, 2<sup>nd</sup>\nedition, Chicago: University of Chicago Press.</li>\n<li>Jevons, W.S., 1866, \u201cA General Mathematical Theory of\nPolitical Economy\u201d, <em>Journal of the Royal Statistical\nSociety</em>, 29: 282\u2013287.</li>\n<li>Joyce, J., 1999, <em>The Foundations of Causal Decision\nTheory</em>, Cambridge: Cambridge University Press.</li>\n<li>Kahneman, D. &amp; Tversky A., <em>Judgment Under Uncertainty:\nHeuristics and Biases</em>, New York: Cambridge University Press.</li>\n<li>Kaplan, J., 1968, \u201cDecision Theory and the Factfinding\nProcess\u201d, <em>Stanford Law Review</em>, 20: 1065-1092. </li>\n<li>Kolmogorov, A. N., 1933, <em>Grundbegriffe der\nWahrscheinlichkeitrechnung, Ergebnisse Der Mathematik</em>; translated\nas <em>Foundations of Probability</em>, New York: Chelsea Publishing\nCompany, 1950.</li>\n<li>Laudan, L., 2006, <em>Truth, Error, and Criminal Law</em>,\nCambridge: Cambridge University Press.</li>\n<li>Lenman, J., 2000. \u201cConsequentialism and\ncluelessness\u201d, <em>Philosophy and Public Affairs</em>, 29(4):\n342\u2013370.</li>\n<li>Lewis, D., 1981, \u201cCausal Decision Theory\u201d,\n<em>Australasian Journal of Philosophy</em>, 59: 5\u201330.</li>\n<li>Levi, I., 1991, \u201cConsequentialism and Sequential\nChoice\u201d, in M. Bacharach and S. Hurley (eds.), <em>Foundations of\nDecision Theory</em>, Oxford: Basil Blackwell Ltd, 92\u201312.</li>\n<li>Lindblom, C.E., 1959, \u201cThe Science of \u2018Muddling\nThrough\u2019\u201d, <em>Public Administration Review</em>, 19:\n79\u201388.</li>\n<li>Loomes, G. And Sugden, R., 1986, \u201cDisappointment and Dynamic\nConsistency in Choice Under Uncertainty\u201d, <em>The Review of\nEconomic Studies</em>, 53(2): 271\u2013282.</li>\n<li>Maher, P., 1993, <em>Betting on Theories</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li>March, J.G. and Simon, H., 1958, <em>Organizations</em>, New York:\nWiley.</li>\n<li>Mason, E., 2013, \u201cObjectivism and Prospectivism About\nRightness\u201d, <em>Journal of Ethics and Social Philosophy</em>, 7:\n1\u201321.</li>\n<li>Mayo, D., 1996, <em>Error and the Growth of Experimental\nKnowledge</em>, Chicago: University of Chicago Press.</li>\n<li>McAskill, W., 2015, <em>Doing Good Better</em>, New York: Gotham\nBooks.</li>\n<li>McGee, V., 1991, \u201cWe Turing Machines Aren\u2019t Expected-Utility\nMaximizers (Even Ideally)\u201d, <em>Philosophical Studies</em>, 64:\n115-123.</li>\n<li>Meacham, C. and Weisberg, J., 2011, \u201cRepresentation Theorems\nand the Foundations of Decision Theory\u201d, <em>Australasian Journal\nof Philosophy</em>, 89: 641\u2013663.</li>\n<li>Menger, K., 1871, <em>Grunds\u00e4tze der\nVolkswirtschaftslehre</em>, translated by James Dingwall and Bert F.\nHoselitz as <em>Principles of Economics</em>, New York: New York\nUniversity Press, 1976;\n <a href=\"http://mises.org/Books/Mengerprinciples.pdf\" target=\"other\">reprinted online</a>,\nLudwig von Mises Institute, 2007.</li>\n<li>Mill, J. S., 1861. <em>Utilitarianism.</em> Edited with an\nintroduction by Roger Crisp. New York: Oxford University Press,\n1998.</li>\n<li>von Neumann, J., and Morgenstern, O., 1944, <em>Theory of Games and\nEconomic Behavior</em>, Princeton: Princeton University Press.</li>\n<li>Nover, H. &amp; H\u00e1jek, A., 2004, \u201cVexing\nexpectations\u201d, <em>Mind</em>, 113: 237\u2013249.</li>\n<li>Nozick, R., 1969, \u201cNewcomb\u2019s Problem and Two Principles of\nChoice,\u201d in Nicholas Rescher (ed.), <em>Essays in Honor of Carl\nG. Hempel</em>, Dordrecht: Reidel, 114\u2013115.</li>\n<li>Oliver, A., 2003, \u201cA quantitative and qualitative test of the\nAllais paradox using health outcomes\u201d, <em>Journal of Economic\nPsychology</em>, 24: 35\u201348.</li>\n<li>Pope, R., 1995, \u201cTowards a More Precise Decision Framework: A\nSeparation of the Negative Utility of Chance from Diminishing Marginal\nUtility and the Preference for Safety\u201d, <em>Theory and\nDecision</em>, 39: 241\u2013265.</li>\n<li>Raiffa, H., 1968, <em>Decision analysis: Introductory lectures on\nchoices under uncertainty</em>, Reading, MA: Addison-Wesley.</li>\n<li>Ramsey, F. P., 1926, \u201cTruth and Probability\u201d, in\n<em>Foundations of Mathematics and other Essays, R. B. Braithwaite</em>\n(ed.), London: Kegan, Paul, Trench, Trubner, &amp; Co., 1931,\n156\u2013198; reprinted in <em>Studies in Subjective Probability</em>,\nH. E. Kyburg, Jr. and H. E. Smokler (eds.), 2nd edition, New York: R.\nE. Krieger Publishing Company, 1980, 23\u201352; reprinted in\n<em>Philosophical Papers</em>, D. H. Mellor (ed.), Cambridge: Cambridge\nUniversity Press, 1990.</li>\n<li>Savage, L.J., 1972, <em>The Foundations of Statistics</em>,\n2<sup>nd</sup> edition, New York: Dover Publications, Inc.</li>\n<li>Sen, A., 1977, \u201cRational Fools: A Critique of the Behavioral\nFoundations of Economic Theory\u201d, <em>Philosophy and Public\nAffairs</em>, 6: 317\u2013344.</li>\n<li>Shafer, G., 2007, \u201cFrom Cournot\u2019s principle to market\nefficiency\u201d, in <em>Augustin Cournot: Modelling Economics</em>,\nJean-Philippe Touffut (ed.), Cheltenham: Edward Elgar, 55\u201395.</li>\n<li>Sidgwick, H., 1907. <em>The Methods of Ethics,</em> Seventh\nEdition. London: Macmillan; first edition, 1874.</li>\n<li>Simon, H., 1956, \u201cA Behavioral Model of Rational\nChoice\u201d, <em>The Quarterly Journal of Economics</em>, 69:\n99\u2013118.</li>\n<li>Skyrms, B., 1980. <em>Causal Necessity: A Pragmatic Investigation\nof the Necessity of Laws</em>, New Haven, CT: Yale University\nPress.</li>\n<li>Smith, H.M., \u201cSubjective Rightness\u201d, <em>Social and\nPolitical Philosophy</em>, 27: 64-110.</li>\n<li>Sobel, J.H., 1994, <em>Taking Chances: Essays on Rational\nChoice</em>, Cambridge: Cambridge University Press.</li>\n<li>Spohn, W., 1977, \u201cWhere Luce and Krantz do really generalize\nSavage\u2019s decision model\u201d, <em>Erkenntnis</em>, 11:\n113\u2013134.</li>\n<li>Srinivasan, A., 2015, \u201cNormativity Without Cartesian\nPrivilege\u201d, <em>No\u00fbs</em>, 25: 273-299.</li>\n<li>Suppes, P., 2002, <em>Representation and Invariance of Scientific\nStructures</em>, Stanford: CSLI Publications.</li>\n<li>Thalos, M. and Richardson, O., 2013, \u201cCapitalization in the\nSt. Petersburg game: Why statistical distributions matter\u201d,\n<em>Politics, Philosophy &amp; Economics</em>, 13: 292-313.</li>\n<li>Weinstein, M.C., Torrence, G., and McGuire, A., 2009 \u201cQALYs:\nthe basics\u201d, <em>Value in Health</em>, 12: S5\u2013S9.</li>\n<li>Weirich, P., 1986, \u201cExpected Utility and Risk\u201d,\n<em>British Journal for the Philosophy of Science</em>, 37:\n419\u2013442.</li>\n<li>Zynda, L., 2000, \u201cRepresentation Theorems and Realism about\nDegrees of Belief\u201d, <em>Philosophy of Science</em>, 67:\n45\u201369.</li>\n</ul>\n</div>"}, "related_entries": {"entry_list": ["decision theory", "decision theory: causal", "Pascal\u2019s wager", "preferences", "probability, interpretations of", "Ramsey, Frank: and intergenerational welfare economics", "rational choice, normative: rivals to expected utility", "risk"], "entry_link": [{"../decision-theory/": "decision theory"}, {"../decision-causal/": "decision theory: causal"}, {"../pascal-wager/": "Pascal\u2019s wager"}, {"../preferences/": "preferences"}, {"../probability-interpret/": "probability, interpretations of"}, {"../ramsey-economics/": "Ramsey, Frank: and intergenerational welfare economics"}, {"../rationality-normative-nonutility/": "rational choice, normative: rivals to expected utility"}, {"../risk/": "risk"}]}, "academic_tools": {"listed_text": ["<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>", "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=rationality-normative-utility\" target=\"other\">How to cite this entry</a>.", "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>", "<a href=\"https://leibniz.stanford.edu/friends/preview/rationality-normative-utility/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.", "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>", "<a href=\"https://www.inphoproject.org/entity?sep=rationality-normative-utility&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).", "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>", "<a href=\"https://philpapers.org/sep/rationality-normative-utility/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."], "listed_links": [{"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=rationality-normative-utility": "How to cite this entry"}, {"https://leibniz.stanford.edu/friends/preview/rationality-normative-utility/": "Preview the PDF version of this entry"}, {"https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"}, {"https://www.inphoproject.org/entity?sep=rationality-normative-utility&redirect=True": "Look up topics and thinkers related to this entry"}, {"https://philpapers.org/sep/rationality-normative-utility/": "Enhanced bibliography for this entry"}, {"https://philpapers.org/": "PhilPapers"}]}, "other_internet_resources": {"listed_text": ["<a href=\"http://ocw.mit.edu/courses/linguistics-and-philosophy/24-222-decisions-games-and-rational-choice-spring-2008/\" target=\"other\">Decisions, Games, and Rational Choice</a>,\n materials for a course taught in Spring 2008 by \nRobert Stalnaker, MIT OpenCourseWare.", "<a href=\"http://dspace.mit.edu/handle/1721.1/99213\" target=\"other\">Microeconomic Theory III</a>, \nmaterials for a course taught in Spring 2010 by Muhamet\n Yildiz, MIT OpenCourseWare.", "<a href=\"http://web.stanford.edu/~jdlevin/Econ%20202/Uncertainty.pdf\" target=\"other\">Choice Under Uncertainty</a>,\n  class lecture notes by Jonathan Levin.", "<a href=\"https://philarchive.org/rec/MONEUT\" target=\"other\">Expected Utility Theory</a>, \nby Philippe Mongin, entry for The Handbook of Economic Methodology.", "<a href=\"http://www.researchgate.net/publication/228900877_The_Origins_of_Expected_Utility_Theory/links/0c96052b159831042a000000\" target=\"other\">The Origins of Expected Utility Theory</a>,\n essay by Yvan Lengwiler."], "listed_links": [{"http://ocw.mit.edu/courses/linguistics-and-philosophy/24-222-decisions-games-and-rational-choice-spring-2008/": "Decisions, Games, and Rational Choice"}, {"http://dspace.mit.edu/handle/1721.1/99213": "Microeconomic Theory III"}, {"http://web.stanford.edu/~jdlevin/Econ%20202/Uncertainty.pdf": "Choice Under Uncertainty"}, {"https://philarchive.org/rec/MONEUT": "Expected Utility Theory"}, {"http://www.researchgate.net/publication/228900877_The_Origins_of_Expected_Utility_Theory/links/0c96052b159831042a000000": "The Origins of Expected Utility Theory"}]}, "tokenized_text": ["1", "defining", "expected", "utility", "concept", "expected", "utility", "best", "illustrated", "example", "suppose", "planning", "long", "walk", "need", "decide", "whether", "bring", "umbrella", "would", "rather", "tote", "umbrella", "sunny", "day", "would", "rather", "face", "rain", "umbrella", "without", "two", "act", "available", "taking", "umbrella", "leaving", "home", "act", "choose", "informal", "problem", "description", "recast", "slightly", "formally", "term", "three", "sort", "entity", "first", "outcomesobjects", "noninstrumental", "preference", "example", "might", "distinguish", "three", "outcome", "either", "end", "dry", "unencumbered", "end", "dry", "encumbered", "unwieldy", "umbrella", "end", "wet", "second", "statesthings", "outside", "decisionmaker", "control", "influence", "outcome", "decision", "example", "two", "state", "either", "raining", "finally", "actsobjects", "decisionmaker", "instrumental", "preference", "sense", "thing", "example", "two", "act", "may", "either", "bring", "umbrella", "leave", "home", "expected", "utility", "theory", "provides", "way", "ranking", "act", "according", "choiceworthy", "higher", "expected", "utility", "better", "choose", "act", "therefore", "best", "choose", "act", "highest", "expected", "utilityor", "one", "event", "several", "act", "tied", "following", "general", "convention", "make", "following", "assumption", "relationship", "act", "state", "outcome", "state", "act", "outcome", "proposition", "ie", "set", "possibility", "maximal", "set", "possibility", "omega", "state", "act", "outcome", "subset", "set", "act", "set", "state", "set", "outcome", "partition", "omega", "word", "act", "state", "individuated", "every", "possibility", "omega", "one", "exactly", "one", "state", "obtains", "agent", "performs", "exactly", "one", "act", "exactly", "one", "outcome", "ensues", "act", "state", "logically", "independent", "state", "rule", "performance", "act", "assume", "moment", "given", "state", "world", "act", "exactly", "one", "possible", "outcome", "section", "11", "briefly", "discus", "one", "might", "weaken", "assumption", "example", "umbrella", "depicted", "following", "matrix", "column", "corresponds", "state", "world", "row", "corresponds", "act", "entry", "corresponds", "outcome", "result", "act", "performed", "state", "world", "state", "rain", "rain", "act", "take", "umbrella", "encumbered", "dry", "encumbered", "dry", "leave", "umbrella", "wet", "free", "dry", "set", "basic", "framework", "rigorously", "define", "expected", "utility", "expected", "utility", "act", "a", "instance", "taking", "umbrella", "depends", "two", "feature", "problem", "value", "outcome", "measured", "real", "number", "called", "utility", "probability", "outcome", "conditional", "a", "given", "three", "piece", "information", "a", "expected", "utility", "defined", "eu", "sum_", "in", "p_", "u", "o", "set", "outcome", "p_", "probability", "outcome", "o", "conditional", "a", "u", "utility", "o", "next", "two", "subsection", "unpack", "conditional", "probability", "function", "p_a", "utility", "function", "u", "11", "conditional", "probability", "term", "p_", "represents", "probability", "o", "given", "a", "roughly", "likely", "outcome", "o", "occur", "supposition", "agent", "chooses", "act", "a", "axiom", "probability", "see", "entry", "interpretation", "probability", "understand", "mean", "must", "answer", "two", "question", "first", "interpretation", "probability", "appropriate", "second", "mean", "assign", "probability", "supposition", "agent", "chooses", "act", "a", "expected", "utility", "theorist", "often", "interpret", "probability", "measuring", "individual", "degree", "belief", "proposition", "e", "likely", "agent", "extent", "agent", "confident", "e", "see", "instance", "ramsey", "1926", "savage", "1972", "jeffrey", "1983", "nothing", "formalism", "expected", "utility", "theory", "force", "interpretation", "u", "could", "instead", "interpret", "probability", "objective", "chance", "von", "neumann", "morgenstern", "1944", "degree", "belief", "warranted", "evidence", "thought", "better", "guide", "rational", "action", "see", "entry", "interpretation", "probability", "discussion", "option", "probability", "supposition", "agent", "chooses", "a", "two", "basic", "type", "answer", "corresponding", "evidential", "decision", "theory", "causal", "decision", "theory", "according", "evidential", "decision", "theory", "endorsed", "jeffrey", "1983", "relevant", "suppositional", "probability", "p_", "conditional", "probability", "p", "mid", "defined", "ratio", "two", "unconditional", "probability", "p", "amp", "p", "jeffrey", "definition", "expected", "utility", "spohn", "1977", "levi", "1991", "object", "decisionmaker", "assign", "probability", "act", "deliberation", "freely", "deciding", "whether", "perform", "act", "a", "take", "account", "belief", "whether", "perform", "a", "spohn", "levi", "right", "jeffrey", "ratio", "undefined", "since", "denominator", "undefined", "nozick", "1969", "raise", "another", "objection", "jeffrey", "definition", "give", "strange", "result", "newcomb", "problem", "predictor", "hand", "closed", "box", "containing", "either", "0", "1", "million", "offer", "open", "box", "containing", "additional", "1000", "either", "refuse", "open", "box", "onebox", "take", "open", "box", "twobox", "catch", "predictor", "predicted", "choice", "beforehand", "prediction", "90", "accurate", "word", "probability", "onebox", "given", "predicts", "onebox", "90", "probability", "twobox", "given", "predicts", "twobox", "90", "finally", "content", "closed", "box", "depend", "prediction", "predictor", "thought", "would", "twobox", "put", "nothing", "closed", "box", "thought", "would", "onebox", "put", "1", "million", "closed", "box", "matrix", "decision", "look", "like", "state", "1", "million", "closed", "box", "0", "closed", "box", "act", "onebox", "1000000", "0", "twobox", "1001000", "1000", "twoboxing", "dominates", "oneboxing", "every", "state", "twoboxing", "yield", "better", "outcome", "yet", "jeffrey", "definition", "conditional", "probability", "oneboxing", "higher", "expected", "utility", "twoboxing", "high", "conditional", "probability", "finding", "1", "million", "closed", "box", "given", "onebox", "oneboxing", "high", "expected", "utility", "likewise", "high", "conditional", "probability", "finding", "nothing", "closed", "box", "given", "twobox", "twoboxing", "low", "expected", "utility", "causal", "decision", "theory", "alternative", "proposal", "get", "around", "problem", "require", "still", "permit", "act", "probability", "recommends", "twoboxing", "newcomb", "problem", "causal", "decision", "theory", "come", "many", "variety", "consider", "representative", "version", "proposed", "savage", "1972", "calculates", "p_", "summing", "probability", "state", "combined", "act", "a", "lead", "outcome", "o", "let", "f_", "outcome", "map", "o", "1", "o", "result", "performing", "a", "state", "map", "o", "0", "otherwise", "p_", "sum_", "sin", "p", "f_", "savage", "proposal", "twoboxing", "come", "higher", "expected", "utility", "oneboxing", "result", "hold", "matter", "probability", "assign", "state", "prior", "decision", "let", "x", "probability", "assign", "state", "closed", "box", "contains", "1", "million", "according", "savage", "expected", "utility", "oneboxing", "twoboxing", "respectively", "x", "cdot", "u", "1000000", "1", "x", "cdot", "u", "0", "x", "cdot", "u", "1001000", "1", "x", "cdot", "u", "1000", "long", "larger", "monetary", "amount", "assigned", "strictly", "larger", "utility", "second", "sum", "utility", "twoboxing", "guaranteed", "larger", "first", "utility", "oneboxing", "savage", "assumes", "act", "state", "enough", "uniquely", "determine", "outcome", "case", "assumption", "break", "suppose", "offer", "sell", "following", "gamble", "toss", "coin", "coin", "land", "head", "win", "100", "coin", "land", "tail", "lose", "100", "refuse", "gamble", "coin", "never", "tossed", "outcome", "would", "resulted", "coin", "tossedi", "might", "100", "might", "lost", "100", "generalze", "savage", "proposal", "letting", "f_", "probability", "function", "map", "outcome", "real", "number", "0", "1", "interval", "lewis", "1981", "skyrms", "1980", "sobel", "1994", "equate", "f_", "objective", "chance", "o", "would", "outcome", "state", "s", "obtained", "agent", "chose", "action", "a", "casesmost", "famously", "newcomb", "problemthe", "jeffrey", "definition", "savage", "definition", "expected", "utility", "come", "apart", "whenever", "following", "two", "condition", "satisfied", "agree", "act", "probabilistically", "independent", "state", "formal", "term", "act", "a", "state", "s", "p", "p", "mid", "frac", "p", "amp", "p", "condition", "violated", "newcomb", "problem", "outcome", "o", "act", "a", "state", "s", "f_", "equal", "conditional", "probability", "o", "given", "a", "s", "formal", "term", "f_", "p", "mid", "amp", "frac", "p", "amp", "amp", "p", "amp", "need", "condition", "arises", "act", "state", "fail", "uniquely", "determine", "outcome", "see", "lewis", "1981", "12", "outcome", "utility", "term", "u", "represents", "utility", "outcome", "o", "roughly", "valuable", "o", "formally", "u", "function", "assigns", "real", "number", "outcome", "unit", "associated", "u", "typically", "called", "utiles", "u", "2", "say", "o", "worth", "2", "utiles", "greater", "utility", "valuable", "outcome", "kind", "value", "measured", "utiles", "utiles", "typically", "taken", "unit", "currency", "like", "dollar", "pound", "yen", "bernoulli", "1738", "argued", "money", "good", "diminishing", "marginal", "utility", "agent", "get", "richer", "every", "successive", "dollar", "gold", "watch", "apple", "le", "valuable", "last", "give", "following", "example", "make", "rational", "sense", "rich", "man", "pauper", "pay", "9000", "ducat", "exchange", "lottery", "ticket", "yield", "50", "chance", "20000", "ducat", "50", "chance", "nothing", "since", "lottery", "give", "two", "men", "chance", "monetary", "prize", "prize", "must", "different", "value", "depending", "whether", "player", "poor", "rich", "classic", "utilitarian", "bentham", "1789", "mill", "1861", "sidgwick", "1907", "interpreted", "utility", "measure", "pleasure", "happiness", "author", "say", "a", "greater", "utility", "b", "agent", "group", "agent", "say", "a", "result", "pleasure", "happiness", "b", "agent", "group", "agent", "one", "objection", "interpretation", "utility", "may", "single", "good", "indeed", "good", "rationality", "requires", "u", "seek", "understand", "utility", "broadly", "enough", "include", "potentially", "desirable", "endspleasure", "knowledge", "friendship", "health", "onit", "clear", "unique", "correct", "way", "make", "tradeoff", "different", "good", "outcome", "receives", "utility", "may", "good", "answer", "question", "whether", "life", "ascetic", "monk", "contains", "le", "good", "life", "happy", "libertinebut", "assigning", "utility", "option", "force", "u", "compare", "contemporary", "decision", "theorist", "typically", "interpret", "utility", "measure", "preference", "say", "a", "greater", "utility", "b", "agent", "simply", "say", "agent", "prefers", "a", "b", "crucial", "approach", "preference", "hold", "outcome", "amount", "pleasure", "combination", "pleasure", "knowledge", "also", "uncertain", "prospect", "lottery", "pay", "1", "million", "dollar", "particular", "coin", "land", "head", "result", "hour", "painful", "electric", "shock", "coin", "land", "tail", "section", "2", "article", "address", "formal", "relationship", "preference", "choice", "detail", "expected", "utility", "theory", "require", "preference", "selfish", "selfinterested", "someone", "prefer", "giving", "money", "charity", "spending", "money", "lavish", "dinner", "prefer", "sacrificing", "life", "allowing", "child", "die", "sen", "1977", "suggests", "person", "psychology", "best", "represented", "using", "three", "ranking", "one", "representing", "person", "narrow", "selfinterest", "second", "representing", "person", "selfinterest", "construed", "broadly", "account", "feeling", "sympathy", "eg", "suffering", "watching", "another", "person", "suffer", "third", "representing", "person", "commitment", "may", "require", "act", "selfinterest", "broadly", "construed", "broome", "1991", "ch", "6", "interprets", "utility", "measuring", "comparison", "objective", "betterness", "worseness", "rather", "personal", "preference", "say", "a", "greater", "utility", "b", "say", "a", "objectively", "better", "b", "rational", "person", "would", "prefer", "a", "b", "nothing", "formalism", "probability", "theory", "requires", "u", "use", "subjective", "rather", "objective", "probability", "nothing", "formalism", "expected", "utility", "theory", "requires", "u", "use", "subjective", "rather", "objective", "value", "interpret", "utility", "term", "personal", "preference", "face", "special", "challenge", "socalled", "problem", "interpersonal", "utility", "comparison", "making", "decision", "distribute", "shared", "resource", "often", "want", "know", "act", "would", "make", "alice", "better", "boband", "much", "better", "utility", "measure", "individual", "preference", "clear", "meaningful", "way", "making", "comparison", "alice", "utility", "constituted", "alice", "preference", "bob", "utility", "constituted", "bob", "preference", "preference", "spanning", "alice", "bob", "assume", "alice", "utility", "10", "equivalent", "bob", "utility", "10", "assume", "getting", "grade", "differential", "equation", "equivalent", "getting", "grade", "basket", "weaving", "good", "time", "consider", "feature", "utility", "function", "carry", "meaningful", "information", "comparison", "informative", "u", "o_1", "gt", "u", "o_2", "person", "o_1", "better", "preferred", "o_2", "comparison", "informativethe", "utility", "function", "must", "carry", "information", "expected", "utility", "theory", "give", "meaningful", "result", "see", "consider", "umbrella", "example", "time", "filled", "probability", "state", "utility", "outcome", "state", "rain", "p", "06", "rain", "p", "04", "act", "take", "umbrella", "encumbered", "dry", "u", "5", "encumbered", "dry", "u", "5", "leave", "umbrella", "wet", "u", "0", "free", "dry", "u", "10", "expected", "utility", "taking", "umbrella", "begin", "align", "eu", "take", "p_", "take", "encumbered", "dry", "cdot", "5", "quad", "p_", "take", "wet", "cdot", "0", "quad", "p_", "take", "free", "dry", "cdot", "10", "5", "end", "align", "expected", "utility", "leaving", "umbrella", "begin", "align", "eu", "leave", "p_", "leave", "encumbered", "dry", "cdot", "5", "quad", "p_", "leave", "wet", "cdot", "0", "quad", "p_", "leave", "free", "dry", "cdot", "10", "4", "end", "align", "since", "eu", "take", "gt", "eu", "leave", "expected", "utility", "theory", "tell", "taking", "umbrella", "better", "leaving", "suppose", "change", "utility", "outcome", "instead", "using", "u", "use", "u", "state", "rain", "p06", "rain", "p04", "act", "take", "umbrella", "encumbered", "dry", "u4", "encumbered", "dry", "u4", "leave", "umbrella", "wet", "u2", "free", "dry", "u8", "new", "expected", "utility", "taking", "umbrella", "begin", "align", "eu", "take", "p_", "take", "encumbered", "dry", "cdot", "4", "quad", "p_", "take", "wet", "cdot", "2", "quad", "p_", "take", "free", "dry", "cdot", "8", "4", "end", "align", "new", "expected", "utility", "leaving", "umbrella", "begin", "align", "eu", "leave", "p_", "leave", "encumbered", "dry", "cdot", "4", "quad", "p_", "leave", "wet", "cdot", "2", "quad", "p_", "leave", "free", "dry", "cdot", "8", "44", "end", "align", "since", "eu", "take", "lt", "eu", "leave", "expected", "utility", "theory", "tell", "leaving", "umbrella", "better", "taking", "utility", "function", "u", "u", "rank", "outcome", "exactly", "way", "free", "dry", "best", "encumbered", "dry", "rank", "middle", "wet", "worst", "yet", "expected", "utility", "theory", "give", "different", "advice", "two", "version", "problem", "must", "substantive", "difference", "preference", "appropriately", "described", "u", "preference", "appropriately", "described", "u", "otherwise", "expected", "utility", "theory", "fickle", "liable", "change", "advice", "fed", "different", "description", "problem", "two", "utility", "function", "represent", "basic", "state", "affair", "measurement", "theory", "answer", "question", "characterizing", "allowable", "transformation", "utility", "functionways", "changing", "leave", "meaningful", "feature", "intact", "characterize", "allowable", "transformation", "utility", "function", "thereby", "specified", "feature", "meaningful", "defender", "expected", "utility", "theory", "typically", "require", "utility", "measured", "linear", "scale", "allowable", "transformation", "positive", "linear", "transformation", "ie", "function", "f", "form", "f", "u", "x", "cdot", "u", "y", "real", "number", "x", "gt", "0", "y", "positive", "linear", "transformation", "outcome", "utility", "never", "affect", "verdict", "expected", "utility", "theory", "a", "greater", "expected", "utility", "b", "utility", "measured", "function", "u", "a", "also", "greater", "expected", "utility", "b", "utility", "measured", "positive", "linear", "transformation", "u", "2", "argument", "expected", "utility", "theory", "choose", "act", "maximize", "expected", "utility", "one", "possible", "answer", "expected", "utility", "theory", "rational", "bedrockthat", "meansend", "rationality", "essentially", "involves", "maximizing", "expected", "utility", "find", "answer", "unsatisfying", "however", "two", "source", "justification", "first", "longrun", "argument", "rely", "evidence", "expectedutility", "maximization", "profitable", "policy", "long", "term", "second", "argument", "based", "representation", "theorem", "suggest", "certain", "rational", "constraint", "preference", "entail", "rational", "agent", "maximize", "expected", "utility", "21", "longrun", "argument", "one", "reason", "maximizing", "expected", "utility", "make", "good", "policy", "long", "run", "feller", "1968", "give", "version", "argument", "relies", "two", "mathematical", "fact", "probability", "strong", "weak", "law", "large", "number", "fact", "concern", "sequence", "independent", "identically", "distributed", "trialsthe", "sort", "setup", "result", "repeatedly", "betting", "way", "sequence", "roulette", "spin", "crap", "game", "weak", "strong", "law", "large", "number", "say", "roughly", "long", "run", "average", "amount", "utility", "gained", "per", "trial", "overwhelmingly", "likely", "close", "expected", "value", "individual", "trial", "weak", "law", "large", "number", "state", "trial", "expected", "value", "mu", "arbitrarily", "small", "real", "number", "epsilon", "gt", "0", "delta", "gt", "0", "finite", "number", "trial", "n", "m", "greater", "equal", "n", "probability", "least", "1delta", "gambler", "average", "gain", "first", "m", "trial", "fall", "within", "epsilon", "mu", "word", "long", "run", "similar", "gamble", "average", "gain", "per", "trial", "highly", "likely", "become", "arbitrarily", "close", "gamble", "expected", "value", "within", "finite", "amount", "time", "finite", "long", "run", "average", "value", "associated", "gamble", "overwhelmingly", "likely", "close", "expected", "value", "strong", "law", "large", "number", "state", "trial", "expected", "value", "mu", "probability", "1", "arbitrarily", "small", "real", "number", "epsilon", "gt", "0", "number", "trial", "increase", "gambler", "average", "winning", "per", "trial", "fall", "within", "epsilon", "mu", "word", "number", "repetition", "gamble", "approach", "infinity", "average", "gain", "per", "trial", "become", "arbitrarily", "close", "gamble", "expected", "value", "probability", "1", "long", "run", "average", "value", "associated", "gamble", "virtually", "certain", "equal", "expected", "value", "several", "objection", "long", "run", "argument", "first", "many", "decision", "repeated", "indefinitely", "many", "similar", "trial", "decision", "career", "pursue", "marry", "live", "instance", "made", "best", "small", "finite", "number", "time", "furthermore", "decision", "made", "different", "trial", "involve", "different", "possible", "outcome", "different", "probability", "clear", "longrun", "consideration", "repeated", "gamble", "bear", "singlecase", "choice", "second", "argument", "relies", "two", "independence", "assumption", "one", "may", "fail", "one", "assumption", "hold", "probability", "different", "trial", "independent", "true", "casino", "gamble", "true", "choice", "wish", "use", "decision", "theoryeg", "choice", "medical", "treatment", "remaining", "sick", "one", "course", "antibiotic", "make", "likely", "remain", "sick", "next", "course", "since", "increase", "chance", "antibioticresistant", "bacteria", "spread", "body", "argument", "also", "requires", "utility", "different", "trial", "independent", "winning", "prize", "one", "trial", "make", "contribution", "decisionmaker", "overall", "utility", "matter", "win", "trial", "assumption", "violated", "many", "realworld", "case", "due", "diminishing", "marginal", "utility", "money", "winning", "10", "million", "ten", "game", "roulette", "worth", "ten", "time", "much", "winning", "1", "million", "one", "game", "roulette", "third", "problem", "strong", "weak", "law", "large", "number", "modally", "weak", "neither", "law", "entail", "gamble", "repeated", "indefinitely", "appropriate", "assumption", "average", "utility", "gain", "per", "trial", "would", "close", "game", "expected", "utility", "establish", "average", "utility", "gain", "per", "trial", "would", "high", "probability", "close", "game", "expected", "utility", "high", "probabilityeven", "probability", "1is", "certainty", "standard", "probability", "theory", "reject", "cournot", "principle", "say", "event", "low", "zero", "probability", "happen", "see", "shafer", "2005", "defense", "cournot", "principle", "sequence", "independent", "identically", "distributed", "trial", "possible", "average", "utility", "payoff", "per", "trial", "diverge", "arbitrarily", "far", "expected", "utility", "individual", "trial", "22", "representation", "theorem", "second", "type", "argument", "expected", "utility", "theory", "relies", "socalled", "representation", "theorem", "follow", "zynda", "2000", "formulation", "argumentslightly", "modified", "reflect", "role", "utility", "well", "probability", "argument", "three", "premise", "rationality", "condition", "axiom", "expected", "utility", "theory", "axiom", "rational", "preference", "representability", "person", "preference", "obey", "axiom", "expected", "utility", "theory", "represented", "degree", "belief", "obey", "law", "probability", "calculus", "utility", "function", "prefers", "act", "higher", "expected", "utility", "reality", "condition", "person", "represented", "degree", "belief", "obey", "probability", "calculus", "utility", "function", "prefers", "act", "higher", "expected", "utility", "person", "really", "degree", "belief", "obey", "law", "probability", "calculus", "really", "prefer", "act", "higher", "expected", "utility", "premise", "entail", "following", "conclusion", "person", "fails", "prefer", "act", "higher", "expected", "utility", "person", "violates", "least", "one", "axiom", "rational", "preference", "premise", "true", "argument", "show", "something", "wrong", "people", "whose", "preference", "odds", "expected", "utility", "theorythey", "violate", "axiom", "rational", "preference", "let", "u", "consider", "premise", "greater", "detail", "beginning", "key", "premise", "representability", "probability", "function", "utility", "function", "together", "represent", "set", "preference", "case", "following", "formula", "hold", "value", "a", "b", "domain", "preference", "relation", "eu", "gt", "eu", "b", "text", "text", "preferred", "b", "mathematical", "proof", "representability", "called", "representation", "theorem", "section", "21", "survey", "three", "influential", "representation", "theorem", "relies", "different", "set", "axiom", "matter", "set", "axiom", "use", "rationality", "condition", "controversial", "case", "preference", "seem", "rationally", "permissibleperhaps", "even", "rationally", "requiredviolate", "axiom", "expected", "utility", "theory", "section", "3", "discus", "case", "detail", "reality", "condition", "also", "controversial", "hampton", "1994", "zynda", "2000", "meacham", "weisberg", "2011", "point", "representable", "using", "probability", "utility", "function", "probability", "utility", "function", "agent", "represented", "expected", "utility", "maximizer", "degree", "belief", "obey", "probability", "calculus", "also", "represented", "someone", "fails", "maximize", "expected", "utility", "degree", "belief", "violate", "probability", "calculus", "think", "expected", "utility", "representation", "right", "one", "several", "option", "perhaps", "defender", "representation", "theorem", "stipulate", "particular", "degree", "belief", "utility", "corresponding", "preference", "main", "challenge", "defender", "response", "explain", "representation", "term", "expected", "utility", "explanatorily", "useful", "better", "alternative", "representation", "perhaps", "probability", "utility", "good", "cleanedup", "theoretical", "substitute", "folk", "notion", "belief", "desireprecise", "scientific", "substitute", "folk", "concept", "meacham", "weisberg", "challenge", "response", "arguing", "probability", "utility", "poor", "standin", "folk", "notion", "third", "possibility", "suggested", "zynda", "fact", "degree", "belief", "made", "true", "independently", "agent", "preference", "provide", "principled", "way", "restrict", "range", "acceptable", "representation", "challenge", "defender", "type", "response", "specify", "additional", "fact", "turn", "consider", "three", "influential", "representation", "theorem", "representation", "theorem", "differ", "three", "philosophically", "significant", "way", "first", "different", "representation", "theorem", "disagree", "object", "preference", "utility", "repeatable", "must", "wholly", "within", "agent", "control", "second", "representation", "theorem", "differ", "treatment", "probability", "disagree", "entity", "probability", "whether", "object", "probability", "utility", "third", "every", "representation", "theorem", "prof", "suitable", "preference", "ordering", "exist", "probability", "utility", "function", "representing", "preference", "ordering", "differ", "unique", "probability", "utility", "function", "word", "differ", "transformation", "probability", "utility", "function", "allowable", "221", "ramsey", "idea", "representation", "theorem", "expected", "utility", "date", "back", "ramsey", "1926", "sketch", "representation", "theorem", "subsequently", "filled", "bradley", "2004", "elliott", "2017", "ramsey", "assumes", "preference", "defined", "domain", "gamble", "yield", "one", "prize", "condition", "proposition", "p", "true", "different", "prize", "condition", "p", "false", "example", "gamble", "receive", "onesie", "baby", "bottle", "scotch", "otherwise", "receive", "twenty", "dollar", "bojack", "win", "kentucky", "derby", "lose", "dollar", "otherwise", "ramsey", "call", "proposition", "ethically", "neutral", "two", "possible", "world", "differing", "regard", "truth", "always", "equal", "value", "ethically", "neutral", "proposition", "probability", "12", "defined", "term", "preference", "proposition", "probability", "12", "case", "indifferent", "side", "bet", "bojack", "win", "kentucky", "derby", "ethically", "neutral", "proposition", "probability", "12", "case", "indifferent", "winning", "twenty", "dollar", "true", "losing", "dollar", "otherwise", "winning", "twenty", "dollar", "false", "losing", "dollar", "otherwise", "positing", "ethically", "neutral", "proposition", "probability", "12", "together", "rich", "space", "prize", "ramsey", "defines", "numerical", "utility", "prize", "rough", "idea", "indifferent", "receiving", "middling", "prize", "m", "certain", "gamble", "yield", "better", "prize", "b", "ethically", "neutral", "proposition", "true", "worse", "prize", "w", "fall", "utility", "m", "halfway", "utility", "b", "w", "using", "numerical", "utility", "exploit", "definition", "expected", "utility", "define", "probability", "proposition", "rough", "idea", "exploit", "richness", "space", "prize", "ensures", "gamble", "g", "yield", "better", "prize", "b", "e", "true", "worse", "prize", "w", "e", "false", "agent", "indifferent", "g", "middling", "prize", "m", "mean", "eu", "g", "eu", "using", "algebra", "plus", "fact", "eu", "g", "p", "e", "u", "b", "1p", "e", "u", "w", "ramsey", "show", "p", "e", "frac", "1", "u", "u", "b", "u", "w", "222", "von", "neumann", "morgenstern", "von", "neumann", "morgenstern", "1944", "claim", "preference", "defined", "domain", "lottery", "lottery", "constant", "yield", "single", "prize", "certainty", "prize", "might", "include", "banana", "million", "dollar", "million", "dollar", "worth", "debt", "death", "new", "car", "lottery", "also", "lottery", "prize", "one", "lottery", "40", "chance", "yielding", "banana", "60", "chance", "yielding", "5050", "gamble", "million", "dollar", "death", "domain", "lottery", "closed", "mixing", "operation", "l", "l", "lottery", "x", "real", "number", "0", "1", "interval", "lottery", "x", "l", "1x", "l", "yield", "l", "probability", "x", "l", "probability", "1x", "show", "every", "preference", "relation", "obeying", "certain", "axiom", "represented", "probability", "used", "define", "lottery", "together", "utility", "function", "unique", "positive", "linear", "transformation", "223", "savage", "instead", "taking", "probability", "granted", "von", "neumann", "morgenstern", "savage", "1972", "defines", "term", "preference", "act", "savage", "posit", "three", "separate", "domain", "probability", "attache", "event", "think", "disjunction", "state", "utility", "intrinsic", "preference", "attach", "outcome", "expected", "utility", "nonintrinsic", "preference", "attach", "act", "savage", "act", "state", "outcome", "must", "satisfy", "certain", "constraint", "act", "must", "wholly", "agent", "control", "publishing", "paper", "mind", "act", "since", "depends", "partly", "editor", "decision", "control", "outcome", "must", "utility", "regardless", "state", "obtains", "win", "fancy", "car", "outcome", "since", "utility", "fancy", "car", "greater", "state", "person", "want", "impress", "wish", "fancy", "car", "le", "state", "lose", "driver", "license", "state", "rule", "performance", "act", "act", "state", "together", "must", "determine", "outcome", "certainty", "outcome", "o", "constant", "act", "yield", "o", "every", "state", "thus", "world", "peace", "outcome", "act", "result", "world", "peace", "matter", "state", "world", "finally", "assumes", "two", "act", "a", "b", "event", "e", "mixed", "act", "a_e", "amp", "b_", "sim", "e", "yield", "outcome", "a", "e", "true", "outcome", "b", "otherwise", "thus", "world", "peace", "end", "world", "outcome", "mixed", "act", "result", "world", "peace", "certain", "coin", "land", "head", "end", "world", "otherwise", "savage", "postulate", "preference", "relation", "act", "give", "axiom", "governing", "preference", "relation", "defines", "subjective", "probability", "degree", "belief", "term", "preference", "key", "move", "define", "least", "likely", "relation", "event", "paraphrase", "suppose", "a", "b", "constant", "act", "a", "preferred", "b", "e", "least", "likely", "f", "case", "agent", "either", "prefers", "a_e", "amp", "b_", "sim", "e", "act", "yield", "a", "e", "obtains", "b", "otherwise", "a_f", "amp", "b_", "sim", "f", "act", "yield", "a", "f", "obtains", "b", "otherwise", "else", "indifferent", "a_e", "amp", "b_", "sim", "e", "a_f", "amp", "b_", "sim", "f", "thought", "behind", "definition", "agent", "considers", "e", "least", "likely", "f", "case", "would", "rather", "bet", "f", "e", "savage", "give", "axiom", "constraining", "rational", "preference", "show", "set", "preference", "satisfying", "axiom", "yield", "least", "likely", "relation", "uniquely", "represented", "probability", "function", "word", "one", "one", "probability", "function", "p", "e", "f", "p", "e", "ge", "p", "f", "e", "least", "likely", "f", "every", "preference", "relation", "obeying", "savage", "axiom", "represented", "probability", "function", "p", "together", "utility", "function", "unique", "positive", "linear", "transformation", "savage", "representation", "theorem", "give", "strong", "result", "starting", "preference", "ordering", "alone", "find", "single", "probability", "function", "narrow", "class", "utility", "function", "represent", "preference", "ordering", "downside", "however", "savage", "build", "implausibly", "strong", "assumption", "domain", "act", "luce", "suppes", "1965", "point", "savage", "constant", "act", "implausible", "recall", "constant", "act", "yield", "outcome", "amount", "value", "every", "state", "take", "good", "outcometotal", "bliss", "everyone", "really", "constant", "act", "outcome", "every", "possible", "state", "including", "state", "human", "race", "wiped", "meteor", "savage", "reliance", "rich", "space", "mixed", "act", "also", "problematic", "savage", "assume", "two", "outcome", "event", "mixed", "act", "yield", "first", "outcome", "event", "occurs", "second", "outcome", "otherwise", "really", "act", "yield", "total", "bliss", "everyone", "killed", "antibioticresistant", "plague", "total", "misery", "otherwise", "luce", "krantz", "1971", "suggest", "way", "reformulating", "savage", "representation", "theorem", "weaken", "assumption", "joyce", "1999", "argues", "even", "weakened", "assumption", "domain", "act", "remains", "implausibly", "rich", "224", "bolker", "jeffrey", "bolker", "1966", "prof", "general", "representation", "theorem", "mathematical", "expectation", "jeffrey", "1983", "us", "basis", "philosophical", "account", "expected", "utility", "theory", "bolker", "theorem", "assumes", "single", "domain", "proposition", "object", "preference", "utility", "probability", "alike", "thus", "proposition", "rain", "today", "utility", "well", "probability", "jeffrey", "interprets", "utility", "proposition", "news", "valuea", "measure", "happy", "disappointed", "would", "learn", "proposition", "true", "convention", "set", "value", "necessary", "proposition", "0the", "necessary", "proposition", "news", "likewise", "proposition", "take", "umbrella", "work", "act", "probability", "well", "utility", "jeffrey", "interprets", "mean", "degree", "belief", "bolker", "give", "axiom", "constraining", "preference", "show", "preference", "satisfying", "axiom", "represented", "probability", "measure", "p", "utility", "measure", "u", "however", "bolker", "axiom", "ensure", "p", "unique", "u", "unique", "positive", "linear", "transformation", "allow", "u", "define", "comparative", "probability", "term", "preference", "instead", "p", "u", "jointly", "represent", "preference", "ordering", "bolker", "show", "pair", "langle", "p", "u", "rangle", "unique", "fractional", "linear", "transformation", "technical", "term", "u", "utility", "function", "normalized", "u", "omega", "0", "inf", "greatest", "lower", "bound", "value", "assigned", "u", "sup", "least", "upper", "bound", "value", "assigned", "u", "lambda", "parameter", "falling", "1inf", "1sup", "fractional", "linear", "transformation", "langle", "p_", "lambda", "u_", "lambda", "rangle", "langle", "p", "u", "rangle", "corresponding", "lambda", "given", "begin", "align", "p_", "lambda", "p", "x", "1", "lambda", "u", "x", "u_", "lambda", "u", "x", "1lambda", "1", "lambda", "u", "x", "end", "align", "notice", "fractional", "linear", "transformation", "probabilityutility", "pair", "disagree", "original", "pair", "proposition", "likelier", "others", "joyce", "1999", "show", "additional", "resource", "bolker", "theorem", "modified", "pin", "unique", "p", "u", "unique", "positive", "linear", "transformation", "need", "supplement", "preference", "ordering", "primitive", "likely", "relation", "governed", "set", "axiom", "linked", "belief", "several", "additional", "axiom", "joyce", "modifies", "bolker", "result", "show", "given", "additional", "axiom", "likely", "relation", "represented", "unique", "p", "preference", "ordering", "represented", "p", "together", "utility", "function", "unique", "positive", "linear", "transformation", "225", "summary", "together", "four", "representation", "theorem", "summed", "following", "table", "theorem", "object", "ofpreference", "order", "ofconstruction", "allowabletransformations", "probability", "allowabletransformations", "utility", "ramsey", "gamble", "preference", "utility", "probability", "identity", "positive", "linear", "von", "neumannmorgenstern", "lottery", "preference", "probability", "utility", "na", "positive", "linear", "savage", "act", "preference", "probability", "utility", "identity", "positive", "linear", "jeffreybolker", "proposition", "preference", "probability", "utility", "fractional", "linear", "notice", "order", "construction", "differs", "theorem", "ramsey", "construct", "representation", "probability", "using", "utility", "von", "neumann", "morgenstern", "begin", "probability", "construct", "representation", "utility", "thus", "although", "arrow", "represent", "mathematical", "relationship", "representation", "represent", "metaphysical", "relationship", "grounding", "reality", "condition", "need", "justified", "independently", "representation", "theorem", "suitably", "structured", "ordinal", "probability", "relation", "picked", "least", "likely", "likely", "equally", "likely", "stand", "onetoone", "correspondence", "cardinal", "probability", "function", "finally", "grey", "line", "preference", "ordinal", "probability", "indicates", "every", "probability", "function", "satisfying", "savage", "axiom", "represented", "unique", "cardinal", "probabilitybut", "result", "hold", "jeffrey", "axiom", "notice", "often", "possible", "follow", "arrow", "circlesfrom", "preference", "ordinal", "probability", "ordinal", "probability", "cardinal", "probability", "cardinal", "probability", "preference", "expected", "utility", "expected", "utility", "back", "preference", "thus", "although", "arrow", "represent", "mathematical", "relationship", "representation", "represent", "metaphysical", "relationship", "grounding", "fact", "drive", "home", "importance", "independently", "justifying", "reality", "conditionrepresentation", "theorem", "justify", "expected", "utility", "theory", "without", "additional", "assumption", "3", "objection", "expected", "utility", "theory", "31", "maximizing", "expected", "utility", "impossible", "ought", "implies", "humanly", "possible", "maximize", "expected", "utility", "march", "simon", "1958", "point", "order", "compute", "expected", "utility", "agent", "need", "dauntingly", "complex", "understanding", "available", "act", "possible", "outcome", "value", "outcome", "choosing", "best", "act", "much", "demanding", "choosing", "act", "merely", "good", "enough", "similar", "point", "appear", "lindblom", "1959", "feldman", "2006", "smith", "2010", "mcgee", "1991", "argues", "maximizing", "expected", "utility", "mathematically", "possible", "even", "ideal", "computer", "limitless", "memory", "order", "maximize", "expected", "utility", "would", "accept", "bet", "offered", "truth", "arithmetic", "reject", "bet", "offered", "false", "sentence", "language", "arithmetic", "arithmetic", "undecidable", "turing", "machine", "determine", "whether", "given", "arithmetical", "sentence", "true", "false", "one", "response", "difficulty", "bounded", "rationality", "approach", "aim", "replace", "expected", "utility", "theory", "tractable", "rule", "another", "argue", "demand", "expected", "utility", "theory", "tractable", "appear", "burchbrown", "2014", "see", "also", "greave", "2016", "relevant", "ought", "implies", "principle", "false", "srinivasan", "2015", "32", "maximizing", "expected", "utility", "irrational", "variety", "author", "given", "example", "expected", "utility", "theory", "seems", "give", "wrong", "prescription", "section", "321", "322", "discus", "example", "rationality", "seems", "permit", "preference", "inconsistent", "expected", "utility", "theory", "example", "suggest", "maximizing", "expected", "utility", "necessary", "rationality", "section", "323", "discus", "example", "expected", "utility", "theory", "permit", "preference", "seem", "irrational", "example", "suggest", "maximizing", "expected", "utility", "sufficient", "rationality", "section", "324", "discus", "example", "expected", "utility", "theory", "requires", "preference", "seem", "rationally", "forbiddena", "challenge", "necessity", "sufficiency", "expected", "utility", "rationality", "321", "counterexample", "involving", "transitivity", "completeness", "expected", "utility", "theory", "implies", "structure", "preference", "mirror", "structure", "greaterthan", "relation", "real", "number", "thus", "according", "expected", "utility", "theory", "preference", "must", "transitive", "a", "preferred", "b", "u", "gt", "u", "b", "b", "preferred", "c", "u", "b", "gt", "u", "c", "a", "must", "preferred", "c", "since", "must", "u", "gt", "u", "c", "likewise", "preference", "must", "complete", "two", "option", "either", "one", "must", "preferred", "agent", "must", "indifferent", "since", "two", "utility", "either", "one", "must", "greater", "two", "must", "equal", "case", "rationality", "seems", "permit", "perhaps", "even", "require", "failure", "transitivity", "failure", "completeness", "example", "preference", "transitive", "nonetheless", "seem", "rationally", "permissible", "quinn", "puzzle", "selftorturer", "1990", "selftorturer", "hooked", "machine", "dial", "setting", "labeled", "0", "1000", "setting", "0", "nothing", "successive", "setting", "delivers", "slightly", "powerful", "electric", "shock", "setting", "0", "painless", "setting", "1000", "cause", "excruciating", "agony", "difference", "two", "adjacent", "setting", "small", "imperceptible", "dial", "fitted", "ratchet", "turned", "never", "suppose", "setting", "selftorturer", "offered", "10000", "move", "next", "tolerating", "setting", "n", "receives", "payoff", "n", "cdot", "10000", "permissible", "selftorturer", "prefer", "setting", "n1", "setting", "n", "n", "0", "999", "since", "difference", "pain", "imperceptible", "difference", "monetary", "payoff", "significant", "prefer", "setting", "1000", "setting", "0", "since", "pain", "setting", "1000", "may", "unbearable", "amount", "money", "make", "also", "seems", "rationally", "permissible", "incomplete", "preference", "pair", "action", "agent", "may", "considered", "view", "prefers", "consider", "jane", "electrician", "never", "given", "much", "thought", "becoming", "professional", "singer", "professional", "astronaut", "perhaps", "option", "infeasible", "perhaps", "considers", "much", "worse", "steady", "job", "electrician", "false", "jane", "prefers", "becoming", "singer", "becoming", "astronaut", "false", "prefers", "becoming", "astronaut", "becoming", "singer", "also", "false", "indifferent", "becoming", "singer", "becoming", "astronaut", "prefers", "becoming", "singer", "receiving", "100", "bonus", "becoming", "singer", "indifferent", "becoming", "singer", "becoming", "astronaut", "would", "rationally", "compelled", "prefer", "singer", "receiving", "100", "bonus", "becoming", "astronaut", "one", "key", "difference", "two", "example", "considered", "jane", "preference", "extended", "adding", "new", "preference", "without", "removing", "one", "way", "let", "u", "represent", "expected", "utility", "maximizer", "hand", "way", "extended", "selftorturer", "preference", "represented", "expected", "utility", "maximizer", "preference", "would", "altered", "one", "popular", "response", "incomplete", "preference", "claim", "rational", "preference", "need", "satisfy", "axiom", "given", "representation", "theorem", "see", "section", "22", "must", "possible", "extend", "satisfy", "axiom", "weaker", "requirement", "preferencesthat", "extendible", "preference", "ordering", "satisfies", "relevant", "axiomsone", "prove", "existence", "half", "relevant", "representation", "theorem", "however", "one", "longer", "establish", "preference", "ordering", "representation", "unique", "allowable", "transformation", "response", "available", "case", "selftorturer", "whose", "preference", "extended", "satisfy", "axiom", "expected", "utility", "theory", "see", "entry", "preference", "extended", "discussion", "selftorturer", "case", "322", "counterexample", "involving", "independence", "allais", "1953", "ellsberg", "1961", "propose", "example", "preference", "represented", "expected", "utility", "function", "nonetheless", "seem", "rational", "example", "involve", "violation", "savage", "independence", "axiom", "independence", "suppose", "a", "a", "two", "act", "produce", "outcome", "event", "e", "false", "act", "b", "one", "must", "a", "preferred", "a", "a_e", "amp", "b_", "sim", "e", "preferred", "a", "_e", "amp", "b_", "sim", "e", "agent", "indifferent", "a", "a", "indifferent", "a_e", "amp", "b_", "sim", "e", "a", "_e", "amp", "b_", "sim", "e", "word", "two", "act", "consequence", "whenever", "e", "false", "agent", "preference", "two", "act", "depend", "consequence", "e", "true", "savage", "definition", "expected", "utility", "expected", "utility", "theory", "entail", "independence", "jeffrey", "definition", "expected", "utility", "theory", "entail", "independence", "presence", "assumption", "state", "probabilistically", "independent", "act", "first", "counterexample", "allais", "paradox", "involves", "two", "separate", "decision", "problem", "ticket", "number", "1", "100", "drawn", "random", "first", "problem", "agent", "must", "choose", "two", "lottery", "lottery", "a", "100", "million", "certainty", "lottery", "b", "500", "million", "one", "ticket", "110", "drawn", "100", "million", "one", "ticket", "12100", "drawn", "nothing", "ticket", "11", "drawn", "second", "decision", "problem", "agent", "must", "choose", "two", "lottery", "lottery", "c", "100", "million", "one", "ticket", "111", "drawn", "nothing", "otherwise", "lottery", "d", "500", "million", "one", "ticket", "110", "drawn", "nothing", "otherwise", "seems", "reasonable", "prefer", "a", "offer", "sure", "100", "million", "b", "added", "10", "chance", "500", "million", "offset", "risk", "getting", "nothing", "also", "seems", "reasonable", "prefer", "d", "10", "chance", "500", "million", "prize", "c", "slightly", "larger", "11", "chance", "much", "smaller", "100", "million", "prize", "together", "preference", "call", "allais", "preference", "violate", "independence", "lottery", "a", "c", "yield", "100", "million", "prize", "ticket", "12100", "converted", "lottery", "b", "d", "replacing", "100", "million", "prize", "0", "violate", "independence", "allais", "preference", "incompatible", "expected", "utility", "theory", "incompatibility", "require", "assumption", "relative", "utility", "0", "100", "million", "500", "million", "500", "million", "utility", "x", "100", "million", "utility", "y", "0", "utility", "z", "expected", "utility", "lottery", "follows", "begin", "align", "eu", "011y", "089y", "eu", "b", "010x", "001z", "089y", "eu", "c", "011y", "089z", "eu", "010x", "001z", "089z", "end", "align", "easy", "see", "condition", "eu", "gt", "eu", "b", "exactly", "condition", "eu", "c", "gt", "eu", "inequality", "obtain", "case", "011y", "gt", "010x", "001z", "ellsberg", "paradox", "also", "involves", "two", "decision", "problem", "generate", "violation", "surething", "principle", "ball", "drawn", "urn", "containing", "30", "red", "ball", "60", "ball", "either", "white", "yellow", "unknown", "proportion", "first", "decision", "problem", "agent", "must", "choose", "following", "lottery", "lottery", "r", "win", "100", "red", "ball", "drawn", "lose", "100", "otherwise", "lottery", "w", "win", "100", "white", "ball", "drawn", "lose", "100", "otherwise", "second", "decision", "problem", "agent", "must", "choose", "following", "lottery", "lottery", "ry", "win", "100", "red", "yellow", "ball", "drawn", "lose", "100", "otherwise", "lottery", "wy", "win", "100", "white", "yellow", "ball", "drawn", "lose", "100", "otherwise", "seems", "reasonable", "prefer", "r", "w", "time", "prefer", "wy", "ry", "call", "combination", "preference", "ellsberg", "preference", "like", "allais", "preference", "ellsberg", "preference", "violate", "independence", "lottery", "w", "r", "yield", "100", "loss", "yellow", "ball", "drawn", "converted", "lottery", "ry", "wy", "simply", "replacing", "100", "loss", "sure", "100", "gain", "violate", "independence", "ellsberg", "preference", "incompatible", "expected", "utility", "theory", "incompatibility", "require", "assumption", "relative", "utility", "winning", "100", "losing", "100", "need", "assumption", "0", "13", "probability", "drawing", "yellow", "ball", "fall", "winning", "100", "utility", "w", "losing", "100", "utility", "l", "begin", "align", "eu", "r", "tfrac", "1", "3", "w", "p", "w", "l", "p", "l", "eu", "w", "tfrac", "1", "3", "l", "p", "w", "w", "p", "l", "eu", "ry", "tfrac", "1", "3", "w", "p", "w", "l", "p", "w", "eu", "wy", "tfrac", "1", "3", "l", "p", "w", "w", "p", "w", "end", "align", "easy", "see", "condition", "eu", "r", "gt", "eu", "w", "exactly", "condition", "eu", "ry", "gt", "eu", "wy", "inequality", "obtain", "case", "13", "w", "p", "w", "l", "gt", "13", "l", "p", "w", "w", "three", "notable", "response", "allais", "ellsberg", "paradox", "first", "one", "might", "follow", "savage", "101", "ff", "raiffa", "1968", "8086", "defend", "expected", "utility", "theory", "ground", "allais", "ellsberg", "preference", "irrational", "second", "one", "might", "follow", "buchak", "2013", "claim", "allais", "ellsberg", "preference", "rationally", "permissible", "expected", "utility", "theory", "fails", "normative", "theory", "rationality", "buchak", "develops", "permissive", "theory", "rationality", "extra", "parameter", "representing", "decisionmaker", "attitude", "toward", "risk", "risk", "parameter", "interacts", "utility", "outcome", "conditional", "probability", "act", "determine", "value", "act", "one", "setting", "risk", "parameter", "yield", "expected", "utility", "theory", "special", "case", "riskaverse", "setting", "rationalise", "allais", "preference", "third", "one", "might", "follow", "loomes", "sugden", "1986", "weirich", "1986", "pope", "1995", "argue", "outcome", "allais", "ellsberg", "paradox", "redescribed", "accommodate", "allais", "ellsberg", "preference", "alleged", "conflict", "allais", "ellsberg", "preference", "one", "hand", "expected", "utility", "theory", "based", "assumption", "given", "sum", "money", "utility", "matter", "obtained", "author", "challenge", "assumption", "loomes", "sugden", "suggest", "addition", "monetary", "amount", "outcome", "gamble", "include", "feeling", "disappointment", "elation", "getting", "le", "expected", "pope", "distinguishes", "postoutcome", "feeling", "elation", "disappointment", "preoutcome", "feeling", "excitement", "fear", "boredom", "safety", "point", "may", "affect", "outcome", "utility", "weirich", "suggests", "value", "monetary", "sum", "depends", "partly", "risk", "went", "obtaining", "irrespective", "gambler", "feeling", "instance", "100", "million", "result", "sure", "bet", "100", "million", "gamble", "might", "paid", "nothing", "broome", "1991", "ch", "5", "raise", "worry", "redescription", "solution", "preference", "justified", "redescribing", "space", "outcome", "thus", "rendering", "axiom", "expected", "utility", "theory", "devoid", "content", "broome", "rebuts", "objection", "suggesting", "additional", "constraint", "preference", "a", "preferred", "b", "a", "b", "must", "differ", "way", "justifies", "preferring", "one", "expected", "utility", "theorist", "count", "allais", "ellsberg", "preference", "rational", "nonmonetary", "difference", "justifies", "placing", "outcome", "equal", "monetary", "value", "different", "spot", "one", "preference", "ordering", "323", "counterexample", "involving", "probability", "0", "event", "seen", "purported", "example", "rational", "preference", "violate", "expected", "utility", "theory", "also", "purported", "example", "irrational", "preference", "satisfy", "expected", "utility", "theory", "typical", "understanding", "expected", "utility", "theory", "two", "act", "tied", "highest", "expected", "utility", "agent", "required", "indifferent", "skyrms", "1980", "p", "74", "point", "view", "let", "u", "derive", "strange", "conclusion", "event", "probability", "0", "instance", "suppose", "throw", "pointsized", "dart", "round", "dartboard", "classical", "probability", "theory", "countenance", "situation", "dart", "probability", "0", "hitting", "particular", "point", "offer", "following", "lousy", "deal", "dart", "hit", "board", "exact", "center", "charge", "100", "otherwise", "money", "change", "hand", "decision", "problem", "captured", "following", "matrix", "state", "hit", "center", "p0", "miss", "center", "p1", "act", "accept", "deal", "100", "0", "refuse", "deal", "0", "0", "expected", "utility", "theory", "say", "permissible", "accept", "dealaccepting", "expected", "utility", "0", "jeffrey", "definition", "savage", "definition", "assume", "dart", "land", "probabilistically", "independent", "bet", "common", "sense", "say", "permissible", "accept", "deal", "refusing", "weakly", "dominates", "accepting", "yield", "better", "outcome", "state", "worse", "outcome", "state", "skyrms", "suggests", "augmenting", "law", "classical", "probability", "extra", "requirement", "impossibility", "assigned", "probability", "0", "easwaran", "2014", "argues", "instead", "reject", "view", "expected", "utility", "theory", "command", "indifference", "act", "equal", "expected", "utility", "instead", "expected", "utility", "theory", "complete", "theory", "rationality", "two", "act", "expected", "utility", "tell", "u", "prefer", "use", "nonexpectedutility", "consideration", "like", "weak", "dominance", "tiebreaker", "324", "counterexample", "involving", "unbounded", "utility", "utility", "function", "u", "bounded", "limit", "good", "thing", "according", "u", "formally", "least", "natural", "number", "sup", "every", "a", "u", "domain", "u", "le", "sup", "likewise", "u", "bounded", "limit", "bad", "thing", "according", "u", "formally", "greatest", "natural", "number", "inf", "every", "a", "u", "domain", "u", "ge", "inf", "expected", "utility", "theory", "run", "trouble", "utility", "function", "unbounded", "one", "problematic", "example", "st", "petersburg", "game", "originally", "published", "bernoulli", "suppose", "coin", "tossed", "land", "tail", "first", "time", "land", "tail", "first", "toss", "win", "2", "land", "tail", "second", "toss", "win", "4", "land", "tail", "third", "toss", "win", "8", "land", "tail", "n", "th", "toss", "win", "2n", "assuming", "dollar", "worth", "one", "utile", "expected", "value", "st", "petersburg", "game", "tfrac", "1", "2", "cdot", "2", "tfrac", "1", "4", "cdot", "4", "tfrac", "1", "8", "cdot", "8", "cdots", "tfrac", "1", "2n", "cdot", "2n", "cdots", "1", "1", "1", "cdots", "infty", "turn", "sum", "diverges", "st", "petersburg", "game", "infinite", "expected", "utility", "thus", "according", "expected", "utility", "theory", "prefer", "opportunity", "play", "st", "petersburg", "game", "finite", "sum", "money", "matter", "large", "furthermore", "since", "infinite", "expected", "utility", "multiplied", "nonzero", "chance", "still", "infinite", "anything", "positive", "probability", "yielding", "st", "petersburg", "game", "infinite", "expected", "utility", "thus", "according", "expected", "utility", "theory", "prefer", "chance", "playing", "st", "petersburg", "game", "however", "slim", "finite", "sum", "money", "however", "large", "nover", "h\u00e1jek", "2004", "argue", "addition", "st", "petersburg", "game", "infinite", "expected", "utility", "infinitary", "game", "whose", "expected", "utility", "undefined", "even", "though", "rationality", "mandate", "certain", "preference", "among", "one", "response", "problematic", "infinitary", "game", "argue", "decision", "problem", "illposed", "jeffrey", "1983", "154", "another", "adopt", "modified", "version", "expected", "utility", "theory", "agrees", "verdict", "ordinary", "case", "yield", "intuitively", "reasonable", "verdict", "infinitary", "game", "thalos", "richardson", "2013", "fine", "2008", "colyvan", "2006", "2008", "easwaran", "2008", "4", "application", "41", "economics", "public", "policy", "1940s", "50", "expected", "utility", "theory", "gained", "currency", "u", "potential", "provide", "mechanism", "would", "explain", "behavior", "macroeconomic", "variable", "became", "apparent", "expected", "utility", "theory", "accurately", "predict", "behavior", "real", "people", "proponent", "instead", "advanced", "view", "might", "serve", "instead", "theory", "rational", "people", "respond", "uncertainty", "see", "herfeld", "2017", "expected", "utility", "theory", "variety", "application", "public", "policy", "welfare", "economics", "harsanyi", "1953", "reason", "expected", "utility", "theory", "claim", "socially", "arrangement", "one", "maximizes", "total", "welfare", "distributed", "across", "society", "society", "theory", "expected", "utility", "also", "direct", "application", "howard", "1980", "introduces", "concept", "micromort", "oneinamillion", "chance", "death", "us", "expected", "utility", "calculation", "gauge", "mortality", "risk", "acceptable", "health", "policy", "qualityadjusted", "life", "year", "qalys", "measure", "expected", "utility", "different", "health", "intervention", "used", "guide", "health", "policy", "see", "weinstein", "et", "al", "2009", "mcaskill", "2015", "us", "expected", "utility", "theory", "address", "central", "question", "effective", "altruism", "good", "utilties", "application", "naturally", "interpreted", "measuring", "something", "like", "happiness", "wellbeing", "rather", "subjective", "preference", "satisfaction", "individual", "agent", "another", "area", "expected", "utility", "theory", "find", "application", "insurance", "sale", "like", "casino", "insurance", "company", "take", "calculated", "risk", "aim", "longterm", "financial", "gain", "must", "take", "account", "chance", "going", "broke", "short", "run", "42", "ethic", "utilitarian", "along", "descendant", "contemporary", "consequentialists", "hold", "rightness", "wrongness", "act", "determined", "moral", "goodness", "badness", "consequence", "consequentialists", "railton", "1984", "interpret", "mean", "ought", "whatever", "fact", "best", "consequence", "difficultperhaps", "impossibleto", "know", "longterm", "consequence", "act", "lenman", "2000", "howardsnyder", "2007", "light", "observation", "jackson", "1991", "argues", "right", "act", "one", "greatest", "expected", "moral", "value", "one", "fact", "yield", "best", "consequence", "jackson", "note", "expected", "moral", "value", "act", "depends", "probability", "function", "work", "jackson", "argues", "every", "probability", "function", "associated", "ought", "ought", "matter", "action", "one", "associated", "decisionmaker", "degree", "belief", "time", "action", "author", "claim", "priority", "oughts", "mason", "2013", "favor", "probability", "function", "reasonable", "agent", "adopt", "response", "evidence", "given", "epistemic", "limitation", "oddie", "menzies", "1992", "favor", "objective", "chance", "function", "measure", "objective", "rightness", "appeal", "complicated", "probability", "function", "define", "notion", "subjective", "rightness", "decisionmakers", "ignorant", "objective", "chance", "still", "others", "smart", "1973", "timmons", "2002", "argue", "even", "ought", "whatever", "best", "consequence", "expected", "utility", "theory", "play", "role", "decision", "procedure", "uncertain", "consequence", "act", "feldman", "2006", "object", "expected", "utility", "calculation", "horribly", "impractical", "real", "life", "decision", "step", "required", "compute", "expected", "utility", "beyond", "ken", "listing", "possible", "outcome", "act", "assigning", "outcome", "utility", "conditional", "probability", "given", "act", "performing", "arithmetic", "necessary", "expected", "utility", "calculation", "expectedutilitymaximizing", "version", "consequentialism", "strictly", "speaking", "theory", "rational", "choice", "theory", "moral", "choice", "whether", "rationality", "requires", "u", "morally", "best", "debate", "43", "epistemology", "expected", "utility", "theory", "used", "address", "practical", "question", "epistemology", "one", "question", "accept", "hypothesis", "typical", "case", "evidence", "logically", "compatible", "multiple", "hypothesis", "including", "hypothesis", "lends", "little", "inductive", "support", "furthermore", "scientist", "typically", "accept", "hypothesis", "probable", "given", "data", "hypothesis", "likely", "enough", "deserve", "acceptance", "bayesians", "maher", "1993", "suggest", "decision", "made", "expected", "utility", "ground", "whether", "accept", "hypothesis", "decision", "problem", "acceptance", "rejection", "act", "captured", "following", "decision", "matrix", "state", "hypothesis", "true", "hypothesis", "false", "act", "accept", "correctly", "accept", "erroneously", "accept", "reject", "erroneously", "reject", "correctly", "reject", "savage", "definition", "expected", "utility", "accepting", "hypothesis", "determined", "probability", "hypothesis", "together", "utility", "four", "outcome", "expect", "jeffrey", "definition", "agree", "savage", "plausible", "assumption", "given", "evidence", "possession", "hypothesis", "probabilistically", "independent", "whether", "accept", "reject", "utility", "understood", "purely", "epistemic", "value", "since", "epistemically", "valuable", "believe", "interesting", "truth", "reject", "falsehood", "critic", "bayesian", "approach", "mayo", "1996", "object", "scientific", "hypothesis", "sensibly", "given", "probability", "mayo", "argues", "order", "assign", "useful", "probability", "event", "need", "statistical", "evidence", "frequency", "similar", "event", "scientific", "hypothesis", "either", "true", "false", "allthere", "population", "world", "like", "meaningfully", "draw", "statistic", "use", "subjective", "probability", "scientific", "purpose", "since", "would", "unacceptably", "arbitrary", "therefore", "expected", "utility", "acceptance", "rejection", "undefined", "ought", "use", "method", "traditional", "statistic", "rely", "comparing", "probability", "evidence", "conditional", "hypothesis", "expected", "utility", "theory", "also", "provides", "guidance", "gather", "evidence", "good", "1967", "argues", "expected", "utility", "ground", "always", "rational", "gather", "evidence", "acting", "provided", "evidence", "free", "cost", "act", "highest", "expected", "utility", "extra", "evidence", "always", "always", "least", "good", "act", "highest", "expected", "utility", "beforehand", "epistemic", "decision", "theory", "expected", "utility", "used", "ass", "belief", "state", "rational", "irrational", "think", "belief", "formation", "mental", "act", "fact", "content", "agent", "belief", "event", "closeness", "truth", "desirable", "feature", "outcome", "use", "expected", "utility", "theory", "evaluate", "degree", "belief", "term", "expected", "closeness", "truth", "entry", "epistemic", "utility", "argument", "probabilism", "includes", "overview", "expected", "utility", "argument", "variety", "epistemic", "norm", "including", "conditionalization", "principal", "principle", "44", "law", "kaplan", "1968", "argues", "expected", "utility", "consideration", "used", "fix", "standard", "proof", "legal", "trial", "jury", "deciding", "whether", "acquit", "convict", "face", "following", "decision", "problem", "state", "guilty", "innocent", "act", "convict", "true", "conviction", "false", "conviction", "acquit", "false", "acquittal", "true", "acquittal", "kaplan", "show", "eu", "convict", "eu", "acquit", "whenever", "p", "guilty", "frac", "1", "1", "frac", "u", "mathrm", "trueconviction", "u", "mathrm", "falseacquittal", "u", "mathrm", "trueacquittal", "u", "mathrm", "falseconviction", "qualitatively", "mean", "standard", "proof", "increase", "disutility", "convicting", "innocent", "person", "u", "mathrm", "trueconviction", "u", "mathrm", "falseacquittal", "increase", "disutility", "acquitting", "guilty", "person", "u", "mathrm", "trueacquittal", "u", "mathrm", "falseconviction", "decrease", "critic", "decisiontheoretic", "approach", "laudan", "2006", "argue", "difficult", "impossible", "bridge", "gap", "evidence", "admissible", "court", "real", "probability", "defendant", "guilt", "probability", "guilt", "depends", "three", "factor", "distribution", "apparent", "guilt", "among", "genuinely", "guilty", "distribution", "apparent", "guilt", "among", "genuinely", "innocent", "ratio", "genuinely", "guilty", "genuinely", "innocent", "defendant", "go", "trial", "see", "bell", "1987", "obstacle", "calculating", "factor", "block", "inference", "judge", "jury", "perception", "apparent", "guilt", "true", "probability", "guilt"]}