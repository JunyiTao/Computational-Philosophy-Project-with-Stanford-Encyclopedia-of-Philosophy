{"url": "formal-epistemology", "title": "Formal Epistemology", "authorship": {"year": "Copyright \u00a9 2021", "author_text": "Jonathan Weisberg\n<jonathan.weisberg@utoronto.ca>", "author_links": [{"http://www.philosophy.utoronto.ca/directory/jonathan-weisberg/": "Jonathan Weisberg"}, {"mailto:jonathan%2eweisberg%40utoronto%2eca": "jonathan.weisberg@utoronto.ca"}], "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2021</a> by\n\n<br/>\n<a href=\"http://www.philosophy.utoronto.ca/directory/jonathan-weisberg/\" target=\"other\">Jonathan Weisberg</a>\n&lt;<a href=\"mailto:jonathan%2eweisberg%40utoronto%2eca\"><em>jonathan<abbr title=\" dot \">.</abbr>weisberg<abbr title=\" at \">@</abbr>utoronto<abbr title=\" dot \">.</abbr>ca</em></a>&gt;\n    </p>\n</div>"}, "pubinfo": ["First published Mon Mar 2, 2015", "substantive revision Mon Mar 15, 2021"], "preamble": "\n\nFormal epistemology explores knowledge and reasoning using\n\u201cformal\u201d tools, tools from math and logic. For example, a\nformal epistemologist might use probability theory to explain how\nscientific reasoning works. Or she might use modal logic to defend a\nparticular theory of knowledge.\n\nThe questions that drive formal epistemology are often the same as\nthose that drive \u201cinformal\u201d epistemology. What is\nknowledge, and how is it different from mere opinion? What separates\nscience from pseudoscience? When is a belief justified? What justifies\nmy belief that the sun will rise tomorrow, or that the external world\nis real and not an illusion induced by Descartes\u2019 demon?\n\nAnd yet, the tools formal epistemologists apply to these questions\nshare much history and interest with other fields, both inside and\noutside philosophy. So formal epistemologists often ask questions that\naren\u2019t part of the usual epistemological core, questions about\ndecision-making\n (\u00a75.1)\n or the meaning of hypothetical language\n (\u00a75.3),\n for example.\n\nPerhaps the best way to get a feel for formal epistemology is to look\nat concrete examples. We\u2019ll take a few classic epistemological\nquestions and look at popular formal approaches to them, to see what\nformal tools bring to the table. We\u2019ll also look at some\napplications of these formal methods outside epistemology.\n", "toc": [{"#FirCasStuConSciThe": "1. First Case Study: Confirming Scientific Theories"}, {"#DedApp": "1.1 The Deductive Approach"}, {"#ProApp": "1.2 The Probabilistic Approach"}, {"#BasBui": "1.2.1 Basic Building Blocks"}, {"#BayThe": "1.2.2 Bayes\u2019 Theorem"}, {"#QuaConRavPar": "1.3 Quantitative Confirmation & The Raven Paradox"}, {"#ProPri": "1.4 The Problem of the Priors"}, {"#Sum": "1.5 Summary"}, {"#SecCasStuProInd": "2. Second Case Study: The Problem of Induction"}, {"#PriInd": "2.1 The Principle of Indifference"}, {"#UpdInf": "2.2 Updating & Inference"}, {"#ThiCasStuRegPro": "3. Third Case Study: The Regress Problem"}, {"#Coh": "3.1 Coherentism"}, {"#FouA": "3.2 Foundationalism"}, {"#FouCasStuLimKno": "4. Fourth Case Study: The Limits of Knowledge"}, {"#EpiModLog": "4.1 Epistemic Modal Logic"}, {"#KnoParAkaChuFitPar": "4.2 The Knowability Paradox (a.k.a. the Church-Fitch Paradox)"}, {"#SelKno": "4.3 Self-Knowledge"}, {"#FifCasStuSocEpi": "5. Fifth Case Study: Social Epistemology"}, {"#TheZolEff": "5.1 The Zollman Effect"}, {"#MisAndPol": "5.2 Mistrust & Polarization"}, {"#AppOutEpi": "6. Applications Outside Epistemology"}, {"#DecThe": "6.1 Decision Theory"}, {"#ExiGodFinTun": "6.2 The Existence of God: Fine-tuning"}, {"#MeaIfT": "6.3 The Meaning of \u2018If\u2026Then\u2026\u2019"}, {"#Bib": "Bibliography"}, {"#Aca": "Academic Tools"}, {"#Oth": "Other Internet Resources"}, {"#Rel": "Related Entries"}], "main_text": "\n1. First Case Study: Confirming Scientific Theories\n\nHow does scientific reasoning work? In the early 20th\ncentury, large swaths of mathematics were successfully reconstructed\nusing first-order logic. Many philosophers sought a similar\nsystematization of the reasoning in empirical sciences, like biology,\npsychology, and physics. Though empirical sciences rely heavily on\nnon-deductive reasoning, the tools of deductive logic still offer a\npromising starting point.\n1.1 The Deductive Approach\n\nConsider a hypothesis like All electrons have negative\ncharge, which in first-order logic is rendered \\(\\forall x (Ex\n\\supset Nx)\\). Having identified some object \\(a\\) as an electron,\nthis hypothesis deductively entails a prediction, \\(Na\\), that \\(a\\)\nhas negative charge:\n\\[ \\begin{array}{l} \\forall x (Ex \\supset Nx)\\\\ Ea\\\\ \\hline Na\n\\end{array} \\]\n\nIf we test this prediction and observe that, indeed, \\(Na\\), this\nwould seem to support the hypothesis.\n\nScientific hypothesis-testing thus appears to work something like\n\u201cdeduction in reverse\u201d (Goodman 1954). If we swap the\nhypothesis and the predicted datum in the above deduction, we get an\nexample of confirmation:\n\\[ \\begin{array}{l} Ea\\\\ Na\\\\ \\overline{\\overline{\\forall x (Ex\n\\supset Nx)}} \\end{array} \\]\n\nHere the double-line represents non-deductive inference. The inference\nis very weak in this case, since the hypothesis has only been verified\nin one instance, \\(a\\). But as we add further instances \\(b\\), \\(c\\),\netc., it becomes stronger (provided we discover no counter-instances,\nof course).\n\nThese observations suggest a proposal due to Nicod (1930) and famously\nexamined by Hempel (1945):\n\nNicod\u2019s Criterion\n\nA universal generalization is confirmed by its positive instances (as\nlong as no counter-instances are discovered): \\(\\forall x(Fx \\supset\nGx)\\) is confirmed by \\(Fa \\wedge Ga\\), by \\(Fb \\wedge Gb\\), etc.\n\nThe general idea is that hypotheses are confirmed when their\npredictions are borne out. To capture this idea formally in deductive\nlogic, we\u2019re equating prediction with logical entailment. When\nan object is \\(F\\), the hypothesis \\(\\forall x(Fx \\supset Gx)\\)\nentails/predicts that the object is \\(G\\). So any discovery of an\nobject that is both \\(F\\) and \\(G\\) confirms the hypothesis.\n\nOne classic challenge for Nicod\u2019s criterion is the notorious\nraven paradox. Suppose we want to test the hypothesis that\nall ravens are black, which we formalize \\(\\forall x(Rx \\supset Bx)\\).\nThat\u2019s logically equivalent to \\(\\forall x(\\neg Bx \\supset \\neg\nRx)\\), by contraposition. And Nicod\u2019s Criterion says this latter\nhypothesis is confirmed by the discovery of any object that is not\nblack and not a raven\u2014a red shirt, for example, or a pair of\nblue underpants (Hempel 1937, 1945). But walking the halls of my\ndepartment noting non-black non-ravens hardly seems a reasonable way\nto verify that all ravens are black. How can \u201cindoor\nornithology\u201d (Goodman 1954) be good science?!\n\nA second, more general challenge for the prediction-as-deduction\napproach is posed by statistical hypotheses. Suppose we want to test\nthe theory that only 50% of ravens are black. This hypothesis entails\nnothing about the color of an individual raven; it might be one of the\nblack ones, it might not. In fact, even a very large survey of ravens,\nall of which turn out to be black, does not contradict this\nhypothesis. It\u2019s always possible that the 50% of ravens that\naren\u2019t black weren\u2019t caught up in the survey. (Maybe\nnon-black ravens are exceptionally skilled at evasion.)\n\nThis challenge suggests some important lessons. First, we need a laxer\nnotion of prediction than deductive entailment. The 50% hypothesis may\nnot entail that a large survey of ravens will have some\nnon-black ravens, but it does suggest this prediction pretty strongly.\nSecond, as a sort of corollary, confirmation is quantitative: it comes\nin degrees. A single, black raven doesn\u2019t do much to support the\nhypothesis that 50% of ravens are black, but a large sample of roughly\nhalf black, half white ravens would. Third and finally, degrees of\nconfirmation should be understood in terms of probability. The 50%\nhypothesis doesn\u2019t make it very probable that a single raven\nwill be black, but it makes it highly probable that a much larger\ncollection will be roughly half black, half non-black. And the\nall-black hypothesis predicts that any sample of ravens will be\nentirely black with \\(100\\)% probability.\n\nA quantitative approach also promises to help resolve the raven\nparadox. The most popular resolution says that observing a red shirt\ndoes confirm that all ravens are black, just by a very minuscule\namount. The raven paradox is thus an illusion: we mistake a minuscule\namount of confirmation for none at all (Hosiasson-Lindenbaum 1940).\nBut to make this response convincing, we need a proper, quantitative\ntheory of confirmation that explains how a red shirt could be relevant\nto a hypothesis about ravens, but only just slightly relevant.\n1.2 The Probabilistic Approach\n\nLet\u2019s start with the idea that to confirm a hypothesis is to\nmake it more probable. The more a piece of evidence increases the\nprobability of a hypothesis, the more it confirms the hypothesis.\n\nWhat we need then is a theory of probability. The standard theory\nbegins with a function, \\(p\\), which takes in a proposition and\nreturns a number, \\(x\\), the probability of that proposition:\n\\(p(A)=x\\). To qualify as a probability function, \\(p\\) must\nsatisfy three axioms:\n\nFor any proposition \\(A\\), \\(0 \\leq p(A) \\leq\n 1\\).[1]\nFor any tautology \\(A\\), \\(p(A)=1\\).\nFor any logically incompatible propositions \\(A\\) and \\(B\\), \\(p(A\n\\vee B) = p(A) + p(B)\\).\n\n\nThe first axiom sets the scale of probability, from 0 to 1, which we\ncan think of as running from 0% probability to 100%\n probability.[2]\n The second axiom places tautologies at the top of this scale: nothing\nis more probable than a\n tautology.[3]\n And finally, the third axiom tells us how to figure out the\nprobability of a hypothesis by breaking it into parts. For example,\nthe probability that an American country will be the first to develop\na cure for Alzheimer\u2019s can be figured by adding the probability\nthat a North American country will be first to the probability that a\nSouth American country will\n be.[4]\n\nWhat about conditional probabilities, like the probability of\ndoing well in your next philosophy class given that you\u2019ve done\nwell in previous ones? So far we\u2019ve only formalized the notion\nof absolute probability, \\(p(A)=x\\). Let\u2019s introduce conditional\nprobability by definition:\n\nDefinition. The conditional probability of\n\\(B\\) given \\(A\\) is written \\(p(B\\mid A)\\), and is defined:\n\n\\[p(B\\mid A) = \\frac{p(B \\wedge A)}{p(A)}.\\]\n\n \n\nWhy this definition? A helpful heuristic is to think of the\nprobability of \\(B\\) given \\(A\\) as something like the portion of the\n\\(A\\)-possibilities that are also \\(B\\)-possibilities. For example,\nthe probability of rolling a high number (4, 5, or 6) on a six-sided\ndie given that the roll is even is 2/3. Why? There are 3 even\npossibilities (2, 4, 6), so \\(p(A) = 3/6\\). Of those 3 possibilities,\n2 are also high numbers (4, 6), so \\(p(B \\wedge A) = 2/6\\). Thus\n\n\\[p(B\\mid A) = \\frac{p(B \\wedge A)}{p(A)} = \\frac{2/6}{3/6} = 2/3.\\]\n\n Generalizing this idea, we start with the quantity of\n\\(A\\)-possibilities as a sort of baseline by putting \\(p(A)\\) in the\ndenominator. Then we consider how many of those are also\n\\(B\\)-possibilities by putting \\(p(B \\wedge A)\\) in the numerator.\n\nNotice, by the way, that \\(p(B\\mid A)\\) is undefined when \\(p(A) =\n0\\). This might seem fine at first. Why worry about the probability of\n\\(B\\) when \\(A\\) is true if there\u2019s no chance \\(A\\) is true? In\nfact there are deep problems lurking here (H\u00e1jek\nm.s., Other Internet Resources), though we won\u2019t\nstop to explore them.\n\nInstead, let\u2019s take advantage of the groundwork we\u2019ve laid\nto state our formal definition of quantitative confirmation. Our\nguiding idea is that evidence confirms a hypothesis to the extent that\nit increases its probability. So we are comparing \\(p(H\\mid E)\\) to\n\\(p(H)\\) by looking at the difference between them:\n\nDefinition. The degree to which \\(E\\) confirms \\(H\\),\ncalled the degree of confirmation, is written \\(c(H,E)\\) and\nis defined: \n\n\\[c(H,E) = p(H\\mid E) - p(H).\\]\n\n \n\nWhen \\(c(H,E)\\) is negative, \\(E\\) actually decreases the probability\nof \\(H\\), and we say that \\(E\\) disconfirms \\(H\\). When\n\\(c(H,E)\\) is 0, we say that \\(E\\) is neutral with respect to\n\\(H\\).\n\nMinimal as they are, these simple axioms and definitions are enough to\nderive many interesting claims about probability and confirmation. The\nfollowing two subsections introduce some elementary, yet promising\nresults. See the\n technical supplement\n for proofs.\n1.2.1 Basic Building Blocks\n\nLet\u2019s start with some elementary theorems that illustrate how\nprobability interacts with deductive logic:\n\nTheorem (No Chance for Contradictions). When \\(A\\) is\na contradiction, \\(p(A) = 0\\).\n\nTheorem (Complementarity for Contradictories). For\nany \\(A\\), \\(p(A) = 1 - p(\\neg A)\\).\n\nTheorem (Equality for Equivalents). When \\(A\\) and\n\\(B\\) are logically equivalent, \\(p(A) = p(B)\\).\n\nTheorem (Conditional Certainty for Logical\nConsequences) When \\(A\\) logically entails \\(B\\), \\(p(B\\mid\nA)=1\\).\n\nThe next three theorems go a bit deeper, and are useful for building\nup more interesting results:\n\nTheorem (Conjunction Costs Probability). For any\n\\(A\\) and \\(B\\), \\(p(A) > p(A \\wedge B)\\) unless \\(p(A \\wedge \\neg\nB)=0\\), in which case \\(p(A) = p(A \\wedge B)\\).\n\nOne way of thinking about what Conjunction Costs Probability says is\nthat the stronger a statement is, the greater the risk of falsehood.\nIf we strengthen \\(A\\) by adding \\(B\\) to it, the resulting, stronger\nstatement is less probable. Unless, that is, there was no chance of\n\\(A\\) being true without \\(B\\) to begin with. In that case, adding\n\\(B\\) to \\(A\\) doesn\u2019t change the risk of falsehood, because\nthere was no chance of \\(A\\) being true without \\(B\\) anyway.\n\nTheorem (The Conjunction Rule). For any \\(A\\) and\n\\(B\\) such that \\(p(B) \\neq 0\\), \\(p(A \\wedge B) = p(A\\mid\nB)p(B)\\).\n\nThis says we can calculate how likely two statements \\(A\\) and \\(B\\)\nare to be true together by temporarily taking \\(B\\) for granted,\nassessing the probability of \\(A\\) in that light, and then giving the\nresult as much weight as \\(B\\)\u2019s probability on its own\nmerits.\n\nTheorem (The Law of Total Probability). For any\n\\(A\\), and any \\(B\\) whose probability is neither \\(0\\) nor 1:\n\n\\[p(A) = p(A\\mid B)p(B) + p(A\\mid \\neg B)p(\\neg B).\\]\n\n \n\nThe Law of Total Probability basically says that we can calculate the\nprobability of \\(A\\) by breaking it down into two possible cases:\n\\(B\\) and \\(\\neg B\\). We consider how likely \\(A\\) is if \\(B\\) is true\nand how likely it is if \\(B\\) is false. We then give each case\nappropriate \u201cweight\u201d, by multiplying it against the\nprobability that it holds, then adding together the results. For this\nto work, \\(p(A\\mid B)\\) and \\(p(A\\mid \\neg B)\\) have to be\nwell-defined, so \\(p(B)\\) can\u2019t be 0 or 1.\n1.2.2 Bayes\u2019 Theorem\n\nThis classic theorem relates a conditional probability \\(p(H\\mid E)\\)\nto the unconditional probability, \\(p(H)\\): \n\n\\[ p(H\\mid E) = p(H)\\frac{p(E\\mid H)}{p(E)}\\]\n\nThe theorem is philosophically important, as we\u2019ll see in a\nmoment. But it\u2019s also useful as a tool for calculating \\(p(H\\mid\nE)\\), because the three terms on the right hand side can often be\ninferred from available statistics.\n\nConsider, for example, whether a student at University X having\nhigh grades (\\(E\\)) says anything about the likelihood of her taking a\nclass in philosophy (\\(H\\)). The registrar tells us that 35% of\nstudents take a philosophy class at some point, so \\(p(H) = 35/100\\).\nThey also tell us that only 20% of students campus-wide have high\ngrades (defined as a GPA of 3.5 or above), so \\(p(E) = 20/100\\). But\nthey don\u2019t keep track of any more detailed information. Luckily,\nthe philosophy department can tell us that 25% of students who take\ntheir classes have high grades, so \\(p(E\\mid H) = 25/100\\).\nThat\u2019s everything we need to apply Bayes\u2019 theorem:\n\n\\[\\begin{split} p(H\\mid E) &=\np(H)\\frac{p(E\\mid H)}{p(E)}\\\\ &= 35/100 \\times\n\\frac{25/100}{20/100}\\\\ &= 7/16\\end{split}\\]\n\nThat\u2019s higher than \\(p(H) = 20/100\\), so we can also see that a\nstudent\u2019s having high grades confirms the hypothesis that she\nwill take a philosophy class.\n\nWhat\u2019s the philosophical significance of Bayes\u2019 theorem?\nIt unifies a number of influential ideas about confirmation and\nscientific methodology, binding them together in a single, simple\nequation. Let\u2019s see how.\n\n\n\nTheoretical Fit. It\u2019s a truism that the better a theory\nfits the evidence, the more the evidence supports it. But what does it\nmean for a theory to fit the evidence?\n\nWhen \\(H\\) entails \\(E\\), the theory says the evidence must be true,\nso the discovery of the evidence fits the theory perfectly. Our\nformalism vindicates the truism in this special case as follows. When\n\\(H\\) entails \\(E\\), Conditional Certainty for Logical Consequences\ntells us that \\(p(E\\mid H)=1\\), so Bayes\u2019 theorem becomes:\n\n\\[p(H\\mid E) = p(H)\\frac{1}{p(E)}\\]\n\nProvided \\(p(E)\\) is less than 1, this amounts to multiplying \\(p(H)\\)\nby a ratio greater than 1, which means \\(p(H\\mid E)\\) comes out larger\nthan \\(p(H)\\). Moreover, since 1 is the greatest quantity that can\nappear in the numerator, the case where \\(H\\) entails \\(E\\) and thus\n\\(p(E\\mid H)=1\\) gives the greatest possible boost to the probability\nof \\(H\\). In other words, confirmation is greatest when the theory\nfits the evidence as well as possible.\n\n(What if \\(p(E) = 1\\), though? Then \\(H\\) may fit \\(E\\), but so may\n\\(\\neg H\\). If \\(p(E)=1\\), we can prove that \\(p(E\\mid H)=1\\) and\n\\(p(E\\mid \\neg H)=1\\) (hint: combine The Law of Total Probability with\nComplementarity for Contradictories). In other words, \\(E\\) fits both\n\\(H\\) and its negation perfectly. So it shouldn\u2019t be able to\ndiscriminate between these two hypotheses. And, indeed, in this case\n\\(p(H\\mid E)\\) comes out the same as \\(p(H)\\), so \\(c(H,E)=0\\).)\n\nWhat about when the theory fits the evidence less than perfectly? If\nwe think of fit as the certainty with which \\(H\\) predicts \\(E\\),\n\\(p(E\\mid H)\\), then the previous analysis generalizes nicely. Suppose\n\\(H\\) predicts \\(E\\) strongly, but not with absolute certainty:\n\\(p(E\\mid H) = 1 - \\varepsilon\\), for some small number\n\\(\\varepsilon\\). Applying Bayes\u2019 theorem again, we have:\n\n\\[ p(H\\mid E) = p(H)\\frac{1-\\varepsilon}{p(E)}\\]\n\nThis again amounts to multiplying \\(p(H)\\) by a ratio larger than 1,\nprovided \\(p(E)\\) isn\u2019t close to 1. So \\(p(H\\mid E)\\) will come\nout larger than \\(p(H)\\). Of course, the larger \\(\\varepsilon\\) gets,\nthe weaker the confirmation becomes, befitting the weakness with which\n\\(H\\) then predicts \\(E\\). \n\n\nNovel Prediction. Another truism is that novel predictions\ncount more. When a theory predicts something we wouldn\u2019t\notherwise expect, it\u2019s confirmed especially strongly if the\nprediction is borne out. For example, Poisson derided the theory that\nlight is a wave because it predicted a bright spot should appear at\nthe center of certain shadows. No one had previously observed such\nbright spots, making it a novel prediction. When the presence of these\nbright spots was then verified, it was a boon for the wave theory.\n\nOnce again, our formalization vindicates the truism. Suppose as before\nthat \\(H\\) predicts \\(E\\) and thus \\(p(E\\mid H) = 1\\), or nearly so. A\nnovel prediction is one where \\(p(E)\\) is low, or at least not very\nhigh. It\u2019s a prediction one wouldn\u2019t expect. Our previous\nanalysis exposed that, in such circumstances, we multiply \\(p(H)\\) by\na large ratio in Bayes\u2019 theorem. Thus \\(p(H\\mid E)\\) comes out\nsignificantly larger than \\(p(H)\\), making \\(c(H,E)\\) large. So novel\npredictions turn out especially confirmatory. \n\n\nPrior Plausibility. A final truism: new evidence for a theory\nhas to be weighed against the theory\u2019s prior plausibility. Maybe\nthe theory is inherently implausible, being convoluted or\nmetaphysically fraught. Or maybe the theory had become implausible\nbecause it clashed with earlier evidence. Or maybe the theory was\nalready pretty plausible, being elegant and fitting well with previous\nevidence. In any case, the new evidence has to be evaluated in light\nof these prior considerations.\n\nOnce again, Bayes\u2019 theorem vindicates this truism. \\(p(H\\mid\nE)\\) is calculated by multiplying \\(p(H)\\) by the factor \\(p(E\\mid\nH)/p(E)\\). We can think of the factor \\(p(E\\mid H)/p(E)\\) as capturing\nthe extent to which the evidence counts for \\(H\\) (or against it, if\n\\(p(E\\mid H)/p(E)\\) is less than 1), which we then multiply against\nthe previous probability of \\(H\\), \\(p(H)\\), in order to obtain\n\\(H\\)\u2019s new, all-things-considered plausibility. If \\(H\\) was\nalready implausible, \\(p(H)\\) will be low and the result of this\nmultiplication will be smaller than it would be if \\(H\\) had already\nbeen plausible, and \\(p(H)\\) had thus been high. \n\n\nLet\u2019s pause to summarize. Bayes\u2019 theorem isn\u2019t just\na useful calculational tool. It also vindicates three truisms about\nconfirmation, unifying them in a single equation. Each truism\ncorresponds to a term in Bayes\u2019 theorem:\n\n\n\n\\(p(E\\mid H)\\) corresponds to theoretical fit. The better the\nhypothesis fits the evidence, the greater this quantity will be. Since\nthis term appears in the numerator in Bayes\u2019 theorem, better fit\nmeans a larger value for \\(p(H\\mid E)\\).\n\n\n\\(p(E)\\) corresponds to predictive novelty, or rather the\nlack of it. The more novel the prediction is, the less we expect \\(E\\)\nto be true, and thus the smaller \\(p(E)\\) is. Since this term appears\nin the denominator of Bayes\u2019 theorem, more novelty means a\nlarger value for \\(p(H\\mid E)\\).\n\n\n\\(p(H)\\) corresponds to prior plausibility. The more\nplausible \\(H\\) is before the discovery of \\(E\\), the greater this\nquantity will be, and thus the greater \\(p(H\\mid E)\\) will\nbe.\n\n\nBut what about the raven paradox?\n1.3 Quantitative Confirmation & The Raven Paradox\n\nRecall the raven paradox: the hypothesis that all ravens are black is\nlogically equivalent to the hypothesis that all non-black things are\nnon-ravens. Yet the latter would seem to be confirmed with each\ndiscovery of a non-black, non-raven\u2026red shirts, blue\nunderpants, etc. Yet examining the contents of your neighbor\u2019s\nclothesline doesn\u2019t seem a good way to research an\nornithological hypothesis. (Nor does it seem a good way to treat your\nneighbor.)\n\nThe classic, quantitative solution originates with\nHosiasson-Lindenbaum (1940). It holds that the discovery of blue\nunderpants does confirm the hypothesis that all ravens are black, just\nby so little that we overlook it. How could blue underpants be\nrelevant to the hypothesis that all ravens are black? Informally, the\nidea is that an object which turns out to be a blue pair of underpants\ncould instead have turned out to be a white raven. When it turns out\nnot to be such a counterexample, our hypothesis passes a weak sort of\ntest. Does our formal theory of confirmation vindicate this informal\nline of thinking? The answer is, \u201cyes, but\u2026\u201d.\n\nThe \u2018but\u2026\u2019 will prove crucial to the fate of\nNicod\u2019s Criterion (spoiler: outlook not good). But let\u2019s\nstart with the \u2018yes\u2019.\n\nWe vindicate the \u2018yes\u2019 with a theorem: discovering an\nobject to be a non-raven that isn\u2019t black, \\(\\neg R \\wedge \\neg\nB\\), just slightly boosts the probability of the hypothesis that all\nravens are black, \\(H\\), if we make certain assumptions. Here\nis the theorem (see the\n technical supplement\n for a proof):\n\nTheorem (Raven Theorem). If (i) \\(p(\\neg R \\mid \\neg\nB)\\) is very high and (ii) \\(p(\\neg B\\mid H)=p(\\neg B)\\), then\n\\(p(H\\mid \\neg R \\wedge \\neg B)\\) is just slightly larger than\n\\(p(H)\\).\n\nThe first assumption, that \\(p(\\neg R \\mid \\neg B)\\) is very high,\nseems pretty sensible. With all the non-ravens in the world, the\nprobability that a given object will be a non-raven is quite high,\nespecially if it\u2019s not black. The second assumption is that\n\\(p(\\neg B\\mid H)=p(\\neg B)\\). In other words, assuming that all\nravens are black doesn\u2019t change the probability that a given\nobject will not be black. This assumption is more controversial\n(Vranas 2004). If all the ravens are black, then some of the things\nthat might have been black aren\u2019t, namely the ravens. In that\ncase shouldn\u2019t \\(p(\\neg B\\mid H) < p(\\neg B)\\) instead? On\nthe other hand, maybe all the ravens being black doesn\u2019t reduce\nthe number of black things in the universe. Maybe it just means that\nother kinds of things are black slightly more often. Luckily, it turns\nout we can replace (ii) with less dubious assumptions (Fitelson 2006;\nFitelson and Hawthorne 2010; Rinard 2014). But we can\u2019t do with\nno assumptions at all, which brings us to two crucial points about\nconfirmation and probability.\n\nThe first point is that Nicod\u2019s Criterion fails. Assumptions\nlike (i) and (ii) of the Raven Theorem don\u2019t always hold. In\nfact, in some situations, discovering a black raven would actually\nlower the probability that all ravens are black. How could\nthis be? The trick is to imagine a situation where the very discovery\nof a raven is bad news for the hypothesis that all ravens are black.\nThis would happen if the only way for all the ravens to be black is\nfor there to be very few of them. Then stumbling across a raven would\nsuggest that ravens are actually plentiful, in which case they\naren\u2019t all black. Good (1967) offers the following, concrete\nillustration. Suppose there are only two possibilities:\n\n\n\nAll ravens are black, though there are only \\(100\\) ravens and a\nmillion other things.\n\n\nThere is one non-black raven out of \\(1,000\\) ravens, and there are a\nmillion other things.\n\n\nIn this case, happening upon a raven favors \\(\\neg H\\) because \\(\\neg\nH\\) makes ravens ten times less exotic. That the raven is black fits\nslightly better with \\(H\\), but not enough to outweigh the first\neffect: black ravens are hardly a rarity on \\(\\neg H\\). This is the\n\u2018but\u2026\u2019 to go with our earlier\n\u2018yes\u2019.\n\nThe second point is a far-reaching moral: that the fates of claims\nabout confirmation often turn crucially on what assumptions we make\nabout the values of \\(p\\). Nicod\u2019s criterion fails in situations\nlike Good\u2019s, where \\(p\\) assigns a lower value to \\(p(R \\wedge\nB\\mid H)\\) than to \\(p(R \\wedge B\\mid \\neg H)\\). But in another\nsituation, where things are reversed, Nicod\u2019s Criterion does\napply. Likewise, a diagnosis of the raven paradox like the standard\none only applies given certain assumptions about \\(p\\), like\nassumptions (i) and (ii) of the Raven Theorem. The probability axioms\nalone generally aren\u2019t enough to tell us when Nicod\u2019s\nCriterion applies, or when confirmation is small or large, positive or\nnegative.\n1.4 The Problem of the Priors\n\nThis last point is a very general, very important phenomenon. Like the\naxioms of first-order logic, the axioms of probability are quite weak\n(Howson and Urbach 1993; Christensen 2004). Unless \\(H\\) is a\ntautology or contradiction, the axioms only tell us that its\nprobability is somewhere between \\(0\\) and 1. If we can express \\(H\\)\nas a disjunction of two logically incompatible sub-hypotheses, \\(H_1\\)\nand \\(H_2\\), and we know the probabilities of these sub-hypotheses,\nthen the third axiom lets us compute \\(p(H) = p(H_1)+p(H_2)\\). But\nthis just pushes things back a step, since the axioms by themselves\nonly tell us that \\(p(H_1)\\) and \\(p(H_2)\\) must themselves lie\nbetween \\(0\\) and 1.\n\nThis weakness of the probability axioms generates the famous\nproblem of the priors, the problem of saying where initial\nprobabilities come from. Are they always based on evidence previously\ncollected? If so, how does scientific inquiry get started? If instead\nthey\u2019re not based on previous evidence but are a\npriori, what principles govern this a priori reasoning?\nFormal epistemologists are split on this question. The so-called\nobjectivists see the probability axioms as incomplete,\nwaiting to be supplemented by additional postulates that determine the\nprobabilities with which inquiry should begin. (The Principle of\nIndifference (PoI) is the leading candidate here. See the entry on the\n interpretation of probability.)\n The so-called subjectivists think instead that there is no\nsingle, correct probability function \\(p\\) with which inquiry should\nbegin. Different inquirers may begin with different values for \\(p\\),\nand none of them is thereby more or less scientific or rational than\nthe others.\n\nIn later sections the problem of the priors will return several times,\nillustrating its importance and ubiquity.\n1.5 Summary\n\nWe\u2019ve seen that formalizing confirmation using probability\ntheory yields an account that succeeds in several significant ways: it\nvindicates several truisms about confirmation, it unifies those\ntruisms in a single equation, and it resolves a classic paradox (not\nto mention others we didn\u2019t discuss (Crupi and Tentori\n2010)).\n\nWe also saw that it raises a problem though, the problem of priors,\nwhich formal epistemologists are divided on how to resolve. And there\nare other problems we didn\u2019t explore, most notably the problems\nof\n logical omniscience\n and\n old evidence\n (see subsections of entry on\n Bayesian epistemology).\n\nThese and other problems have led to the exploration and development\nof other approaches to scientific reasoning, and reasoning in general.\nSome stick to the probabilistic framework but develop different\nmethodologies within it (Fisher 1925; Neyman and Pearson 1928a,b;\nRoyall 1997; Mayo 1996; Mayo and Spanos 2011; see entry on the\n philosophy of statistics).\n Others depart from standard probability theory, like\n Dempster-Shafer theory\n (Shafer 1976; see entry on\n formal representations of belief),\n a variant of probability theory meant to solve the problem of the\npriors and make other improvements.\n Ranking theory\n (Spohn 1988, 2012; again see entry on\n formal representations of belief)\n also bears some resemblance to probability theory but draws much\ninspiration from\n possible-world semantics for conditionals\n (see entry on\n indicative conditionals).\n Bootstrapping theory (Glymour 1980; Douven and Meijs 2006) leaves the\nprobabilistic framework behind entirely, drawing inspiration instead\nfrom the deduction-based approach we began with. Still other\napproaches develop\n non-monotonic logics (see entry),\n logics for making not only deductive inferences, but also defeasible,\ninductive inferences (Pollock 1995, 2008; Horty 2012).\n Formal learning theory\n provides a framework for studying the long-run consequences of a wide\nrange of methodologies.\n\nFor the next two sections we\u2019ll build on the probabilistic\napproach introduced here, since it\u2019s currently the most popular\nand influential approach to formal epistemology. But it\u2019s\nimportant to remember that there is a rich and variegated range of\nalternative approaches, and that this one has its problems, some\nconsequences of which we\u2019ll soon encounter.\n2. Second Case Study: The Problem of Induction\n\nA lot of our reasoning seems to involve projecting observed patterns\nonto unobserved instances. For example, suppose I don\u2019t know\nwhether the coin I\u2019m holding is biased or fair. If I flip it 9\ntimes and it lands tails every time, I\u2019ll expect the\n10th toss to come up tails too. What justifies this kind of\nreasoning? Hume famously argued that nothing can justify it. In modern\nform, Hume\u2019s challenge is essentially this: a justification for\nsuch reasoning must appeal to either an inductive argument or a\ndeductive one. Appealing to an inductive argument would be\nunacceptably circular. While a deductive argument would have to show\nthat unobserved instances will resemble observed ones, which is not a\nnecessary truth, and hence not demonstrable by any valid argument. So\nno argument can justify projecting observed patterns onto unobserved\ncases. (Russell and Restall (2010) offer a formal development. Haack\n(1976) discusses the supposed asymmetry between induction and\ndeduction here.)\n\nCan probability come to the rescue here? What if instead of deducing\nthat unobserved instances will resemble observed ones we just deduce\nthat they\u2019ll probably resemble the observed ones? If we\ncan deduce from the probability axioms that the next toss is likely to\ncome up tails given that it landed tails 9 out of 9 times so far, that\nwould seem to solve Hume\u2019s problem.\n\nUnfortunately, no such deduction is possible: the probability axioms\nsimply don\u2019t entail the conclusion we want. How can that be?\nConsider all the different sequences of heads (\\(\\mathsf{H}\\)) and\ntails (\\(\\mathsf{T}\\)) we might get in the course of 10 tosses:\n\n\\[\\begin{array}{c}\n\\mathsf{HHHHHHHHHH}\\\\\n\\mathsf{HHHHHHHHHT}\\\\\n\\mathsf{HHHHHHHHTH}\\\\\n\\vdots\\\\\n\\mathsf{HHHHHHHHTT}\\\\\n\\mathsf{HHHHHHHTHT}\\\\\n\\vdots\\\\\n\\mathsf{TTTTTTTTTH}\\\\\n\\mathsf{TTTTTTTTTT}\\\\\n\\end{array}\\]\n\n\nThere are 1024 possible sequences, so the probability of each possible\nsequence would seem to be \\(1/1024\\). Of course, only two of them\nbegin with 9 tails in a row, namely the last two. So, once we\u2019ve\nnarrowed things down to a sequence that begins with 9 out of 9 tails,\nthe probability of tails on the 10th toss is \\(1/2\\), same\nas heads. More formally, applying the definition conditional\nprobability gives us:\n\\[\\begin{align} p(T_{10} \\mid T_{1\\ldots9})\n&= \\frac{p(T_{10} \\wedge T_{1\\ldots9})}{p(T_{1\\ldots9})}\\\\ &=\n\\frac{1/1024}{2/1024}\\\\ &= \\frac{1}{2}\\end{align}\\]\n\nSo it looks like the axioms of probability entail that the\nfirst 9 tosses tell us nothing about the 10th toss.\n\nIn fact, though, the axioms of probability don\u2019t even entail\nthat\u2014they don\u2019t actually say anything about\n\\(p(T_{10} \\mid T_{1\\ldots9})\\). In the previous paragraph, we assumed\nthat each possible sequence of tosses was equally probable, with\n\\(p(\\ldots)=1/1024\\) the same for each sequence. But the probability\naxioms don\u2019t require this \u201cuniform\u201d assignment. As\nwe saw earlier when we encountered the problem of the priors\n (1.4),\n the probability axioms only tell us that tautologies have probability\n1 (and contradictions probability \\(0\\)). Contingent propositions can\nhave any probability from \\(0\\) to 1, and this includes the\nproposition that the sequence of tosses will be\n\\(\\mathsf{HHHHHHHTHT}\\), or any other sequence of \\(\\mathsf{H}\\)s and\n\\(\\mathsf{T}\\)s.\n\nWe can exploit this freedom and get more sensible, induction-friendly\nresults if we assign prior probabilities using a different scheme\nadvocated by Carnap (1950). Suppose instead of assigning each possible\nsequence the same probability, we assign each possible number of\n\\(\\mathsf{T}\\)s the same probability. We could get anywhere from 0 to\n10 \\(\\mathsf{T}\\)s, so each possible number of \\(\\mathsf{T}\\)s has\nprobability 1/11. Now, there\u2019s just one way of getting 0\n\\(\\mathsf{T}\\)s: \n\n\\[\\mathsf{HHHHHHHHHH}\\]\n\n\nSo \\(p(H_{1\\ldots10})=1/11\\). But there are 10 ways of getting 1\n\\(\\mathsf{T}\\):\n\\[\\begin{array}{c} \\mathsf{HHHHHHHHHT}\\\\\n\\mathsf{HHHHHHHHTH}\\\\ \\mathsf{HHHHHHHTHH}\\\\ \\vdots\\\\\n\\mathsf{THHHHHHHHH}\\end{array}\\]\n\nSo this possibility\u2019s probability of \\(1/11\\) is divided 10\nways, yielding probability \\(1/110\\) for each subpossibility, e.g.,\n\\(p(\\mathsf{HHHHHHHTHH})=1/110\\). And then there are 45 ways of\ngetting 2 \\(\\mathsf{T}\\)s:\n\\[\\begin{array}{c} \\mathsf{HHHHHHHHTT}\\\\\n\\mathsf{HHHHHHHTHT}\\\\ \\mathsf{HHHHHHTHHT}\\\\ \\vdots\\\\\n\\mathsf{TTHHHHHHHH}\\end{array}\\]\n\nSo here the probability of \\(1/11\\) is divided \\(45\\) ways, yielding a\nprobability of \\(1/495\\) for each subpossibility, e.g.,\n\\(p(\\mathsf{HTHHHHHTHH})=1/495\\). And so on.\n\nWhat then becomes of \\(p(T_{10} \\mid T_{1\\ldots9})\\)?\n\\[\\begin{align} p(T_{10} \\mid T_{1\\ldots9})\n&= \\frac{p(T_{10} \\wedge T_{1\\ldots9})}{p(T_{1\\ldots9})}\\\\ &=\n\\frac{p(T_{1\\ldots10})}{p(T_{1\\ldots10} \\vee [T_{1\\ldots9} \\wedge\nH_{10}])}\\\\ &= \\frac{p(T_{1\\ldots10})}{p(T_{1\\ldots10}) +\np(T_{1\\ldots9} \\wedge H_{10})}\\\\ &= \\frac{1/11}{1/11 + 1/110}\\\\\n&= \\frac{10}{11}\\end{align}\\]\n\nSo we get a much more reasonable result when we assign prior\nprobabilities according to Carnap\u2019s two-stage scheme. However,\nthis scheme is not mandated by the axioms of probability.\n\nOne thing this teaches us is that the probability axioms are silent on\nHume\u2019s problem. Inductive reasoning is compatible with the\naxioms, since Carnap\u2019s way of constructing the prior\nprobabilities makes a 10th \\(\\mathsf{T}\\) quite likely\ngiven an initial string of \\(9\\) \\(\\mathsf{T}\\)s. But the axioms are\nalso compatible with skepticism about induction. On the first way of\nconstructing the prior probabilities, a string of \\(\\mathsf{T}\\)s\nnever makes the next toss any more likely to be a \\(\\mathsf{T}\\), no\nmatter how long the string gets! In fact, there are further ways of\nconstructing the prior probabilities that yield\n\u201canti-induction\u201d, where the more \\(\\mathsf{T}\\)s we\nobserve, the less likely the next toss is to be a\n\\(\\mathsf{T}\\).\n\nWe also learn something else though, something more constructive: that\nHume\u2019s problem is a close cousin of the problem of the priors.\nIf we could justify Carnap\u2019s way of assigning prior\nprobabilities, we would be well on our way to solving Hume\u2019s\nproblem. (Why only on our way? More on that in a moment, but very\nbriefly: because we\u2019d still have to justify using conditional\nprobabilities as our guide to the new, unconditional probabilities.)\nCan we justify Carnap\u2019s two-stage scheme? This brings us to a\nclassic debate in formal epistemology.\n2.1 The Principle of Indifference\n\nIf you had to bet on a horserace without knowing anything about any of\nthe horses, which one would you bet on? It probably wouldn\u2019t\nmatter to you: each horse is as likely to win as the others, so\nyou\u2019d be indifferent between the available wagers. If there are\n3 horses in the race, each has a 1/3 chance of winning; if there are\n5, each has a 1/5 chance; etc. This kind of reasoning is common and is\noften attributed to the Principle of\n Indifference:[5]\n\nThe Principle of Indifference (PoI)\n\nGiven \\(n\\) mutually exclusive and jointly exhaustive possibilities,\nnone of which is favored over the others by the available evidence,\nthe probability of each is \\(1/n\\).\n\nPoI looks quite plausible at first, and may even have the flavor of a\nconceptual truth. How could one possibility be more probable than\nanother if the evidence doesn\u2019t favor it? And yet, the PoI faces\na classic and recalcitrant challenge.\n\nConsider the first horse listed in the race, Athena. There are two\npossibilities, that she will win and that she will lose. Our evidence\n(or lack thereof) favors neither possibility, so the PoI says the\nprobability that she\u2019ll win is \\(1/2\\). But suppose there are\nthree horses in the race: Athena, Beatrice, and Cecil. Since our\nevidence favors none of them over any other, the PoI requires that we\nassign probability \\(1/3\\) to each, which contradicts our earlier\nconclusion that Athena\u2019s probability of winning is \\(1/2\\).\n\nThe source of the trouble is that possibilities can be subdivided into\nfurther subpossibilities. The possibility of Athena losing can be\nsubdivided into two subpossibilities, one where Beatrice wins and\nanother where Cecil wins. Because we lack any relevant evidence, the\navailable evidence doesn\u2019t seem to favor the coarser\npossibilities over the finer subpossibilities, leading to\ncontradictory probability assignments. What we need, it seems, is some\nway of choosing a single, privileged way of dividing up the space of\npossibilities so that we can apply the PoI consistently.\n\nIt\u2019s natural to think we should use the more fine-grained\ndivision of possibilities, the three-way division in the case of\nAthena, Beatrice, and Cecil. But we can actually divide things\nfurther\u2014infinitely further in fact. For example, Athena might\nwin by a full length, by half a length, by a quarter of a length, etc.\nSo the possibility that she wins is actually infinitely divisible. We\ncan extend the PoI to handle such infinite divisions of possibilities\nin a natural way by saying that, if Athena wins, the probability that\nshe\u2019ll win by between 1 and 2 lengths is twice the probability\nthat she\u2019ll win by between \\(1/2\\) and 1 length. But the same\nproblem we were trying to solve still persists, in the form of the\nnotorious Bertrand paradox (Bertrand 2007 [1888]).\n\nThe paradox is nicely illustrated by the following example from van\nFraassen (1989). Suppose a factory cuts iron cubes with edge-lengths\nranging from \\(0\\) cm to 2 cm. What is the probability that the next\ncube to come off the line will have edges between \\(0\\) cm and 1 cm in\nlength? Without further information about how the factory goes about\nproducing cubes, the PoI would seem to say the probability is \\(1/2\\).\nThe range from \\(0\\) to 1 covers \\(1/2\\) the full range of\npossibilities from \\(0\\) to 2. But now consider this question: what is\nthe probability that the next cube to come off the line will have\nvolume between \\(0\\) cubic cm and 1 cubic cm? Here the PoI seems to\nsay the probability is \\(1/8\\). For the range from \\(0\\) to 1 covers\nonly \\(1/8\\) the full range of possible volumes from \\(0\\) to \\(8\\)\ncubic cm. So we have two different probabilities for equivalent\npropositions: a cube has edge-length between \\(0\\) and 1 cm if and\nonly if it has a volume between \\(0\\) cubic cm and 1 cubic cm. Once\nagain, the probabilities given by the PoI seem to depend on how we\ndescribe the range of possible outcomes. Described in terms of length,\nwe get one answer; described in terms of volume, we get another.\n\nImportantly, Bertrand\u2019s paradox applies quite generally. Whether\nwe\u2019re interested in the size of a cube, the distance by which a\nhorse will win, or any other parameter measured in real numbers, we\ncan always redescribe the space of possible outcomes so that the\nprobabilities assigned by the PoI come out differently. Even an\ninfinitely fine division of the space of possibilities doesn\u2019t\nfix the problem: the probabilities assigned by the PoI still depend on\nhow we describe the space of possibilities.\n\nWe face essentially this problem when we frame the problem of\ninduction in probabilistic terms. Earlier we saw two competing ways of\nassigning prior probabilities to sequences of coin tosses. One way\ndivides the possible outcomes according to the exact sequence in which\n\\(\\mathsf{H}\\) and \\(\\mathsf{T}\\) occur. The PoI assigns each possible\nsequence a probability of \\(1/1024\\), with the result that the first 9\ntosses tell us nothing about the 10th toss. The second,\nCarnapian way instead divides the possible outcomes according to the\nnumber of \\(\\mathsf{T}\\)s, regardless of where they occur in the\nsequence. The PoI then assigns each possible number of \\(\\mathsf{T}\\)s\nthe same probability, \\(1/11\\). The result then is that the first 9\ntosses tell us a lot about the 10th toss: if the first 9\ntosses are tails, the 10th toss has a \\(10/11\\) chance of\ncoming up tails too.\n\nSo one way of applying the PoI leads to inductive skepticism, the\nother yields the inductive optimism that seems so indispensable to\nscience and daily life. If we could clarify how the PoI should be\napplied, and justify its use, we would have our answer to Hume\u2019s\nproblem (or at least the first half\u2014we still have to address the\nissue of using conditional probabilities as a guide to new,\nunconditional probabilities). Can it be clarified and justified?\n\nHere again we run up against one of the deepest and oldest divides in\nformal epistemology, that between subjectivists and objectivists. The\nsubjectivists hold that any assignment of probabilities is a\nlegitimate, reasonable way to start one\u2019s inquiry. One need only\nconform to the three probability axioms to be reasonable. They take\nthis view largely because they despair of clarifying the PoI. They see\nno reason, for example, that we should follow Carnap in first dividing\naccording to the number of \\(\\mathsf{T}\\)s, and only then subdividing\naccording to where in sequence those \\(\\mathsf{T}\\)s appear. Closely\nrelated to this skepticism is a skepticism about the prospects for\njustifying the PoI, even once clarified, in a way that would put it on\na par with the three axioms of probability. We haven\u2019t yet\ntouched on how the three axioms are supposed to be justified. But the\nclassic story is this: a family of\n theorems\u2014Dutch book theorems (see entry)\n and\n representation theorems (see entry)\u2014are\n taken to show that any deviation from the three axioms of probability\nleads to irrational decision-making. For example, if you deviate from\nthe axioms, you will accept a set of bets that is bound to lose money,\neven though you can see that losing money is inevitable a\npriori. These theorems don\u2019t extend to violations of the\nPoI though, however it\u2019s clarified. So subjectivists conclude\nthat violating the PoI is not irrational.\n\nSubjectivists aren\u2019t thereby entirely helpless in the face of\nthe problem of induction, though. According to them, any initial\nassignment of probabilities is reasonable, including Carnap\u2019s.\nSo if you do happen to start out with a Carnap-esque assignment, you\nwill be an inductive optimist, and reasonably so. It\u2019s just that\nyou don\u2019t have to start out that way. You could instead start\nout treating each possible sequence of \\(\\mathsf{H}\\)s and\n\\(\\mathsf{T}\\)s as equally probable, in which case you\u2019ll end up\nan inductive skeptic. That\u2019s reasonable too. According to\nsubjectivism, induction is perfectly rational, it just isn\u2019t the\nonly rational way to reason.\n\nObjectivists hold instead that there\u2019s just one way to assign\ninitial probabilities (though some allow a bit of flexibility (Maher\n1996)). These initial probabilities are given by the PoI, according to\northodox objectivism. As for the PoI\u2019s conflicting probability\nassignments depending on how possibilities are divided up, some\nobjectivists propose restricting it to avoid these inconsistencies\n(Castell 1998). Others argue that it\u2019s actually appropriate for\nprobability assignments to depend on the way possibilities are divvied\nup, since this reflects the language in which we conceive the\nsituation, and our language reflects knowledge we bring to the matter\n(Williamson 2007). Still others argue that the PoI\u2019s assignments\ndon\u2019t actually depend on the way possibilities are divided\nup\u2014it\u2019s just hard to tell sometimes when the evidence\nfavors one possibility over another (White 2009).\n\nWhat about justifying the PoI though? Subjectivists have traditionally\njustified the three axioms of probability by appeal to one of the\naforementioned theorems: the Dutch book theorem or some form of\nrepresentation theorem. But as we noted earlier, these theorems\ndon\u2019t extend to the PoI.\n\nRecently, a different sort of justification has been gaining favor,\none that may extend to the PoI. Arguments that rely on Dutch book or\nrepresentation theorems have long been suspect because of their\npragmatic character. They aim to show that deviating from the\nprobability axioms leads to irrational choices, which seems to show at\nbest that obeying the probability axioms is part of pragmatic\nrationality, as opposed to epistemic irrationality. (But see\nChristensen (1996, 2001) and Vineberg (1997, 2001) for replies.)\nPreferring a more properly epistemic approach, Joyce (1998, 2009)\nargues that deviating from the probability axioms takes one\nunnecessarily far from the truth, no matter what the truth turns out\nto be. Pettigrew (2016) adapts this approach to the PoI, showing that\nviolations of the PoI increase one\u2019s risk of being further from\nthe truth. (But see Carr (2017) for a critical perspective on this\ngeneral approach.)\n2.2 Updating & Inference\n\nWhether we prefer the subjectivist\u2019s response to Hume\u2019s\nproblem or the objectivist\u2019s, a crucial element is still\nmissing. Earlier we noted that justifying a Carnapian assignment of\nprior probabilities only gets us half way to a solution. We still have\nto turn these prior probabilities into posterior\nprobabilities: initially, the probability of tails on the tenth toss\nwas \\(1/2\\), but after observing the first 9 tosses come out tails,\nit\u2019s supposed to be \\(10/11\\). Having justified our initial\nassignment of probabilities\u2014whether the subjectivist way or the\nobjectivist way\u2014we can prove that \\(p(T_{10}\\mid\nT_{1\\ldots9})=10/11\\) compared to \\(p(T_{10})=1/2\\). But that\ndoesn\u2019t mean the new probability of \\(T_{10}\\) is\n\\(10/11\\). Remember, the symbolism \\(p(T_{10}\\mid T_{1\\ldots9})\\)\nis just shorthand for the fraction \\(p(T_{10} \\wedge\nT_{1\\ldots9})/p(T_{1\\ldots9})\\). So the fact that \\(p(T_{10}\\mid\nT_{1\\ldots9})=10/11\\) just means that this ratio is \\(10/11\\), which\nis still just a fact about the initial, prior\nprobabilities.\n\nTo appreciate the problem, it helps to forget probabilities for a\nmoment and think in simple, folksy terms. Suppose you aren\u2019t\nsure whether \\(A\\) is true, but you believe that if it is true, then\nso is \\(B\\). If you then learn that \\(A\\) is in fact true, you then\nhave two options. You might conclude that \\(B\\) is true, but you might\ninstead decide that you were wrong at the outset to think \\(B\\) is\ntrue if \\(A\\) is. Faced with the prospect of accepting \\(B\\), you\nmight find it too implausible to accept, and thus abandon your\ninitial, conditional belief that \\(B\\) is true if \\(A\\) is (Harman\n1986).\n\nLikewise, we might start out unsure whether the first \\(9\\) tosses\nwill come up tails, but believe that if they do, then the probability\nof the \\(10\\)th toss coming up tails is \\(10/11\\). Then, when we see\nthe first \\(9\\) tosses come up tails, we might conclude that the\n\\(10\\)th toss has a \\(10/11\\) chance of coming up tails, or,\nwe might instead decide we were wrong at the outset to think it had a\n\\(10/11\\) chance of coming up tails on the \\(10\\)th toss if it came up\ntails on the first \\(9\\) tosses.\n\nThe task is to justify taking the first route rather than the second:\nsticking to our conditional belief that, if \\(T_{1\\ldots9}\\), then\n\\(T_{10}\\) has probability \\(10/11\\), even once we\u2019ve learned\nthat indeed \\(T_{1\\ldots9}\\). Standing by one\u2019s conditional\nprobabilities in this way is known as \u201cconditionalizing\u201d,\nbecause one thereby turns the old conditional probabilities into new,\nunconditional probabilities. To see why sticking by your old\nconditional probabilities amounts to turning them into unconditional\nprobabilities, let\u2019s keep using \\(p\\) to represent the prior\nprobabilities, and let\u2019s introduce \\(p'\\) to stand for the new,\nposterior probabilities after we learn that \\(T_{1\\ldots9}\\). If we\nstand by our prior conditional probabilities, then \n\n\\[p'(T_{10}\\mid T_{1\\ldots9}) = p(T_{10}\\mid T_{1\\ldots9})=10/11.\\]\n\n And\nsince we now know that \\(T_{1\\ldots9}\\), \\(p'(T_{1\\ldots9})=1\\). It\nthen follows that \\(p'(T_{10})=10/11\\):\n\\[\\begin{align} p'(T_{10}\\mid T_{1\\ldots9})\n&= \\frac{p'(T_{10} \\wedge T_{1\\ldots9})}{p'(T_{1\\ldots9})}\\\\\n&= p'(T_{10} \\wedge T_{1\\ldots9})\\\\ &= p'(T_{10})\\\\ &=\n10/11\\end{align}\\]\n\nThe first line follows from the definition of conditional probability.\nThe second follows from the fact that \\(p'(T_{1\\ldots9})=1\\), since\nwe\u2019ve seen how the first \\(9\\) tosses go. The third line follows\nfrom an elementary theorem of the probability axioms: conjoining \\(A\\)\nwith another proposition \\(B\\) that has probability 1 results in the\nsame probability, i.e., \\(p(A \\wedge B)=p(A)\\) when \\(p(B)=1\\).\n(Deriving this theorem is left as an exercise for the reader.)\nFinally, the last line just follows from our assumption that\n\n\\[p'(T_{10}\\mid T_{1\\ldots9}) = p(T_{10}\\mid T_{1\\ldots9})=10/11.\\]\n\n The thesis that we should generally update probabilities\nin this fashion is known as conditionalization. \n\nConditionalization\n\nGiven the prior probability assignment \\(p(H\\mid E)\\), the new,\nunconditional probability assignment to \\(H\\) upon learning \\(E\\)\nshould be \\(p'(H)=p(H\\mid E)\\).\n\nA number of arguments have been given for this principle, many of them\nparallel to the previously mentioned arguments for the axioms of\nprobability. Some appeal to Dutch books (Teller 1973; Lewis 1999),\nothers to the pursuit of cognitive values (Greaves and Wallace 2006),\nespecially closeness to the truth (Leitgeb and Pettigrew 2010a,b), and\nstill others to the idea that one should generally revise one\u2019s\nbeliefs as little as possible when accommodating new information\n(Williams 1980).\n\nThe details of these arguments can get very technical, so we\nwon\u2019t examine them here. The important thing for the moment is\nto appreciate that (i) inductive inference is a dynamic process, since\nit involves changing our beliefs over time, but (ii) the general\nprobability axioms, and particular assignments of prior probabilities\nlike Carnap\u2019s, are static, concerning only the initial\nprobabilities. Thus (iii) a full theory of inference that answers\nHume\u2019s challenge must appeal to additional, dynamic principles\nlike Conditionalization. So (iv) we need to justify these additional,\ndynamic principles in order to justify a proper theory of inference\nand answer Hume\u2019s challenge.\n\nImportantly, the morals summarized in (i)\u2013(iv) are extremely\ngeneral. They don\u2019t just apply to formal epistemologies based in\nprobability theory. They also apply to a wide range of theories based\nin other formalisms, like\n Dempster-Shafer theory,\n ranking theory,\n belief-revision theory,\n and\n non-monotonic logics.\n One way of viewing the takeaway here, then, is as follows.\n\nFormal epistemology gives us precise ways of stating how induction\nworks. But these precise formulations do not themselves solve a\nproblem like Hume\u2019s, for they rely on assumptions like the\nprobability axioms, Carnap\u2019s assignment of prior probabilities,\nand Conditionalization. Still, they do help us isolate and clarify\nthese assumptions, and then formulate various arguments in their\ndefense. Whether formal epistemology thereby aids in the solution of\nHume\u2019s problem depends on whether these formulations and\njustifications are plausible, which is controversial.\n3. Third Case Study: The Regress Problem\n\nThe problem of induction challenges our inferences from the observed\nto the unobserved. The regress problem challenges our knowledge at an\neven more fundamental level, questioning our ability to know anything\nby observation in the first place (see Weintraub 1995 for a critical\nanalysis of this distinction).\n\nTo know something, it seems you must have some justification for\nbelieving it. For example, your knowledge that Socrates taught Plato\nis based on testimony and textual sources handed down through the\nyears. But how do you know these testimonies and texts are reliable\nsources? Presumably this knowledge is itself based on some further\njustification\u2014various experiences with these sources, their\nagreement with each other, with other things you\u2019ve observed\nindependently, and so on. But the basis of this knowledge too can be\nchallenged. How do you know that these sources even say what you think\nthey say, or that they even exist\u2014maybe every experience\nyou\u2019ve had reading The Apology has been a mirage or a\ndelusion.\n\nThe famous Agrippan trilemma identifies three possible ways this\nregress of justification might ultimately unfold. First, it could go\non forever, with \\(A\\) justified by \\(B\\) justified by \\(C\\) justified\nby \u2026, ad infinitum. Second, it it could cycle back on\nitself at some point, with \\(A\\) justified by \\(B\\) justified by \\(C\\)\njustified by\u2026justified by \\(B\\), for example. Third and\nfinally, the regress might stop at some point, with \\(A\\) justified by\n\\(B\\) justified by \\(C\\) justified by\u2026justified by \\(N\\), which\nis not justified by any further belief.\n\nThese three possibilities correspond to three classic responses to\nthis regress of justification. Infinitists hold that the regress goes\non forever, coherentists that it cycles back on itself, and\nfoundationalists that it ultimately terminates. The proponents of each\nview reject the alternatives as unacceptable. Infinitism looks\npsychologically unrealistic, requiring an infinite tree of beliefs\nthat finite minds like ours could not accommodate. Coherentism seems\nto make justification unacceptably circular, and thus too easy to\nachieve. And foundationalism seems to make justification arbitrary,\nsince the beliefs at the end of the regress apparently have no\njustification.\n\nThe proponents of each view have long striven to answer the concerns\nabout their own view, and to show that the concerns about the\nalternatives cannot be adequately answered. Recently, methods from\nformal epistemology have begun to be recruited to examine the adequacy\nof these answers. We\u2019ll look at some work that\u2019s been done\non coherentism and foundationalism, since these have been the focus of\nboth informal and formal work. (For work on infinitism, see Turri and\nKlein 2014. See Haack (1993) for a hybrid option,\n\u201cfoundherentism\u201d.)\n3.1 Coherentism\n\nThe immediate concern about coherentism is that it makes justification\ncircular. How can a belief be justified by other beliefs which are,\nultimately, justified by the first belief in question? If cycles of\njustification are allowed, what\u2019s to stop one from believing\nanything one likes, and appealing to it as a justification for\nitself?\n\nCoherentists usually respond that justification doesn\u2019t actually\ngo in cycles. In fact, it isn\u2019t even really a relationship\nbetween individual beliefs. Rather, a belief is justified by being\npart of a larger body of beliefs that fit together well, that\ncohere. Justification is thus global, or\nholistic. It is a feature of an entire body of beliefs first,\nand only of individual beliefs second, in virtue of their being part\nof the coherent whole. When we trace the justification for a belief\nback and back and back until we come full circle, we aren\u2019t\nexposing the path by which it\u2019s justified. Rather, we are\nexposing the various interconnections that make the whole web\njustified as a unit. That these connections can be traced in a circle\nmerely exposes how interconnected the web is, being connected in both\ndirections, from \\(A\\) to \\(B\\) to \u2026to \\(N\\), and then from\n\\(N\\) all the way back to \\(A\\) again.\n\nStill, arbitrariness remains a worry: you can still believe just about\nanything, provided you also believe many other things that fit well\nwith it. If I want to believe in ghosts, can I just adopt a larger\nworld view on which supernatural and paranormal phenomena are rife?\nThis worry leads to a further one, a worry about truth: given that\nalmost any belief can be embedded in a larger, just-so story that\nmakes sense of it, why expect a coherent body of beliefs to be true?\nThere are many coherent stories one can tell, the vast majority of\nwhich will be massively false. If coherence is no indication of truth,\nhow can it provide justification?\n\nThis is where formal methods come in: what does probability theory\ntell us about the connection between coherence and truth? Are more\ncoherent bodies of belief more likely to be true? Less likely?\n\nKlein and Warfield (1994) argue that coherence often\ndecreases probability. Why? Increases in coherence often come\nfrom new beliefs that make sense of our existing beliefs. A detective\ninvestigating a crime may be puzzled by conflicting testimony until\nshe learns that the suspect has an identical twin, which explains why\nsome witnesses report seeing the suspect in another city the day of\nthe crime. And yet, adding the fact about the identical twin to her\nbody of beliefs actually decreases its probability. This follows from\na theorem of the probability axioms we noted earlier\n (\u00a71.2),\n Conjunction Costs Probability, which says that conjoining \\(A\\) with\n\\(B\\) generally yields a lower probability than for \\(A\\) alone\n(unless \\(p(A \\wedge \\neg B)=0\\)). Intuitively, the more things you\nbelieve the more risks you take with the truth. But making sense of\nthings often requires believing more.\n\nMerricks (1995) replies that it\u2019s only the probability of the\nentire belief corpus that goes down when beliefs are added. But the\nindividual probabilities of the beliefs it contains are what\u2019s\nat issue. And from the detective\u2019s point of view, her individual\nbeliefs do become more probable when made sense of by the additional\ninformation that the suspect has an identical twin. Shogenji (1999)\ndiffers: coherence of the whole cannot influence probability of the\nparts. Coherence is for the parts to stand or fall together, so just\nas coherence makes all the members more likely to be true together, it\nmakes it more likely that they are all false (at the expense of the\npossibility that some will turn out true and others false).\n\nInstead, Shogenji prefers to answer Klein & Warfield at the\ncollective level, the level of the whole belief corpus. He argues that\nthe corpora Klein & Warfield compare differ in probability because\nthey are of different strengths. The more beliefs a corpus\ncontains, or the more specific its beliefs are, the stronger it is. In\nthe case of the detective, adding the information about the twin\nincreases the strength of her beliefs. And, in general, increasing\nstrength decreases probability, since as we\u2019ve seen, \\(p(A\n\\wedge B) \\leq p(A)\\). Thus the increase in the coherence of the\ndetective\u2019s beliefs is accompanied by an increase in strength.\nThe net effect, argues Shogenji, is negative: the probability of the\ncorpus goes down because the increase in strength outweighs the\nincrease in coherence.\n\nTo vindicate this diagnosis, Shogenji appeals to a formula for\nmeasuring the coherence of a belief-set in probabilistic terms, which\nwe\u2019ll label coh:\n\\[ \\textit{coh}(A_1,\\ldots,A_n) = \\frac{p(A_1\n\\wedge \\ldots \\wedge A_n)}{p(A_1) \\times \\ldots \\times\np(A_n)}\\]\n\nTo see the rationale behind this formula, consider the simple case of\njust two beliefs:\n\\[\\begin{align} \\textit{coh}(A,B) &=\n\\frac{p(A \\wedge B)}{p(A) \\times p(B)}\\\\ &= \\frac{p(A \\mid\nB)}{p(A)}\\end{align}\\]\n\nWhen \\(B\\) has no bearing on \\(A\\), \\(p(A\\mid B)=p(A)\\), and this\nratio just comes out 1, which is our neutral point. If instead \\(B\\)\nraises the probability of \\(A\\), this ratio comes out larger than 1;\nand if \\(B\\) lowers the probability of \\(A\\), it comes out smaller\nthan 1. So \\(\\textit{coh}(A,B)\\) measures the extent to which \\(A\\)\nand \\(B\\) are related. Shogenji\u2019s formula\n\\(\\textit{coh}(A_1,\\ldots,A_n)\\) generalizes this idea for larger\ncollections of propositions.\n\nHow does measuring coherence this way vindicate Shogenji\u2019s reply\nto Klein & Warfield, that the increase in the detective\u2019s\ncoherence is outweighed by an increase in the strength of her beliefs?\nThe denominator in the formula for \\(\\textit{coh}\\) tracks strength:\nthe more propositions there are, and the more specific they are, the\nsmaller this denominator will be. So if we compare two belief-sets\nwith the same strength, their denominators will be the same. Thus, if\none is more coherent than the other, it must be because its numerator\nis greater. Thus coherence increases with overall probability,\nprovided strength is held constant. Since in the detective\u2019s\ncase overall probability does not increase despite the increase in\ncoherence, it must be because the strength of her commitments had an\neven stronger influence.\n\nShogenji\u2019s measure of coherence is criticized by other authors,\nmany of whom offer their own, preferred measures (Akiba 2000; Olsson\n2002, 2005; Glass 2002; Bovens & Hartmann 2003; Fitelson 2003;\nDouven and Meijs 2007). Which measure is correct, if any, remains\ncontroversial, as does the fate of Klein & Warfield\u2019s\nargument against coherentism. Another line of probabilistic attack on\ncoherentism, which we won\u2019t explore here, comes from Huemer\n(1997) and is endorsed by Olsson (2005). Huemer (2011) later retracts\nthe argument though, on the grounds that it foists unnecessary\ncommitments on the coherentist. More details are available in\n the entry on coherentism.\n3.2 Foundationalism\n\nFoundationalists hold that some beliefs are justified without being\njustified by other beliefs. Which beliefs have this special,\nfoundational status? Foundationalists usually identify either beliefs\nabout perceived or remembered matters, like \u201cthere\u2019s a\ndoor in front of me\u201d or \u201cI had eggs yesterday\u201d, or\nelse beliefs about how things seem to us, like \u201cthere appears to\nbe a door in front of me\u201d or \u201cI seem to remember having\neggs yesterday\u201d. Either way, the challenge is to say how these\nbeliefs can be justified if they are not justified by any other\nbeliefs.\n\nOne view is that these beliefs are justified by our perceptual and\nmemorial states. When it looks like there\u2019s a door in front of\nme, this perceptual state justifies me in believing that there is a\ndoor there, provided I have no reason to distrust this appearance. Or,\nat least, I am justified in believing that there appears to\nbe a door there. So foundational beliefs are not arbitrary, they are\njustified by closely related perceptual and memorial states. Still,\nthe regress ends there, because it makes no sense to ask what\njustifies a state of perception or memory. These states are outside\nthe domain of epistemic normativity.\n\nA classic criticism of foundationalism now arises, a version of the\ninfamous\n Sellarsian dilemma.\n Must you know that your (say) vision is reliable to be justified in\nbelieving that there\u2019s a door in front of you on the basis of\nits looking that way? If so, we face the first horn of the dilemma:\nthe regress of justification is revived. For what justifies your\nbelief that your vision is reliable? Appealing to previous cases where\nyour vision proved reliable just pushes things back a step, since the\nsame problem now arises for the reliability of your memory. Could we\nsay instead that the appearance of a door is enough by itself to\njustify your belief in the door? Then we face the second horn: such a\nbelief would seem to be arbitrary, formed on the basis of a source you\nhave no reason to trust, namely your vision (Sellars 1956; Bonjour\n1985; Cohen 2002).\n\nThis second horn is sharpened by White (2006), who formalizes it in\nprobabilistic terms. Let \\(A(D)\\) be the proposition that there\nappears to be a door before you, and \\(D\\) the proposition that there\nreally is a door there. The conjunction \\(A(D) \\wedge \\neg D\\)\nrepresents the possibility that appearances are misleading in this\ncase. It says there appears to be a door but isn\u2019t really. Using\nthe probability axioms, we can prove that \\(p(D\\mid A(D)) \\leq p(\\neg\n(A(D) \\wedge \\neg D))\\) (see\n technical supplement \u00a73).\n In other words, the probability that there really is a door given\nthat there appears to be one cannot exceed the initial probability\nthat appearances are not misleading in this case. So it seems that any\njustification \\(A(D)\\) lends to belief in \\(D\\) must be preceded by\nsome justification for believing that appearances are not misleading,\ni.e., \\(\\neg (A(D) \\wedge \\neg D)\\). Apparently then, you must know\n(or have reason to believe) your sources are reliable before you can\ntrust them. (Pryor 2013 elucidates some tacit assumptions in this\nargument.)\n\nLying in wait at the other horn of the Sellarsian dilemma is the\nPrinciple of Indifference (PoI). What is the initial probability that\nthe appearance as of a door is misleading, according to the PoI? On\none way of thinking about it, your vision can be anywhere from 100%\nreliable to 0% reliable. That is, the way things appear to us might be\naccurate all the time, none of the time, or anywhere in between. If we\nregard every degree of reliability from 0% to 100% as equally\nprobable, the effect is the same as if we just assumed experience to\nbe 50% reliable. The PoI will then assign \\(p(D\\mid A(D))=1/2\\). This\nresult effectively embraces skepticism, since we remain agnostic about\nthe presence of the door despite appearances.\n\nWe saw earlier\n (\u00a72.1)\n that the PoI assigns different probabilities depending on how we\ndivide up the space of possibilities. What if we divide things up this\nway instead:\n\n\n\n\\(D\\)\n\\(\\neg D\\) \n\n\\(A(D)\\)\n\\(1/4\\)\n\\(1/4\\) \n\n\\(\\neg A(D)\\)\n\\(1/4\\)\n\\(1/4\\) \n\n\nOnce again, we get the skeptical, agnostic result that \\(p(D\\mid\nA(D))=1/2\\). Other ways of dividing up the space of possibilities will\nsurely deliver better, anti-skeptical results. But then some argument\nfor preferring those ways of dividing things up will be wanted,\nlaunching the regress of justification all over again.\n\nSubjectivists, who reject the PoI and allow any assignment of initial\nprobabilities as long as it obeys the probability axioms, may respond\nthat it\u2019s perfectly permissible to assign a high initial\nprobability to the hypothesis that our senses are (say) 95% reliable.\nBut they must also admit that it is permissible to assign a high\ninitial probability to the hypothesis that our senses are 0% reliable,\ni.e., wrong all the time. Subjectivists can say that belief in the\nexternal world is justified, but they must allow that skepticism is\njustified too. Some foundationalists may be able to live with this\nresult, but many seek to understand how experience justifies external\nworld beliefs in a stronger sense\u2014in a way that can be used to\ncombat skeptics, rather than merely agreeing to disagree with\nthem.\n4. Fourth Case Study: The Limits of Knowledge\n\nSo far we\u2019ve used just one formal tool, probability theory. We\ncan get many similar results in the above applications using other\ntools, like\n Dempster-Shafer theory\n or\n ranking theory.\n But let\u2019s move to a new application, and a new tool.\nLet\u2019s use modal logic to explore the limits of knowledge.\n4.1 Epistemic Modal Logic\n\nThe language of modal logic is the same as ordinary, classical logic,\nbut with an additional sentential operator, \\(\\Box\\), thrown in to\nrepresent necessity. If a sentence \\(\\phi\\) isn\u2019t just true, but\nnecessarily true, we write \\(\\Box \\phi\\).\n\nThere are many kinds of necessity, though. Some things are logically\nnecessary, like tautologies. Others may not be logically necessary,\nbut still metaphysically necessary. (That Hesperus and Phosphorus are\nidentical is a popular example; more controversial candidates are\nGod\u2019s existence or facts about parental origin, e.g., the fact\nthat Ada Lovelace\u2019s father was Lord Byron.)\n\nBut the kind of necessity that concerns us here is epistemic\nnecessity, the necessity of things that must be true given what\nwe know. For example, it is epistemically necessary for you that the\nauthor of this sentence is human. If you didn\u2019t know that\nalready (maybe you hadn\u2019t considered the question), it had to be\ntrue given other things you did know: that humans are the only beings\non Earth capable of constructing coherent surveys of formal\nepistemology, and that this is such a survey (I hope).\n\nIn epistemic modal logic then, it makes sense to write \\(K \\phi\\)\ninstead of \\(\\Box \\phi\\), where \\(K \\phi\\) means that \\(\\phi\\) is\nknown to be true, or at least follows from what is known to be true.\nKnown by whom? That depends on the application. Let\u2019s assume we\nare talking about your knowledge unless specified otherwise.\n\nWhat axioms should epistemic modal logic include? Well, any tautology\nof propositional logic should be a theorem, like \\(\\phi \\supset\n\\phi\\). For that matter, formulas with the \\(K\\) operator that are\nsimilarly truth-table valid, like \\(K \\phi \\supset K \\phi\\), should be\ntheorems too. So we\u2019ll just go ahead and make all these formulas\ntheorems in the crudest way possible, by making them all axioms:\n\n(P) Any\nsentence that is truth-table valid by the rules of\nclassical logic is an axiom. \n\n\nAdopting P immediately makes our list of axioms\ninfinite. But they\u2019re all easily identified by the truth-table\nmethod, so we won\u2019t worry about it.\n\nMoving beyond classical logic, all so-called \u201cnormal\u201d\nmodal logics share an axiom that looks pretty sensible for epistemic\napplications: \n\n\\[\\tag{\\(\\bf K\\)}\nK (\\phi \\supset \\psi) \\supset (K \\phi \\supset K \\psi)\n\\]\n\n\nIf you know that \\(\\phi \\supset \\psi\\) is true, then if you also know\n\\(\\phi\\), you also know \\(\\psi\\). Or at least, \\(\\psi\\) follows from\nwhat you know if \\(\\phi \\supset \\psi\\) and \\(\\phi\\) do. (The\n\u2018K\u2019 here stands for \u2018Kripke\u2019\nby the way, not for \u2018knowledge\u2019.) Another common axiom\nshared by all \u201calethic\u201d modal logics also looks good:\n\n\\[\\tag{\\(\\bf T\\)}\nK \\phi \\supset \\phi\n\\]\n\n\nIf you know \\(\\phi\\), it must be true. (Note: K and\nT are actually axiom schemas, since any sentence of\nthese forms is an axiom. So each of these schemas actually adds\ninfinitely many axioms, all of the same general form.)\n\nTo these axioms we\u2019ll add two inference rules. The first,\nfamiliar from classical logic, states that from \\(\\phi \\supset \\psi\\)\nand \\(\\phi\\), one may derive \\(\\psi\\). Formally: \n\n\\[\\tag{\\(\\bf{MP}\\)}\n\\phi \\supset \\psi, \\phi \\vdash \\psi\n\\]\n\n\nThe second rule is specific to modal logic and states that from\n\\(\\phi\\) one can infer \\(K \\phi\\). Formally: \n\n\\[\\tag{\\(\\textbf{NEC}\\)}\n\\phi \\vdash K \\phi\n\\]\n\n\nThe NEC rule looks immediately suspect: doesn\u2019t\nit make everything true known? Actually, no: our logic only admits\naxioms and things that follow from them by MP. So\nonly logical truths will be subject to the NEC rule,\nand these are epistemically necessary: they\u2019re either known, or\nthey follow from what we know, because they follow given no\nassumptions at all. (NEC stands for\n\u2018necessary\u2019, epistemically necessary in the present\nsystem.)\n\nThe three axiom schemas P, K, and\nT, together with the derivation rules\nMP and NEC, complete our minimal\nepistemic modal logic. They allow us to derive some basic theorems,\none of which we\u2019ll use in the next section:\n\nTheorem (\\(\\bwedge\\)-distribution). \\(K(\\phi \\wedge\n\\psi) \\supset (K \\phi \\wedge K \\psi)\\) \n\n(See the\n technical supplement\n for a proof). This theorem says roughly that if you know a\nconjunction, then you know each conjunct. At least, each conjunct\nfollows from what you know (I\u2019ll be leaving this qualifier\nimplicit from now on), which seems pretty sensible.\n\nCan we prove anything more interesting? With some tweaks here and\nthere, we can derive some quite striking results about the limits of\nour knowledge.\n4.2 The Knowability Paradox (a.k.a. the Church-Fitch Paradox)\n\nCan everything that is true be known? Or are there some truths that\ncould never be known, even in principle? A famous argument popularized\nby Fitch (1963) and originally due to Alonzo Church (Salerno 2009)\nsuggests not: some truths are unknowable. For if all truths were\nknowable in principle, we could derive that all truths are actually\nknown already, which would be absurd.\n\nThe argument requires a slight extension of our epistemic logic, to\naccommodate the notion of knowability. For us, \\(K\\) means known (or\nentailed by the known), whereas knowability adds an extra modal layer:\nwhat it\u2019s possible to know. So we\u2019ll need a\nsentential operator \\(\\Diamond\\) in our language to represent\nmetaphysical possibility. Thus \\(\\Diamond \\phi\\) means\n\u201cit\u2019s metaphysically possible for \\(\\phi\\) to be\ntrue\u201d. In fact, \\(\\Diamond \\phi\\) is just short for \\(\\neg \\Box\n\\neg \\phi\\), since what doesn\u2019t have to be false can be true. So\nwe can actually add the \\(\\Box\\) instead and assume that, like the\n\\(K\\) operator, it obeys the NEC rule. (As with the\nNEC rule for the \\(K\\) operator, it\u2019s okay that\nwe can always derive \\(\\Box \\phi\\) from \\(\\phi\\), because we can only\nderive \\(\\phi\\) in the first place when \\(\\phi\\) is a logical truth.)\n\\(\\Diamond\\) is then just \\(\\neg \\Box \\neg\\) by definition.\n\nWith this addition to our language in place, we can derive the\nfollowing lemma (see the\n technical supplement\n for the derivation):\n\nLemma (Unknowns are Unknowable). \\( \\neg \\Diamond\nK(\\phi \\wedge \\neg K \\phi)\\)\n\nThis lemma basically says you can\u2019t know a fact of the sort,\n\u201c\\(\\phi\\) is true but I don\u2019t know it\u2019s true\u201d,\nwhich seems pretty sensible. If you knew such a conjunction, the\nsecond conjunct would have to be true, which conflicts with your\nknowing the first conjunct. (This is where\n\\(\\bwedge\\)-distribution proves useful.)\n\nYet this plausible looking lemma leads almost immediately to the\nunknowability of some truths. Suppose for reductio that\neverything true could be known, at least in principle. That is,\nsuppose we took as an axiom:\n\nKnowledge Without Limits\n\n\\(\\phi \\supset \\Diamond K \\phi\\) \n\nWe would then be able to derive in just a few lines that everything\ntrue is actually known, i.e., \\(\\phi \\supset K \\phi\\).\n\\begin{array}{rll} 1.& (\\phi \\wedge \\neg K \\phi) \\supset \\Diamond\nK (\\phi \\wedge \\neg K \\phi)& \\textbf{Knowledge Without Limits}\\\\\n2.& \\neg (\\phi \\wedge \\neg K\\phi)& 1,\\ \\textbf{Unknowns are\nUnknowable, P}\\\\ 3.& \\phi \\supset K\\phi& 2,\\ \\textbf{P}\\\\\n\\end{array}\n\n\nIf \\(K\\) represents what God knows, this would be fine. But if \\(K\\)\nrepresents what you or I know, it seems absurd! Not only are there\ntruths we don\u2019t know, most truths don\u2019t even follow from\nwhat we know. Knowledge Without Limits appears to be\nthe culprit here, so it seems there are some things we could not know,\neven in principle. But see\n the entry on Fitch\u2019s paradox of knowability\n for more discussion.\n4.3 Self-Knowledge\n\nEven if we can\u2019t know some things, might we at least have\nunlimited access to our own knowledge? Are we at least always able to\ndiscern whether we know something? A popular axiom in the logic of\nmetaphysical necessity is the so-called S4 axiom: \\(\\Box \\phi \\supset\n\\Box \\Box \\phi\\). This says that whatever is necessary had to\nbe necessary. In epistemic logic, the corresponding formula is:\n\n\\[\\tag{\\(\\bf KK\\)}\nK \\phi \\supset KK \\phi\n\\]\n\n\nThis says roughly that whenever we know something, we know that we\nknow it. Hintikka (1962) famously advocates including\nKK as an axiom of epistemic logic. But an influential\nargument due to Williamson (2000) suggests otherwise.\n\nThe argument hinges on the idea that knowledge can\u2019t be had by\nluck. Specifically, to know something, it must be that you\ncouldn\u2019t have been wrong very easily. Otherwise, though you\nmight be right, it\u2019s only by luck. For example, you might\ncorrectly guess that there are exactly 967 jellybeans in the jar on my\ndesk, but even though you\u2019re right, you just got lucky. You\ndidn\u2019t know there were 967 jellybeans, because there could\neasily have been 968 jellybeans without you noticing the\ndifference.\n\nTo formalize this \u201cno-luck\u201d idea, let the propositions\n\\(\\phi_1, \\phi_2\\), etc. say that the number of jellybeans is at least\n1, at least 2, etc. We\u2019ll assume you\u2019re eyeballing the\nnumber of jellybeans in the jar, not counting them carefully. Because\nyou\u2019re an imperfect estimator of large quantities of jellybeans,\nyou can\u2019t know that there are at least 967 jellybeans in the\njar. If you think there are at least 967 jellybeans, you could easily\nmake the mistake of thinking there are at least 968, in which case\nyou\u2019d be wrong. So we can formalize the \u201cnot easily\nwrong\u201d idea in this scenario as follows:\n\nSafety\n\n\\(K \\phi_i \\supset \\phi_{i+1}\\) when \\(i\\) is large (at least \\(100\\)\nlet\u2019s say). \n\nThe idea is that knowledge requires a margin for error, a margin of at\nleast one jellybean in our example. Presumably more than one\njellybean, but at least one. Within one jellybean of the true number,\nyou can\u2019t discern truth from falsehood. (See Nozick (1981) for a\ndifferent conception of a \u201cno luck\u201d requirement on\nknowledge, which Roush (2005; 2009) formalizes in probabilistic\nterms.)\n\nHaving explained all this to you though, here\u2019s something else\nyou now know: that the Safety thesis is true. So we\nalso have:\n\nKnowledge of Safety\n\n\\(K(K \\phi_i \\supset \\phi_{i+1})\\) when \\(i\\) is large. \n\nAnd combining Knowledge of Safety with\nKK yields an absurd result: \\begin{array}{rll}\n1.& K \\phi_{100}& \\mbox{Assumption}\\\\ 2.& KK\n\\phi_{100}& 1, \\mathbf{KK}\\\\ 3.& K(K \\phi_{100} \\supset\n\\phi_{101})& \\textbf{Knowledge of Safety}\\\\ 4.& KK \\phi_{100}\n\\supset K \\phi_{101}& 3, \\mathbf{K}\\\\ 5.& K \\phi_{101}&\n2,4, \\mathbf{MP}\\\\ &&\\mbox{repeat steps (2)\u2013(5) for\n}\\phi_{101}, \\phi_{102}, \\ldots, \\phi_n\\\\ m.& K \\phi_n& m-1,\n\\mathbf{MP}\\\\ m'.& \\phi_n& m, \\mathbf{T}\\\\ \\end{array}\n\n\nGiven the assumption on line (1), that you know there are at least\n\\(100\\) jellybeans in the jar (which you can plainly see), we can show\nthat there are more jellybeans in the jar than stars in the galaxy.\nSet \\(n\\) high enough and the jellybeans even outnumber the particles\nin the universe! (Notice that we don\u2019t rely on\nNEC anywhere in this derivation, so it\u2019s okay\nto use non-logical assumptions like line (1) and Knowledge of\nSafety.)\n\nWhat\u2019s the philosophical payoff if we join Williamson in\nrejecting KK on these grounds? Skeptical arguments\nthat rely on KK might be disarmed. For example, a\nskeptic might argue that to know something, you must be able to rule\nout any competing alternatives. For example, to know the external\nworld is real, you must be able to rule out the possibility that you\nare being deceived by Descartes\u2019 demon (Stroud 1984). But then\nyou must also be able to rule out the possibility that you\ndon\u2019t know the external world is real, since this is\nplainly an alternative to your knowing it is real. That is,\nyou must \\(K \\neg\\neg K\\phi\\), and thus \\(KK\\phi\\) (Greco 2014). So\nthe driving premise of this skeptical argument entails the\nKK thesis, which we\u2019ve seen reason to\nreject.\n\nOther skeptical arguments don\u2019t rely on KK, of\ncourse. For example, a different skeptical tack begins with the\npremise that a victim of Descartes\u2019 demon has exactly the same\nevidence as a person in the real world, since their experiential\nstates are indistinguishable. But if our evidence is the same in the\ntwo scenarios, we have no justification for believing we are in one\nrather than the other. Williamson (2000: ch. 8) deploys an argument\nsimilar to his reductio of KK against the\npremise that the evidence is the same in the real world and the demon\nworld. The gist is that we don\u2019t always know what evidence we\nhave in a given scenario, much as we don\u2019t always know what we\nknow. Indeed, Williamson argues that any interesting feature of our\nown minds is subject to a similar argument, including that it appears\nto us that \\(\\phi\\): \\(A\\phi \\supset KA\\phi\\) faces a similar\nreductio to that for \\(K\\phi \\supset KK \\phi\\). For further\nanalysis and criticism, see Hawthorne (2005), Mahtani (2008),\nRamachandran (2009), Cresto (2012), and Greco (2014).\n5. Fifth Case Study: Social Epistemology\n\nInteresting things happen when we study whole communities, not just\nisolated individuals. Here we\u2019ll look at information-sharing\nbetween researchers, and find two interesting results. First, sharing\ninformation freely can actually hurt a community\u2019s ability to\ndiscover the truth. Second, mistrust between members of the community\ncan lead to a kind of polarization.\n\nWe\u2019ll also introduce a new tool in the process: computer\nsimulation. The python code to reproduce this section\u2019s results\ncan be \n downloaded from GitHub.\n5.1 The Zollman Effect\n\nImagine there are two treatments for some medical condition. One\ntreatment is old, and its efficacy is well known: it has a .5 chance\nof curing the condition in any given case. The other treatment is new,\nand might be slightly better or slightly worse: a .501 chance of\nsuccess, or else .499. Researchers aren\u2019t sure yet which it\nis.\n\nAt present, some doctors are wary of the new treatment, others are\nmore optimistic. So some try it on their patients while others stick\nto the old ways. As it happens the optimists are right: the new\ntreatment is superior: it has a .501 chance of success.\n\nSo, will the new treatment\u2019s superiority eventually emerge as a\nconsensus within the community? As data on its performance are\ngathered and shared, shouldn\u2019t it become clear over time that\nthe new treatment is slightly better?\n\nNot necessarily. It\u2019s possible that those trying the new\ntreatment will hit a string of bad luck. Initial studies may get a run\nof less-than-stellar results, which don\u2019t accurately reflect the\nnew treatment\u2019s superiority. After all, it\u2019s only slightly\nbetter than the traditional treatment. So it might not show its mettle\nright away. And if it doesn\u2019t, the optimists may abandon it\nbefore it has a chance to prove itself.\n\nOne way to mitigate this danger is to limit the flow of information in\nthe medical community. Following Zollman (2007), let\u2019s\ndemonstrate this by simulation.\n\nWe\u2019ll create a network of \u201cdoctors,\u201d each with their\nown initial credence that the new treatment is superior. Those with\ncredence above .5 will try the new treatment, others will stick to the\nold one. Doctors connected by a line share their results with each\nother, and everyone then updates on whatever results they see using\nBayes\u2019 theorem (\u00a71.2.2).\n\nWe\u2019ll consider networks of different sizes, from 3 to 10\ndoctors. And we\u2019ll try three different network\n\u201cshapes,\u201d either a complete network, a wheel, or a\ncycle:\n\n\nThree network configurations, illustrated here with 6 doctors each\n\n\nOur conjecture is that the cycle will prove most reliable. A doctor\nwho gets an unlucky string of misleading results will do the least\ndamage there. Sharing their results might discourage their two\nneighbours from learning the truth. But the others in the network may\nkeep investigating, and ultimately learn the truth about the new\ntreatment\u2019s superiority. The wheel should be more vulnerable to\naccidental misinformation, however, and the complete network most\nvulnerable.\n\nHere are the details. Initially, each doctor is assigned a random\ncredence that the new treatment is superior, chosen uniformly from the\n[0, 1] interval. Those with credence above .5 will then try the new\ntreatment on 1,000 patients. The number of successes will be randomly\ndetermined by performing 1,000 \u201cflips\u201d of a virtual coin\nwith probability .501 of heads (successful treatment).\n\nEach doctor then shares their results with their neighbours, and\nupdates by Bayes\u2019 theorem on all data available to them. Then we\ndo another round of experimenting, sharing, and updating, followed by\nanother, and so on until the community reaches a consensus.\n\nConsensus can be achieved in either of two ways. Either everyone\nlearns the truth, that the new treatment is superior, by achieving\nhigh credence in it (above .99 we\u2019ll say). Alternatively,\neveryone might reach credence .5 or lower in the new treatment. Then\nno one experiments with it further, so it\u2019s impossible for it to\nmake a comeback.\n\nHere\u2019s what happens when we run each simulation 10,000 times.\nBoth the shape of the network and the number of doctors affect how\noften the community finds the truth. The first factor is the Zollman\neffect: the less connected the network, the more likely they\u2019ll\nfind the truth.\n\n\nProbability of discovering the truth\ndepends on network configuration and number of doctors.\n\n\nBut notice that a bigger community is more likely to find the truth\ntoo. Why? Because bigger, less connected networks are better insulated\nagainst misleading results. Some doctors are bound to get data that\ndon\u2019t reflect the true character of the new treatment once in a\nwhile. And when that happens, their misleading results risk polluting\nthe community with misinformation, discouraging others from\nexperimenting with the new treatment. But the more people in the\nnetwork, the more likely the misleading results will be swamped by\naccurate, representative results from others. And the fewer people see\nthe misleading results, the fewer people will be misled.\n\nHere\u2019s an animated pair of simulations to illustrate the first\neffect. Here I\u2019ve set the six doctors\u2019 starting credences\nto the same, even spread in both networks: .3, .4, .5, .6, .7, and .8.\nI also gave them the same sequence of random data. Only the\nconnections in the networks are different, and in this case it makes\nall the difference. Only the cycle learns the truth. The complete\nnetwork goes dark very early, abandoning the novel treatment entirely\nafter just 26 iterations.\n\n\nTwo networks with identical priors encounter\n identical evidence, but only one discovers the truth.\n [Alternative link to video]\n\n\nWhat saves the cycle network is the doctor who starts with .8 credence\n(bottom left). They start out optimistic enough to keep going after\nthe group encounters an initial string of dismaying results. In the\ncomplete network, however, they receive so much negative evidence\nearly on that they give up almost right away. Their optimism is\noverwhelmed by the negative findings of their many neighbours. Whereas\nthe cycle exposes them to less of this discouraging evidence, giving\nthem time to keep experimenting with the novel treatment, ultimately\nwinning over their neighbours.\n\nAs Rosenstock, Bruner, and O\u2019Connor (2017) put it: sometimes\nless is more, when it comes to sharing the results of scientific\ninquiry. But how important is this effect? How often is it present,\nand is it big enough to worry about in actual practice?\n\nRosenstock, Bruner, and O\u2019Connor argue that the Zollman effect\nonly afflicts epistemically \u201chard\u201d problems. It\u2019s\nonly because the difference between our two treatments is so hard to\ndiscern from the data that the Zollman effect is a concern. If the new\ntreatment were much more noticeably superior to the old one, say a .7\nchance of success rather than the .501 we imagined above,\nwouldn\u2019t there be little chance of its superiority going\nunnoticed?\n\nSo Rosenstock, Bruner, and O\u2019Connor rerun the simulations with\ndifferent values for \u201cepsilon,\u201d the increase in\nprobability of success afforded by the new treatment. Before we held\nepsilon fixed at .001 = .501 \u2212 .5. But now we\u2019ll let it\nvary up to .1. For simplicity we\u2019ll only consider a complete\nnetwork versus a cycle this time, and we\u2019ll hold the number of\ndoctors fixed at 10. (The number of trials each round continues to be\n1,000.)\n\n\nThe Zollman effect vanishes as the difference in efficacy between the two treatments increases\n\n\n\nObserve how the Zollman effect shrinks as epsilon grows. In fact\nit\u2019s only visible up to about .025 in these simulations.\n\nRosenstock, Bruner, and O\u2019Connor also run other variations to\nshow that if our medical community is much larger, or if each doctor\ngathers a much larger sample before sharing, the Zollman effect\nvanishes. It becomes very unlikely that an unrepresentative sample\nwill arise and discourage the whole community. So there\u2019s no\nreal harm in sharing data freely.\n\nA natural question then is: how often do real-world research\ncommunities face the kind of \u201chard\u201d problem where the\nZollman effect is a real concern? Rosenstock, Bruner, and\nO\u2019Connor acknowledge that some laboratory experiments have found\nsimilar effects, where limiting communication between subjects leads\nto improved epistemic outcomes. But they also stress that the Zollman\neffect is not \u201crobust,\u201d requiring fairly specific\ncircumstances to arise (small epsilon, a small research community, and\nnot-too-large sample sizes). Since the above model is both simple and\nidealized, this lack of robustness should give us pause, they argue,\nabout its likely applicability in real-world scenarios.\n5.2 Mistrust & Polarization\n\nLet\u2019s switch now to a different use of these epistemic network\nmodels. So far our doctors updated on each other\u2019s data as if it\nwere their own. But what if they mistrust one another? It\u2019s\nnatural to have less than full faith in those whose opinions differ\nfrom your own. They seem to have gone astray somewhere, after all. And\neven if not, their views may have illicitly influenced their\nresearch.\n\nSo maybe our doctors won\u2019t take the data shared by others at\nface value. Suppose instead they discount it, especially when the\nsource\u2019s viewpoint differs greatly from their own.\nO\u2019Connor & Weatherall (2018) and Weatherall &\nO\u2019Connor (forthcoming) explore this possibility, and find that\nit can lead to polarization. Instead of the community reaching a\nconsensus, some doctors in the community may abandon the new\ntreatment, even while others conclude that it\u2019s superior.\n\nIn the example animated below, doctors in blue have credence above .5,\nso they experiment with the new treatment, sharing the results with\neveryone. Doctors in green have credence .5 or below, but are still\npersuadable. They still trust the blue doctors enough to update on\ntheir results\u2014though they discount these results more the\ngreater their difference of opinion with the doctor who generated\nthem. Finally, red doctors ignore results entirely. They\u2019re so\nfar from all the blue doctors that they don\u2019t trust them at\nall.\n\n\nExample of polarization in the O\u2019Connor-Weatherall model \n[Alternative link to video]\n\n\nIn this simulation, we reach a point where there are no more green\ndoctors, only unpersuadable skeptics in red and highly confident\nbelievers in blue. And the blues have become so confident,\nthey\u2019re unlikely to ever move close enough to any of the reds to\nget their ear. So we\u2019ve reached a stable state of\npolarization.\n\nHow often does such polarization occur? It depends on the size of the\ncommunity, and on the \u201crate of mistrust.\u201d To program this\nmodel, we have to decide how much one doctor discounts another\u2019s\ndata, given their difference of opinion. This \"rate of mistrust\" is an\nadjustable parameter in the model.\n\nHere\u2019s how these two factors\u2014community size and rate of\nmistrust\u2014affect the probability of polarization. (Note that we\nonly consider complete networks here.)\n\n\nProbability of polarization depends on community size and rate of mistrust.\n\n\nSo, the more doctors are inclined to mistrust one another, the more\nlikely they are to end up polarized. No surprise there. But larger\ncommunities are also more disposed to polarize. Why?\n\nAs O\u2019Connor & Weatherall explain, the more doctors there\nare, the more likely it is that strong skeptics will be present at the\nstart of inquiry: doctors with credence well below .5. These doctors\nwill tend to ignore the reports of the optimists experimenting with\nthe new treatment. So they anchor a skeptical segment of the\npopulation.\n\nSo far we\u2019ve glossed over an important detail of O\u2019Connor\n& Weatherall\u2019s model. How does the discounting work, and how\ndo doctor\u2019s update on discounted evidence? When Dr.\u00a0X\nreports data \\(E\\) to Dr.\u00a0Y, Y doesn\u2019t simply\nconditionalize on \\(E\\). That would mean they take X\u2019s report at\nface value. So what do they do?\n\nTo compute their updated credence \\(p'(H)\\) in the new\ntreatment\u2019s superiority, Y takes a weighted average of\n\\(p(H \\mid E)\\) and \\(p(H \\mid \\neg E)\\). This\nprocedure is a famous variation on conditionalization known as\n Jeffrey Conditionalization:\n\nJeffrey Conditionalization\n\nGiven the prior probability assignments \\(p(H\\mid E)\\) and \\(p(H\\mid\n\\neg E)\\), the new, unconditional probability assignment to \\(H\\) upon\nlearning \\(E\\) with level of certainty \\(p'(E)\\) should be:\n\n\\[p'(H) = p(H \\mid E)p'(E) + p(H \\mid \\neg E)p'(\\neg E).\\]\n\n \n\nThis formula looks a lot like the law of total probability\n(\u00a71.2.1), but there\u2019s a crucial difference. The weights in\nthis weighted average are not \\(p(E)\\) and \\(p(\\neg E)\\). They are\ninstead \\(p'(E)\\) and \\(p'(\\neg E)\\). They are the updated,\nalready-discounted probabilities Y assigns to X\u2019s report and its\nnegation.\n\nO\u2019Connor & Weatherall (2018) suggest a natural formula for\ncomputing \\(p'(E)\\) and \\(p'(\\neg E)\\), which we won\u2019t go into\nhere. We\u2019ll just note that the choice of formula is crucial to the\npolarization effect. Mistrust doesn\u2019t necessarily introduce the\npossibility of polarization; the mistrust has to be sufficiently\nstrong (greater than 1.0 in the above figure). There has to be a point\nat which agents won\u2019t trust each other at all because their difference\nof opinion is so great. Otherwise the skeptics would never ignore\ntheir optimistic colleagues entirely, so they\u2019d eventually be won over\nby their encouraging reports.\n\nThis illustrates a general issue with update rules like Jeffrey\nConditionalization: to apply them, we first need to determine the new\nprobabilities to assign to the evidence. From there we can determine\nthe new probabilities of other propositions. But this essential bit of\ninput is something for which we don\u2019t have a rule; it\u2019s a\nsort of loose end in the formal system, something that\u2019s left up\nto us as users of the model. For some discussion of the\nepistemological significance of this point, see Field (1978) and\nChristensen (1992).\n\nFor a different formal approach to polarization, see Dorst (2020, \nOther Internet Resources). For\nother work on network epistemology see Zollman (2013) and\n \u00a74.3 of the entry on social epistemology,\n and the references therein.\n\nOther formal projects in social epistemology include work on the\nrelationship between social and individual rationality (Mayo-Wilson,\nZollman, and Danks 2011); on judgment aggregation/opinion pooling\n(Genest and Zidek 1986; List and Pettit 2002; Russell, Hawthorne, and\nBuchak 2015); on learning from the beliefs of others (Easwaran et\nal 2016; Bradley 2018); and on the social benefits of competing\nupdate rules, such as Conditionalization vs.\u00a0Inference to the\nBest Explanation (Douven and Wenmackers 2017; Pettigrew m.s., \nOther Internet Resources).\n6. Applications Outside Epistemology\n\nTools like probability theory and epistemic logic have numerous uses\nin many areas of philosophy besides epistemology. Here we\u2019ll\nlook briefly at just a few examples: how to make decisions, whether\nGod exists, and what hypothetical discourses like\n\u2018if\u2026then \u2026\u2019 mean.\n6.1 Decision Theory\n\nShould you keep reading this section, or should you stop here and go\ndo something else? That all depends: what might you gain by continuing\nreading, and what are the odds those gains will surpass the gains of\ndoing something else instead? Decision theory weighs these\nconsiderations to determine which choice is best.\n\nTo see how the weighing works, let\u2019s start with a very simple\nexample: betting on the outcome of a die-roll. In particular,\nlet\u2019s suppose a 5 or 6 will win you $19, while any other outcome\nloses you $10. Should you take this bet? We can represent the choice\nyou face in the form of a table:\n\n\n\nRoll 1\u20134\nRoll 5 or 6 \n\nBet\n\u2212$10\n\\(+\\)$19 \n\nDon\u2019t bet\n$0\n$0 \n\n\nSo far, taking the bet looks pretty good: you stand to gain almost\ntwice as much as you stand to lose. What the table doesn\u2019t show,\nhowever, is that you\u2019re twice as likely to lose as to win:\n\\(2/3\\) vs. \\(1/3\\). So let\u2019s add this information in:\n\n\n\nRoll 1\u20134\nRoll 5 or 6 \n\nBet\n\\(\\substack{-$10\\\\ p=2/3}\\)\n\\(\\substack{+$19\\\\ p=1/3}\\) \n\nDon\u2019t bet\n\\(\\substack{-$0\\\\ p=2/3}\\)\n\\(\\substack{+$0\\\\ p=1/3}\\) \n\n\nNow we can see that the potential downside of betting, namely losing\n$10, isn\u2019t outweighed by the potential upside. What you stand to\nwin isn\u2019t quite twice what you\u2019d lose, but the probability\nof losing is twice as much. Formally, we can express this\nline of thinking as follows:\n\\[ (-10 \\times 2/3) + (19 \\times 1/3) = -1/3\n< 0\\]\n\nIn other words, when the potential losses and gains are weighed\nagainst their respective probabilities, their sum total fails to\nexceed 0. But $0 is what you can expect if you don\u2019t bet. So\nbetting doesn\u2019t quite measure up to abstaining in this\nexample.\n\nThat\u2019s the basic idea at the core of decision theory, but\nit\u2019s still a long way from being satisfactory. For one thing,\nthis calculation assumes money is everything, which it surely\nisn\u2019t. Suppose you need exactly $29 to get a bus home for the\nnight, and all you have is the $10 bill in your pocket, which on its\nown is no use (even the cheapest drink at the casino bar is $11). So\nlosing your $10 isn\u2019t really much worse than keeping\nit\u2014you might as well be broke either way. But gaining\n$19, now that\u2019s worth a lot to you. If you can just get the bus\nback home, you won\u2019t have to sleep rough for the night.\n\nSo we have to consider how much various dollar-amounts are worth\nto you. Losing $10 is worth about the same to you as losing $0,\nthough gaining $19 is much, much more valuable. To capture these\nfacts, we introduce a function, \\(u\\), which represents the\nutility of various possible outcomes. For you, \\(u(-$10)\n\\approx u(-$0)\\), but \\(u(+$19) \\gg u(-$0)\\).\n\nExactly how much is gaining $19 worth to you? What is\n\\(u(+$19)=\\ldots\\), exactly? We can actually answer this question if\nwe just set a scale first. For example, suppose we want to know\nexactly how much you value a gain of $19 on a scale that ranges from\ngaining nothing to gaining $100. Then we set \\(u(+$0)=0\\) and\n\\(u(+$100)=1\\), so that our scale ranges from 0 to 1. Then we can\ncalculate \\(u(+$19)\\) by asking how much you would be willing to risk\nto gain $100 instead of just $19. That is, suppose you had a choice\nbetween just being handed $19 with no strings attached vs. being\noffered a (free) gamble that pays $100 if you win, but nothing\notherwise. How high would the probability of winning that $100 have to\nbe for you to take a chance on it instead of the guaranteed $19? Given\nwhat\u2019s at stake\u2014making it home for the night vs. sleeping\nrough\u2014you probably wouldn\u2019t accept much risk for the\nchance at the full $100 instead of the guaranteed $19. Let\u2019s say\nyou\u2019d accept at most .01 risk, i.e., the chance of winning the\nfull $100 would have to be at least .99 for you to trade the\nguaranteed $19 for the chance at the full $100. Well, then, on a scale\nfrom gaining $0 to gaining $100, you value gaining $19 quite highly:\n.99 out of 1. (This method of measuring utility was discovered and\npopularized by von Neumann and Morgenstern (1944), though\nessentially the same idea was previously discovered by Ramsey (1964\n[1926]).)\n\nOur full decision theory relies on two functions then, \\(p\\) and\n\\(u\\). The probability function \\(p\\) reflects how likely you think\nthe various possible outcomes of an action are to obtain, while \\(u\\)\nrepresents how desirable each outcome is. Faced with a choice between\ntwo possible courses of action, \\(A\\) and \\(\\neg A\\), with two\npossible states the world might be in, \\(S\\) and \\(\\neg S\\), there are\nfour possible outcomes, \\(O_1,\\ldots,O_4\\). For example, if you bet $1\non a coin-flip coming up heads and it does comes up heads, outcome\n\\(O_1\\) obtains and you win $1; if instead it comes up tails, outcome\n\\(O_2\\) obtains and you lose $1. The general shape of such situations\nis thus:\n\n\n\n\\(S\\)\n\\(\\neg S\\) \n\n\\(A\\)\n\\(\\substack{u(O_1)\\\\ p(S)}\\)\n\\(\\substack{u(O_2)\\\\ p(\\neg S)}\\) \n\n\\(\\neg A\\)\n\\( \\substack{u(O_3)\\\\p(S)}\\)\n\\( \\substack{u(O_4)\\\\p(\\neg S)}\\) \n\n\nTo weigh the probabilities and the utilities against each other, we\nthen define the notion of expected utility:\n\nDefinition. The expected utility of act\n\\(A\\), \\(EU(A)\\), is defined: \n\n\\[ EU(A) = p(S)u(O_1) + p(\\neg S)u(O_2).\\]\n\n The expected\nutility of act \\(\\neg A\\), \\(EU(\\neg A)\\), is likewise:\n\n\\[ EU(\\neg A) = p(S)u(O_3) + p(\\neg S)u(O_4).\\]\n\n \n\n(Why \u201cexpected\u201d utility? If you faced the same decision\nproblem over and over again, and each time you chose option \\(A\\), in\nthe long run you could expect your average utility to be approximately\n\\(EU(A)\\).) The same idea extends to cases with more than two ways\nthings could turn out simply by adding columns to the table and\nmultiplying/summing all the way across. When there are more than two\npossible actions, we just add more rows and do the same.\n\nFinally, our decision theory culminates in the following norm:\n\nExpected Utility Maximization\n\nChoose the option with the highest expected utility. (In case of a\ntie, either option is acceptable.)\n\nWe haven\u2019t given much of an argument for this rule, except that\nit \u201cweighs\u201d the desirability of each possible outcome\nagainst the probability that it will obtain. There are various ways\none might develop this weighing idea, however. The one elaborated here\nis due to Savage (1954). It is considered the classic/orthodox\napproach in social sciences like economics and psychology.\nPhilosophers, however, tend to prefer variations on Savage\u2019s\nbasic approach: either the \u201cevidential\u201d decision theory\ndeveloped by Jeffrey (1965) or some form of\n \u201ccausal\u201d decision theory (see entry)\n (Gibbard and Harper 1978; Skyrms 1980; Lewis 1981; Joyce 1999).\n\nThese approaches all agree on the broad idea that the correct decision\nrule weighs probabilities and utilities in linear fashion: multiply\nthen add (see\n the entry on expected utility).\n A different approach recently pioneered by Buchak (2013, 2014) holds\nthat (in)tolerance for risk throws a non-linear wrench into this\nequation, however (see also Steele 2007). And taking account of\npeople\u2019s cognitive limitations has long been thought to require\nfurther departures from the traditional, linear model (Kahneman and\nTversky 1979; Payne, Bettman, and Johnson 1993; Gigerenzer, Todd, and\nGroup 1999; Weirich 2004).\n6.2 The Existence of God: Fine-tuning\n\nThe mathematical theories of probability and decision emerged together\nin correspondence between Blaise Pascale and Pierre de Fermat in the\nmid-17th Century. Pascal went on to apply them to\ntheological questions, developing his famous \u201cwager\u201d\nargument\n (see entry on Pascal\u2019s Wager)\n for belief in God. Probability theory now commonly appears in\ndiscussions of other arguments for and against theism, especially the\nargument from design. Though Darwin is generally thought to have\ntoppled theistic appeals to biological design, newer findings in\ncosmology and physics seem to support a new probabilistic argument for\nGod\u2019s existence.\n\nThe development of the universe from the Big Bang to its present form\ndepended on two factors: the laws of physics and the initial\nconditions at the time of the Big Bang. Both factors appear to have\nbeen carefully arranged so that the universe would be capable of\nsupporting life. Had certain constants in the physical laws been\nslightly different, intelligent life would never have been able to\nevolve. For example, had the forces that bind the nuclei of atoms\ntogether been slightly stronger or weaker, only hydrogen would exist.\nThere would be no carbon, oxygen, or other elements available to form\ncomplex molecules or organisms. Similarly, had the expansion speed of\nthe Big Bang been slightly different, the universe would have either\nsimply collapsed back in on itself soon after the Big Bang, or else\ndispersed into diffuse dust. Stars and planets would never have formed\n(Rees 1999).\n\nThese findings point to a new kind of design argument, one untouched\nby the advent of evolutionary theory. Evolution might explain the\ndesigns we find in the organic world, but what explains the fact that\nour cosmos appears to be \u201cfine-tuned\u201d to allow the\nexistence of (intelligent) life? Apparently, the cosmos actually was\nfine-tuned, by a creator who deliberately designed it so that it would\ncontain (intelligent) life. If there were no such designer, the\nfine-tuning of the cosmos would be a massively improbable\ncoincidence.\n\nTo make this argument rigorous, it\u2019s often formulated in\nprobabilistic terms. Following Sober (2005), we\u2019ll adopt a\nsimple, modest formulation. Let \\(F\\) be the evidence that our\nuniverse is fine-tuned, as just described, and let \\(D\\) be the\n\u201cdesign hypothesis\u201d, the hypothesis that the universe was\ncreated by an intelligent designer with the aim of creating\n(intelligent) life. The argument then runs:\n\n\n\n\\(p(F\\mid D) > p(F\\mid \\neg D)\\)\n\n\nIn general, when \\(p(E\\mid H) > p(E\\mid \\neg H)\\), then \\(E\\)\nsupports \\(H\\) over \\(\\neg H\\).\n\n\nSo \\(F\\) supports \\(D\\) over \\(\\neg D\\).\n\n\nThe argument is plainly valid, so discussion focuses on the\npremises.\n\nThe rationale behind (1) is that \\(p(F\\mid \\neg D)\\) is quite small,\nsince there are so many ways the physical laws and initial constants\ncould have been, almost all of which would have yielded a universe\ninhospitable to life. Without a designer to ensure hospitable\nconstants and conditions, a hospitable outcome would have been\nmassively improbable. But \\(p(F\\mid D)\\), on the other hand, is fairly\nhigh: the envisioned designer\u2019s aim in creating the universe was\nto create life, after all.\n\nTo see the rationale for (2), recall our discussion of confirmation\ntheory\n (\u00a71.2).\n According to our definition of confirmation, evidence confirms a\nhypothesis just in case \\(p(H\\mid E)>p(H)\\), which Bayes\u2019\ntheorem tells us is equivalent to \\(p(E\\mid H) > p(E)\\). Likewise,\n\\(E\\) disconfirms \\(\\neg H\\) just in case \\(p(E) > p(E\\mid\n\\neg H)\\). Now, we can prove that if \\(p(E\\mid H) > p(E)\\), then\n\\(p(E) > p(E\\mid \\neg H)\\). So if \\(E\\) confirms \\(H\\), it\ndisconfirms \\(\\neg H\\), which amounts to \\(E\\) supporting \\(H\\) over\n\\(\\neg H\\).\n\nIt\u2019s crucial to note, however, that \\(E\\) supporting \\(H\\) over\n\\(\\neg H\\) does not mean that, once we learn \\(E\\), \\(H\\)\nbecomes more probable than \\(\\neg H\\). It just means that \\(E\\) raises\nthe probability of \\(H\\) and decreases the probability of \\(\\neg H\\).\nIf \\(H\\) was very improbable to begin with, then \\(E\\) might not\nincrease its probability enough to make it more probable than \\(\\neg\nH\\). This is why our formulation of the argument is so modest. It only\naims to show that \\(F\\) is evidence for \\(D\\) and against \\(\\neg D\\).\nIt makes no claims about how strong the evidence is, or whether it\nshould leave us theists or atheists in the end (Sober 2005). Yet\ncritics argue that even this modest argument is unsound. We\u2019ll\nconsider four such lines of criticism.\n\nOne line of criticism appeals to so-called \u201canthropic\u201d\nconsiderations. The idea is that some findings are a consequence of\nour nature as observers, and thus reflect something about us rather\nthan the phenomena under discussion. For example, I might notice that\nwhenever I observe a physical object, the observation happens while I\nam awake. But I shouldn\u2019t conclude from this that physical\nobjects only exist when I am awake. This feature of my observations\njust reflects something about me: I have to be awake to make these\nobservations. Likewise, these critics argue, we can only observe a\ncosmos that has the features necessary to support (intelligent) life.\nSo our discovery that our universe is fine-tuned only reflects a\nlimitation in us, that we could not observe the opposite (McMullin\n1993; Sober 2005).\n\nProponents of the fine-tuning argument respond that our inability to\nobserve something does not render observations to the contrary\nuninformative. For example, Leslie (1989) notes that someone put\nbefore an expert firing squad cannot observe that they do not survive,\nsince they won\u2019t be alive to make the observation. Yet in the\nunlikely event that they do survive, that\u2019s strong evidence that\nthe squad missed by design. Expert firing squads rarely miss by\naccident. Sober (2005) responds that a firing-squad survivor does\nindeed have evidence, but on a different basis, one that isn\u2019t\navailable to proponents of the design argument. See Monton (2006) and\nSober (2009) for further discussion.\n\nA different line of criticism objects that \\(p(F\\mid \\neg D)\\)\nisn\u2019t low after all: even without a designer, the fine-tuning\ndiscovery was \u201cinevitable\u201d because our universe is just\none in an infinite sequence of universes, oscillating from bang to\ncrunch and back to bang again, with a new set of constants and initial\nconditions emerging at each bang (Wheeler 1973; Leslie 1989). Sooner\nor later, this endless cycle of universal reboots is bound to hit upon\na life-supporting configuration of constants and initial conditions,\nso \\(p(F\\mid \\neg D)\\) may even equal 1, contra premise (1). (How we\ncould know about this endless cycle of universes is a tricky question.\nThe crucial piece of evidence might be that it explains why our\nuniverse is fine-tuned. But then, the same may be true of the design\nhypothesis, \\(D.)\\)\n\nHacking (1987) counters that these \u201coscillating universes\u201d\nonly ensure that some universe at some point in the sequence\nis capable of supporting life. But they make it no more likely that\nthis universe would. At the time of our Big Bang, there were\nstill innumerably life-unfriendly ways things could have started off,\nall equally likely if there was no designer to ensure a life-friendly\nbeginning. Just as rolling a pair of dice over and over again ensures\nthat snake-eyes (both dice coming up 1) will turn up at some point,\nwhatever roll they do turn up on was still extremely unlikely to turn\nout that way. If the 53rd roll comes up snake-eyes, this\nwas hardly inevitable; in fact, it was quite improbable, only a 1 in\n36 chance. Hacking suggests that a different sort of \u201cmultiple\nuniverses\u201d hypothesis escapes this problem: Carter\u2019s\n(1974) hypothesis that all the possible Big Bang-type universes exist\n\u201cside by side\u201d, rather than in an oscillating sequence.\nThen, Hacking suggests, it follows deductively that our universe had\nto exist, so \\(p(F\\mid \\neg D)\\) comes out 1 after all. But White\n(2000) counters that the fallacy in the appeal to Wheeler\u2019s\nmodel afflicts the appeal to Carter\u2019s model too. Even with the\nmultitude of universes existing \u201cside by side\u201d,\nthis one didn\u2019t have to be one of the few with\nlife-friendly parameters.\n\nA third line of criticism attacks the rationale for assigning a low\nnumber to \\(p(F\\mid \\neg D)\\). The complaint is that the rationale\nactually makes \\(p(F\\mid \\neg D)=0\\), and also assigns probability 0\nto many other, intuitively much more probable, ways the universe might\nhave turned out. How so? The rationale for a low \\(p(F\\mid \\neg D)\\)\ngoes something like this: take an apparently fine-tuned parameter of\nour universe, like its expansion speed. This speed had to be exactly\nbetween 9 and 10 km/sc, let\u2019s pretend, for the universe to be\nable to support life. But given that it could have been any speed from\n0 km/sc to 100 km/sc to \\(1,000,000\\) km/sc to\u2026that it would\nend up in the narrow 9\u201310 km/sc window was extremely unlikely to\nhappen without divine guidance. But, the objection goes, the same\ncould be said of much larger ranges, like a \\(10^1\\)\u2013\\(10^{10}\\)\nkm/sc window. Even that large range is a drop in the infinite bucket\nof speeds that could have obtained, from 0 through the entire positive\nreal line. In fact, any finite range is effectively 0% of\ninfinity\u2014indeed, it really is \\(0\\%\\) on the standard ways of\nmeasuring these things (Colyvan, Garfield, and Priest 2005). So even\nif our universe only needed \u201ccoarse tuning\u201d to support\nlife, i.e., even if it would have supported life given any of a\nmassively broad yet finite range of conditions, a parallel premise to\n(1) could be justified by this rationale, and a corresponding\n\u201ccoarse-tuning argument\u201d for design offered (McGrew,\nMcGrew, and Vestrup 2001).\n\nCollins (2009) points out an uncomfortable consequence of this\nobjection, that the fine-tuning argument would be compelling if only\n\\(\\neg D\\) were more life-friendly. Imagine that the laws of\nphysics only permitted a finite range of possible expansion speeds,\nsay 0\u2013100 km/s, with a speed of 9\u201310 km/s required to\nsupport life. Then premise (1) would hold and the fine-tuning argument\nwould succeed: \\(p(F\\mid \\neg D)=1/100\\), with \\(p(F\\mid D)\\)\npresumably much higher, maybe even 1. Now imagine the possible range\nto be much larger, say 0\u2013\\(10^{10}\\) km/s. The argument then\nbecomes even stronger, with \\(p(F\\mid \\neg D)=1/10^{10}\\). As the\nupper limit on possible expansion speeds increases, the argument\nbecomes stronger and stronger\u2026until the limit becomes infinite,\nat which point the argument fails, according to the present\nobjection.\n6.3 The Meaning of \u2018If\u2026Then\u2026\u2019\n\nHypothetical discourses have a puzzling connection to reality. Suppose\nI assert, \u201cIf the GDP continues to decline, unemployment will\nrise\u201d, but the GDP does not continue to decline, instead holding\nsteady. Is what I said true or false? It\u2019s not obvious, since my\nstatement has not been tested by the world in the obvious way. If the\nGDP had continued to decline yet unemployment had fallen, my statement\nwould have been tested, and it would have failed. But GDP held steady,\nso what test can my assertion be put to?\n\nWhen working with propositional logic, we often translate ordinary\n\u2018If \u2026then \u2026\u2019 statements using the material\nconditional, \\(\\supset\\). But the probability of a\n\\(\\supset\\)-statement often exceeds that of the corresponding\n\u2018If \u2026then \u2026\u2019 statement. For example,\nit\u2019s very improbable that I\u2019ll win an Olympic gold medal\nin diving (\\(G\\)) if I train five hours a day (\\(T\\)). Olympic divers\nretire by the time they\u2019re my age. Yet \\(p(T \\supset G)\\) is\nquite high, for the simple reason that \\(T \\supset G\\) is equivalent\nto \\(\\neg T \\vee G\\) and \\(\\neg T\\) is very probable. I won\u2019t be\ntraining for Olympic diving one minute a day, much less five hours. I\ndon\u2019t even swim. So it\u2019s hard to accept \\(\\supset\\) as a\ngood model of \u2018If \u2026then \u2026\u2019, though some\nphilosophers do nevertheless think it\u2019s correct (Grice 1989;\nJackson 1987).\n\nCould we introduce a new connective with a different semantics than\n\\(\\supset\\) that would do better? A striking theorem discovered by\nLewis (1976) suggests not. The theorem relies on an assumption posited\nby Stalnaker (1970): that the probability of \u201cIf \\(A\\) then\n\\(B\\)\u201d is the same as the conditional probability, \\(p(B\\mid\nA)\\). Let\u2019s use \\(A \\rightarrow B\\) as shorthand for the\nEnglish, \u201cIf \\(A\\) then \\(B\\)\u201d:\n\nStalnaker\u2019s Hypothesis\n\n\\(p(A \\rightarrow B) = p(B\\mid A)\\), for any propositions \\(A\\) and\n\\(B\\) and probability function \\(p\\) such that \\(p(A) \\neq 0.\\)\n\nStalnaker\u2019s Hypothesis might seem obvious at first, even\ntautological. Isn\u2019t \\(p(B\\mid A)\\) just the probability of the\nproposition \\(B\\mid A\\), which is just shorthand for \u201c\\(B\\) is\ntrue if \\(A\\) is\u201d? This is a common misconception for newcomers\nto probability theory, one that Lewis shows leads to disastrous\nresults. If we think of \\(B\\mid A\\) as a complex proposition built out\nof the sentences \\(A\\) and \\(B\\) with a connective \\(\\mid \\),\nprobability theory goes to pot (see the\n technical supplement\n for a proof):\n\nTheorem (Lewis\u2019 Triviality Theorem). If\nStalnaker\u2019s Hypothesis is true, then \\(p(B\\mid A)=p(B)\\) for all\npropositions \\(A\\) and \\(B\\) such that \\(p(A) \\neq 0\\) and \\(1 >\np(B) > 0\\).\n\nApparently, no propositional connective \\(\\rightarrow\\) can obey\nStalnaker\u2019s Hypothesis. If one did, every proposition would be\nindependent of every other (except where things are absolutely\ncertain). But surely some facts are relevant to some others.\n\nOne thing this tells us is that the right way to read \\(p(B\\mid A)\\)\nis not as the probability of some sentence, \\(B\\mid A\\), but instead\nas a two-place function. The syntax \\(p(B\\mid A)\\) is misleading, and\nmight be more clearly written \\(p(B,A)\\), the standard notation for a\ntwo-place function like \\(f(x,y)=x^2+y^2\\).\n\nBut a more troubling lesson is that we face an uncomfortable choice:\neither there is no such thing as the proposition \\(A \\rightarrow B\\),\nor the probability of the proposition \\(A \\rightarrow B\\)\ndoesn\u2019t always match \\(p(B\\mid A)\\). The first option would seem\nto make assertions of the form \u201cIf \u2026then \u2026\u201d\na peculiar exception to the compositionality of natural language\nsemantics (but see Edgington 2000). The second option is\ncounterintuitive, and also apparently counter to empirical evidence\nthat people ordinarily do take \\(p(A \\rightarrow B)\\) to be the same\nas \\(p(B\\mid A)\\) (Douven and Dietz 2011).\n\nA particularly striking thing about this problem is how robust it is.\nNot only have many related theorems been proved using probability\ntheory (H\u00e1jek 1989; Edgington 1995; Bradley 2000), but similar\nresults have also emerged in a completely independent formal\nframework:\n the theory of belief revision.\n\nBelief revision theory represents beliefs with sentences of\npropositional logic: \\(A\\), \\(A \\supset B\\), \\(\\neg (A \\wedge \\neg\nB)\\), and so on. Your full corpus of beliefs is a set of such\nsentences we call \\(K\\) (not to be confused with the sentential\noperator \\(K\\) from epistemic logic\n (\u00a74.1)).\n Importantly, we assume that \\(K\\) contains everything entailed by\nyour beliefs: if \\(A\\) and \\(A \\supset B\\) are in \\(K\\), then so is\n\\(B\\), for example.\n\nOf course, real people don\u2019t believe everything their beliefs\nentail, but it helps keep things simple to make this assumption. You\ncan think of it as an idealization: we\u2019re theorizing about what\nyour beliefs should look like if you were a perfect logician. (Notice\nthat probability theory has a similar feature encoded in axiom (2),\nand epistemic logic\u2019s K axiom and\nNEC rule together have a similar effect.)\n\nThe main aim of belief revision theory is to say how you should revise\nyour beliefs when you learn new information. Suppose you learn about\nthe existence of a new planet, Algernon. How should \\(K\\) change when\nyou learn this new fact, \\(A\\)? As long as \\(A\\) doesn\u2019t\ncontradict your existing beliefs, the standard view is that you should\njust add \\(A\\) to \\(K\\), along with everything that follows logically\nfrom the members of \\(K\\) and \\(A\\) together. We call the new set of\nbeliefs \\(K + A\\): add \\(A\\) to \\(K\\) along with all that follows\nlogically (Alchourr\u00f3n, G\u00e4rdenfors, and Makinson 1985).\n\nWhat if \\(A\\) does contradict your existing beliefs? Then \\(K + A\\)\nwouldn\u2019t do, since it would be inconsistent. We\u2019d have to\nremove some of your existing beliefs to make room for \\(A\\). Luckily,\nfor our purposes here we don\u2019t have to worry about how this\nworks. We\u2019ll only consider cases where \\(A\\) is consistent with\n\\(K\\), in which case \\(K + A\\) will do.\n\nNow, suppose we want to add a new connective \\(\\rightarrow\\) to our\nlanguage to represent \u2018If \u2026then \u2026\u2019. When\nshould you believe a sentence of the form \\(A \\rightarrow B\\)? The\nclassic answer comes from an idea of Ramsey\u2019s: that we decide\nwhether to accept \\(A \\rightarrow B\\) by temporarily adding \\(A\\) to\nour stock of beliefs and then seeing whether \\(B\\) follows (Ramsey\n1990 [1929]). This idea yields a principle called the Ramsey\nTest:\n\nRamsey Test\n\n\\(K\\) contains \\(A \\rightarrow B\\) if \\(K + A\\) contains \\(B\\); and\n\\(K\\) contains \\(\\neg (A \\rightarrow B)\\) if \\(K + A\\) contains \\(\\neg\nB\\).\n\nIn other words, you accept \\(A \\rightarrow B\\) if adding \\(A\\) to your\nstock of beliefs brings \\(B\\) with it. If instead adding \\(A\\) brings\n\\(\\neg B\\) with it, you reject this conditional (Etlin 2009).\n\nPlausible as the Ramsey Test is, G\u00e4rdenfors (1986) shows that it\ncannot hold unless your beliefs are absurdly opinionated. We\u2019ll\nstate this result somewhat informally (see the\n technical supplement\n for a somewhat informal proof):\n\nTheorem (G\u00e4rdenfors\u2019 Triviality Theorem).\nAs long as there are two propositions \\(A\\) and \\(B\\) such that \\(K\\)\nis agnostic about \\(A\\), \\(A \\supset B\\), and \\(A \\supset \\neg B\\),\nthe Ramsey Test cannot hold.\n\nApparently, much as no propositional connective \\(\\rightarrow\\) can\nobey Stalnaker\u2019s Hypothesis in probability theory, none can obey\nThe Ramsey Test in belief revision theory either. Whether we approach\nepistemology using probabilities or flat-out beliefs, the same problem\narises. Should we conclude that conditionals have no factual content?\nIt\u2019s a hotly contested question, on which\n the entry on conditionals\n has more.\n", "bibliography": {"categories": [], "cat_ref_text": {"ref_list": ["Akiba, Ken, 2000, \u201cShogenji\u2019s Probabilistic Measure of\nCoherence Is Incoherent\u201d, <em>Analysis</em>, 60(4):\n356\u201359.", "Alchourr\u00f3n, Carlos E., Peter G\u00e4rdenfors, and David\nMakinson, 1985, \u201cOn the Logic of Theory Change: Partial Meet\nContraction and Revision Functions\u201d, <em>The Journal of Symbolic\nLogic</em>, 50(2): 510\u201330.", "Bertrand, Joseph L.F., 2007 [1888], <em>Calcul Des\nProbabilit\u00e9s</em>, Oxford University Press.", "Bonjour, Laurence, 1985, <em>The Structure of Empirical\nKnowledge</em>, Harvard University Press.", "Bovens, Luc and Stephan Hartmann, 2003, <em>Bayesian\nEpistemology</em>, Oxford University Press.", "Bradley, Richard, 2000, \u201cA Preservation Condition for\nConditionals\u201d, <em>Analysis</em>, 60(3): 219\u201322.", "\u2013\u2013\u2013, 2018, \u201cLearning From Others:\nConditioning Versus Averaging\u201d, <em>Theory and Decision</em>,\n85(1): 5\u201320.", "Buchak, Lara, 2013, <em>Risk and Rationality</em>, Oxford\nUniversity Press.", "\u2013\u2013\u2013, 2014, \u201cRisk and Tradeoffs\u201d,\n<em>Erkenntnis</em>, 79(6): 1091\u20131117.", "Carnap, Rudolph, 1950, <em>Logical Foundations of\nProbability</em>, Chicago: University of Chicago Press.", "Carr, Jennifer, 2013, \u201cJustifying Bayesianism\u201d, PhD\nthesis, Massachusetts Institute of Technology.", "\u2013\u2013\u2013, 2017, \u201cEpistemic Utility Theory and\nthe Aim of Belief\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 95(3): 511\u201334.", "Carter, Brandon, 1974, \u201cLarge Number Coincidences and the\nAnthropic Principle in Cosmology\u201d, in <em>Confrontation of\nCosmological Theories with Observational Data</em>, edited by Malcolm\nS. Longair, 291\u201398, Boston: D. Reidel.", "Castell, Paul, 1998, \u201cA Consistent Restriction of the\nPrinciple of Indifference\u201d, <em>British Journal for the\nPhilosophy of Science</em>, 49(3): 387\u201395.", "Christensen, David, 1992, \u201cConfirmational Holism and\nBayesian Epistemology\u201d, <em>Philosophy of Science</em>, 59(4):\n540\u2013557.", "\u2013\u2013\u2013, 1996, \u201cDutch Book Arguments\nDepragmatized: Epistemic Consistency for Partial Believers\u201d,\n<em>The Journal of Philosophy</em>, 93(9): 450\u201379.", "\u2013\u2013\u2013, 2001, \u201cPreference-Based Arguments for\nProbabilism\u201d, <em>Philosophy of Science</em>,\n68(3):356\u2013376.", "\u2013\u2013\u2013, 2004, <em>Putting Logic in Its Place</em>,\nOxford University Press.", "Cohen, Stewart, 2002, \u201cBasic Knowledge and the Problem of\nEasy Knowledge\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 65(2): 309\u201329.", "Collins, Robin, 2009, \u201cThe Teleological Argument: An\nExploration of the Fine-Tuning of the Universe\u201d, in <em>The\nBlackwell Companion to Natural Theology</em>, edited by William Lane\nCraig and J.P. Moreland, 202\u201381. Wiley-Blackwell.", "Colyvan, Mark, Jay L. Garfield, and Graham Priest, 2005,\n\u201cProblems with the Argument from Fine Tuning\u201d,\n<em>Synthese</em>, 145(3): 325\u201338.", "Cresto, Eleonora, 2012, \u201cA Defense of Temperate Epistemic\nTransparency\u201d, <em>Journal of Philosophical Logic</em>, 41(6):\n923\u201355.", "Crupi, Vincenzo, and Katya Tentori, 2010, \u201cIrrelevant\nConjunction: Statement and Solution of a New Paradox\u201d,\n<em>Philosophy of Science</em>, 77(1): 1\u201313.", "Douven, Igor, and Richard Dietz, 2011, \u201cA Puzzle About\nStalnaker\u2019s Hypothesis\u201d, <em>Topoi</em>, 30(1):\n31\u201337.", "Douven, Igor, and Wouter Meijs, 2006, \u201cBootstrap\nConfirmation Made Quantitative\u201d, <em>Synthese</em>, 149(1):\n97\u2013132.", "\u2013\u2013\u2013, 2007, \u201cMeasuring Coherence\u201d,\n<em>Synthese</em>, 156(3): 405\u201325.", "Douven, Igor and Sylvia Wenmackers, 2017, \u201cInference to the\nBest Explanation versus Bayes\u2019s Rule in a Social Setting\u201d,\n<em>British Journal for the Philosophy of science</em>, 68(2):\n535\u2013570.", "Easwaran, Kenny, Luke Fenton-Glynn, Christopher Hitchcock, and\nJoel D. Velasco, 2016, \u201cUpdating on the Credences of Others:\nDisagreement, Agreement, and Synergy\u201d, <em>Philosophers\u2019\nImprint</em>, 16(11): 1\u201339.", "Edgington, Dorothy, 1995, \u201cOn Conditionals\u201d,\n<em>Mind</em>, 104: 235\u2013329.", "\u2013\u2013\u2013, 2000, \u201cGeneral Conditional\nStatements: A Reply to K\u00f6lbel\u201d, <em>Mind</em>, 109:\n109\u201316.", "Etlin, David, 2009, \u201cThe Problem of Noncounterfactual\nConditionals\u201d, <em>Philosophy of Science</em>, 76(5):\n676\u201388.", "Field, Hartry, 1978, \u201cA Note on Jeffrey\nConditionalization\u201d, <em>Philosophy of Science</em>, 45(3):\n361\u2013367.", "Fisher, Ronald A., 1925, <em>Statistical Methods for Research\nWorkers</em>, Edinburgh: Oliver; Boyd.", "Fitch, Frederic B., 1963, \u201cA Logical Analysis of Some Value\nConcepts\u201d, <em>The Journal of Symbolic Logic</em>, 28(2):\n135\u201342.", "Fitelson, Branden, 2003, \u201cA Probabilistic Theory of\nCoherence\u201d, <em>Analysis</em>, 63(3): 194\u201399.", "\u2013\u2013\u2013, 2006, \u201cThe Paradox of\nConfirmation\u201d, <em>Philosophy Compass</em>, 1(1): 95.", "Fitelson, Branden, and James Hawthorne, 2010, \u201cHow Bayesian\nConfirmation Theory Handles the Paradox of the Ravens\u201d, in\n<em>The Place of Probability in Science</em>, 284:247\u201375, New\nYork: Springer.", "G\u00e4rdenfors, Peter, 1986, \u201cBelief Revisions and the\nRamsey Test for Conditionals\u201d, <em>The Philosophical\nReview</em>, 95(1): 81\u201393.", "Genest, Christian and James V. Zidek, 1986, \u201cCombining\nProbability Distributions: A Critique and an Annotated\nBibliography\u201d, <em>Statistical Science</em>, 1(1):\n114\u2013135.", "Gibbard, Allan, and William Harper, 1978, \u201cCounterfactuals\nand Two Kinds of Expected Utility\u201d, in <em>Foundations and\nApplications of Decision Theory</em>, edited by A. Hooker, J.J. Leach,\nand E.F. McClennen, Dordrecht: D. Reidel.", "Gigerenzer, Gerd, Peter M. Todd, and The ABC Research Group, 1999,\n<em>Simple Heuristics That Make Us Smart</em>, Oxford University\nPress.", "Glass, David H., 2002, \u201cCoherence, Explanation, and Bayesian\nNetworks\u201d, <em>Artificial Intelligence and Cognitive\nScience</em>, 2464: 177\u201382.", "Glymour, Clark, 1980, <em>Theory and Evidence</em>, Princeton\nUniversity Press.", "Good, I.J., 1967, \u201cThe White Shoe Is a Red Herring\u201d,\n<em>British Journal for the Philosophy of Science</em>, 17(4):\n322.", "Goodman, Nelson, 1954, <em>Fact, Fiction, and Forecast</em>,\nCambridge, MA: Harvard University Press.", "Greaves, Hilary, and David Wallace, 2006, \u201cJustifying\nConditionalization: Conditionalization Maximizes Expected Epistemic\nUtility\u201d, <em>Mind</em>, 115: 607\u201332.", "Greco, Daniel, 2014, \u201cCould KK Be OK?\u201d <em>The Journal\nof Philosophy</em>, 111(4): 169\u2013197.", "Grice, Paul, 1989, <em>Studies in the Ways of Words</em>,\nCambridge, MA: Harvard University Press.", "Haack, Susan, 1976, \u201cThe Justification of Deduction\u201d,\n<em>Mind</em>, 85(337): 112\u201319.", "\u2013\u2013\u2013, 1993, <em>Evidence and Inquiry: Towards\nReconstruction in Epistemology</em>, Oxford: Blackwell\nPublishers.", "Hacking, Ian, 1987, \u201cThe Inverse Gambler\u2019s Fallacy:\nThe Argument from Design. the Anthropic Principle Applied to Wheeler\nUniverses\u201d, <em>Mind</em>, 96(383): 331\u201340.", "Harman, Gilbert, 1986, <em>Change in View: Principles of\nReasoning</em>, Cambridge, MA: MIT Press.", "Hawthorne, John, 2005, \u201cKnowledge and Evidence\u201d,\n<em>Philosophy and Phenomenological Research</em>, 70(2):\n452\u201358.", "H\u00e1jek, Alan, 1989, \u201cProbabilities of Conditionals:\nRevisited\u201d, <em>Journal of Philosophical Logic</em>, 18(4):\n423\u201328.", "Hempel, Carl G., 1937, \u201cLe Probl\u00e8me de La\nV\u00e9rit\u00e9\u201d, <em>Theoria</em>, 3(2):\n206\u201344.", "\u2013\u2013\u2013, 1945, \u201cStudies in the Logic of\nConfirmation I\u201d, <em>Mind</em>, 54: 1\u201326.", "Hintikka, Jaakko, 1962, <em>Knowledge and Belief: An Introduction\nto the Logic of the Two Notions</em>, Ithaca, NY: Cornell University\nPress.", "Horty, John F., 2012, <em>Reasons as Defaults</em>, Oxford\nUniversity Press.", "Hosiasson-Lindenbaum, Janina, 1940, \u201cOn Confirmation\u201d,\n<em>The Journal of Symbolic Logic</em>, 5(4): 133\u201348.", "Howson, Colin, and Peter Urbach, 1993, <em>Scientific Reasoning:\nThe Bayesian Approach</em>, Chicago: Open Court.", "Huemer, Michael, 1997, \u201cProbability and Coherence\nJustification\u201d, <em>The Southern Journal of Philosophy</em>,\n35(4): 463\u201372.", "\u2013\u2013\u2013, 2011, \u201cDoes Probability Theory Refute\nCoherentism?\u201d <em>The Journal of Philosophy</em>, 108(1):\n35\u201354.", "Jackson, Frank, 1987, <em>Conditionals</em>, Oxford: Clarendon\nPress.", "Jeffrey, Richard C., 1965, <em>The Logic of Decision</em>,\nChicago: University of Chicago Press.", "Joyce, James, 1998, \u201cA Nonpragmatic Vindication of\nProbabilism\u201d, <em>Philosophy of Science</em>, 65(4):\n575\u2013603.", "\u2013\u2013\u2013, 1999, <em>The Foundations of Causal\nDecision Theory</em>, Cambridge University Press.", "\u2013\u2013\u2013, 2009, \u201cAccuracy and Coherence:\nProspects for an Alethic Epistemology of Partial Belief\u201d, in\n<em>Degrees of Belief</em>, edited by Franz Huber and Christoph\nSchmidt-Petri, 342:263\u201397. Synthese Library, Dordrecht:\nSpringer.", "Kahneman, Daniel, and Amos Tversky, 1979, \u201cProspect Theory:\nAn Analysis of Decision Under Risk\u201d, <em>Econometrica</em>,\n47(2): 263\u2013292.", "Keynes, John Maynard, 1921, <em>A Treatise on Probability</em>,\nNew York: MacMillan.", "Klein, Peter, and Ted A. Warfield, 1994, \u201cWhat Price\nCoherence?\u201d <em>Analysis</em>, 54(3): 129\u201332.", "Leitgeb, Hannes, and Richard Pettigrew, 2010a, \u201cAn Objective\nJustification of Bayesianism I: Measuring Inaccuracy\u201d,\n<em>Philosophy of Science</em>, 77(2): 201\u201335.", "\u2013\u2013\u2013, 2010b, \u201cAn Objective Justification of\nBayesianism II: The Consequences of Minimizing Inaccuracy\u201d,\n<em>Philosophy of Science</em>, 77(2): 236\u2013272.", "Leslie, John, 1989, <em>Universes</em>, London: Routledge.", "Lewis, David, 1976, \u201cProbabilities of Conditionals and\nConditional Probabilities\u201d, <em>The Philosophical Review</em>,\nLXXXV(3): 297\u2013315.", "\u2013\u2013\u2013, 1981, \u201cCausal Decision Theory\u201d,\n<em>Australasian Journal of Philosophy</em>, 59(1): 5\u201330.", "\u2013\u2013\u2013, 1999, \u201cWhy Conditionalize?\u201d in\n<em>Papers in Metaphysics and Epistemology</em>, 403\u20137,\nCambridge University Press.", "List, Christian and Philip Pettit, 2002, \u201cAggregating Sets\nof Judgments: An Impossibility Result\u201d, <em>Economics and\nPhilosophy</em>, 18(1): 89\u2013110.", "Maher, Patrick, 1996, \u201cSubjective and Objective\nConfirmation\u201d, <em>Philosophy of Science</em>, 63(2):\n149\u2013174.", "Mahtani, Anna, 2008, \u201cWilliamson on Inexact\nKnowledge\u201d, <em>Philosophical Studies</em>, 139(2):\n171\u201380.", "Mayo, Deborah G., 1996, <em>Error and the Growth of Experimental\nKnowledge</em>, Chicago: University of Chicago Press.", "Mayo, Deborah G., and Aris Spanos, 2011, \u201cError\nStatistics\u201d, in <em>Philosophy of Statistics</em>, edited by\nPrasanta S. Bandyopadhyay and Malcolm R. Forster, Vol. 7. Handbook of\nPhilosophy of Science, Elsevier.", "Mayo-Wilson, Conor, Kevin J.S. Zollman, and David Danks, 2011,\n\u201cThe Independence Thesis: When Individual and Social\nEpistemology Diverge\u201d, <em>Philosophy of Science</em>, 78(4):\n653\u201377.", "McGrew, Timothy, Lydia McGrew, and Eric Vestrup, 2001,\n\u201cProbabilities and the Fine-Tuning Argument: A Skeptical\nView\u201d, <em>Mind</em>, 110(440): 1027\u201337.", "McMullin, Ernan, 1993, \u201cIndifference Principle and Anthropic\nPrinciple in Cosmology\u201d, <em>Studies in the History and\nPhilosophy of Science</em>, 24: 359\u201389.", "Merricks, Trenton, 1995, \u201cOn Behalf of the\nCoherentist\u201d, <em>Analysis</em>, 55(4): 306\u20139.", "Monton, Bradley, 2006, \u201cGod, Fine-Tuning, and the Problem of\nOld Evidence\u201d, <em>British Journal for the Philosophy of\nScience</em>, 57(2): 405\u201324.", "Neyman, Jerzy, and Karl Pearson, 1928a, \u201cOn the Use and\nInterpretation of Certain Test Criteria for Purposes of Statistical\nInference, Part I\u201d, <em>Biometrika</em>, 20A(1/2):\n175\u2013240.", "\u2013\u2013\u2013, 1928b, \u201cOn the Use and Interpretation\nof Certain Test Criteria for Purposes of Statistical Inference, Part\nI\u201d, <em>Biometrika</em>, 20A(3/4): 263\u201394.", "Nicod, Jean, 1930, <em>Foundations of Geometry and Induction</em>,\nNew York: Harcourt, Brace, &amp; Co.", "Nozick, Robert, 1981, <em>Philosophical Explanations</em>,\nCambridge, MA: Harvard University Press.", "O\u2019Connor, Cailin, and James Owen Weatherall, 2018,\n\u201cScientific Polarization\u201d, <em>European Journal for\nPhilosophy of Science</em>, 8(3): 855\u2013875.", "Olsson, Erik J., 2002, \u201cWhat Is the Problem of Coherence and\nTruth?\u201d <em>The Journal of Philosophy</em>, 99(5):\n246\u201372.", "\u2013\u2013\u2013, 2005, <em>Against Coherence: Truth,\nProbability, and Justification</em>, Oxford University Press.", "Payne, John W., James R. Bettman, and Eric J. Johnson, 1993,\n<em>The Adaptive Decision Maker</em>, Cambridge University Press.", "Pettigrew, Richard, 2016, \u201cAccuracy, Risk, and the Principle\nof Indifference\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 92(1): 35\u201359.", "Pollock, John L., 1995, <em>Cognitive Carpentry</em>,\n<em>Philosophy of Science</em>, Cambridge: MIT Press.", "\u2013\u2013\u2013, 2008, \u201cDefeasible Reasoning\u201d,\nin <em>Reasoning: Studies of Human Inference and Its Foundations</em>,\nedited by Jonathan E. Adler and Lance J. Rips, Cambridge University\nPress.", "Pryor, James, 2013, \u201cProblems for Credulism\u201d, in\n<em>Seemings and Justification: New Essays on Dogmatism and Phenomenal\nConservatism</em>, edited by Chris Tucker, Oxford University\nPress.", "Ramachandran, Murali, 2009, \u201cAnti-Luminosity: Four\nUnsuccessful Strategies\u201d, <em>Australasian Journal of\nPhilosophy</em>, 87(4): 659\u2013673.", "Ramsey, Frank Plumpton, 1964 [1926], \u201cTruth and\nProbability\u201d, in <em>Studies in Subjective Probability</em>,\nedited by Henry E. Kyburg and Howard E. Smokler, 61\u201392, New\nYork: Wiley.", "\u2013\u2013\u2013, 1990 [1929], \u201cGeneral Propositions\nand Causality\u201d, in <em>Philosophical Papers</em>, 145\u201363,\nCambridge: Cambridge University Press.", "Rees, Martin, 1999, <em>Just Six Numbers</em>, Basic Books.", "Rinard, Susanna, 2014, \u201cA New Bayesian Solution to the\nParadox of the Ravens\u201d, <em>Philosophy of Science</em>, 81(1):\n81\u2013100.", "Rosenstock, Sarita, Justin Bruner, and Cailin O\u2019Connor,\n2017, \u201cIn Epistemic Networks, Is Less Really More?\u201d,\n<em>Philosophy of Science</em>, 84(2): 234\u2013252.", "Roush, Sherrilyn, 2005, <em>Tracking Truth: Knowledge, Evidence,\nand Science</em>, Oxford University Press.", "\u2013\u2013\u2013, 2009, \u201cPr\u00e8cis of <em>Tracking\nTruth</em>\u201d, <em>Philosophy and Phenomenological Research</em>,\n79(1): 213\u201322.", "Royall, Richard, 1997, <em>Statistical Evidence: A Likelihood\nParadigm</em>, London: Chapman &amp; Hall.", "Russell, Gillian, and Greg Restall, 2010, \u201cBarriers to\nImplication\u201d, in <em>Hume on Is and Ought</em>, edited by\nCharles Pigden, Palgrave MacMillan.", "Russell, Jeffrey Sanford, John Hawthorne, and Lara Buchak, 2015,\n\u201cGroupthink\u201d, <em>Philosophical studies</em>, 172(5):\n1287\u20131309.", "Salerno, Joe, 2009, \u201cKnowability Noir\u201d, in <em>New\nEssays on the Knowability Paradox</em>, edited by Joe Salerno, Oxford:\nOxford University Press.", "Savage, Leonard J., 1954, <em>The Foundations of Statistics</em>,\nNew York: Wiley Publications in Statistics.", "Sellars, Wilfrid, 1956, \u201cEmpiricism and the Philosophy of\nMind\u201d, in <em>Minnesota Studies in the Philosophy of Science,\nVolume I: The Foundations of Science and the Concepts of Psychology\nand Psychoanalysis</em>, edited by Herbert Feigl and Michael Scriven,\nUniversity of Minnesota Press.", "Shafer, Glenn, 1976, <em>A Mathematical Theory of Evidence</em>,\nPrinceton University Press.", "Shogenji, Tomoji, 1999, \u201cIs Coherence Truth\nConducive?\u201d <em>Analysis</em>, 59(4): 338\u201345.", "Skyrms, Brian, 1980, \u201cThe Role of Causal Factors in Rational\nDecision\u201d, in <em>Causal Necessity</em>, Brian Skyrms, pp.\n128\u2013139, New Haven: Yale University Press.", "Sober, Elliott, 2005, \u201cThe Design Argument\u201d, in\n<em>The Blackwell Guide to the Philosophy of Religion</em>, edited by\nWilliam E. Mann, 117\u201347, Blackwell Publishing.", "\u2013\u2013\u2013, 2009, \u201cAbsence of Evidence and\nEvidence of Absence\u201d, <em>Philosophical Studies</em>, 143(1):\n63\u201390.", "Spohn, Wolfgang, 1988, \u201cOrdinal Conditional Functions: A\nDynamic Theory of Epistemic States\u201d, in <em>Causation in\nDecision, Belief Change, and Statistics II</em>, edited by William\nLeonard Harper and Brian Skyrms, Kluwer.", "\u2013\u2013\u2013, 2012, <em>The Laws of Belief: Ranking\nTheory and Its Philosophical Applications</em>, Oxford University\nPress.", "Stalnaker, Robert, 1970, \u201cProbability and\nConditionals\u201d, <em>Philosophy of Science</em>, 37(1):\n64\u201380.", "Steele, Katie, 2007, \u201cDistinguishing Indeterminate Belief\nfrom \u2018Risk-Averse\u2019 Preferences\u201d, <em>Synthese</em>,\n158(2): 189\u2013205.", "Stroud, Barry, 1984, <em>The Philosophical Significance of\nSkepticism</em>, Oxford University Press.", "Teller, Paul, 1973, \u201cConditionalisation and\nObservation\u201d, <em>Synthese</em>, 26: 218\u201358.", "Turri, John, and Peter D. Klein (eds), 2014, <em>Ad Infinitum: New\nEssays on Epistemological Infinitism</em>, Oxford: Oxford University\nPress.", "<span>van Fraassen</span>, Bas, 1989, <em>Laws and Symmetry</em>,\nOxford University Press.", "Vineberg, Susan, 1997, \u201cDutch Books, Dutch Strategies, and\nWhat They Show About Rationality\u201d, <em>Philosophical\nStudies</em>, 86(2): 185\u2013201.", "\u2013\u2013\u2013, 2001, \u201cThe Notion of Consistency for\nPartial Belief\u201d, <em>Philosophical Studies</em>, 102(3):\n281\u201396.", "<span>von Neumann</span>, John, and Oskar Morgenstern, 1944,\n<em>Theory of Games and Economic Behavior</em>, Princeton University\nPress.", "Vranas, Peter B.M., 2004, \u201cHempel\u2019s Raven Paradox: A\nLacuna in the Standard Bayesian Account\u201d, <em>British Journal\nfor the Philosophy of Science</em>, 55: 545\u201360.", "Weatherall, James Owen, and Cailin O\u2019Connor, forthcoming,\n\u201cEndogenous Epistemic Factionalization\u201d,\n<em>Synthese</em>, first online 04 June 2020. \ndoi:10.1007/s11229-020-02675-3", "Weintraub, Ruth, 1995, \u201cWhat Was Hume\u2019s Contribution\nto the Problem of Induction\u201d, <em>The Philosophical\nQuarterly</em>, 45(181): 460\u201370.", "Weirich, Paul, 2004, <em>Realistic Decision Theory: Rules for\nNonideal Agents in Nonideal Circumstances</em>, New York: Oxford\nUniversity Press.", "Wheeler, John Archibald, 1973, \u201cFrom Relativity to\nMutability\u201d, in <em>The Physicist\u2019s Conception of\nNature</em>, edited by Jagdesh Mehra. Springer.", "White, Roger, 2000, \u201cFine-Tuning and Multiple\nUniverses\u201d, <em>No\u00fbs</em>, 34(2): 260\u201376.", "\u2013\u2013\u2013, 2006, \u201cProblems for Dogmatism\u201d,\n<em>Philosophical Studies</em>, 131(3): 525\u201357.", "\u2013\u2013\u2013, 2009, \u201cEvidential Symmetry and Mushy\nCredence\u201d, in <em>Oxford Studies in Epistemology</em>, Oxford\nUniversity Press.", "Williams, P.M., 1980, \u201cBayesian Conditionalisation and the\nPrinciple of Minimum Information\u201d, <em>British Journal for the\nPhilosophy of Science</em>, 32(2): 131\u201344.", "Williamson, Jon, 2007, \u201cInductive Influence\u201d,\n<em>British Journal for the Philosophy of Science</em>, 58(4):\n689\u2013708.", "Williamson, Timothy, 2000, <em>Knowledge and Its Limits</em>,\nOxford University Press.", "Zollman, Kevin J. S., 2007, \u201cThe Communication Structure of\nEpistemic Communities\u201d, <em>Philosophy of Science</em>, 74(5):\n574\u2013587.", "\u2013\u2013\u2013, 2013, \u201cNetwork Epistemology:\nCommunication in Epistemic Communities\u201d, <em>Philosophy\nCompass</em>, 8(1): 15\u201327."]}, "raw_text": "<div id=\"bibliography\">\n<h2><a id=\"Bib\">Bibliography</a></h2>\n<ul class=\"hanging\">\n<li>Akiba, Ken, 2000, \u201cShogenji\u2019s Probabilistic Measure of\nCoherence Is Incoherent\u201d, <em>Analysis</em>, 60(4):\n356\u201359.</li>\n<li>Alchourr\u00f3n, Carlos E., Peter G\u00e4rdenfors, and David\nMakinson, 1985, \u201cOn the Logic of Theory Change: Partial Meet\nContraction and Revision Functions\u201d, <em>The Journal of Symbolic\nLogic</em>, 50(2): 510\u201330.</li>\n<li>Bertrand, Joseph L.F., 2007 [1888], <em>Calcul Des\nProbabilit\u00e9s</em>, Oxford University Press.</li>\n<li>Bonjour, Laurence, 1985, <em>The Structure of Empirical\nKnowledge</em>, Harvard University Press.</li>\n<li>Bovens, Luc and Stephan Hartmann, 2003, <em>Bayesian\nEpistemology</em>, Oxford University Press.</li>\n<li>Bradley, Richard, 2000, \u201cA Preservation Condition for\nConditionals\u201d, <em>Analysis</em>, 60(3): 219\u201322.</li>\n<li>\u2013\u2013\u2013, 2018, \u201cLearning From Others:\nConditioning Versus Averaging\u201d, <em>Theory and Decision</em>,\n85(1): 5\u201320.</li>\n<li>Buchak, Lara, 2013, <em>Risk and Rationality</em>, Oxford\nUniversity Press.</li>\n<li>\u2013\u2013\u2013, 2014, \u201cRisk and Tradeoffs\u201d,\n<em>Erkenntnis</em>, 79(6): 1091\u20131117.</li>\n<li>Carnap, Rudolph, 1950, <em>Logical Foundations of\nProbability</em>, Chicago: University of Chicago Press.</li>\n<li>Carr, Jennifer, 2013, \u201cJustifying Bayesianism\u201d, PhD\nthesis, Massachusetts Institute of Technology.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cEpistemic Utility Theory and\nthe Aim of Belief\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 95(3): 511\u201334.</li>\n<li>Carter, Brandon, 1974, \u201cLarge Number Coincidences and the\nAnthropic Principle in Cosmology\u201d, in <em>Confrontation of\nCosmological Theories with Observational Data</em>, edited by Malcolm\nS. Longair, 291\u201398, Boston: D. Reidel.</li>\n<li>Castell, Paul, 1998, \u201cA Consistent Restriction of the\nPrinciple of Indifference\u201d, <em>British Journal for the\nPhilosophy of Science</em>, 49(3): 387\u201395.</li>\n<li>Christensen, David, 1992, \u201cConfirmational Holism and\nBayesian Epistemology\u201d, <em>Philosophy of Science</em>, 59(4):\n540\u2013557.</li>\n<li>\u2013\u2013\u2013, 1996, \u201cDutch Book Arguments\nDepragmatized: Epistemic Consistency for Partial Believers\u201d,\n<em>The Journal of Philosophy</em>, 93(9): 450\u201379.</li>\n<li>\u2013\u2013\u2013, 2001, \u201cPreference-Based Arguments for\nProbabilism\u201d, <em>Philosophy of Science</em>,\n68(3):356\u2013376.</li>\n<li>\u2013\u2013\u2013, 2004, <em>Putting Logic in Its Place</em>,\nOxford University Press.</li>\n<li>Cohen, Stewart, 2002, \u201cBasic Knowledge and the Problem of\nEasy Knowledge\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 65(2): 309\u201329.</li>\n<li>Collins, Robin, 2009, \u201cThe Teleological Argument: An\nExploration of the Fine-Tuning of the Universe\u201d, in <em>The\nBlackwell Companion to Natural Theology</em>, edited by William Lane\nCraig and J.P. Moreland, 202\u201381. Wiley-Blackwell.</li>\n<li>Colyvan, Mark, Jay L. Garfield, and Graham Priest, 2005,\n\u201cProblems with the Argument from Fine Tuning\u201d,\n<em>Synthese</em>, 145(3): 325\u201338.</li>\n<li>Cresto, Eleonora, 2012, \u201cA Defense of Temperate Epistemic\nTransparency\u201d, <em>Journal of Philosophical Logic</em>, 41(6):\n923\u201355.</li>\n<li>Crupi, Vincenzo, and Katya Tentori, 2010, \u201cIrrelevant\nConjunction: Statement and Solution of a New Paradox\u201d,\n<em>Philosophy of Science</em>, 77(1): 1\u201313.</li>\n<li>Douven, Igor, and Richard Dietz, 2011, \u201cA Puzzle About\nStalnaker\u2019s Hypothesis\u201d, <em>Topoi</em>, 30(1):\n31\u201337.</li>\n<li>Douven, Igor, and Wouter Meijs, 2006, \u201cBootstrap\nConfirmation Made Quantitative\u201d, <em>Synthese</em>, 149(1):\n97\u2013132.</li>\n<li>\u2013\u2013\u2013, 2007, \u201cMeasuring Coherence\u201d,\n<em>Synthese</em>, 156(3): 405\u201325.</li>\n<li>Douven, Igor and Sylvia Wenmackers, 2017, \u201cInference to the\nBest Explanation versus Bayes\u2019s Rule in a Social Setting\u201d,\n<em>British Journal for the Philosophy of science</em>, 68(2):\n535\u2013570.</li>\n<li>Easwaran, Kenny, Luke Fenton-Glynn, Christopher Hitchcock, and\nJoel D. Velasco, 2016, \u201cUpdating on the Credences of Others:\nDisagreement, Agreement, and Synergy\u201d, <em>Philosophers\u2019\nImprint</em>, 16(11): 1\u201339.</li>\n<li>Edgington, Dorothy, 1995, \u201cOn Conditionals\u201d,\n<em>Mind</em>, 104: 235\u2013329.</li>\n<li>\u2013\u2013\u2013, 2000, \u201cGeneral Conditional\nStatements: A Reply to K\u00f6lbel\u201d, <em>Mind</em>, 109:\n109\u201316.</li>\n<li>Etlin, David, 2009, \u201cThe Problem of Noncounterfactual\nConditionals\u201d, <em>Philosophy of Science</em>, 76(5):\n676\u201388.</li>\n<li>Field, Hartry, 1978, \u201cA Note on Jeffrey\nConditionalization\u201d, <em>Philosophy of Science</em>, 45(3):\n361\u2013367.</li>\n<li>Fisher, Ronald A., 1925, <em>Statistical Methods for Research\nWorkers</em>, Edinburgh: Oliver; Boyd.</li>\n<li>Fitch, Frederic B., 1963, \u201cA Logical Analysis of Some Value\nConcepts\u201d, <em>The Journal of Symbolic Logic</em>, 28(2):\n135\u201342.</li>\n<li>Fitelson, Branden, 2003, \u201cA Probabilistic Theory of\nCoherence\u201d, <em>Analysis</em>, 63(3): 194\u201399.</li>\n<li>\u2013\u2013\u2013, 2006, \u201cThe Paradox of\nConfirmation\u201d, <em>Philosophy Compass</em>, 1(1): 95.</li>\n<li>Fitelson, Branden, and James Hawthorne, 2010, \u201cHow Bayesian\nConfirmation Theory Handles the Paradox of the Ravens\u201d, in\n<em>The Place of Probability in Science</em>, 284:247\u201375, New\nYork: Springer.</li>\n<li>G\u00e4rdenfors, Peter, 1986, \u201cBelief Revisions and the\nRamsey Test for Conditionals\u201d, <em>The Philosophical\nReview</em>, 95(1): 81\u201393.</li>\n<li>Genest, Christian and James V. Zidek, 1986, \u201cCombining\nProbability Distributions: A Critique and an Annotated\nBibliography\u201d, <em>Statistical Science</em>, 1(1):\n114\u2013135.</li>\n<li>Gibbard, Allan, and William Harper, 1978, \u201cCounterfactuals\nand Two Kinds of Expected Utility\u201d, in <em>Foundations and\nApplications of Decision Theory</em>, edited by A. Hooker, J.J. Leach,\nand E.F. McClennen, Dordrecht: D. Reidel.</li>\n<li>Gigerenzer, Gerd, Peter M. Todd, and The ABC Research Group, 1999,\n<em>Simple Heuristics That Make Us Smart</em>, Oxford University\nPress.</li>\n<li>Glass, David H., 2002, \u201cCoherence, Explanation, and Bayesian\nNetworks\u201d, <em>Artificial Intelligence and Cognitive\nScience</em>, 2464: 177\u201382.</li>\n<li>Glymour, Clark, 1980, <em>Theory and Evidence</em>, Princeton\nUniversity Press.</li>\n<li>Good, I.J., 1967, \u201cThe White Shoe Is a Red Herring\u201d,\n<em>British Journal for the Philosophy of Science</em>, 17(4):\n322.</li>\n<li>Goodman, Nelson, 1954, <em>Fact, Fiction, and Forecast</em>,\nCambridge, MA: Harvard University Press.</li>\n<li>Greaves, Hilary, and David Wallace, 2006, \u201cJustifying\nConditionalization: Conditionalization Maximizes Expected Epistemic\nUtility\u201d, <em>Mind</em>, 115: 607\u201332.</li>\n<li>Greco, Daniel, 2014, \u201cCould KK Be OK?\u201d <em>The Journal\nof Philosophy</em>, 111(4): 169\u2013197.</li>\n<li>Grice, Paul, 1989, <em>Studies in the Ways of Words</em>,\nCambridge, MA: Harvard University Press.</li>\n<li>Haack, Susan, 1976, \u201cThe Justification of Deduction\u201d,\n<em>Mind</em>, 85(337): 112\u201319.</li>\n<li>\u2013\u2013\u2013, 1993, <em>Evidence and Inquiry: Towards\nReconstruction in Epistemology</em>, Oxford: Blackwell\nPublishers.</li>\n<li>Hacking, Ian, 1987, \u201cThe Inverse Gambler\u2019s Fallacy:\nThe Argument from Design. the Anthropic Principle Applied to Wheeler\nUniverses\u201d, <em>Mind</em>, 96(383): 331\u201340.</li>\n<li>Harman, Gilbert, 1986, <em>Change in View: Principles of\nReasoning</em>, Cambridge, MA: MIT Press.</li>\n<li>Hawthorne, John, 2005, \u201cKnowledge and Evidence\u201d,\n<em>Philosophy and Phenomenological Research</em>, 70(2):\n452\u201358.</li>\n<li>H\u00e1jek, Alan, 1989, \u201cProbabilities of Conditionals:\nRevisited\u201d, <em>Journal of Philosophical Logic</em>, 18(4):\n423\u201328.</li>\n<li>Hempel, Carl G., 1937, \u201cLe Probl\u00e8me de La\nV\u00e9rit\u00e9\u201d, <em>Theoria</em>, 3(2):\n206\u201344.</li>\n<li>\u2013\u2013\u2013, 1945, \u201cStudies in the Logic of\nConfirmation I\u201d, <em>Mind</em>, 54: 1\u201326.</li>\n<li>Hintikka, Jaakko, 1962, <em>Knowledge and Belief: An Introduction\nto the Logic of the Two Notions</em>, Ithaca, NY: Cornell University\nPress.</li>\n<li>Horty, John F., 2012, <em>Reasons as Defaults</em>, Oxford\nUniversity Press.</li>\n<li>Hosiasson-Lindenbaum, Janina, 1940, \u201cOn Confirmation\u201d,\n<em>The Journal of Symbolic Logic</em>, 5(4): 133\u201348.</li>\n<li>Howson, Colin, and Peter Urbach, 1993, <em>Scientific Reasoning:\nThe Bayesian Approach</em>, Chicago: Open Court.</li>\n<li>Huemer, Michael, 1997, \u201cProbability and Coherence\nJustification\u201d, <em>The Southern Journal of Philosophy</em>,\n35(4): 463\u201372.</li>\n<li>\u2013\u2013\u2013, 2011, \u201cDoes Probability Theory Refute\nCoherentism?\u201d <em>The Journal of Philosophy</em>, 108(1):\n35\u201354.</li>\n<li>Jackson, Frank, 1987, <em>Conditionals</em>, Oxford: Clarendon\nPress.</li>\n<li>Jeffrey, Richard C., 1965, <em>The Logic of Decision</em>,\nChicago: University of Chicago Press.</li>\n<li>Joyce, James, 1998, \u201cA Nonpragmatic Vindication of\nProbabilism\u201d, <em>Philosophy of Science</em>, 65(4):\n575\u2013603.</li>\n<li>\u2013\u2013\u2013, 1999, <em>The Foundations of Causal\nDecision Theory</em>, Cambridge University Press.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cAccuracy and Coherence:\nProspects for an Alethic Epistemology of Partial Belief\u201d, in\n<em>Degrees of Belief</em>, edited by Franz Huber and Christoph\nSchmidt-Petri, 342:263\u201397. Synthese Library, Dordrecht:\nSpringer.</li>\n<li>Kahneman, Daniel, and Amos Tversky, 1979, \u201cProspect Theory:\nAn Analysis of Decision Under Risk\u201d, <em>Econometrica</em>,\n47(2): 263\u2013292.</li>\n<li>Keynes, John Maynard, 1921, <em>A Treatise on Probability</em>,\nNew York: MacMillan.</li>\n<li>Klein, Peter, and Ted A. Warfield, 1994, \u201cWhat Price\nCoherence?\u201d <em>Analysis</em>, 54(3): 129\u201332.</li>\n<li>Leitgeb, Hannes, and Richard Pettigrew, 2010a, \u201cAn Objective\nJustification of Bayesianism I: Measuring Inaccuracy\u201d,\n<em>Philosophy of Science</em>, 77(2): 201\u201335.</li>\n<li>\u2013\u2013\u2013, 2010b, \u201cAn Objective Justification of\nBayesianism II: The Consequences of Minimizing Inaccuracy\u201d,\n<em>Philosophy of Science</em>, 77(2): 236\u2013272.</li>\n<li>Leslie, John, 1989, <em>Universes</em>, London: Routledge.</li>\n<li>Lewis, David, 1976, \u201cProbabilities of Conditionals and\nConditional Probabilities\u201d, <em>The Philosophical Review</em>,\nLXXXV(3): 297\u2013315.</li>\n<li>\u2013\u2013\u2013, 1981, \u201cCausal Decision Theory\u201d,\n<em>Australasian Journal of Philosophy</em>, 59(1): 5\u201330.</li>\n<li>\u2013\u2013\u2013, 1999, \u201cWhy Conditionalize?\u201d in\n<em>Papers in Metaphysics and Epistemology</em>, 403\u20137,\nCambridge University Press.</li>\n<li>List, Christian and Philip Pettit, 2002, \u201cAggregating Sets\nof Judgments: An Impossibility Result\u201d, <em>Economics and\nPhilosophy</em>, 18(1): 89\u2013110.</li>\n<li>Maher, Patrick, 1996, \u201cSubjective and Objective\nConfirmation\u201d, <em>Philosophy of Science</em>, 63(2):\n149\u2013174.</li>\n<li>Mahtani, Anna, 2008, \u201cWilliamson on Inexact\nKnowledge\u201d, <em>Philosophical Studies</em>, 139(2):\n171\u201380.</li>\n<li>Mayo, Deborah G., 1996, <em>Error and the Growth of Experimental\nKnowledge</em>, Chicago: University of Chicago Press.</li>\n<li>Mayo, Deborah G., and Aris Spanos, 2011, \u201cError\nStatistics\u201d, in <em>Philosophy of Statistics</em>, edited by\nPrasanta S. Bandyopadhyay and Malcolm R. Forster, Vol. 7. Handbook of\nPhilosophy of Science, Elsevier.</li>\n<li>Mayo-Wilson, Conor, Kevin J.S. Zollman, and David Danks, 2011,\n\u201cThe Independence Thesis: When Individual and Social\nEpistemology Diverge\u201d, <em>Philosophy of Science</em>, 78(4):\n653\u201377.</li>\n<li>McGrew, Timothy, Lydia McGrew, and Eric Vestrup, 2001,\n\u201cProbabilities and the Fine-Tuning Argument: A Skeptical\nView\u201d, <em>Mind</em>, 110(440): 1027\u201337.</li>\n<li>McMullin, Ernan, 1993, \u201cIndifference Principle and Anthropic\nPrinciple in Cosmology\u201d, <em>Studies in the History and\nPhilosophy of Science</em>, 24: 359\u201389.</li>\n<li>Merricks, Trenton, 1995, \u201cOn Behalf of the\nCoherentist\u201d, <em>Analysis</em>, 55(4): 306\u20139.</li>\n<li>Monton, Bradley, 2006, \u201cGod, Fine-Tuning, and the Problem of\nOld Evidence\u201d, <em>British Journal for the Philosophy of\nScience</em>, 57(2): 405\u201324.</li>\n<li>Neyman, Jerzy, and Karl Pearson, 1928a, \u201cOn the Use and\nInterpretation of Certain Test Criteria for Purposes of Statistical\nInference, Part I\u201d, <em>Biometrika</em>, 20A(1/2):\n175\u2013240.</li>\n<li>\u2013\u2013\u2013, 1928b, \u201cOn the Use and Interpretation\nof Certain Test Criteria for Purposes of Statistical Inference, Part\nI\u201d, <em>Biometrika</em>, 20A(3/4): 263\u201394.</li>\n<li>Nicod, Jean, 1930, <em>Foundations of Geometry and Induction</em>,\nNew York: Harcourt, Brace, &amp; Co.</li>\n<li>Nozick, Robert, 1981, <em>Philosophical Explanations</em>,\nCambridge, MA: Harvard University Press.</li>\n<li>O\u2019Connor, Cailin, and James Owen Weatherall, 2018,\n\u201cScientific Polarization\u201d, <em>European Journal for\nPhilosophy of Science</em>, 8(3): 855\u2013875.</li>\n<li>Olsson, Erik J., 2002, \u201cWhat Is the Problem of Coherence and\nTruth?\u201d <em>The Journal of Philosophy</em>, 99(5):\n246\u201372.</li>\n<li>\u2013\u2013\u2013, 2005, <em>Against Coherence: Truth,\nProbability, and Justification</em>, Oxford University Press.</li>\n<li>Payne, John W., James R. Bettman, and Eric J. Johnson, 1993,\n<em>The Adaptive Decision Maker</em>, Cambridge University Press.</li>\n<li>Pettigrew, Richard, 2016, \u201cAccuracy, Risk, and the Principle\nof Indifference\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 92(1): 35\u201359.</li>\n<li>Pollock, John L., 1995, <em>Cognitive Carpentry</em>,\n<em>Philosophy of Science</em>, Cambridge: MIT Press.</li>\n<li>\u2013\u2013\u2013, 2008, \u201cDefeasible Reasoning\u201d,\nin <em>Reasoning: Studies of Human Inference and Its Foundations</em>,\nedited by Jonathan E. Adler and Lance J. Rips, Cambridge University\nPress.</li>\n<li>Pryor, James, 2013, \u201cProblems for Credulism\u201d, in\n<em>Seemings and Justification: New Essays on Dogmatism and Phenomenal\nConservatism</em>, edited by Chris Tucker, Oxford University\nPress.</li>\n<li>Ramachandran, Murali, 2009, \u201cAnti-Luminosity: Four\nUnsuccessful Strategies\u201d, <em>Australasian Journal of\nPhilosophy</em>, 87(4): 659\u2013673.</li>\n<li>Ramsey, Frank Plumpton, 1964 [1926], \u201cTruth and\nProbability\u201d, in <em>Studies in Subjective Probability</em>,\nedited by Henry E. Kyburg and Howard E. Smokler, 61\u201392, New\nYork: Wiley.</li>\n<li>\u2013\u2013\u2013, 1990 [1929], \u201cGeneral Propositions\nand Causality\u201d, in <em>Philosophical Papers</em>, 145\u201363,\nCambridge: Cambridge University Press.</li>\n<li>Rees, Martin, 1999, <em>Just Six Numbers</em>, Basic Books.</li>\n<li>Rinard, Susanna, 2014, \u201cA New Bayesian Solution to the\nParadox of the Ravens\u201d, <em>Philosophy of Science</em>, 81(1):\n81\u2013100.</li>\n<li>Rosenstock, Sarita, Justin Bruner, and Cailin O\u2019Connor,\n2017, \u201cIn Epistemic Networks, Is Less Really More?\u201d,\n<em>Philosophy of Science</em>, 84(2): 234\u2013252.</li>\n<li>Roush, Sherrilyn, 2005, <em>Tracking Truth: Knowledge, Evidence,\nand Science</em>, Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cPr\u00e8cis of <em>Tracking\nTruth</em>\u201d, <em>Philosophy and Phenomenological Research</em>,\n79(1): 213\u201322.</li>\n<li>Royall, Richard, 1997, <em>Statistical Evidence: A Likelihood\nParadigm</em>, London: Chapman &amp; Hall.</li>\n<li>Russell, Gillian, and Greg Restall, 2010, \u201cBarriers to\nImplication\u201d, in <em>Hume on Is and Ought</em>, edited by\nCharles Pigden, Palgrave MacMillan.</li>\n<li>Russell, Jeffrey Sanford, John Hawthorne, and Lara Buchak, 2015,\n\u201cGroupthink\u201d, <em>Philosophical studies</em>, 172(5):\n1287\u20131309.</li>\n<li>Salerno, Joe, 2009, \u201cKnowability Noir\u201d, in <em>New\nEssays on the Knowability Paradox</em>, edited by Joe Salerno, Oxford:\nOxford University Press.</li>\n<li>Savage, Leonard J., 1954, <em>The Foundations of Statistics</em>,\nNew York: Wiley Publications in Statistics.</li>\n<li>Sellars, Wilfrid, 1956, \u201cEmpiricism and the Philosophy of\nMind\u201d, in <em>Minnesota Studies in the Philosophy of Science,\nVolume I: The Foundations of Science and the Concepts of Psychology\nand Psychoanalysis</em>, edited by Herbert Feigl and Michael Scriven,\nUniversity of Minnesota Press.</li>\n<li>Shafer, Glenn, 1976, <em>A Mathematical Theory of Evidence</em>,\nPrinceton University Press.</li>\n<li>Shogenji, Tomoji, 1999, \u201cIs Coherence Truth\nConducive?\u201d <em>Analysis</em>, 59(4): 338\u201345.</li>\n<li>Skyrms, Brian, 1980, \u201cThe Role of Causal Factors in Rational\nDecision\u201d, in <em>Causal Necessity</em>, Brian Skyrms, pp.\n128\u2013139, New Haven: Yale University Press.</li>\n<li>Sober, Elliott, 2005, \u201cThe Design Argument\u201d, in\n<em>The Blackwell Guide to the Philosophy of Religion</em>, edited by\nWilliam E. Mann, 117\u201347, Blackwell Publishing.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cAbsence of Evidence and\nEvidence of Absence\u201d, <em>Philosophical Studies</em>, 143(1):\n63\u201390.</li>\n<li>Spohn, Wolfgang, 1988, \u201cOrdinal Conditional Functions: A\nDynamic Theory of Epistemic States\u201d, in <em>Causation in\nDecision, Belief Change, and Statistics II</em>, edited by William\nLeonard Harper and Brian Skyrms, Kluwer.</li>\n<li>\u2013\u2013\u2013, 2012, <em>The Laws of Belief: Ranking\nTheory and Its Philosophical Applications</em>, Oxford University\nPress.</li>\n<li>Stalnaker, Robert, 1970, \u201cProbability and\nConditionals\u201d, <em>Philosophy of Science</em>, 37(1):\n64\u201380.</li>\n<li>Steele, Katie, 2007, \u201cDistinguishing Indeterminate Belief\nfrom \u2018Risk-Averse\u2019 Preferences\u201d, <em>Synthese</em>,\n158(2): 189\u2013205.</li>\n<li>Stroud, Barry, 1984, <em>The Philosophical Significance of\nSkepticism</em>, Oxford University Press.</li>\n<li>Teller, Paul, 1973, \u201cConditionalisation and\nObservation\u201d, <em>Synthese</em>, 26: 218\u201358.</li>\n<li>Turri, John, and Peter D. Klein (eds), 2014, <em>Ad Infinitum: New\nEssays on Epistemological Infinitism</em>, Oxford: Oxford University\nPress.</li>\n<li><span>van Fraassen</span>, Bas, 1989, <em>Laws and Symmetry</em>,\nOxford University Press.</li>\n<li>Vineberg, Susan, 1997, \u201cDutch Books, Dutch Strategies, and\nWhat They Show About Rationality\u201d, <em>Philosophical\nStudies</em>, 86(2): 185\u2013201.</li>\n<li>\u2013\u2013\u2013, 2001, \u201cThe Notion of Consistency for\nPartial Belief\u201d, <em>Philosophical Studies</em>, 102(3):\n281\u201396.</li>\n<li><span>von Neumann</span>, John, and Oskar Morgenstern, 1944,\n<em>Theory of Games and Economic Behavior</em>, Princeton University\nPress.</li>\n<li>Vranas, Peter B.M., 2004, \u201cHempel\u2019s Raven Paradox: A\nLacuna in the Standard Bayesian Account\u201d, <em>British Journal\nfor the Philosophy of Science</em>, 55: 545\u201360.</li>\n<li>Weatherall, James Owen, and Cailin O\u2019Connor, forthcoming,\n\u201cEndogenous Epistemic Factionalization\u201d,\n<em>Synthese</em>, first online 04 June 2020. \ndoi:10.1007/s11229-020-02675-3</li>\n<li>Weintraub, Ruth, 1995, \u201cWhat Was Hume\u2019s Contribution\nto the Problem of Induction\u201d, <em>The Philosophical\nQuarterly</em>, 45(181): 460\u201370.</li>\n<li>Weirich, Paul, 2004, <em>Realistic Decision Theory: Rules for\nNonideal Agents in Nonideal Circumstances</em>, New York: Oxford\nUniversity Press.</li>\n<li>Wheeler, John Archibald, 1973, \u201cFrom Relativity to\nMutability\u201d, in <em>The Physicist\u2019s Conception of\nNature</em>, edited by Jagdesh Mehra. Springer.</li>\n<li>White, Roger, 2000, \u201cFine-Tuning and Multiple\nUniverses\u201d, <em>No\u00fbs</em>, 34(2): 260\u201376.</li>\n<li>\u2013\u2013\u2013, 2006, \u201cProblems for Dogmatism\u201d,\n<em>Philosophical Studies</em>, 131(3): 525\u201357.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cEvidential Symmetry and Mushy\nCredence\u201d, in <em>Oxford Studies in Epistemology</em>, Oxford\nUniversity Press.</li>\n<li>Williams, P.M., 1980, \u201cBayesian Conditionalisation and the\nPrinciple of Minimum Information\u201d, <em>British Journal for the\nPhilosophy of Science</em>, 32(2): 131\u201344.</li>\n<li>Williamson, Jon, 2007, \u201cInductive Influence\u201d,\n<em>British Journal for the Philosophy of Science</em>, 58(4):\n689\u2013708.</li>\n<li>Williamson, Timothy, 2000, <em>Knowledge and Its Limits</em>,\nOxford University Press.</li>\n<li>Zollman, Kevin J. S., 2007, \u201cThe Communication Structure of\nEpistemic Communities\u201d, <em>Philosophy of Science</em>, 74(5):\n574\u2013587.</li>\n<li>\u2013\u2013\u2013, 2013, \u201cNetwork Epistemology:\nCommunication in Epistemic Communities\u201d, <em>Philosophy\nCompass</em>, 8(1): 15\u201327.</li>\n</ul>\n</div>"}, "related_entries": {"entry_list": ["Bayes\u2019 Theorem", "belief, formal representations of", "conditionals", "confirmation", "decision theory: causal", "Dutch book arguments", "epistemic paradoxes", "epistemic utility arguments for epistemic norms", "epistemology", "epistemology: Bayesian", "Fitch\u2019s paradox of knowability", "game theory", "induction: problem of", "justification, epistemic: coherentist theories of", "justification, epistemic: foundationalist theories of", "learning theory, formal", "logic: and probability", "logic: conditionals", "logic: epistemic", "logic: inductive", "logic: modal", "logic: non-monotonic", "Pascal\u2019s wager", "preferences", "probabilities, imprecise", "probability, interpretations of", "rational choice, normative: expected utility", "reasoning: defeasible", "risk", "social choice theory", "statistics, philosophy of"], "entry_link": [{"../bayes-theorem/": "Bayes\u2019 Theorem"}, {"../formal-belief/": "belief, formal representations of"}, {"../conditionals/": "conditionals"}, {"../confirmation/": "confirmation"}, {"../decision-causal/": "decision theory: causal"}, {"../dutch-book/": "Dutch book arguments"}, {"../epistemic-paradoxes/": "epistemic paradoxes"}, {"../epistemic-utility/": "epistemic utility arguments for epistemic norms"}, {"../epistemology/": "epistemology"}, {"../epistemology-bayesian/": "epistemology: Bayesian"}, {"../fitch-paradox/": "Fitch\u2019s paradox of knowability"}, {"../game-theory/": "game theory"}, {"../induction-problem/": "induction: problem of"}, {"../justep-coherence/": "justification, epistemic: coherentist theories of"}, {"../justep-foundational/": "justification, epistemic: foundationalist theories of"}, {"../learning-formal/": "learning theory, formal"}, {"../logic-probability/": "logic: and probability"}, {"../logic-conditionals/": "logic: conditionals"}, {"../logic-epistemic/": "logic: epistemic"}, {"../logic-inductive/": "logic: inductive"}, {"../logic-modal/": "logic: modal"}, {"../logic-nonmonotonic/": "logic: non-monotonic"}, {"../pascal-wager/": "Pascal\u2019s wager"}, {"../preferences/": "preferences"}, {"../imprecise-probabilities/": "probabilities, imprecise"}, {"../probability-interpret/": "probability, interpretations of"}, {"../rationality-normative-utility/": "rational choice, normative: expected utility"}, {"../reasoning-defeasible/": "reasoning: defeasible"}, {"../risk/": "risk"}, {"../social-choice/": "social choice theory"}, {"../statistics/": "statistics, philosophy of"}]}, "academic_tools": {"listed_text": ["<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>", "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=formal-epistemology\" target=\"other\">How to cite this entry</a>.", "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>", "<a href=\"https://leibniz.stanford.edu/friends/preview/formal-epistemology/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.", "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>", "<a href=\"https://www.inphoproject.org/entity?sep=formal-epistemology&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).", "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>", "<a href=\"https://philpapers.org/sep/formal-epistemology/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."], "listed_links": [{"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=formal-epistemology": "How to cite this entry"}, {"https://leibniz.stanford.edu/friends/preview/formal-epistemology/": "Preview the PDF version of this entry"}, {"https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"}, {"https://www.inphoproject.org/entity?sep=formal-epistemology&redirect=True": "Look up topics and thinkers related to this entry"}, {"https://philpapers.org/sep/formal-epistemology/": "Enhanced bibliography for this entry"}, {"https://philpapers.org/": "PhilPapers"}]}, "other_internet_resources": {"listed_text": ["Dorst, Kevin, \n\u201c<a href=\"https://www.psychologytoday.com/ca/blog/reasonably-polarized/202009/why-polarization-can-be-rational\" target=\"other\">Why Polarization Can Be Rational</a>\u201d, \n posted at <em>Psychology Today</em>, 28 September 2020.", "H\u00e1jek, Alan, m.s.,\n \u201c<a href=\"http://philosophy.anu.edu.au/sites/default/files/Staying%20Regular.December%2028.2012.pdf\" target=\"other\">Staying Regular?</a>\u201d\n ", "Pettigrew, Richard, m.s.,\n \u201c<a href=\"https://drive.google.com/file/d/1l2gBJ8zjpttXrl0gdMjan7HFKGr7llRb/view\" target=\"other\">On the Pragmatic and Epistemic Virtues of Inference to the Best Explanation</a>\u201d.", "<a href=\"http://fitelson.org/few/\" target=\"other\">The Formal Epistemology Workshop</a>:\n complete schedules of talks for every year since the first workshop\nin 2004, including the papers and/or slides.", "<a href=\"http://fitelson.org/topics/syllabus.html\" target=\"other\">Recent Topics in Formal Epistemology</a>:\n syllabus and readings from Branden Fitelson\u2019s 2011 course at\nRutgers University.", "<a href=\"http://fitelson.org/probability/notes.html\" target=\"other\">Lecture notes on Probability and Induction</a>:\n from Branden Fitelson\u2019s 2008 course at UC Berkeley.", "<a href=\"http://ocw.mit.edu/courses/linguistics-and-philosophy/24-222-decisions-games-and-rational-choice-spring-2008/index.htm\" target=\"other\">Decisions, Games, and Rational Choice</a>:\n complete materials from Robert Stalnaker\u2019s 2008 course at\nMIT.", "<a href=\"http://www.iep.utm.edu/conf-ind/\" target=\"other\">\u201cConfirmation &amp; Induction\u201d</a>:\n entry in the <em>Internet Encyclopedia of Philosophy</em>, by Franz\nHuber.", "<a href=\"http://jonathanweisberg.org/publication/2011%20Varieties%20of%20Bayesianism/\" target=\"other\">\u201cVarieties of Bayesianism\u201d</a>:\n a survey of the Bayesian approach to formal epistemology by Jonathan\nWeisberg."], "listed_links": [{"https://www.psychologytoday.com/ca/blog/reasonably-polarized/202009/why-polarization-can-be-rational": "Why Polarization Can Be Rational"}, {"http://philosophy.anu.edu.au/sites/default/files/Staying%20Regular.December%2028.2012.pdf": "Staying Regular?"}, {"https://drive.google.com/file/d/1l2gBJ8zjpttXrl0gdMjan7HFKGr7llRb/view": "On the Pragmatic and Epistemic Virtues of Inference to the Best Explanation"}, {"http://fitelson.org/few/": "The Formal Epistemology Workshop"}, {"http://fitelson.org/topics/syllabus.html": "Recent Topics in Formal Epistemology"}, {"http://fitelson.org/probability/notes.html": "Lecture notes on Probability and Induction"}, {"http://ocw.mit.edu/courses/linguistics-and-philosophy/24-222-decisions-games-and-rational-choice-spring-2008/index.htm": "Decisions, Games, and Rational Choice"}, {"http://www.iep.utm.edu/conf-ind/": "\u201cConfirmation & Induction\u201d"}, {"http://jonathanweisberg.org/publication/2011%20Varieties%20of%20Bayesianism/": "\u201cVarieties of Bayesianism\u201d"}]}, "tokenized_text": ["1", "first", "case", "study", "confirming", "scientific", "theory", "scientific", "reasoning", "work", "early", "20th", "century", "large", "swath", "mathematics", "successfully", "reconstructed", "using", "firstorder", "logic", "many", "philosopher", "sought", "similar", "systematization", "reasoning", "empirical", "science", "like", "biology", "psychology", "physic", "though", "empirical", "science", "rely", "heavily", "nondeductive", "reasoning", "tool", "deductive", "logic", "still", "offer", "promising", "starting", "point", "11", "deductive", "approach", "consider", "hypothesis", "like", "electron", "negative", "charge", "firstorder", "logic", "rendered", "forall", "x", "ex", "supset", "nx", "identified", "object", "a", "electron", "hypothesis", "deductively", "entail", "prediction", "na", "a", "negative", "charge", "begin", "array", "l", "forall", "x", "ex", "supset", "nx", "ea", "hline", "na", "end", "array", "test", "prediction", "observe", "indeed", "na", "would", "seem", "support", "hypothesis", "scientific", "hypothesistesting", "thus", "appears", "work", "something", "like", "deduction", "reverse", "goodman", "1954", "swap", "hypothesis", "predicted", "datum", "deduction", "get", "example", "confirmation", "begin", "array", "l", "ea", "na", "overline", "overline", "forall", "x", "ex", "supset", "nx", "end", "array", "doubleline", "represents", "nondeductive", "inference", "inference", "weak", "case", "since", "hypothesis", "verified", "one", "instance", "a", "add", "instance", "b", "c", "etc", "becomes", "stronger", "provided", "discover", "counterinstances", "course", "observation", "suggest", "proposal", "due", "nicod", "1930", "famously", "examined", "hempel", "1945", "nicod", "criterion", "universal", "generalization", "confirmed", "positive", "instance", "long", "counterinstances", "discovered", "forall", "x", "fx", "supset", "gx", "confirmed", "fa", "wedge", "ga", "fb", "wedge", "gb", "etc", "general", "idea", "hypothesis", "confirmed", "prediction", "borne", "capture", "idea", "formally", "deductive", "logic", "equating", "prediction", "logical", "entailment", "object", "f", "hypothesis", "forall", "x", "fx", "supset", "gx", "entailspredicts", "object", "g", "discovery", "object", "f", "g", "confirms", "hypothesis", "one", "classic", "challenge", "nicod", "criterion", "notorious", "raven", "paradox", "suppose", "want", "test", "hypothesis", "raven", "black", "formalize", "forall", "x", "rx", "supset", "bx", "logically", "equivalent", "forall", "x", "neg", "bx", "supset", "neg", "rx", "contraposition", "nicod", "criterion", "say", "latter", "hypothesis", "confirmed", "discovery", "object", "black", "ravena", "red", "shirt", "example", "pair", "blue", "underpants", "hempel", "1937", "1945", "walking", "hall", "department", "noting", "nonblack", "nonravens", "hardly", "seems", "reasonable", "way", "verify", "raven", "black", "indoor", "ornithology", "goodman", "1954", "good", "science", "second", "general", "challenge", "predictionasdeduction", "approach", "posed", "statistical", "hypothesis", "suppose", "want", "test", "theory", "50", "raven", "black", "hypothesis", "entail", "nothing", "color", "individual", "raven", "might", "one", "black", "one", "might", "fact", "even", "large", "survey", "raven", "turn", "black", "contradict", "hypothesis", "always", "possible", "50", "raven", "black", "caught", "survey", "maybe", "nonblack", "raven", "exceptionally", "skilled", "evasion", "challenge", "suggests", "important", "lesson", "first", "need", "laxer", "notion", "prediction", "deductive", "entailment", "50", "hypothesis", "may", "entail", "large", "survey", "raven", "nonblack", "raven", "suggest", "prediction", "pretty", "strongly", "second", "sort", "corollary", "confirmation", "quantitative", "come", "degree", "single", "black", "raven", "much", "support", "hypothesis", "50", "raven", "black", "large", "sample", "roughly", "half", "black", "half", "white", "raven", "would", "third", "finally", "degree", "confirmation", "understood", "term", "probability", "50", "hypothesis", "make", "probable", "single", "raven", "black", "make", "highly", "probable", "much", "larger", "collection", "roughly", "half", "black", "half", "nonblack", "allblack", "hypothesis", "predicts", "sample", "raven", "entirely", "black", "100", "probability", "quantitative", "approach", "also", "promise", "help", "resolve", "raven", "paradox", "popular", "resolution", "say", "observing", "red", "shirt", "confirm", "raven", "black", "minuscule", "amount", "raven", "paradox", "thus", "illusion", "mistake", "minuscule", "amount", "confirmation", "none", "hosiassonlindenbaum", "1940", "make", "response", "convincing", "need", "proper", "quantitative", "theory", "confirmation", "explains", "red", "shirt", "could", "relevant", "hypothesis", "raven", "slightly", "relevant", "12", "probabilistic", "approach", "let", "start", "idea", "confirm", "hypothesis", "make", "probable", "piece", "evidence", "increase", "probability", "hypothesis", "confirms", "hypothesis", "need", "theory", "probability", "standard", "theory", "begin", "function", "p", "take", "proposition", "return", "number", "x", "probability", "proposition", "p", "x", "qualify", "probability", "function", "p", "must", "satisfy", "three", "axiom", "proposition", "a", "0", "leq", "p", "leq", "1", "1", "tautology", "a", "p", "1", "logically", "incompatible", "proposition", "a", "b", "p", "vee", "b", "p", "p", "b", "first", "axiom", "set", "scale", "probability", "0", "1", "think", "running", "0", "probability", "100", "probability", "2", "second", "axiom", "place", "tautology", "top", "scale", "nothing", "probable", "tautology", "3", "finally", "third", "axiom", "tell", "u", "figure", "probability", "hypothesis", "breaking", "part", "example", "probability", "american", "country", "first", "develop", "cure", "alzheimer", "figured", "adding", "probability", "north", "american", "country", "first", "probability", "south", "american", "country", "4", "conditional", "probability", "like", "probability", "well", "next", "philosophy", "class", "given", "done", "well", "previous", "one", "far", "formalized", "notion", "absolute", "probability", "p", "x", "let", "introduce", "conditional", "probability", "definition", "definition", "conditional", "probability", "b", "given", "a", "written", "p", "bmid", "defined", "p", "bmid", "frac", "p", "b", "wedge", "p", "definition", "helpful", "heuristic", "think", "probability", "b", "given", "a", "something", "like", "portion", "a", "possibilities", "also", "b", "possibilities", "example", "probability", "rolling", "high", "number", "4", "5", "6", "sixsided", "die", "given", "roll", "even", "23", "3", "even", "possibility", "2", "4", "6", "p", "36", "3", "possibility", "2", "also", "high", "number", "4", "6", "p", "b", "wedge", "26", "thus", "p", "bmid", "frac", "p", "b", "wedge", "p", "frac", "26", "36", "23", "generalizing", "idea", "start", "quantity", "a", "possibilities", "sort", "baseline", "putting", "p", "denominator", "consider", "many", "also", "b", "possibilities", "putting", "p", "b", "wedge", "numerator", "notice", "way", "p", "bmid", "undefined", "p", "0", "might", "seem", "fine", "first", "worry", "probability", "b", "a", "true", "chance", "a", "true", "fact", "deep", "problem", "lurking", "h\u00e1jek", "ms", "internet", "resource", "though", "stop", "explore", "instead", "let", "take", "advantage", "groundwork", "laid", "state", "formal", "definition", "quantitative", "confirmation", "guiding", "idea", "evidence", "confirms", "hypothesis", "extent", "increase", "probability", "comparing", "p", "hmid", "e", "p", "h", "looking", "difference", "definition", "degree", "e", "confirms", "h", "called", "degree", "confirmation", "written", "c", "h", "e", "defined", "c", "h", "e", "p", "hmid", "e", "p", "h", "c", "h", "e", "negative", "e", "actually", "decrease", "probability", "h", "say", "e", "disconfirms", "h", "c", "h", "e", "0", "say", "e", "neutral", "respect", "h", "minimal", "simple", "axiom", "definition", "enough", "derive", "many", "interesting", "claim", "probability", "confirmation", "following", "two", "subsection", "introduce", "elementary", "yet", "promising", "result", "see", "technical", "supplement", "proof", "121", "basic", "building", "block", "let", "start", "elementary", "theorem", "illustrate", "probability", "interacts", "deductive", "logic", "theorem", "chance", "contradiction", "a", "contradiction", "p", "0", "theorem", "complementarity", "contradictory", "a", "p", "1", "p", "neg", "theorem", "equality", "equivalent", "a", "b", "logically", "equivalent", "p", "p", "b", "theorem", "conditional", "certainty", "logical", "consequence", "a", "logically", "entail", "b", "p", "bmid", "1", "next", "three", "theorem", "go", "bit", "deeper", "useful", "building", "interesting", "result", "theorem", "conjunction", "cost", "probability", "a", "b", "p", "p", "wedge", "b", "unless", "p", "wedge", "neg", "b", "0", "case", "p", "p", "wedge", "b", "one", "way", "thinking", "conjunction", "cost", "probability", "say", "stronger", "statement", "greater", "risk", "falsehood", "strengthen", "a", "adding", "b", "resulting", "stronger", "statement", "le", "probable", "unless", "chance", "a", "true", "without", "b", "begin", "case", "adding", "b", "a", "change", "risk", "falsehood", "chance", "a", "true", "without", "b", "anyway", "theorem", "conjunction", "rule", "a", "b", "p", "b", "neq", "0", "p", "wedge", "b", "p", "amid", "b", "p", "b", "say", "calculate", "likely", "two", "statement", "a", "b", "true", "together", "temporarily", "taking", "b", "granted", "assessing", "probability", "a", "light", "giving", "result", "much", "weight", "b", "probability", "merit", "theorem", "law", "total", "probability", "a", "b", "whose", "probability", "neither", "0", "1", "p", "p", "amid", "b", "p", "b", "p", "amid", "neg", "b", "p", "neg", "b", "law", "total", "probability", "basically", "say", "calculate", "probability", "a", "breaking", "two", "possible", "case", "b", "neg", "b", "consider", "likely", "a", "b", "true", "likely", "b", "false", "give", "case", "appropriate", "weight", "multiplying", "probability", "hold", "adding", "together", "result", "work", "p", "amid", "b", "p", "amid", "neg", "b", "welldefined", "p", "b", "0", "1", "122", "bayes", "theorem", "classic", "theorem", "relates", "conditional", "probability", "p", "hmid", "e", "unconditional", "probability", "p", "h", "p", "hmid", "e", "p", "h", "frac", "p", "emid", "h", "p", "e", "theorem", "philosophically", "important", "see", "moment", "also", "useful", "tool", "calculating", "p", "hmid", "e", "three", "term", "right", "hand", "side", "often", "inferred", "available", "statistic", "consider", "example", "whether", "student", "university", "x", "high", "grade", "e", "say", "anything", "likelihood", "taking", "class", "philosophy", "h", "registrar", "tell", "u", "35", "student", "take", "philosophy", "class", "point", "p", "h", "35100", "also", "tell", "u", "20", "student", "campuswide", "high", "grade", "defined", "gpa", "35", "p", "e", "20100", "keep", "track", "detailed", "information", "luckily", "philosophy", "department", "tell", "u", "25", "student", "take", "class", "high", "grade", "p", "emid", "h", "25100", "everything", "need", "apply", "bayes", "theorem", "begin", "split", "p", "hmid", "e", "p", "h", "frac", "p", "emid", "h", "p", "e", "35100", "times", "frac", "25100", "20100", "716end", "split", "higher", "p", "h", "20100", "also", "see", "student", "high", "grade", "confirms", "hypothesis", "take", "philosophy", "class", "philosophical", "significance", "bayes", "theorem", "unifies", "number", "influential", "idea", "confirmation", "scientific", "methodology", "binding", "together", "single", "simple", "equation", "let", "see", "theoretical", "fit", "truism", "better", "theory", "fit", "evidence", "evidence", "support", "mean", "theory", "fit", "evidence", "h", "entail", "e", "theory", "say", "evidence", "must", "true", "discovery", "evidence", "fit", "theory", "perfectly", "formalism", "vindicates", "truism", "special", "case", "follows", "h", "entail", "e", "conditional", "certainty", "logical", "consequence", "tell", "u", "p", "emid", "h", "1", "bayes", "theorem", "becomes", "p", "hmid", "e", "p", "h", "frac", "1", "p", "e", "provided", "p", "e", "le", "1", "amount", "multiplying", "p", "h", "ratio", "greater", "1", "mean", "p", "hmid", "e", "come", "larger", "p", "h", "moreover", "since", "1", "greatest", "quantity", "appear", "numerator", "case", "h", "entail", "e", "thus", "p", "emid", "h", "1", "give", "greatest", "possible", "boost", "probability", "h", "word", "confirmation", "greatest", "theory", "fit", "evidence", "well", "possible", "p", "e", "1", "though", "h", "may", "fit", "e", "may", "neg", "h", "p", "e", "1", "prove", "p", "emid", "h", "1", "p", "emid", "neg", "h", "1", "hint", "combine", "law", "total", "probability", "complementarity", "contradictory", "word", "e", "fit", "h", "negation", "perfectly", "able", "discriminate", "two", "hypothesis", "indeed", "case", "p", "hmid", "e", "come", "p", "h", "c", "h", "e", "0", "theory", "fit", "evidence", "le", "perfectly", "think", "fit", "certainty", "h", "predicts", "e", "p", "emid", "h", "previous", "analysis", "generalizes", "nicely", "suppose", "h", "predicts", "e", "strongly", "absolute", "certainty", "p", "emid", "h", "1", "varepsilon", "small", "number", "varepsilon", "applying", "bayes", "theorem", "p", "hmid", "e", "p", "h", "frac", "1varepsilon", "p", "e", "amount", "multiplying", "p", "h", "ratio", "larger", "1", "provided", "p", "e", "close", "1", "p", "hmid", "e", "come", "larger", "p", "h", "course", "larger", "varepsilon", "get", "weaker", "confirmation", "becomes", "befitting", "weakness", "h", "predicts", "e", "novel", "prediction", "another", "truism", "novel", "prediction", "count", "theory", "predicts", "something", "otherwise", "expect", "confirmed", "especially", "strongly", "prediction", "borne", "example", "poisson", "derided", "theory", "light", "wave", "predicted", "bright", "spot", "appear", "center", "certain", "shadow", "one", "previously", "observed", "bright", "spot", "making", "novel", "prediction", "presence", "bright", "spot", "verified", "boon", "wave", "theory", "formalization", "vindicates", "truism", "suppose", "h", "predicts", "e", "thus", "p", "emid", "h", "1", "nearly", "novel", "prediction", "one", "p", "e", "low", "least", "high", "prediction", "one", "expect", "previous", "analysis", "exposed", "circumstance", "multiply", "p", "h", "large", "ratio", "bayes", "theorem", "thus", "p", "hmid", "e", "come", "significantly", "larger", "p", "h", "making", "c", "h", "e", "large", "novel", "prediction", "turn", "especially", "confirmatory", "prior", "plausibility", "final", "truism", "new", "evidence", "theory", "weighed", "theory", "prior", "plausibility", "maybe", "theory", "inherently", "implausible", "convoluted", "metaphysically", "fraught", "maybe", "theory", "become", "implausible", "clashed", "earlier", "evidence", "maybe", "theory", "already", "pretty", "plausible", "elegant", "fitting", "well", "previous", "evidence", "case", "new", "evidence", "evaluated", "light", "prior", "consideration", "bayes", "theorem", "vindicates", "truism", "p", "hmid", "e", "calculated", "multiplying", "p", "h", "factor", "p", "emid", "h", "p", "e", "think", "factor", "p", "emid", "h", "p", "e", "capturing", "extent", "evidence", "count", "h", "p", "emid", "h", "p", "e", "le", "1", "multiply", "previous", "probability", "h", "p", "h", "order", "obtain", "h", "new", "allthingsconsidered", "plausibility", "h", "already", "implausible", "p", "h", "low", "result", "multiplication", "smaller", "would", "h", "already", "plausible", "p", "h", "thus", "high", "let", "pause", "summarize", "bayes", "theorem", "useful", "calculational", "tool", "also", "vindicates", "three", "truism", "confirmation", "unifying", "single", "equation", "truism", "corresponds", "term", "bayes", "theorem", "p", "emid", "h", "corresponds", "theoretical", "fit", "better", "hypothesis", "fit", "evidence", "greater", "quantity", "since", "term", "appears", "numerator", "bayes", "theorem", "better", "fit", "mean", "larger", "value", "p", "hmid", "e", "p", "e", "corresponds", "predictive", "novelty", "rather", "lack", "novel", "prediction", "le", "expect", "e", "true", "thus", "smaller", "p", "e", "since", "term", "appears", "denominator", "bayes", "theorem", "novelty", "mean", "larger", "value", "p", "hmid", "e", "p", "h", "corresponds", "prior", "plausibility", "plausible", "h", "discovery", "e", "greater", "quantity", "thus", "greater", "p", "hmid", "e", "raven", "paradox", "13", "quantitative", "confirmation", "raven", "paradox", "recall", "raven", "paradox", "hypothesis", "raven", "black", "logically", "equivalent", "hypothesis", "nonblack", "thing", "nonravens", "yet", "latter", "would", "seem", "confirmed", "discovery", "nonblack", "nonravenred", "shirt", "blue", "underpants", "etc", "yet", "examining", "content", "neighbor", "clothesline", "seem", "good", "way", "research", "ornithological", "hypothesis", "seem", "good", "way", "treat", "neighbor", "classic", "quantitative", "solution", "originates", "hosiassonlindenbaum", "1940", "hold", "discovery", "blue", "underpants", "confirm", "hypothesis", "raven", "black", "little", "overlook", "could", "blue", "underpants", "relevant", "hypothesis", "raven", "black", "informally", "idea", "object", "turn", "blue", "pair", "underpants", "could", "instead", "turned", "white", "raven", "turn", "counterexample", "hypothesis", "pass", "weak", "sort", "test", "formal", "theory", "confirmation", "vindicate", "informal", "line", "thinking", "answer", "yes", "but", "but", "prove", "crucial", "fate", "nicod", "criterion", "spoiler", "outlook", "good", "let", "start", "yes", "vindicate", "yes", "theorem", "discovering", "object", "nonraven", "black", "neg", "r", "wedge", "neg", "b", "slightly", "boost", "probability", "hypothesis", "raven", "black", "h", "make", "certain", "assumption", "theorem", "see", "technical", "supplement", "proof", "theorem", "raven", "theorem", "p", "neg", "r", "mid", "neg", "b", "high", "ii", "p", "neg", "bmid", "h", "p", "neg", "b", "p", "hmid", "neg", "r", "wedge", "neg", "b", "slightly", "larger", "p", "h", "first", "assumption", "p", "neg", "r", "mid", "neg", "b", "high", "seems", "pretty", "sensible", "nonravens", "world", "probability", "given", "object", "nonraven", "quite", "high", "especially", "black", "second", "assumption", "p", "neg", "bmid", "h", "p", "neg", "b", "word", "assuming", "raven", "black", "change", "probability", "given", "object", "black", "assumption", "controversial", "vranas", "2004", "raven", "black", "thing", "might", "black", "namely", "raven", "case", "p", "neg", "bmid", "h", "p", "neg", "b", "instead", "hand", "maybe", "raven", "black", "reduce", "number", "black", "thing", "universe", "maybe", "mean", "kind", "thing", "black", "slightly", "often", "luckily", "turn", "replace", "ii", "le", "dubious", "assumption", "fitelson", "2006", "fitelson", "hawthorne", "2010", "rinard", "2014", "assumption", "brings", "u", "two", "crucial", "point", "confirmation", "probability", "first", "point", "nicod", "criterion", "fails", "assumption", "like", "ii", "raven", "theorem", "always", "hold", "fact", "situation", "discovering", "black", "raven", "would", "actually", "lower", "probability", "raven", "black", "could", "trick", "imagine", "situation", "discovery", "raven", "bad", "news", "hypothesis", "raven", "black", "would", "happen", "way", "raven", "black", "stumbling", "across", "raven", "would", "suggest", "raven", "actually", "plentiful", "case", "black", "good", "1967", "offer", "following", "concrete", "illustration", "suppose", "two", "possibility", "raven", "black", "though", "100", "raven", "million", "thing", "one", "nonblack", "raven", "1000", "raven", "million", "thing", "case", "happening", "upon", "raven", "favor", "neg", "h", "neg", "h", "make", "raven", "ten", "time", "le", "exotic", "raven", "black", "fit", "slightly", "better", "h", "enough", "outweigh", "first", "effect", "black", "raven", "hardly", "rarity", "neg", "h", "but", "go", "earlier", "yes", "second", "point", "farreaching", "moral", "fate", "claim", "confirmation", "often", "turn", "crucially", "assumption", "make", "value", "p", "nicod", "criterion", "fails", "situation", "like", "good", "p", "assigns", "lower", "value", "p", "r", "wedge", "bmid", "h", "p", "r", "wedge", "bmid", "neg", "h", "another", "situation", "thing", "reversed", "nicod", "criterion", "apply", "likewise", "diagnosis", "raven", "paradox", "like", "standard", "one", "applies", "given", "certain", "assumption", "p", "like", "assumption", "ii", "raven", "theorem", "probability", "axiom", "alone", "generally", "enough", "tell", "u", "nicod", "criterion", "applies", "confirmation", "small", "large", "positive", "negative", "14", "problem", "prior", "last", "point", "general", "important", "phenomenon", "like", "axiom", "firstorder", "logic", "axiom", "probability", "quite", "weak", "howson", "urbach", "1993", "christensen", "2004", "unless", "h", "tautology", "contradiction", "axiom", "tell", "u", "probability", "somewhere", "0", "1", "express", "h", "disjunction", "two", "logically", "incompatible", "subhypotheses", "h_1", "h_2", "know", "probability", "subhypotheses", "third", "axiom", "let", "u", "compute", "p", "h", "p", "h_1", "p", "h_2", "push", "thing", "back", "step", "since", "axiom", "tell", "u", "p", "h_1", "p", "h_2", "must", "lie", "0", "1", "weakness", "probability", "axiom", "generates", "famous", "problem", "prior", "problem", "saying", "initial", "probability", "come", "always", "based", "evidence", "previously", "collected", "scientific", "inquiry", "get", "started", "instead", "based", "previous", "evidence", "priori", "principle", "govern", "priori", "reasoning", "formal", "epistemologist", "split", "question", "socalled", "objectivists", "see", "probability", "axiom", "incomplete", "waiting", "supplemented", "additional", "postulate", "determine", "probability", "inquiry", "begin", "principle", "indifference", "poi", "leading", "candidate", "see", "entry", "interpretation", "probability", "socalled", "subjectivist", "think", "instead", "single", "correct", "probability", "function", "p", "inquiry", "begin", "different", "inquirer", "may", "begin", "different", "value", "p", "none", "thereby", "le", "scientific", "rational", "others", "later", "section", "problem", "prior", "return", "several", "time", "illustrating", "importance", "ubiquity", "15", "summary", "seen", "formalizing", "confirmation", "using", "probability", "theory", "yield", "account", "succeeds", "several", "significant", "way", "vindicates", "several", "truism", "confirmation", "unifies", "truism", "single", "equation", "resolve", "classic", "paradox", "mention", "others", "discus", "crupi", "tentori", "2010", "also", "saw", "raise", "problem", "though", "problem", "prior", "formal", "epistemologist", "divided", "resolve", "problem", "explore", "notably", "problem", "logical", "omniscience", "old", "evidence", "see", "subsection", "entry", "bayesian", "epistemology", "problem", "led", "exploration", "development", "approach", "scientific", "reasoning", "reasoning", "general", "stick", "probabilistic", "framework", "develop", "different", "methodology", "within", "fisher", "1925", "neyman", "pearson", "1928a", "b", "royall", "1997", "mayo", "1996", "mayo", "spanos", "2011", "see", "entry", "philosophy", "statistic", "others", "depart", "standard", "probability", "theory", "like", "dempstershafer", "theory", "shafer", "1976", "see", "entry", "formal", "representation", "belief", "variant", "probability", "theory", "meant", "solve", "problem", "prior", "make", "improvement", "ranking", "theory", "spohn", "1988", "2012", "see", "entry", "formal", "representation", "belief", "also", "bear", "resemblance", "probability", "theory", "draw", "much", "inspiration", "possibleworld", "semantics", "conditionals", "see", "entry", "indicative", "conditionals", "bootstrapping", "theory", "glymour", "1980", "douven", "meijs", "2006", "leaf", "probabilistic", "framework", "behind", "entirely", "drawing", "inspiration", "instead", "deductionbased", "approach", "began", "still", "approach", "develop", "nonmonotonic", "logic", "see", "entry", "logic", "making", "deductive", "inference", "also", "defeasible", "inductive", "inference", "pollock", "1995", "2008", "horty", "2012", "formal", "learning", "theory", "provides", "framework", "studying", "longrun", "consequence", "wide", "range", "methodology", "next", "two", "section", "build", "probabilistic", "approach", "introduced", "since", "currently", "popular", "influential", "approach", "formal", "epistemology", "important", "remember", "rich", "variegated", "range", "alternative", "approach", "one", "problem", "consequence", "soon", "encounter", "2", "second", "case", "study", "problem", "induction", "lot", "reasoning", "seems", "involve", "projecting", "observed", "pattern", "onto", "unobserved", "instance", "example", "suppose", "know", "whether", "coin", "holding", "biased", "fair", "flip", "9", "time", "land", "tail", "every", "time", "expect", "10th", "toss", "come", "tail", "justifies", "kind", "reasoning", "hume", "famously", "argued", "nothing", "justify", "modern", "form", "hume", "challenge", "essentially", "justification", "reasoning", "must", "appeal", "either", "inductive", "argument", "deductive", "one", "appealing", "inductive", "argument", "would", "unacceptably", "circular", "deductive", "argument", "would", "show", "unobserved", "instance", "resemble", "observed", "one", "necessary", "truth", "hence", "demonstrable", "valid", "argument", "argument", "justify", "projecting", "observed", "pattern", "onto", "unobserved", "case", "russell", "restall", "2010", "offer", "formal", "development", "haack", "1976", "discus", "supposed", "asymmetry", "induction", "deduction", "probability", "come", "rescue", "instead", "deducing", "unobserved", "instance", "resemble", "observed", "one", "deduce", "probably", "resemble", "observed", "one", "deduce", "probability", "axiom", "next", "toss", "likely", "come", "tail", "given", "landed", "tail", "9", "9", "time", "far", "would", "seem", "solve", "hume", "problem", "unfortunately", "deduction", "possible", "probability", "axiom", "simply", "entail", "conclusion", "want", "consider", "different", "sequence", "head", "mathsf", "h", "tail", "mathsf", "might", "get", "course", "10", "toss", "begin", "array", "c", "mathsf", "hhhhhhhhhh", "mathsf", "hhhhhhhhht", "mathsf", "hhhhhhhhth", "vdots", "mathsf", "hhhhhhhhtt", "mathsf", "hhhhhhhtht", "vdots", "mathsf", "ttttttttth", "mathsf", "tttttttttt", "end", "array", "1024", "possible", "sequence", "probability", "possible", "sequence", "would", "seem", "11024", "course", "two", "begin", "9", "tail", "row", "namely", "last", "two", "narrowed", "thing", "sequence", "begin", "9", "9", "tail", "probability", "tail", "10th", "toss", "12", "head", "formally", "applying", "definition", "conditional", "probability", "give", "u", "begin", "align", "p", "t_", "10", "mid", "t_", "1ldots9", "frac", "p", "t_", "10", "wedge", "t_", "1ldots9", "p", "t_", "1ldots9", "frac", "11024", "21024", "frac", "1", "2", "end", "align", "look", "like", "axiom", "probability", "entail", "first", "9", "toss", "tell", "u", "nothing", "10th", "toss", "fact", "though", "axiom", "probability", "even", "entail", "thatthey", "actually", "say", "anything", "p", "t_", "10", "mid", "t_", "1ldots9", "previous", "paragraph", "assumed", "possible", "sequence", "toss", "equally", "probable", "p", "ldots", "11024", "sequence", "probability", "axiom", "require", "uniform", "assignment", "saw", "earlier", "encountered", "problem", "prior", "14", "probability", "axiom", "tell", "u", "tautology", "probability", "1", "contradiction", "probability", "0", "contingent", "proposition", "probability", "0", "1", "includes", "proposition", "sequence", "toss", "mathsf", "hhhhhhhtht", "sequence", "mathsf", "h", "mathsf", "s", "exploit", "freedom", "get", "sensible", "inductionfriendly", "result", "assign", "prior", "probability", "using", "different", "scheme", "advocated", "carnap", "1950", "suppose", "instead", "assigning", "possible", "sequence", "probability", "assign", "possible", "number", "mathsf", "probability", "could", "get", "anywhere", "0", "10", "mathsf", "possible", "number", "mathsf", "probability", "111", "one", "way", "getting", "0", "mathsf", "mathsf", "hhhhhhhhhh", "p", "h_", "1ldots10", "111", "10", "way", "getting", "1", "mathsf", "begin", "array", "c", "mathsf", "hhhhhhhhht", "mathsf", "hhhhhhhhth", "mathsf", "hhhhhhhthh", "vdots", "mathsf", "thhhhhhhhh", "end", "array", "possibility", "probability", "111", "divided", "10", "way", "yielding", "probability", "1110", "subpossibility", "eg", "p", "mathsf", "hhhhhhhthh", "1110", "45", "way", "getting", "2", "mathsf", "begin", "array", "c", "mathsf", "hhhhhhhhtt", "mathsf", "hhhhhhhtht", "mathsf", "hhhhhhthht", "vdots", "mathsf", "tthhhhhhhh", "end", "array", "probability", "111", "divided", "45", "way", "yielding", "probability", "1495", "subpossibility", "eg", "p", "mathsf", "hthhhhhthh", "1495", "becomes", "p", "t_", "10", "mid", "t_", "1ldots9", "begin", "align", "p", "t_", "10", "mid", "t_", "1ldots9", "frac", "p", "t_", "10", "wedge", "t_", "1ldots9", "p", "t_", "1ldots9", "frac", "p", "t_", "1ldots10", "p", "t_", "1ldots10", "vee", "t_", "1ldots9", "wedge", "h_", "10", "frac", "p", "t_", "1ldots10", "p", "t_", "1ldots10", "p", "t_", "1ldots9", "wedge", "h_", "10", "frac", "111", "111", "1110", "frac", "10", "11", "end", "align", "get", "much", "reasonable", "result", "assign", "prior", "probability", "according", "carnap", "twostage", "scheme", "however", "scheme", "mandated", "axiom", "probability", "one", "thing", "teach", "u", "probability", "axiom", "silent", "hume", "problem", "inductive", "reasoning", "compatible", "axiom", "since", "carnap", "way", "constructing", "prior", "probability", "make", "10th", "mathsf", "quite", "likely", "given", "initial", "string", "9", "mathsf", "s", "axiom", "also", "compatible", "skepticism", "induction", "first", "way", "constructing", "prior", "probability", "string", "mathsf", "never", "make", "next", "toss", "likely", "mathsf", "matter", "long", "string", "get", "fact", "way", "constructing", "prior", "probability", "yield", "antiinduction", "mathsf", "observe", "le", "likely", "next", "toss", "mathsf", "also", "learn", "something", "else", "though", "something", "constructive", "hume", "problem", "close", "cousin", "problem", "prior", "could", "justify", "carnap", "way", "assigning", "prior", "probability", "would", "well", "way", "solving", "hume", "problem", "way", "moment", "briefly", "still", "justify", "using", "conditional", "probability", "guide", "new", "unconditional", "probability", "justify", "carnap", "twostage", "scheme", "brings", "u", "classic", "debate", "formal", "epistemology", "21", "principle", "indifference", "bet", "horserace", "without", "knowing", "anything", "horse", "one", "would", "bet", "probably", "matter", "horse", "likely", "win", "others", "indifferent", "available", "wager", "3", "horse", "race", "13", "chance", "winning", "5", "15", "chance", "etc", "kind", "reasoning", "common", "often", "attributed", "principle", "indifference", "5", "principle", "indifference", "poi", "given", "n", "mutually", "exclusive", "jointly", "exhaustive", "possibility", "none", "favored", "others", "available", "evidence", "probability", "1n", "poi", "look", "quite", "plausible", "first", "may", "even", "flavor", "conceptual", "truth", "could", "one", "possibility", "probable", "another", "evidence", "favor", "yet", "poi", "face", "classic", "recalcitrant", "challenge", "consider", "first", "horse", "listed", "race", "athena", "two", "possibility", "win", "lose", "evidence", "lack", "thereof", "favor", "neither", "possibility", "poi", "say", "probability", "win", "12", "suppose", "three", "horse", "race", "athena", "beatrice", "cecil", "since", "evidence", "favor", "none", "poi", "requires", "assign", "probability", "13", "contradicts", "earlier", "conclusion", "athena", "probability", "winning", "12", "source", "trouble", "possibility", "subdivided", "subpossibilities", "possibility", "athena", "losing", "subdivided", "two", "subpossibilities", "one", "beatrice", "win", "another", "cecil", "win", "lack", "relevant", "evidence", "available", "evidence", "seem", "favor", "coarser", "possibility", "finer", "subpossibilities", "leading", "contradictory", "probability", "assignment", "need", "seems", "way", "choosing", "single", "privileged", "way", "dividing", "space", "possibility", "apply", "poi", "consistently", "natural", "think", "use", "finegrained", "division", "possibility", "threeway", "division", "case", "athena", "beatrice", "cecil", "actually", "divide", "thing", "furtherinfinitely", "fact", "example", "athena", "might", "win", "full", "length", "half", "length", "quarter", "length", "etc", "possibility", "win", "actually", "infinitely", "divisible", "extend", "poi", "handle", "infinite", "division", "possibility", "natural", "way", "saying", "athena", "win", "probability", "win", "1", "2", "length", "twice", "probability", "win", "12", "1", "length", "problem", "trying", "solve", "still", "persists", "form", "notorious", "bertrand", "paradox", "bertrand", "2007", "1888", "paradox", "nicely", "illustrated", "following", "example", "van", "fraassen", "1989", "suppose", "factory", "cut", "iron", "cube", "edgelengths", "ranging", "0", "cm", "2", "cm", "probability", "next", "cube", "come", "line", "edge", "0", "cm", "1", "cm", "length", "without", "information", "factory", "go", "producing", "cube", "poi", "would", "seem", "say", "probability", "12", "range", "0", "1", "cover", "12", "full", "range", "possibility", "0", "2", "consider", "question", "probability", "next", "cube", "come", "line", "volume", "0", "cubic", "cm", "1", "cubic", "cm", "poi", "seems", "say", "probability", "18", "range", "0", "1", "cover", "18", "full", "range", "possible", "volume", "0", "8", "cubic", "cm", "two", "different", "probability", "equivalent", "proposition", "cube", "edgelength", "0", "1", "cm", "volume", "0", "cubic", "cm", "1", "cubic", "cm", "probability", "given", "poi", "seem", "depend", "describe", "range", "possible", "outcome", "described", "term", "length", "get", "one", "answer", "described", "term", "volume", "get", "another", "importantly", "bertrand", "paradox", "applies", "quite", "generally", "whether", "interested", "size", "cube", "distance", "horse", "win", "parameter", "measured", "real", "number", "always", "redescribe", "space", "possible", "outcome", "probability", "assigned", "poi", "come", "differently", "even", "infinitely", "fine", "division", "space", "possibility", "fix", "problem", "probability", "assigned", "poi", "still", "depend", "describe", "space", "possibility", "face", "essentially", "problem", "frame", "problem", "induction", "probabilistic", "term", "earlier", "saw", "two", "competing", "way", "assigning", "prior", "probability", "sequence", "coin", "toss", "one", "way", "divide", "possible", "outcome", "according", "exact", "sequence", "mathsf", "h", "mathsf", "occur", "poi", "assigns", "possible", "sequence", "probability", "11024", "result", "first", "9", "toss", "tell", "u", "nothing", "10th", "toss", "second", "carnapian", "way", "instead", "divide", "possible", "outcome", "according", "number", "mathsf", "regardless", "occur", "sequence", "poi", "assigns", "possible", "number", "mathsf", "probability", "111", "result", "first", "9", "toss", "tell", "u", "lot", "10th", "toss", "first", "9", "toss", "tail", "10th", "toss", "1011", "chance", "coming", "tail", "one", "way", "applying", "poi", "lead", "inductive", "skepticism", "yield", "inductive", "optimism", "seems", "indispensable", "science", "daily", "life", "could", "clarify", "poi", "applied", "justify", "use", "would", "answer", "hume", "problem", "least", "first", "halfwe", "still", "address", "issue", "using", "conditional", "probability", "guide", "new", "unconditional", "probability", "clarified", "justified", "run", "one", "deepest", "oldest", "divide", "formal", "epistemology", "subjectivist", "objectivists", "subjectivist", "hold", "assignment", "probability", "legitimate", "reasonable", "way", "start", "one", "inquiry", "one", "need", "conform", "three", "probability", "axiom", "reasonable", "take", "view", "largely", "despair", "clarifying", "poi", "see", "reason", "example", "follow", "carnap", "first", "dividing", "according", "number", "mathsf", "subdividing", "according", "sequence", "mathsf", "appear", "closely", "related", "skepticism", "skepticism", "prospect", "justifying", "poi", "even", "clarified", "way", "would", "put", "par", "three", "axiom", "probability", "yet", "touched", "three", "axiom", "supposed", "justified", "classic", "story", "family", "theoremsdutch", "book", "theorem", "see", "entry", "representation", "theorem", "see", "entry", "are", "taken", "show", "deviation", "three", "axiom", "probability", "lead", "irrational", "decisionmaking", "example", "deviate", "axiom", "accept", "set", "bet", "bound", "lose", "money", "even", "though", "see", "losing", "money", "inevitable", "priori", "theorem", "extend", "violation", "poi", "though", "however", "clarified", "subjectivist", "conclude", "violating", "poi", "irrational", "subjectivist", "thereby", "entirely", "helpless", "face", "problem", "induction", "though", "according", "initial", "assignment", "probability", "reasonable", "including", "carnap", "happen", "start", "carnapesque", "assignment", "inductive", "optimist", "reasonably", "start", "way", "could", "instead", "start", "treating", "possible", "sequence", "mathsf", "h", "mathsf", "equally", "probable", "case", "end", "inductive", "skeptic", "reasonable", "according", "subjectivism", "induction", "perfectly", "rational", "rational", "way", "reason", "objectivists", "hold", "instead", "one", "way", "assign", "initial", "probability", "though", "allow", "bit", "flexibility", "maher", "1996", "initial", "probability", "given", "poi", "according", "orthodox", "objectivism", "poi", "conflicting", "probability", "assignment", "depending", "possibility", "divided", "objectivists", "propose", "restricting", "avoid", "inconsistency", "castell", "1998", "others", "argue", "actually", "appropriate", "probability", "assignment", "depend", "way", "possibility", "divvied", "since", "reflects", "language", "conceive", "situation", "language", "reflects", "knowledge", "bring", "matter", "williamson", "2007", "still", "others", "argue", "poi", "assignment", "actually", "depend", "way", "possibility", "divided", "upit", "hard", "tell", "sometimes", "evidence", "favor", "one", "possibility", "another", "white", "2009", "justifying", "poi", "though", "subjectivist", "traditionally", "justified", "three", "axiom", "probability", "appeal", "one", "aforementioned", "theorem", "dutch", "book", "theorem", "form", "representation", "theorem", "noted", "earlier", "theorem", "extend", "poi", "recently", "different", "sort", "justification", "gaining", "favor", "one", "may", "extend", "poi", "argument", "rely", "dutch", "book", "representation", "theorem", "long", "suspect", "pragmatic", "character", "aim", "show", "deviating", "probability", "axiom", "lead", "irrational", "choice", "seems", "show", "best", "obeying", "probability", "axiom", "part", "pragmatic", "rationality", "opposed", "epistemic", "irrationality", "see", "christensen", "1996", "2001", "vineberg", "1997", "2001", "reply", "preferring", "properly", "epistemic", "approach", "joyce", "1998", "2009", "argues", "deviating", "probability", "axiom", "take", "one", "unnecessarily", "far", "truth", "matter", "truth", "turn", "pettigrew", "2016", "adapts", "approach", "poi", "showing", "violation", "poi", "increase", "one", "risk", "truth", "see", "carr", "2017", "critical", "perspective", "general", "approach", "22", "updating", "inference", "whether", "prefer", "subjectivist", "response", "hume", "problem", "objectivist", "crucial", "element", "still", "missing", "earlier", "noted", "justifying", "carnapian", "assignment", "prior", "probability", "get", "u", "half", "way", "solution", "still", "turn", "prior", "probability", "posterior", "probability", "initially", "probability", "tail", "tenth", "toss", "12", "observing", "first", "9", "toss", "come", "tail", "supposed", "1011", "justified", "initial", "assignment", "probabilitieswhether", "subjectivist", "way", "objectivist", "waywe", "prove", "p", "t_", "10", "mid", "t_", "1ldots9", "1011", "compared", "p", "t_", "10", "12", "mean", "new", "probability", "t_", "10", "1011", "remember", "symbolism", "p", "t_", "10", "mid", "t_", "1ldots9", "shorthand", "fraction", "p", "t_", "10", "wedge", "t_", "1ldots9", "p", "t_", "1ldots9", "fact", "p", "t_", "10", "mid", "t_", "1ldots9", "1011", "mean", "ratio", "1011", "still", "fact", "initial", "prior", "probability", "appreciate", "problem", "help", "forget", "probability", "moment", "think", "simple", "folksy", "term", "suppose", "sure", "whether", "a", "true", "believe", "true", "b", "learn", "a", "fact", "true", "two", "option", "might", "conclude", "b", "true", "might", "instead", "decide", "wrong", "outset", "think", "b", "true", "a", "faced", "prospect", "accepting", "b", "might", "find", "implausible", "accept", "thus", "abandon", "initial", "conditional", "belief", "b", "true", "a", "harman", "1986", "likewise", "might", "start", "unsure", "whether", "first", "9", "toss", "come", "tail", "believe", "probability", "10", "th", "toss", "coming", "tail", "1011", "see", "first", "9", "toss", "come", "tail", "might", "conclude", "10", "th", "toss", "1011", "chance", "coming", "tail", "might", "instead", "decide", "wrong", "outset", "think", "1011", "chance", "coming", "tail", "10", "th", "toss", "came", "tail", "first", "9", "toss", "task", "justify", "taking", "first", "route", "rather", "second", "sticking", "conditional", "belief", "t_", "1ldots9", "t_", "10", "probability", "1011", "even", "learned", "indeed", "t_", "1ldots9", "standing", "one", "conditional", "probability", "way", "known", "conditionalizing", "one", "thereby", "turn", "old", "conditional", "probability", "new", "unconditional", "probability", "see", "sticking", "old", "conditional", "probability", "amount", "turning", "unconditional", "probability", "let", "keep", "using", "p", "represent", "prior", "probability", "let", "introduce", "p", "stand", "new", "posterior", "probability", "learn", "t_", "1ldots9", "stand", "prior", "conditional", "probability", "p", "t_", "10", "mid", "t_", "1ldots9", "p", "t_", "10", "mid", "t_", "1ldots9", "1011", "since", "know", "t_", "1ldots9", "p", "t_", "1ldots9", "1", "follows", "p", "t_", "10", "1011", "begin", "align", "p", "t_", "10", "mid", "t_", "1ldots9", "frac", "p", "t_", "10", "wedge", "t_", "1ldots9", "p", "t_", "1ldots9", "p", "t_", "10", "wedge", "t_", "1ldots9", "p", "t_", "10", "1011end", "align", "first", "line", "follows", "definition", "conditional", "probability", "second", "follows", "fact", "p", "t_", "1ldots9", "1", "since", "seen", "first", "9", "toss", "go", "third", "line", "follows", "elementary", "theorem", "probability", "axiom", "conjoining", "a", "another", "proposition", "b", "probability", "1", "result", "probability", "ie", "p", "wedge", "b", "p", "p", "b", "1", "deriving", "theorem", "left", "exercise", "reader", "finally", "last", "line", "follows", "assumption", "p", "t_", "10", "mid", "t_", "1ldots9", "p", "t_", "10", "mid", "t_", "1ldots9", "1011", "thesis", "generally", "update", "probability", "fashion", "known", "conditionalization", "conditionalization", "given", "prior", "probability", "assignment", "p", "hmid", "e", "new", "unconditional", "probability", "assignment", "h", "upon", "learning", "e", "p", "h", "p", "hmid", "e", "number", "argument", "given", "principle", "many", "parallel", "previously", "mentioned", "argument", "axiom", "probability", "appeal", "dutch", "book", "teller", "1973", "lewis", "1999", "others", "pursuit", "cognitive", "value", "greave", "wallace", "2006", "especially", "closeness", "truth", "leitgeb", "pettigrew", "2010a", "b", "still", "others", "idea", "one", "generally", "revise", "one", "belief", "little", "possible", "accommodating", "new", "information", "williams", "1980", "detail", "argument", "get", "technical", "examine", "important", "thing", "moment", "appreciate", "inductive", "inference", "dynamic", "process", "since", "involves", "changing", "belief", "time", "ii", "general", "probability", "axiom", "particular", "assignment", "prior", "probability", "like", "carnap", "static", "concerning", "initial", "probability", "thus", "iii", "full", "theory", "inference", "answer", "hume", "challenge", "must", "appeal", "additional", "dynamic", "principle", "like", "conditionalization", "iv", "need", "justify", "additional", "dynamic", "principle", "order", "justify", "proper", "theory", "inference", "answer", "hume", "challenge", "importantly", "moral", "summarized", "iv", "extremely", "general", "apply", "formal", "epistemology", "based", "probability", "theory", "also", "apply", "wide", "range", "theory", "based", "formalism", "like", "dempstershafer", "theory", "ranking", "theory", "beliefrevision", "theory", "nonmonotonic", "logic", "one", "way", "viewing", "takeaway", "follows", "formal", "epistemology", "give", "u", "precise", "way", "stating", "induction", "work", "precise", "formulation", "solve", "problem", "like", "hume", "rely", "assumption", "like", "probability", "axiom", "carnap", "assignment", "prior", "probability", "conditionalization", "still", "help", "u", "isolate", "clarify", "assumption", "formulate", "various", "argument", "defense", "whether", "formal", "epistemology", "thereby", "aid", "solution", "hume", "problem", "depends", "whether", "formulation", "justification", "plausible", "controversial", "3", "third", "case", "study", "regress", "problem", "problem", "induction", "challenge", "inference", "observed", "unobserved", "regress", "problem", "challenge", "knowledge", "even", "fundamental", "level", "questioning", "ability", "know", "anything", "observation", "first", "place", "see", "weintraub", "1995", "critical", "analysis", "distinction", "know", "something", "seems", "must", "justification", "believing", "example", "knowledge", "socrates", "taught", "plato", "based", "testimony", "textual", "source", "handed", "year", "know", "testimony", "text", "reliable", "source", "presumably", "knowledge", "based", "justificationvarious", "experience", "source", "agreement", "thing", "observed", "independently", "basis", "knowledge", "challenged", "know", "source", "even", "say", "think", "say", "even", "existmaybe", "every", "experience", "reading", "apology", "mirage", "delusion", "famous", "agrippan", "trilemma", "identifies", "three", "possible", "way", "regress", "justification", "might", "ultimately", "unfold", "first", "could", "go", "forever", "a", "justified", "b", "justified", "c", "justified", "ad", "infinitum", "second", "could", "cycle", "back", "point", "a", "justified", "b", "justified", "c", "justified", "byjustified", "b", "example", "third", "finally", "regress", "might", "stop", "point", "a", "justified", "b", "justified", "c", "justified", "byjustified", "n", "justified", "belief", "three", "possibility", "correspond", "three", "classic", "response", "regress", "justification", "infinitists", "hold", "regress", "go", "forever", "coherentists", "cycle", "back", "foundationalists", "ultimately", "terminates", "proponent", "view", "reject", "alternative", "unacceptable", "infinitism", "look", "psychologically", "unrealistic", "requiring", "infinite", "tree", "belief", "finite", "mind", "like", "could", "accommodate", "coherentism", "seems", "make", "justification", "unacceptably", "circular", "thus", "easy", "achieve", "foundationalism", "seems", "make", "justification", "arbitrary", "since", "belief", "end", "regress", "apparently", "justification", "proponent", "view", "long", "striven", "answer", "concern", "view", "show", "concern", "alternative", "adequately", "answered", "recently", "method", "formal", "epistemology", "begun", "recruited", "examine", "adequacy", "answer", "look", "work", "done", "coherentism", "foundationalism", "since", "focus", "informal", "formal", "work", "work", "infinitism", "see", "turri", "klein", "2014", "see", "haack", "1993", "hybrid", "option", "foundherentism", "31", "coherentism", "immediate", "concern", "coherentism", "make", "justification", "circular", "belief", "justified", "belief", "ultimately", "justified", "first", "belief", "question", "cycle", "justification", "allowed", "stop", "one", "believing", "anything", "one", "like", "appealing", "justification", "coherentists", "usually", "respond", "justification", "actually", "go", "cycle", "fact", "even", "really", "relationship", "individual", "belief", "rather", "belief", "justified", "part", "larger", "body", "belief", "fit", "together", "well", "cohere", "justification", "thus", "global", "holistic", "feature", "entire", "body", "belief", "first", "individual", "belief", "second", "virtue", "part", "coherent", "whole", "trace", "justification", "belief", "back", "back", "back", "come", "full", "circle", "exposing", "path", "justified", "rather", "exposing", "various", "interconnection", "make", "whole", "web", "justified", "unit", "connection", "traced", "circle", "merely", "expose", "interconnected", "web", "connected", "direction", "a", "b", "to", "n", "n", "way", "back", "a", "still", "arbitrariness", "remains", "worry", "still", "believe", "anything", "provided", "also", "believe", "many", "thing", "fit", "well", "want", "believe", "ghost", "adopt", "larger", "world", "view", "supernatural", "paranormal", "phenomenon", "rife", "worry", "lead", "one", "worry", "truth", "given", "almost", "belief", "embedded", "larger", "justso", "story", "make", "sense", "expect", "coherent", "body", "belief", "true", "many", "coherent", "story", "one", "tell", "vast", "majority", "massively", "false", "coherence", "indication", "truth", "provide", "justification", "formal", "method", "come", "probability", "theory", "tell", "u", "connection", "coherence", "truth", "coherent", "body", "belief", "likely", "true", "le", "likely", "klein", "warfield", "1994", "argue", "coherence", "often", "decrease", "probability", "increase", "coherence", "often", "come", "new", "belief", "make", "sense", "existing", "belief", "detective", "investigating", "crime", "may", "puzzled", "conflicting", "testimony", "learns", "suspect", "identical", "twin", "explains", "witness", "report", "seeing", "suspect", "another", "city", "day", "crime", "yet", "adding", "fact", "identical", "twin", "body", "belief", "actually", "decrease", "probability", "follows", "theorem", "probability", "axiom", "noted", "earlier", "12", "conjunction", "cost", "probability", "say", "conjoining", "a", "b", "generally", "yield", "lower", "probability", "a", "alone", "unless", "p", "wedge", "neg", "b", "0", "intuitively", "thing", "believe", "risk", "take", "truth", "making", "sense", "thing", "often", "requires", "believing", "merricks", "1995", "reply", "probability", "entire", "belief", "corpus", "go", "belief", "added", "individual", "probability", "belief", "contains", "issue", "detective", "point", "view", "individual", "belief", "become", "probable", "made", "sense", "additional", "information", "suspect", "identical", "twin", "shogenji", "1999", "differs", "coherence", "whole", "influence", "probability", "part", "coherence", "part", "stand", "fall", "together", "coherence", "make", "member", "likely", "true", "together", "make", "likely", "false", "expense", "possibility", "turn", "true", "others", "false", "instead", "shogenji", "prefers", "answer", "klein", "warfield", "collective", "level", "level", "whole", "belief", "corpus", "argues", "corpus", "klein", "warfield", "compare", "differ", "probability", "different", "strength", "belief", "corpus", "contains", "specific", "belief", "stronger", "case", "detective", "adding", "information", "twin", "increase", "strength", "belief", "general", "increasing", "strength", "decrease", "probability", "since", "seen", "p", "wedge", "b", "leq", "p", "thus", "increase", "coherence", "detective", "belief", "accompanied", "increase", "strength", "net", "effect", "argues", "shogenji", "negative", "probability", "corpus", "go", "increase", "strength", "outweighs", "increase", "coherence", "vindicate", "diagnosis", "shogenji", "appeal", "formula", "measuring", "coherence", "beliefset", "probabilistic", "term", "label", "coh", "textit", "coh", "a_1", "ldots", "a_n", "frac", "p", "a_1", "wedge", "ldots", "wedge", "a_n", "p", "a_1", "times", "ldots", "times", "p", "a_n", "see", "rationale", "behind", "formula", "consider", "simple", "case", "two", "belief", "begin", "align", "textit", "coh", "b", "frac", "p", "wedge", "b", "p", "times", "p", "b", "frac", "p", "mid", "b", "p", "end", "align", "b", "bearing", "a", "p", "amid", "b", "p", "ratio", "come", "1", "neutral", "point", "instead", "b", "raise", "probability", "a", "ratio", "come", "larger", "1", "b", "lower", "probability", "a", "come", "smaller", "1", "textit", "coh", "b", "measure", "extent", "a", "b", "related", "shogenji", "formula", "textit", "coh", "a_1", "ldots", "a_n", "generalizes", "idea", "larger", "collection", "proposition", "measuring", "coherence", "way", "vindicate", "shogenji", "reply", "klein", "warfield", "increase", "detective", "coherence", "outweighed", "increase", "strength", "belief", "denominator", "formula", "textit", "coh", "track", "strength", "proposition", "specific", "smaller", "denominator", "compare", "two", "beliefsets", "strength", "denominator", "thus", "one", "coherent", "must", "numerator", "greater", "thus", "coherence", "increase", "overall", "probability", "provided", "strength", "held", "constant", "since", "detective", "case", "overall", "probability", "increase", "despite", "increase", "coherence", "must", "strength", "commitment", "even", "stronger", "influence", "shogenji", "measure", "coherence", "criticized", "author", "many", "offer", "preferred", "measure", "akiba", "2000", "olsson", "2002", "2005", "glass", "2002", "bovens", "hartmann", "2003", "fitelson", "2003", "douven", "meijs", "2007", "measure", "correct", "remains", "controversial", "fate", "klein", "warfield", "argument", "coherentism", "another", "line", "probabilistic", "attack", "coherentism", "explore", "come", "huemer", "1997", "endorsed", "olsson", "2005", "huemer", "2011", "later", "retracts", "argument", "though", "ground", "foists", "unnecessary", "commitment", "coherentist", "detail", "available", "entry", "coherentism", "32", "foundationalism", "foundationalists", "hold", "belief", "justified", "without", "justified", "belief", "belief", "special", "foundational", "status", "foundationalists", "usually", "identify", "either", "belief", "perceived", "remembered", "matter", "like", "door", "front", "egg", "yesterday", "else", "belief", "thing", "seem", "u", "like", "appears", "door", "front", "seem", "remember", "egg", "yesterday", "either", "way", "challenge", "say", "belief", "justified", "justified", "belief", "one", "view", "belief", "justified", "perceptual", "memorial", "state", "look", "like", "door", "front", "perceptual", "state", "justifies", "believing", "door", "provided", "reason", "distrust", "appearance", "least", "justified", "believing", "appears", "door", "foundational", "belief", "arbitrary", "justified", "closely", "related", "perceptual", "memorial", "state", "still", "regress", "end", "make", "sense", "ask", "justifies", "state", "perception", "memory", "state", "outside", "domain", "epistemic", "normativity", "classic", "criticism", "foundationalism", "arises", "version", "infamous", "sellarsian", "dilemma", "must", "know", "say", "vision", "reliable", "justified", "believing", "door", "front", "basis", "looking", "way", "face", "first", "horn", "dilemma", "regress", "justification", "revived", "justifies", "belief", "vision", "reliable", "appealing", "previous", "case", "vision", "proved", "reliable", "push", "thing", "back", "step", "since", "problem", "arises", "reliability", "memory", "could", "say", "instead", "appearance", "door", "enough", "justify", "belief", "door", "face", "second", "horn", "belief", "would", "seem", "arbitrary", "formed", "basis", "source", "reason", "trust", "namely", "vision", "sellars", "1956", "bonjour", "1985", "cohen", "2002", "second", "horn", "sharpened", "white", "2006", "formalizes", "probabilistic", "term", "let", "proposition", "appears", "door", "d", "proposition", "really", "door", "conjunction", "wedge", "neg", "d", "represents", "possibility", "appearance", "misleading", "case", "say", "appears", "door", "really", "using", "probability", "axiom", "prove", "p", "dmid", "leq", "p", "neg", "wedge", "neg", "see", "technical", "supplement", "3", "word", "probability", "really", "door", "given", "appears", "one", "exceed", "initial", "probability", "appearance", "misleading", "case", "seems", "justification", "lends", "belief", "d", "must", "preceded", "justification", "believing", "appearance", "misleading", "ie", "neg", "wedge", "neg", "apparently", "must", "know", "reason", "believe", "source", "reliable", "trust", "pryor", "2013", "elucidates", "tacit", "assumption", "argument", "lying", "wait", "horn", "sellarsian", "dilemma", "principle", "indifference", "poi", "initial", "probability", "appearance", "door", "misleading", "according", "poi", "one", "way", "thinking", "vision", "anywhere", "100", "reliable", "0", "reliable", "way", "thing", "appear", "u", "might", "accurate", "time", "none", "time", "anywhere", "regard", "every", "degree", "reliability", "0", "100", "equally", "probable", "effect", "assumed", "experience", "50", "reliable", "poi", "assign", "p", "dmid", "12", "result", "effectively", "embrace", "skepticism", "since", "remain", "agnostic", "presence", "door", "despite", "appearance", "saw", "earlier", "21", "poi", "assigns", "different", "probability", "depending", "divide", "space", "possibility", "divide", "thing", "way", "instead", "d", "neg", "d", "14", "14", "neg", "14", "14", "get", "skeptical", "agnostic", "result", "p", "dmid", "12", "way", "dividing", "space", "possibility", "surely", "deliver", "better", "antiskeptical", "result", "argument", "preferring", "way", "dividing", "thing", "wanted", "launching", "regress", "justification", "subjectivist", "reject", "poi", "allow", "assignment", "initial", "probability", "long", "obeys", "probability", "axiom", "may", "respond", "perfectly", "permissible", "assign", "high", "initial", "probability", "hypothesis", "sens", "say", "95", "reliable", "must", "also", "admit", "permissible", "assign", "high", "initial", "probability", "hypothesis", "sens", "0", "reliable", "ie", "wrong", "time", "subjectivist", "say", "belief", "external", "world", "justified", "must", "allow", "skepticism", "justified", "foundationalists", "may", "able", "live", "result", "many", "seek", "understand", "experience", "justifies", "external", "world", "belief", "stronger", "sensein", "way", "used", "combat", "skeptic", "rather", "merely", "agreeing", "disagree", "4", "fourth", "case", "study", "limit", "knowledge", "far", "used", "one", "formal", "tool", "probability", "theory", "get", "many", "similar", "result", "application", "using", "tool", "like", "dempstershafer", "theory", "ranking", "theory", "let", "move", "new", "application", "new", "tool", "let", "use", "modal", "logic", "explore", "limit", "knowledge", "41", "epistemic", "modal", "logic", "language", "modal", "logic", "ordinary", "classical", "logic", "additional", "sentential", "operator", "box", "thrown", "represent", "necessity", "sentence", "phi", "true", "necessarily", "true", "write", "box", "phi", "many", "kind", "necessity", "though", "thing", "logically", "necessary", "like", "tautology", "others", "may", "logically", "necessary", "still", "metaphysically", "necessary", "hesperus", "phosphorus", "identical", "popular", "example", "controversial", "candidate", "god", "existence", "fact", "parental", "origin", "eg", "fact", "ada", "lovelace", "father", "lord", "byron", "kind", "necessity", "concern", "u", "epistemic", "necessity", "necessity", "thing", "must", "true", "given", "know", "example", "epistemically", "necessary", "author", "sentence", "human", "know", "already", "maybe", "considered", "question", "true", "given", "thing", "know", "human", "being", "earth", "capable", "constructing", "coherent", "survey", "formal", "epistemology", "survey", "hope", "epistemic", "modal", "logic", "make", "sense", "write", "k", "phi", "instead", "box", "phi", "k", "phi", "mean", "phi", "known", "true", "least", "follows", "known", "true", "known", "depends", "application", "let", "assume", "talking", "knowledge", "unless", "specified", "otherwise", "axiom", "epistemic", "modal", "logic", "include", "well", "tautology", "propositional", "logic", "theorem", "like", "phi", "supset", "phi", "matter", "formula", "k", "operator", "similarly", "truthtable", "valid", "like", "k", "phi", "supset", "k", "phi", "theorem", "go", "ahead", "make", "formula", "theorem", "crudest", "way", "possible", "making", "axiom", "p", "sentence", "truthtable", "valid", "rule", "classical", "logic", "axiom", "adopting", "p", "immediately", "make", "list", "axiom", "infinite", "easily", "identified", "truthtable", "method", "worry", "moving", "beyond", "classical", "logic", "socalled", "normal", "modal", "logic", "share", "axiom", "look", "pretty", "sensible", "epistemic", "application", "tag", "bf", "k", "k", "phi", "supset", "psi", "supset", "k", "phi", "supset", "k", "psi", "know", "phi", "supset", "psi", "true", "also", "know", "phi", "also", "know", "psi", "least", "psi", "follows", "know", "phi", "supset", "psi", "phi", "k", "stand", "kripke", "way", "knowledge", "another", "common", "axiom", "shared", "alethic", "modal", "logic", "also", "look", "good", "tag", "bf", "t", "k", "phi", "supset", "phi", "know", "phi", "must", "true", "note", "k", "actually", "axiom", "schema", "since", "sentence", "form", "axiom", "schema", "actually", "add", "infinitely", "many", "axiom", "general", "form", "axiom", "add", "two", "inference", "rule", "first", "familiar", "classical", "logic", "state", "phi", "supset", "psi", "phi", "one", "may", "derive", "psi", "formally", "tag", "bf", "mp", "phi", "supset", "psi", "phi", "vdash", "psi", "second", "rule", "specific", "modal", "logic", "state", "phi", "one", "infer", "k", "phi", "formally", "tag", "textbf", "nec", "phi", "vdash", "k", "phi", "nec", "rule", "look", "immediately", "suspect", "make", "everything", "true", "known", "actually", "logic", "admits", "axiom", "thing", "follow", "mp", "logical", "truth", "subject", "nec", "rule", "epistemically", "necessary", "either", "known", "follow", "know", "follow", "given", "assumption", "nec", "stand", "necessary", "epistemically", "necessary", "present", "system", "three", "axiom", "schema", "p", "k", "together", "derivation", "rule", "mp", "nec", "complete", "minimal", "epistemic", "modal", "logic", "allow", "u", "derive", "basic", "theorem", "one", "use", "next", "section", "theorem", "bwedge", "distribution", "k", "phi", "wedge", "psi", "supset", "k", "phi", "wedge", "k", "psi", "see", "technical", "supplement", "proof", "theorem", "say", "roughly", "know", "conjunction", "know", "conjunct", "least", "conjunct", "follows", "know", "leaving", "qualifier", "implicit", "seems", "pretty", "sensible", "prove", "anything", "interesting", "tweak", "derive", "quite", "striking", "result", "limit", "knowledge", "42", "knowability", "paradox", "aka", "churchfitch", "paradox", "everything", "true", "known", "truth", "could", "never", "known", "even", "principle", "famous", "argument", "popularized", "fitch", "1963", "originally", "due", "alonzo", "church", "salerno", "2009", "suggests", "truth", "unknowable", "truth", "knowable", "principle", "could", "derive", "truth", "actually", "known", "already", "would", "absurd", "argument", "requires", "slight", "extension", "epistemic", "logic", "accommodate", "notion", "knowability", "u", "k", "mean", "known", "entailed", "known", "whereas", "knowability", "add", "extra", "modal", "layer", "possible", "know", "need", "sentential", "operator", "diamond", "language", "represent", "metaphysical", "possibility", "thus", "diamond", "phi", "mean", "metaphysically", "possible", "phi", "true", "fact", "diamond", "phi", "short", "neg", "box", "neg", "phi", "since", "false", "true", "actually", "add", "box", "instead", "assume", "like", "k", "operator", "obeys", "nec", "rule", "nec", "rule", "k", "operator", "okay", "always", "derive", "box", "phi", "phi", "derive", "phi", "first", "place", "phi", "logical", "truth", "diamond", "neg", "box", "neg", "definition", "addition", "language", "place", "derive", "following", "lemma", "see", "technical", "supplement", "derivation", "lemma", "unknown", "unknowable", "neg", "diamond", "k", "phi", "wedge", "neg", "k", "phi", "lemma", "basically", "say", "know", "fact", "sort", "phi", "true", "know", "true", "seems", "pretty", "sensible", "knew", "conjunction", "second", "conjunct", "would", "true", "conflict", "knowing", "first", "conjunct", "bwedge", "distribution", "prof", "useful", "yet", "plausible", "looking", "lemma", "lead", "almost", "immediately", "unknowability", "truth", "suppose", "reductio", "everything", "true", "could", "known", "least", "principle", "suppose", "took", "axiom", "knowledge", "without", "limit", "phi", "supset", "diamond", "k", "phi", "would", "able", "derive", "line", "everything", "true", "actually", "known", "ie", "phi", "supset", "k", "phi", "begin", "array", "rll", "1", "phi", "wedge", "neg", "k", "phi", "supset", "diamond", "k", "phi", "wedge", "neg", "k", "phi", "textbf", "knowledge", "without", "limit", "2", "neg", "phi", "wedge", "neg", "kphi", "1", "textbf", "unknown", "unknowable", "p", "3", "phi", "supset", "kphi", "2", "textbf", "p", "end", "array", "k", "represents", "god", "know", "would", "fine", "k", "represents", "know", "seems", "absurd", "truth", "know", "truth", "even", "follow", "know", "knowledge", "without", "limit", "appears", "culprit", "seems", "thing", "could", "know", "even", "principle", "see", "entry", "fitch", "paradox", "knowability", "discussion", "43", "selfknowledge", "even", "know", "thing", "might", "least", "unlimited", "access", "knowledge", "least", "always", "able", "discern", "whether", "know", "something", "popular", "axiom", "logic", "metaphysical", "necessity", "socalled", "s4", "axiom", "box", "phi", "supset", "box", "box", "phi", "say", "whatever", "necessary", "necessary", "epistemic", "logic", "corresponding", "formula", "tag", "bf", "kk", "k", "phi", "supset", "kk", "phi", "say", "roughly", "whenever", "know", "something", "know", "know", "hintikka", "1962", "famously", "advocate", "including", "kk", "axiom", "epistemic", "logic", "influential", "argument", "due", "williamson", "2000", "suggests", "otherwise", "argument", "hinge", "idea", "knowledge", "luck", "specifically", "know", "something", "must", "wrong", "easily", "otherwise", "though", "might", "right", "luck", "example", "might", "correctly", "guess", "exactly", "967", "jellybeans", "jar", "desk", "even", "though", "right", "got", "lucky", "know", "967", "jellybeans", "could", "easily", "968", "jellybeans", "without", "noticing", "difference", "formalize", "noluck", "idea", "let", "proposition", "phi_1", "phi_2", "etc", "say", "number", "jellybeans", "least", "1", "least", "2", "etc", "assume", "eyeballing", "number", "jellybeans", "jar", "counting", "carefully", "imperfect", "estimator", "large", "quantity", "jellybeans", "know", "least", "967", "jellybeans", "jar", "think", "least", "967", "jellybeans", "could", "easily", "make", "mistake", "thinking", "least", "968", "case", "wrong", "formalize", "easily", "wrong", "idea", "scenario", "follows", "safety", "k", "phi_i", "supset", "phi_", "i1", "i", "large", "least", "100", "let", "say", "idea", "knowledge", "requires", "margin", "error", "margin", "least", "one", "jellybean", "example", "presumably", "one", "jellybean", "least", "one", "within", "one", "jellybean", "true", "number", "discern", "truth", "falsehood", "see", "nozick", "1981", "different", "conception", "luck", "requirement", "knowledge", "roush", "2005", "2009", "formalizes", "probabilistic", "term", "explained", "though", "something", "else", "know", "safety", "thesis", "true", "also", "knowledge", "safety", "k", "k", "phi_i", "supset", "phi_", "i1", "i", "large", "combining", "knowledge", "safety", "kk", "yield", "absurd", "result", "begin", "array", "rll", "1", "k", "phi_", "100", "mbox", "assumption", "2", "kk", "phi_", "100", "1", "mathbf", "kk", "3", "k", "k", "phi_", "100", "supset", "phi_", "101", "textbf", "knowledge", "safety", "4", "kk", "phi_", "100", "supset", "k", "phi_", "101", "3", "mathbf", "k", "5", "k", "phi_", "101", "24", "mathbf", "mp", "mbox", "repeat", "step", "2", "5", "phi_", "101", "phi_", "102", "ldots", "phi_n", "m", "k", "phi_n", "m1", "mathbf", "mp", "m", "phi_n", "mathbf", "end", "array", "given", "assumption", "line", "1", "know", "least", "100", "jellybeans", "jar", "plainly", "see", "show", "jellybeans", "jar", "star", "galaxy", "set", "n", "high", "enough", "jellybeans", "even", "outnumber", "particle", "universe", "notice", "rely", "nec", "anywhere", "derivation", "okay", "use", "nonlogical", "assumption", "like", "line", "1", "knowledge", "safety", "philosophical", "payoff", "join", "williamson", "rejecting", "kk", "ground", "skeptical", "argument", "rely", "kk", "might", "disarmed", "example", "skeptic", "might", "argue", "know", "something", "must", "able", "rule", "competing", "alternative", "example", "know", "external", "world", "real", "must", "able", "rule", "possibility", "deceived", "descartes", "demon", "stroud", "1984", "must", "also", "able", "rule", "possibility", "know", "external", "world", "real", "since", "plainly", "alternative", "knowing", "real", "must", "k", "negneg", "kphi", "thus", "kkphi", "greco", "2014", "driving", "premise", "skeptical", "argument", "entail", "kk", "thesis", "seen", "reason", "reject", "skeptical", "argument", "rely", "kk", "course", "example", "different", "skeptical", "tack", "begin", "premise", "victim", "descartes", "demon", "exactly", "evidence", "person", "real", "world", "since", "experiential", "state", "indistinguishable", "evidence", "two", "scenario", "justification", "believing", "one", "rather", "williamson", "2000", "ch", "8", "deploys", "argument", "similar", "reductio", "kk", "premise", "evidence", "real", "world", "demon", "world", "gist", "always", "know", "evidence", "given", "scenario", "much", "always", "know", "know", "indeed", "williamson", "argues", "interesting", "feature", "mind", "subject", "similar", "argument", "including", "appears", "u", "phi", "aphi", "supset", "kaphi", "face", "similar", "reductio", "kphi", "supset", "kk", "phi", "analysis", "criticism", "see", "hawthorne", "2005", "mahtani", "2008", "ramachandran", "2009", "cresto", "2012", "greco", "2014", "5", "fifth", "case", "study", "social", "epistemology", "interesting", "thing", "happen", "study", "whole", "community", "isolated", "individual", "look", "informationsharing", "researcher", "find", "two", "interesting", "result", "first", "sharing", "information", "freely", "actually", "hurt", "community", "ability", "discover", "truth", "second", "mistrust", "member", "community", "lead", "kind", "polarization", "also", "introduce", "new", "tool", "process", "computer", "simulation", "python", "code", "reproduce", "section", "result", "downloaded", "github", "51", "zollman", "effect", "imagine", "two", "treatment", "medical", "condition", "one", "treatment", "old", "efficacy", "well", "known", "5", "chance", "curing", "condition", "given", "case", "treatment", "new", "might", "slightly", "better", "slightly", "worse", "501", "chance", "success", "else", "499", "researcher", "sure", "yet", "present", "doctor", "wary", "new", "treatment", "others", "optimistic", "try", "patient", "others", "stick", "old", "way", "happens", "optimist", "right", "new", "treatment", "superior", "501", "chance", "success", "new", "treatment", "superiority", "eventually", "emerge", "consensus", "within", "community", "data", "performance", "gathered", "shared", "become", "clear", "time", "new", "treatment", "slightly", "better", "necessarily", "possible", "trying", "new", "treatment", "hit", "string", "bad", "luck", "initial", "study", "may", "get", "run", "lessthanstellar", "result", "accurately", "reflect", "new", "treatment", "superiority", "slightly", "better", "traditional", "treatment", "might", "show", "mettle", "right", "away", "optimist", "may", "abandon", "chance", "prove", "one", "way", "mitigate", "danger", "limit", "flow", "information", "medical", "community", "following", "zollman", "2007", "let", "demonstrate", "simulation", "create", "network", "doctor", "initial", "credence", "new", "treatment", "superior", "credence", "5", "try", "new", "treatment", "others", "stick", "old", "one", "doctor", "connected", "line", "share", "result", "everyone", "update", "whatever", "result", "see", "using", "bayes", "theorem", "122", "consider", "network", "different", "size", "3", "10", "doctor", "try", "three", "different", "network", "shape", "either", "complete", "network", "wheel", "cycle", "three", "network", "configuration", "illustrated", "6", "doctor", "conjecture", "cycle", "prove", "reliable", "doctor", "get", "unlucky", "string", "misleading", "result", "least", "damage", "sharing", "result", "might", "discourage", "two", "neighbour", "learning", "truth", "others", "network", "may", "keep", "investigating", "ultimately", "learn", "truth", "new", "treatment", "superiority", "wheel", "vulnerable", "accidental", "misinformation", "however", "complete", "network", "vulnerable", "detail", "initially", "doctor", "assigned", "random", "credence", "new", "treatment", "superior", "chosen", "uniformly", "0", "1", "interval", "credence", "5", "try", "new", "treatment", "1000", "patient", "number", "success", "randomly", "determined", "performing", "1000", "flip", "virtual", "coin", "probability", "501", "head", "successful", "treatment", "doctor", "share", "result", "neighbour", "update", "bayes", "theorem", "data", "available", "another", "round", "experimenting", "sharing", "updating", "followed", "another", "community", "reach", "consensus", "consensus", "achieved", "either", "two", "way", "either", "everyone", "learns", "truth", "new", "treatment", "superior", "achieving", "high", "credence", "99", "say", "alternatively", "everyone", "might", "reach", "credence", "5", "lower", "new", "treatment", "one", "experiment", "impossible", "make", "comeback", "happens", "run", "simulation", "10000", "time", "shape", "network", "number", "doctor", "affect", "often", "community", "find", "truth", "first", "factor", "zollman", "effect", "le", "connected", "network", "likely", "find", "truth", "probability", "discovering", "truth", "depends", "network", "configuration", "number", "doctor", "notice", "bigger", "community", "likely", "find", "truth", "bigger", "le", "connected", "network", "better", "insulated", "misleading", "result", "doctor", "bound", "get", "data", "reflect", "true", "character", "new", "treatment", "happens", "misleading", "result", "risk", "polluting", "community", "misinformation", "discouraging", "others", "experimenting", "new", "treatment", "people", "network", "likely", "misleading", "result", "swamped", "accurate", "representative", "result", "others", "fewer", "people", "see", "misleading", "result", "fewer", "people", "misled", "animated", "pair", "simulation", "illustrate", "first", "effect", "set", "six", "doctor", "starting", "credence", "even", "spread", "network", "3", "4", "5", "6", "7", "8", "also", "gave", "sequence", "random", "data", "connection", "network", "different", "case", "make", "difference", "cycle", "learns", "truth", "complete", "network", "go", "dark", "early", "abandoning", "novel", "treatment", "entirely", "26", "iteration", "two", "network", "identical", "prior", "encounter", "identical", "evidence", "one", "discovers", "truth", "alternative", "link", "video", "save", "cycle", "network", "doctor", "start", "8", "credence", "bottom", "left", "start", "optimistic", "enough", "keep", "going", "group", "encounter", "initial", "string", "dismaying", "result", "complete", "network", "however", "receive", "much", "negative", "evidence", "early", "give", "almost", "right", "away", "optimism", "overwhelmed", "negative", "finding", "many", "neighbour", "whereas", "cycle", "expose", "le", "discouraging", "evidence", "giving", "time", "keep", "experimenting", "novel", "treatment", "ultimately", "winning", "neighbour", "rosenstock", "bruner", "connor", "2017", "put", "sometimes", "le", "come", "sharing", "result", "scientific", "inquiry", "important", "effect", "often", "present", "big", "enough", "worry", "actual", "practice", "rosenstock", "bruner", "connor", "argue", "zollman", "effect", "afflicts", "epistemically", "hard", "problem", "difference", "two", "treatment", "hard", "discern", "data", "zollman", "effect", "concern", "new", "treatment", "much", "noticeably", "superior", "old", "one", "say", "7", "chance", "success", "rather", "501", "imagined", "little", "chance", "superiority", "going", "unnoticed", "rosenstock", "bruner", "connor", "rerun", "simulation", "different", "value", "epsilon", "increase", "probability", "success", "afforded", "new", "treatment", "held", "epsilon", "fixed", "001", "501", "5", "let", "vary", "1", "simplicity", "consider", "complete", "network", "versus", "cycle", "time", "hold", "number", "doctor", "fixed", "10", "number", "trial", "round", "continues", "1000", "zollman", "effect", "vanishes", "difference", "efficacy", "two", "treatment", "increase", "observe", "zollman", "effect", "shrink", "epsilon", "grows", "fact", "visible", "025", "simulation", "rosenstock", "bruner", "connor", "also", "run", "variation", "show", "medical", "community", "much", "larger", "doctor", "gather", "much", "larger", "sample", "sharing", "zollman", "effect", "vanishes", "becomes", "unlikely", "unrepresentative", "sample", "arise", "discourage", "whole", "community", "real", "harm", "sharing", "data", "freely", "natural", "question", "often", "realworld", "research", "community", "face", "kind", "hard", "problem", "zollman", "effect", "real", "concern", "rosenstock", "bruner", "connor", "acknowledge", "laboratory", "experiment", "found", "similar", "effect", "limiting", "communication", "subject", "lead", "improved", "epistemic", "outcome", "also", "stress", "zollman", "effect", "robust", "requiring", "fairly", "specific", "circumstance", "arise", "small", "epsilon", "small", "research", "community", "nottoolarge", "sample", "size", "since", "model", "simple", "idealized", "lack", "robustness", "give", "u", "pause", "argue", "likely", "applicability", "realworld", "scenario", "52", "mistrust", "polarization", "let", "switch", "different", "use", "epistemic", "network", "model", "far", "doctor", "updated", "data", "mistrust", "one", "another", "natural", "le", "full", "faith", "whose", "opinion", "differ", "seem", "gone", "astray", "somewhere", "even", "view", "may", "illicitly", "influenced", "research", "maybe", "doctor", "take", "data", "shared", "others", "face", "value", "suppose", "instead", "discount", "especially", "source", "viewpoint", "differs", "greatly", "connor", "weatherall", "2018", "weatherall", "connor", "forthcoming", "explore", "possibility", "find", "lead", "polarization", "instead", "community", "reaching", "consensus", "doctor", "community", "may", "abandon", "new", "treatment", "even", "others", "conclude", "superior", "example", "animated", "doctor", "blue", "credence", "5", "experiment", "new", "treatment", "sharing", "result", "everyone", "doctor", "green", "credence", "5", "still", "persuadable", "still", "trust", "blue", "doctor", "enough", "update", "resultsthough", "discount", "result", "greater", "difference", "opinion", "doctor", "generated", "finally", "red", "doctor", "ignore", "result", "entirely", "far", "blue", "doctor", "trust", "example", "polarization", "connorweatherall", "model", "alternative", "link", "video", "simulation", "reach", "point", "green", "doctor", "unpersuadable", "skeptic", "red", "highly", "confident", "believer", "blue", "blue", "become", "confident", "unlikely", "ever", "move", "close", "enough", "red", "get", "ear", "reached", "stable", "state", "polarization", "often", "polarization", "occur", "depends", "size", "community", "rate", "mistrust", "program", "model", "decide", "much", "one", "doctor", "discount", "another", "data", "given", "difference", "opinion", "rate", "mistrust", "adjustable", "parameter", "model", "two", "factorscommunity", "size", "rate", "mistrustaffect", "probability", "polarization", "note", "consider", "complete", "network", "probability", "polarization", "depends", "community", "size", "rate", "mistrust", "doctor", "inclined", "mistrust", "one", "another", "likely", "end", "polarized", "surprise", "larger", "community", "also", "disposed", "polarize", "connor", "weatherall", "explain", "doctor", "likely", "strong", "skeptic", "present", "start", "inquiry", "doctor", "credence", "well", "5", "doctor", "tend", "ignore", "report", "optimist", "experimenting", "new", "treatment", "anchor", "skeptical", "segment", "population", "far", "glossed", "important", "detail", "connor", "weatherall", "model", "discounting", "work", "doctor", "update", "discounted", "evidence", "dr", "x", "report", "data", "e", "dr", "simply", "conditionalize", "e", "would", "mean", "take", "x", "report", "face", "value", "compute", "updated", "credence", "p", "h", "new", "treatment", "superiority", "take", "weighted", "average", "p", "h", "mid", "e", "p", "h", "mid", "neg", "e", "procedure", "famous", "variation", "conditionalization", "known", "jeffrey", "conditionalization", "jeffrey", "conditionalization", "given", "prior", "probability", "assignment", "p", "hmid", "e", "p", "hmid", "neg", "e", "new", "unconditional", "probability", "assignment", "h", "upon", "learning", "e", "level", "certainty", "p", "e", "p", "h", "p", "h", "mid", "e", "p", "e", "p", "h", "mid", "neg", "e", "p", "neg", "e", "formula", "look", "lot", "like", "law", "total", "probability", "121", "crucial", "difference", "weight", "weighted", "average", "p", "e", "p", "neg", "e", "instead", "p", "e", "p", "neg", "e", "updated", "alreadydiscounted", "probability", "assigns", "x", "report", "negation", "connor", "weatherall", "2018", "suggest", "natural", "formula", "computing", "p", "e", "p", "neg", "e", "go", "note", "choice", "formula", "crucial", "polarization", "effect", "mistrust", "necessarily", "introduce", "possibility", "polarization", "mistrust", "sufficiently", "strong", "greater", "10", "figure", "point", "agent", "trust", "difference", "opinion", "great", "otherwise", "skeptic", "would", "never", "ignore", "optimistic", "colleague", "entirely", "eventually", "encouraging", "report", "illustrates", "general", "issue", "update", "rule", "like", "jeffrey", "conditionalization", "apply", "first", "need", "determine", "new", "probability", "assign", "evidence", "determine", "new", "probability", "proposition", "essential", "bit", "input", "something", "rule", "sort", "loose", "end", "formal", "system", "something", "left", "u", "user", "model", "discussion", "epistemological", "significance", "point", "see", "field", "1978", "christensen", "1992", "different", "formal", "approach", "polarization", "see", "dorst", "2020", "internet", "resource", "work", "network", "epistemology", "see", "zollman", "2013", "43", "entry", "social", "epistemology", "reference", "therein", "formal", "project", "social", "epistemology", "include", "work", "relationship", "social", "individual", "rationality", "mayowilson", "zollman", "danks", "2011", "judgment", "aggregationopinion", "pooling", "genest", "zidek", "1986", "list", "pettit", "2002", "russell", "hawthorne", "buchak", "2015", "learning", "belief", "others", "easwaran", "et", "al", "2016", "bradley", "2018", "social", "benefit", "competing", "update", "rule", "conditionalization", "vs", "inference", "best", "explanation", "douven", "wenmackers", "2017", "pettigrew", "ms", "internet", "resource", "6", "application", "outside", "epistemology", "tool", "like", "probability", "theory", "epistemic", "logic", "numerous", "us", "many", "area", "philosophy", "besides", "epistemology", "look", "briefly", "example", "make", "decision", "whether", "god", "exists", "hypothetical", "discourse", "like", "ifthen", "mean", "61", "decision", "theory", "keep", "reading", "section", "stop", "go", "something", "else", "depends", "might", "gain", "continuing", "reading", "odds", "gain", "surpass", "gain", "something", "else", "instead", "decision", "theory", "weighs", "consideration", "determine", "choice", "best", "see", "weighing", "work", "let", "start", "simple", "example", "betting", "outcome", "dieroll", "particular", "let", "suppose", "5", "6", "win", "19", "outcome", "loses", "10", "take", "bet", "represent", "choice", "face", "form", "table", "roll", "14", "roll", "5", "6", "bet", "10", "19", "bet", "0", "0", "far", "taking", "bet", "look", "pretty", "good", "stand", "gain", "almost", "twice", "much", "stand", "lose", "table", "show", "however", "twice", "likely", "lose", "win", "23", "vs", "13", "let", "add", "information", "roll", "14", "roll", "5", "6", "bet", "substack", "10", "p23", "substack", "19", "p13", "bet", "substack", "0", "p23", "substack", "0", "p13", "see", "potential", "downside", "betting", "namely", "losing", "10", "outweighed", "potential", "upside", "stand", "win", "quite", "twice", "lose", "probability", "losing", "twice", "much", "formally", "express", "line", "thinking", "follows", "10", "times", "23", "19", "times", "13", "13", "0", "word", "potential", "loss", "gain", "weighed", "respective", "probability", "sum", "total", "fails", "exceed", "0", "0", "expect", "bet", "betting", "quite", "measure", "abstaining", "example", "basic", "idea", "core", "decision", "theory", "still", "long", "way", "satisfactory", "one", "thing", "calculation", "assumes", "money", "everything", "surely", "suppose", "need", "exactly", "29", "get", "bus", "home", "night", "10", "bill", "pocket", "use", "even", "cheapest", "drink", "casino", "bar", "11", "losing", "10", "really", "much", "worse", "keeping", "ityou", "might", "well", "broke", "either", "way", "gaining", "19", "worth", "lot", "get", "bus", "back", "home", "sleep", "rough", "night", "consider", "much", "various", "dollaramounts", "worth", "losing", "10", "worth", "losing", "0", "though", "gaining", "19", "much", "much", "valuable", "capture", "fact", "introduce", "function", "u", "represents", "utility", "various", "possible", "outcome", "u", "10", "approx", "u", "0", "u", "19", "gg", "u", "0", "exactly", "much", "gaining", "19", "worth", "u", "19", "ldots", "exactly", "actually", "answer", "question", "set", "scale", "first", "example", "suppose", "want", "know", "exactly", "much", "value", "gain", "19", "scale", "range", "gaining", "nothing", "gaining", "100", "set", "u", "0", "0", "u", "100", "1", "scale", "range", "0", "1", "calculate", "u", "19", "asking", "much", "would", "willing", "risk", "gain", "100", "instead", "19", "suppose", "choice", "handed", "19", "string", "attached", "vs", "offered", "free", "gamble", "pay", "100", "win", "nothing", "otherwise", "high", "would", "probability", "winning", "100", "take", "chance", "instead", "guaranteed", "19", "given", "stakemaking", "home", "night", "vs", "sleeping", "roughyou", "probably", "accept", "much", "risk", "chance", "full", "100", "instead", "guaranteed", "19", "let", "say", "accept", "01", "risk", "ie", "chance", "winning", "full", "100", "would", "least", "99", "trade", "guaranteed", "19", "chance", "full", "100", "well", "scale", "gaining", "0", "gaining", "100", "value", "gaining", "19", "quite", "highly", "99", "1", "method", "measuring", "utility", "discovered", "popularized", "von", "neumann", "morgenstern", "1944", "though", "essentially", "idea", "previously", "discovered", "ramsey", "1964", "1926", "full", "decision", "theory", "relies", "two", "function", "p", "u", "probability", "function", "p", "reflects", "likely", "think", "various", "possible", "outcome", "action", "obtain", "u", "represents", "desirable", "outcome", "faced", "choice", "two", "possible", "course", "action", "a", "neg", "a", "two", "possible", "state", "world", "might", "s", "neg", "s", "four", "possible", "outcome", "o_1", "ldots", "o_4", "example", "bet", "1", "coinflip", "coming", "head", "come", "head", "outcome", "o_1", "obtains", "win", "1", "instead", "come", "tail", "outcome", "o_2", "obtains", "lose", "1", "general", "shape", "situation", "thus", "s", "neg", "s", "a", "substack", "u", "o_1", "p", "substack", "u", "o_2", "p", "neg", "neg", "a", "substack", "u", "o_3", "p", "substack", "u", "o_4", "p", "neg", "weigh", "probability", "utility", "define", "notion", "expected", "utility", "definition", "expected", "utility", "act", "a", "eu", "defined", "eu", "p", "u", "o_1", "p", "neg", "u", "o_2", "expected", "utility", "act", "neg", "a", "eu", "neg", "likewise", "eu", "neg", "p", "u", "o_3", "p", "neg", "u", "o_4", "expected", "utility", "faced", "decision", "problem", "time", "chose", "option", "a", "long", "run", "could", "expect", "average", "utility", "approximately", "eu", "idea", "extends", "case", "two", "way", "thing", "could", "turn", "simply", "adding", "column", "table", "multiplyingsumming", "way", "across", "two", "possible", "action", "add", "row", "finally", "decision", "theory", "culminates", "following", "norm", "expected", "utility", "maximization", "choose", "option", "highest", "expected", "utility", "case", "tie", "either", "option", "acceptable", "given", "much", "argument", "rule", "except", "weighs", "desirability", "possible", "outcome", "probability", "obtain", "various", "way", "one", "might", "develop", "weighing", "idea", "however", "one", "elaborated", "due", "savage", "1954", "considered", "classicorthodox", "approach", "social", "science", "like", "economics", "psychology", "philosopher", "however", "tend", "prefer", "variation", "savage", "basic", "approach", "either", "evidential", "decision", "theory", "developed", "jeffrey", "1965", "form", "causal", "decision", "theory", "see", "entry", "gibbard", "harper", "1978", "skyrms", "1980", "lewis", "1981", "joyce", "1999", "approach", "agree", "broad", "idea", "correct", "decision", "rule", "weighs", "probability", "utility", "linear", "fashion", "multiply", "add", "see", "entry", "expected", "utility", "different", "approach", "recently", "pioneered", "buchak", "2013", "2014", "hold", "tolerance", "risk", "throw", "nonlinear", "wrench", "equation", "however", "see", "also", "steele", "2007", "taking", "account", "people", "cognitive", "limitation", "long", "thought", "require", "departure", "traditional", "linear", "model", "kahneman", "tversky", "1979", "payne", "bettman", "johnson", "1993", "gigerenzer", "todd", "group", "1999", "weirich", "2004", "62", "existence", "god", "finetuning", "mathematical", "theory", "probability", "decision", "emerged", "together", "correspondence", "blaise", "pascale", "pierre", "de", "fermat", "mid17th", "century", "pascal", "went", "apply", "theological", "question", "developing", "famous", "wager", "argument", "see", "entry", "pascal", "wager", "belief", "god", "probability", "theory", "commonly", "appears", "discussion", "argument", "theism", "especially", "argument", "design", "though", "darwin", "generally", "thought", "toppled", "theistic", "appeal", "biological", "design", "newer", "finding", "cosmology", "physic", "seem", "support", "new", "probabilistic", "argument", "god", "existence", "development", "universe", "big", "bang", "present", "form", "depended", "two", "factor", "law", "physic", "initial", "condition", "time", "big", "bang", "factor", "appear", "carefully", "arranged", "universe", "would", "capable", "supporting", "life", "certain", "constant", "physical", "law", "slightly", "different", "intelligent", "life", "would", "never", "able", "evolve", "example", "force", "bind", "nucleus", "atom", "together", "slightly", "stronger", "weaker", "hydrogen", "would", "exist", "would", "carbon", "oxygen", "element", "available", "form", "complex", "molecule", "organism", "similarly", "expansion", "speed", "big", "bang", "slightly", "different", "universe", "would", "either", "simply", "collapsed", "back", "soon", "big", "bang", "else", "dispersed", "diffuse", "dust", "star", "planet", "would", "never", "formed", "rees", "1999", "finding", "point", "new", "kind", "design", "argument", "one", "untouched", "advent", "evolutionary", "theory", "evolution", "might", "explain", "design", "find", "organic", "world", "explains", "fact", "cosmos", "appears", "finetuned", "allow", "existence", "intelligent", "life", "apparently", "cosmos", "actually", "finetuned", "creator", "deliberately", "designed", "would", "contain", "intelligent", "life", "designer", "finetuning", "cosmos", "would", "massively", "improbable", "coincidence", "make", "argument", "rigorous", "often", "formulated", "probabilistic", "term", "following", "sober", "2005", "adopt", "simple", "modest", "formulation", "let", "f", "evidence", "universe", "finetuned", "described", "let", "d", "design", "hypothesis", "hypothesis", "universe", "created", "intelligent", "designer", "aim", "creating", "intelligent", "life", "argument", "run", "p", "fmid", "p", "fmid", "neg", "general", "p", "emid", "h", "p", "emid", "neg", "h", "e", "support", "h", "neg", "h", "f", "support", "d", "neg", "d", "argument", "plainly", "valid", "discussion", "focus", "premise", "rationale", "behind", "1", "p", "fmid", "neg", "quite", "small", "since", "many", "way", "physical", "law", "initial", "constant", "could", "almost", "would", "yielded", "universe", "inhospitable", "life", "without", "designer", "ensure", "hospitable", "constant", "condition", "hospitable", "outcome", "would", "massively", "improbable", "p", "fmid", "hand", "fairly", "high", "envisioned", "designer", "aim", "creating", "universe", "create", "life", "see", "rationale", "2", "recall", "discussion", "confirmation", "theory", "12", "according", "definition", "confirmation", "evidence", "confirms", "hypothesis", "case", "p", "hmid", "e", "p", "h", "bayes", "theorem", "tell", "u", "equivalent", "p", "emid", "h", "p", "e", "likewise", "e", "disconfirms", "neg", "h", "case", "p", "e", "p", "emid", "neg", "h", "prove", "p", "emid", "h", "p", "e", "p", "e", "p", "emid", "neg", "h", "e", "confirms", "h", "disconfirms", "neg", "h", "amount", "e", "supporting", "h", "neg", "h", "crucial", "note", "however", "e", "supporting", "h", "neg", "h", "mean", "learn", "e", "h", "becomes", "probable", "neg", "h", "mean", "e", "raise", "probability", "h", "decrease", "probability", "neg", "h", "h", "improbable", "begin", "e", "might", "increase", "probability", "enough", "make", "probable", "neg", "h", "formulation", "argument", "modest", "aim", "show", "f", "evidence", "d", "neg", "d", "make", "claim", "strong", "evidence", "whether", "leave", "u", "theist", "atheist", "end", "sober", "2005", "yet", "critic", "argue", "even", "modest", "argument", "unsound", "consider", "four", "line", "criticism", "one", "line", "criticism", "appeal", "socalled", "anthropic", "consideration", "idea", "finding", "consequence", "nature", "observer", "thus", "reflect", "something", "u", "rather", "phenomenon", "discussion", "example", "might", "notice", "whenever", "observe", "physical", "object", "observation", "happens", "awake", "conclude", "physical", "object", "exist", "awake", "feature", "observation", "reflects", "something", "awake", "make", "observation", "likewise", "critic", "argue", "observe", "cosmos", "feature", "necessary", "support", "intelligent", "life", "discovery", "universe", "finetuned", "reflects", "limitation", "u", "could", "observe", "opposite", "mcmullin", "1993", "sober", "2005", "proponent", "finetuning", "argument", "respond", "inability", "observe", "something", "render", "observation", "contrary", "uninformative", "example", "leslie", "1989", "note", "someone", "put", "expert", "firing", "squad", "observe", "survive", "since", "alive", "make", "observation", "yet", "unlikely", "event", "survive", "strong", "evidence", "squad", "missed", "design", "expert", "firing", "squad", "rarely", "miss", "accident", "sober", "2005", "responds", "firingsquad", "survivor", "indeed", "evidence", "different", "basis", "one", "available", "proponent", "design", "argument", "see", "monton", "2006", "sober", "2009", "discussion", "different", "line", "criticism", "object", "p", "fmid", "neg", "low", "even", "without", "designer", "finetuning", "discovery", "inevitable", "universe", "one", "infinite", "sequence", "universe", "oscillating", "bang", "crunch", "back", "bang", "new", "set", "constant", "initial", "condition", "emerging", "bang", "wheeler", "1973", "leslie", "1989", "sooner", "later", "endless", "cycle", "universal", "reboots", "bound", "hit", "upon", "lifesupporting", "configuration", "constant", "initial", "condition", "p", "fmid", "neg", "may", "even", "equal", "1", "contra", "premise", "1", "could", "know", "endless", "cycle", "universe", "tricky", "question", "crucial", "piece", "evidence", "might", "explains", "universe", "finetuned", "may", "true", "design", "hypothesis", "d", "hacking", "1987", "counter", "oscillating", "universe", "ensure", "universe", "point", "sequence", "capable", "supporting", "life", "make", "likely", "universe", "would", "time", "big", "bang", "still", "innumerably", "lifeunfriendly", "way", "thing", "could", "started", "equally", "likely", "designer", "ensure", "lifefriendly", "beginning", "rolling", "pair", "dice", "ensures", "snakeeyes", "dice", "coming", "1", "turn", "point", "whatever", "roll", "turn", "still", "extremely", "unlikely", "turn", "way", "53rd", "roll", "come", "snakeeyes", "hardly", "inevitable", "fact", "quite", "improbable", "1", "36", "chance", "hacking", "suggests", "different", "sort", "multiple", "universe", "hypothesis", "escape", "problem", "carter", "1974", "hypothesis", "possible", "big", "bangtype", "universe", "exist", "side", "side", "rather", "oscillating", "sequence", "hacking", "suggests", "follows", "deductively", "universe", "exist", "p", "fmid", "neg", "come", "1", "white", "2000", "counter", "fallacy", "appeal", "wheeler", "model", "afflicts", "appeal", "carter", "model", "even", "multitude", "universe", "existing", "side", "side", "one", "one", "lifefriendly", "parameter", "third", "line", "criticism", "attack", "rationale", "assigning", "low", "number", "p", "fmid", "neg", "complaint", "rationale", "actually", "make", "p", "fmid", "neg", "0", "also", "assigns", "probability", "0", "many", "intuitively", "much", "probable", "way", "universe", "might", "turned", "rationale", "low", "p", "fmid", "neg", "go", "something", "like", "take", "apparently", "finetuned", "parameter", "universe", "like", "expansion", "speed", "speed", "exactly", "9", "10", "kmsc", "let", "pretend", "universe", "able", "support", "life", "given", "could", "speed", "0", "kmsc", "100", "kmsc", "1000000", "kmsc", "tothat", "would", "end", "narrow", "910", "kmsc", "window", "extremely", "unlikely", "happen", "without", "divine", "guidance", "objection", "go", "could", "said", "much", "larger", "range", "like", "101", "10", "10", "kmsc", "window", "even", "large", "range", "drop", "infinite", "bucket", "speed", "could", "obtained", "0", "entire", "positive", "real", "line", "fact", "finite", "range", "effectively", "0", "infinityindeed", "really", "0", "standard", "way", "measuring", "thing", "colyvan", "garfield", "priest", "2005", "even", "universe", "needed", "coarse", "tuning", "support", "life", "ie", "even", "would", "supported", "life", "given", "massively", "broad", "yet", "finite", "range", "condition", "parallel", "premise", "1", "could", "justified", "rationale", "corresponding", "coarsetuning", "argument", "design", "offered", "mcgrew", "mcgrew", "vestrup", "2001", "collins", "2009", "point", "uncomfortable", "consequence", "objection", "finetuning", "argument", "would", "compelling", "neg", "d", "lifefriendly", "imagine", "law", "physic", "permitted", "finite", "range", "possible", "expansion", "speed", "say", "0100", "kms", "speed", "910", "kms", "required", "support", "life", "premise", "1", "would", "hold", "finetuning", "argument", "would", "succeed", "p", "fmid", "neg", "1100", "p", "fmid", "presumably", "much", "higher", "maybe", "even", "1", "imagine", "possible", "range", "much", "larger", "say", "0", "10", "10", "kms", "argument", "becomes", "even", "stronger", "p", "fmid", "neg", "110", "10", "upper", "limit", "possible", "expansion", "speed", "increase", "argument", "becomes", "stronger", "strongeruntil", "limit", "becomes", "infinite", "point", "argument", "fails", "according", "present", "objection", "63", "meaning", "ifthen", "hypothetical", "discourse", "puzzling", "connection", "reality", "suppose", "assert", "gdp", "continues", "decline", "unemployment", "rise", "gdp", "continue", "decline", "instead", "holding", "steady", "said", "true", "false", "obvious", "since", "statement", "tested", "world", "obvious", "way", "gdp", "continued", "decline", "yet", "unemployment", "fallen", "statement", "would", "tested", "would", "failed", "gdp", "held", "steady", "test", "assertion", "put", "working", "propositional", "logic", "often", "translate", "ordinary", "then", "statement", "using", "material", "conditional", "supset", "probability", "supset", "statement", "often", "exceeds", "corresponding", "then", "statement", "example", "improbable", "win", "olympic", "gold", "medal", "diving", "g", "train", "five", "hour", "day", "t", "olympic", "diver", "retire", "time", "age", "yet", "p", "supset", "g", "quite", "high", "simple", "reason", "supset", "g", "equivalent", "neg", "vee", "g", "neg", "t", "probable", "training", "olympic", "diving", "one", "minute", "day", "much", "le", "five", "hour", "even", "swim", "hard", "accept", "supset", "good", "model", "then", "though", "philosopher", "nevertheless", "think", "correct", "grice", "1989", "jackson", "1987", "could", "introduce", "new", "connective", "different", "semantics", "supset", "would", "better", "striking", "theorem", "discovered", "lewis", "1976", "suggests", "theorem", "relies", "assumption", "posited", "stalnaker", "1970", "probability", "a", "b", "conditional", "probability", "p", "bmid", "let", "use", "rightarrow", "b", "shorthand", "english", "a", "b", "stalnaker", "hypothesis", "p", "rightarrow", "b", "p", "bmid", "proposition", "a", "b", "probability", "function", "p", "p", "neq", "0", "stalnaker", "hypothesis", "might", "seem", "obvious", "first", "even", "tautological", "p", "bmid", "probability", "proposition", "bmid", "a", "shorthand", "b", "true", "a", "common", "misconception", "newcomer", "probability", "theory", "one", "lewis", "show", "lead", "disastrous", "result", "think", "bmid", "a", "complex", "proposition", "built", "sentence", "a", "b", "connective", "mid", "probability", "theory", "go", "pot", "see", "technical", "supplement", "proof", "theorem", "lewis", "triviality", "theorem", "stalnaker", "hypothesis", "true", "p", "bmid", "p", "b", "proposition", "a", "b", "p", "neq", "0", "1", "p", "b", "0", "apparently", "propositional", "connective", "rightarrow", "obey", "stalnaker", "hypothesis", "one", "every", "proposition", "would", "independent", "every", "except", "thing", "absolutely", "certain", "surely", "fact", "relevant", "others", "one", "thing", "tell", "u", "right", "way", "read", "p", "bmid", "probability", "sentence", "bmid", "a", "instead", "twoplace", "function", "syntax", "p", "bmid", "misleading", "might", "clearly", "written", "p", "b", "standard", "notation", "twoplace", "function", "like", "f", "x", "x2y2", "troubling", "lesson", "face", "uncomfortable", "choice", "either", "thing", "proposition", "rightarrow", "b", "probability", "proposition", "rightarrow", "b", "always", "match", "p", "bmid", "first", "option", "would", "seem", "make", "assertion", "form", "then", "peculiar", "exception", "compositionality", "natural", "language", "semantics", "see", "edgington", "2000", "second", "option", "counterintuitive", "also", "apparently", "counter", "empirical", "evidence", "people", "ordinarily", "take", "p", "rightarrow", "b", "p", "bmid", "douven", "dietz", "2011", "particularly", "striking", "thing", "problem", "robust", "many", "related", "theorem", "proved", "using", "probability", "theory", "h\u00e1jek", "1989", "edgington", "1995", "bradley", "2000", "similar", "result", "also", "emerged", "completely", "independent", "formal", "framework", "theory", "belief", "revision", "belief", "revision", "theory", "represents", "belief", "sentence", "propositional", "logic", "a", "supset", "b", "neg", "wedge", "neg", "b", "full", "corpus", "belief", "set", "sentence", "call", "k", "confused", "sentential", "operator", "k", "epistemic", "logic", "41", "importantly", "assume", "k", "contains", "everything", "entailed", "belief", "a", "supset", "b", "k", "b", "example", "course", "real", "people", "believe", "everything", "belief", "entail", "help", "keep", "thing", "simple", "make", "assumption", "think", "idealization", "theorizing", "belief", "look", "like", "perfect", "logician", "notice", "probability", "theory", "similar", "feature", "encoded", "axiom", "2", "epistemic", "logic", "k", "axiom", "nec", "rule", "together", "similar", "effect", "main", "aim", "belief", "revision", "theory", "say", "revise", "belief", "learn", "new", "information", "suppose", "learn", "existence", "new", "planet", "algernon", "k", "change", "learn", "new", "fact", "a", "long", "a", "contradict", "existing", "belief", "standard", "view", "add", "a", "k", "along", "everything", "follows", "logically", "member", "k", "a", "together", "call", "new", "set", "belief", "k", "a", "add", "a", "k", "along", "follows", "logically", "alchourr\u00f3n", "g\u00e4rdenfors", "makinson", "1985", "a", "contradict", "existing", "belief", "k", "a", "since", "would", "inconsistent", "remove", "existing", "belief", "make", "room", "a", "luckily", "purpose", "worry", "work", "consider", "case", "a", "consistent", "k", "case", "k", "a", "suppose", "want", "add", "new", "connective", "rightarrow", "language", "represent", "then", "believe", "sentence", "form", "rightarrow", "b", "classic", "answer", "come", "idea", "ramsey", "decide", "whether", "accept", "rightarrow", "b", "temporarily", "adding", "a", "stock", "belief", "seeing", "whether", "b", "follows", "ramsey", "1990", "1929", "idea", "yield", "principle", "called", "ramsey", "test", "ramsey", "test", "k", "contains", "rightarrow", "b", "k", "a", "contains", "b", "k", "contains", "neg", "rightarrow", "b", "k", "a", "contains", "neg", "b", "word", "accept", "rightarrow", "b", "adding", "a", "stock", "belief", "brings", "b", "instead", "adding", "a", "brings", "neg", "b", "reject", "conditional", "etlin", "2009", "plausible", "ramsey", "test", "g\u00e4rdenfors", "1986", "show", "hold", "unless", "belief", "absurdly", "opinionated", "state", "result", "somewhat", "informally", "see", "technical", "supplement", "somewhat", "informal", "proof", "theorem", "g\u00e4rdenfors", "triviality", "theorem", "long", "two", "proposition", "a", "b", "k", "agnostic", "a", "supset", "b", "supset", "neg", "b", "ramsey", "test", "hold", "apparently", "much", "propositional", "connective", "rightarrow", "obey", "stalnaker", "hypothesis", "probability", "theory", "none", "obey", "ramsey", "test", "belief", "revision", "theory", "either", "whether", "approach", "epistemology", "using", "probability", "flatout", "belief", "problem", "arises", "conclude", "conditionals", "factual", "content", "hotly", "contested", "question", "entry", "conditionals"]}