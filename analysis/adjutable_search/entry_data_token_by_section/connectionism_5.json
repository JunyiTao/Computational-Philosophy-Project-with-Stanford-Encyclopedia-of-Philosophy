{
    "main_text": "Connectionist Representation\n6. Connectionist Representation\n\nConnectionist models provide a new paradigm for understanding how\ninformation might be represented in the brain. A seductive but naive\nidea is that single neurons (or tiny neural bundles) might be devoted\nto the representation of each thing the brain needs to record. For\nexample, we may imagine that there is a grandmother neuron that fires\nwhen we think about our grandmother. However, such local\nrepresentation is not likely. There is good evidence that our\ngrandmother thought involves complex patterns of activity distributed\nacross relatively large parts of cortex.\n\nIt is interesting to note that distributed, rather than local\nrepresentations on the hidden units are the natural products of\nconnectionist training methods. The activation patterns that appear on\nthe hidden units while NETtalk processes text serve as an example.\nAnalysis reveals that the net learned to represent such categories as\nconsonants and vowels, not by creating one unit active for consonants\nand another for vowels, but rather in developing two different\ncharacteristic patterns of activity across all the hidden units.\n\nGiven the expectations formed from our experience with local\nrepresentation on the printed page, distributed representation seems\nboth novel and difficult to understand. But the technique exhibits\nimportant advantages. For example, distributed representations,\n(unlike symbols stored in separate fixed memory locations) remain\nrelatively well preserved when parts of the model are destroyed or\noverloaded. More importantly, since representations are coded in\npatterns rather than firings of individual units, relationships\nbetween representations are coded in the similarities and differences\nbetween these patterns. So the internal properties of the\nrepresentation carry information on what it is about (Clark 1993: 19).\nIn contrast, local representation is conventional. No intrinsic\nproperties of the representation (a unit\u2019s firing) determine its\nrelationships to the other symbols. This self-reporting feature of\ndistributed representations promises to resolve a philosophical\nconundrum about meaning. In a symbolic representational scheme, all\nrepresentations are composed out of symbolic atoms (like words in a\nlanguage). Meanings of complex symbol strings may be defined by the\nway they are built up out of their constituents, but what fixes the\nmeanings of the atoms?\n\nConnectionist representational schemes provide an end run around the\npuzzle by simply dispensing with atoms. Every distributed\nrepresentation is a pattern of activity across all the units, so there\nis no principled way to distinguish between simple and complex\nrepresentations. To be sure, representations are composed out of the\nactivities of the individual units. But none of these\n\u201catoms\u201d codes for any symbol. The representations are\nsub-symbolic in the sense that analysis into their components leaves\nthe symbolic level behind.\n\nThe sub-symbolic nature of distributed representation provides a novel\nway to conceive of information processing in the brain. If we model\nthe activity of each neuron with a number, then the activity of the\nwhole brain can be given by a giant vector (or list) of numbers, one\nfor each neuron. Both the brain\u2019s input from sensory systems and\nits output to individual muscle neurons can also be treated as vectors\nof the same kind. So the brain amounts to a vector processor, and the\nproblem of psychology is transformed into questions about which\noperations on vectors account for the different aspects of human\ncognition.\n\nSub-symbolic representation has interesting implications for the\nclassical hypothesis that the brain must contain symbolic\nrepresentations that are similar to sentences of a language. This\nidea, often referred to as the language of thought (or LOT) thesis may\nbe challenged by the nature of connectionist representations. It is\nnot easy to say exactly what the LOT thesis amounts to, but van Gelder\n(1990) offers an influential and widely accepted benchmark for\ndetermining when the brain should be said to contain sentence-like\nrepresentations. It is that when a representation is tokened one\nthereby tokens the constituents of that representation. For example,\nif I write \u201cJohn loves Mary\u201d I have thereby written the\nsentence\u2019s constituents: \u201cJohn\u201d \u201cloves\u201d\nand \u201cMary\u201d. Distributed representations for complex\nexpressions like \u201cJohn loves Mary\u201d can be constructed that\ndo not contain any explicit representation of their parts (Smolensky\n1990). The information about the constituents can be extracted from\nthe representations, but neural network models do not need to\nexplicitly extract this information themselves in order to process it\ncorrectly (Chalmers 1990). This suggests that neural network models\nserve as counterexamples to the idea that the language of thought is a\nprerequisite for human cognition. However, the matter is still a topic\nof lively debate (Fodor 1997).\n\nThe novelty of distributed and superimposed connectionist information\nstorage naturally causes one to wonder about the viability of\nclassical notions of symbolic computation in describing the brain.\nRamsey (1997) argues that though we may attribute symbolic\nrepresentations to neural nets, those attributions do not figure in\nlegitimate explanations of the model\u2019s behavior. This claim is\nimportant because the classical account of cognitive processing, (and\nfolk intuitions) presume that representations play an explanatory role\nin understanding the mind. It has been widely thought that cognitive\nscience requires, by its very nature, explanations that appeal to\nrepresentations (Von Eckardt 2003). If Ramsey is right, the point may\ncut in two different ways. Some may use it to argue for a new and\nnon-classical understanding of the mind, while others would use it to\nargue that connectionism is inadequate since it cannot explain what it\nmust. However, Haybron (2000) argues against Ramsey that there is\nample room for representations with explanatory role in radical\nconnectionist architectures. Roth (2005) makes the interesting point\nthat contrary to first impressions, it may also make perfect sense to\nexplain a net\u2019s behavior by reference to a computer program,\neven if there is no way to discriminate a sequence of steps of the\ncomputation through time.\n\nThe debate concerning the presence of classical representations and a\nlanguage of thought has been clouded by lack of clarity in defining\nwhat should count as the representational \u201cvehicles\u201d in\ndistributed neural models. Shea (2007) makes the point that the\nindividuation of distributed representations should be defined by the\nway activation patterns on the hidden units cluster together. It is\nthe relationships between clustering regions in the space of\npossible activation patterns that carry representational content, not\nthe activations themselves, nor the collection of units responsible\nfor the activation. On this understanding, prospects are improved for\nlocating representational content in neural nets that can be compared\nin nets of different architectures, that is causally involved in\nprocessing, and which overcomes some objections to holistic accounts\nof meaning.\n\nIn a series of papers Horgan and Tienson (1989, 1990) have championed\na view called representations without rules. According to this view\nclassicists are right to think that human brains (and good\nconnectionist models of them) contain explanatorily robust\nrepresentations; but they are wrong to think that those\nrepresentations enter in to hard and fast rules like the steps of a\ncomputer program. The idea that connectionist systems may follow\ngraded or approximate regularities (\u201csoft laws\u201d as Horgan\nand Tienson call them) is intuitive and appealing. However, Aizawa\n(1994) argues that given an arbitrary neural net with a representation\nlevel description, it is always possible to outfit it with hard and\nfast representation-level rules. Guarini (2001) responds that if we\npay attention to notions of rule following that are useful to\ncognitive modeling, Aizawa\u2019s constructions will seem beside the\npoint.\n",
    "section_title": "6. Connectionist Representation",
    "entry_title": "Connectionism",
    "hierarchy_title": "Connectionism || Connectionist Representation",
    "tokenized_text": [
        "connectionist",
        "representation",
        "connectionist",
        "representation",
        "connectionist",
        "model",
        "provide",
        "new",
        "paradigm",
        "understanding",
        "information",
        "might",
        "represented",
        "brain",
        "seductive",
        "naive",
        "idea",
        "single",
        "neuron",
        "tiny",
        "neural",
        "bundle",
        "might",
        "devoted",
        "representation",
        "thing",
        "brain",
        "need",
        "record",
        "example",
        "may",
        "imagine",
        "grandmother",
        "neuron",
        "fire",
        "think",
        "grandmother",
        "however",
        "local",
        "representation",
        "likely",
        "good",
        "evidence",
        "grandmother",
        "thought",
        "involves",
        "complex",
        "pattern",
        "activity",
        "distributed",
        "across",
        "relatively",
        "large",
        "part",
        "cortex",
        "interesting",
        "note",
        "distributed",
        "rather",
        "local",
        "representation",
        "hidden",
        "unit",
        "natural",
        "product",
        "connectionist",
        "training",
        "method",
        "activation",
        "pattern",
        "appear",
        "hidden",
        "unit",
        "nettalk",
        "process",
        "text",
        "serve",
        "example",
        "analysis",
        "reveals",
        "net",
        "learned",
        "represent",
        "category",
        "consonant",
        "vowel",
        "creating",
        "one",
        "unit",
        "active",
        "consonant",
        "another",
        "vowel",
        "rather",
        "developing",
        "two",
        "different",
        "characteristic",
        "pattern",
        "activity",
        "across",
        "hidden",
        "unit",
        "given",
        "expectation",
        "formed",
        "experience",
        "local",
        "representation",
        "printed",
        "page",
        "distributed",
        "representation",
        "seems",
        "novel",
        "difficult",
        "understand",
        "technique",
        "exhibit",
        "important",
        "advantage",
        "example",
        "distributed",
        "representation",
        "unlike",
        "symbol",
        "stored",
        "separate",
        "fixed",
        "memory",
        "location",
        "remain",
        "relatively",
        "well",
        "preserved",
        "part",
        "model",
        "destroyed",
        "overloaded",
        "importantly",
        "since",
        "representation",
        "coded",
        "pattern",
        "rather",
        "firing",
        "individual",
        "unit",
        "relationship",
        "representation",
        "coded",
        "similarity",
        "difference",
        "pattern",
        "internal",
        "property",
        "representation",
        "carry",
        "information",
        "clark",
        "contrast",
        "local",
        "representation",
        "conventional",
        "intrinsic",
        "property",
        "representation",
        "unit",
        "firing",
        "determine",
        "relationship",
        "symbol",
        "selfreporting",
        "feature",
        "distributed",
        "representation",
        "promise",
        "resolve",
        "philosophical",
        "conundrum",
        "meaning",
        "symbolic",
        "representational",
        "scheme",
        "representation",
        "composed",
        "symbolic",
        "atom",
        "like",
        "word",
        "language",
        "meaning",
        "complex",
        "symbol",
        "string",
        "may",
        "defined",
        "way",
        "built",
        "constituent",
        "fix",
        "meaning",
        "atom",
        "connectionist",
        "representational",
        "scheme",
        "provide",
        "end",
        "run",
        "around",
        "puzzle",
        "simply",
        "dispensing",
        "atom",
        "every",
        "distributed",
        "representation",
        "pattern",
        "activity",
        "across",
        "unit",
        "principled",
        "way",
        "distinguish",
        "simple",
        "complex",
        "representation",
        "sure",
        "representation",
        "composed",
        "activity",
        "individual",
        "unit",
        "none",
        "atom",
        "code",
        "symbol",
        "representation",
        "subsymbolic",
        "sense",
        "analysis",
        "component",
        "leaf",
        "symbolic",
        "level",
        "behind",
        "subsymbolic",
        "nature",
        "distributed",
        "representation",
        "provides",
        "novel",
        "way",
        "conceive",
        "information",
        "processing",
        "brain",
        "model",
        "activity",
        "neuron",
        "number",
        "activity",
        "whole",
        "brain",
        "given",
        "giant",
        "vector",
        "list",
        "number",
        "one",
        "neuron",
        "brain",
        "input",
        "sensory",
        "system",
        "output",
        "individual",
        "muscle",
        "neuron",
        "also",
        "treated",
        "vector",
        "kind",
        "brain",
        "amount",
        "vector",
        "processor",
        "problem",
        "psychology",
        "transformed",
        "question",
        "operation",
        "vector",
        "account",
        "different",
        "aspect",
        "human",
        "cognition",
        "subsymbolic",
        "representation",
        "interesting",
        "implication",
        "classical",
        "hypothesis",
        "brain",
        "must",
        "contain",
        "symbolic",
        "representation",
        "similar",
        "sentence",
        "language",
        "idea",
        "often",
        "referred",
        "language",
        "thought",
        "lot",
        "thesis",
        "may",
        "challenged",
        "nature",
        "connectionist",
        "representation",
        "easy",
        "say",
        "exactly",
        "lot",
        "thesis",
        "amount",
        "van",
        "gelder",
        "offer",
        "influential",
        "widely",
        "accepted",
        "benchmark",
        "determining",
        "brain",
        "said",
        "contain",
        "sentencelike",
        "representation",
        "representation",
        "tokened",
        "one",
        "thereby",
        "token",
        "constituent",
        "representation",
        "example",
        "write",
        "john",
        "love",
        "mary",
        "thereby",
        "written",
        "sentence",
        "constituent",
        "john",
        "love",
        "mary",
        "distributed",
        "representation",
        "complex",
        "expression",
        "like",
        "john",
        "love",
        "mary",
        "constructed",
        "contain",
        "explicit",
        "representation",
        "part",
        "smolensky",
        "information",
        "constituent",
        "extracted",
        "representation",
        "neural",
        "network",
        "model",
        "need",
        "explicitly",
        "extract",
        "information",
        "order",
        "process",
        "correctly",
        "chalmers",
        "suggests",
        "neural",
        "network",
        "model",
        "serve",
        "counterexample",
        "idea",
        "language",
        "thought",
        "prerequisite",
        "human",
        "cognition",
        "however",
        "matter",
        "still",
        "topic",
        "lively",
        "debate",
        "fodor",
        "novelty",
        "distributed",
        "superimposed",
        "connectionist",
        "information",
        "storage",
        "naturally",
        "cause",
        "one",
        "wonder",
        "viability",
        "classical",
        "notion",
        "symbolic",
        "computation",
        "describing",
        "brain",
        "ramsey",
        "argues",
        "though",
        "may",
        "attribute",
        "symbolic",
        "representation",
        "neural",
        "net",
        "attribution",
        "figure",
        "legitimate",
        "explanation",
        "model",
        "behavior",
        "claim",
        "important",
        "classical",
        "account",
        "cognitive",
        "processing",
        "folk",
        "intuition",
        "presume",
        "representation",
        "play",
        "explanatory",
        "role",
        "understanding",
        "mind",
        "widely",
        "thought",
        "cognitive",
        "science",
        "requires",
        "nature",
        "explanation",
        "appeal",
        "representation",
        "von",
        "eckardt",
        "ramsey",
        "right",
        "point",
        "may",
        "cut",
        "two",
        "different",
        "way",
        "may",
        "use",
        "argue",
        "new",
        "nonclassical",
        "understanding",
        "mind",
        "others",
        "would",
        "use",
        "argue",
        "connectionism",
        "inadequate",
        "since",
        "explain",
        "must",
        "however",
        "haybron",
        "argues",
        "ramsey",
        "ample",
        "room",
        "representation",
        "explanatory",
        "role",
        "radical",
        "connectionist",
        "architecture",
        "roth",
        "make",
        "interesting",
        "point",
        "contrary",
        "first",
        "impression",
        "may",
        "also",
        "make",
        "perfect",
        "sense",
        "explain",
        "net",
        "behavior",
        "reference",
        "computer",
        "program",
        "even",
        "way",
        "discriminate",
        "sequence",
        "step",
        "computation",
        "time",
        "debate",
        "concerning",
        "presence",
        "classical",
        "representation",
        "language",
        "thought",
        "clouded",
        "lack",
        "clarity",
        "defining",
        "count",
        "representational",
        "vehicle",
        "distributed",
        "neural",
        "model",
        "shea",
        "make",
        "point",
        "individuation",
        "distributed",
        "representation",
        "defined",
        "way",
        "activation",
        "pattern",
        "hidden",
        "unit",
        "cluster",
        "together",
        "relationship",
        "clustering",
        "region",
        "space",
        "possible",
        "activation",
        "pattern",
        "carry",
        "representational",
        "content",
        "activation",
        "collection",
        "unit",
        "responsible",
        "activation",
        "understanding",
        "prospect",
        "improved",
        "locating",
        "representational",
        "content",
        "neural",
        "net",
        "compared",
        "net",
        "different",
        "architecture",
        "causally",
        "involved",
        "processing",
        "overcomes",
        "objection",
        "holistic",
        "account",
        "meaning",
        "series",
        "paper",
        "horgan",
        "tienson",
        "championed",
        "view",
        "called",
        "representation",
        "without",
        "rule",
        "according",
        "view",
        "classicist",
        "right",
        "think",
        "human",
        "brain",
        "good",
        "connectionist",
        "model",
        "contain",
        "explanatorily",
        "robust",
        "representation",
        "wrong",
        "think",
        "representation",
        "enter",
        "hard",
        "fast",
        "rule",
        "like",
        "step",
        "computer",
        "program",
        "idea",
        "connectionist",
        "system",
        "may",
        "follow",
        "graded",
        "approximate",
        "regularity",
        "soft",
        "law",
        "horgan",
        "tienson",
        "call",
        "intuitive",
        "appealing",
        "however",
        "aizawa",
        "argues",
        "given",
        "arbitrary",
        "neural",
        "net",
        "representation",
        "level",
        "description",
        "always",
        "possible",
        "outfit",
        "hard",
        "fast",
        "representationlevel",
        "rule",
        "guarini",
        "responds",
        "pay",
        "attention",
        "notion",
        "rule",
        "following",
        "useful",
        "cognitive",
        "modeling",
        "aizawa",
        "construction",
        "seem",
        "beside",
        "point"
    ]
}