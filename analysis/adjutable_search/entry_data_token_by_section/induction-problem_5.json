{
    "main_text": "Tackling the First Horn of Hume\u2019s Dilemma || Bayesian solution\n3.3 Bayesian solution\n\nAnother way in which one can try to construct an a priori\nargument that the premises of an inductive inference make its\nconclusion probable, is to make use of the formalism of probability\ntheory itself. At the time Hume wrote, probabilities were used to\nanalyze games of chance. And in general, they were used to address the\nproblem of what we would expect to see, given that a certain cause was\nknown to be operative. This is the so-called problem of \u201cdirect\ninference\u201d. However, the problem of induction concerns the\n\u201cinverse\u201d problem of determining the cause or general\nhypothesis, given particular observations.\n\nOne of the first and most important methods for tackling the\n\u201cinverse\u201d problem using probabilities was developed by\nThomas Bayes. Bayes\u2019s essay containing the main results was\npublished after his death in 1764 (Bayes 1764). However, it is\npossible that the work was done significantly earlier and was in fact\nwritten in direct response to the publication of Hume\u2019s Enquiry\nin 1748 (see Zabell 1989: 290\u201393, for discussion of what is\nknown about the history).\n\nWe will illustrate the Bayesian method using the problem of drawing\nballs from an urn. Suppose that we have an urn which contains white\nand black balls in an unknown proportion. We draw a sample of balls\nfrom the urn by removing a ball, noting its color, and then putting it\nback before drawing again.\n\nConsider first the problem of direct inference. Given the proportion\nof white balls in the urn, what is the probability of various outcomes\nfor a sample of observations of a given size? Suppose the proportion\nof white balls in the urn is \\(\\theta = 0.6\\). The probability of\ndrawing one white ball in a sample of one is then \\(p(W; \\theta = 0.6)\n= 0.6\\). We can also compute the probability for other outcomes, such\nas drawing two white balls in a sample of two, using the rules of the\nprobability calculus (see section 1 of H\u00e1jek 2011). Generally,\nthe probability that \\(n_w\\) white balls are drawn in a sample of size\nN, is given by the binomial distribution: \n\\[ p(n_w;\\theta=x) = \\left(\\begin{matrix}N\\\\\nn_w\n\\end{matrix}\\right) x^{n_w} (1-x)^{(N-n_w)} \\]\n\n\nThis is a specific example of a \u201csampling distribution\u201d,\n\\(p(E\\mid H)\\), which gives the probability of certain evidence\nE in a sample, on the assumption that a certain hypothesis\nH is true. Calculation of the sampling distribution can in\ngeneral be done a priori, given the rules of the probability\ncalculus.\n\nHowever, the problem of induction is the inverse problem. We want to\ninfer not what the sample will be like, with a known hypothesis,\nrather we want to infer a hypothesis about the general situation or\npopulation, based on the observation of a limited sample. The\nprobabilities of the candidate hypotheses can then be used to inform\npredictions about further observations. In the case of the urn, for\nexample, we want to know what the observation of a particular sample\nfrequency of white balls, \\(\\frac{n_w}{N}\\), tells us about\n\\(\\theta\\), the proportion of white balls in the urn.\n\nThe idea of the Bayesian approach is to assign probabilities not only\nto the events which constitute evidence, but also to hypotheses. One\nstarts with a \u201cprior probability\u201d distribution over the\nrelevant hypotheses \\(p(H)\\). On learning some evidence E,\nthe Bayesian updates the prior \\(p(H)\\) to the conditional probability\n\\(p(H\\mid E)\\). This update rule is called the \u201crule of\nconditionalisation\u201d. The conditional probability \\(p(H\\mid E)\\)\nis known as the \u201cposterior probability\u201d, and is calculated\nusing Bayes\u2019 rule: \n\\[ p(H\\mid E) = \\frac{p(E\\mid H) p(H)}{p(E)} \\]\n\n\nHere the sampling distribution can be taken to be a conditional\nprobability \\(p(E\\mid H)\\), which is known as the\n\u201clikelihood\u201d of the hypothesis H on evidence\nE.\n\nOne can then go on to compute the predictive distribution for as yet\nunobserved data \\(E'\\), given observations E. The predictive\ndistribution in a Bayesian approach is given by \n\\[ p(E'\\mid E) = \\sum_{H} p(E'\\mid H) p(H\\mid E) \\]\n\n\nwhere the sum becomes an integral in cases where H is a\ncontinuous variable.\n\nFor the urn example, we can compute the posterior probability\n\\(p(\\theta\\mid n_w)\\) using Bayes\u2019 rule, and the likelihood\ngiven by the binomial distribution above. In order to do so, we also\nneed to assign a prior probability distribution to the parameter\n\\(\\theta\\). One natural choice, which was made early on by Bayes\nhimself and by Laplace, is to put a uniform prior over the parameter\n\\(\\theta\\). Bayes\u2019 own rationale for this choice was that then\nif you work out the probability of each value for the number of whites\nin the sample based only on the prior, before any data is observed,\nall those probabilities are equal. Laplace had a different\njustification, based on the Principle of Indifference. This principle\nstates that if you don\u2019t have any reason to favor one hypothesis\nover another, you should assign them all equal probabilities.\n\nWith the choice of uniform prior, the posterior probability and\npredictive distribution can be calculated. It turns out that the\nprobability that the next ball will be white, given that \\(n_w\\) of\nN draws were white, is given by \n\\[ p(w\\mid n_w) = \\frac{n_w + 1}{N+2} \\]\n\n\nThis is Laplace\u2019s famous \u201crule of succession\u201d\n(1814). Suppose on the basis of observing 90 white balls out of 100,\nwe calculate by the rule of succession that the probability of the\nnext ball being white is \\(91/102=0.89\\). It is quite conceivable that\nthe next ball might be black. Even in the case, where all 100 balls\nhave been white, so that the probability of the next ball being white\nis 0.99, there is still a small probability that the next ball is not\nwhite. What the probabilistic reasoning supplies then is not an\nargument to the conclusion that the next ball will be a certain color,\nbut an argument to the conclusion that certain future observations are\nvery likely given what has been observed in the past.\n\nOverall, the Bayes-Laplace argument in the urn case provides an\nexample of how probabilistic reasoning can take us from evidence about\nobservations in the past to a prediction for how likely certain future\nobservations are. The question is what kind of solution, if any, this\ntype of calculation provides to the problem of induction. At first\nsight, since it is just a mathematical calculation, it looks as though\nit does indeed provide an a priori argument from the premises\nof an inductive inference to the proposition that a certain conclusion\nis probable.\n\nHowever, in order to establish this definitively, one would need to\nargue that all the components and assumptions of the argument are\na priori and this requires further examination of at least\nthree important issues.\n\nFirst, the Bayes-Laplace argument relies on the rules of the\nprobability calculus. What is the status of these rules? Does\nfollowing them amount to a priori reasoning? The answer to\nthis depends in part on how probability itself is interpreted. Broadly\nspeaking, there are prominent interpretations of probability according\nto which the rules plausibly have a priori status and could\nform the basis of a demonstrative argument. These include the\nclassical interpretation originally developed by Laplace (1814), the\nlogical interpretation (Keynes (1921), Johnson (1921), Jeffreys\n(1939), Carnap (1950), Cox (1946, 1961), and the subjectivist\ninterpretation of Ramsey (1926), Savage (1954), and de Finetti (1964).\nAttempts to argue for a probabilistic a priori solution to\nthe problem of induction have been primarily associated with these\ninterpretations.\n\nSecondly, in the case of the urn, the Bayes-Laplace argument is based\non a particular probabilistic model\u2014the binomial model. This\ninvolves the assumption that there is a parameter describing an\nunknown proportion \\(\\theta\\) of balls in the urn, and that the data\namounts to independent draws from a distribution over that parameter.\nWhat is the basis of these assumptions? Do they generalize to other\ncases beyond the actual urn case\u2014i.e., can we see observations\nin general as analogous to draws from an \u201cUrn of Nature\u201d?\nThere has been a persistent worry that these types of assumptions,\nwhile reasonable when applied to the case of drawing balls from an\nurn, will not hold for other cases of inductive inference. Thus, the\nprobabilistic solution to the problem of induction might be of\nrelatively limited scope. At the least, there are some assumptions\ngoing into the choice of model here that need to be made explicit.\nArguably the choice of model introduces empirical assumptions, which\nwould mean that the probabilistic solution is not an a priori\none.\n\nThirdly, the Bayes-Laplace argument relies on a particular choice of\nprior probability distribution. What is the status of this assignment,\nand can it be based on a priori principles? Historically, the\nBayes-Laplace choice of a uniform prior, as well as the whole concept\nof classical probability, relied on the Principle of Indifference.\nThis principle has been regarded by many as an a priori\nprinciple. However, it has also been subjected to much criticism on\nthe grounds that it can give rise to inconsistent probability\nassignments (Bertrand 1888; Borel 1909; Keynes 1921). Such\ninconsistencies are produced by there being more than one way to carve\nup the space of alternatives, and different choices give rise to\nconflicting probability assignments. One attempt to rescue the\nPrinciple of Indifference has been to appeal to explanationism, and\nargue that the principle should be applied only to the carving of the\nspace at \u201cthe most explanatorily basic level\u201d, where this\nlevel is identified according to an a priori notion of\nexplanatory priority (Huemer 2009).\n\nThe quest for an a priori argument for the assignment of the\nprior has been largely abandoned. For many, the subjectivist\nfoundations developed by Ramsey, de Finetti and Savage provide a more\nsatisfactory basis for understanding probability. From this point of\nview, it is a mistake to try to introduce any further a\npriori constraints on the probabilities beyond those dictated by\nthe probability rules themselves. Rather the assignment of priors may\nreflect personal opinions or background knowledge, and no prior is\na priori an unreasonable choice.\n\nSo far, we have considered probabilistic arguments which place\nprobabilities over hypotheses in a hypothesis space as well as\nobservations. There is also a tradition of attempts to determine what\nprobability distributions we should have, given certain observations,\nfrom the starting point of a joint probability distribution over all\nthe observable variables. One may then postulate axioms directly on\nthis distribution over observables, and examine the consequences for\nthe predictive distribution. Much of the development of inductive\nlogic, including the influential programme by Carnap, proceeded in\nthis manner (Carnap 1950, 1952).\n\nThis approach helps to clarify the role of the assumptions behind\nprobabilistic models. One assumption that one can make about the\nobservations is that they are \u201cexchangeable\u201d. This means\nthat the joint distribution of the random variables is invariant under\npermutations. Informally, this means that the order of the\nobservations does not affect the probability. For instance, in the urn\ncase, this would mean that drawing first a white ball and then a black\nball is just as probable as first drawing a black and then a white. De\nFinetti proved a general representation theorem that if the joint\nprobability distribution of an infinite sequence of random variables\nis assumed to be exchangeable, then it can be written as a mixture of\ndistribution functions from each of which the data behave as if they\nare independent random draws (de Finetti 1964). In the case of the urn\nexample, the theorem shows that it is as if the data are\nindependent random draws from a binomial distribution over a parameter\n\\(\\theta\\), which itself has a prior probability distribution.\n\nThe assumption of exchangeability may be seen as a natural\nformalization of Hume\u2019s assumption that the past resembles the\nfuture. This is intuitive because assuming exchangeability means\nthinking that the order of observations, both past and future, does\nnot matter to the probability assignments.\n\nHowever, the development of the programme of inductive logic revealed\nthat many generalizations are possible. For example, Johnson proposed\nto assume an axiom he called the \u201csufficientness\npostulate\u201d. This states that outcomes can be of a number of\ndifferent types, and that the conditional probability that the next\noutcome is of type i depends only on the number of previous\ntrials and the number of previous outcomes of type i (Johnson\n1932). Assuming the sufficientness postulate for three or more types\ngives rise to a general predictive distribution corresponding to\nCarnap\u2019s \u201ccontinuum of inductive methods\u201d (Carnap\n1952). This predictive distribution takes the form: \n\\[ p(i\\mid N_1,N_2,\\ldots N_t)= \\frac{N_i + k}{N_1 +N_2 + \\cdots + N_t + kt} \\]\n\n\nfor some positive number k. This reduces to Laplace\u2019s\nrule of succession when \\(t=2\\) and \\(k=1\\).\n\nGeneralizations of the notion of exchangeability, such as\n\u201cpartial exchangeability\u201d and \u201cMarkov\nexchangeability\u201d, have been explored, and these may be thought\nof as forms of symmetry assumption (Zabell 1988; Skyrms 2012). As less\nrestrictive axioms on the probabilities for observables are assumed,\nthe result is that there is no longer a unique result for the\nprobability of a prediction, but rather a whole class of possible\nprobabilities, mapped out by a generalized rule of succession such as\nthe above. Therefore, in this tradition, as in the Bayes-Laplace\napproach, we have moved away from producing an argument which produces\na unique a priori probabilistic answer to Hume\u2019s problem.\n\nOne might think then that the assignment of the prior, or the relevant\ncorresponding postulates on the observable probability distribution,\nis precisely where empirical assumptions enter into inductive\ninferences. The probabilistic calculations are empirical arguments,\nrather than a priori ones. If this is correct, then the\nprobabilistic framework has not in the end provided an a\npriori solution to the problem of induction, but it has rather\nallowed us to clarify what could be meant by Hume\u2019s claim that\ninductive inferences rely on the Uniformity Principle.\n",
    "section_title": "3.3 Bayesian solution",
    "entry_title": "The Problem of Induction",
    "hierarchy_title": "The Problem of Induction || Tackling the First Horn of Hume\u2019s Dilemma || Bayesian solution",
    "tokenized_text": [
        "tackling",
        "first",
        "horn",
        "hume",
        "dilemma",
        "bayesian",
        "solution",
        "bayesian",
        "solution",
        "another",
        "way",
        "one",
        "try",
        "construct",
        "priori",
        "argument",
        "premise",
        "inductive",
        "inference",
        "make",
        "conclusion",
        "probable",
        "make",
        "use",
        "formalism",
        "probability",
        "theory",
        "time",
        "hume",
        "wrote",
        "probability",
        "used",
        "analyze",
        "game",
        "chance",
        "general",
        "used",
        "address",
        "problem",
        "would",
        "expect",
        "see",
        "given",
        "certain",
        "cause",
        "known",
        "operative",
        "socalled",
        "problem",
        "direct",
        "inference",
        "however",
        "problem",
        "induction",
        "concern",
        "inverse",
        "problem",
        "determining",
        "cause",
        "general",
        "hypothesis",
        "given",
        "particular",
        "observation",
        "one",
        "first",
        "important",
        "method",
        "tackling",
        "inverse",
        "problem",
        "using",
        "probability",
        "developed",
        "thomas",
        "bayes",
        "bayes",
        "essay",
        "containing",
        "main",
        "result",
        "published",
        "death",
        "bayes",
        "however",
        "possible",
        "work",
        "done",
        "significantly",
        "earlier",
        "fact",
        "written",
        "direct",
        "response",
        "publication",
        "hume",
        "enquiry",
        "see",
        "zabell",
        "discussion",
        "known",
        "history",
        "illustrate",
        "bayesian",
        "method",
        "using",
        "problem",
        "drawing",
        "ball",
        "urn",
        "suppose",
        "urn",
        "contains",
        "white",
        "black",
        "ball",
        "unknown",
        "proportion",
        "draw",
        "sample",
        "ball",
        "urn",
        "removing",
        "ball",
        "noting",
        "color",
        "putting",
        "back",
        "drawing",
        "consider",
        "first",
        "problem",
        "direct",
        "inference",
        "given",
        "proportion",
        "white",
        "ball",
        "urn",
        "probability",
        "various",
        "outcome",
        "sample",
        "observation",
        "given",
        "size",
        "suppose",
        "proportion",
        "white",
        "ball",
        "urn",
        "theta",
        "probability",
        "drawing",
        "one",
        "white",
        "ball",
        "sample",
        "one",
        "p",
        "w",
        "theta",
        "also",
        "compute",
        "probability",
        "outcome",
        "drawing",
        "two",
        "white",
        "ball",
        "sample",
        "two",
        "using",
        "rule",
        "probability",
        "calculus",
        "see",
        "section",
        "h\u00e1jek",
        "generally",
        "probability",
        "n_w",
        "white",
        "ball",
        "drawn",
        "sample",
        "size",
        "n",
        "given",
        "binomial",
        "distribution",
        "p",
        "n_w",
        "thetax",
        "left",
        "begin",
        "matrix",
        "n",
        "n_w",
        "end",
        "matrix",
        "right",
        "x",
        "n_w",
        "x",
        "nn_w",
        "specific",
        "example",
        "sampling",
        "distribution",
        "p",
        "emid",
        "h",
        "give",
        "probability",
        "certain",
        "evidence",
        "e",
        "sample",
        "assumption",
        "certain",
        "hypothesis",
        "h",
        "true",
        "calculation",
        "sampling",
        "distribution",
        "general",
        "done",
        "priori",
        "given",
        "rule",
        "probability",
        "calculus",
        "however",
        "problem",
        "induction",
        "inverse",
        "problem",
        "want",
        "infer",
        "sample",
        "like",
        "known",
        "hypothesis",
        "rather",
        "want",
        "infer",
        "hypothesis",
        "general",
        "situation",
        "population",
        "based",
        "observation",
        "limited",
        "sample",
        "probability",
        "candidate",
        "hypothesis",
        "used",
        "inform",
        "prediction",
        "observation",
        "case",
        "urn",
        "example",
        "want",
        "know",
        "observation",
        "particular",
        "sample",
        "frequency",
        "white",
        "ball",
        "frac",
        "n_w",
        "n",
        "tell",
        "u",
        "theta",
        "proportion",
        "white",
        "ball",
        "urn",
        "idea",
        "bayesian",
        "approach",
        "assign",
        "probability",
        "event",
        "constitute",
        "evidence",
        "also",
        "hypothesis",
        "one",
        "start",
        "prior",
        "probability",
        "distribution",
        "relevant",
        "hypothesis",
        "p",
        "h",
        "learning",
        "evidence",
        "e",
        "bayesian",
        "update",
        "prior",
        "p",
        "h",
        "conditional",
        "probability",
        "p",
        "hmid",
        "e",
        "update",
        "rule",
        "called",
        "rule",
        "conditionalisation",
        "conditional",
        "probability",
        "p",
        "hmid",
        "e",
        "known",
        "posterior",
        "probability",
        "calculated",
        "using",
        "bayes",
        "rule",
        "p",
        "hmid",
        "e",
        "frac",
        "p",
        "emid",
        "h",
        "p",
        "h",
        "p",
        "e",
        "sampling",
        "distribution",
        "taken",
        "conditional",
        "probability",
        "p",
        "emid",
        "h",
        "known",
        "likelihood",
        "hypothesis",
        "h",
        "evidence",
        "e",
        "one",
        "go",
        "compute",
        "predictive",
        "distribution",
        "yet",
        "unobserved",
        "data",
        "e",
        "given",
        "observation",
        "e",
        "predictive",
        "distribution",
        "bayesian",
        "approach",
        "given",
        "p",
        "emid",
        "e",
        "sum_",
        "h",
        "p",
        "emid",
        "h",
        "p",
        "hmid",
        "e",
        "sum",
        "becomes",
        "integral",
        "case",
        "h",
        "continuous",
        "variable",
        "urn",
        "example",
        "compute",
        "posterior",
        "probability",
        "p",
        "thetamid",
        "n_w",
        "using",
        "bayes",
        "rule",
        "likelihood",
        "given",
        "binomial",
        "distribution",
        "order",
        "also",
        "need",
        "assign",
        "prior",
        "probability",
        "distribution",
        "parameter",
        "theta",
        "one",
        "natural",
        "choice",
        "made",
        "early",
        "bayes",
        "laplace",
        "put",
        "uniform",
        "prior",
        "parameter",
        "theta",
        "bayes",
        "rationale",
        "choice",
        "work",
        "probability",
        "value",
        "number",
        "white",
        "sample",
        "based",
        "prior",
        "data",
        "observed",
        "probability",
        "equal",
        "laplace",
        "different",
        "justification",
        "based",
        "principle",
        "indifference",
        "principle",
        "state",
        "reason",
        "favor",
        "one",
        "hypothesis",
        "another",
        "assign",
        "equal",
        "probability",
        "choice",
        "uniform",
        "prior",
        "posterior",
        "probability",
        "predictive",
        "distribution",
        "calculated",
        "turn",
        "probability",
        "next",
        "ball",
        "white",
        "given",
        "n_w",
        "n",
        "draw",
        "white",
        "given",
        "p",
        "wmid",
        "n_w",
        "frac",
        "n_w",
        "n",
        "laplace",
        "famous",
        "rule",
        "succession",
        "suppose",
        "basis",
        "observing",
        "white",
        "ball",
        "calculate",
        "rule",
        "succession",
        "probability",
        "next",
        "ball",
        "white",
        "quite",
        "conceivable",
        "next",
        "ball",
        "might",
        "black",
        "even",
        "case",
        "ball",
        "white",
        "probability",
        "next",
        "ball",
        "white",
        "still",
        "small",
        "probability",
        "next",
        "ball",
        "white",
        "probabilistic",
        "reasoning",
        "supply",
        "argument",
        "conclusion",
        "next",
        "ball",
        "certain",
        "color",
        "argument",
        "conclusion",
        "certain",
        "future",
        "observation",
        "likely",
        "given",
        "observed",
        "past",
        "overall",
        "bayeslaplace",
        "argument",
        "urn",
        "case",
        "provides",
        "example",
        "probabilistic",
        "reasoning",
        "take",
        "u",
        "evidence",
        "observation",
        "past",
        "prediction",
        "likely",
        "certain",
        "future",
        "observation",
        "question",
        "kind",
        "solution",
        "type",
        "calculation",
        "provides",
        "problem",
        "induction",
        "first",
        "sight",
        "since",
        "mathematical",
        "calculation",
        "look",
        "though",
        "indeed",
        "provide",
        "priori",
        "argument",
        "premise",
        "inductive",
        "inference",
        "proposition",
        "certain",
        "conclusion",
        "probable",
        "however",
        "order",
        "establish",
        "definitively",
        "one",
        "would",
        "need",
        "argue",
        "component",
        "assumption",
        "argument",
        "priori",
        "requires",
        "examination",
        "least",
        "three",
        "important",
        "issue",
        "first",
        "bayeslaplace",
        "argument",
        "relies",
        "rule",
        "probability",
        "calculus",
        "status",
        "rule",
        "following",
        "amount",
        "priori",
        "reasoning",
        "answer",
        "depends",
        "part",
        "probability",
        "interpreted",
        "broadly",
        "speaking",
        "prominent",
        "interpretation",
        "probability",
        "according",
        "rule",
        "plausibly",
        "priori",
        "status",
        "could",
        "form",
        "basis",
        "demonstrative",
        "argument",
        "include",
        "classical",
        "interpretation",
        "originally",
        "developed",
        "laplace",
        "logical",
        "interpretation",
        "keynes",
        "johnson",
        "jeffreys",
        "carnap",
        "cox",
        "subjectivist",
        "interpretation",
        "ramsey",
        "savage",
        "de",
        "finetti",
        "attempt",
        "argue",
        "probabilistic",
        "priori",
        "solution",
        "problem",
        "induction",
        "primarily",
        "associated",
        "interpretation",
        "secondly",
        "case",
        "urn",
        "bayeslaplace",
        "argument",
        "based",
        "particular",
        "probabilistic",
        "modelthe",
        "binomial",
        "model",
        "involves",
        "assumption",
        "parameter",
        "describing",
        "unknown",
        "proportion",
        "theta",
        "ball",
        "urn",
        "data",
        "amount",
        "independent",
        "draw",
        "distribution",
        "parameter",
        "basis",
        "assumption",
        "generalize",
        "case",
        "beyond",
        "actual",
        "urn",
        "caseie",
        "see",
        "observation",
        "general",
        "analogous",
        "draw",
        "urn",
        "nature",
        "persistent",
        "worry",
        "type",
        "assumption",
        "reasonable",
        "applied",
        "case",
        "drawing",
        "ball",
        "urn",
        "hold",
        "case",
        "inductive",
        "inference",
        "thus",
        "probabilistic",
        "solution",
        "problem",
        "induction",
        "might",
        "relatively",
        "limited",
        "scope",
        "least",
        "assumption",
        "going",
        "choice",
        "model",
        "need",
        "made",
        "explicit",
        "arguably",
        "choice",
        "model",
        "introduces",
        "empirical",
        "assumption",
        "would",
        "mean",
        "probabilistic",
        "solution",
        "priori",
        "one",
        "thirdly",
        "bayeslaplace",
        "argument",
        "relies",
        "particular",
        "choice",
        "prior",
        "probability",
        "distribution",
        "status",
        "assignment",
        "based",
        "priori",
        "principle",
        "historically",
        "bayeslaplace",
        "choice",
        "uniform",
        "prior",
        "well",
        "whole",
        "concept",
        "classical",
        "probability",
        "relied",
        "principle",
        "indifference",
        "principle",
        "regarded",
        "many",
        "priori",
        "principle",
        "however",
        "also",
        "subjected",
        "much",
        "criticism",
        "ground",
        "give",
        "rise",
        "inconsistent",
        "probability",
        "assignment",
        "bertrand",
        "borel",
        "keynes",
        "inconsistency",
        "produced",
        "one",
        "way",
        "carve",
        "space",
        "alternative",
        "different",
        "choice",
        "give",
        "rise",
        "conflicting",
        "probability",
        "assignment",
        "one",
        "attempt",
        "rescue",
        "principle",
        "indifference",
        "appeal",
        "explanationism",
        "argue",
        "principle",
        "applied",
        "carving",
        "space",
        "explanatorily",
        "basic",
        "level",
        "level",
        "identified",
        "according",
        "priori",
        "notion",
        "explanatory",
        "priority",
        "huemer",
        "quest",
        "priori",
        "argument",
        "assignment",
        "prior",
        "largely",
        "abandoned",
        "many",
        "subjectivist",
        "foundation",
        "developed",
        "ramsey",
        "de",
        "finetti",
        "savage",
        "provide",
        "satisfactory",
        "basis",
        "understanding",
        "probability",
        "point",
        "view",
        "mistake",
        "try",
        "introduce",
        "priori",
        "constraint",
        "probability",
        "beyond",
        "dictated",
        "probability",
        "rule",
        "rather",
        "assignment",
        "prior",
        "may",
        "reflect",
        "personal",
        "opinion",
        "background",
        "knowledge",
        "prior",
        "priori",
        "unreasonable",
        "choice",
        "far",
        "considered",
        "probabilistic",
        "argument",
        "place",
        "probability",
        "hypothesis",
        "hypothesis",
        "space",
        "well",
        "observation",
        "also",
        "tradition",
        "attempt",
        "determine",
        "probability",
        "distribution",
        "given",
        "certain",
        "observation",
        "starting",
        "point",
        "joint",
        "probability",
        "distribution",
        "observable",
        "variable",
        "one",
        "may",
        "postulate",
        "axiom",
        "directly",
        "distribution",
        "observables",
        "examine",
        "consequence",
        "predictive",
        "distribution",
        "much",
        "development",
        "inductive",
        "logic",
        "including",
        "influential",
        "programme",
        "carnap",
        "proceeded",
        "manner",
        "carnap",
        "approach",
        "help",
        "clarify",
        "role",
        "assumption",
        "behind",
        "probabilistic",
        "model",
        "one",
        "assumption",
        "one",
        "make",
        "observation",
        "exchangeable",
        "mean",
        "joint",
        "distribution",
        "random",
        "variable",
        "invariant",
        "permutation",
        "informally",
        "mean",
        "order",
        "observation",
        "affect",
        "probability",
        "instance",
        "urn",
        "case",
        "would",
        "mean",
        "drawing",
        "first",
        "white",
        "ball",
        "black",
        "ball",
        "probable",
        "first",
        "drawing",
        "black",
        "white",
        "de",
        "finetti",
        "proved",
        "general",
        "representation",
        "theorem",
        "joint",
        "probability",
        "distribution",
        "infinite",
        "sequence",
        "random",
        "variable",
        "assumed",
        "exchangeable",
        "written",
        "mixture",
        "distribution",
        "function",
        "data",
        "behave",
        "independent",
        "random",
        "draw",
        "de",
        "finetti",
        "case",
        "urn",
        "example",
        "theorem",
        "show",
        "data",
        "independent",
        "random",
        "draw",
        "binomial",
        "distribution",
        "parameter",
        "theta",
        "prior",
        "probability",
        "distribution",
        "assumption",
        "exchangeability",
        "may",
        "seen",
        "natural",
        "formalization",
        "hume",
        "assumption",
        "past",
        "resembles",
        "future",
        "intuitive",
        "assuming",
        "exchangeability",
        "mean",
        "thinking",
        "order",
        "observation",
        "past",
        "future",
        "matter",
        "probability",
        "assignment",
        "however",
        "development",
        "programme",
        "inductive",
        "logic",
        "revealed",
        "many",
        "generalization",
        "possible",
        "example",
        "johnson",
        "proposed",
        "assume",
        "axiom",
        "called",
        "sufficientness",
        "postulate",
        "state",
        "outcome",
        "number",
        "different",
        "type",
        "conditional",
        "probability",
        "next",
        "outcome",
        "type",
        "depends",
        "number",
        "previous",
        "trial",
        "number",
        "previous",
        "outcome",
        "type",
        "johnson",
        "assuming",
        "sufficientness",
        "postulate",
        "three",
        "type",
        "give",
        "rise",
        "general",
        "predictive",
        "distribution",
        "corresponding",
        "carnap",
        "continuum",
        "inductive",
        "method",
        "carnap",
        "predictive",
        "distribution",
        "take",
        "form",
        "p",
        "imid",
        "n_",
        "n_",
        "ldots",
        "n_t",
        "frac",
        "n_i",
        "k",
        "n_",
        "n_",
        "cdots",
        "n_t",
        "kt",
        "positive",
        "number",
        "k",
        "reduces",
        "laplace",
        "rule",
        "succession",
        "t",
        "k",
        "generalization",
        "notion",
        "exchangeability",
        "partial",
        "exchangeability",
        "markov",
        "exchangeability",
        "explored",
        "may",
        "thought",
        "form",
        "symmetry",
        "assumption",
        "zabell",
        "skyrms",
        "le",
        "restrictive",
        "axiom",
        "probability",
        "observables",
        "assumed",
        "result",
        "longer",
        "unique",
        "result",
        "probability",
        "prediction",
        "rather",
        "whole",
        "class",
        "possible",
        "probability",
        "mapped",
        "generalized",
        "rule",
        "succession",
        "therefore",
        "tradition",
        "bayeslaplace",
        "approach",
        "moved",
        "away",
        "producing",
        "argument",
        "produce",
        "unique",
        "priori",
        "probabilistic",
        "answer",
        "hume",
        "problem",
        "one",
        "might",
        "think",
        "assignment",
        "prior",
        "relevant",
        "corresponding",
        "postulate",
        "observable",
        "probability",
        "distribution",
        "precisely",
        "empirical",
        "assumption",
        "enter",
        "inductive",
        "inference",
        "probabilistic",
        "calculation",
        "empirical",
        "argument",
        "rather",
        "priori",
        "one",
        "correct",
        "probabilistic",
        "framework",
        "end",
        "provided",
        "priori",
        "solution",
        "problem",
        "induction",
        "rather",
        "allowed",
        "u",
        "clarify",
        "could",
        "meant",
        "hume",
        "claim",
        "inductive",
        "inference",
        "rely",
        "uniformity",
        "principle"
    ]
}