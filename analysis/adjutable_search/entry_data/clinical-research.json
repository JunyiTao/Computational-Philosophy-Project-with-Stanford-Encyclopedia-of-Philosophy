{
    "url": "clinical-research",
    "title": "The Ethics of Clinical Research",
    "authorship": {
        "year": "Copyright \u00a9 2021",
        "author_text": "David Wendler\n<dwendler@nih.gov>",
        "author_links": [
            {
                "mailto:dwendler%40nih%2egov": "dwendler@nih.gov"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2021</a> by\n\n<br/>\nDavid Wendler\n&lt;<a href=\"mailto:dwendler%40nih%2egov\"><em>dwendler<abbr title=\" at \">@</abbr>nih<abbr title=\" dot \">.</abbr>gov</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Fri Jan 30, 2009",
        "substantive revision Wed Jun 23, 2021"
    ],
    "preamble": "\n\nClinical research attempts to address a relatively straightforward,\nand important challenge: how do we determine whether one medical\nintervention is better than another, whether it offers greater\nclinical benefit and/or poses fewer risks? Clinicians may one day be\nable to answer these questions by relying on computer models, thereby\navoiding reliance on clinical research and the ethical concerns it\nraises. Until that day, clinical researchers begin by testing\npotential new medical interventions in the laboratory, and often in\nanimals. While these methods can provide valuable information and, in\nthe case of animal research, raise important ethical issues of their\nown, potential new interventions eventually must be tested in human\nbeings. Interventions which work miracles in test tubes and in mice,\noften leave humans untouched, or worse off.\n\nTesting medical interventions in humans typically poses some\nrisks to the participants, no matter how many laboratory and\nanimal tests precede it. In this way, the process of collecting\ndata through clinical trials to improve health and well-being\ninevitably exposes research participants to some risks for the benefit\nof future patients. This brings us to the central ethical challenge\nposed by clinical research: When is it ethically permissible to expose\nresearch participants to risks of harm for the benefit of others? The\npresent entry focuses on this concern, and canvasses the most\nprominent attempts to address it. The present entry largely brackets\nthe range of interesting and important ethical challenges that arise\nin the course of conducting clinical research: How should it be\nreviewed? Who may conduct it? What must potential participants\nunderstand to give valid consent? May it be conducted in countries\nthat will not be able to afford the intervention being tested? Do\ninvestigators have any obligations to treat unrelated medical\nconditions in participants that they uncover during the course of\ntheir research?\n\nOne might attempt to address the central ethical challenge by limiting\nclinical research to the medical setting, offering experimental\ninterventions to patients who want to try them. This approach, which\nhas the virtue of evaluating interventions in the process of trying to\nhelp individual patients, makes sense for comparisons of two or more\ninterventions that are widely accepted and already in clinical use. In\ncontrast, this approach poses enormous scientific and practical\nproblems with respect to testing new interventions. On the practical\nside, who would be willing to manufacture a new intervention without\nknowing whether it works? What dose should be used? How often should\nthe new drug be taken? More importantly, this approach might not yield\nreliable information as to whether the new treatment is useful or\nharmful until hundreds, perhaps thousands of people have received it.\nClinical research is designed to address these concerns by\nsystematically assessing potential new treatments in a small number of\nindividuals, including very sick ones, before offering them more\nwidely. As we go about our daily lives, driving cars, flushing our\nwaste down the drain, exhaling, getting a dog, we inevitably expose\nothers to risks of harm. Despite the fact that these practices pervade\nour lives, there has been surprisingly little philosophical analysis\nof the conditions under which they are acceptable (Hayenhjelm and\nWolff 2012). In addition to being of value in its own right,\nevaluation of the central ethical challenge posed by clinical research\nthus provides an opportunity to consider one of the more fundamental\nconcerns in moral theory: when is it acceptable to expose some\nindividuals to risks of harm?\n",
    "toc": [
        {
            "#WhatClinRese": "1. What is Clinical Research?"
        },
        {
            "#EarlClinRese": "2. Early Clinical Research"
        },
        {
            "#AbusGuid": "3. Abuses and Guidelines"
        },
        {
            "#ClinReseClinCare": "4. Clinical Research and Clinical Care"
        },
        {
            "#LibeAnal": "5. A Libertarian Analysis"
        },
        {
            "#ContTheo": "6. Contract Theory"
        },
        {
            "#MiniRisk": "7. Minimal Risks"
        },
        {
            "#GoalInte": "8. Goals and Interests"
        },
        {
            "#InduSponRese": "9. Industry Sponsored Research"
        },
        {
            "#LearHealCare": "10. Learning Health Care"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. What is Clinical Research?\n\nHuman subjects research is research which studies humans, as opposed\nto animals, atoms, or asteroids. Assessment of whether humans prefer\n100 dollars or a 1% chance of 10,000 dollars constitutes human\nsubjects research. Clinical research refers to the subset of human\nsubjects research that evaluates the impact interventions have on\nhuman beings with the goal of assessing whether they might help to\nimprove human health and well-being. The present analysis focuses on\nresearch that is designed to improve human health and well-being by\nidentifying better methods to treat, cure or prevent illness or\ndisease. This focus is intended to bracket the question of whether\nresearch on enhancements that might increase our well-being by making\nus better than normal, allowing us to remember more or worry less,\nwithout treating, curing, or preventing illness or disease\nqualifies as clinical research.\n\nWe shall also bracket the question of whether quality improvement and\nquality assurance projects qualify as clinical research. To briefly\nconsider the type of research at the heart of this debate, consider a\nhospital which proposes to evaluate the impact of checklists on the\nquality of patient care. Half the nurses in the hospital are told to\ncontinue to provide care as usual; the other half are provided with a\nchecklist and instructed to mechanically check off each item as they\ncomplete it when caring for their patients. The question of whether\nthis activity constitutes clinical research is of theoretical interest\nas a means to clarifying the precise boundaries of the concept. Should\nwe say that this is not clinical research because the checklist is\nused by the nurses, not administered to the patients? Or should we say\nthis is clinical research because it involves the systematic testing\nof a hypothesis which is answered by collecting data on patient\noutcomes? The answer has significant practical implications,\ndetermining whether these activities must satisfy existing regulations\nfor clinical research, including whether the clinicians need to obtain\npatients\u2019 informed consent before the nurses taking care of them\ncan use the checklist.\n\nWhile clinical medicine is enormously better than it was 100 or even\n50 years ago, there remain many diseases against which current\nclinical medicine offers an inadequate response. To name just a few,\nmalaria kills over a million people, mostly children, every year;\nchronic diseases, chief among them heart disease and stroke, kill\nmillions each year, and there still are no effective treatments for\nAlzheimer disease. The social value of clinical research lies in its\nability to collect information that might be useful for identifying\nimproved methods to address these conditions. Yet, it is the\nrare  study which definitively establishes that a particular\nmethod is effective and safe for treating, curing or preventing some\nillness. The success of specific research studies more commonly lies\nin the gathering of information that, together with the results of\nmany other studies, may yield these improvements. For example,\nprior to establishing the efficacy of a new treatment for a given\ncondition, researchers typically need to identify the cause of the\ncondition, possible mechanisms for treating it, a safe and effective\ndose, and ways of testing whether the drug alters the course of the\ndisease.\n\nThe process of testing potential new treatments can take 10\u201315 years,\nand is standardly divided into phases. Formalized phase 0 studies are\na relatively recent phenomenon involving the testing of interventions\nand methods which might be used in later phase studies. A phase 0\nstudy might be designed to determine the mechanism of action of a\nparticular drug and evaluate different ways to administer it. Phase 1\nstudies are the earliest tests of a new intervention and are conducted\nin small numbers of individuals. Phase 1 studies are designed to\nevaluate the pharmacokinetics and pharmacodynamics of new treatments,\nessentially evaluating how the drug influences the human body and how\nthe human body influences the drug. Phase 1 studies also evaluate the\nrisks of the treatment and attempt to identify an appropriate dose to\nbe used in subsequent phase 2 studies. Phase 1 studies pose risks and\nfrequently offer little if any potential for clinical benefit to\nparticipants. As a result, a significant amount of the ethical concern\nover clinical research focuses on phase 1 studies.\n\nIf phase 1 testing is successful, potential new treatments go on to\nlarger phase 2 studies which are designed to further assess risks and\nalso to evaluate whether there is any evidence that the treatment\nmight be beneficial. Successful phase 2 studies are followed by phase\n3 studies which involve hundreds, sometimes thousands of patients.\nPhase 3 studies are designed to provide a rigorous test of the\nefficacy of a treatment and frequently involve randomization of\nparticipants to the new treatment or a control, which might be the\ncurrent treatment or a placebo. Finally, post-marketing or phase 4\nstudies evaluate the use of interventions in clinical practice.\n\nThe first three phases of clinical trials typically include\npurely research procedures, such as blood draws, imaging scans, or\nbiopsies, that are included in the study to collect data regarding the\ntreatment under study. Analysis of the central ethical challenge posed\nby clinical research thus focuses on three related risk-benefit\nprofiles: (a) the risk-benefit profile of the interventions(s) under\nstudy; (b) the risk-benefit profile of the included research\nprocedures; and (c) the risk-benefit profile of the study as a\nwhole.\n\nIn some cases, receipt of potential new treatments is in the ex ante\ninterests of research participants. For example, the risks posed by an\nexperimental cancer treatment might be justified by the possibility\nthat it will extend participants\u2019 lives. Moreover, the\nrisk/benefit profile of the treatment might be as favorable for\nparticipants as the risk/benefit profile of the available\nalternatives. In these cases, receipt of the experimental intervention\nex ante promotes participants\u2019 interests. In other cases,\nparticipation in research poses \u2018net\u2019 risks, that is,\nrisks of harm which are not, or not entirely, justified by potential\nclinical benefits to individual participants. A first in human trial\nof an experimental treatment might involve a single dose to see\nwhether humans can tolerate it. And it might occur in healthy\nindividuals who have no need of treatment. These studies pose risks to\nparticipants and offer essentially no chance for clinical benefit. The\nqualifier to \u2018essentially\u2019 no chance of clinical benefit\nis intended to capture the fact that the research procedures included\nin clinical trials may inadvertently end up providing some clinical\nbenefit to some participants. For example, a biopsy that is used to\ncollect research data may disclose a previously unidentified and\ntreatable condition. The chance for such benefit, albeit real, is\ntypically so remote that it is not sufficient to compensate for the\nrisks of the procedure. Whether a study as a whole poses net risks\ndepends on whether the potential benefits of the experimental\nintervention compensate for its risks plus the net risks of the\nresearch procedures included in the study.\n\nClinical research which poses net risks raises important ethical\nconcern. Net-risk studies raise concern that participants are being\nused as mere means to collect information to benefit future patients.\nResearch procedures that pose net risks may seem to raise less concern\nwhen they are embedded within a study which offers a favorable\nrisk-benefit profile overall. Yet, since these procedures pose net\nrisks, and since the investigators could provide participants with the\nnew potential treatment alone, they require justification. An\ninvestigator who is about to insert a needle into a research\nparticipant to obtain some blood purely for laboratory purposes faces\nthe question of whether doing so is ethically justified, even when the\nprocedure is included in a study that offers participants the\npotential for important medical benefit. The goal of ethical analyses\nof clinical research is to provide an answer.\n\nClinical research poses three types of net risks: absolute, relative,\nand indirect (Rid and Wendler 2011). Absolute net risks arise when the\nrisks of an intervention or procedure are not justified by its\npotential clinical benefits. Most commentators focus on this\npossibility with respect to research procedures which pose some risks\nand offer (essentially) no chance of clinical benefit, such as blood\ndraws to obtain cells for laboratory studies. Research with healthy\nvolunteers is another example which frequently offers no chance for\nclinical benefit. Clinical research also poses absolute net risks when\nit offers a chance for clinical benefit which is not sufficient to\njustify the risks participants face. A kidney biopsy to obtain tissue\nfrom presumed healthy volunteers may offer some very low chance of\nidentifying an unrecognized and treatable pathology. This intervention\nnonetheless poses net risks if the chance for clinical benefit for the\nparticipants is not sufficient to justify the risks of their\nundergoing the biopsy.\n\nRelative net risks arise when the risks of a research intervention are\njustified by its potential clinical benefits, but the\nintervention\u2019s risk-benefit profile is less favorable than the\nrisk-benefit profile of one or more available alternatives. Imagine\nthat investigators propose a randomized, controlled trial to compare\nan inexpensive drug against an expensive and somewhat more effective\ndrug. Such trials make sense when, in the absence of a direct\ncomparison, it is unclear whether the increased effectiveness of the\nmore expensive drug justifies its costs. In this case, receipt of the\ncheaper drug would be contrary to participants\u2019 interest in\ncomparison to receiving the more expensive drug. The trial thus poses\nrelative net risks to participants.\n\nIndirect net risks arise when a research intervention has a favorable\nrisk-benefit profile, but the intervention diminishes the risk-benefit\nprofile of other interventions provided as part of or in parallel to\nthe study. For example, an experimental drug for cancer might\nundermine the effectiveness of other drugs individuals are taking for\ntheir condition. The risks of research participation can be compounded\nif the indicated response to the harm in question poses additional\nrisks. Kidney damage suffered as the result of research participation\nmight lead to the need for short-term dialysis which poses additional\nrisks to the individual; a participant who experiences a postlumbar\npuncture headache might need a \u2018blood patch\u2019 which poses\nsome risk of blood entering the epidural space which would call for a\nfurther response which carries additional risks. While commentators\ntend to focus on the risks of physical harm, participation in clinical\nresearch can pose other types of risks as well, including\npsychological, economic, and social risks. Depending on the study and\nthe circumstances, individuals who are injured as the result of\nparticipating in research might incur significant expenses. Most\nguidelines and regulations stipulate that evaluation of the\nacceptability of clinical research studies should take into account\nall the different risks to which participants are exposed.\n\nTo assess the ethics of exposing research participants to risks, one\nneeds an account of why exposing others to risks raises ethical\nconcern in the first place. Being exposed to risks obviously raises\nconcern to the extent that the potential harm to which the risk refers\nis realized: the chance of a headache turns into an actual headache.\nBeing exposed to risks also can lead to negative consequences as a\nresult of the recognition that one is at risk of harm. Individuals who\nrecognize that they face a risk may become frightened; they also may\ntake costly or burdensome measures to protect themselves. In contrast,\nthe literature on the ethics of clinical research implicitly assumes\nthat being exposed to risks is not per se harmful. The mere fact that\nparticipants are exposed to risks is not regarded as necessarily\ncontrary to their interests. It depends on whether the risk is\nrealized in an actual harm.\n\nIt is one thing to expose a consenting adult to risks to save the\nhealth or life of an identified and present other, particularly when\nthe two individuals are first degree relatives. It is another thing,\nor seems to many to be another thing, to expose consenting individuals\nto risks to help unknown and unidentified, and possibly future others.\nAlmost no one objects to operating on a healthy, consenting adult to\nobtain a kidney that might save a present and ailing sibling,\neven though the operation poses some risk of serious harm and offers\nthe donor no potential for clinical benefit. Attempts to obtain a\nkidney from a healthy, consenting adult and give it to an unidentified\nindividual are met with greater ethical concern. The extent of the\nconcern increases as the path from risk exposure to benefit becomes\nlonger and more tenuous. Many clinical research studies expose\nparticipants to risks in order to collect generalizable information\nwhich, if combined with the results of other, as yet non-existent\nstudies, may eventually benefit future patients through the\nidentification of a new intervention, assuming the appropriate\nregulatory authorities approve it, some company or group chooses to\nmanufacture it, and patients can afford to purchase it. The potential\nbenefits of clinical research may thus be realized someday, but the\nrisks and burdens are clear and present.\n\nIncreasingly, researchers obtain and store human biological\nsamples for use in future research studies. These studies raise\nimportant questions regarding what might be called\n\u2018contribution\u2019 and \u2018information\u2019 risks. The\nformer question concerns the conditions under which it is acceptable\nto ask individuals to contribute to answering the scientific question\nposed by a given study (Jonas 1969). The fact that this question has\nbeen ignored by many commentators and regulations may trace to an\noverly narrow understanding of individuals\u2019 interests.\nIndividuals undoubtedly have an interest in avoiding the kinds of\nphysical harms, pain, infection, loss of organ function,\nthat they face in clinical research. This leaves the question of\nwhether individuals\u2019 interests are implicated, and whether they\ncan be set back, by contributing to particular projects,\nactivities and goals?\n\nConsider the routine practice of storing leftover samples of\nparticipants\u2019 blood for use in future research projects.\nFor the purposes of protecting participants\u2019 interests, does it\nmatter what goals these future studies attempt to advance? Can\nindividuals be harmed if their samples are used to promote\ngoals which conflict with their fundamental values? For\nexample, are the interests of individuals who fundamentally\noppose cloning set back if their samples are used in a\nstudy that successfully identifies improved methods to clone human\nbeings?\n\nThe possibility of information risks garnered significant\nattention when investigators used DNA samples obtained from members of\nthe Havasupai tribe in Arizona to study \u201ctheories of the\ntribe\u2019s geographical origins.\u201d The study\u2019s\nconclusion that early members of the tribe had migrated from Asia\nacross the Bering Strait contradicted the tribe\u2019s own views that\nthey originated in the Grand Canyon (Harmon 2010). Can learning the\ntruth, in this case the origins of one\u2019s tribal group, harm\nresearch participants?\n\nAttempts to determine when it is acceptable to expose participant to\nrisks for the benefit of others, including future others who do not\nyet exist, have been significantly influenced by its history, by how\nit has been conducted and, in particular, by how it has been\nmisconducted (Lederer 1995; Beecher 1966). Thus, to understand the\ncurrent state of the ethics of clinical research, it is useful to know\nsomething of its past.\n2. Early Clinical Research\n\nModern clinical research may have begun on the 20th of May,\n1747, aboard the HMS Salisbury. James Lind, the ship\u2019s surgeon,\nwas concerned with the costs scurvy was exacting on British sailors,\nand was skeptical of some of the interventions, cider, elixir of\nvitriol, vinegar, sea-water, being used at the time to treat it.\nUnlike other clinicians of his day, Lind did not simply assume that he\nwas correct and treat his patients accordingly. He designed a study.\nHe chose 12 sailors from among the 30 or so Salisbury\u2019s crew\nmembers who were suffering from scurvy, and divided them into six\ngroups of 2 sailors each. Lind assigned a different intervention to\neach of the groups, including two sailors turned research participants\nwho received 2 oranges and 1 lemon each day. Within a week these two\nwere sailors again; the others remained patients, and several were\ndying.\n\nThe ethics of clinical research begins by asking how we should think\nabout the fate of these latter sailors. Did Lind treat them\nappropriately? Do they have a moral claim against Lind? It is widely\nassumed that physicians should do what they think is best for the\npatient in front of them. Lind, despite being a physician, did not\nfollow this maxim. He felt strongly that giving sea water to\nindividuals with scurvy was a bad idea, but he gave sea water to 2 of\nthe sailors in his study to test whether he, or others, were right. To\nput the fundamental concern raised by clinical research in its\nsimplest form: Did Lind sacrifice these two sailors, patients under\nhis care, for the benefit of others? \n\nLind\u2019s experiments represent perhaps the first modern clinical\ntrial because he attempted to address one of the primary challenges\nfacing those who set out to evaluate medical treatments. How does one\nshow that any differences in the outcomes of the treatments under\nstudy are a result of the treatments themselves, and not a result of\nthe patients who received them, or other differences in the\npatients\u2019 environment or diet? How could Lind be confident that\nthe improvements in the two sailors were the result of the oranges and\nlemons, and not a result of the fact that he happened to give them to\nthe two patients who occupied the most salutary rooms on the ship?\nLind tried to address the challenge of confounding variables by\nbeginning with patients who were as similar as possible. He carefully\nchose the 12 subjects for his experiment from a much larger pool of\nailing sailors; he also tried to ensure that all 12 received the same\nrations each day, apart from the treatments provided as part of his\nstudy. It is also worth noting that Lind\u2019s dramatic results were\nlargely ignored for decades, leading to uncounted and unnecessary\ndeaths, and highlighting the importance of combining clinical research\nwith effective promulgation and implementation. The Royal Navy did not\nadopt citrus rations for another 50 years (Sutton 2003), at which\npoint scurvy essentially disappeared from the Royal Navy.\n\nLind\u2019s experiments, despite controlling for a number of factors,\ndid not exclude the possibility that his own choices of which sailors\ngot which treatment influenced the results. More recent experiments,\nincluding the first modern randomized, placebo controlled trial of\nStreptomycin for TB in 1948 (D\u2019Arcy Hart 1999), attempt to\naddress this concern by assigning treatments to patients using a\nrandom selection process. By randomly assigning patients to treatment\ngroups these studies ushered in the modern era of controlled, clinical\ntrials. And, by taking the choice of which treatment a given patient\nreceives out of the hands of the treating clinician, these trials\nunderscore and, some argue, exacerbate the ethical concerns raised by\nclinical research (Hellman and Hellman 1991). A foundational principle\nof clinical medicine is the importance of individual judgment. A\nphysician who decides which treatments her patients receive by\nflipping a coin is guilty of malpractice. A clinical investigator who\nrelies on the same methods receives awards and gets published in elite\njournals. One might conclude that sacrifice of the interests of some,\noften sick patients, for the benefit of future patients, is\nessentially mandated by the scientific method (Miller & Weijer\n2006; Rothman 2000). The history of clinical research seems to provide\ntragic support for this view.\n3. Abuses and Guidelines\n\nThe history of clinical research is littered with abuses. Indeed, one\naccount maintains that the history of pediatric research is\n\u201clargely one of child abuse\u201d (Lederer and Grodin 1994, 19;\nalso see Lederer 2003). This history has had a significant influence\non how research ethicists understand the concerns raised by clinical\nresearch and on how policy makers attempt to address them. In\nparticular, policy makers have responded to previous abuses by\ndeveloping guidelines intended to prevent their recurrence.\n\nThe most influential abuses in this regard were the horrific\nexperiments conducted by Nazi physicians during WW II (abuses\nperpetrated by Japanese physicians were also horrific, but have\nreceived significantly less attention). Response to these abuses led\nto the Nuremberg Code (Grodin & Annas 1996; Shuster 1997), which\nis frequently regarded as the first set of formal guidelines for\nclinical research, an ironic claim on two counts. First, there is some\ndebate over whether the Nuremberg Code was intended to apply generally\nto clinical research or whether, as a legal ruling in a specific\ntrial, it was intended to address only the cases before the court\n(Katz 1996). Second, the Germans themselves had developed systematic\nresearch guidelines as early as 1931 (Vollmann & Winau 1996).\nThese guidelines were still legally in force at the time of the Nazi\natrocities and clearly prohibited a great deal of what the Nazi\ndoctors did.\n\nWide consensus developed by the end of the 1950s that the Nuremberg\nCode was inadequate to the ethics of clinical research. Specifically,\nthe Nuremberg Code did not include a requirement that clinical\nresearch receive independent ethics review and approval. In addition,\nthe first and longest principle in the Nuremberg Code states that\ninformed consent is \u201cessential\u201d to ethical clinical\nresearch (Nuremberg Military Tribunal 1947). This requirement provides\na powerful safeguard against the abuse of research participants. It\nalso appears to preclude clinical research with individuals who cannot\nconsent.\n\nOne could simply insist that the informed consent of participants is\nnecessary to ethical clinical research and accept the opportunity\ncosts thus incurred. Representatives of the World Medical Association,\nwho hoped to avoid these costs, began meeting in the early 1960s to\ndevelop guidelines, which would become the Declaration of\nHelsinki, to address the perceived shortcomings of the Nuremberg Code\n(Goodyear, Krleza-Jeric, and Lemmens 2007). They recognized that\ninsisting on informed consent as a necessary condition for clinical\nresearch would preclude a good deal of research designed to find\nbetter ways to treat dementia and conditions affecting children, as\nwell as research in emergency situations. Regarding consent as\nnecessary precludes such research even when it poses only minimal\nrisks or offers participants a compensating potential for important\nclinical benefit. The challenge, still facing us today, is to identify\nprotections for research participants which are sufficient to protect\nthem without being so strict as to preclude appropriate research\ndesigned to benefit the groups to which they belong.\n\nThe Declaration of Helsinki (World Medical Organization 1996) allows\nindividuals who cannot consent to be enrolled in clinical research\nbased on the permission of the participant\u2019s representative. The\nU.S. federal regulations governing clinical research take a similar\napproach. These regulations are not laws in the strict sense of being\npassed by Congress and applying to all research conducted on U.S.\nsoil. Instead, the regulations represent administrative laws which\neffectively attach to clinical research at the beginning and the end.\nResearch conducted using U.S. federal monies, for instance, research\nfunded by the NIH, or research involving NIH researchers, must follow\nthe U.S. regulations (Department of Health and Human Services 2005).\nResearch that is included as part of an application for approval from\nthe U.S. FDA also must have been conducted according to FDA\nregulations which, except for a few exceptions, are essentially the\nsame. Although many countries now have their own national regulations\n(Brody 1998), the U.S. regulations continue to exert enormous\ninfluence around the world because so much clinical research is\nconducted using U.S. federal money and U.S. federal investigators, and\nthe developers of medical treatments often want to obtain approval for\nthe U.S. market.\n\nThe abuses perpetrated as part of the infamous Tuskegee syphilis study\nwere made public in 1972, 40 years after the study was initiated. The\nresulting outcry led to the formation of the U.S. National Commission,\nwhich was charged with evaluating the ethics of clinical research with\nhumans and developing recommendations for appropriate safeguards.\nThese deliberations resulted in a series of recommendations for the\nconduct of clinical research, which became the framework for existing\nU.S. regulations. The U.S. regulations, like many regulations, place\nno clear limits on the risks to which competent and consenting adults\nmay be exposed. In contrast, strict limits are placed on the level of\nresearch risks to which those unable to consent may be exposed,\nparticularly children. In the case of pediatric research, the standard\nprocess for review and approval is limited to studies that offer a\n\u2018prospect of direct\u2019 benefit and research that poses\nminimal risk or a minor increase over minimal risk. Studies that\ncannot be approved in one of these categories must be reviewed by an\nexpert panel and approved by a high government official. While this\n4th category offers important flexibility, it implies that, at least\nin principle, U.S. regulations do not mandate a ceiling on the risks\nto which pediatric research participants may be exposed for the\nbenefit of others. This reinforces the importance of considering how\nwe might justify exposing participants to research risks, both minimal\nand greater than minimal, for the benefit of others.\n4. Clinical Research and Clinical Care\n\nLind\u2019s experiments on scurvy exemplify the fact that clinical\nresearch is often conducted by clinicians and often is conducted on\npatients. Many commentators have thus assumed that clinical\nresearch should be governed by the ethics of clinical care, and the\nmethods of research should not diverge from the methods that are\nacceptable in clinical care. On this approach, participants should not\nbe denied any beneficial treatments available in the clinical setting\nand they should not be exposed to any risks not present in the\nclinical setting.\n\nSome proponents (Rothman 2000) argue that this approach is implied by\nthe kind of treatment that patients, understood as individuals who\nhave a condition or illness needing treatment, are owed. Such\nindividuals are owed treatment that promotes, or at least is\nconsistent with their medical interests. Others (Miller & Weijer\n2006) argue that the norms of clinical research derive largely from\nthe obligations that bear on clinicians. These commentators argue that\nit is unacceptable for a physician to participate in, or even support\nthe participation of her patients in a clinical trial unless that\ntrial is consistent with the patients\u2019 medical interests. To do\nless is to provide substandard medical treatment and to violate\none\u2019s obligations as a clinician.\n\nThe claim that the treatment of research participants should be\nconsistent with the norms which govern clinical care has been applied\nmost prominently to the ethics of randomized clinical trials (Hellman\n& Hellman 1991). Randomized trials determine which treatment a\ngiven research participant receives based on a random process, not\nbased on clinical judgment of which treatment would be best for that\npatient. Lind assigned the different existing treatments for scurvy to\nthe sailors in his study based not on what he thought was best for\nthem, but based on what he thought would yield an effective\ncomparative test. Lind did not give each intervention to the same\nnumber of sailors because he thought that all the interventions had an\nequal chance of being effective. To the contrary, he did this because\nhe was confident that several of the interventions were harmful and\nthis design was the best way to show it. Contemporary clinical\nresearchers go even further, assigning participants to treatments\nrandomly. Because this aspect of clinical research represents a clear\ndeparture from the practice of clinical medicine it appears to\nsacrifice the interests of participants in order to collect valid\ndata.\n\nOne of the most influential responses to this concern (Freedman 1987)\nargues that randomization is acceptable when the study in question\nsatisfies what has come to be known as \u2018clinical\nequipoise.\u2019 Clinical equipoise obtains when, for the population\nof patients from which participants will be selected, the available\nclinical evidence does not favor one of the treatments being used over\nthe others. In addition, it must be the case that there are no\ntreatments available outside the trial that are better than those used\nin the trial. Satisfaction of these conditions seems to imply that the\ninterests of research participants will not be undermined in the\nservice of collecting scientific information. If the available data do\nnot favor any of the treatments being used, randomizing participants\nseems as good a process as any other for choosing which treatment they\nreceive.\n\nProponents of clinical equipoise as an ethical requirement for\nclinical research determine whether equipoise obtains not by appeal to\nthe belief states of individual clinicians, but based on whether there\nis consensus among the community of experts regarding which treatment\nis best. Lind believed that sea water was ineffective for the\ntreatment of scurvy. Yet, in the absence of agreement among the\ncommunity of experts, this view essentially constituted an individual\npreference rather than a clinical norm. This suggests that it was\nacceptable for Lind to randomly assign sailors under his care to the\nprevailing treatments in order to test, in essence, whose preferred\ntreatment was the best. In this way, the existence of uncertainty\nwithin the community of experts seems to offer a way to reconcile the\nmethods of clinical research with the norms of clinical medicine.\n\nCritics respond that even when clinical equipoise obtains for the\npopulation of patients, the specific circumstances of individual\npatients within that population might imply that one of the treatments\nunder investigation is better for them (Gifford 2007). A specific\npatient may have reduced liver function which places her at greater\nrisk of harm if she receives a treatment metabolized by the liver. And\nsome patients may have personal preferences which incline them toward\none treatment over another (e.g., they may prefer a one-time riskier\nprocedure to multiple, lower risk procedures which pose the same\ncollective risk). Current debate focuses on whether randomized\nclinical trials can take these possibilities into account in a way\nthat is consistent with the norms of clinical medicine.\n\nEven if the existence of clinical equipoise can justify some\nrandomized trials, a significant problem remains, namely, many studies\nand procedures which are crucial to the identification and development\nof improved methods for protecting and advancing health and well-being\nare inconsistent with participants\u2019 medical interests. This\nconcern arises for many phase 1 studies which offer essentially no\nchance for medical benefit and pose at least some risks, and to that\nextent are inconsistent with the participants\u2019 medical\ninterests.\n\nPhase 3 studies which randomize participants to a potential new\ntreatment or existing standard treatment, and satisfy clinical\nequipoise, typically include purely research procedures, such as\nadditional blood draws, to evaluate the drugs being tested. Enrollment\nin these studies may be consistent with participants\u2019 medical\ninterests in the sense that the overall risk-benefit ratio is at\nleast as favorable as the available alternatives. Yet, evaluation of\nthe overall risk-benefit profile of the study masks the fact that it\nincludes individual procedures which are contrary to\nparticipants\u2019 medical interests, and contrary to the norms of\nclinical medicine.\n\nThe attempt to protect research participants by appeal to the\nobligations clinicians have to promote the medical interests of their\npatients also seems to leave healthy volunteers unprotected.\nAlternatively, proponents might characterize this position in terms of\nclinicians\u2019 obligations to others in general: clinicians should\nnot perform procedures on others unless doing so promotes the\nindividual\u2019s clinical interests. This approach seems to preclude\nessentially all research with healthy volunteers. For example, many\nphase 1 studies are conducted in healthy volunteers to determine a\nsafe dose of the drug under study. These studies, vital to drug\ndevelopment, are inconsistent with the principle that clinicians\nshould expose individuals to risks only when doing so is consistent\nwith their clinical interests. It follows that appeal to clinical\nequipoise alone cannot render clinical research consistent with the\nnorms of clinical practice.\n\nCommentators sometimes attempt to justify net-risk procedures that are\nincluded within studies, and studies that overall pose net risks by\ndistinguishing between \u2018therapeutic\u2019 and\n\u2018non-therapeutic\u2019 research (Miller and Weijer 2006). The\nclaim here is that the demand of consistency with participants\u2019\nmedical interests applies only to therapeutic research;\nnon-therapeutic research studies and procedures may diverge from these\nnorms to a certain extent, provided participants\u2019 medical\ninterests are not significantly compromised. The distinction between\ntherapeutic and non-therapeutic research is sometimes based on the\ndesign of the studies in question, and sometimes based on the\nintentions of the investigators. Studies designed to benefit\nparticipants, or investigators who intend to benefit participants are\nconducting therapeutic studies. Those designed to collect\ngeneralizable knowledge or in which the investigators intend to do so\nconstitute non-therapeutic research.\n\nThe problem with the distinction between therapeutic and\nnon-therapeutic research so defined is that research itself often is\ndefined as a practice designed to collect generalizable knowledge and\nconducted by investigators who intend to achieve this end (Levine\n1988). On this definition, all research qualifies as non-therapeutic.\nConversely, most investigators intend to benefit their participants in\nsome way or other. Perhaps they design the study in a way that\nprovides participants with clinically useful findings, or they provide\nminor care not required for research purposes, or referrals to\ncolleagues. Even if proponents can make good on the distinction\nbetween therapeutic and non-therapeutic research in theory, these\npractices appear to render it irrelevant to the practice of clinical\nresearch. More importantly, it is not clear why investigators\u2019\nresponsibilities to patients, or patients\u2019 claims on\ninvestigators, should vary as a function of this distinction. Why\nthink that investigators are allowed to expose patients to some risks\nfor the benefit of others, but only in the context of research that is\nnot designed to benefit the participants? To apply this proposed\nresolution to pediatric research, why might it be acceptable to expose\ninfants to risks for the benefit of others, but only in the context of\nstudies which offer the infants no chance for personal benefit?\n\nTo take one possibility, it is not clear that this view can be\ndefended by appeal to physicians\u2019 role responsibilities. A prima\nfacie plausible view holds that physicians\u2019 role\nresponsibilities apply to all encounters between physicians and\npatients who need medical treatment. This view would imply that\nphysicians may not compromise patients\u2019 medical interests when\nconducting therapeutic studies, but also seems to prohibit\nnon-therapeutic research procedures with patients. Alternatively, one\nmight argue that physicians\u2019 role responsibilities apply only in\nthe context of clinical care and so do not apply in the context of\nclinical research at all. This articulation yields a more plausible\nview, but does not support the use of the therapeutic/ non-therapeutic\ndistinction. It provides no reason to think that physicians\u2019\nobligations differ based on the type of research in question.\n\nCritics argue that these problems highlight the fundamental confusion\nthat results when one attempts to evaluate clinical research based on\nnorms appropriate to clinical medicine. They instead distinguish\nbetween the ethics of clinical research and the ethics of clinical\ncare, arguing that it is inappropriate to assume that investigators\nare subject to the claims and obligations which apply to physicians,\ndespite the fact that the individuals who conduct clinical research\noften are physicians (Miller and Brody 2007).\n\nThe claim that clinical research should satisfy the norms of clinical\nmedicine has this strong virtue: it provides a clear method to protect\nindividual research participants and reassure the public that they are\nbeing so protected. If research participants are treated consistent\nwith their medical interests, we can be reasonably confident that\nimprovements in clinical medicine will not be won at the expense of\nexploiting them. Most accounts of the ethics of clinical research now\nrecognize the limitations of this approach and search for ways to\nensure that research participants are not exposed to excessive risks\nwithout assuming that the claims of clinical medicine apply to\nclinical researchers (Emanuel, Wendler, and Grady 2000; CIOMS 2002).\nDismissal of the distinction between therapeutic and non-therapeutic\nresearch thus yields an increase in both conceptual clarity and\nconcern regarding the potential for abuse of research\nparticipants.\n\nClinicians, first trained as physicians taught to act in the best\ninterests of the patient in front of them, often struggle with the\nprocess of exposing some patients to risky procedures for the benefit\nof others. It is one thing for philosophers to insist, no matter how\naccurately, that research participants are not patients and need not\nbe treated according to the norms of clinical medicine. It is another\nthing for clinical researchers to regard research participants who are\nsuffering from disease and illness as anything other than patients.\nThese clinical instincts, while understandable and laudable, have the\npotential to obscure the true nature of clinical research, as\ninvestigators and participants alike try to convince themselves that\nclinical research involves nothing more than the provision of clinical\ncare. One way to try to address this collective and often willful\nconfusion would be to identify a justification for exposing research\nparticipants to net risks for the benefit of others.\n5. A Libertarian Analysis\n\nIt is often said that those working in bioethics are obsessed with the\nprinciple of respect for individual autonomy. Advocates of this view\nof bioethicists cite the high esteem accorded in the field to the\nrequirement of obtaining individual informed consent and the frequent\nattempts to resolve bioethical challenges by citing its satisfaction.\nOne might assume that this view within bioethics traces to implicit\nendorsement of a libertarian analysis according to which it is\npermissible for competent and informed individuals to do whatever they\nprefer, provided those with whom they interact are competent, informed\nand in agreement. In the words of Mill, investigators should be\npermitted to conduct research and expose participants to risks\nprovided they obtain their \u201cfree, voluntary, and undeceived\nconsent and participation\u201d (On Liberty, page 11). Setting aside\nthe question of whether this view accurately characterizes bioethics\nand bioethicists generally, it does not apply to the vast majority of\nwork done on the ethics of clinical research. Almost no one in the\nfield argues that it is permissible for investigators to conduct any\nresearch they want provided they obtain the free and informed consent\nof those they enroll.\n\nCurrent research ethics does place significant weight on informed\nconsent and many regulations and guidelines devote much of their\nlength to articulating the requirement for informed consent. Yet, as\nexemplified by the response to the Nuremberg Code, almost no one\nregards informed consent as necessary and sufficient for ethical\nresearch. Most regulations and guidelines, beginning with the\nDeclaration of Helsinki, first adopted in 1964 (World Medical\nOrganization 1996), allow investigators to conduct research on humans\nonly when it has been approved by an independent group charged with\nensuring that the study is ethically acceptable. Most regulations\nfurther place limits on the types of research that independent ethics\ncommittees may approve. They must find that the research has important\nsocial value and the risks have been minimized, thereby restricting\nthe types of research to which even competent adults may consent. Are\nthese requirements justified, or are they inappropriate infringements\non the free actions of competent individuals? The importance of\nanswering this question goes beyond its relevance to debates over\nLibertarianism. Presumably, the requirements placed on clinical\nresearch have the effect of reducing to some extent the number of\nresearch studies that get conducted. The fact that at least some of\nthe prohibited studies likely would have important social value,\nhelping to identify better ways to promote health and well-being,\nprovides a normative reason to eliminate the restrictions, unless\nthere is some compelling reason to retain them.\n\nThe libertarian claim that valid informed consent is necessary and\nsufficient to justify exposing research participants to risks for the\nbenefit of others seems to imply, consistent with the first principle\nof the Nuremberg Code, that research with individuals who cannot\nconsent is unethical. This plausible and tempting claim commits one to\nthe view that research with children, research in many emergency\nsituations, and research with the demented elderly all are ethically\nimpermissible. One could consistently maintain such a view but the\nsocial costs of adopting it would be great. It is estimated, for\nexample, that approximately 70% of medications provided to children\nhave not been tested in children, even for basic safety and efficacy\n(Roberts, Rodriquez, Murphy, Crescenzi 2003; Field & Behrman 2004;\nCaldwell, Murphy, Butow, and Craig 2004). Absent clinical research\nwith children, pediatricians will be forced to continue to provide\nfrequently inappropriate treatment, leading to significant harms that\ncould have been avoided by pursuing clinical research to identify\nbetter approaches.\n\nOne response would be to argue that the Libertarian analysis is not\nintended as an analysis of the conditions under which clinical\nresearch is acceptable. Instead, the claim might be that it provides\nan analysis of the conditions under which it is acceptable to conduct\nclinical research with competent adults. Informed consent is necessary\nand sufficient for enrolling competent adults in research. While this\nview does not imply that research with participants who cannot consent\nis impermissible, it faces the not insignificant challenge of\nproviding an account for why such research might be acceptable.\n\nBracketing the question of individuals who cannot consent, many of the\nlimitations on clinical research apply to research with competent\nadults. How might these limitations be justified? One approach would\nbe to essentially grant the Libertarian analysis on theoretical\ngrounds, but then argue that the conditions for its implementation are\nrarely realized in practice. In particular, there are good reasons,\nand significant empirical data, to question how often clinical\nresearch actually involves participants who are sufficiently informed\nto provide valid consent. Even otherwise competent adults often fail\nto understand clinical research sufficiently to make their own\ninformed decisions regarding whether to enroll (Flory and Emanuel\n2004).\n\nTo consider an example which is much discussed in the research ethics\nliterature, it is commonly assumed that valid consent for randomized\nclinical trials requires individuals to understand randomization. It\nrequires individuals to understand that the treatment they will\nreceive, if they enroll in the study, will be determined by a process\nwhich does not take into account which of the treatments is better for\nthem (Kupst 2003). There is an impressive wealth of data which\nsuggests that many, perhaps most individuals who participate in\nclinical research do not understand this (Snowden 1997; Featherstone\nand Donovan 2002; Appelbaum 2004). The data also suggest that these\nfailures of understanding often are resistant to educational\ninterventions.\n\nWith this in mind, one might regard the limitations on research with\ncompetent adults as betraying the paternalism embedded in most\napproaches to the ethics of clinical research (Miller and Wertheimer\n2007). Although the charge of paternalism often carries with it some\ndegree of condemnation, there is a strong history of what is regarded\nas appropriate paternalism in the context of clinical research. This\ntoo may have evolved from clinical medicine. Clinicians are charged\nwith protecting and promoting the interests of the patient \u201cin\nfront of them\u201d. Clinician researchers, who frequently begin\ntheir careers as clinicians, may regard themselves as similarly\ncharged. Paternalism involves interfering with the liberty of agents\nfor their own benefit (Feinberg 1986; see also entry on\n paternalism).\n As the terms are used in the present debate, \u2018soft\u2019\npaternalism involves interfering with the liberty of an individual in\norder to promote their interests on the grounds that the action being\ninterfered with is the result of impaired decision-making: \u201cA\nfreedom-restricting intervention is based on soft paternalism only\nwhen the target\u2019s decision-making is substantially impaired,\nwhen the agent lacks (or we have reason to suspect that he lacks) the\ninformation or capacity to protect his own interests\u2014as when\nA prevents B from drinking the liquid in a glass because\nA knows it contains poison but B does not\u201d (Miller\n& Wertheimer 2007). \u2018Hard\u2019 paternalism, in contrast,\ninvolves interfering with the liberty of an individual in order to\npromote their interests, despite the fact that the action being\ninterfered with is the result of an informed and voluntary choice by a\ncompetent individual.\n\nIf the myriad restrictions on clinical research were justified on the\nbasis of hard paternalism they would represent restrictions on\nindividuals\u2019 autonomous actions. However, the data on the extent\nto which otherwise competent adults fail to understand what they need\nto understand to provide valid consent suggests that the limitations\ncan instead be justified on the grounds of soft paternalism. This\nsuggests that while the restrictions may limit the liberty of adult\nresearch participants, they do not limit their autonomy. In this way,\none may regard many of the regulations on clinical research not as\ninconsistent with the libertarian ideal, but instead as starting from\nthat ideal and recognizing that otherwise competent adults often fail\nto attain it.\n\nEven if most research participants had sufficient understanding to\nprovide valid consent, it would not follow that there should be no\nlimitations on research with competent adults. The conditions on what\none individual may do to another are not exhausted by what the second\nindividual consents to. Perhaps some individuals may choose for\nthemselves to be treated with a lack of respect, even tortured. It\ndoes not follow that it is acceptable for me or you to treat them\naccordingly. As independent moral agents we need sufficient reason to\nbelieve that our actions, especially the ways in which we treat\nothers, are appropriate, and this evaluation concerns, in typical\ncases, more than just the fact that the affected individuals consented\nto them.\n\nUnderstood in this way, many of the limitations on the kinds of\nresearch to which competent adults may consent are not justified, or\nat least not solely justified, on paternalistic grounds. Instead,\nthese limitations point to a crucial and often overlooked concern in\nresearch ethics. The regulations for clinical research often are\ncharacterized as protecting the participants of research from harm.\nAlthough this undoubtedly is an important and perhaps primary function\nof the regulations, they also have an important role in limiting the\nextent to which investigators harm research participants, and limiting\nthe extent to which society supports and benefits from a process which\ninappropriately harms others. It is not just that research\nparticipants should not be exposed to risk of harm without compelling\nreason. Investigators should not expose them to such risks without\ncompelling reason, and society should not support and benefit from\ntheir doing so.\n\nThis aspect of the ethics of clinical research has strong connections\nwith the view that the obligations of clinicians restrict what sort of\nclinical research they may conduct. On that view, it is the fact that\none is a physician and is obligated to promote the best interests of\nthose with whom one interacts professionally which determines what one\nis allowed to do to participants. This connection highlights the\npressing questions that arise once we attempt to move beyond the view\nthat clinical research is subject to the norms of clinical medicine.\nThere is a certain plausibility to the claim that a researcher is not\nacting as a clinician and so may not be subject to the obligations\nthat bear on clinicians. Or perhaps we might say that the\nresearcher/subject dyad is distinct from the physician/patient dyad\nand is not necessarily subject to the same norms. But, once we\nconclude that we need an account of the ethics of clinical\nresearch, distinct from the ethics of clinical care, one is left with\nthe question of which limitations apply to what researchers may do to\nresearch participants.\n\nIt seems clear that researchers may not expose research participants\nto risks without sufficient justification, and also clear that this\nclaim applies even to those who provide free and informed consent. The\ncurrent challenge then is to develop an analysis of the conditions\nunder which it is acceptable for investigators to expose participants\nto risks and determine to what extent current regulations need to be\nmodified to reflect this analysis. To consider briefly the extent of\nthis challenge, and to underscore and clarify the claim that the\nethics of clinical research go beyond the protection of research\nparticipants to include the independent consideration of what\nconstitutes appropriate behavior on the part of investigators,\nconsider an example.\n\nPhysical and emotional abuse cause enormous suffering, and a good deal\nof research is designed to study various methods to reduce instances\nof abuse and also to help victims recover from being abused. Imagine\nthat a team of investigators establishes a laboratory to promote the\nlatter line of research. The investigators will enroll consenting\nadults and, to mimic the experience of extended periods of abuse in\nreal life, they will abuse their participants emotionally and\nphysically for a week. The abused participants will then be used in\nstudies to evaluate the efficacy of different methods for helping\nvictims to cope with the effects of abuse.\n\nThe proper response to this proposal is not to claim that the study is\nacceptable because the participants are competent and they gave\ninformed consent. The proper response is to point out that, while\nthese considerations are undoubtedly important, they do not\nestablish that the study is ethically acceptable. One needs to\nconsider many other things. Is the experiment sufficiently similar to\nreal life abuse that its results will have external validity? Are\nthere less risky ways to obtain the same results? Finally, even if\nthese questions are answered in a way that supports the research, the\nquestion remains whether investigators may ethically treat their\nparticipants in this way. The fact that essentially everyone working\nin research ethics would hold that this study is\nunethical\u2014investigators are not permitted to treat participants\nin this way\u2014suggests that research ethics, both in terms of how\nit is practiced and possibly how it should be practiced, goes beyond\nrespect for individual autonomy to include independent standards on\ninvestigator behavior. Defining those standards represents one of the\nmore important challenges for research ethics.\n\nAs exemplified by Lind\u2019s experiments on treatments for scurvy,\nclinical research studies were first conducted by clinicians wondering\nwhether the methods they were using were effective. To answer this\nquestion, the clinicians altered the ways in which they treated their\npatients in order to yield information that would allow them to assess\ntheir methods. In this way, clinical research studies initially were\npart of, but an exception to standard clinical practice. As a result,\nclinical research came to be seen as an essentially unique activity.\nAnd widespread recognition of clinical research\u2019s scandals and\nabuses led to the view that this activity needed its own extensive\nregulations.\n\nMore recently, some commentators have come to question the view that\nclinical research is a unique human activity, as well as the\nregulations and guidelines which result from this view. In particular,\nit has been argued that this view has led to overly restrictive\nrequirements on clinical research, requirements that hinder\nscientists\u2019 ability to improve medical care for future patients,\nand also fail to respect the liberty of potential research\nparticipants. This view is often described in terms of the claim that\nmany regulations and guidelines for clinical research are based on an\nunjustified \u2018research exceptionalism\u2019 (Wertheimer\n2010).\n\nThe central ethical concern raised by clinical research involves the\npractice of exposing participants to risks for the benefit of others.\nYet, as noted previously, we are constantly exposing individuals to\nrisks for our benefit and the benefit of others. When you drive to the\nstore, you expose your neighbors to some increased risk of pollution\nfor the benefits you derive from shopping; speeding ambulances expose\npedestrians to risks for the benefit of the patients they carry;\nfactories expose their workers to risks for the benefit of their\ncustomers; charities expose volunteers to risks for the benefit of\nrecipients. Despite this similarity, clinical research is widely\nregarded as ethically problematic and is subject to significantly\ngreater regulation, review, and oversight (Wilson and Hunter 2010).\nAlmost no one regards driving, ambulances, charities, or factories as\ninherently problematic. Even those who are not great supporters of a\ngiven charity do not argue that it treats its volunteers as guinea\npigs, despite exposing them to risks for the benefit of others. And no\none argues that charitable activities should satisfy the requirements\nthat are routinely applied to clinical research, such as the\nrequirements for independent review and written consent based on an\nexhaustive description of the risks and potential benefits of the\nactivity, its purpose, duration, scope, and procedures.\n\nGiven that many activities expose some to risks for the benefit of\nothers, yet are not subject to such extensive regulation, some\ncommentators conclude that many of the requirements for clinical\nresearch are unjustified (Sachs 2010, Stewart et al. 2008, and\nSullivan 2008). This work is based on the assumption that, when it\ncomes to regulation and ethical analysis, we should treat clinical\nresearch as we treat other activities in daily life which involve\nexposing some to risks for the benefit of others. This assumption\nleads to a straightforward solution to the central ethical problem\nposed by clinical research.\n\nExposing factory workers to risks for the benefit of others is deemed\nethically acceptable when they agree to do the work and are paid a\nfair wage. The solution suggested for the ethical concern of\nnon-beneficial research is to obtain consent and pay research\nparticipants a fair wage for their efforts. This view is much less\nrestrictive than current regulations for clinical research, but seems\nto be less permissive than a Libertarian analysis. The latter\ndifference is evident in claims that research studies should treat\nparticipants fairly and not exploit them, even if individuals consent\nto being so treated.\n\nThe gap between this approach and the traditional view of research\nethics is evident in the fact that advocates of the traditional view\ntend to regard payment of research participants as exacerbating rather\nthan resolving its ethical concerns, raising, among others, worries of\nundue inducement and commodification. Those who are concerned about\nresearch exceptionalism, in contrast, tend to regard payment as it is\nregarded in most other contexts in daily life: some is good and more\nis better.\n\nThe claims of research exceptionalism have led to valuable discussion\nof the extent to which clinical research differs from other activities\nwhich pose risks to participants for the benefit of others and whether\nany of the differences justify the extensive regulations and\nguidelines standardly applied to clinical research. Proponents of\nresearch exceptionalism who regard many of the existing regulations as\nunjustified face the challenge of articulating an appropriate set of\nregulations for clinical research. While comparisons to factory work\nprovide a useful lens for thinking about the ethics of clinical\nresearch, it is not immediately obvious what positive recommendations\nfollow from this perspective. After all, it is not as if there is\ngeneral consensus regarding the regulations to which industry should\nbe subject. Some endorse minimum wage laws; others oppose them. There\nare further arguments over whether workers should be able to unionize;\nwhether governments should set safety standards for industry; whether\nthere should be rules protecting workers against discrimination.\n6. Contract Theory\n\nA few commentators (Caplan 1984; Harris 2005; Heyd 1996) try to\njustify exposing research participants to risks for the benefit\nof others by citing an obligation to participate in clinical research.\nAt least all individuals who have access to medical care have\nbenefited from the efforts of previous research participants in the\nform of effective vaccines and better medical treatments. One might\ntry to argue that these benefits obligate us to participate in\nclinical research when its our turn.\n\nCurrent participation in clinical research typically benefits future\npatients. However, if we incur an obligation for the benefits that are\ndue to previous research studies, we presumably are obligated to the\npatients who participated in those studies, an obligation we cannot\ndischarge by participating in current studies. This approach also does\nnot provide a way to justify the very first clinical trials, such as\nLind\u2019s, which of necessity enrolled participants who had never\nbenefited from previous clinical research.\n\nAlternatively, one might argue that the obligation to participate does\nnot trace to the benefits we receive from the efforts of previous\nresearch participants. Rather, the obligation is to the overall social\nsystem of which clinical research is a part (Brock 1994). For example,\none might argue that individuals acquire this obligation as the result\nof being raised in the context of a cooperative scheme or society. We\nare obligated to do our part because of the many benefits we have\nenjoyed as a result of living within such a scheme.\n\nThe first challenge for this view is to explain why the mere enjoyment\nof benefits, without some prospective agreement to respond in kind,\nobligates individuals to help others. Presumably, your doing a nice\nthing for me yesterday, without my knowledge or invitation, does not\nobligate me to do you a good turn today. This concern seems even\ngreater with respect to pediatric research. Children certainly benefit\nfrom previous research studies, but typically do so unknowingly and\noften with vigorous opposition. The example of pediatric research\nmakes the further point that justification of clinical research\non straightforward contractualist grounds will be difficult at best.\nContract theories have difficulties with those groups, such as\nchildren, who do not accept in any meaningful way the benefits of the\nsocial system under which they live (Gauthier 1990).\n\nIn a Rawlsian vein, one might try to establish an obligation to\nparticipate in clinical research based on the choices individuals\nwould make regarding the structure of society from a position of\nignorance regarding their own place within that society, from behind a\nveil of ignorance (Rawls 1999). To make this argument, one would have\nto modify the Rawlsian argument in several respects. The knowledge\nthat one is currently living could well bias one\u2019s decision\nagainst the conduct of clinical research. Those who know they are\nalive at the time the decision is being made have already reaped many\nof the benefits they will receive from the conduct of clinical\nresearch.\n\nTo avoid these biases, we might stretch the veil of ignorance to\nobscure the generation to which one belongs\u2014past, present or\nfuture (Brock 1994). Under a veil of ignorance so stretched,\nindividuals might choose to participate in clinical research as long\nas the benefits of the practice exceed its overall burdens. One could\nthen argue that justice as fairness gives all individuals an\nobligation to participate in clinical research when their turn comes.\nThis approach seems to have the advantage of explaining why we can\nexpose even children to some risks for the benefit of others, and why\nparents can give permission for their children to participate in such\nresearch. This argument also seems to imply not simply that clinical\nresearch is acceptable, but that, in a range of cases, individuals\nhave an obligation to participate in it. It implies that adults whose\nturn has come are obligated to participate in clinical research,\nalthough for practical reasons we might refrain from forcing them to\ndo so.\n\nThis justification for clinical research faces several challenges.\nFirst, Rawlsian arguments typically are used to determine the basic\nstructure of society, that is, to determine a fair arrangement of the\nbasic institutions within the society (Rawls 1999). If the structure\nof society meets these basic conditions, members of the society cannot\nargue that the resulting distribution of benefits and burdens is\nunfair. Yet, even when the structure of society meets the conditions\nfor fairness, it does not follow that individuals are obligated to\nparticipate in the society so structured. Competent adults can decide\nto leave a society that meets these conditions rather than enjoy its\nbenefits (whether they have any better places to go is another\nquestion). The right of exit suggests that the fairness of the system\ndoes not generate an obligation to participate, but rather defends the\nsystem against those who would argue that it is unfair to some of the\nparticipants over others. At most, then, the present argument can show\nthat it is not unfair to enroll a given individual in a research\nstudy, that this is a reasonable thing for all individuals, including\nthose who are unable to consent.\n\nSecond, it is important to ask on what grounds individuals behind the\nveil of ignorance make their decisions. In particular: are these\ndecisions constrained or guided by moral considerations? (Dworkin\n1989; Stark 2000). It seems plausible to think that they would be.\nAfter all, we are seeking the ethical approach or policy with respect\nto clinical research. The problem, then, is that the answer we get in\nthis case may depend significantly on which ethical constraints are\nbuilt into the system, rendering the approach question begging. Most\nimportantly, we are considering whether it is ethical to expose\nindividuals who cannot consent to risks for the benefit of others. If\nit isn\u2019t, then it seems that this should be a limitation on the\nchoices individuals can make from behind the veil of ignorance, in\nwhich case appeal to those choices will not be able to\njustify pediatric research, nor  research with incompetent\nadults. And if this research is ethical it is unclear why we need this\nmechanism to justify it.\n\nProponents might avoid this dilemma by assuming that individuals\nbehind the veil of ignorance will make decisions based purely on\nself-interest, unconstrained by moral limits or considerations.\nPresumably, many different systems would satisfy this requirement. In\nparticular, the system that produces the greatest amount of benefits\noverall may well be one that we regard as unethical. Many endorse the\nview that clinical research studies which offer no potential benefit\nto participants and pose a high chance of serious risk, such as death,\nare unethical, independent of the magnitude of the social value to be\ngained. For example, almost all research ethicists would regard as\nunethical a study which intentionally infects a few participants\nwith the HIV virus, even when the study offers the potential to\nidentify a cure for AIDS. Yet, individuals behind the veil of\nignorance who make decisions based solely on self-interest might well\nallow this study on the grounds that it offers a positive cost-benefit\nratio overall: the high risks to a few participants are clearly\noutweighed by the potential to save the lives of millions.\n\nThe question here is not whether a reasonable person would choose to\nmake those who are badly off even worse off in order to elevate the\nstatus of those more privileged. Rather, both options involve some\nindividuals being in unfortunate circumstances, namely, infected with\nthe HIV virus. The difference is that the one option (not conducting\nthe study) involves many more individuals becoming infected over time,\nwhereas the other option involves significantly fewer individuals\nbeing infected, but some as the result of being injected in the\nprocess of identifying a cure. Since the least desirable circumstances\n(being infected with HIV) are the same in both cases, the reasonable\nchoice, even if one endorses the maximin strategy, seems to be\nwhichever option reduces the total number of individuals who are in\nthose circumstances, revealing that, in the present case at least, the\nRawlsian approach seems not to take into account the way in which\nindividuals end up in the positions they occupy.\n7. Minimal Risks\n\nLimits on risks are a central part of almost all current research\nregulations and guidelines. With respect to those who can consent,\nthere is an essentially implicit agreement that the risks should not\nbe too high (as noted earlier, some argue that there should not\nbe any net risks to even competent adults in the context of so-called\ntherapeutic research). However, there is no consensus regarding how to\ndetermine which risks are acceptable in this context. With respect to\nthose who cannot consent, many commentators argue that clinical\nresearch is acceptable when the net risks are very low. The challenge,\ncurrently faced by many in clinical research, is to identify a\nstandard, and find a reliable way to implement it, for what\nconstitutes a sufficiently low risk in this context. An interesting\nand important question in this regard is whether the level of\nacceptable risks varies depending on the particular class of\nindividuals who cannot consent. Is the level of acceptable risks the\nsame for individuals who were once competent, such as previously\ncompetent adults with Alzheimer disease, individuals who are not now\nbut are expected to become competent, such as healthy children, and\nindividuals who are not now and likely never will be competent, such\nas individuals born with severe cognitive disabilities?\n\nSome argue that the risks of clinical research qualify as sufficiently\nlow when they are \u2018negligible\u2019, understood as risks that\ndo not pose any chance of serious harm (Nicholson 1986). Researchers\nwho ask children a few questions for research purposes may expose them\nto risks no more worrisome than that of being mildly upset for a few\nminutes. Exposing participants to a risk of minor harm for the benefit\nof others does not seem to raise ethical concern. Or one might argue\nthat the ethical concerns it raises do not merit serious ethical\nconcern. Despite the plausibility of these views, very few studies\nsatisfy the negligible risk standard. Even routine procedures that are\nwidely accepted in pediatric research, such as single blood draws,\npose some, typically very low risk of more than negligible harm.\n\nOthers (Kopelman 2000; Resnik 2005) define risks as sufficiently low\nor \u2018minimal\u2019 when they do not exceed the risks individuals\nface during the performance of routine examinations. This standard\nprovides a clear and quantifiable threshold for acceptable risks. Yet,\nthe risks of routine medical procedures for healthy individuals are so\nlow that this standard seems to prohibit intuitively acceptable\nresearch. This approach faces the additional problem that, as the\ntechniques of clinical medicine become safer and less invasive,\nincreasing numbers of procedures used in clinical research would\nmove from acceptable to unacceptable. And, at a theoretical level, one\nmight wonder why we should think that the risks we currently happen to\naccept in the context of clinical care for healthy children should\ndefine the level of risk that is acceptable in clinical research. Why\nthink that the ethical acceptability of a  blood draw in\npediatric research depends on whether clinicians still use blood draws\nas part of clinical screening for healthy children?\n\nMany guidelines (U.S. Department of Health and Human Services 2005;\nAustralian National Health and Medical Research Council 1999) and\ncommentators take the view that clinical research is ethically\nacceptable as long as the net risks do not exceed the risks\nindividuals face in daily life. Many of those involved in clinical\nresearch implicitly assume that this minimal risk standard is\nessentially equivalent to the negligible risk standard. If the risks\nof research are no greater than the risks individuals face in daily\nlife, then the research does not pose risk of any serious harm. As an\nattitude toward many of the risks we face in daily life, this view\nmakes sense. We could not get through the day if we were conscious of\nall the risks we face. Crossing the street poses more risks than one\ncan catalog, much less process readily. When these risks are\nsufficiently low, psychologically healthy individuals place them in\nthe cognitive background, ignoring them unless the circumstances\nprovide reason for special concern (e.g. one hears a siren, or sees a\nlarge gap in the sidewalk).\n\nPaul Ramsey reports that members of the US National Commission often\nused the terms \u2018minimal\u2019 and \u2018negligible\u2019 in a way\nwhich seemed to imply that they were willing to allow minimal risk\nresearch, even with children, on the grounds that it poses no chance\nof serious harm (Ramsey 1978). The members then went on to argue that\nan additional ethical requirement for such research is a guarantee of\ncompensation for any serious research injuries. This approach to\nminimal risk pediatric research highlights nicely the somewhat\nconfused attitudes we often have toward risks, especially those of\ndaily life.\n\nWe go about our daily lives as though harms with very low probability\nare not going to occur, effectively treating low probability harms as\nzero probability events. To this extent, we are not Bayesians about\nthe risks of daily life. We treat some possible harms as impossible\nfor the purposes of getting through the day. This attitude, crucial to\nliving our lives, does not imply that there are no serious risks in\ndaily life. The fact that our attitude toward the risks of everyday\nlife is justified by its ability to help us to get through the day\nundermines its ability to provide an ethical justification for\nexposing research participants to the same risks in the context of\nnon-beneficial research (Ross & Nelson 2006).\n\nFirst, the extent to which we ignore the risks of daily life is not a\nfully rational process. In many cases, our attitude regarding risks is\na function of features of the situation that are not correlated\ndirectly with the risk level, such as our perceived level of control\nand our familiarity with the activity (Tversky, Kahneman 1974;\nTversky, Kahneman 1981; Slovic 1987; Weinstein 1989). Second, to the\nextent that the process of ignoring some risks is rational, we are\ninvolved in a process of determining which risks are worth paying\nattention to. Some risks are so low that they are not worth paying\nattention to. Consideration of them would be more harmful (would cost\nus more) than the expected value of being aware of them in the first\nplace.\n\nTo some extent, then, our attitudes in this regard are based on a\nrational cost/benefit analysis. To that extent, these attitudes do not\nprovide an ethical argument for exposing research participants to\nrisks for the benefit of others. The fact that the costs to an\nindividual of paying attention to a given risk in daily life are\ngreater than the benefits to that individual does not seem to have any\nrelevance for what risks we may expose them to for the benefit of\nothers. Finally, there is a chance of serious harm from many of the\nactivities of daily life. This reveals that the \u2018risks of daily\nlife\u2019 standard does not preclude the chance of some participants\nexperiencing serious harm. Indeed, one could put the point in a much\nstronger way. Probabilities being what they are, the risks of daily\nlife standard implies that if we conduct enough minimal risk research\neventually a few participants will die and scores will suffer\npermanent disability.\n\nAs suggested above, a more plausible line of argument would be to\ndefend clinical research that poses minimal risk on the grounds\nthat it does not increase the risks to which participants are\nexposed. It seems plausible to assume that at any given time an\nindividual will either be participating in research or involved in the\nactivities of daily life. But, by assumption, the risks of the two\nactivities are essentially equivalent, implying that enrollment in the\nstudy, as opposed to allowing the participant to continue to\nparticipate in the activities of daily life does not increase the\nrisks to which he is exposed.\n\nThe problem with this argument is that the risks of research often are\nadditive rather than substitutive. For example, participation in a\nstudy might require the participant to drive to the clinic for a\nresearch visit. The present defense succeeds to the extent that this\ntrip replaces another trip in the car, or some similarly risky\nactivity in which the participant would have been otherwise involved.\nIn practice, this often is not the case. The participant instead may\nsimply put off the trip to the mall until after the research visit. In\nthat case, the participant\u2019s risk of serious injury from a car\ntrip may be doubled as a result of her participation in research.\nMoreover, we accept many risks in daily life because the relevant\nactivities offer those who pursue them a chance of personal benefit.\nWe allow children to take the bus because we assume that the benefits\nof receiving an education justify the risks. The fact that we accept\nthese risks given the potential benefits provides no reason to think\nthat the same risks or even the same level of risk would be acceptable\nin the context of an activity which offers no chance of medical\nbenefit. Finally, applied strictly, this justification seems to imply\nthat investigators should evaluate what risks individuals would face\nif they did not enroll in the research, and enroll only those who\nwould otherwise face similar or greater levels of risk.\n8. Goals and Interests\n\nIn one of the most influential papers in the history of research\nethics, Hans Jonas (1969) argues that the progress clinical research\noffers is normatively optional, whereas the need to protect\nindividuals from the harms to which clinical research exposes them is\nmandatory. He writes:\n\n\u2026 unless the present state is intolerable, the melioristic goal\n[of biomedical research] is in a sense gratuitous, and this is not\nonly from the vantage point of the present. Our descendants have a\nright to be left an unplundered planet; they do not have a right to\nnew miracle cures. We have sinned against them if by our doing, we\nhave destroyed their inheritance not if by the time they come around\narthritis has not yet been conquered (unless by sheer neglect). (Jonas\n1969, 230\u2013231)\n\n\nJonas\u2019s view does not imply that clinical research is\nnecessarily unethical, but the conditions on when it may be conducted\nare very strict. This argument may seem plausible to the extent that\none regards, as Jonas does, the benefits of clinical research to be\nones that make an acceptable state in life even better. The example of\narthritis cited by Jonas characterizes this view. Curing arthritis,\nlike curing dyspepsia, baldness, and the minor aches and pains of\nliving and aging, may be nice, but may be thought to address no\nprofound problem in our lives. If this were all that clinical research\nhad to offer, we might be reluctant to accept many risks in order to\nachieve its goals. We should not, in particular, take much chance of\nwronging individuals, or exploiting them to realize these goals.\n\nThis argument makes sense to the extent that one regards the status\nquo as acceptable. Yet, without further argument, it is not clear why\none should accept this view; it seems almost certain that those\nsuffering from serious illness that might be addressed by future\nresearch will not accept it. Judgments regarding the present state of\nsociety concern very general level considerations and a determination\nthat society overall is doing fairly well is consistent with many\nindividuals suffering terrible diseases. Presumably, the suffering of\nthese individuals provides some reason to conduct clinical research.\nIn response, one might understand Jonas to be arguing that the present\nstate of affairs involves sufficiently good medicine and adequately\nflourishing lives such that the needs which could now be addressed by\nadditional clinical research are not of sufficient importance to\njustify the risks raised by conducting it. It might have been the\ncase, at some point in the past, that life was sufficiently nasty,\nbrutish and short to justify running the risk of exploiting research\nparticipants in the process of identifying ways to improve the human\nlot. But, we have advanced, in part thanks to clinical research,\nwell beyond that point. This reading need not interpret Jonas as\nignoring the fact that there remain serious ills to be cured. Instead,\nhe might be arguing that these ills, while real and unfortunate, are\nnot of sufficient gravity, or perhaps prevalence to justify the risks\nof conducting clinical research.\n\nThis view implicitly expands the ethical concerns raised by clinical\nresearch. We have been focusing on the importance of protecting\nindividual research participants. However, Jonas assumes that clinical\nresearch also threatens society in some sense. There are at least two\npossibilities here. First, it might be thought that the conduct of\nunethical research reaches beyond individual investigators to taint\nsociety as a whole. This does not seem unreasonable given that\nclinical research typically is conducted in the name of and often for\nthe benefit of society. Second, one might be concerned that allowing\ninvestigators to expose research participants to some risks for the\nbenefit of others might put us on a slippery slope that ends with\nserious abuses throughout society.\n\nAn alternative reading would be to interpret Jonas as arguing from a\nversion of the active-passive distinction. It is often claimed that\nthere is a profound moral difference between actively causing harm\nversus merely allowing harm to occur, between killing someone versus\nallowing them to die, for example. Jonas often seems to appeal to this\ndistinction when evaluating the ethics of clinical research. The idea\nis that conducting clinical research involves investigators actively\nexposing individuals to risks of harm and, when those harms are\nrealized, it involves investigators actively harming them. The\ninvestigator who injects a participant with an experimental\nmedication actively exposes the individual to risks for the\nbenefit of others and actively harms, perhaps even kills those who\nsuffer harm as a result. And, to the extent that clinical research is\nconducted in the name of and for the benefit of society in general,\none can say without too much difficulty that society is complicit in\nthese harms. Not conducting clinical research, in contrast, involves\nour allowing individuals to be subject to diseases that we might\notherwise have been able to avoid or cure. And this situation, albeit\ntragic and unfortunate, has the virtue of not involving clear moral\nwrongdoing.\n\nThe problem with at least this version of the argument is that the\nbenefits of clinical research often involve finding safer ways to\ntreat disease. The benefits of this type of clinical research, to the\nextent they are realized, involve clinicians being able to provide\nless harmful, less toxic medications to patients. Put differently,\nmany types of clinical research offer the potential to identify\nmedical treatments which harm patients less than current ones. This\nnot an idle goal. One study found that the incidence of serious\nadverse events from the appropriate use of clinical medications (i.e.\nexcluding such things as errors in drug administration, noncompliance,\noverdose, and drug abuse) in hospitalized patients was 6.7%. The same\nstudy, using data from 1994, concludes that the approved and properly\nprescribed use of medications is likely the 5th leading\ncause of death in the US (Lazarou, Pomeranz, and Corey 1998).\n\nThese data suggest that the normative calculus is significantly more\ncomplicated than the present reading of Jonas suggests. The question\nis not whether it is permissible to risk harming some individuals in\norder to make other individuals slightly better off. Instead, we have\nto decide how to trade off the possibility of clinicians exposing\npatients to greater risks of harm (albeit with a still favorable\nrisk-benefit ratio) in the process of treating them versus clinical\nresearchers exposing participants to risk of harm in the process of\ntrying to identify improved methods to treat others. This is not to\nsay that there is no normative difference between these two\nactivities, only that that difference is not accurately described as\nthe difference between harming individuals versus improving their lot\nbeyond some already acceptable status quo. It is not even a difference\nbetween harming some individuals versus allowing other individuals to\nsuffer harms. The argument that needs to be made is that harming\nindividuals in the process of conducting clinical research potentially\ninvolves a significant moral wrong not present when clinicians harm\npatients in the process of treating them.\n\nThe primary concern here is that, by exposing participants to risks of\nharm, the process of conducting clinical research involves the threat\nof exploitation of a particular kind. It runs the risk of\ninvestigators treating persons as things, devoid of any interests of\ntheir own. The worry here is not so much that investigators and\nparticipants enter together into the shared activity of clinical\nresearch with different, perhaps even conflicting goals. The concern\nis rather that, in the process of conducting clinical research,\ninvestigators treat participants as if they had no goals at all or,\nperhaps, that any goals they might have are normatively\nirrelevant.\n\nJonas argues that this concern can be addressed, and the process of\nexperimenting on some to benefit others made ethically acceptable,\nonly when the research participants share the goals of the research\nstudy. Ethically appropriate research, on Jonas\u2019s view, is\nmarked by: \u201cappropriation of the research purpose into the\nperson\u2019s own scheme of ends\u201d (Jonas 1969, 236). And\nassuming that it is in one\u2019s interests to achieve one\u2019s,\nat least, proper goals, it follows that, by participating in research,\nparticipants will be acting in their own interests, despite the fact\nthat they are thereby being exposed to risky procedures which are\nperformed to collect information to benefit others.\n\nJonas claims in some passages that research participants, at least\nthose with an illness, can share the goals of a clinical research\nstudy only when they have the condition or illness under study (Jonas\n1969). These passages reveal something of the account of human\ninterests on which Jonas\u2019s arguments rely. On standard\npreference satisfaction accounts of human interests, what is in a\ngiven individual\u2019s interests depends on what the individual\nhappens to want or prefer, or the goals the individual happens to\nendorse, or the goals the individual would endorse in some idealized\nstate scrubbed clean of the delusions, misconceptions and confusion\nwhich inform their actual preferences (Griffin 1986). On this view,\nparticipation in clinical research would promote an individual\u2019s\ninterests as long as she was well informed and wanted to participate.\nThis would be so whether or not she had the condition being studied.\nJonas\u2019s view, in contrast, seems to be that there are objective\nconditions under which individuals can share the goals of a given\nresearch study. They can endorse the cause of curing or at least\nfinding treatments for Alzheimer disease only if they suffer from the\ndisease themselves.\n\nOne possible objection would be to argue that there are many reasons\nwhy an individual might endorse the goals of a given study, apart\nfrom having the disease themselves. One might have family members\nwith the disease, or co-religionists, or have adopted improved\ntreatment of the disease as an important personal goal. The larger\nquestion is whether participants endorsing the goals of a clinical\nresearch study is a necessary condition on its acceptability. Recent\ncommentators and guidelines rarely, if ever, endorse this condition,\nalthough at least some of them might be assuming that the requirement\nto obtain free and informed consent will ensure its satisfaction. It\nmight be assumed, that is, that competent, informed, and free\nindividuals will enroll in research only when they share the goals of\nthe study in question.\n\nJonas was cognizant of the extent to which the normative concerns\nraised by clinical research are not exhausted by the risks to which\nparticipants are exposed, but also include the extent to which\ninvestigators and by implication society are the agents of their\nexposure to risks. For this reason, he recognized that the libertarian\nresponse is inadequate, even with respect to competent adults who\ntruly understand. Finally, to the extent Jonas\u2019s claims rely on\nan objective account of human interests, one may wonder whether he\nadopts an overly restrictive one. Why should we think, on an objective\naccount, that individuals will have an interest in contributing to the\ngoals of a given study only when they have the disease it addresses?\nMoreover, although we will not pursue the point here, appeal to an\nobjective account of human interests raises the possibility of\njustifying the process of exposing research participants to risks for\nthe benefit of others on the grounds that contributing to valuable\nprojects, including presumably some clinical research\nstudies, promotes (most) individuals\u2019 interests (Wendler\n2010).\n9. Industry Sponsored Research\n\nThe fundamental ethical challenge posed by clinical research is\nwhether it is acceptable to expose some to research risks for the\nbenefit of others. In the standard formulation, the one we have been\nconsidering to this point, the benefits that others enjoy as the\nresult of participants\u2019 participation in clinical research are\nmedical and health benefits, better treatments for disease, better\nmethods to prevent disease.\n\nIndustry funded research introduces the potential for a very different\nsort of benefit and thereby potentially alters, in a fundamental way,\nthe moral concerns raised by clinical research. Pharmaceutical\ncompanies typically focus on generating profit and increasing stock\nprice and market share. Indeed, it is sometimes argued that\ncorporations have an obligation to their shareholders to pursue\nincreased market share and share price (Friedman 1970). This approach\nmay well lead companies to pursue new medical treatments which have\nlittle or no potential to improve overall health and well-being\n(Huskamp 2006; Croghan and Pittman 2004). \u201cMe-too\u201d drugs\nare the classic example here. These are drugs identical in all\nclinically relevant respects to approved drugs already in use. The\ndevelopment of a me-too drug offers the potential to redistribute\nmarket share without increasing overall health and well-being.\n\nThere is considerable debate regarding how many me-too drugs there\nreally are and what is required for a drug to qualify as effectively\nidentical (Garattini 1997). For example, if the existing treatment\nneeds to be taken with meals, but a new treatment need not, is that a\nclinically relevant advance? Bracketing these questions, a drug\ncompany may well be interested in a drug which clearly qualifies as a\nme-too drug. The company may be able, by relying on a savvy marketing\ndepartment, to convince physicians to prescribe, and consumers to\nrequest the new one, thus increasing profit for the company without\nadvancing health and well-being.\n\nThe majority of clinical research was once conducted by governmental\nagencies. For example, the US NIH is likely the largest governmental\nsponsor of clinical research in the world. However, its research\nbudget has declined over the past 20 years (Mervis 2004, 2008), and it\nis estimated that a majority, perhaps a significant majority of\nclinical research studies are now conducted by industry: \u201cas\nrecently as 1991 eighty per cent of industry-sponsored trials were\nconducted in academic health centers\u2026Impatient with the slow\npace of academic bureaucracies, pharmaceutical companies have moved\ntrials to the private sector, where more than seventy per cent of them\nare now conducted\u201d (Elliott 2008, Angell 2008, Miller and Brody\n2005).\n\nIn addition to transforming the fundamental ethical challenge posed by\nclinical research, industry sponsored research has the potential to\ntransform the way that many of the specific ethical concerns are\naddressed within that context. For example, the possibility that\ninvestigators and funders may earn significant amounts of money from\ntheir participation in clinical research might, it is thought, warp\ntheir judgment in ways that conflict with appropriate protection of\nresearch participants (Fontanarosa, Flanagin, and DeAngelis 2005).\nWhen applied to investigators and funders this concern calls into\nquestion the very significant percentage of research funded by and\noften conducted by for-profit organizations. Skeptics might wonder\nwhether the goal of making money has any greater potential to\ninfluence judgment inappropriately compared to many other motivations\nthat are widely accepted, even esteemed in the context of clinical\nresearch, such as gaining tenure and fame, impressing one\u2019s\ncolleagues, or winning the Nobel Prize.\n\nFinancial conflicts of interest in clinical research point to a\ntension between relying on profits to motivate research versus\ninsulating drug development and testing from the profit motive as a\nway of protecting research participants and future patients (Psaty and\nKronmal 2008). Finally, if a company can make billions of dollars a\nyear from a single drug, one wonders what constitutes an appropriate\nresponse to the participants who were vital to its development. On a\nstandard definition, whether a given transaction is fair depends on\nthe risks and burdens that each party to the transaction bears and the\nextent to which others benefit from the party\u2019s participation in\nthe transaction (see entry on\n exploitation).\n A series of clinical research studies can result in a company earning\ntens of billions of dollars in profits. Recognizing that a fair level\nof benefit is a complex function of participants\u2019 inputs\ncompared to the inputs of others, and the extent to which third\nparties benefit from those inputs, it is difficult to see how one\nmight fill in the details of this scenario to show that the typically\nminimal, or non-existent compensation offered to research participants\nis fair.\n\nAt the same time, addressing this potential for exploitation by\noffering substantial payments to research participants who contribute\nto especially lucrative studies would introduce its own set of ethical\nconcerns: is payment an appropriate response to the kind of\ncontribution made by research participants; might payment constitute\nan undue inducement to participate; will payment undermine other\nparticipants\u2019 altruistic motivations; to what extent does\npayment encourage research participants to provide misleading or false\ninformation to investigators in order to enroll and remain in research\nstudies?\n10. Learning Health Care\n\nLike most early clinical research, James Lind\u2019s experiments on\ntreatments for scurvy took place in the clinical setting, with a\nphysician evaluating different possible treatments in his patients.\nThis practice eventually led to concern that it did not offer\nsufficient protection for patients who were frequently unaware that\nthey were involved in research. And this concern led to separating\nclinical research from clinical care and subjecting it to\nsignificantly more extensive regulations, including independent review\nand extensive consent. This approach offered greater protections for\nresearch participants and likely led to more sophisticated clinical\ntrials as the result of being conducted by dedicated researchers\nrather than clinicians in their spare time. \n\nThis segregation of clinical research from clinical care has also had\nsignificant drawbacks. It makes clinical research much more expensive\nand much more difficult to conduct. Given that studies are conducted\nin specialized environments, this approach has also undermined to some\nextent the relevance that the findings of clinical trials have for\nclinical care. For example, clinical trials assessing possible new\ntreatments for hypertension are conducted in individuals who are aware\nthat the trials exist and take the time to find out what is required\nto enroll. These studies frequently have trouble enrolling sufficient\nnumbers of participants and take years to complete. At the same time,\non the other side of the clinical research/clinical care divide,\nmillions of patients with hypertension who might be eligible for a\nclinical trial are obtaining care from their doctors. Moreover, the\ncountless data points generated by these encounters, what dose did the\npatient receive, did they experience any side effects, how long did\nthey last, end up gathering dust in the patients\u2019 medical\nrecords rather than being systematically collected and used to inform\nfuture practice.\n\nIn response, commentators have called for developing learning health\ncare systems. According to one definition, a learning health care\nsystem is one in which \u201cscience, informatics, incentives, and\nculture are aligned for continuous improvement and innovation, with\nbest practices seamlessly embedded in the care process, patients and\nfamilies active participants in all elements, and new knowledge\ncaptured as an integral by-product of the care experience\u201d\n(Committee on Learning 2013). The important point for present purposes\nis that these commentators are calling for the desegregation of\nclinical research and clinical care, with clinical research once again\nbeing conducted in the context of clinical care. This approach offers\nwhat seems a potentially appealing response to the central challenge\nof justifying the risks to which research participants are exposed.\nPut simply, this practice would be justified by the fact that the\npractice of exposing individuals to research risks is an essential\ncomponent of a learning health care system which continuously\nevaluates methods of providing clinical care and passes the benefits\nof the improvements on to its members (Faden et al 2013).\n\nThe segregated model of clinical research was designed to protect\nresearch participants from exploitation. The primary drawbacks are\nthat it is inefficient and it raises concerns over free riders,\nallowing patients to realize the benefits of improved clinical care\nwithout having to accept any of the risks associated with its\ngeneration. Learning health care systems are intended to address the\nproblem of inefficiency. Given that all the members of learning health\ncare systems are possible research participants and also beneficiaries\nof research, they may, in the process, address concerns over free\nriders. \n\nThe ethical challenge learning health care systems face is whether it\nis possible to do away with the segregated model, along with its\nregulations and practices, without reintroducing the potential for\nparticipant exploitation. For example, should individuals in a\nlearning health care system be told that their data might be used for\nresearch purposes? Should they be notified when it is? To what extent\ncan patients in learning health care systems be exposed to added risks\nfor the purposes of research? Should they be permitted to decline\nbeing so exposed? In the end, then, on-going attempts to address the\nconcerns raised by clinical research raise new ethical concerns and,\nthereby, offer opportunities for philosophers and others looking for\ninteresting, not to mention practically important issues in need of\nanalysis and resolution. \n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Angell, M., 2008. \u201cIndustry sponsored clinical research: a\nbroken system,\u201d <em>Journal of the American Medical\nAssociation</em>, 80: 899\u2013904.",
                "Appelbaum, P.S., with C.W. Lidz and T. Grisso, 2004.\n\u201cTherapeutic misconception in clinical research: frequency and\nrisk factors,\u201d <em>IRB: Ethics and Human Research</em>, 26:\n1\u20138.",
                "Australian Government, National Health and Medical Research\nCouncil, 1999. <em>National statement on ethical conduct in research\ninvolving humans</em>. Ch 2.1: 92. Commonwealth of Australia,\n1999.",
                "Beecher, H. K., 1966. \u201cEthics and clinical research,\u201d\n<em>N Engl J Med</em>, 274: 1354\u201360.",
                "Brock, D. W., 1994. \u201cEthical issues in exposing children to\nrisks in research,\u201d Chapter 3 (pp. 81\u2013101) of Grodin and\nGlantz (eds.), <em>Children as Research Subjects</em>, New York:\nOxford University Press.",
                "Brody, B.A., 1998. <em>The Ethics of Biomedical Research: An\nInternational Perspective</em>, Oxford: Oxford University Press.",
                "Caldwell, P.H.Y., with S.B. Murphy, P.H. Butow, and J.C. Craig,\n2004. \u201cClinical trials in children,\u201d <em>Lancet</em>, 364:\n803\u201311.",
                "Caplan, A., 1984. \u201cIs there a duty to serve as a subject in\nbiomedical research?\u201d <em>IRB: Ethics and Human Research</em>,\n6: 1\u20135.",
                "Committee on the Learning Health Care System in America; Institute\nof Medicine; Smith M, Saunders R, Stuckhardt L, et\nal. (eds.), <em>Best Care at Lower Cost: The Path to Continuously\nLearning Health Care in America</em>, Washington, D.C.: National\nAcademies Press; 2013 May 10.",
                "Council for International Organizations of Medical Sciences, 2002.\n<em>International ethical guidelines for biomedical research involving\nhuman subjects</em>. Geneva: CIOMS.",
                "Croghan, T.W., and P.M. Pittman, 2004. \u201cThe medicine\ncabinet: What\u2019s in it, why, and can we change the\ncontents?\u201d <em>Health Affairs</em>, 23: 23\u201333.",
                "D\u2019Arcy Hart, P., 1999. \u201cA change in scientific\napproach: From alternation to randomised allocation in clinical trials\nin the 1940s,\u201d <em>BMJ</em>, 319: 572\u20133.",
                "Department of Health and Human Services, 2005. <em>Code of Federal\nRegulations</em>: Title 45 (Public Welfare). Part 46: protection of\nhuman subjects (45 CFR 46). US Government Printing Office.",
                "Dworkin, R., 1989, \u201cThe original position,\u201d in\n<em>Reading Rawls</em>, Norman Daniels (ed.), Stanford: Stanford\nUniversity Press, 16\u201353.",
                "Dworkin, G., 2005. \u201cPaternalism,\u201d in <em>Stanford\nEncyclopedia of Philosophy</em> (Winter 2005 Edition), Edward N. Zalta\n(ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/win2005/entries/paternalism/\">https://plato.stanford.edu/archives/win2005/entries/paternalism/</a>&gt;.",
                "Elliott, C., 2008, \u201cGuinea-pigging,\u201d <em>The New\nYorker</em>, January 7, 2008, p. 36.",
                "Emanuel, E.J., with D. Wendler and C. Grady 2000. \u201cWhat\nmakes clinical research ethical?,\u201d <em>Journal of the American\nMedical Association</em>, 283: 2701\u201311.",
                "Faden, R.R., and T.L. Beauchamp, 1986. <em>A History and Theory of\nInformed Consent</em>, New York: Oxford University Press, pp.\n200\u2013232.",
                "Faden, R.R.,  N.E. Kass, S.N. Goodman, P. Pronovost, S. Tunis, and\nT.L Beauchamp. <em>An ethics framework for a learning health care system:\na departure from traditional research ethics and clinical ethics</em>,\nHastings Center Report 2013; Spec No: S16-27.",
                "Featherstone, K., and J.L. Donovan, 2002. \u201cWhy don\u2019t\nthey just tell me straight, why allocate it? The struggle to make\nsense of participating in a randomised controlled trial,\u201d\n<em>Social Science and Medicine</em>, 55: 709\u201319.",
                "Feinberg, J., 1986. <em>Harm to Self</em>, Oxford: Oxford\nUniversity Press, pp. 3\u201326.",
                "Field, M.J., and R.E. Behrman, 2004. <em>The Ethical Conduct of\nClinical Research Involving Children</em>, Washington DC: National\nAcademies Press, Ch. 2.",
                "Flory, J., and E. Emanuel, 2004. \u201cInterventions to improve\nresearch participants\u2019 understanding in informed consent for\nresearch: A systematic review,\u201d <em>Journal of the American\nMedical Association</em>, 292: 1593\u20131601.",
                "Fontanarosa P.B., with A. Flanagin A. and C.D. DeAngelis, 2005.\n\u201cReporting conflicts of interest, financial aspects of research,\nand role of sponsors in funded studies,\u201d <em>Journal of the\nAmerican Medical Association</em>, 294: 110\u201311.",
                "Freedman, B., 1987. \u201cEquipoise and the ethics of clinical\nresearch,\u201d <em>The New England Journal of Medicine</em>, 317:\n141\u201345.",
                "Friedman M., 1970, \u201cThe social responsibility of business is\nto increase its profits,\u201d <em>The New York Times Magazine</em>,\nSeptember 13, 1970.",
                "Garattini S., 1997. \u201cAre me-too drugs justified?,\u201d\n<em>J Nephrol</em>, 10: 283\u201394.",
                "Gauthier, D., 1990. <em>Morals by Agreement</em>, Oxford:\nClarendon Press.",
                "Gifford, F., 2007. \u201cPulling the plug on clinical equipoise:\nA critique of Miller and Weijer,\u201d <em>Kennedy Institute of\nEthics Journal</em>, 17: 203\u201326.",
                "Goodyear, M.D., with K. Krleza-Jeric and T. Lemmens, 2007.\n\u201cThe Declaration of Helsinki,\u201d <em>BMJ</em>, 335:\n624\u20135.",
                "Grady, C., 2005. \u201cPayment of clinical research\nsubjects,\u201d <em>J Clin Invest</em>, 115: 1681\u20137.",
                "Griffin, J., 1986. <em>Well-being: Its Meaning, Measurement and\nMoral Importance</em>, Oxford: Clarendon.",
                "Grodin, M.A., and G.J. Annas, 1996. \u201cLegacies of Nuremberg:\nMedical ethics and human rights,\u201d <em>Journal of the American\nMedical Association</em>, 276: 1682\u201383.",
                "Harmon, A., 2010. \u201cIndian Tribe Wins Fight to Limit Research\nof Its DNA,\u201d <em>New York Times</em>, 21 April 2010.",
                "Harris, J., 2005. \u201cScientific research is a moral\nduty,\u201d <em>Journal of Medical Ethics</em>, 31:\n242\u201348.",
                "Hayenhjelm, M., and J. Wolff, 2012. \u201cThe moral problem of\nrisk impositions: A survey of the literature,\u201d <em>European\nJournal of Philosophy</em>, 20 (Supplement S1): E26\u2013E51.",
                "Hellman, S., and D.S. Hellman, 1991. \u201cOf mice but not men:\nProblems of the randomized clinical trial,\u201d <em>The New England\nJournal of Medicine</em>, 324: 1585\u201389.",
                "Heyd, D., 1996. \u201cExperimentation on trial: Why should one\ntake part in medical research?\u201d, <em>Jahrbuch fur Recht und\nEthik [Annual Review of Law and Ethics]</em>, 4: 189\u2013204.",
                "Huskamp, H.A., 2006. \u201cPrices, profits, and innovation:\nExamining criticisms of new psychotropic drugs\u2019 value,\u201d\n<em>Health Affairs</em>, 25: 635\u201346.",
                "Jonas, H., 1969. \u201cPhilosophical reflections on experimenting\nwith human subjects\u201d, <em>Daedalus</em>, 98: 219\u2013247.",
                "Katz, J., 1996. \u201cThe Nuremberg Code and the Nuremberg trial.\nA reappraisal,\u201d <em>Journal of the American Medical\nAssociation</em> 276: 1662\u20136.",
                "Kopelman, L.M., 2000. \u201cChildren as research subjects: A\ndilemma,\u201d <em>Journal of Medicine and Philosophy</em>, 25:\n745\u201364.",
                "Kupst, M.J., with A.F. Patenaude, G.A. Walco, and C. Sterling,\n2003. \u201cClinical trials in pediatric cancer: Parental\nperspectives on informed consent,\u201d <em>Journal of Pediatric\nHematology and Oncology</em>, 25: 787\u201390.",
                "Lazarou, J., with B.H. Pomeranz and P.N. Corey, 1998.\n\u201cIncidence of adverse drug reactions in hospitalized patients: A\nmeta-analysis of prospective studies,\u201d <em>Journal of the\nAmerican Medical Association</em>; 279: 1200\u201305.",
                "Lederer, S.E., 1995. <em>Subjected to Science: Human\nExperimentation in America before the Second World War</em>.\nBaltimore: Johns Hopkins University Press.",
                "\u2013\u2013\u2013, 2003, \u201cChildren as guinea pigs:\nHistorical perspective,\u201d <em>Accountability in Research</em>,\n10(1): 1\u201316.",
                "Lederer, S.E., and M.A. Grodin, \u201cHistorical overview:\nPediatric experimentation,\u201d in M.A. Grodin and L.H. Glantz\n(eds.), <em>Children as Research Subjects: Science, Ethics and\nLaw</em>, New York: Oxford University Press, 1994.",
                "Levine, R.J., 1988. <em>Ethics and Regulation of Clinical\nResearch</em>. 2nd ed. New Haven, Conn: Yale University Press.",
                "Macklin, R., 1981. \u201cDue and undue inducements: On paying\nmoney to research subjects,\u201d <em>IRB: A Review of Human Subjects\nResearch</em>, 3: 1\u20136.",
                "Mervis, J., 2004. \u201cU.S. Science budget: Caught in a squeeze\nbetween tax cuts and military spending,\u201d <em>Science</em>, 30:\n587.",
                "\u2013\u2013\u2013, 2008. \u201cU.S. Budget: Promising year\nends badly after fiscal showdown squeezes science,\u201d\n<em>Science</em>, 319: 18\u20139.",
                "Mill, John Stuart, 1869, <em>On Liberty</em>. Page reference to\n<em>On Liberty and Other Writings</em>, Stefan Collini (ed.),\nCambridge, Cambridge University Press, 2005, 12th edition.",
                "Miller, F.G., and H. Brody, 2007. \u201cClinical equipoise and\nthe incoherence of research ethics,\u201d <em>Journal of Medicine and\nPhilosophy</em>, 32: 151\u201365.",
                "Miller, F.G., and A. Wertheimer, 2007. \u201cFacing up to\npaternalism in research ethics,\u201d <em>Hastings Center\nReport</em>, 37: 24\u201334.",
                "Miller, P.B., and C. Weijer, 2006. \u201cTrust based obligations\nof the state and physician-researchers to patient-subjects,\u201d\n<em>Journal of Medical Ethics</em>, 32: 542\u201347.",
                "National Bioethics Advisory Commission (NBAC), 2001. <em>Ethical\nand Policy Issues in Research Involving Human Participants</em>.\nWashington, DC: NBAC.",
                "Nicholson, R.H., 1986. <em>Medical Research with Children: Ethics,\nLaw, Practice</em>. Oxford: Oxford University Press. Pages\n87\u2013100.",
                "Nuremberg Code, 1947, in <em>Trials of war criminals before the\nNuremberg Military Tribunals under Control Council Law No. 10</em>,\nVol. 2, Washington, D.C.: U.S. Government Printing Office, 1949, pp.\n181\u2013182. Reprinted in <em>Journal of the American Medical\nAssociation</em>, 276: 1961.",
                "Psaty, B.M., and R.A. Kronmal, 2008. \u201cReporting mortality\nfindings in trials of rofecoxib for Alzheimer disease or cognitive\nimpairment: A case study based on documents from rofecoxib\nlitigation,\u201d <em>Journal of the American Medical\nAssociation</em>, 299: 1813\u20137.",
                "Ramsey, P., 1978. \u201cEthical dimensions of experimental\nresearch on children\u201d, in <em>Research on Children: Medical\nImperatives, Ethical Quandaries, and Legal Constraints</em>, J. van\nEys (ed.), Baltimore: University Park Press, p. 61.",
                "Rawls, J., 1999. <em>A Theory of Justice</em>. Cambridge, Mass:\nBelknap Press of Harvard University Press.",
                "Resnik, D.B., 2005. \u201cEliminating the daily life risks\nstandard from the definition of minimal risk,\u201d <em>Journal of\nMedical Ethics</em>, 31: 35\u20138.",
                "Rid, A., and D. Wendler, 2011. \u201cA framework for risk-benefit\nevaluations in biomedical research,\u201d <em>Kennedy Institute of\nEthics Journal</em>, 21(2): 141\u2013179.",
                "Roberts, R., with W. Rodriquez, D. Murphy, and T. Crescenzi, 2003.\n\u201cPediatric drug labeling: Improving the safety and efficacy of\npediatric therapies,\u201d <em>Journal of the American Medical\nAssociation</em>, 290: 905\u201311.",
                "Ross, L.F., and R.M. Nelson, 2006. \u201cPediatric research and\nthe federal minimal risk standard,\u201d <em>Journal of the American\nMedical Association</em>, 295: 759.",
                "Rothman, D.J., 2000. \u201cThe shame of medical research\u201d,\n<em>The New York Review of Books</em>, 47 (19): 60\u201364.",
                "Sachs, Ben, 2010. \u201cThe exceptional ethics of the\ninvestigator-subject relationship,\u201d <em>Journal of Medicine and\nPhilosophy</em>, 35: 64\u201380.",
                "Shuster, E., 1997. \u201cFifty years later: The significance of\nthe Nuremberg Code,\u201d <em>The New England Journal of\nMedicine</em>, 337: 1436\u201340.",
                "Slovic, P., 1987. \u201cPerception of risk,\u201d\n<em>Science</em>, 236: 280\u201385.",
                "Snowdon, C., with J. Garcia, and D. Elbourne, 1997. \u201cMaking\nsense of randomization: Responses of parents of critically ill babies\nto random allocation of treatment in a clinical trial,\u201d\n<em>Social Science and Medicine</em>, 45: 1337\u201355.",
                "Spilker, B., 1991. <em>Guide to clinical trials</em>,\nPhiladelphia: Lippincott, Williams and Wilkins.",
                "Stark, C., 2000. \u201cHypothetical consent and\njustification,\u201d <em>Journal of Philosophy</em>, 97:\n313\u201334.",
                "Stewart, Paul M., with Anna Stears, Jeremy W. Tomlinson, and\nMorris J. Brown, 2008. \u201cRegulation\u2014the real threat to\nclinical research,\u201d <em>British Medical Journal</em>, 337:\n1085\u20131087.",
                "Sullivan, Richard, 2008. \u201cThe good, the bad and the ugly:\nEffect of regulation on cancer research,\u201d <em>Lancet\nOncology</em>, 9: 2\u20133.",
                "Sutton, G., 2003. \u201cPutrid gums and \u2018dead men\u2019s\ncloaths\u2019: James Lind aboard the Salisbury,\u201d <em>Journal of\nthe Royal Society of Medicine</em>, 96: 605\u20138.",
                "Tversky, A., and D. Kahneman, 1974. \u201cJudgments under\nuncertainty: Heuristics and biases,\u201d <em>Science</em>, 185:\n1124\u201331.",
                "\u2013\u2013\u2013, 1981, \u201cThe framing of decisions and\nthe rationality of choice,\u201d <em>Science</em>, 211:\n453\u20138.",
                "Vollmann J., and R. Winau, 1996. \u201cInformed consent in human\nexperimentation before the Nuremberg code,\u201d <em>British Medical\nJournal</em>, 313: 1445\u20137.",
                "Weinstein, N., 1989. \u201cOptimistic biases about personal\nrisks,\u201d <em>Science</em>, 246: 1232\u20133.",
                "Wenar, L., 2008. \u201cJohn Rawls\u201d, <em>The Stanford\nEncyclopedia of Philosophy (Summer 2008 Edition)</em>, Edward N. Zalta\n(ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/sum2008/entries/rawls/\">https://plato.stanford.edu/archives/sum2008/entries/rawls/</a>&gt;.",
                "Wendler, D., 2010, <em>The Ethics of Pediatric Research</em>,\nOxford: Oxford University Press.",
                "Wertheimer, A., 2008. \u201cExploitation\u201d, <em>The Stanford\nEncyclopedia of Philosophy</em> (Fall 2008 Edition), Edward N. Zalta\n(ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/fall2008/entries/exploitation/\">https://plato.stanford.edu/archives/fall2008/entries/exploitation/</a>&gt;.",
                "\u2013\u2013\u2013, 2010, <em>Rethinking the Ethics of Clinical\nResearch: Widening the Lens</em>, Oxford: Oxford University\nPress.",
                "Wilson, James, and David Hunter, 2010. \u201cResearch\nexceptionalism,\u201d <em>American Journal of Bioethics</em>, 10:\n45\u201354.",
                "World Medical Organization, 1996. <em>Declaration of\nHelsinki</em>, British Medical Journal, 313 (7070):\n1448\u20131449."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Angell, M., 2008. \u201cIndustry sponsored clinical research: a\nbroken system,\u201d <em>Journal of the American Medical\nAssociation</em>, 80: 899\u2013904.</li>\n<li>Appelbaum, P.S., with C.W. Lidz and T. Grisso, 2004.\n\u201cTherapeutic misconception in clinical research: frequency and\nrisk factors,\u201d <em>IRB: Ethics and Human Research</em>, 26:\n1\u20138.</li>\n<li>Australian Government, National Health and Medical Research\nCouncil, 1999. <em>National statement on ethical conduct in research\ninvolving humans</em>. Ch 2.1: 92. Commonwealth of Australia,\n1999.</li>\n<li>Beecher, H. K., 1966. \u201cEthics and clinical research,\u201d\n<em>N Engl J Med</em>, 274: 1354\u201360.</li>\n<li>Brock, D. W., 1994. \u201cEthical issues in exposing children to\nrisks in research,\u201d Chapter 3 (pp. 81\u2013101) of Grodin and\nGlantz (eds.), <em>Children as Research Subjects</em>, New York:\nOxford University Press.</li>\n<li>Brody, B.A., 1998. <em>The Ethics of Biomedical Research: An\nInternational Perspective</em>, Oxford: Oxford University Press.</li>\n<li>Caldwell, P.H.Y., with S.B. Murphy, P.H. Butow, and J.C. Craig,\n2004. \u201cClinical trials in children,\u201d <em>Lancet</em>, 364:\n803\u201311.</li>\n<li>Caplan, A., 1984. \u201cIs there a duty to serve as a subject in\nbiomedical research?\u201d <em>IRB: Ethics and Human Research</em>,\n6: 1\u20135.</li>\n<li>Committee on the Learning Health Care System in America; Institute\nof Medicine; Smith M, Saunders R, Stuckhardt L, et\nal. (eds.), <em>Best Care at Lower Cost: The Path to Continuously\nLearning Health Care in America</em>, Washington, D.C.: National\nAcademies Press; 2013 May 10.</li>\n<li>Council for International Organizations of Medical Sciences, 2002.\n<em>International ethical guidelines for biomedical research involving\nhuman subjects</em>. Geneva: CIOMS.</li>\n<li>Croghan, T.W., and P.M. Pittman, 2004. \u201cThe medicine\ncabinet: What\u2019s in it, why, and can we change the\ncontents?\u201d <em>Health Affairs</em>, 23: 23\u201333.</li>\n<li>D\u2019Arcy Hart, P., 1999. \u201cA change in scientific\napproach: From alternation to randomised allocation in clinical trials\nin the 1940s,\u201d <em>BMJ</em>, 319: 572\u20133.</li>\n<li>Department of Health and Human Services, 2005. <em>Code of Federal\nRegulations</em>: Title 45 (Public Welfare). Part 46: protection of\nhuman subjects (45 CFR 46). US Government Printing Office.</li>\n<li>Dworkin, R., 1989, \u201cThe original position,\u201d in\n<em>Reading Rawls</em>, Norman Daniels (ed.), Stanford: Stanford\nUniversity Press, 16\u201353.</li>\n<li>Dworkin, G., 2005. \u201cPaternalism,\u201d in <em>Stanford\nEncyclopedia of Philosophy</em> (Winter 2005 Edition), Edward N. Zalta\n(ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/win2005/entries/paternalism/\">https://plato.stanford.edu/archives/win2005/entries/paternalism/</a>&gt;.</li>\n<li>Elliott, C., 2008, \u201cGuinea-pigging,\u201d <em>The New\nYorker</em>, January 7, 2008, p. 36.</li>\n<li>Emanuel, E.J., with D. Wendler and C. Grady 2000. \u201cWhat\nmakes clinical research ethical?,\u201d <em>Journal of the American\nMedical Association</em>, 283: 2701\u201311.</li>\n<li>Faden, R.R., and T.L. Beauchamp, 1986. <em>A History and Theory of\nInformed Consent</em>, New York: Oxford University Press, pp.\n200\u2013232.</li>\n<li>Faden, R.R.,  N.E. Kass, S.N. Goodman, P. Pronovost, S. Tunis, and\nT.L Beauchamp. <em>An ethics framework for a learning health care system:\na departure from traditional research ethics and clinical ethics</em>,\nHastings Center Report 2013; Spec No: S16-27.</li>\n<li>Featherstone, K., and J.L. Donovan, 2002. \u201cWhy don\u2019t\nthey just tell me straight, why allocate it? The struggle to make\nsense of participating in a randomised controlled trial,\u201d\n<em>Social Science and Medicine</em>, 55: 709\u201319.</li>\n<li>Feinberg, J., 1986. <em>Harm to Self</em>, Oxford: Oxford\nUniversity Press, pp. 3\u201326.</li>\n<li>Field, M.J., and R.E. Behrman, 2004. <em>The Ethical Conduct of\nClinical Research Involving Children</em>, Washington DC: National\nAcademies Press, Ch. 2.</li>\n<li>Flory, J., and E. Emanuel, 2004. \u201cInterventions to improve\nresearch participants\u2019 understanding in informed consent for\nresearch: A systematic review,\u201d <em>Journal of the American\nMedical Association</em>, 292: 1593\u20131601.</li>\n<li>Fontanarosa P.B., with A. Flanagin A. and C.D. DeAngelis, 2005.\n\u201cReporting conflicts of interest, financial aspects of research,\nand role of sponsors in funded studies,\u201d <em>Journal of the\nAmerican Medical Association</em>, 294: 110\u201311.</li>\n<li>Freedman, B., 1987. \u201cEquipoise and the ethics of clinical\nresearch,\u201d <em>The New England Journal of Medicine</em>, 317:\n141\u201345.</li>\n<li>Friedman M., 1970, \u201cThe social responsibility of business is\nto increase its profits,\u201d <em>The New York Times Magazine</em>,\nSeptember 13, 1970.</li>\n<li>Garattini S., 1997. \u201cAre me-too drugs justified?,\u201d\n<em>J Nephrol</em>, 10: 283\u201394.</li>\n<li>Gauthier, D., 1990. <em>Morals by Agreement</em>, Oxford:\nClarendon Press.</li>\n<li>Gifford, F., 2007. \u201cPulling the plug on clinical equipoise:\nA critique of Miller and Weijer,\u201d <em>Kennedy Institute of\nEthics Journal</em>, 17: 203\u201326.</li>\n<li>Goodyear, M.D., with K. Krleza-Jeric and T. Lemmens, 2007.\n\u201cThe Declaration of Helsinki,\u201d <em>BMJ</em>, 335:\n624\u20135.</li>\n<li>Grady, C., 2005. \u201cPayment of clinical research\nsubjects,\u201d <em>J Clin Invest</em>, 115: 1681\u20137.</li>\n<li>Griffin, J., 1986. <em>Well-being: Its Meaning, Measurement and\nMoral Importance</em>, Oxford: Clarendon.</li>\n<li>Grodin, M.A., and G.J. Annas, 1996. \u201cLegacies of Nuremberg:\nMedical ethics and human rights,\u201d <em>Journal of the American\nMedical Association</em>, 276: 1682\u201383.</li>\n<li>Harmon, A., 2010. \u201cIndian Tribe Wins Fight to Limit Research\nof Its DNA,\u201d <em>New York Times</em>, 21 April 2010.</li>\n<li>Harris, J., 2005. \u201cScientific research is a moral\nduty,\u201d <em>Journal of Medical Ethics</em>, 31:\n242\u201348.</li>\n<li>Hayenhjelm, M., and J. Wolff, 2012. \u201cThe moral problem of\nrisk impositions: A survey of the literature,\u201d <em>European\nJournal of Philosophy</em>, 20 (Supplement S1): E26\u2013E51.</li>\n<li>Hellman, S., and D.S. Hellman, 1991. \u201cOf mice but not men:\nProblems of the randomized clinical trial,\u201d <em>The New England\nJournal of Medicine</em>, 324: 1585\u201389.</li>\n<li>Heyd, D., 1996. \u201cExperimentation on trial: Why should one\ntake part in medical research?\u201d, <em>Jahrbuch fur Recht und\nEthik [Annual Review of Law and Ethics]</em>, 4: 189\u2013204.</li>\n<li>Huskamp, H.A., 2006. \u201cPrices, profits, and innovation:\nExamining criticisms of new psychotropic drugs\u2019 value,\u201d\n<em>Health Affairs</em>, 25: 635\u201346.</li>\n<li>Jonas, H., 1969. \u201cPhilosophical reflections on experimenting\nwith human subjects\u201d, <em>Daedalus</em>, 98: 219\u2013247.</li>\n<li>Katz, J., 1996. \u201cThe Nuremberg Code and the Nuremberg trial.\nA reappraisal,\u201d <em>Journal of the American Medical\nAssociation</em> 276: 1662\u20136.</li>\n<li>Kopelman, L.M., 2000. \u201cChildren as research subjects: A\ndilemma,\u201d <em>Journal of Medicine and Philosophy</em>, 25:\n745\u201364.</li>\n<li>Kupst, M.J., with A.F. Patenaude, G.A. Walco, and C. Sterling,\n2003. \u201cClinical trials in pediatric cancer: Parental\nperspectives on informed consent,\u201d <em>Journal of Pediatric\nHematology and Oncology</em>, 25: 787\u201390.</li>\n<li>Lazarou, J., with B.H. Pomeranz and P.N. Corey, 1998.\n\u201cIncidence of adverse drug reactions in hospitalized patients: A\nmeta-analysis of prospective studies,\u201d <em>Journal of the\nAmerican Medical Association</em>; 279: 1200\u201305.</li>\n<li>Lederer, S.E., 1995. <em>Subjected to Science: Human\nExperimentation in America before the Second World War</em>.\nBaltimore: Johns Hopkins University Press.</li>\n<li>\u2013\u2013\u2013, 2003, \u201cChildren as guinea pigs:\nHistorical perspective,\u201d <em>Accountability in Research</em>,\n10(1): 1\u201316.</li>\n<li>Lederer, S.E., and M.A. Grodin, \u201cHistorical overview:\nPediatric experimentation,\u201d in M.A. Grodin and L.H. Glantz\n(eds.), <em>Children as Research Subjects: Science, Ethics and\nLaw</em>, New York: Oxford University Press, 1994.</li>\n<li>Levine, R.J., 1988. <em>Ethics and Regulation of Clinical\nResearch</em>. 2nd ed. New Haven, Conn: Yale University Press.</li>\n<li>Macklin, R., 1981. \u201cDue and undue inducements: On paying\nmoney to research subjects,\u201d <em>IRB: A Review of Human Subjects\nResearch</em>, 3: 1\u20136.</li>\n<li>Mervis, J., 2004. \u201cU.S. Science budget: Caught in a squeeze\nbetween tax cuts and military spending,\u201d <em>Science</em>, 30:\n587.</li>\n<li>\u2013\u2013\u2013, 2008. \u201cU.S. Budget: Promising year\nends badly after fiscal showdown squeezes science,\u201d\n<em>Science</em>, 319: 18\u20139.</li>\n<li>Mill, John Stuart, 1869, <em>On Liberty</em>. Page reference to\n<em>On Liberty and Other Writings</em>, Stefan Collini (ed.),\nCambridge, Cambridge University Press, 2005, 12th edition.</li>\n<li>Miller, F.G., and H. Brody, 2007. \u201cClinical equipoise and\nthe incoherence of research ethics,\u201d <em>Journal of Medicine and\nPhilosophy</em>, 32: 151\u201365.</li>\n<li>Miller, F.G., and A. Wertheimer, 2007. \u201cFacing up to\npaternalism in research ethics,\u201d <em>Hastings Center\nReport</em>, 37: 24\u201334.</li>\n<li>Miller, P.B., and C. Weijer, 2006. \u201cTrust based obligations\nof the state and physician-researchers to patient-subjects,\u201d\n<em>Journal of Medical Ethics</em>, 32: 542\u201347.</li>\n<li>National Bioethics Advisory Commission (NBAC), 2001. <em>Ethical\nand Policy Issues in Research Involving Human Participants</em>.\nWashington, DC: NBAC.</li>\n<li>Nicholson, R.H., 1986. <em>Medical Research with Children: Ethics,\nLaw, Practice</em>. Oxford: Oxford University Press. Pages\n87\u2013100.</li>\n<li>Nuremberg Code, 1947, in <em>Trials of war criminals before the\nNuremberg Military Tribunals under Control Council Law No. 10</em>,\nVol. 2, Washington, D.C.: U.S. Government Printing Office, 1949, pp.\n181\u2013182. Reprinted in <em>Journal of the American Medical\nAssociation</em>, 276: 1961.</li>\n<li>Psaty, B.M., and R.A. Kronmal, 2008. \u201cReporting mortality\nfindings in trials of rofecoxib for Alzheimer disease or cognitive\nimpairment: A case study based on documents from rofecoxib\nlitigation,\u201d <em>Journal of the American Medical\nAssociation</em>, 299: 1813\u20137.</li>\n<li>Ramsey, P., 1978. \u201cEthical dimensions of experimental\nresearch on children\u201d, in <em>Research on Children: Medical\nImperatives, Ethical Quandaries, and Legal Constraints</em>, J. van\nEys (ed.), Baltimore: University Park Press, p. 61.</li>\n<li>Rawls, J., 1999. <em>A Theory of Justice</em>. Cambridge, Mass:\nBelknap Press of Harvard University Press.</li>\n<li>Resnik, D.B., 2005. \u201cEliminating the daily life risks\nstandard from the definition of minimal risk,\u201d <em>Journal of\nMedical Ethics</em>, 31: 35\u20138.</li>\n<li>Rid, A., and D. Wendler, 2011. \u201cA framework for risk-benefit\nevaluations in biomedical research,\u201d <em>Kennedy Institute of\nEthics Journal</em>, 21(2): 141\u2013179.</li>\n<li>Roberts, R., with W. Rodriquez, D. Murphy, and T. Crescenzi, 2003.\n\u201cPediatric drug labeling: Improving the safety and efficacy of\npediatric therapies,\u201d <em>Journal of the American Medical\nAssociation</em>, 290: 905\u201311.</li>\n<li>Ross, L.F., and R.M. Nelson, 2006. \u201cPediatric research and\nthe federal minimal risk standard,\u201d <em>Journal of the American\nMedical Association</em>, 295: 759.</li>\n<li>Rothman, D.J., 2000. \u201cThe shame of medical research\u201d,\n<em>The New York Review of Books</em>, 47 (19): 60\u201364.</li>\n<li>Sachs, Ben, 2010. \u201cThe exceptional ethics of the\ninvestigator-subject relationship,\u201d <em>Journal of Medicine and\nPhilosophy</em>, 35: 64\u201380.</li>\n<li>Shuster, E., 1997. \u201cFifty years later: The significance of\nthe Nuremberg Code,\u201d <em>The New England Journal of\nMedicine</em>, 337: 1436\u201340.</li>\n<li>Slovic, P., 1987. \u201cPerception of risk,\u201d\n<em>Science</em>, 236: 280\u201385.</li>\n<li>Snowdon, C., with J. Garcia, and D. Elbourne, 1997. \u201cMaking\nsense of randomization: Responses of parents of critically ill babies\nto random allocation of treatment in a clinical trial,\u201d\n<em>Social Science and Medicine</em>, 45: 1337\u201355.</li>\n<li>Spilker, B., 1991. <em>Guide to clinical trials</em>,\nPhiladelphia: Lippincott, Williams and Wilkins.</li>\n<li>Stark, C., 2000. \u201cHypothetical consent and\njustification,\u201d <em>Journal of Philosophy</em>, 97:\n313\u201334.</li>\n<li>Stewart, Paul M., with Anna Stears, Jeremy W. Tomlinson, and\nMorris J. Brown, 2008. \u201cRegulation\u2014the real threat to\nclinical research,\u201d <em>British Medical Journal</em>, 337:\n1085\u20131087.</li>\n<li>Sullivan, Richard, 2008. \u201cThe good, the bad and the ugly:\nEffect of regulation on cancer research,\u201d <em>Lancet\nOncology</em>, 9: 2\u20133.</li>\n<li>Sutton, G., 2003. \u201cPutrid gums and \u2018dead men\u2019s\ncloaths\u2019: James Lind aboard the Salisbury,\u201d <em>Journal of\nthe Royal Society of Medicine</em>, 96: 605\u20138.</li>\n<li>Tversky, A., and D. Kahneman, 1974. \u201cJudgments under\nuncertainty: Heuristics and biases,\u201d <em>Science</em>, 185:\n1124\u201331.</li>\n<li>\u2013\u2013\u2013, 1981, \u201cThe framing of decisions and\nthe rationality of choice,\u201d <em>Science</em>, 211:\n453\u20138.</li>\n<li>Vollmann J., and R. Winau, 1996. \u201cInformed consent in human\nexperimentation before the Nuremberg code,\u201d <em>British Medical\nJournal</em>, 313: 1445\u20137.</li>\n<li>Weinstein, N., 1989. \u201cOptimistic biases about personal\nrisks,\u201d <em>Science</em>, 246: 1232\u20133.</li>\n<li>Wenar, L., 2008. \u201cJohn Rawls\u201d, <em>The Stanford\nEncyclopedia of Philosophy (Summer 2008 Edition)</em>, Edward N. Zalta\n(ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/sum2008/entries/rawls/\">https://plato.stanford.edu/archives/sum2008/entries/rawls/</a>&gt;.</li>\n<li>Wendler, D., 2010, <em>The Ethics of Pediatric Research</em>,\nOxford: Oxford University Press.</li>\n<li>Wertheimer, A., 2008. \u201cExploitation\u201d, <em>The Stanford\nEncyclopedia of Philosophy</em> (Fall 2008 Edition), Edward N. Zalta\n(ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/fall2008/entries/exploitation/\">https://plato.stanford.edu/archives/fall2008/entries/exploitation/</a>&gt;.</li>\n<li>\u2013\u2013\u2013, 2010, <em>Rethinking the Ethics of Clinical\nResearch: Widening the Lens</em>, Oxford: Oxford University\nPress.</li>\n<li>Wilson, James, and David Hunter, 2010. \u201cResearch\nexceptionalism,\u201d <em>American Journal of Bioethics</em>, 10:\n45\u201354.</li>\n<li>World Medical Organization, 1996. <em>Declaration of\nHelsinki</em>, British Medical Journal, 313 (7070):\n1448\u20131449.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "cloning",
            "contract law, philosophy of",
            "decision-making capacity",
            "exploitation",
            "health",
            "informed consent",
            "original position",
            "paternalism",
            "Rawls, John",
            "risk"
        ],
        "entry_link": [
            {
                "../cloning/": "cloning"
            },
            {
                "../contract-law/": "contract law, philosophy of"
            },
            {
                "../decision-capacity/": "decision-making capacity"
            },
            {
                "../exploitation/": "exploitation"
            },
            {
                "../health-disease/": "health"
            },
            {
                "../informed-consent/": "informed consent"
            },
            {
                "../original-position/": "original position"
            },
            {
                "../paternalism/": "paternalism"
            },
            {
                "../rawls/": "Rawls, John"
            },
            {
                "../risk/": "risk"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=clinical-research\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/clinical-research/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=clinical-research&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/clinical-research/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=clinical-research": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/clinical-research/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=clinical-research&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/clinical-research/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "<a href=\"http://bioethics.net/\" target=\"other\">Bioethics.net</a>,\n organized by the editors of the American Journal of Bioethics.",
            "<a href=\"http://www.drze.de/BELIT\" target=\"other\">Bioethics Literature Database</a>,\n German site for conducting searches",
            "<a href=\"http://bioethics.georgetown.edu/nrc/\" target=\"other\">National Reference Center for Bioethics Literature</a>,\n organized by the research library at the Kennedy Institute of\nEthics",
            "<a href=\"http://www.nuffieldbioethics.org/\" target=\"other\">Nuffield Council on Bioethics</a>,\n organized by the Nuffield council, the preeminent organization on\nethics in Britain",
            "<a href=\"http://www.hhs.gov/ohrp/\" target=\"other\">Office for Human Research Protections</a>\n (OHRP), Department of Health and Human Services, website of the office\nthat oversees U.S. research regulations.",
            "<a href=\"http://www.primr.org/\" target=\"other\">PRIM&amp;R</a>,\n Public Responsibility in Medicine and Research"
        ],
        "listed_links": [
            {
                "http://bioethics.net/": "Bioethics.net"
            },
            {
                "http://www.drze.de/BELIT": "Bioethics Literature Database"
            },
            {
                "http://bioethics.georgetown.edu/nrc/": "National Reference Center for Bioethics Literature"
            },
            {
                "http://www.nuffieldbioethics.org/": "Nuffield Council on Bioethics"
            },
            {
                "http://www.hhs.gov/ohrp/": "Office for Human Research Protections"
            },
            {
                "http://www.primr.org/": "PRIM&R"
            }
        ]
    }
}