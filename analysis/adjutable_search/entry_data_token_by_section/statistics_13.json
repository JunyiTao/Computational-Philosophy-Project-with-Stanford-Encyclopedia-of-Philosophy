{
    "main_text": "Statistical models || Model comparisons\n5.1 Model comparisons\nThere are in fact very many methods for evaluating statistical\nmodels (Claeskens and Hjort 2008, Wagenmakers and Waldorp 2006). In\nfirst instance, the methods occasion the comparison of statistical\nmodels, but very often they are used for selecting one model over the\nothers. In what follows we only review prominent techniques that have\nled to philosophical debate: Akaike's information criterion, the\nBayesian information criterion, and furthermore the computation of\nmarginal likelihoods and posterior model probabilities, both\nassociated with Bayesian model selection. We leave aside methods that\nuse cross-validation as they have, unduly, not received as much\nattention in the philosophical literature.\n5.1.1 Akaike's information criterion\nAkaike's information criterion, modestly termed An\nInformation Criterion or AIC for short, is based on the classical\nstatistical procedure of estimation (see Burnham and Anderson 2002,\nKieseppa 1997). It starts from the idea that a model \\(M\\) can be\njudged by the estimate \\(\\hat{\\theta}\\) that it delivers, and more\nspecifically by the proximity of this estimate to the distribution\nwith which the data are actually generated, i.e., the true\ndistribution. This proximity is often equated with the expected\npredictive accuracy of the estimate, because if the estimate and the\ntrue distribution are closer to each other, their predictions will be\nbetter aligned to one another as well. In the derivation of the AIC,\nthe so-called relative entropy or Kullback-Leibler divergence\nof the two distributions is used as a measure of their proximity, and\nhence as a measure of the expected predictive accuracy of the\nestimate.\nNaturally, the true distribution is not known to the statistician\nwho is evaluating the model. If it were, then the whole statistical\nanalysis would be useless. However, it turns out that we can give an\nunbiased estimation of the divergence between the true distribution\nand the distribution estimated from a particular model,\n\n \\[ \\text{AIC}[M] = - 2 \\log P( s \\mid h_{\\hat{\\theta}(s)} ) + 2 d , \\]\n\nin which \\(s\\) is the sample data, \\(\\hat{\\theta}(s)\\) is the maximum\nlikelihood estimate (MLE) of the model \\(M\\), and \\(d = dim(\\Theta)\\)\nis the number of dimensions of the parameter space of the model. The\nMLE of the model thereby features in an expression of the model\nquality, i.e., in a role that is conceptually distinct from the\nestimator function.\nAs can be seen from the expression above, a model with a smaller\nAIC is preferable: we want the fit to be optimal at little cost in\ncomplexity. Notice that the number of dimensions, or independent\nparameters, in the model increases the AIC and thereby lowers the\neligibility of the model: if two models achieve the same maximum\nlikelihood for the sample, then the model with fewer parameters will\nbe preferred. For this reason, statistical model selection by the AIC\ncan be seen as an independent motivation for preferring simple models\nover more complex ones (Sober and Forster 1994). But this result also\ninvites some critical remarks. For one, we might impose other criteria\nthan merely the unbiasedness on the estimation of the proximity to the\ntruth, and this will lead to different expressions for the\napproximation. Moreover, it is not always clearcut what the\ndimensions of the model under scrutiny really are. For curve fitting\nthis may seem simple, but for more complicated models or different\nconceptualizations of the space of models, things do not look so easy\n(cf. Myung et al 2001, Kieseppa 2001). \nA prime example of model selection is presented in curve\nfitting.  Given a sample \\(s\\) consisting of a set of points in\nthe plane \\((x, y)\\), we are asked to choose the curve that fits these\ndata best. We assume that the models under consideration are of the\nform \\(y = f(x) + \\epsilon\\), where \\(\\epsilon\\) is a normal\ndistribution with mean 0 and a fixed standard deviation, and where\n\\(f\\) is a polynomial function. Different models are characterized by\npolynomials of different degrees that have different numbers of\nparameters. Estimations fix the parameters of these polynomials. For\nexample, for the 0-degree polynomial \\(f(x) = c_{0}\\) we estimate the\nconstant \\(\\hat{c_{0}}\\) for which the probability of the data is\nmaximal, and for the 1-degree polynomial \\(f(x) = c_{0} + c_{1}\\, x\\)\nwe estimate the slope \\(\\hat{c_{1}}\\) and the offset\n\\(\\hat{c_{0}}\\). Now notice that for a total of \\(n\\) points, we can\nalways find a polynomial of degree \\(n\\) that intersects with all\npoints exactly, resulting in a comparatively high maximum likelihood\n\\(P(s \\mid \\{\\hat{c_{0}}, \\ldots \\hat{c_{n}} \\})\\). Applying the AIC,\nhowever, we will typically find that some model with a polynomial of\ndegree \\(k < n\\) is preferable. Although \\(P(s \\mid \\{\\hat{c_{0}},\n\\ldots \\hat{c_{k}} \\})\\) will be somewhat lower, this is compensated\nfor in the AIC by the smaller number of parameters.\n5.1.2 Bayesian evaluation of models\nVarious other prominent model selection tools are based on methods\nfrom Bayesian statistics. They all start from the idea that the\nquality of a model is expressed in the performance of the model on the\nsample data: the model that, on the whole, makes the sampled data most\nprobable is to be preferred.  Because of this, there is a close\nconnection with the hierarchical Bayesian modelling referred to\nearlier (Gelman 2013). The central notion in the Bayesian model\nselection tools is thus the marginal likelihood of the model, i.e.,\nthe weighted average of the likelihoods over the model, using the\nprior distribution as a weighing function:\n\n\\[ P(s \\mid M_{i}) \\; = \\; \\int_{\\theta \\in \\Theta_{i}} P(h_{\\theta}) P(s\n\\mid h_{\\theta}) d\\theta . \\]\n\nHere \\(\\Theta_{i}\\) is the parameter space belonging to model\n\\(M_{i}\\).  The marginal likelihoods can be combined with a prior\nprobability over models, \\(P(M_{i})\\), to derive the\nso-called posterior model probability, using Bayes'\ntheorem. One way of evaluating models, known as Bayesian model\nselection, is by comparing the models on their marginal\nlikelihood, or else on their posteriors (cf. Kass and Raftery\n1995).\nUsually the marginal likelihood cannot be computed analytically.\nNumerical approximations can often be obtained, but for practical\npurposes it has proved very useful, and quite sufficient, to employ an\napproximation of the marginal likelihood. This approximation has\nbecome known as the Bayesian information criterion, or BIC\nfor short (Schwarz 1978, Raftery 1995). It turns out that this\napproximation shows remarkable similarities to the AIC:\n\n\\[ \\text{BIC}[M] \\; = \\; - 2 \\log P(s \\mid h_{\\hat{\\theta}(s)}) + d \\log\nn . \\]\n\nHere \\(\\hat{\\theta}(s)\\) is again the maximum likelihood estimate of\nthe model, \\(d = dim(M)\\) the number of independent parameters, and\n\\(n\\) is the number of data points in the sample. The latter\ndependence is the only difference with the AIC, but a major difference\nin how the model evaluation may turn out.\nThe concurrence of the AIC and the BIC seems to give a further\nmotivation for our intuitive preference for simple models over more\ncomplex ones. Indeed, other model selection tools, like the\ndeviance information criterion (Spiegelhalter et al 2002) and\nthe approach based on minimum description length (Grunwald\n2007), also result in expressions that feature a term that penalizes\ncomplex models. However, this is not to say that the dimension term\nthat we know from the information criteria exhausts the notion of\nmodel complexity. There is ongoing debate in the philosophy of science\nconcerning the merits of model selection in explications of the notion\nof simplicity, informativeness, and the like (see, for example, Sober\n2004, Romeijn and van de Schoot 2008, Romeijn et al 2012, Sprenger\n2013).\n5.2 Statistics without models\nThere are also statistical methods that refrain from the use of a\nparticular model, by focusing exclusively on the data or by\ngeneralizing over all possible models.  Some of these techniques are\nproperly localized in descriptive statistics: they do not concern an\ninference from data but merely serve to describe the data in a\nparticular way. Statistical methods that do not rely on an explicit\nmodel choice have unfortunately not attracted much attention in the\nphilosophy of statistics, but for completeness sake they will be\nbriefly discussed here.\n5.2.1 Data reduction techniques\nOne set of methods, and a quite important one for many practicing\nstatisticians, is aimed at data reduction. Often the sample\ndata are very rich, e.g., consisting of a set of points in a space of\nvery many dimensions. The first step in a statistical analysis may\nthen be to pick out the salient variability in the data, in order to\nscale down the computational burden of the analysis itself.\nThe technique of principal component analysis (PCA) is\ndesigned for this purpose (Jolliffe 2002). Given a set of points in a\nspace, it seeks out the set of vectors along which the variation in\nthe points is large. As an example, consider two points in a plane\nparameterized as \\((x, y)\\): the points \\((0, 0)\\) and \\((1, 1)\\). In\nthe \\(x\\)-direction and in the \\(y\\)-direction the variation is \\(1\\),\nbut over the diagonal the variation is maximal, namely\n\\(\\sqrt{2}\\). The vector on the diagonal is called the principal\ncomponent of the data. In richer data structures, and using a more\ngeneral measure of variation among points, we can find the first\ncomponent in a similar way. Moreover, we can repeat the procedure\nafter subtracting the variation along the last found component, by\nprojecting the data onto the plane perpendicular to that\ncomponent. This allows us to build up a set of principal components of\ndiminishing importance.\nPCA is only one item from a large collection of techniques that are\naimed at keeping the data manageable and finding patterns in it, a\ncollection that also includes kernel methods and support\nvector machines (e.g., Vapnik and Kotz 2006). For present\npurposes, it is important to stress that such tools should not be\nconfused with statistical analysis: they do not involve the testing or\nevaluation of distributions over sample space, even though they build\nup and evaluate models of the data. This sets them apart from, e.g.,\nconfirmatory and exploratory factor analysis (Bartholomew 2008), which\nis sometimes taken to be a close relative of PCA because both\nsets of techniques allows us to identify salient dimensions within\nsample space, along which the data show large variation. \nPracticing statisticians often employ data reduction tools to\narrive at conclusions on the distributions from which the data were\nsampled. There is already a wide use for machine learning and data\nmining techniques in the sciences, and we may expect even mode usage\nof these techniques in the future, because so much data is now coming\navailable for scientific analysis. However, in the philosophy of\nstatistics there is as yet little debate over the epistemic status of\nconclusions reached by means of these techniques. Philosophers of\nstatistics would do well to direct some attention here.\n5.2.2 Formal learning theory\nAn entirely different approach to statistics is presented by\n formal learning theory.\nThis is again a vast area of research, primarily located in\ncomputer science and artificial intelligence. The discipline is here\nmentioned briefly, as another example of an approach to statistics\nthat avoids the choice of a statistical model altogether and merely\nidentifies patterns in the data. We leave aside the theory of\nneural networks, which also concerns predictive systems that\ndo not rely on a statistical model, and focus on the theory of\nlearning algorithms because of all these approaches they have seen\nmost philosophical attention.\nPioneering work on formal learning was done by Solomonoff\n(1964). As before, the setting is one in which the data consist of\nstrings of 0's and 1's, and in which an agent is attempting to\nidentify the pattern in these data. So, for example, the data may be a\nstring of the form \\(0101010101\\ldots\\), and the challenge is to\nidentify this strings as an alternating sequence. The central idea of\nSolomonoff is that all possible computable patterns must be considered\nby the agent, and therefore that no restrictive choice on statistical\nhypotheses is warranted. Solomonoff then defined a formal system in\nwhich indeed all patterns can be taken into consideration, effectively\nusing a Bayesian analysis with a cleverly constructed prior over all\ncomputable hypotheses.\nThis general idea can also be identified in a rather new field on\nthe intersection of Bayesian statistics and machine learning,\nBayesian nonparametrics (e.g., Orbanz and Teh\n2010, Hjort et al 2010). Rather than specifying, at the outset, a\nconfined set of distributions from which a statistical analysis is\nsupposed to choose on the basis of the data, the idea is that the data\nare confronted with a potentially infinite-dimensional space of\npossible distributions. The set of distributions taken into\nconsideration is then made relative to the data obtained: the\ncomplexity of the model grows with the sample. The result is a\npredictive system that performs an online model selection alongside a\nBayesian accommodation of the posterior over the model.\nCurrent formal learning theory is a lively field, to which\nphilosophers of statistics also contribute (e.g., Kelly 1996, Kelly et\nal 1997). Particularly salient for the present concerns is that the\nsystems of formal learning are set up to achieve some notion of\nadequate universal prediction, without confining themselves\nto a specific set of hypotheses, and hence by imposing minimal\nconstraints on the set of possible patterns in the data. It is a\nmatter of debate whether this is at all possible, and to what extent\nthe predictions of formal learning theory thereby rely on, e.g.,\nimplicit assumptions on structure of the sample space. Philosophical\nreflection on this is only in its infancy.\n6. Related topics\n\nThere are numerous topics in the philosophy of science that bear\ndirect relevance to the themes covered in this lemma. A few central\ntopics are mentioned here to direct the reader to related lemmas in\nthe encyclopedia. \nOne very important topic that is immediately adjacent to the\nphilosophy of statistics is \n confirmation theory, \nthe philosophical theory that describes and justifies\nrelations between scientific theory and empirical\nevidence. Arguably, the theory of statistics is a proper part of\nconfirmation theory, as it describes and justifies the relation that\nobtains between statistical theory and evidence in the form of\nsamples. It can be insightful to place statistical procedures in this\nwider framework of relations between evidence and theory. Zooming out\neven further, the philosophy of statistics is part of the\nphilosophical topic of methodology, i.e., the general theory on\nwhether and how science acquires knowledge. Thus conceived, statistics\nis one component in a large collection of scientific methods\ncomprising concept formation, experimental design, manipulation and\nobservation, confirmation, revision, and theorizing.\nThere are also a fair number of specific topics from the philosophy\nof science that are spelled out in terms of statistics or that are\nlocated in close proximity to it. One of these topics is the process\nof measurement, in particular the measurement of latent variables on\nthe basis of statistical facts about manifest variables.  The\nso-called representational theory of measurement (Kranz et al\n1971) relies on statistics, in particular on factor analysis, to\nprovide a conceptual clarification of how mathematical structures\nrepresent empirical phenomena. Another important topic form the\nphilosophy of science is causation (see the entries on\n probabilistic causation\nand\n Reichenbach's common cause principle). \nPhilosophers have employed probability theory to capture causal\nrelations ever since Reichenbach (1956), but more recent work in\ncausality and statistics (e.g., Spirtes et al 2001) has given the\ntheory of probabilistic causality an enormous impulse. Here\nagain, statistics provides a basis for the conceptual analysis of\ncausal relations.\nAnd there is so much more.  Several specific statistical\ntechniques, like factor analysis and the theory of Bayesian networks,\ninvite conceptual discussion of their own accord. Numerous topics\nwithin the philosophy of science lend themselves to statistical\nelucidation, e.g., the coherence, informativeness, and surprise of\nevidence. And in turn there is a wide range of discussions in the\nphilosophy of science that inform a proper understanding of\nstatistics. Among them are debates over experimentation and\nintervention, concepts of chance, the nature of scientific models, and\ntheoretical terms. The reader is invited to consult the entries on\nthese topics to find further indications of how they relate to the\nphilosophy of statistics.",
    "section_title": "5.1 Model comparisons",
    "entry_title": "Philosophy of Statistics",
    "hierarchy_title": "Philosophy of Statistics || Statistical models || Model comparisons",
    "tokenized_text": [
        "statistical",
        "model",
        "model",
        "comparison",
        "model",
        "comparison",
        "fact",
        "many",
        "method",
        "evaluating",
        "statistical",
        "model",
        "claeskens",
        "hjort",
        "wagenmakers",
        "waldorp",
        "first",
        "instance",
        "method",
        "occasion",
        "comparison",
        "statistical",
        "model",
        "often",
        "used",
        "selecting",
        "one",
        "model",
        "others",
        "follows",
        "review",
        "prominent",
        "technique",
        "led",
        "philosophical",
        "debate",
        "akaike",
        "s",
        "information",
        "criterion",
        "bayesian",
        "information",
        "criterion",
        "furthermore",
        "computation",
        "marginal",
        "likelihood",
        "posterior",
        "model",
        "probability",
        "associated",
        "bayesian",
        "model",
        "selection",
        "leave",
        "aside",
        "method",
        "use",
        "crossvalidation",
        "unduly",
        "received",
        "much",
        "attention",
        "philosophical",
        "literature",
        "akaike",
        "s",
        "information",
        "criterion",
        "akaike",
        "s",
        "information",
        "criterion",
        "modestly",
        "termed",
        "information",
        "criterion",
        "aic",
        "short",
        "based",
        "classical",
        "statistical",
        "procedure",
        "estimation",
        "see",
        "burnham",
        "anderson",
        "kieseppa",
        "start",
        "idea",
        "model",
        "m",
        "judged",
        "estimate",
        "hat",
        "theta",
        "delivers",
        "specifically",
        "proximity",
        "estimate",
        "distribution",
        "data",
        "actually",
        "generated",
        "ie",
        "true",
        "distribution",
        "proximity",
        "often",
        "equated",
        "expected",
        "predictive",
        "accuracy",
        "estimate",
        "estimate",
        "true",
        "distribution",
        "closer",
        "prediction",
        "better",
        "aligned",
        "one",
        "another",
        "well",
        "derivation",
        "aic",
        "socalled",
        "relative",
        "entropy",
        "kullbackleibler",
        "divergence",
        "two",
        "distribution",
        "used",
        "measure",
        "proximity",
        "hence",
        "measure",
        "expected",
        "predictive",
        "accuracy",
        "estimate",
        "naturally",
        "true",
        "distribution",
        "known",
        "statistician",
        "evaluating",
        "model",
        "whole",
        "statistical",
        "analysis",
        "would",
        "useless",
        "however",
        "turn",
        "give",
        "unbiased",
        "estimation",
        "divergence",
        "true",
        "distribution",
        "distribution",
        "estimated",
        "particular",
        "model",
        "text",
        "aic",
        "log",
        "p",
        "mid",
        "h_",
        "hat",
        "theta",
        "s",
        "sample",
        "data",
        "hat",
        "theta",
        "maximum",
        "likelihood",
        "estimate",
        "mle",
        "model",
        "m",
        "dim",
        "theta",
        "number",
        "dimension",
        "parameter",
        "space",
        "model",
        "mle",
        "model",
        "thereby",
        "feature",
        "expression",
        "model",
        "quality",
        "ie",
        "role",
        "conceptually",
        "distinct",
        "estimator",
        "function",
        "seen",
        "expression",
        "model",
        "smaller",
        "aic",
        "preferable",
        "want",
        "fit",
        "optimal",
        "little",
        "cost",
        "complexity",
        "notice",
        "number",
        "dimension",
        "independent",
        "parameter",
        "model",
        "increase",
        "aic",
        "thereby",
        "lower",
        "eligibility",
        "model",
        "two",
        "model",
        "achieve",
        "maximum",
        "likelihood",
        "sample",
        "model",
        "fewer",
        "parameter",
        "preferred",
        "reason",
        "statistical",
        "model",
        "selection",
        "aic",
        "seen",
        "independent",
        "motivation",
        "preferring",
        "simple",
        "model",
        "complex",
        "one",
        "sober",
        "forster",
        "result",
        "also",
        "invite",
        "critical",
        "remark",
        "one",
        "might",
        "impose",
        "criterion",
        "merely",
        "unbiasedness",
        "estimation",
        "proximity",
        "truth",
        "lead",
        "different",
        "expression",
        "approximation",
        "moreover",
        "always",
        "clearcut",
        "dimension",
        "model",
        "scrutiny",
        "really",
        "curve",
        "fitting",
        "may",
        "seem",
        "simple",
        "complicated",
        "model",
        "different",
        "conceptualization",
        "space",
        "model",
        "thing",
        "look",
        "easy",
        "cf",
        "myung",
        "et",
        "al",
        "kieseppa",
        "prime",
        "example",
        "model",
        "selection",
        "presented",
        "curve",
        "fitting",
        "given",
        "sample",
        "s",
        "consisting",
        "set",
        "point",
        "plane",
        "x",
        "asked",
        "choose",
        "curve",
        "fit",
        "data",
        "best",
        "assume",
        "model",
        "consideration",
        "form",
        "f",
        "x",
        "epsilon",
        "epsilon",
        "normal",
        "distribution",
        "mean",
        "fixed",
        "standard",
        "deviation",
        "f",
        "polynomial",
        "function",
        "different",
        "model",
        "characterized",
        "polynomial",
        "different",
        "degree",
        "different",
        "number",
        "parameter",
        "estimation",
        "fix",
        "parameter",
        "polynomial",
        "example",
        "degree",
        "polynomial",
        "f",
        "x",
        "c_",
        "estimate",
        "constant",
        "hat",
        "c_",
        "probability",
        "data",
        "maximal",
        "degree",
        "polynomial",
        "f",
        "x",
        "c_",
        "c_",
        "x",
        "estimate",
        "slope",
        "hat",
        "c_",
        "offset",
        "hat",
        "c_",
        "notice",
        "total",
        "n",
        "point",
        "always",
        "find",
        "polynomial",
        "degree",
        "n",
        "intersects",
        "point",
        "exactly",
        "resulting",
        "comparatively",
        "high",
        "maximum",
        "likelihood",
        "p",
        "mid",
        "hat",
        "c_",
        "ldots",
        "hat",
        "c_",
        "n",
        "applying",
        "aic",
        "however",
        "typically",
        "find",
        "model",
        "polynomial",
        "degree",
        "k",
        "n",
        "preferable",
        "although",
        "p",
        "mid",
        "hat",
        "c_",
        "ldots",
        "hat",
        "c_",
        "k",
        "somewhat",
        "lower",
        "compensated",
        "aic",
        "smaller",
        "number",
        "parameter",
        "bayesian",
        "evaluation",
        "model",
        "various",
        "prominent",
        "model",
        "selection",
        "tool",
        "based",
        "method",
        "bayesian",
        "statistic",
        "start",
        "idea",
        "quality",
        "model",
        "expressed",
        "performance",
        "model",
        "sample",
        "data",
        "model",
        "whole",
        "make",
        "sampled",
        "data",
        "probable",
        "preferred",
        "close",
        "connection",
        "hierarchical",
        "bayesian",
        "modelling",
        "referred",
        "earlier",
        "gelman",
        "central",
        "notion",
        "bayesian",
        "model",
        "selection",
        "tool",
        "thus",
        "marginal",
        "likelihood",
        "model",
        "ie",
        "weighted",
        "average",
        "likelihood",
        "model",
        "using",
        "prior",
        "distribution",
        "weighing",
        "function",
        "p",
        "mid",
        "m_",
        "int_",
        "theta",
        "in",
        "theta_",
        "p",
        "h_",
        "theta",
        "p",
        "mid",
        "h_",
        "theta",
        "dtheta",
        "theta_",
        "parameter",
        "space",
        "belonging",
        "model",
        "m_",
        "marginal",
        "likelihood",
        "combined",
        "prior",
        "probability",
        "model",
        "p",
        "m_",
        "derive",
        "socalled",
        "posterior",
        "model",
        "probability",
        "using",
        "bayes",
        "theorem",
        "one",
        "way",
        "evaluating",
        "model",
        "known",
        "bayesian",
        "model",
        "selection",
        "comparing",
        "model",
        "marginal",
        "likelihood",
        "else",
        "posterior",
        "cf",
        "ka",
        "raftery",
        "usually",
        "marginal",
        "likelihood",
        "computed",
        "analytically",
        "numerical",
        "approximation",
        "often",
        "obtained",
        "practical",
        "purpose",
        "proved",
        "useful",
        "quite",
        "sufficient",
        "employ",
        "approximation",
        "marginal",
        "likelihood",
        "approximation",
        "become",
        "known",
        "bayesian",
        "information",
        "criterion",
        "bic",
        "short",
        "schwarz",
        "raftery",
        "turn",
        "approximation",
        "show",
        "remarkable",
        "similarity",
        "aic",
        "text",
        "bic",
        "log",
        "p",
        "mid",
        "h_",
        "hat",
        "theta",
        "log",
        "n",
        "hat",
        "theta",
        "maximum",
        "likelihood",
        "estimate",
        "model",
        "dim",
        "number",
        "independent",
        "parameter",
        "n",
        "number",
        "data",
        "point",
        "sample",
        "latter",
        "dependence",
        "difference",
        "aic",
        "major",
        "difference",
        "model",
        "evaluation",
        "may",
        "turn",
        "concurrence",
        "aic",
        "bic",
        "seems",
        "give",
        "motivation",
        "intuitive",
        "preference",
        "simple",
        "model",
        "complex",
        "one",
        "indeed",
        "model",
        "selection",
        "tool",
        "like",
        "deviance",
        "information",
        "criterion",
        "spiegelhalter",
        "et",
        "al",
        "approach",
        "based",
        "minimum",
        "description",
        "length",
        "grunwald",
        "also",
        "result",
        "expression",
        "feature",
        "term",
        "penalizes",
        "complex",
        "model",
        "however",
        "say",
        "dimension",
        "term",
        "know",
        "information",
        "criterion",
        "exhaust",
        "notion",
        "model",
        "complexity",
        "ongoing",
        "debate",
        "philosophy",
        "science",
        "concerning",
        "merit",
        "model",
        "selection",
        "explication",
        "notion",
        "simplicity",
        "informativeness",
        "like",
        "see",
        "example",
        "sober",
        "romeijn",
        "van",
        "de",
        "schoot",
        "romeijn",
        "et",
        "al",
        "sprenger",
        "statistic",
        "without",
        "model",
        "also",
        "statistical",
        "method",
        "refrain",
        "use",
        "particular",
        "model",
        "focusing",
        "exclusively",
        "data",
        "generalizing",
        "possible",
        "model",
        "technique",
        "properly",
        "localized",
        "descriptive",
        "statistic",
        "concern",
        "inference",
        "data",
        "merely",
        "serve",
        "describe",
        "data",
        "particular",
        "way",
        "statistical",
        "method",
        "rely",
        "explicit",
        "model",
        "choice",
        "unfortunately",
        "attracted",
        "much",
        "attention",
        "philosophy",
        "statistic",
        "completeness",
        "sake",
        "briefly",
        "discussed",
        "data",
        "reduction",
        "technique",
        "one",
        "set",
        "method",
        "quite",
        "important",
        "one",
        "many",
        "practicing",
        "statistician",
        "aimed",
        "data",
        "reduction",
        "often",
        "sample",
        "data",
        "rich",
        "eg",
        "consisting",
        "set",
        "point",
        "space",
        "many",
        "dimension",
        "first",
        "step",
        "statistical",
        "analysis",
        "may",
        "pick",
        "salient",
        "variability",
        "data",
        "order",
        "scale",
        "computational",
        "burden",
        "analysis",
        "technique",
        "principal",
        "component",
        "analysis",
        "pca",
        "designed",
        "purpose",
        "jolliffe",
        "given",
        "set",
        "point",
        "space",
        "seek",
        "set",
        "vector",
        "along",
        "variation",
        "point",
        "large",
        "example",
        "consider",
        "two",
        "point",
        "plane",
        "parameterized",
        "x",
        "point",
        "x",
        "direction",
        "y",
        "direction",
        "variation",
        "diagonal",
        "variation",
        "maximal",
        "namely",
        "sqrt",
        "vector",
        "diagonal",
        "called",
        "principal",
        "component",
        "data",
        "richer",
        "data",
        "structure",
        "using",
        "general",
        "measure",
        "variation",
        "among",
        "point",
        "find",
        "first",
        "component",
        "similar",
        "way",
        "moreover",
        "repeat",
        "procedure",
        "subtracting",
        "variation",
        "along",
        "last",
        "found",
        "component",
        "projecting",
        "data",
        "onto",
        "plane",
        "perpendicular",
        "component",
        "allows",
        "u",
        "build",
        "set",
        "principal",
        "component",
        "diminishing",
        "importance",
        "pca",
        "one",
        "item",
        "large",
        "collection",
        "technique",
        "aimed",
        "keeping",
        "data",
        "manageable",
        "finding",
        "pattern",
        "collection",
        "also",
        "includes",
        "kernel",
        "method",
        "support",
        "vector",
        "machine",
        "eg",
        "vapnik",
        "kotz",
        "present",
        "purpose",
        "important",
        "stress",
        "tool",
        "confused",
        "statistical",
        "analysis",
        "involve",
        "testing",
        "evaluation",
        "distribution",
        "sample",
        "space",
        "even",
        "though",
        "build",
        "evaluate",
        "model",
        "data",
        "set",
        "apart",
        "eg",
        "confirmatory",
        "exploratory",
        "factor",
        "analysis",
        "bartholomew",
        "sometimes",
        "taken",
        "close",
        "relative",
        "pca",
        "set",
        "technique",
        "allows",
        "u",
        "identify",
        "salient",
        "dimension",
        "within",
        "sample",
        "space",
        "along",
        "data",
        "show",
        "large",
        "variation",
        "practicing",
        "statistician",
        "often",
        "employ",
        "data",
        "reduction",
        "tool",
        "arrive",
        "conclusion",
        "distribution",
        "data",
        "sampled",
        "already",
        "wide",
        "use",
        "machine",
        "learning",
        "data",
        "mining",
        "technique",
        "science",
        "may",
        "expect",
        "even",
        "mode",
        "usage",
        "technique",
        "future",
        "much",
        "data",
        "coming",
        "available",
        "scientific",
        "analysis",
        "however",
        "philosophy",
        "statistic",
        "yet",
        "little",
        "debate",
        "epistemic",
        "status",
        "conclusion",
        "reached",
        "mean",
        "technique",
        "philosopher",
        "statistic",
        "would",
        "well",
        "direct",
        "attention",
        "formal",
        "learning",
        "theory",
        "entirely",
        "different",
        "approach",
        "statistic",
        "presented",
        "formal",
        "learning",
        "theory",
        "vast",
        "area",
        "research",
        "primarily",
        "located",
        "computer",
        "science",
        "artificial",
        "intelligence",
        "discipline",
        "mentioned",
        "briefly",
        "another",
        "example",
        "approach",
        "statistic",
        "avoids",
        "choice",
        "statistical",
        "model",
        "altogether",
        "merely",
        "identifies",
        "pattern",
        "data",
        "leave",
        "aside",
        "theory",
        "neural",
        "network",
        "also",
        "concern",
        "predictive",
        "system",
        "rely",
        "statistical",
        "model",
        "focus",
        "theory",
        "learning",
        "algorithm",
        "approach",
        "seen",
        "philosophical",
        "attention",
        "pioneering",
        "work",
        "formal",
        "learning",
        "done",
        "solomonoff",
        "setting",
        "one",
        "data",
        "consist",
        "string",
        "s",
        "s",
        "agent",
        "attempting",
        "identify",
        "pattern",
        "data",
        "example",
        "data",
        "may",
        "string",
        "form",
        "ldots",
        "challenge",
        "identify",
        "string",
        "alternating",
        "sequence",
        "central",
        "idea",
        "solomonoff",
        "possible",
        "computable",
        "pattern",
        "must",
        "considered",
        "agent",
        "therefore",
        "restrictive",
        "choice",
        "statistical",
        "hypothesis",
        "warranted",
        "solomonoff",
        "defined",
        "formal",
        "system",
        "indeed",
        "pattern",
        "taken",
        "consideration",
        "effectively",
        "using",
        "bayesian",
        "analysis",
        "cleverly",
        "constructed",
        "prior",
        "computable",
        "hypothesis",
        "general",
        "idea",
        "also",
        "identified",
        "rather",
        "new",
        "field",
        "intersection",
        "bayesian",
        "statistic",
        "machine",
        "learning",
        "bayesian",
        "nonparametrics",
        "eg",
        "orbanz",
        "teh",
        "hjort",
        "et",
        "al",
        "rather",
        "specifying",
        "outset",
        "confined",
        "set",
        "distribution",
        "statistical",
        "analysis",
        "supposed",
        "choose",
        "basis",
        "data",
        "idea",
        "data",
        "confronted",
        "potentially",
        "infinitedimensional",
        "space",
        "possible",
        "distribution",
        "set",
        "distribution",
        "taken",
        "consideration",
        "made",
        "relative",
        "data",
        "obtained",
        "complexity",
        "model",
        "grows",
        "sample",
        "result",
        "predictive",
        "system",
        "performs",
        "online",
        "model",
        "selection",
        "alongside",
        "bayesian",
        "accommodation",
        "posterior",
        "model",
        "current",
        "formal",
        "learning",
        "theory",
        "lively",
        "field",
        "philosopher",
        "statistic",
        "also",
        "contribute",
        "eg",
        "kelly",
        "kelly",
        "et",
        "al",
        "particularly",
        "salient",
        "present",
        "concern",
        "system",
        "formal",
        "learning",
        "set",
        "achieve",
        "notion",
        "adequate",
        "universal",
        "prediction",
        "without",
        "confining",
        "specific",
        "set",
        "hypothesis",
        "hence",
        "imposing",
        "minimal",
        "constraint",
        "set",
        "possible",
        "pattern",
        "data",
        "matter",
        "debate",
        "whether",
        "possible",
        "extent",
        "prediction",
        "formal",
        "learning",
        "theory",
        "thereby",
        "rely",
        "eg",
        "implicit",
        "assumption",
        "structure",
        "sample",
        "space",
        "philosophical",
        "reflection",
        "infancy",
        "related",
        "topic",
        "numerous",
        "topic",
        "philosophy",
        "science",
        "bear",
        "direct",
        "relevance",
        "theme",
        "covered",
        "lemma",
        "central",
        "topic",
        "mentioned",
        "direct",
        "reader",
        "related",
        "lemma",
        "encyclopedia",
        "one",
        "important",
        "topic",
        "immediately",
        "adjacent",
        "philosophy",
        "statistic",
        "confirmation",
        "theory",
        "philosophical",
        "theory",
        "describes",
        "justifies",
        "relation",
        "scientific",
        "theory",
        "empirical",
        "evidence",
        "arguably",
        "theory",
        "statistic",
        "proper",
        "part",
        "confirmation",
        "theory",
        "describes",
        "justifies",
        "relation",
        "obtains",
        "statistical",
        "theory",
        "evidence",
        "form",
        "sample",
        "insightful",
        "place",
        "statistical",
        "procedure",
        "wider",
        "framework",
        "relation",
        "evidence",
        "theory",
        "zooming",
        "even",
        "philosophy",
        "statistic",
        "part",
        "philosophical",
        "topic",
        "methodology",
        "ie",
        "general",
        "theory",
        "whether",
        "science",
        "acquires",
        "knowledge",
        "thus",
        "conceived",
        "statistic",
        "one",
        "component",
        "large",
        "collection",
        "scientific",
        "method",
        "comprising",
        "concept",
        "formation",
        "experimental",
        "design",
        "manipulation",
        "observation",
        "confirmation",
        "revision",
        "theorizing",
        "also",
        "fair",
        "number",
        "specific",
        "topic",
        "philosophy",
        "science",
        "spelled",
        "term",
        "statistic",
        "located",
        "close",
        "proximity",
        "one",
        "topic",
        "process",
        "measurement",
        "particular",
        "measurement",
        "latent",
        "variable",
        "basis",
        "statistical",
        "fact",
        "manifest",
        "variable",
        "socalled",
        "representational",
        "theory",
        "measurement",
        "kranz",
        "et",
        "al",
        "relies",
        "statistic",
        "particular",
        "factor",
        "analysis",
        "provide",
        "conceptual",
        "clarification",
        "mathematical",
        "structure",
        "represent",
        "empirical",
        "phenomenon",
        "another",
        "important",
        "topic",
        "form",
        "philosophy",
        "science",
        "causation",
        "see",
        "entry",
        "probabilistic",
        "causation",
        "reichenbach",
        "s",
        "common",
        "cause",
        "principle",
        "philosopher",
        "employed",
        "probability",
        "theory",
        "capture",
        "causal",
        "relation",
        "ever",
        "since",
        "reichenbach",
        "recent",
        "work",
        "causality",
        "statistic",
        "eg",
        "spirtes",
        "et",
        "al",
        "given",
        "theory",
        "probabilistic",
        "causality",
        "enormous",
        "impulse",
        "statistic",
        "provides",
        "basis",
        "conceptual",
        "analysis",
        "causal",
        "relation",
        "much",
        "several",
        "specific",
        "statistical",
        "technique",
        "like",
        "factor",
        "analysis",
        "theory",
        "bayesian",
        "network",
        "invite",
        "conceptual",
        "discussion",
        "accord",
        "numerous",
        "topic",
        "within",
        "philosophy",
        "science",
        "lend",
        "statistical",
        "elucidation",
        "eg",
        "coherence",
        "informativeness",
        "surprise",
        "evidence",
        "turn",
        "wide",
        "range",
        "discussion",
        "philosophy",
        "science",
        "inform",
        "proper",
        "understanding",
        "statistic",
        "among",
        "debate",
        "experimentation",
        "intervention",
        "concept",
        "chance",
        "nature",
        "scientific",
        "model",
        "theoretical",
        "term",
        "reader",
        "invited",
        "consult",
        "entry",
        "topic",
        "find",
        "indication",
        "relate",
        "philosophy",
        "statistic"
    ]
}