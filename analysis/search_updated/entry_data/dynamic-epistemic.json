{
    "url": "dynamic-epistemic",
    "title": "Dynamic Epistemic Logic",
    "authorship": {
        "year": "Copyright \u00a9 2016",
        "author_text": "Alexandru Baltag\n<a.baltag@uva.nl>\nBryan Renne\n<brenne@gmail.com>",
        "author_links": [
            {
                "https://sites.google.com/site/thealexandrubaltagsite/": "Alexandru Baltag"
            },
            {
                "mailto:a%2ebaltag%40uva%2enl": "a.baltag@uva.nl"
            },
            {
                "http://bryan.renne.org/": "Bryan Renne"
            },
            {
                "mailto:brenne%40gmail%2ecom": "brenne@gmail.com"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2016</a> by\n\n<br/>\n<a href=\"https://sites.google.com/site/thealexandrubaltagsite/\" target=\"other\">Alexandru Baltag</a>\n&lt;<a href=\"mailto:a%2ebaltag%40uva%2enl\"><em>a<abbr title=\" dot \">.</abbr>baltag<abbr title=\" at \">@</abbr>uva<abbr title=\" dot \">.</abbr>nl</em></a>&gt;<br/>\n<a href=\"http://bryan.renne.org/\" target=\"other\">Bryan Renne</a>\n&lt;<a href=\"mailto:brenne%40gmail%2ecom\"><em>brenne<abbr title=\" at \">@</abbr>gmail<abbr title=\" dot \">.</abbr>com</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Fri Jun 24, 2016"
    ],
    "preamble": "\n\nDynamic Epistemic Logic is the study of modal logics of model change.\nDEL (pronounced \u201cdell\u201d) is a highly active area of applied\nlogic that touches on topics in many areas, including Formal and\nSocial Epistemology, Epistemic and Doxastic Logic, Belief Revision,\nmulti-agent and distributed systems, Artificial Intelligence,\nDefeasible and Non-monotonic Reasoning, and Epistemic Game Theory.\nThis article surveys DEL, identifying along the way a number of open\nquestions and natural directions for further research.\n",
    "toc": [
        {
            "#Intr": "1. Introduction"
        },
        {
            "#PublComm": "2. Public communication"
        },
        {
            "#PublAnnoLogi": "2.1 Public Announcement Logic"
        },
        {
            "#GrouKnowCommKnowDistKnow": "2.2 Group knowledge: common knowledge and distributed knowledge"
        },
        {
            "#CommKnow": "2.2.1 Common knowledge"
        },
        {
            "#DistKnow": "2.2.2 Distributed knowledge"
        },
        {
            "#MoorSent": "2.3 Moore sentences"
        },
        {
            "#CompEpisInte": "3. Complex epistemic interactions"
        },
        {
            "#ActiModeDescCompInfoScen": "3.1 Action models describe complex informational scenarios"
        },
        {
            "#ExamActiMode": "3.2 Examples of action models"
        },
        {
            "#LogiEpisActi": "3.3 The Logic of Epistemic Actions"
        },
        {
            "#VariGene": "3.4 Variants and generalizations "
        },
        {
            "#BeliChanDynaEpisLogi": "4. Belief change and Dynamic Epistemic Logic"
        },
        {
            "#BeliReviErroAwarBeliChan": "4.1 Belief Revision: error-aware belief change"
        },
        {
            "#StatDynaBeliChan": "4.2 Static and dynamic belief change"
        },
        {
            "#PlauModeBeliChan": "4.3 Plausibility models and belief change"
        },
        {
            "#LogiDoxaActiActiPrioUpda": "4.4 The Logic of Doxastic Actions: Action-priority update"
        },
        {
            "#EvidDynaJustBeli": "4.5 Evidential dynamics and justified belief"
        },
        {
            "#ProbUpdaDynaEpisLogi": "5. Probabilistic update in Dynamic Epistemic Logic"
        },
        {
            "#ApplDynaEpisLogi": "6. Applications of Dynamic Epistemic Logic"
        },
        {
            "#PrefDyna": "6.1 Preference dynamics"
        },
        {
            "#ConnTempLogi": "6.2 Connections with Temporal Logic"
        },
        {
            "#ConnMainEpis": "6.3 Connections to mainstream Epistemology"
        },
        {
            "#Conc": "7. Conclusion"
        },
        {
            "#Appe": "Appendices"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. Introduction\n\nDynamic Epistemic Logic is the study of a family of modal logics, each\nof which is obtained from a given logical language by adding one or\nmore modal operators that describe model-transforming actions. If\n\\([A]\\) is such a modality, then new formulas of the form \\([A]F\\) are\nused to express the statement that F is true after the\noccurrence of action A. To determine whether \\([A]F\\) is true\nat a pointed Kripke model \\((M,w)\\) (see\n Appendix A\n for definitions), we transform the current Kripke model M\naccording to the prescription of action A and we obtain a new\npointed Kripke model \\((M',w')\\) at which we then investigate whether\nF is true. If it is true there, then we say that original\nformula \\([A]F\\) is true in our starting situation \\((M,w)\\). If\nF is not true in the newly produced situation \\((M',w')\\), then\nwe conclude the opposite: \\([A]F\\) is not true in our starting\nsituation \\((M,w)\\). In this way, we obtain the meaning of \\([A]F\\)\nnot by the analysis of what obtains in a single Kripke model but by\nthe analysis of what obtains as a result of a specific\nmodality-specified Kripke model transformation. This is a shift from a\nstatic semantics of truth that takes place in an individual\nKripke model to a dynamic semantics of truth that takes place\nacross modality-specified Kripke model transformations. The advantage\nof the dynamic perspective is that we can analyze the epistemic and\ndoxastic consequences of actions such as public and private\nannouncements without having to \u201chard wire\u201d the results\ninto the model from the start. Furthermore, we may look at the\nconsequences of different sequences of actions simply by changing the\nsequence of action-describing modalities. \n\nIn the following sections, we will look at the many model-changing\nactions that have been studied in Dynamic Epistemic Logic. Many\nnatural applications and questions arise as part of this study, and we\nwill see some of the results obtained in this work. Along the way it\nwill be convenient to consider many variations of the general formal\nsetup described above. Despite these differences, at the core is the\nsame basic idea: new modalities describing certain\napplication-specific model-transforming operations are added to an\nexisting logical language and the study proceeds from there.\nProceeding now ourselves, we begin with what is perhaps the\nquintessential and most basic model-transforming operation: the public\nannouncement. \n2. Public communication\n2.1 Public Announcement Logic\n\nPublic Announcement Logic (PAL) is the modal logic study of knowledge,\nbelief, and public communication. PAL (pronounced \u201cpal\u201d)\nis used to reason about knowledge and belief and the changes brought\nabout in knowledge and belief as per the occurrence of completely\ntrustworthy, truthful announcements. PAL\u2019s most common\nmotivational examples include the Muddy Children Puzzle and\nthe Sum and Product Puzzle (see, e.g., Plaza 1989, 2007). The\nCheryl\u2019s Birthday problem, which became a sensation on\nthe Internet in April 2015, can also be addressed using PAL. Here we\npresent a version of the Cheryl\u2019s Birthday problem due to Chang\n(2015, 15 April) and a three-child version of the Muddy Children\nPuzzle (Fagin et al. 1995). Instead of presenting the traditional Sum\nand Product Puzzle (see Plaza (1989, 2007) for details), we present\nour own simplification that we call the Sum and Least Common\nMultiple Problem. \n\n\nCheryl\u2019s Birthday (version of Chang (2015, 15\nApril)). Albert and Bernard just met Cheryl.\n\u201cWhen\u2019s your birthday?\u201d Albert asked Cheryl.\n\nCheryl thought a second and said, \u201cI\u2019m not going to tell\nyou, but I\u2019ll give you some clues\u201d. She wrote down a list\nof 10 dates:\n\nMay 15, May 16, May 19\nJune 17, June 18\nJuly 14, July 16\nAugust 14, August 15, August 17\n\n\n\u201cMy birthday is one of these\u201d, she said.\n\nThen Cheryl whispered in Albert\u2019s ear the month\u2014and only\nthe month\u2014of her birthday. To Bernard, she whispered the day,\nand only the day.\n\n\u201cCan you figure it out now?\u201d she asked Albert.\n\n\nAlbert: I don\u2019t know when your birthday is, but I know\nBernard doesn\u2019t know either.\nBernard: I didn\u2019t know originally, but now I do.\nAlbert: Well, now I know too!\n\n\n\nWhen is Cheryl\u2019s birthday?\n\n\n\nThe Muddy Children Puzzle. Three children are playing\nin the mud. Father calls the children to the house, arranging them in\na semicircle so that each child can clearly see every other child.\n\u201cAt least one of you has mud on your forehead\u201d, says\nFather. The children look around, each examining every other\nchild\u2019s forehead. Of course, no child can examine his or her\nown. Father continues, \u201cIf you know whether your forehead is\ndirty, then step forward now\u201d. No child steps forward. Father\nrepeats himself a second time, \u201cIf you know whether your\nforehead is dirty, then step forward now\u201d. Some but not all of\nthe children step forward. Father repeats himself a third time,\n\u201cIf you know whether your forehead is dirty, then step forward\nnow\u201d. All of the remaining children step forward. How many\nchildren have muddy foreheads?\n\n\n\nThe Sum and Least Common Multiple Puzzle. Referee\nreminds Mr. S and Mr. L that the least common multiple\n(\u201c\\(\\text{lcm}\\)\u201d) of two positive integers x and\ny is the smallest positive integer that is divisible without\nany remainder by both x and y (e.g.,\n\\(\\text{lcm}(3,6)=6\\) and \\(\\text{lcm}(5,7)=35\\)). Referee then says,\n\n\n\nAmong the integers ranging from \\(2\\) to \\(7\\), including \\(2\\) and\n\\(7\\) themselves, I will choose two different numbers. I will whisper\nthe sum to Mr. S and the least common multiple to Mr. L. \n\n\nReferee then does as promised. The following dialogue then takes\nplace:\n\n\nMr. S: I know that you don\u2019t know the numbers.\nMr. L: Ah, but now I do know them.\nMr. S: And so do I!\n\n\n\nWhat are the numbers?\n\n\nThe Sum and Product Puzzle is like the Sum and Least Common Multiple\nPuzzle except that the allowable integers are taken in the range\n\\(2,\\dots,100\\) (inclusive), Mr. L is told the product of the two\nnumbers (instead of their least common multiple), and the dialogue is\naltered slightly (L: \u201cI don\u2019t know the numbers\u201d, S:\n\u201cI knew you didn\u2019t know them\u201d, L: \u201cAh, but now\nI do know them\u201d, S: \u201cAnd now so do I!\u201d). These\nchanges result in a substantially more difficult problem. See Plaza\n(1989, 2007) for details. \n\nThe reader is advised to try solving the puzzles himself or herself\nand to read more about PAL below before looking at the PAL-based\nsolutions found in a\n Appendix B.\n Later, after the requisite basics of PAL have been presented, the\nauthors will again point the reader to this appendix. \n\nThere are many variations of these puzzles, some of which motivate\nlogics that can handle more than just public communication.\nRestricting attention to the variations above, we note that a formal\nlogic for reasoning about these puzzles must be able to represent\nvarious agents\u2019 knowledge along with changes in this knowledge\nthat are brought about as a result of public announcements. One\nimportant thing to note is that the announcements in the puzzles are\nall truthful and completely trustworthy: so that we\ncan solve the puzzles, we tacitly assume (among other things) that\neverything that is announced is in fact true and that all agents\naccept the content of a public announcement without question. These\nassumptions are of course unrealistic in many everyday situations,\nand, to be sure, there are more sophisticated Dynamic Epistemic Logics\nthat can address more complicated and nuanced attitudes agents may\nhave with respect to the information they receive. Nevertheless, in an\nappropriately restricted situation, Public Announcement Logic provides\na basic framework for reasoning about truthful, completely trustworthy\npublic announcements. \n\nGiven a nonempty set \\(\\sP\\) of propositional letters and a finite\nnonempty set \\(\\sA\\) of agents, the basic modal language \\eqref{ML} is\ndefined as follows:  \n\n\\[\\begin{gather*}\nF  \\ccoloneqq p \\mid F \\wedge F \\mid \\neg F \\mid [a]F \\\\\n \\small p \\in \\sP,\\; a \\in \\sA\n\\taglabel{ML}\n\\end{gather*}\\]\n\n\nFormulas \\([a]F\\) are assigned a reading that is doxastic\n(\u201cagent a believes F\u201d) or epistemic\n(\u201cagent a knows F\u201d), with the particular\nreading depending on the application one has in mind. In this article\nwe will use both readings interchangeably, choosing whichever is more\nconvenient in a given context. In the language \\eqref{ML}, Boolean\nconnectives other than negation \\(\\lnot\\) and conjunction \\(\\land\\)\nare taken as abbreviations in terms of negation in conjunction as is\nfamiliar from any elementary Logic textbook. See\n Appendix A\n for further details on \\eqref{ML} and its Kripke semantics. \n\nThe language \\(\\eqref{PAL}\\) of Public Announcement Logic extends the\nbasic modal language \\eqref{ML} by adding formulas \\([F!]G\\) to\nexpress that \u201cafter the public announcement of F, formula\nG is true\u201d:  \n\n\\[\\begin{gather*}\nF \\ccoloneqq p \\mid F \\wedge F \\mid \\neg F \\mid [a]F \\mid [F!]F \\\\\n \\small p \\in \\sP,\\; a \\in \\sA\n\\taglabel{PAL}\n\\end{gather*}\\]\n\n\nSemantically, the formula \\([F!]G\\) is interpreted in a Kripke model\nas follows: to say that \\([F!]G\\) is true means that, whenever\nF is true, G is true after we eliminate all not-F\npossibilities (and all arrows to and from these possibilities). This\nmakes sense: since the public announcement of F is completely\ntrustworthy, all agents respond by collectively eliminating all\nnon-F possibilities from consideration. So to see what obtains\nafter a public announcement of F occurs, we eliminate the\nnon-F worlds and then see what is true in the resulting\nsituation. Formally, \\(\\eqref{PAL}\\)-formulas are evaluated as an\nextension of the binary truth relation \\(\\models\\) between pointed\nKripke models and \\eqref{ML}-formulas (defined in\n Appendix A)\n as follows: given a Kripke model \\(M=(W,R,V)\\) and a world \\(w\\in\nW\\), \n\n\\(M,w\\models p\\) holds if and only if \\(w\\in V(p)\\);\n\\(M,w\\models F\\land G\\) holds if and only if both \\(M,w\\models F\\)\nand \\(M,w\\models G\\);\n\\(M,w\\models\\lnot F\\) holds if and only if \\(M,w\\not\\models\nF\\);\n\\(M,w\\models[a]F\\) holds if and only if \\(M,v\\models F\\) for each\nv satisfying \\(wR_av\\); and\n\\(M,w \\models [F!]G\\) holds if and only if we have that \\(M,w\n\\not\\models F\\) or that \\(M[F!],w \\models G\\), where the model\n\n\\[\nM[F!] = (W[F!],R[F!],V[F!])\n\\]\n\n is defined by:\n\n\n \\(W[F!] \\coloneqq \\{ v \\in W \\mid M,v \\models F\\}\\) \u2014\nretain only the worlds where F is true, \n \\(xR[F!]_ay\\) if and only if \\(xR_ay\\) \u2014 leave arrows\nbetween remaining worlds unchanged, and \n \\(v \\in V[F!](p)\\) if an only if \\(v \\in V(p)\\) \u2014 leave the\nvaluation the same at remaining worlds. \n \n\n\nNote that the formula \\([F!]G\\) is vacuously true if F is\nfalse: the announcement of a false formula is inconsistent with our\nassumption of truthful announcements, and hence every formula follows\nafter a falsehood is announced (ex falso quodlibet). It is\nworth remarking that the dual announcement operator \\(\\may{F!}\\)\ndefined by  \n\n\\[ \\may{F!}G \\coloneqq \\neg[F!]\\neg G \\] \n\n\ngives the formula \\(\\may{F!} G\\) the following meaning: F is\ntrue and, after F is announced, G is also true. In\nparticular, we observe that the announcement formula \\(\\may{F!} G\\) is\nfalse whenever F is false. \n\nOften one wishes to restrict attention to a class of Kripke models\nwhose relations \\(R_a\\) satisfy certain desirable properties such as\nreflexivity, transitivity, Euclideanness, or seriality. Reflexivity\ntells us that agent knowledge is truthful, transitivity tells us that\nagents know what they know, Euclideanness tells us that agents know\nwhat they do not know, and seriality tells us that agent knowledge is\nconsistent. (A belief reading is also possible.) In order to study\npublic announcements over such classes, we must be certain that the\npublic announcement of a formula F does not transform a given\nKripke model M into a new model \\(M[F!]\\) that falls outside of\nthe class. The following theorem indicates when it is that a given\nclass of Kripke models is \u201cclosed\u201d under public\nannouncements (meaning a public announcement performed on a model in\nthe class always yields another model in the class). \n\nSee\n Appendix C\n for the definition of reflexivity, transitivity, Euclideanness,\nseriality, and other important relational properties. \n\n\nPublic Announcement Closure Theorem. Let\n\\(M=(W,R,V)\\) be a Kripke model and F be a formula true at at\nleast one world in W.\n\n If \\(R_a\\) is reflexive, then so is \\(R[F!]_a\\). \n If \\(R_a\\) is transitive, then so is \\(R[F!]_a\\). \n If \\(R_a\\) is Euclidean, then so is \\(R[F!]_a\\). \n If \\(R_a\\) is serial and Euclidean, then so is\n\\(R[F\\land\\bigwedge_{x\\in\\sA}\\may{x} F!]_a\\). \n\n\n\nThe Public Announcement Closure Theorem tells us that reflexivity,\ntransitivity, and Euclideanness are always closed under the public\nannouncement operation. Seriality is in general not; however, if\nseriality comes with Euclideanness, then public announcements of\nformulas of the form \\(F\\land\\bigwedge_{x\\in\\sA}\\may{x} F\\) (read,\n\u201cF is true and consistent with each agent\u2019s\nknowledge\u201d) preserve both seriality and Euclideanness.\nTherefore, if we wish to study classes of models that are serial,\nthen, to make use of the above theorem, we will need to further\nrestrict to models that are both serial and Euclidean and we will need\nto restrict the language of public announcements so that all\nannouncement formulas have this form. (One could also restrict to\nanother form, so long as public announcements of this form preserve\nseriality over some class \\(\\sC\\) of serial models.) Restricting the\nlanguage \\eqref{PAL} by requiring that public announcements have the\nform \\(F\\land\\bigwedge_{x\\in\\sA}\\may{x} F\\) leads to the language\n\\eqref{sPAL} of serial Public Announcement Logic, which we\nmay use when interested in serial and Euclidean Kripke models. \n\n\\[\\begin{gather*}\nF  \\ccoloneqq p \\mid F \\wedge F \\mid \\neg F \\mid [a]F \\mid [F\\land\\bigwedge_{x\\in\\sA}\\may{x} F!]F\\\\\n\\small p \\in \\sP,\\; a \\in \\sA\n\\taglabel{sPAL}\n\\end{gather*}\\]\n\n\nGiven a class of Kripke models satisfying certain properties and a\nmodal logic \\(\\L\\) in the language \\eqref{ML} that can reason about\nthat class, we would like to construct a Public Announcement Logic\nwhose soundness and completeness are straightforwardly proved. To do\nthis, we would like to know in advance that \\(\\L\\) is sound and\ncomplete with respect to the class of models in question, that some\npublic announcement extension \\(\\LPAL\\) of the language \\eqref{ML}\n(e.g., the language \\eqref{sPAL} or maybe even \\eqref{PAL} itself)\nwill include announcements that do not spoil closure, and that there\nis an easy way for us to determine the truth of \\(\\LPAL\\)-formulas by\nlooking only the underlying modal language \\eqref{ML}. This way, we\ncan \u201creduce\u201d completeness of the public announcement\ntheory to the completeness of the basic modal theory \\(\\L\\). We call\nsuch theories for which this is possible PAL-friendly. \n\n\nPAL-friendly theory. To say that a logic \\(\\L\\) is\nPAL-friendly means we have the following:\n\n \\(\\L\\) is a normal multi-modal logic in the language \\eqref{ML}\n(i.e., with modals \\([a]\\) for each agent \\(a\\in\\sA\\)), \n there is a class of Kripke models \\(\\sC\\) such that \\(\\L\\) is\nsound and complete with respect to the collection of pointed Kripke\nmodels based on models in \\(\\sC\\), and \n there is a language \\(\\LPAL\\) (the \u201cannouncement extension\nof \\(\\L\\)\u201d) obtained from \\eqref{PAL} by restricting the form of\npublic announcement modals \\([F!]\\) such that \\(\\sC\\) is closed under\npublic announcements of this form (i.e., performing a public\nannouncement of this form on a model in \\(\\sC\\) having at least one\nworld at which the announced formula is true yields another model in\n\\(\\sC\\)). \n\n\n\nSee\n Appendix D\n for the exact meaning of the first component of a PAL-friendly\ntheory. \n\nExamples of PAL-friendly theories include the common \u201clogic of\nbelief\u201d (multi-modal \\(\\mathsf{KD45}\\)), the common \u201clogic\nof knowledge\u201d (multi-modal \\(\\mathsf{S5}\\)), multi-modal\n\\(\\mathsf{K}\\), multi-modal \\(\\mathsf{T}\\), multi-modal\n\\(\\mathsf{S4}\\), and certain logics that mix modal operators of the\npreviously mentioned types (e.g., \\(\\mathsf{S5}\\) for \\([a]\\) and\n\\(\\mathsf{T}\\) for all other agent modal operators \\([b]\\)). Fixing a\nPAL-friendly theory \\(\\L\\), we easily obtain an axiomatic theory of\npublic announcement logic based on \\(\\L\\) as follows. \n\n\nThe axiomatic theory \\(\\PAL\\).\n\n Axiom schemes and rules for the PAL-friendly theory \\(\\L\\) \n Reduction axioms (all in the language \\(\\LPAL\\)):\n\n\n \\( [F!]p \\leftrightarrow (F\\to p) \\) for letters \\(p\\in\\sP\\)\n\n\u201cAfter a false announcement, every letter holds\u2014a\ncontradiction. After a true announcement, letters retain their truth\nvalues.\u201d \n \\([F!](G\\land H)\\leftrightarrow([F!]G\\land[F!]H)\\)\n\n\u201cA conjunction is true after an announcement iff each conjunct\nis.\u201d \n \\([F]\\lnot G\\leftrightarrow(F\\to\\lnot[F!]G)\\)\n\n\u201cG is false after an announcement iff the announcement,\nwhenever truthful, does not make G true.\u201d \n \\([F!][a]G \\leftrightarrow (F\\to[a][F!]G)\\)\n\n\u201ca knows G after an announcement iff the\nannouncement, whenever truthful, is known by a to make G\ntrue.\u201d \n \n Announcement Necessitation Rule: from G, infer \\([F!]G\\)\nwhenever the latter is in \\(\\LPAL\\).\n\n\u201cA validity holds after any announcement.\u201d \n\n\n\nThe reduction axioms characterize truth of an announcement formula\n\\([F!]G\\) in terms of the truth of other announcement formulas\n\\([F!]H\\) whose post-announcement formula H is less complex\nthan the original post-announcement formula G. In the case\nwhere G is just a propositional letter p, Reduction\nAxiom 1 says that the truth of \\([F!]p\\) can be reduced to a formula\nnot containing any announcements of F. So we see that the\nreduction axioms \u201creduce\u201d statements of truth of\ncomplicated announcements to statements of truth of simpler and\nsimpler announcements until the mention of announcements is not\nnecessary. For example, writing the reduction axiom used in a\nparenthetical subscript, we have the following sequence of provable\nequivalences:  \n\n\\[\n\\begin{array}{ll}\n& [[b]p!](p\\land[a]p) \\\\\n\\leftrightarrow_{(2)} & [[b]p!]p\\land[[b]p!][a]p\\\\\n\\leftrightarrow_{(1)} & ([b]p\\to p)\\land[[b]p!][a]p\\\\\n\\leftrightarrow_{(4)} & ([b]p\\to p)\\land([b]p\\to[a][[b]p!]p)\\\\\n\\leftrightarrow_{(1)} & ([b]p\\to p)\\land([b]p\\to[a]([b]p\\to p))\n\\end{array}\n\\]\n\n\nNotice that the last formula does not contain public announcements.\nHence we see that the reduction axioms allow us to express the truth\nof the announcement-containing formula \\([[b]p!](p\\land[a]p)\\) in\nterms of a provably equivalent announcement-free formula. This is true\nin general. \n\n\n\\(\\PAL\\) Reduction Theorem. Given a PAL-friendly\ntheory \\(\\L\\), every F in the language \\(\\LPAL\\) of Public\nAnnouncement Logic (without common knowledge) is \\(\\PAL\\)-provably\nequivalent to a formula \\(F^\\circ\\) coming from the announcement-free\nfragment of \\(\\LPAL\\).\n\n\nThe Reduction Theorem makes proving completeness of the axiomatic\ntheory with respect to the appropriate class of pointed Kripke models\neasy: since every \\(\\LPAL\\)-formula can all be expressed using a\nprovably equivalent announcement-free \\eqref{ML}-formula, completeness\nof the theory \\(\\PAL\\) follows by the Reduction Theorem, the soundness\nof \\(\\PAL\\), and the known completeness of the underlying modal theory\n\\(\\L\\). \n\n\n\\(\\PAL\\) Soundness and Completeness. \\(\\PAL\\) is\nsound and complete with respect to the collection \\(\\sC_*\\) of pointed\nKripke models for which the underlying PAL-friendly theory \\(\\L\\) is\nsound and complete. That is, for each \\(\\LPAL\\)-formula F, we\nhave that \\(\\PAL\\vdash F\\) if and only if \\(\\sC_*\\models F\\).\n\n\nOne interesting \\(\\PAL\\)-derivable scheme (available if allowed by the\nlanguage \\(\\LPAL\\)) is the following:  \n\n\\[\n[F!][G!]H \\leftrightarrow [F\\land[F!]G!]H\n\\]\n\n\nThis says that two consecutive announcements can be combined into a\nsingle announcement: to announce that F is true and then to\nannounce that G is true will have the same result as announcing\nthe single statement that \u201cF is true and, after F\nis announced, G is true\u201d. \n\nWe conclude with a few complexity results for Public Announcement\nLogic. \n\n\nPAL Complexity. Let \\(\\sC\\) be the class of all\nKripke models. Let \\(\\sC_{\\mathsf{S5}}\\) be the class of Kripke models\nsuch that each binary accessibility relation is reflexive, transitive,\nand symmetric.\n\n The satisfiability problem for single-agent \\eqref{PAL} over\n\\(\\sC_{\\mathsf{S5}}\\) is NP-complete (Lutz 2006). \nThe satisfiability problem for multi-agent \\eqref{PAL} over\n\\(\\sC_{\\mathsf{S5}}\\) is PSPACE-complete (Lutz 2006). \nThe model checking problem for \\eqref{PAL} over \\(\\sC\\) is in P\n(Kooi and van Benthem 2004). \n\n\n\nOne thing to note about the theory \\(\\PAL\\) as presented above is that\nit is parameterized on a PAL-friendly logic \\(\\L\\). Therefore,\n\u201cPublic Announcement Logic\u201d as an area of study in fact\nencompasses a wide-ranging family individual Public Announcement\nLogics, one for each instance of \\(\\L\\). Unless otherwise noted, the\nresults and concepts we present apply to all logics within this\nfamily. \n\nIn\n Appendix E,\n we detail further aspects of Public Announcement Logic: schematic\nvalidity, expressivity and succinctness, Gerbrandy\u2013Groeneveld\nannouncements, consistency-preserving announcements and Arrow Update\nLogic, and quantification over public announcements in Arbitrary\nPublic Announcement Logic. \n\nWhile iterated public announcements seem like a natural operation to\nconsider (motivated by, e.g., the Muddy Children Puzzle), Miller and\nMoss (2005) showed that a logic of such a language cannot be\nrecursively axiomatized. \n\nFinally, PAL-based solutions to the Cheryl\u2019s Birthday, Muddy\nChildren, and Sum and Least Common Multiple Puzzles are presented in\n Appendix B.\n \n2.2 Group knowledge: common knowledge and distributed knowledge\n2.2.1 Common knowledge\n\nTo reason about common knowledge and public announcements, we add the\ncommon knowledge operators \\([B*]\\) to the language for each group of\nagents \\(B\\subseteq\\sA\\). The formula \\([B*]F\\) is read, \u201dit is\ncommon knowledge among the group B that F is\ntrue\u201d. We define the language \\eqref{PAL+C} of public\nannouncement logic with common knowledge as follows: \n\n\\[\\begin{gather*}\nF  \\ccoloneqq p \\mid F \\wedge F \\mid \\neg F \\mid [a]F \\mid [F!]F \\mid [B*]F \\\\\n \\small p \\in \\sP,\\; a \\in \\sA,\\; B\\subseteq\\sA\n\\taglabel{PAL+C}\n\\end{gather*}\\]\n\n\nThe semantics of this language over pointed Kripke models is defined\nin\n Appendix A.\n We recall two key defined expressions: \n\n\n\\([B]F\\) denotes \\(\\bigwedge_{a\\in B}[a]F\\) \u2014 \u201ceveryone in\ngroup B knows (or believes) F\u201d;\n\n\\([C]F\\) denotes \\([\\sA*]F\\) \u2014 \u201cit is common knowledge (or\nbelief) that F is true.\u201d\n\n\nFor convenience in what follows, we will adopt the epistemic (i.e.,\nknowledge) reading of formulas in the remainder of this subsection. In\nparticular, using the language \\eqref{PAL+C}, we are able to provide a\nformal sense in which public announcements bring about common\nknowledge. \n\n\nTheorem. For each pointed Kripke model \\((M,w)\\), we\nhave:\n\n \\(M,w\\models[p!][C]p\\) for each propositional letter \\(p\\in\\sP\\).\n\n\u201cA propositional letter becomes common knowledge after it is\nannounced.\u201d \nIf F is successful (i.e., \\(\\models[F!]F\\)), then\n\\(M,w\\models[F!][C]F\\).\n\n\u201cA successful formula becomes common knowledge after it is\nannounced.\u201d \n\n\n\nWe now examine the axiomatic theory of public announcement logic with\ncommon knowledge. \n\n\nThe axiomatic theory \\(\\PALC\\).\n\n Axiom schemes and rules for the theory\n \\(\\PAL\\)\n\nAxiom schemes for common knowledge:\n\n\n \\([B*](F\\to G)\\to([B*]F\\to[B*]G)\\)\n\n\u201cCommon knowledge is closed under logical consequence.\u201d\n\n \\([B*]F\\leftrightarrow(F\\land[B][B*]F)\\), the \u201cMix\naxiom\u201d\n\n\u201cCommon knowledge is equivalent to truth and group knowledge of\ncommon knowledge.\u201d \n\\([B*](F\\to[B]F)\\to(F\\to[B*]F)\\), the \u201cInduction\naxiom\u201d\n\n\u201cIf there is common knowledge that truth implies group knowledge\nand there is truth, then there is common knowledge.\u201d \n \nCK Necessitation Rule: from F, infer \\([B*]F\\)\n\n\u201cThere is common knowledge of every validity.\u201d \nAnnouncement-CK Rule: from \\(H\\to[F!]G\\) and \\((H\\land\nF)\\to[B]H\\), infer \\(H\\to[F!][B*]G\\)\n\n\u201cIf H guarantees the truth of G after F is\nannounced and the joint truth of H and F guarantees\ngroup knowledge of H, then H guarantees the announcement\nof F will lead to common knowledge of G.\u201d \n\n\n\n\n\\(\\PALC\\) Soundness and Completeness (Baltag, Moss, and\nSolecki 1998, 1999; see also van Ditmarsch, van der Hoek, and Kooi\n2007). \\(\\PALC\\) is sound and complete with respect to the\ncollection \\(\\sC_*\\) of pointed Kripke models for which the underlying\npublic announcement logic \\(\\PAL\\) is sound and complete. That is, for\neach \\eqref{PAL+C}-formula F, we have that \\(\\PALC\\vdash F\\) if\nand only if \\(\\sC_*\\models F\\).\n\n\nUnlike the proof of completeness for the logic \\(\\PAL\\) without common\nknowledge, the proof for the logic \\(\\PALC\\) with common knowledge\ndoes not proceed by way of a reduction theorem. This is because adding\ncommon knowledge to the language strictly increases the expressivity.\n\n\n\nTheorem (Baltag, Moss, and Solecki 1998, 1999; see also van\nDitmarsch, van der Hoek, and Kooi 2007). Over the class of\nall pointed Kripke models, the language \\eqref{PAL+C} of public\nannouncement logic with common knowledge is strictly more expressive\nthan language \\eqref{PAL} without common knowledge. In particular, the\n\\eqref{PAL+C}-formula \\([p!][C]q\\) cannot be expressed in \\eqref{PAL}\nwith respect to the class of all pointed Kripke models: for every\n\\eqref{PAL}-formula F there exists a pointed Kripke model\n\\((M,w)\\) such that \\(M,w\\not\\models F\\leftrightarrow[p!][C]q\\).\n\n\nThis result rules out the possibility of a reduction theorem for\n\\(\\PALC\\): we cannot find a public announcement-free equivalent of\nevery \\eqref{PAL+C}-formula. This led van Benthem, van Eijck, and Kooi\n(2006) to develop a common knowledge-like operator for which a\nreduction theorem does hold. The result is the binary relativized\ncommon knowledge operator \\([B*](F|G)\\), which is read,\n\u201cF is common knowledge among group B relative to\nthe information that G is true\u201d. The language \\eqref{RCK}\nof relativized common knowledge is given by the following grammar:\n \n\n\\[\\begin{gather*}\nF  \\ccoloneqq \np \\mid F \\wedge F \\mid \\neg F \\mid [a]F \\mid [F!]F \\mid [B*](F|F) \\\\\n\\small p \\in \\sP,\\; a \\in \\sA,\\; B\\subseteq\\sA\n\\taglabel{RCK}\n\\end{gather*}\\]\n\n\nand the language \\eqref{RCK+P} of relativized common knowledge with\npublic announcements is obtained by adding public announcements to\n\\eqref{RCK}:  \n\n\\[\\begin{gather*}\nF  \\ccoloneqq \np \\mid F \\wedge F \\mid \\neg F \\mid [a]F \\mid [F!]F \\mid [B*](F|F) \\mid [F!]F \\\\\n \\small p \\in \\sP,\\; a \\in \\sA,\\; B\\subseteq\\sA\n\\taglabel{RCK+P}\n\\end{gather*}\\]\n\n\nThe semantics of \\eqref{RCK} is an extension of the semantics of\n\\eqref{ML}, and the semantics of \\eqref{RCK+P} is an extension of the\nsemantics of \\eqref{PAL}. In each case, the extension is obtained by\nadding the following inductive truth clause: \n\n \\(M,w\\models[B*](F|G)\\) holds if and only if \\(M,v\\models F\\) for\neach v satisfying \\(w(R[G!]_B)^*v\\) \n\n\nHere we recall that \\(R[G!]\\) is the function that obtains after the\npublic announcement of G; that is, we have \\(xR[G!]_ay\\) if and\nonly if x and y are in the model after the announcement\nof G (i.e., \\(M,w\\models G\\) and \\(M,y\\models G\\)) and there is\nan a-arrow from x to y in the original model\n(i.e., \\(xR_ay\\)). The relation \\(R[G!]_B\\) is then the union of the\nrelations for those agents in B; that is, we have \\(xR[G!]_By\\)\nif and only if there is an \\(a\\in B\\) with \\(xR[G!]_ay\\). Finally,\n\\((R[G!]_B)^*\\) is the reflexive-transitive closure of the relation\n\\(R[G!]_B\\); that is, we have \\(x(R[G!]_B)^*y\\) if and only if \\(x=y\\)\nor there is a finite sequence  \n\n\\[\nx\\,R[G!]_B\\,z_1\\,R[G!]_B\\cdots R[G!]_B\\,z_n\\,R[G!]_B\\,y\n\\]\n\n\nof \\(R[G!]_B\\)-arrows connecting x to y. So, all\ntogether, the formula \\([B*](F|G)\\) is true at w if and only if\nan F-world is at the end of every finite path (of length zero\nor greater) that begins at w, contains only G-worlds,\nand uses only arrows for agents in B. Intuitively, this says\nthat if the agents in B commonly assume G is true in\njointly entertaining possible alternatives to the given state of\naffairs w, then, relative to this assumption, F is\ncommon knowledge among those in B. \n\nAs observed by van Benthem, van Eijck, and Kooi (2006), relativized\ncommon knowledge is not the same as non-relativized common knowledge\nafter an announcement. For example, over the collection of all pointed\nKripke models, the following formulas are not equivalent: \n\n \\(\\lnot[\\{a,b\\}*]([a]p\\mid p)\\) \u2014 \u201cit is not the case\nthat, relative to p, it is common knowledge among a and\nb that a knows p.\u201d \n \\([p!]\\lnot[\\{a,b\\}*][a]p\\) \u2014 \u201cafter p is\nannounced, it is not the case that it is common knowledge among\na and b that a knows p.\u201d \n\n\nIn particular, in the pointed model \\((M,w)\\) pictured in Figure 1,\nthe formula \\(\\lnot[\\{a,b\\}*]([a]p\\mid p)\\) is true because there is a\npath that begins at w, contains only p-worlds, uses only\narrows in \\(\\{a,b\\}\\), and ends on the \\(\\lnot[a]p\\)-world u.\n\n\n\n\nM\n\n\nFigure 1: The pointed Kripke model\n\\((M,w)\\).\n\n\nHowever, the formula \\([p!]\\lnot[\\{a,b\\}*][a]p\\) is false at \\((M,w)\\)\nbecause, after the announcement of p, the model \\(M[p!]\\)\npictured in Figure 2 obtains, and all worlds in this model are\n\\([a]p\\)-worlds. In fact, whenever p is true, the formula\n\\([p!]\\lnot[\\{a,b\\}*][a]p\\) is always false: after the\nannouncement of p, all that remains are p-worlds, and\ntherefore every world is an \\([a]p\\)-world. \n\n\n\n\\(M[p!]\\)\n\n\nFigure 2: The pointed Kripke model\n\\((M[p!],w)\\).\n\n\nThe axiomatic theories of relativized common knowledge with and\nwithout public announcements along with expressivity results for the\ncorresponding languages are detailed in\n Appendix F.\n \n\nWe now state two complexity results for the languages of this\nsubsection. \n\n\n\\eqref{PAL+C} and \\eqref{RCK} Complexity. Let \\(\\sC\\)\nbe the class of all Kripke models. Let \\(\\sC_{\\mathsf{S5}}\\) be the\nclass of Kripke models such that each binary accessibility relation is\nreflexive, transitive, and symmetric.\n\n The satisfiability problem for each of \\eqref{PAL+C} and\n\\eqref{RCK} over \\(\\sC_{\\mathsf{S5}}\\) is EXPTIME-complete (Lutz\n2006). \nThe model checking problem for each of \\eqref{PAL+C} and\n\\eqref{RCK} over \\(\\sC\\) is in P (Kooi and van Benthem 2004). \n\n\n\nIn the remainder of the article, unless otherwise stated, we will\ngenerally assume that we are working with languages that do not\ncontain common knowledge or relativized common knowledge. \n2.2.2 Distributed knowledge\n\nAnother notion of group knowledge is distributed knowledge\n(Fagin et al. 1995). Intuitively, a group B of agents has\ndistributed knowledge that F is true if and only if, were they\nto pool together all that they know, they would then know F. As\nan example, if agents a and b are going to visit a\nmutual friend, a knows that the friend is at home or at work,\nand b knows that the friend is at work or at the cafe, then\na and b have distributed knowledge that the friend is at\nwork: after they pool together what they know, they will each know the\nlocation of the friend. Distributed knowledge and public announcements\nhave been studied by W\u00e1ng and \u00c5gotnes (2011). Related to\nthis is the study of whether a notion of group knowledge (such as\ndistributed knowledge) satisfies the property that something known by\nthe group can be established via communication; see Roelofsen (2007)\nfor details. \n2.3 Moore sentences\n\nIt may seem as though public announcements always\n\u201csucceed\u201d, by which we mean that after something is\nannounced, we are guaranteed that that it is true. After all, this is\noften the purpose of an announcement: by making the announcement, we\nwish to inform everyone of its truth. However, it is not hard to come\nup with announcements that are true when announced but false\nafterward; that is, not all announcements are successful. Here are a\nfew everyday examples in plain English. \n\n Agent a, who is visiting Amsterdam for the first time,\nsteps off the plane in the Amsterdam Airport Schiphol and\ntruthfully says, \u201ca has never made a statement in\nAmsterdam\u201d.\n\nThis is unsuccessful because it is \u201cself-defeating\u201d: it\nrules out various past statements, but it itself is one of those ruled\nout, so the announcement violates what it says. \nAgent a who does not know it is raining, is told, \u201cIt\nis raining but a does not know it\u201d.\n\nThis is an example of a Moore formula, which are sentences of\nthe form \u201cp is true but agent a does not know\np.\u201c In the language \\eqref{ML}, Moore formulas have the\nform \\(p\\land\\lnot[a]p\\). An announcement of a Moore formula is\nunsuccessful because, after the announcement the agent comes to know\nthe first conjunct p (the statement \u201cit is raining\u201d\nin the example), which therefore falsifies the second conjunct\n\\(\\lnot[a]p\\) (the statement \u201ca does not know it is\nraining\u201d in the example). \n\n\nThe opposite of unsuccessful formulas are the \u201csuccessful\u201d\nones: these are the formulas that are true after they are announced.\nHere one should distinguish between \u201cperformative\nannouncements\u201d that bring about truth by their very occurrence\n(e.g., a judge says, \u201cThe objection is overruled\u201d, which\nhas the effect of making the objection overruled) and\n\u201cinformative announcements\u201d that simply inform their\nlisteners of truth (e.g., our mutual friend says, \u201cI live on\n207th Street\u201d, which has the effect of informing us of something\nthat is already true). Performative announcements are best addressed\nin a Dynamic Epistemic Logic setting using factual changes, a\ntopic discussed in\n Appendix G.\n For now our concern will be with informative announcements. \n\nThe phenomena of (un)successfulness of announcements was noted early\non by Hintikka (1962) but was not studied in detail until the advent\nof Dynamic Epistemic Logic. In DEL, the explicit language for public\nannouncements provides for an explicit syntactic definition of\n(un)successfulness. \n\n\n(Un)successful formula (van Ditmarsch and Kooi 2006; see also\nGerbrandy 1999). Let F be a formula in a language with\npublic announcements.\n\n To say that F is successful means that\n\\(\\models[F!]F\\).\n\n\u201cA successful formula is one that is always true after it is\nannounced.\u201d \nTo say that F is unsuccessful means that\nFis not successful (i.e., \\(\\not\\models[F!]F\\)).\n\n\u201cAn unsuccessful formula is one that may be false after it is\nannounced.\u201d \n\n\n\nAs we have seen, the Moore formula  \n\n\\[\\begin{equation*}\\tag{MF} p\\land\\lnot[a]p \\end{equation*}\\]\n\n\nis unsuccessful: if (MF) is true, then its announcement eliminates all\n\\(\\lnot p\\)-worlds, thereby falsifying \\(\\lnot[a]p\\) (since the truth\nof \\(\\lnot[a]p\\) requires the existence of an a-arrow leading\nto a \\(\\lnot p\\)-world). \n\nAn example of a successful formula is a propositional letter p.\nIn particular, after an announcement of p, it is clear that\np still holds (since the propositional valuation does not\nchange); that is, \\([p!]p\\). Moreover, as the reader can easily\nverify, the formula \\([a]p\\) is also successful. \n\nIn considering (un)successful formulas, a natural question arises: can\nwe provide an syntactic characterization of the formulas that are\n(un)successful? That is, is there a way for us know whether a formula\nis (un)successful simply by looking at its form? Building off of the\nwork of Visser et al. (1994) and Andr\u00e9ka, Ne\u0301meti, and van\nBenthem (1998), van Ditmarsch and Kooi (2006) provide one\ncharacterization of some of the successful \\eqref{PAL+C}-formulas.\n\n\n\nTheorem (van Ditmarsch and Kooi 2006). The\npreserved formulas are formed by the following grammar.\n\n\\[\\begin{gather*}\nF \\ccoloneqq p \\mid \\lnot p \\mid F\\land F \\mid F\\lor F\\mid [a]F\\mid [\\lnot F!]F \\mid [B*]F\n\\\\\n\\small p\\in\\sP,\\; a\\in\\sA,\\; B\\subseteq\\sA\n\\end{gather*}\\]\n\n Every preserved formula is successful.\n\n\nUsing a slightly different notion of successfulness wherein a formula\nF is said to be successful if and only if we have that\n\\(M,w\\models F\\land \\may{a}F\\) implies \\(M[F!],w\\models F\\) for each\npointed Kripke model \\((M,w)\\) coming from a given class \\(\\sC\\),\nHolliday and Icard (2010) provide a comprehensive analysis of\n(un)successfulness with respect to the class of single-agent\n\\(\\mathsf{S5}\\) Kripke models and with respect to the class of\nsingle-agent \\(\\mathsf{KD45}\\) Kripke models. In particular, they\nprovide a syntactic characterization of the successful formulas over\nthese classes of Kripke models. This analysis was extended in part to\na multi-agent setting by Saraf and Sourabh (2012). The highly\ntechnical details of these works are beyond the scope of the present\narticle. \n\nFor more on Moore sentences, we refer the reader to\n Section 5.3\n of the Stanford Encyclopedia of Philosophy entry on\n Epistemic Paradoxes\n (Sorensen 2011). \n3. Complex epistemic interactions\n\nIn the previous section, we focused on one kind of model-transforming\naction: the public announcement. In this section, we look at the\npopular \u201caction model\u201d generalization of public\nannouncements due to Baltag, Moss, and Solecki (Baltag, Moss, and\nSolecki 1998), together referred to as \u201cBMS\u201d. Action\nmodels are simple relational structures that can be used to describe a\nvariety of informational actions, from public announcements to more\nsubtle communications that may contain degrees of privacy,\nmisdirection, deception, and suspicion, to name just a few\npossibilities. \n3.1 Action models describe complex informational scenarios\n\nTo begin, let us consider a specific example of a more complex\ncommunicative action: a completely private announcement. The idea of\nthis action is that one agent, let us call her a, is to receive\na message in complete privacy. Accordingly, no other agent should\nlearn the contents of this message, and, furthermore, no other agent\nshould even consider the possibility that agent a received the\nmessage in the first place. (Think of agent a traveling\nunnoticed to a secret and secure location, finding and reading a coded\nmessage only she can decode, and then destroying the message then and\nthere.) One way to think about this action is as follows: there are\ntwo possible events that might occur. One of these, let us call it\nevent e, is the announcement that p is true; this is the\nsecret message to a. The other event, let us call it f,\nis the announcement that the propositional constant \\(\\top\\) for truth\nis true, an action that conveys no new propositional information\n(since \\(\\top\\) is a tautology). Agent a should know that the\nmessage is p and hence that the event that is in fact occurring\nis e. All other agents should mistakenly believe that it is\ncommon knowledge that the message is \\(\\top\\) and not even consider\nthe possibility that the message is p. Accordingly, other\nagents should consider event f the one and only possibility and\nmistakenly believe that this is common knowledge. We picture a\ndiagrammatic representation of this setup in Figure 3. \n\n\n\n\\(\\Pri_a(p)\\)\n\n\nFigure 3: The pointed action model\n\\((\\Pri_a(p),e)\\) for the completely private announcement of p\nto agent a.\n\n\nIn the figure, our two events e and f are pictured as\nrectangles (to distinguish these from the circled worlds of a Kripke\nmodel). The formula appearing inside an event\u2019s rectangle is\nwhat is announced when the event occurs. So event e represents\nthe announcement of p, and event f represents the\nannouncement of \\(\\top\\). The event that actually occurs, called the\n\u201cpoint\u201d, is indicated using a double rectangle; in this\ncase, the point is e. The only event that a considers\npossible is e because the only a-arrow leaving e\nloops right back to e. But all of the agents in our agent set\n\\(\\sA\\) other than a mistakenly consider the alternative event\nf as the only possibility: all non\u2013a-arrows\nleaving e point to f. Furthermore, from the perspective\nof event f, it is common knowledge that event f (and its\nannouncement of \\(\\top\\)) is the only event that occurs: every agent\nhas exactly one arrow leaving f and this arrow loops right back\nto f. Accordingly, the structure pictured above describes the\nfollowing action: p is to be announced, agent a is to\nknow this, and all other agents are to mistakenly believe it is common\nknowledge that \\(\\top\\) is announced. Structures like those pictured\nin Figure 3 are called action models. \n\n\n\n\nAction model (Baltag, Moss, and Solecki 1998, 1999; see also\nBaltag and Moss 2004). Other names in the literature:\n\u201cevent model\u201d or \u201cupdate model\u201d. Given a set\nof formulas \\(\\Lang\\) and a finite nonempty set \\(\\sA\\) of agents, an\naction model is a structure \n\n\\[ A=(E,R,\\pre) \\]\n\n consisting of\n\n a nonempty finite set E of the possible communicative\nevents that might occur, \n a function \\(R:\\sA\\to P(W\\times W)\\) that assigns to each agent\n\\(a\\in\\sA\\) a binary possibility relation \\(R_a\\subseteq E\\times E\\),\nand \n a function \\(\\pre:E\\to\\Lang\\) that assigns to each event \\(e\\in\nE\\) a precondition formula \\(\\pre(e)\\in\\Lang\\). Intuitively,\nthe precondition \\(\\pre(e)\\) is announced when event e occurs.\n\n\n\nNotation: if A is an action model, then adding a superscript\nA to a symbol in \\(\\{E,R,\\pre\\}\\) is used to denote a component\nof the triple that makes up A in such a way that\n\\((E^A,R^A,\\pre^A)=A\\). We define a pointed action model,\nsometimes also called an action, to be a pair \\((A,e)\\)\nconsisting of an action model A and an event \\(e\\in E^A\\) that\nis called the \\(point\\). In drawing action models, events are drawn as\nrectangles, and a point (if any) is indicated with a double rectangle.\nWe use many of the same drawing and terminological conventions for\naction models that we use for (pointed) Kripke models (see\n Appendix A).\n\n\n\\((\\Pri_a(p),e)\\) is the action pictured in\n Figure 3.\n Given an initial pointed Kripke model \\((M,w)\\) at which p is\ntrue, we determine the model-transforming effect of the action\n\\((\\Pri_a(p),e)\\) by constructing a new pointed Kripke model\n\n\\[ (M[\\Pri_a(p)],(w,e)). \\]\n\n The construction of the Kripke model \\(M[\\Pri_a(p)]\\) is\ngiven by the BMS \u201cproduct update\u201d. \n\n\n\n\nProduct update (Baltag, Moss, and Solecki 1998, 1999; see also\nBaltag and Moss 2004). Let \\((M,w)\\) be a pointed Kripke\nmodel and \\((A,e)\\) be a pointed action model. Let \\(\\models\\) be a\nbinary satisfaction relation defined between \\((M,w)\\) and formulas in\nthe language \\(\\Lang\\) of the precondition function\n\\(\\pre^A:E^A\\to\\Lang\\) of the action model A. If\n\\(M,w\\models\\pre^A(e)\\), then the Kripke model \n\n\\[\nM[A]=(W[A],R[A],V[A])\n\\]\n\n is defined\nvia the product update operation \\(M\\mapsto M[A]\\) given as\nfollows:\n\n \\(W[A] \\coloneqq \\{ (v,f)\\in W\\times E \\mid M,v\\models\\pre^A(f)\n\\}\\) \u2014 pair worlds with events whose preconditions they satisfy,\n\n\\((v_1,f_1)R[A]_a(v_2,f_2)\\) if and only if \\(v_1 R^M_a v_2\\) and\n\\(f_1 R^A_a f_2\\) \u2014 insert an a-arrow in \\(M[A]\\) between\na pair just in case there is an a-arrow in M between the\nworlds and an a-arrow in A between the events, and \n\\(V[A]((v,f))\\coloneqq V^M(p)\\) \u2014 make the valuation of\np at the pair \\((v,f)\\) just as it was at v. \n\n\nAn action \\((A,e)\\) operates on an initial situation \\((M,w)\\)\nsatisfying \\(M,w\\models\\pre^A(e)\\) via the product update to produce\nthe resultant situation \\((M[A],(w,e))\\). \n\n\nIn this definition, the worlds of \\(M[A]\\) are obtained by making\nmultiple copies of the worlds of M, one copy per event \\(f\\in\nE^A\\). The event-f copy of a world v in M is\nrepresented by the pair \\((v,f)\\). Such a pair is to be included in\nthe worlds of \\(M[A]\\) if and only if \\((M,v)\\) satisfies the\nprecondition \\(\\pre^A(f)\\) of event f. The term \u201cproduct\nupdate\u201d comes from the fact that the set \\(W[A]\\) of worlds of\n\\(M[A]\\) is specified by restricting the full Cartesian product\n\\(W^M\\times E^A\\) to those pairs \\((v,f)\\) whose indicated world\nv satisfies the precondition \\(\\pre^A(f)\\) of the indicated\nevent f; that is, the \u201cproduct update\u201d is based on\na restricted Cartesian product, hence the name. \n\nAccording to the product update, we insert an a-arrow\n\\((v_1,f_1)\\to_a (v_2,f_2)\\) in \\(M[A]\\) if and only if there is an\na-arrow \\(v_1\\to_a v_2\\) in M and an a-arrow\n\\(f_1\\to_a f_2\\) in A. In this way, agent a\u2019s\nuncertainty in the resultant model \\(M[A]\\) comes from two sources:\nher initial uncertainty in M (represented by \\(R^M_a\\)) as to\nwhich is the actual world and her uncertainty in A (represented\nby \\(R^A_a\\)) as to which is the actual event. Finally, the valuation\nat the copy \\((v,f)\\) in \\(M[A]\\) is just the same as it was at the\noriginal world v in M. \n\nFor an example of the product update in action, consider the following\npointed Kripke model \\((M,w)\\): \n\n\n\nM\n\n\n\nThe action model \\(\\Pri_a(p)\\) from\n Figure 3\n operates on \\((M,w)\\) via the product update to produce the resultant\nsituation \\((M[\\Pri_a(p)],(w,e))\\) pictured as follows: \n\n\n\n\\(M[\\Pri_a(p)]\\)\n\n\n\nIndeed, to produce \\(M[\\Pri_a(p)]\\) from M via the product\nupdate with the action model \\(\\Pri_a(p)\\): \n\n Event e has us copy worlds at which\n\\(\\pre^{\\Pri_a(p)}(e)=p\\) is true; this is just the world w,\nwhich we retain in the form \\((w,e)\\) with the same valuation. \nEvent f has us copy worlds at which\n\\(\\pre^{\\Pri_a(p)}(f)=\\top\\) is true; this is both w and\nv, which we retain in the forms \\((w,f)\\) and \\((v,f)\\),\nrespectively, with their same respective valuations. \nWe interconnect the worlds in \\(M[\\Pri_a(p)]\\) with agent arrows\naccording to the recipe of the product update: place an arrow between\npairs just in case we have arrows componentwise in M and in\n\\(\\Pri_a(p)\\), respectively. For example, we have a b-arrow\n\\((w,e)\\to_b(v,f)\\) in \\(M[\\Pri_a(p)]\\) because we have the\nb-arrow \\(w\\to_b v\\) in M and the b-arrow\n\\(e\\to_b f\\) in \\(\\Pri_a(p)\\). \nThe point (i.e., actual world) \\((w,e)\\) of the resultant\nsituation is obtained by paring together the point w from the\ninitial situation \\((M,w)\\) and the point e from the applied\naction \\((\\Pri_a(p),e)\\). \n\n\nWe therefore obtain the model \\(M[\\Pri_a(p)]\\) as pictured above. We\nnote that the product update-induced mapping \n\n\\[\n(M,w) \\mapsto\n(M[A],(w,e))\n\\]\n\n from the\ninitial situation \\((M,w)\\) to the resultant situation\n\\((M[A],(w,e))\\) has the following effect: we go from an initial\nsituation \\((M,w)\\) in which neither agent knows whether p is\ntrue to a resultant situation \\((M[A],(w,e))\\) in which a knows\np is true but b mistakenly believes everyone\u2019s\nknowledge is unchanged. This is of course just what we want of the\nprivate announcement of p to agent a. \n\nWe now take a moment to comment on the similarities and differences\nbetween action models and Kripke models. To begin, both are labeled\ndirected graphs (consisting of labeled nodes and labeled edges\npointing between the nodes). A node of a Kripke model (a\n\u201cworld\u201d) is labeled by the propositional letters that are\ntrue at the world; in contrast, a node of an action model (an\n\u201cevent\u201d) is labeled by a single formula that is to be\nannounced if the event occurs. However, in both cases, agent\nuncertainty is represented using the same \u201cconsidered\npossibilities\u201d approach. In the case of Kripke models, an agent\nconsiders various possibilities for the world that might be actual; in\nthe case of action models, an agent considers various possibilities\nfor the event that might actually occur. The key insight behind action\nmodels, as put forward by Baltag, Moss, and Solecki (1998), is that\nthese two uncertainties can be represented using similar\ngraph-theoretic structures. We can therefore leverage our experience\nworking with Kripke models when we need to devise new action models\nthat describe complex communicative actions. In particular, to\nconstruct an action model for a given action, all we must do is break\nup the action into a number of simple announcement events and then\ndescribe the agents\u2019 respective uncertainties among these events\nin the appropriate way so as to obtain the desired action. The\ndifficulty, of course, is in determining the exact uncertainty\nrelationships. However, this determination amounts to inserting the\nappropriate agent arrows between possible events, and doing this\nrequires the same kind of reasoning as that which we used in the\nconstruction of Kripke models meeting certain basic or higher-order\nknowledge constraints. We demonstrate this now by way of example,\nconstructing a few important action models along the way. \n3.2 Examples of action models\n\nWe saw the example of a completely private announcement in\n Figure 3,\n a complex action in which one agent learns something without the\nother agents even suspecting that this is so. Before devising an\naction model for another similarly complicated action, let us return\nto our most basic action: the public announcement of p. The\nidea of this action is that all agents receive the information that\np is true, and this is common knowledge. So to construct an\naction model for this action, we need only one event e that\nconveys the announcement that p is true, and the occurrence of\nthis event should be common knowledge. This leads us immediately to\nthe action model \\(\\Pub(p)\\) pictured in Figure 4. \n\n\n\n\\(\\Pub(p)\\)\n\n\nFigure 4: The pointed action model\n\\((\\Pub(p),e)\\) for the public announcement of p. \n\n\nIt is not difficult to see that \\(\\Pub(p)\\) is just what we want:\nevent e conveys the desired announcement and the reflexive\narrows for each agent make it so that this event is common knowledge.\nIt is important to note that in virtue of the fact that we can\nconstruct an action model for public announcements, it follows that\naction models are a generalization of public announcements. \n\nWe now turn to a more complicated action: the semi-private\nannouncement of p to agent a (sometimes called the\n\u201csemi-public announcement\u201d of p to agent a).\nThe idea of this action is that agent a is told that p\nis true, the other agents know that a is told the truth value\nof p, but these other agents do not know what it is exactly\nthat a is told. This suggests an action model with two events,\none for each thing that a might be told: an event e that\nannounces p and event f that announces \\(\\lnot p\\).\nAgent a is to know which event occurs, whereas all other agents\nare to be uncertain as to which event occurs. This leads us to the\naction model \\(\\frac12\\Pri_a(p)\\) pictured in Figure 5. \n\n\n\n\\(\\frac12\\Pri_a(p)\\)\n\n\nFigure 5: The pointed action model\n\\((\\frac12\\Pri_a(p),e)\\) for the semi-private announcement of p\nto agent a. \n\n\nWe see that \\(\\frac12\\Pri_a(p)\\) satisfies just what we want: the\nactual event that occurs is the point e (the announcement of\nthe precondition p), agent a knows this, but all other\nagents consider it possible that either e (the announcement of\np) or f (the announcement of \\(\\lnot p\\)) occurred.\nFurthermore, the other agents know that a knows which event was\nthe case (since at each of the events e and f that they\nconsider possible, agent a knows the event that occurs). This\nis just what we want of a semi-private announcement. \n\nFinally, let us consider a much more challenging action: the\nmisleading private announcement of p to agent a. The\nidea of this action is that agent a is told p in a\ncompletely private manner but all other agents are misled into\nbelieving that a received the private announcement of \\(\\lnot\np\\) instead. So to construct an action model for this, we need a few\nelements: events for the private announcement of \\(\\lnot p\\) to\na that the non-a agents mistakenly believe occurs and an\nevent for the actual announcement of p that only a knows\noccurs. As for the events for the private announcement of \\(\\lnot p\\),\nit follows by a simple modification of\n Figure 3\n that the private announcement of \\(\\lnot p\\) to agent a is the\naction \\((\\Pri_a(\\lnot p),e)\\) pictured as follows: \n\n\n\n\\(\\Pri_a(\\lnot p)\\)\n\n\n\nSince the other agents are to believe that the above action occurs,\nthey should believe it is event e that occurs. However, they\nare mistaken: what actually does occur is a new event g that\nconveys to a the private information that p is true.\nTaken together, we obtain the action \\((\\MPri_a(p),g)\\) pictured in\nFigure 6. \n\n\n\n\\(\\MPri_a(p)\\)\n\n\nFigure 6: The pointed action model\n\\((\\MPri_a(p),g)\\) for the misleading private announcement of p\nto agent a. \n\n\nLooking at \\(\\MPri_a(p)\\), we see that if we were to to delete event\ng (and all arrows to and from g), then we would obtain\n\\(\\Pri_a(\\lnot p)\\). So events e and f in \\(\\MPri_a(p)\\)\nplay the role of representing the \u201cmisdirection\u201d the\nnon-a agents experience: the private announcement of \\(\\lnot\np\\) to agent a. However, it is event g that actually\noccurs: this event conveys to a that p is true while\nmisleading the other agents into believing that it is event e,\nthe event corresponding to the private announcement of \\(\\lnot p\\) to\na, that occurs. In sum, a receives the information that\np is true while the other agents are mislead into believing\nthat a received the private announcement of \\(\\lnot p\\). One\nconsequence of this is that non-a agents come to hold the\nfollowing beliefs: \\(\\lnot p\\) is true, agent a knows this, and\nagent a believes the others believe that no new propositional\ninformation was provided. These beliefs are all incorrect. The\nnon-a agents are therefore highly mislead. \n3.3 The Logic of Epistemic Actions\n\nNow that we have seen a number of action models, we turn to the formal\nsyntax and semantics of the language \\eqref{EAL} of Epistemic\nAction Logic (a.k.a., the Logic of Epistemic Actions).\nWe define the language \\eqref{EAL} along with the set \\(\\AM_*\\) of\npointed action models with preconditions in the language \\eqref{EAL}\naccording to the following recursive grammar:  \n\n\\[\\begin{gather*}\nF  \\ccoloneqq p \\mid F \\wedge F \\mid \\neg F \\mid [a]F \\mid [A,e]F \\\\\n \\small p \\in \\sP,\\; a \\in \\sA,\\; (A,e)\\in\\AM_*\n\\taglabel{EAL}\n\\end{gather*}\\]\n\n\nTo be clear: in the language \\eqref{EAL}, the precondition\n\\(\\pre^A(e)\\) of an action model A may be a formula that\nincludes an action model modality \\([A',e']\\) for some other action\n\\((A',e')\\in\\AM_*\\). For full technical details on how this works,\nplease see\n Appendix H.\n \n\nFor convenience, we let \\(\\AM\\) denote the set of all action models\nwhose preconditions are all in the language \\eqref{EAL}. As we saw in\nthe previous two subsections, the set \\(\\AM_*\\) contains pointed\naction models for public announcements\n (Figure 4),\n private announcements\n (Figure 3),\n semi-private announcements\n (Figure 5),\n and misleading private announcements\n (Figure 6),\n along with many others. The satisfaction relation \\(\\models\\) between\npointed Kripke models and formulas of \\eqref{EAL} is the smallest\nextension of the relation \\(\\models\\) for \\eqref{ML} (see\n Appendix A)\n satisfying the following: \n\n \\(M,w\\models[A,e]G\\) holds if and only if\n\\(M,w\\not\\models\\pre^A(e)\\) or \\(M[A],(w,e)\\models G\\), where the\nKripke model \\(M[A]\\) is defined via the\n BMS product update\n (Baltag, Moss, and Solecki 1999). \n\n\nNote that the formula \\([A,e]G\\) is vacuously true if the precondition\n\\(\\pre(e)\\) of event e is false. Accordingly, the action model\nsemantics retains the assumption of truthfulness that we had for\npublic announcements. That is, for an event to actually occur, its\nprecondition must be true. As a consequence, the occurrence of an\nevent e implies that its precondition \\(\\pre(e)\\) was true, and\nhence the occurrence of an event conveys its precondition formula as a\nmessage. If an event can occur at a given world, then we say that the\nevent is executable at that world. \n\n\nExecutable events and action models. To say that a\npointed action model \\((A,e)\\) is executable at a pointed\nKripke model \\((M,w)\\) means that \\(M,w\\models\\pre(e)\\). To say that\nan event f in an action model A is executable\nmeans that \\((A,f)\\) is executable. To say that an action model\nA is executable in a Kripke model M means there\nis an event f in A and a world v in M such\nthat f is executable at \\((M,v)\\).\n\n\nAs was the case for PAL, one often wishes to restrict attention to\nKripke models whose relations \\(R_a\\) satisfy certain desirable\nproperties such as reflexivity, transitivity, Euclideanness, and\nseriality. In order to study actions over such classes, we must be\ncertain that the actions do not transform a Kripke model in the class\ninto a new Kripke model not in the class; that is, we must ensure that\nthe class of Kripke models is \u201cclosed\u201d under actions. The\nfollowing theorem provides some sufficient conditions that guarantee\nclosure. \n\n\nAction Model Closure Theorem. Let \\(M=(W^M,R^M,V)\\)\nbe a Kripke model and \\(A=(W^A,R^A,\\pre)\\) be an action model\nexecutable in M.\n\n If \\(R^M_a\\) and \\(R^A_a\\) are reflexive, then so is\n\\(R^M[A]_a\\). \nIf \\(R^M_a\\) and \\(R^A_a\\) are transitive, then so is\n\\(R^M[A]_a\\). \nIf \\(R^M_a\\) and \\(R^A_a\\) are Euclidean, then so is \\(R^M[A]_a\\).\n\nIf A satisfies the condition that every event \\(e\\in W^A\\)\ngives rise to a nonempty set \n\n\\[ S(e)\\subseteq \\{f\\in W^A\\mid eR^A_af\\} \\]\n\n of events such that\n\n\\[\n\\textstyle\n\\models \\pre^A(e) \\to\n\\may{a}\\left(\\bigvee_{f\\in S(e)}\\pre^A(f)\\right)\n\\,,\n\\]\n\n then \\(R^M[A]_a\\) is serial. (Note: the condition on\nA and the executability of A in M together imply\nthat \\(R^M_a\\) is serial.) \n\n\n\nThis theorem, like the analogous theorem for Public Announcement\nLogic, is used in providing simple sound and complete theories for the\nLogic of Epistemic Actions based on appropriate\n\u201caction-friendly\u201d logics. \n\n\nAction-friendly logic. To say that a logic \\(\\L\\) is\naction-friendly means we have the following:\n\n \\(\\L\\) is a normal multi-modal logic in the language \\eqref{ML}\n(i.e., with modals \\([a]\\) for each agent \\(a\\in\\sA\\)), \nthere is a class of Kripke models \\(\\sC\\) such that \\(\\L\\) is\nsound and complete with respect to the collection of pointed Kripke\nmodels based on models in \\(\\sC\\), and \nthere is a language \\(\\LEAL\\) (the \u201caction model extension\nof \\(\\L\\)\u201d) obtained from \\eqref{EAL} by restricting the form of\naction models such that \\(\\sC\\) is closed under the product update\nwith executable actions of this form (i.e., performing an executable\naction model of this form on a model in \\(\\sC\\) yields another model\nin \\(\\sC\\)). \n\n\n\nThe various axiomatic theories of modal logic with action models\n(without common knowledge) are obtained based on the choice of an\nunderlying action-friendly logic \\(\\L\\). \n\n\nThe axiomatic theory \\(\\EAL\\). Other names in the\nliterature: \\(\\DEL\\) or \\(\\AM\\) (for \u201caction model\u201d; see\nvan Ditmarsch, van der Hoek, and Kooi 2007).\n\n Axiom schemes and rules for the action-friendly logic \\(\\L\\)\n\n Reduction axioms (each in the language \\(\\LEAL\\)):\n\n\n \\([A,e]p\\leftrightarrow(\\pre(e)\\to p)\\) for letters \\(p\\in\\sP\\)\n\n\u201cAfter a non-executable action, every letter holds\u2014a\ncontradiction. After an executable action, letters retain their truth\nvalues.\u201d \n \\([A,e](G\\land H)\\leftrightarrow([A,e]G\\land[A,e]H)\\)\n\n\u201cA conjunction is true after an action iff each conjunct\nis.\u201d \n \\([A,e]\\lnot G\\leftrightarrow(\\pre(e)\\to\\lnot[A,e]G)\\)\n\n\u201cG is false after an action iff the action, whenever\nexecutable, does not make G true.\u201d \n \\([A,e][a]G\\leftrightarrow (\\pre(e)\\to\\bigwedge_{e R_a f}\n[a][A,f]G)\\)\n\n\u201ca knows G after an action iff the action,\nwhenever executable, is known by a to make G true\ndespite her uncertainty of the actual event.\u201d \n \nAction Necessitation Rule: from G, infer \\([A,e]G\\)\nwhenever the latter is in \\(\\LEAL\\).\n\n\u201cA validity holds after any action.\u201d \n\n\n\nThe first three reduction axioms are nearly identical to the\ncorresponding reduction axioms for \\(\\PAL\\), except that the first and\nthird \\(\\EAL\\) reduction axioms check the truth of a precondition in\nthe place where the \\(\\PAL\\) reduction axioms would check the truth of\nthe formula to be announced. This is actually the same kind of check:\nfor an event, the precondition must hold in order for the event to be\nexecutable; for a public announcement, the formula must be true in\norder for the public announcement to occur (and hence for the public\nannouncement event in question to be \u201cexecutable\u201d). The\nmajor difference between the \\(\\PAL\\) and \\(\\EAL\\) reduction axioms is\nin the fourth \\(\\EAL\\) reduction axiom. This axiom specifies the\nconditions under which an agent has belief (or knowledge) of something\nafter the occurrence of an action. In particular, adopting a doxastic\nreading for this discussion, the axiom says that agent a\nbelieves G after the occurrence of action \\((A,e)\\) if and only\nif the formula \n\n\\[\n\\textstyle\n\\pre(e)\\to\\bigwedge_{e R_af}[a][A,f]G\n\\]\n\n is true. This formula, in turn, says that\nif the precondition is true\u2014and therefore the action is\nexecutable\u2014then, for each of the possible events the agent\nentertains, she believes that G is true if the event in\nquestion occurs. This makes sense: a cannot be sure which of\nthe events has occurred, and so for her to believe something after the\naction has occurred, she must be sure that this something is true no\nmatter which of her entertained events might have been the actual one.\nFor example, if a sees her friend b become elated as he\nlistens to something he hears on the other side of a private phone\ncall, then the a may not know exactly what it is that b\nis being told; nevertheless, a has reason to believe that\nb is receiving good news because, no matter what it is exactly\nthat he is being told (i.e., no matter which of the events she thinks\nthat he may be hearing), she knows from his reaction that he must be\nreceiving good news. \n\nAs was the case for \\(\\PAL\\), the \\(\\EAL\\) reduction axioms allow us\nto \u201creduce\u201d each formula containing action models to a\nprovably equivalent formula whose action model modalities appear\nbefore formulas of lesser complexity, allowing us to eliminate action\nmodel modalities completely via a sequence of provable equivalences.\nAs a consequence, we have the following. \n\n\n\\(\\EAL\\) Reduction Theorem (Baltag, Moss, and Solecki 1998,\n1999; see also Baltag and Moss 2004). Given an\naction-friendly logic \\(\\L\\), every F in the language \\(\\LEAL\\)\nof Epistemic Action Logic (without common knowledge) is\n\\(\\EAL\\)-provably equivalent to a formula \\(F^\\circ\\) coming from the\naction model-free modal language \\eqref{ML}.\n\n\nOnce we have proved \\(\\EAL\\) is sound, the Reduction Theorem leads us\nto axiomatic completeness via the known completeness of the underlying\nmodal theory. \n\n\n\\(\\EAL\\) Soundness and Completeness (Baltag, Moss, and Solecki\n1998, 1999; see also Baltag and Moss 2004). \\(\\EAL\\) is sound\nand complete with respect to the collection \\(\\sC_*\\) of pointed\nKripke models for which the underlying action-friendly logic \\(\\L\\) is\nsound and complete. That is, for each \\(\\LEAL\\)-formula F, we\nhave that \\(\\EAL\\vdash F\\) if and only if \\(\\sC_*\\models F\\).\n\n\nWe saw above that for \\(\\PAL\\) it was possible to combine two\nconsecutive announcements into a single announcement via the schematic\nvalidity \n\n\\[ [F!][G!]H\\leftrightarrow[F\\land[F!]G!]H.  \\]\n\n Something similar is available for action\nmodels. \n\n\nAction model composition. The composition\n\\(A\\circ B=(E,R,\\pre)\\) of action models \\(A=(E^A,R^A,\\pre^A)\\) and\n\\(B=(E^B,R^B,\\pre^B)\\) is defined as follows:\n\n \\(E=E^A\\times E^B\\) \u2014 composed events are pairs \\((e,f)\\)\nof constituent events; \n \\((e_1,f_1) R_a (e_2,f_2)\\) if and only if \\(e_1 R^A_a e_2\\) and\n\\(f_1 R^B_a f_2\\) \u2014 a composed event is entertained iff its\nconstituent events are; and \n \\(\\pre((e_1,e_2))=\\pre^A(e_1)\\land[A,e_1]\\pre^B(e_2)\\) \u2014 a\ncomposed event is executable iff the first constituent is executable\nand, after it occurs, the second constituent is executable as well.\n\n\n\n\n\nComposition Theorem. Each instance of the following\nschemes is \\(\\EAL\\)-derivable (so long as they are permitted in the\nlanguage \\(\\LEAL\\)).\n\n Composition Scheme: \\([A,e][B,f]G\\leftrightarrow[A\\circ\nB,(e,f)]G\\) \n Associativity Scheme: \\([A\\circ B,(e,f)][C,g]H \\leftrightarrow\n[A,e][B\\circ C,(f,g)]H\\) \n\n\n\nWe conclude this subsection with two complexity results for\n\\eqref{EAL}. \n\n\nEAL Complexity (Aucher and Schwarzentruber 2013). Let\n\\(\\sC\\) be the class of all Kripke models.\n\nThe satisfiability problem for \\eqref{EAL} over \\(\\sC\\) is\nNEXPTIME-complete.\nThe model checking problem for \\eqref{EAL} over \\(\\sC\\) is\nPSPACE-complete.\n\n\n\nAppendix G\n provides information on action model equivalence (including the\nnotions of action model bisimulation and emulation), studies a simple\nmodification that enables action models to change the truth value of\npropositional letters (permitting so-called \u201cfactual\nchanges\u201d), and shows how to add common knowledge to \\(\\EAL\\).\n\n3.4 Variants and generalizations \n\nIn this section, we mention some variants of the action model approach\nto Kripke model transformation. \n\n Graph modifier logics. Aucher et al. (2009)\nstudy extensions of \\eqref{ML} that contain modalities for performing\ncertain graph modifying operations. \nGeneralized Arrow Update Logic. Kooi and Renne\n(2011b) introduce a theory of model-changing operations that delete\narrows instead of worlds. This theory, which is equivalent to \\(\\EAL\\)\nin terms of language expressivity and update expressivity, is a\ngeneralization of a simpler theory called Arrow Update Logic (see\n Section 4\n of\n Appendix E).\n \nLogic of Communication and Change. Van Benthem,\nvan Eijck, and Kooi (2006) introduce \\(\\LCC\\), the Logic of\nCommunication and Change, as a Propositional Dynamic Logic-like\nlanguage that incorporates action models with \u201cfactual\nchange\u201d. \nGeneral Dynamic Dynamic Logic. Girard, Seligman,\nand Liu (2012) propose General Dynamic Dynamic Logic \\(\\GDDL\\), a\nPropositional Dynamic Logic-style language that has complex action\nmodel-like modalities that themselves contain Propositional Dynamic\nLogic-style instructions. \n\n\nMore on these variants to the action model approach may be found in\n Appendix I.\n \n4. Belief change and Dynamic Epistemic Logic\n\nUp to this point, the logics we have developed all have one key\nlimitation: an agent cannot meaningfully assimilate information that\ncontradicts her knowledge or beliefs; that is, incoming information\nthat is inconsistent with an agent\u2019s knowledge or\nbelief leads to difficulties. For example, if agent a believes\np, then announcing that p is false brings about a state\nin which the agent\u2019s beliefs are trivialized (in the sense that\nshe comes to believe every sentence):  \n\n\\[\\models [a]p\\to[\\lnot p!][a]F\\quad \\text{for all formulas } F.\\]\n\n\nNote that in the above, we may replace F by a contradiction\nsuch as the propositional constant \\(\\bot\\) for falsehood.\nAccordingly, an agent who initially believes p is lead by an\nannouncement that p is false to an inconsistent state in which\nshe believes everything, including falsehoods. This\ntrivialization occurs whenever something is announced that contradicts\nthe agent\u2019s beliefs; in particular, it occurs if a contradiction\nsuch as \\(\\bot\\) is itself announced:  \n\n\\[\\models[\\bot!][a]F\\quad \\text{ for all formulas } F.\\]\n\n\nIn everyday life, the announcement of a contradiction, when recognized\nas such, is generally not informative; at best, a listener who\nrealizes she is hearing a contradiction learns that there is some\nproblem with the announcer or the announced information itself.\nHowever, the announcement of something that is not intrinsically\ncontradictory but merely contradicts existing beliefs is an everyday\noccurrence of great importance: upon receipt of trustworthy\ninformation that our belief about something is wrong, a rational\nresponse is to adjust our beliefs in an appropriate way. Part of this\nadjustment requires a determination of our attitude toward the general\nreliability or trustworthiness of the incoming information: perhaps we\ntrust it completely, like a young child trusts her parents. Or maybe\nour attitude is more nuanced: we are willing to trust the information\nfor now, but we still allow for the possibility that it might be\nwrong, perhaps leading us to later revise our beliefs if and when we\nlearn that it is incorrect. Or maybe we are much more skeptical: we\ndistrust the information for now, but we do not completely disregard\nthe possibility, however seemingly remote, that it might turn out to\nbe true. \n\nWhat is needed is an adaptation of the above-developed frameworks that\ncan handle incoming information that may contradict existing beliefs\nand that does so in a way that accounts for the many nuanced attitudes\nan agent may have with respect to the general reliability or\ntrustworthiness of the information. This has been a focus of much\nrecent activity in the DEL literature. \n4.1 Belief Revision: error-aware belief change\n\nBelief Revision is the study of belief change brought about by the\nacceptance of incoming information that may contradict initial beliefs\n(G\u00e4rdenfors 2003; Ove Hansson 2012; Peppas 2008). The seminal\nwork in this area is due to Alchourr\u00f3n, G\u00e4rdenfors, and\nMackinson, or \u201cAGM\u201d (1985). The AGM approach to belief\nrevision characterizes belief change using a number of postulates.\nEach postulate provides a qualitative account of the belief revision\nprocess by saying what must obtain with respect to the agent\u2019s\nbeliefs after revision by an incoming formula F. For example,\nthe AGM Success postulate says that the formulas the agent\nbelieves after revision by F must include F itself; that\nis, the revision always \u201csucceeds\u201d in causing the agent to\ncome to believe the incoming information F. \n\nBelief Revision has traditionally restricted attention to\nsingle-agent, \u201contic\u201d belief change: the beliefs in\nquestion all belong to a single agent, and the beliefs themselves\nconcern only the \u201cfacts\u201d of the world and not, in\nparticular, higher-order beliefs (i.e., beliefs about beliefs).\nFurther, as a result of the Success postulate, the incoming formula\nF that brings about the belief change is assumed to be\ncompletely trustworthy: the agent accepts without question\nthe incoming information F and incorporates it into her set of\nbeliefs as per the belief change process. \n\nWork on belief change in Dynamic Epistemic Logic incorporates key\nideas from Belief Revision Theory but removes three key restrictions.\nFirst, belief change in DEL can can involve higher-order beliefs (and\nnot just \u201contic\u201d information). Second, DEL can be used in\nmulti-agent scenarios. Third, the DEL approach permits agents to have\nmore nuanced attitudes with respect to the incoming information. \n4.2 Static and dynamic belief change\n\nThe literature on belief change in Dynamic Epistemic Logic makes an\nimportant distinction between \u201cstatic\u201d and\n\u201cdynamic\u201d belief change (van Ditmarsch 2005; Baltag and\nSmets 2008b; van Benthem 2007). \n\n Static belief change: the objects of agent\nbelief are fixed external truths that do not change, though the\nagent\u2019s beliefs about these truths may change. In a motto,\nstatic belief change involves \u201cchanging beliefs about an\nunchanging situation\u201d. \nDynamic belief change: the objects of agent\nbelief include not only external truths but also the beliefs\nthemselves, and part or all of these can change. In a motto, dynamic\nbelief change involves \u201cchanging beliefs about a\nchanging situation that itself includes these very\nbeliefs\u201d. \n\n\nTo better explain and illustrate the difference, let us consider the\nresult of a belief change brought about by the Moore formula \n\n\\[\\begin{equation*}\\taglabel{MF}\np\\land\\lnot[a]p,\n\\end{equation*}\\]\n\n\ninformally read, \u201cp is true but agent a does not\nbelieve it\u201d. Let us suppose that this formula is true; that is,\np is true and, indeed, agent a does not believe that\np is true. Now suppose that agent a receives the formula\n\\eqref{MF} from a completely trustworthy source and is supposed to\nchange her beliefs to take into account the information this formula\nprovides. In a dynamic belief change, she will accept the formula\n\\eqref{MF} and hence, in particular, she will come to believe that\np is true. But then the formula \\eqref{MF} becomes false: she\nnow believes p and therefore the formula \\(\\lnot[a]p\\)\n(\u201cagent a does not believe p\u201d) is false. So\nwe see that this belief change is indeed dynamic: in revising her\nbeliefs based on the incoming true formula \\eqref{MF}, the truth of\nthe formula \\eqref{MF} was itself changed. That is, the\n\u201csituation\u201d, which involves the truth of p and the\nagent\u2019s beliefs about this truth, changed as per the belief\nchange brought about by the agent learning that \\eqref{MF} is true.\n(As an aside, this example shows that for dynamic belief\nchange, the AGM Success postulate is violated and so must be dropped.)\n\n\nPerhaps surprisingly, it is also possible to undergo a static\nbelief change upon receipt of the true formula \\eqref{MF} from a\ncompletely trustworthy source. For this to happen, we must think of\nthe \u201csituation\u201d with regard to the truth of p and\nthe agent\u2019s beliefs about this truth as completely static, like\na \u201csnapshot in time\u201d. We then look at how the\nagent\u2019s beliefs about that static snapshot might change upon\nreceipt of the completely trustworthy information that \\eqref{MF} was\ntrue in the moment of that snapshot. To make sense of this, it might\nbe helpful to think of it this way: the agent learns something in\nthe present about what was true of her situation in the\npast. So her present views about her past beliefs change, but the\npast beliefs remain fixed. It is as though the agent studies a\nphotograph of herself from the past: her \u201cpresent self\u201d\nchanges her beliefs about that \u201cpast self\u201d pictured in the\nphotograph, fixed forever in time. In a certain respect, the\n\u201cpast self\u201d might as well be a different person: \n\n\nNow that I have been told \\eqref{MF} is true at the moment pictured in\nthe photograph, what can I say about the situation in the picture and\nabout the person in that situation? \n\n\nSo to perform a static belief change upon receipt of the\nincoming formula F, the agent is to change her present belief\nbased on the information that F was true in the state of\naffairs that existed before she was told about F.\nAccordingly, in performing a static belief change upon receipt of\n\\eqref{MF}, the agent will come to accept that, just before she was\ntold \\eqref{MF}, the letter p was true but she did not believe\nthat p was true. But most importantly, this will not cause her\nto believe that \\eqref{MF} is true afterward: she is only\nchanging her beliefs about what was true in the past; she has\nnot been provided with information that bears on the present. In\nparticular, while she will change her belief about the truth of\np in the moment that existed just before she was informed of\n\\eqref{MF}, she will leave her present belief about p as it is\n(i.e., she still will not know that p is true). Therefore, upon\nstatic belief revision by \\eqref{MF}, it is still the case that\n\\eqref{MF} is true! (As an aside, this shows that for static\nbelief change, the AGM Success postulate is satisfied.) \n\nStatic belief change occurs in everyday life when we receive\ninformation about something that can quickly change, so that the\ninformation can become \u201cstale\u201d (i.e., incorrect) just\nafter we receive it. This happens, for example, with our knowledge of\nthe price of a high-volume, high-volatility stock during trading\nhours: if we check the price and then look away for the rest of the\nday, we only know the price at the given moment in the past and cannot\nguarantee that the price remains the same, even right after we checked\nit. Therefore, we only know the price of the stock in the\npast\u2014not in the present\u2014even though for practical reasons\nwe sometimes operate under the fiction that the price remains constant\nafter we checked it and therefore speak as though we know it (even\nthough we really do not). \n\nDynamic belief change is more common in everyday life. It happens\nwhenever we receive information whose truth cannot rapidly become\n\u201cstale\u201d: we are given the information and this information\nbears directly on our present situation. \n\nWe note that the distinction between static and dynamic belief change\nmay raise a dilemma that bears on the problem of skepticism in\nEpistemology (see, e.g., entry on\n Epistemology):\n our \u201cdynamic belief change skeptic\u201d might claim that\nall belief changes must be static because we cannot really\nknow that then information we have received has not become stale. To\nthe authors\u2019 knowledge, this topic has not yet been explored.\n\n4.3 Plausibility models and belief change\n\nIn the DEL study of belief change, situations involving the beliefs of\nmultiple agents are represented using a variation of basic Kripke\nmodels called plausibility models. Static belief change is\ninterpreted as conditionalization in these models: without changing\nthe model (i.e., the situation), we see what the agent would believe\nconditional on the incoming information. This will be explained in\ndetail in a moment. Dynamic belief change involves transforming\nplausibility models: after introducing plausibility model-compatible\naction models, we use model operators defined from these\n\u201cplausibility action models\u201d to describe changes in the\nplausibility model (i.e., the situation) itself. \n\nOur presentation of the DEL approach to belief change will follow\nBaltag and Smets (2008b), so all theorems and definitions in the\nremainder of Section 4 are due to them unless otherwise noted. Their\nwork is closely linked with the work of van Benthem (2007), Board\n(2004), Grove (1988), and others. For an alternative approach based on\nPropositional Dynamic Logic, we refer the reader to van Eijck and Wang\n(2008). \n\nPlausibility models are used to represent more nuanced versions of\nknowledge and belief. These models are also used to reason about\nstatic belief changes. The idea behind plausibility models is\nsimilar to that for our basic Kripke models: each agent considers\nvarious worlds as possible candidates for the actual one. However,\nthere is a key difference: among any two worlds w and v\nthat an agent a considers possible, she imposes a relative\nplausibility order. The plausibility order for agent a\nis denoted by \\(\\geq_a\\). We write \n\n\\(w\\geq_a v\\) to mean that \u201cworld w is no more plausible\nthan world v according to agent a\u201d.\n\n\nNote that if we think of \\(\\geq_a\\) as a \u201cgreater than or equal\nto\u201d sign, it is the \u201csmaller\u201d world that is either\nmore plausible or else of equal plausibility. The reason for\nordering things in this way comes from an idea due to Grove (1988): we\nthink of each world as positioned on the surface of exactly one of a\nseries of concentric spheres (of non-equal radii), with a more\nplausible world located on a sphere of smaller radius and a less\nplausible world located on a sphere of greater radius. Consider the\nfollowing illustration: \n\n\n\n\nIn this diagram, the black concentric circles indicate spheres, the\nblue points on the smallest (i.e., innermost) sphere are the most\nplausible worlds overall, the red points on the second-smallest (i.e.,\nmiddle) sphere are the second-most plausible worlds, and the green\npoints on the largest sphere are the least plausible worlds overall.\n\n\nWe write \\(\\leq_a\\) (\u201cno less plausible than\u201d) for the\nconverse plausibility relation: \\(w\\leq_a v\\) means that\n\\(v\\geq_a w\\). Also, we define the strict plausibility\nrelation \\(\\gt_a\\) (\u201cstrictly more plausible than\u201d)\nin the usual way: \\(w\\gt_a v\\) means that we have \\(w\\geq_a v\\) and\n\\(v\\ngeq_a w\\). (A slash through the relation means the relation does\nnot hold.) The strict converse plausibility relation\n\\(\\lt_a\\) (\u201cstrictly less plausible than\u201d) is defined as\nexpected: \\(w\\lt_a v\\) means that \\(v\\gt_a w\\). Finally, we define the\nequi-plausibility relation \\(\\simeq_a\\) (\u201cequally\nplausible\u201d) as follows: \\(w\\simeq_a v\\) means that we have\n\\(w\\geq_a v\\) and \\(v\\geq_a w\\). \n\nWe draw plausibility models much like our basic Kripke models from\nbefore except that we use dashed arrows (instead of solid ones) in\norder to indicate the plausibility relations and also to indicate that\nthe picture in question is one of a plausibility model. We adopt the\nfollowing conventions for drawing plausibility models. \n\n One-way arrows indicate non-increasing plausibility:\n\n\n\n indicates \\(v\\geq_aw\\) for each \\(a\\in\\{a_0,\\dots,a_n\\}\\) \n Two-way arrows are a shorthand for two one-way arrows, one in\neach direction: letting \\(\\sigma\\) denote a comma-separated list of\nagents in \\(\\sA\\),\n\n\n\n\n\n\nindicates\n\n\n\n\n \n Reflexive arrows are implied (so that \\(\\geq_a\\) is reflexive for\neach \\(a\\in\\sA\\)):\n\n\n\n\n\n\nindicates\n\n\n\n\n \n Transitive arrows are implied (so that \\(\\geq_a\\) is transitive\nfor each \\(a\\in\\sA\\)):\n\n\n\n indicates\n\n\n\n The transitive arrow rule and the two-way arrow rule may\ninteract: if one or both of the arrows \\(u\\dashrightarrow_a v\\) or\n\\(v\\dashrightarrow_a w\\) were two-way, then we would still obtain the\nimplied transitive arrow \\(u\\dashrightarrow_a w\\). \n\n\nAn absence of a drawn or implied a-arrow from v to\nw indicates \\(v\\not\\geq_a w\\): \n\n\n\n\n\nindicates \\(v\\not\\geq_a w\\)\n\n\n\nThe picture above indicates there is no a-arrow from v\nto w that is either drawn or implied. So we conclude that\n\\(v\\not\\geq_a w\\) only after we have taken into account all drawn and\nimplied a-arrows and determined that no a-arrow from\nv to w is indicated.  \n The picture must specify a relation \\(\\geq_a\\) that is locally connected: defining for each world w the connected component \\[ \\cc_a(w) \\coloneqq \\{ v\\in W \\mid w({\\geq_a}\\cup{\\leq_a})^*v\\} \\] of w, we have that \\(v\\in\\cc_a(w)\\) implies \\(w\\geq_a v\\) or \\(v\\geq_a w\\). \n\n To explain\nthe meaning of this property, we first explain the definition of the\nconnected component \\(\\cc_a(w)\\). This set is based on the union\nrelation \\({\\geq_a}\\cup{\\leq_a}\\), which relates two worlds if and\nonly if they are related according to \\(\\geq_a\\) or \\(\\leq_a\\); that\nis, we have \\(w({\\geq_a}\\cup{\\leq_a})v\\) if and only if \\(w\\geq_a v\\)\nor \\(w\\leq_a v\\). We then take the union relation and apply the\noperator \\((-)^*\\), which forms the reflexive-transitive\nclosure \\(R^*\\) of a relation R: the relation \\(R^*\\)\nrelates two worlds if and only if they are the same or there exists a\nsequence of intermediate worlds that are stepwise connected by the\nunderlying relation R. Therefore, we have\n\\(w({\\geq_a}\\cup{\\leq_a})^*v\\) if and only if \\(w=v\\) or there exists\na sequence \\(u_1,\\dots,u_n\\) of worlds such that \n\n\\[\nw({\\geq_a}\\cup{\\leq_a})u_1\n({\\geq_a}\\cup{\\leq_a})\\cdots\n({\\geq_a}\\cup{\\leq_a})u_n({\\geq_a}\\cup{\\leq_a})v.\n\\]\n\n So,\ntaken together, we have \\(v\\in\\cc_a(w)\\) if and only if \\(v=w\\) or\nthere is a sequence \\(u_1,\\dots,u_n\\) of worlds connecting v to\nw stepwise in terms of plausibility (without regard to whether\nthe relative plausibility is increasing, decreasing, or remaining the\nsame). In terms of our pictures of plausibility models, we have\n\\(v\\in\\cc_a(w)\\) if and only if, after taking into account all drawn\nand implied a-arrows and disregarding arrow directionality,\nv and w are the same or are linked by a sequence of\na-arrows (in which each arrow can be followed both forward and\nbackward). The property of local connectedness then tells us that if\n\\(v\\in\\cc_a(w)\\), then we must have \\(w\\geq_a v\\) or \\(v\\geq_a w\\).\nThat is, if there is an undirected a-arrow path from w\nto v, then there is an a-arrow directly linking w\nand v in one direction or the other. Therefore, if we think of\n\\(\\cc_a(w)\\) as the set of worlds that the agent a considers to\nbe possible whenever w is the actual world, local connectedness\ntells us that agent a must always have an opinion as to the\nrelative plausibility between any two worlds that she considers to be\npossible. It is in this sense that each agent must be\n\u201copinionated\u201c as to the relative plausibility of worlds\nshe considers possible. As an example, the property of local\nconnectivity disallows the following picture:\n\n\n\n This picture is disallowed because because it violates local\nconnectivity for \\(\\geq_a\\): we have \\(v\\in\\cc_a(w)\\) and yet neither\n\\(v\\geq_a w\\) nor \\(w\\geq_a v\\). In detail: we have \\(v\\in\\cc_a(w)\\)\nbecause we have the undirected a-arrow path \\(w\\dashleftarrow_a\nu\\dashrightarrow_a v\\) from w to v; and we have neither\n\\(y\\geq_a z\\) nor \\(z\\geq_a y\\) because, after adding all implied\narrows (in this case only reflexive arrows must be added), we find\nthat we have neither \\(v\\dashrightarrow_a w\\) nor \\(v\\dashleftarrow_a\nw\\). \n\n\nWorlds in the same connected component are said to be\ninformationally equivalent. \n\n\nInformational equivalence. Worlds v and\nw are said to be informationally equivalent (for agent\na) if and only if \\(\\cc_a(w)=\\cc_a(v)\\). Notice that we\nhave \\(\\cc_a(w)=\\cc_a(v)\\) if and only if \\(v\\in\\cc_a(w)\\) if and only\nif \\(w\\in\\cc_a(v)\\).\n\n\nThe idea is that if w is the actual world, then agent a\nhas the information that the actual world must be one of those in her\nconnected component \\(\\cc_a(w)\\). Thus the set \\(\\cc_a(w)\\) makes up\nthe worlds agent a considers to be possible whenever w\nis the actual world. And since \\(w\\in\\cc_a(w)\\), agent a will\nalways consider the actual world to be possible. Local connectivity\nthen guarantees that the agent always has an opinion as to the\nrelative plausibility of any two worlds among those in \\(\\cc_a(w)\\)\nthat she considers possible. \n\nOne consequence of local connectivity is that informationally\nequivalent states can be stratified according to Grove's idea (Grove\n1988) of concentric spheres: the most plausible worlds overall are\npositioned on the innermost sphere, the next-most-plausible worlds are\npositioned on the next-most-larger sphere, and so on, all the way out\nto the positioning of the least-most-plausible worlds on the largest\nsphere overall. (The number of worlds in our pictures of plausibility\nmodels will always be finite\u2014otherwise we could not draw them\naccording to our above-specified conventions\u2014so it is always\npossible to organize the worlds in our pictures into concentric\nspheres in this way.) \n\nGrove spheres (Grove 1988) also suggest a natural method for static\nbelief revision in plausibility models: if the agent is told by a\ncompletely trustworthy source that the actual world is among some\nnonempty subset \\(S\\subseteq \\cc_a(w)\\) of her informationally\nequivalent worlds, then she will restrict her attention to the worlds\nin S. The most plausible worlds in S will be the worlds\nshe then considers to be most plausible overall, the\nnext-most-plausible worlds in S will be the worlds she then\nconsiders to be next-most-plausible overall, and so on. That is, she\nwill \u201creposition\u201d her system of spheres around the set\nS. \n\nTo see how all of this works, let us consider a simple example\nscenario in which our two agents a and b are discussing\nthe truth of two statements p and q. In the course of\nthe conversation, it becomes common knowledge that neither agent has\nany information about q and hence neither knows whether\nq is true, though, as it turns out, q happens to be\ntrue. However, it is common knowledge that agent b is an expert\nabout an area of study whose body of work encompasses the question of\nwhether p is true. Further, agent b publicly delivers\nhis expert opinion: p is true. Agent a trusts agent\nb\u2019s expertise and so she (agent a) comes to\nbelieve that p is true. But her trust is not absolute: a\nstill maintains the possibility that agent b is wrong or\ndeceitful; hence she is willing to concede that her belief of p\nis incorrect. Nevertheless, she does trust b for now and comes\nto believe p. Unfortunately, her trust is misplaced: agent\nb has knowingly lied; p is actually false. We picture\nthis scenario in Figure 8. \n\n\n\nN\n\n\nFigure 8: The pointed plausibility model\n\\((N,w_1)\\). \n\n\nIt is easy to see that the pointed plausibility model \\((N,w_1)\\)\nclearly satisfies the property of local connectedness, so this is an\nallowable picture. To see that this picture reasonably represents the\nabove-describe example scenario, first notice that we have one world\nfor each of the four possible truth assignments to the two letters\np and q. At the actual world \\(w_1\\), the letter\np is false and the letter q is true. Agent a\nconsiders each of the four worlds to be informationally equivalent\n(since she does not know with certainty which world is the actual\none); however, she considers the p-worlds to be strictly more\nplausible than the \\(\\lnot p\\)-worlds. This represents her belief that\np is true: each of the worlds she considers to be most\nplausible overall satisfies p. Further, if she is told that\np is in fact false, she will restrict her attention to the\nnext-most-plausible \\(\\lnot p\\)-worlds, thereby statically revising\nher belief. It is in this sense that she trusts b (and so\nbelieves p is true) but does not completely rule out the\npossibility that he is incorrect or deceptive. Since a has no\ninformation about q, each of her spheres\u2014the inner\np-sphere and the outer \\(\\lnot p\\)-sphere\u2014contains both a\nworld at which q is true and a world at which q is\nfalse. \n\nNow let us look at the attitudes of agent b. First, we see that\nb has two connected components, one consisting of the\np-worlds and the other consisting of the \\(\\lnot p\\)-worlds,\nand these two components are not informationally equivalent. That is,\nno p-world is informationally equivalent to a \\(\\lnot p\\)-world\nin the eyes of agent b. This tells us that b\nconclusively knows whether p is true. Further, a knows\nthis is so (since each of a\u2019s informationally equivalent\nworlds is one in which b knows whether p is true). Since\nthe actual world is a \\(\\lnot p\\)-world, agent b in fact knows\np is false. Finally, we see that b knows that a\nmistakenly believes that p is true: at each of b\u2019s\ninformationally equivalent worlds \\(w_1\\) and \\(w_2\\), agent a\nbelieves that p is true (since a\u2019s most plausible\nworlds overall, \\(w_3\\) and \\(w_4\\), both satisfy p). \n\nWe are now ready for the formal definition of plausibility models.\nThis definition summarizes what we have seen so far. \n\n\nPlausibility model. Given a nonempty set \\(\\sP\\) of\npropositional letters and a finite nonempty set \\(\\sA\\) of agents, a\nplausibility model is a structure \n\n\\[\nM=(W,\\geq,V)\n\\]\n\n consisting\nof\n\n a nonempty set W of worlds identifying the\npossible states of affairs that might obtain, \na function \\(\\geq\\) that assigns to each agent \\(a\\in\\sA\\) a\nbinary relation \\(\\geq_a\\) on W satisfying the property of\nPlausibility that we define shortly, and \na propositional valuation V mapping each\npropositional letter to the set of worlds at which that letter is\ntrue. \n We define the following relations, with a negation of a relation\nindicated by placing a slash through the relational symbol:\n\n\n Converse plausibility: \\(w\\leq_a v\\) means we have\n\\(v\\geq_a w\\). \nStrict plausibility: \\(w\\gt_a v\\) means we have \\(w\\geq_a\nv\\) and \\(v\\not\\geq_a w\\). \nStrict converse plausibility: \\(w\\lt_a v\\) means we have\n\\(v\\geq_a w\\) and \\(w\\not\\geq_a v\\). \nEqui-plausibility: \\(w\\simeq_a v\\) means we have\n\\(w\\geq_a v\\) and \\(v\\geq_a w\\). \n\n\nFor each world w in W and agent a, we define the\nconnected component of w, also called the\na-connected component if emphasizing a is\nimportant, as follows: \n\n\\[\n\\cc_a(w) \\coloneqq \\{ v\\in W \\mid w({\\geq_a}\\cup{\\leq_a})^*v\\} .\n\\]\n\n If \\(\\cc_a(w)=\\cc_a(w)\\), then we\nsay that w and v are informationally equivalent\n(or that they are a-informationally equivalent). The\nrelation \\(\\geq_a\\) must satisfy the property of\nPlausibility, which consists of the following three\nitems:\n\n \\(\\geq_a\\) is reflexive and transitive; \n\\(\\geq_a\\) is locally connected: \\(v\\in\\cc_a(w)\\) implies\n\\(w\\geq_a v\\) or \\(v\\geq_a w\\); and \n\\(\\geq_a\\) is converse well-founded: for each nonempty set \\(S\\subseteq W\\) of worlds, the set \\[ \\textstyle \\min_a(S)\\coloneqq\\{w\\in S\\mid \\forall v\\in S:v\\not\\lt_a w\\} \\] of a-minimal elements of S is itself nonempty.  \n\n\nA pointed plausibility model, sometimes called a\nscenario or a situation, is a pair \\((M,w)\\)\nconsisting of a plausibility model M and a world w\n(called the point) that designates the state of affairs that\nwe (the formal modelers) currently assume to be actual. \n\n\nIntuitively, \\(w \\geq_a v\\) means that w is no more plausible\nthan v according to agent a. Therefore, it is the\n\u201csmaller\u201d worlds that are more plausible, so that\n\\(\\min_a(\\cc_w(w))\\) is the set of worlds that agent a\nconsiders to be most plausible of all worlds that are\ninformationally equivalent with w. \n Local connectivity, as we have seen, ensures that the agent has an opinion as to the relative plausibility of informationally equivalent worlds. Converse well-foundedness guarantees that the agent can always stratify informationally equivalent worlds in such a way that some worlds are the most plausible overall. As a result, we cannot have a situation where agent a has some sequence \\[ w_1\\gt_a w_2\\gt_a w_3 \\gt_a \\cdots \\] of worlds of strictly increasing plausibility, a circumstance in which it would be impossible to find \u201cthe most plausible worlds\u201d. By forbidding such a circumstance, converse well-foundedness guarantees that the notion of \u201cthe most plausible worlds\u201d is always well-defined.  \n\nThe collection of formulas interpreted on pointed plausibility models\ngenerally contains at least the formulas coming from the language\n\\eqref{KBox} defined by the following grammar:  \n\n\\[\\begin{gather*}\nF \\ccoloneqq p \\mid F \\wedge F \\mid \\neg F \\mid K_aF \\mid \\Box_a F \\\\\n\\small p \\in \\sP,\\; a \\in \\sA\n\\tag{\\(K\\Box\\)}\\label{KBox}\n\\end{gather*}\\]\n\n\nThe satisfaction relation \\(\\models\\) between pointed plausibility\nmodels and formulas of \\eqref{KBox} is defined as follows. \n\n\\(M,w\\models p\\) holds if and only if \\(w\\in V(p)\\).\n\\(M,w\\models F\\land G\\) holds if and only if both \\(M,w\\models F\\)\nand \\(M,w\\models G\\).\n\\(M,w\\models\\lnot F\\) holds if and only if \\(M,w\\not\\models\nF\\).\n\\(M,w\\models K_aF\\) holds if and only if \\(M,v\\models F\\) for each\n\\(v\\in\\cc_a(w)\\).\n\\(M,w\\models \\Box_aF\\) holds if and only if \\(M,v\\models F\\) for\neach \\(v\\leq_a w\\).\n\n\nFor each \\eqref{KBox}-formula F and plausibility model \\(M =\n(W, \\geq, V)\\), we define the set  \n\n\\[\n\\sem{F}_M \\coloneqq \\{ w\\in W\\mid M,w\\models F\\}\n\\]\n\n\nof worlds at which F is true. If M is fixed, we may\nsimply write \\(\\sem{F}\\) without the subscript M. \n\n\\(K_aF\\) is assigned the reading \u201cagent a has information\nthat F is true\u201d. One may consider \\(K_a\\) as a kind of\nknowledge, though not the kind usually possessed by actual, real-life\nagents (because it satisfies properties such as closure under logical\nconsequence that are typically not satisfied in practice).\nIntuitively, possession of information of F is belief in\nF that persists upon receipt of any further\ninformation, even information that is not true. This kind of\nknowledge is therefore infallible and indefeasible. \n\nWe assign \\(\\Box_aF\\) the reading \u201cagent a defeasibly\nknows F\u201d. This is a weak notion of knowledge studied by\nLehrer and Paxson (1969) and by Lehrer (1990, 2000) and formalized by\nStalnaker (1980, 2006). Intuitively, defeasible knowledge of F\nis belief in F that persists upon receipt of any further true\ninformation: the agent believes F and, if told any further\ntrue information, she will continue to believe F.\nDefeasible knowledge is sometimes also called \u201csafe\nbelief\u201d. \n\nThe dual form of information possession \\(K_aF\\), written \\(\\hat K_a\nF\\), denotes informational consistency:  \n\n\\[\n\\hat K_a F \\mbox{ denotes } \\lnot K_a\\lnot F.\n\\]\n\n\nwhich has the meaning that F is consistent with agent\na\u2019s information. We use this to define a notion of\nconditional belief:  \n\n\\[\nB_a^GF \\mbox{ denotes } \\hat K_aG \\to \\hat K_a(G\\land\\Box_a(G\\to F)).\n\\]\n\n\nwhich is assigned the reading \u201cagent a believes F\nconditional on G\u201d. Sometimes \\(B_a^GF\\) is abbreviated by\n\\(B_a(F|G)\\). Though the meaning of \\(B_a^GF\\) can be derived from the\nabove definitions, the following provides a more intuitive\ninterpretation. \n\n\nTheorem. For each pointed plausibility model\n\\((M,w)\\), we have: \n\n \\[ \\textstyle M,w\\models B_a^GF \\quad\\text{iff}\\quad \\min_a(\\sem{G}_M\\cap\\cc_a(w))\\subseteq\\sem{F}_M ; \\] \n\n that is, agent a believes\nF conditional on G at world w if and only if\nF is true at the most plausible G-worlds that are\nconsistent with a\u2019s information. \n\n\nThis theorem tell us that to see what an agent believes conditional on\nG, all we need to do is look at the agent\u2019s most\nplausible G-worlds. In this way, conditional belief has the\nagent \u201crecenter\u201d her system of spheres over the set of all\nworlds at which G is true. Conditional belief thereby\nimplements static belief revision: to see what agent a believes\nafter statically revising her beliefs by G we simply see what\nit is she believes conditional on G. Thus \\(B_a^GF\\) says that\nagent a believes F after statically revising her beliefs\nby G. \n\nThe notion of conditional belief allows us to connect the notions\nknowledge possession \\(K_a\\) and defeasible knowledge \\(\\Box_a\\) with\nthe defeasibility analysis of knowledge, as indicated by the following\nresult. \n\n\nTheorem. For each pointed plausibility model\n\\((M,w)\\), we have each of the following.\n\n \\(M,w\\models K_aF\\) if and only if for each \\eqref{KBox}-formula\nG, we have \\(M,w\\models B_a^GF\\).\n\n\u201cInformation possession \\(K_a\\) is belief that persists under\nreceipt of any information.\u201d \n \\(M,w\\models\\Box_aF\\) if and only if for each\n\\eqref{KBox}-formula G satisfying \\(M,w\\models G\\), we have\n\\(M,w\\models B_a^GF\\).\n\n\u201cDefeasible knowledge \\(\\Box_a\\) is belief that persists under\nreceipt of true information.\u201d \n\n\n\nConditional belief gives rise to a notion of unconditional\nbelief obtained by taking the trivial condition \\(\\top\\) (i.e.,\nthe propositional constant for truth) as the condition: \n\n\\[\nB_aF    \\mbox{ denotes } B_a^\\top F .\n\\]\n\n\nSo to see what the agent believes unconditionally, we simply\nconditionalize her beliefs on the trivial condition \\(\\top\\), which is\ntrue everywhere. It is then easy to see that we have the following.\n\n\n\nTheorem. For each pointed plausibility model\n\\((M,w)\\), we have: \n\n\\[\n\\textstyle\nM,w\\models B_aF \\quad\\text{iff}\\quad \\min_a(\\cc_a(w))\\subseteq\\sem{F}_M;\n\\]\n\n that is, agent a believes\nF (unconditionally) at world w if and only if F\nis true at the most plausible worlds that are consistent with\na\u2019s information. \n\n\nWe conclude this section with the axiomatic theory characterizing\nthose formulas that are valid in all plausibility models. Since we can\nexpress conditional belief (and since conditional belief describes\nstatic belief revision), what we obtain is a theory of defeasible\nknowledge, possession of information, conditional belief,\nunconditional belief, and static belief revision. \n\n\nThe axiomatic theory \\(\\KBox\\).\n\n The \\(\\mathsf{S5}\\) axiom schemes and rules for \\(K_a\\) for each\n\\(a\\in\\sA\\) \n The \\(\\mathsf{S4}\\) axiom schemes and rules for \\(\\Box_a\\) for\neach \\(a\\in\\sA\\) \n\\(K_aF\\to\\Box_a F\\)\n\n\u201cIf F follows from a\u2019s information, then\na defeasibly knows F.\u201d \n\\(K_a(\\Box_a F\\to G)\\lor K_a(\\Box_a G\\to F)\\)\n\n\u201cWorlds consistent with the information received are always\ncomparable in terms of plausibility.\u201d (That this axiom has this\nmeaning requires some technical details; see Baltag et al. (2014). In\nparticular, the axiom may be viewed as a slight modification of the .3\nscheme from basic modal logic; see, e.g., Blackburn et al. 2002).\n\n\n\n\n\n\\(\\KBox\\) Soundness and Completeness. \\(\\KBox\\) is\nsound and complete with respect to the collection \\(\\sC_*\\) of pointed\nplausibility models. That is, for each \\eqref{KBox}-formula F,\nwe have that \\(\\KBox\\vdash F\\) if and only if \\(\\sC_*\\models F\\).\n\n\nInstead of taking information possession \\(K_a\\) and defeasible\nknowledge \\(\\Box_a\\) as the basic propositional attitudes, one may\ninstead choose conditional belief statements \\(B_a^GF\\). This choice\ngives the theory \\(\\CDL\\) of Conditional Doxastic Logic. See\n Appendix J\n for details. \n\nWe may define a number of additional propositional attitudes beyond\nconditional belief \\(B_a^GF\\), defeasible knowledge \\(\\Box_aF\\), and\ninformation possession \\(K_aF\\). We take a brief look at a two of\nthese that have important connections with the Belief Revision\nliterature. \n\n The unary revision operator \\(*_aF\\) has the semantics:\n\n\t  \\[M,w\\models *_aF\n\t      \\mbox{ means }\n\t  M,w\\models F \\mbox{ and } M,v\\not\\models F\n\t  \\mbox{ for all } v\\lt_a w\\]\n\n That is, to say that \\(*_aF\\) is true at world w\nmeans that F is true at w and that F is false at\nany world v that agent a ranks strictly more plausible.\nSo to have \\(*_aF\\) true at w says that w will be among\nthe most plausible after the agent undergoes a belief revision by\nF. The unary revision operator \\(*_aF\\) therefore picks out the\nworlds that will make up agent a\u2019s theory of beliefs\nafter revision by F. As such, we have \n\n\t  \\[\nM,w\\models B_a^FG \t      \\quad\\text{ iff }    \t  M,w\\models K_a(*_aF\\to G),\n\\]\n\n which says\nthat agent a believes G after revision by F if\nand only if she knows that G is a consequence of her theory\nafter revision by F.\n\n\n\n For each natural number n, we have a\ndegree-n belief operator \\(B_a^nF\\). To define the\nsemantics of these operators, we first define formulas \\(b_a^n\\) for\neach natural number n according to the following: \n\n\t\\[\\begin{align*}\n\tb_a^0 &= *_a\\top, \\\\\n\tb_a^{n+1} &=\n\t*_a(\\lnot b_a^0\\land \\lnot b_a^1\\land\\cdots\\land\\lnot b_a^n) .\n\t\\end{align*}\\]\n\n\\(b_a^0\\) is true at the worlds the agent a ranks most\nplausible overall, \\(b_a^1\\) is true at the worlds the agent a\nranks next-most plausible after the \\(b_a^0\\)-worlds, \\(b_a^2\\) is\npicks out the next-most plausible after the \\(b_a^1\\)-worlds, and so\non. The \\(b_a^n\\)-worlds thereby pick out agent a\u2019s\n\u201cdegree-n theory of belief\u201d, which is the\ncollection of beliefs the agent will hold after giving up all theories\nof lesser degree. This setup allows us to realize Spohn's (1988)\nnotion of \u201cdegrees of belief\u201d: \n\n\t  \\[\nM,w\\models B_a^nF\n\t      \\mbox{ means }    M,w\\models K_a(b_a^n\\to F)\\land \\bigwedge_{i\\lt n}\\lnot\t  K_a(b_a^i\\to F),\n\\]\n\n which says\nthat agent a believes F to degree n if and only\nif she knows it follows from her degree-n theory and she does\nnot know it to follow from any of her theories of lesser degree. \n\n4.4 The Logic of Doxastic Actions: Action-priority update\n\nThe theories and operators we have seen so far all concern\nstatic belief change. We now wish to turn to dynamic\nbelief change. For this the approach follows the typical pattern in\nDynamic Epistemic Logic: we take a given static theory (in this case\n\\(\\KBox\\)) and we add action model-style modalities to create the\ndynamic theory. When we did this before in the case of basic\nmulti-modal epistemic and doxastic logic, the relational structure of\nthe added action models matched the relational structure of the models\nof the theory\u2014Kripke models. The structural match between action\nmodels and finite Kripke models is not accidental: the semantics of\naction model modalities (as explained by the\n BMS product update)\n uses the same Kripke model-based notion of agent uncertainty over\nobjects (i.e., the \u201cworlds\u201d) to describe agent uncertainty\nover action model objects (i.e., the \u201cevents\u201d). Both\nuncertainties are represented using the same kind of structure: the\nbinary possibility relation \\(R_a\\). \n\nFor the present theory of conditional belief \\(B_a^FG\\), defeasible\nknowledge \\(\\Box_aF\\), and information possession \\(K_aF\\), we take a\nsimilar approach: we define plausibility action models, which\nare action model-type objects whose relational structure matches the\nrelational structure of the models of this theory\u2014plausibility\nmodels. Since a finite plausibility model has the form \\((W,\\geq,V)\\),\nour intuition from the Kripke model case suggests that plausibility\naction models should have the form \\((E,\\geq,\\pre)\\), with E a\nfinite nonempty set of events, \\(\\geq\\) a function giving a\nplausibility relation \\(\\geq_a\\) for each agent a, and \\(\\pre\\)\na precondition function as before. \n\n\nPlausibility action model. Given a set of formulas\n\\(\\Lang\\) and a finite nonempty set \\(\\sA\\) of agents, a\nplausibility action model is a structure \n\n\\[ A=(E,\\geq,\\pre) \\]\n\nconsisting of\n\n a nonempty finite set E of the possible communicative\nevents that might occur, \na function \\(\\geq\\) that assigns to each agent \\(a\\in\\sA\\) a\nbinary relation \\(\\geq_a\\) on E satisfying the property of\nPlausibility defined earlier, and \na function \\(\\pre:E\\to\\Lang\\) that assigns to each event e\nin E a formula \\(\\pre(e)\\in\\Lang\\) called the\nprecondition of e. Intuitively, the precondition is\nannounced when the event occurs. \n\n\nA pointed plausibility action model, sometimes also called an\naction, is a pair \\((A,e)\\) consisting of a plausibility\naction model A and an event e in A that is called\nthe point. In drawing plausibility action models, events are\ndrawn as rectangles, a point (if any) is indicated with a double\nrectangle, and arrows are drawn using dashes (as for plausibility\nmodels). We use many of the same drawing and terminological\nconventions for plausibility action models that we use for (pointed)\nplausibility models.\n\n\nAs expected, the main difference between plausibility action models\nand basic action models is that the agent-specific component (i.e.,\nthe function \\(\\geq\\) giving the agent-specific relation \\(\\geq_a\\)).\nIn constructing new plausibility models based on plausibility action\nmodels, we may follow a construction similar to the\n product update.\n To make this work, our main task is to describe how the plausibility\nrelation \\(\\geq_a\\) in the resultant plausibility model \\(M[A]\\) is to\nbe determined in terms of the plausibility relations coming from the\ngiven initial plausibility model M and the plausibility action\nmodel A. For this it will be helpful to consider an example.\n\n\n\n\n\\(\\rPub_G(q)\\)\n\n\nFigure 9: The pointed plausibility\naction model \\((\\rPub(q),e)\\) for the revisable public announcement of\nq (also called the \u201clexicographic upgrade by\nq\u201d by van Benthem 2007). \n\n\nFigure 9 depicts \\((\\rPub(q),e)\\), a pointed plausibility action model\nconsisting of two events: the event f in which \\(\\lnot q\\) is\nannounced and the event e in which q is announced. Event\ne is the event that actually occurs. For each agent a\n(coming from the full set of agents \\(\\sA\\)), event e is\nstrictly more plausible. We adopt the\n same drawing conventions\n for plausibility action models that we did for plausibility models:\none- and two-way arrows, reflexive and transitive closures, and the\nrequirement of local connectedness. (Well-foundedness follows because\nthe set E of events is finite.) Accordingly, Figure 9\nimplicitly contains reflexive dashed arrows for each agent at each\nevent. \n\n\\((\\rPub(q),e)\\) has the following intuitive effect: the public\nannouncement of q (i.e., event e) occurs and this is\ncommon knowledge; however, the agents still maintain the possibility\nthat the negation \\(\\lnot q\\) was announced (i.e., event f\noccurred). In effect, the agents will come to believe q\n(because the announcement of this was most plausible), but they will\nnevertheless maintain the less plausible possibility that q is\nfalse. This allows the agents to accept the announced formula q\nbut with some caution: they can still revise their beliefs if they\nlater learn that q is false. \n\nThe \u201caction-priority update\u201d is the analog of the product\nupdate for plausibility models. \n\n\nAction-priority update (Baltag and Smets 2008b). Let\n\\((M,w)\\) be a pointed plausibility model and \\((A,e)\\) be a pointed\nplausibility action model. Let \\(\\models\\) be a binary satisfaction\nrelation defined between \\((M,w)\\) and formulas in the language\n\\(\\Lang\\) of the precondition function \\(\\pre^A:E^A\\to\\Lang\\) of the\nplausibility action model A. If \\(M,w\\models\\pre^A(e)\\), then\nthe plausibility model \n\n\\[ M[A]=(W[A],{\\geq}[A],V[A]) \\]\n\n is defined via the\naction-priority update operation \\(M\\mapsto M[A]\\) given as\nfollows:\n\n \\(W[A] \\coloneqq \\{ (v,f)\\in W\\times E \\mid M,v\\models\\pre^A(f)\n\\}\\) \u2014 pair worlds with events whose preconditions they satisfy;\n\n\\((v_1,f_1)\\mathrel{{\\geq}[A]_a}(v_2,f_2)\\) if and only if we have\none of the following:\n\n\n \\(f_1\\gt_a f_2\\) and \\(\\cc_a(v_1)=\\cc_a(v_2)\\) \u2014 events of\nstrictly differing plausibility are applied to informationally\nequivalent worlds, or \n \\(f_1\\simeq_a f_2\\) and \\(v_1\\geq_a v_2\\) \u2014 equi-plausible\nevents are applied to informationally equivalent worlds of differing\nplausibility; \n \n\\(V[A]((v,f))\\coloneqq V^M(p)\\) \u2014 make the valuation of\np at the pair \\((v,f)\\) just as it was at v. \n\n\nAn action \\((A,e)\\) operates on an initial situation \\((M,w)\\)\nsatisfying \\(M,w\\models\\pre^A(e)\\) via the action-priority update to\nproduce the resultant situation \\((M[A],(w,e))\\). Note that we may\nwrite the plausibility relation \\(\\mathrel{{\\geq}[A]_a}\\) for agent\na after the action-priority update by A simply as\n\\(\\geq_a\\) when the meaning is clear from context.\n\n\nWe now turn to Action-Priority Update Logic (a.k.a., the\nLogic of Doxastic Actions). To begin, we define the language\n\\eqref{APUL} of Action-Priority Update Logic along with the set\n\\(\\PAM_*\\) of pointed plausibility action models having preconditions\nin the language \\eqref{APUL} according to the following recursive\ngrammar:  \n\n\\[\\begin{gather*}\nF  \\ccoloneqq  p \\mid F \\wedge F \\mid \\neg F \\mid K_aF \\mid \\Box_aF \\mid [A,e]F \\\\ \n\\small p \\in \\sP,\\; a \\in \\sA,\\; (A,e)\\in\\PAM_* \n\\taglabel{APUL} \n\\end{gather*} \\]\n\n\nThe satisfaction relation \\(\\models\\) between pointed plausibility\nmodels and formulas of \\eqref{APUL} is the smallest extension of the\nabove-defined satisfaction relation \\(\\models\\) for \\eqref{KBox}\nsatisfying the following: \n\n \\(M,w\\models[A,e]G\\) holds if and only if\n\\(M,w\\not\\models\\pre(e)\\) or \\(M[A],(w,e)\\models G\\), where the model\n\\(M[A]\\) is given by the action-priority update. \n\n\nIn addition to the revisable public announcement\n (Figure 9),\n there are a number of interesting pointed plausibility action models.\n\n\n\n\n\\(\\rPri_G(q)\\)\n\n\nFigure 11: The pointed plausibility\naction model \\((\\rPri_G(q),e)\\) for the private announcement of\nq to the group of agents G. \n\n\nFigure 11 depicts the private announcement of q to a group of\nagents G. This consists of two events: the event e in\nwhich q is announced and the event f in which the\npropositional constant for truth \\(\\top\\) is announced. For agents\noutside the group G, the most plausible event is the one in\nwhich the \\(\\top\\) is announced; for agents in the group, the most\nplausible event is the one in which q is announced. In reality,\nthe announcement of q (i.e., event e) occurs. Since the\npropositional constant for truth \\(\\top\\) is uninformative, the agents\noutside of G will come to believe that the situation is as it\nwas before. The agents inside G, however, will come to believe\nq. \n\nThe plausibility action model version of the private announcement\n(Figure 11) is almost identical to the action model version of the\nprivate announcement\n (Figure 3).\n This is because action models are easily converted into plausibility\naction models: simply change the arrows to dashed arrows. In this way,\nwe readily obtain plausibility action models from our existing action\nmodels. In particular, we can obtain plausibility actions for a public\nannouncement by converting\n Figure 4,\n for a semi-private announcement by converting\n Figure 5,\n and for a misleading private announcement by converting\n Figure 6.\n \n\nFinally, van Benthem (2007) studied two important operations on\nmulti-agent plausibility models that are representable using the\naction-priority update. \n\n The lexicographic upgrade \\([\\Up F]G\\) (Rott 1989; van\nBenthem 2007): after changing the plausibility relation so that\nF-worlds are ranked over \\(\\lnot F\\)-worlds but worlds within\neach of the F- and \\(\\lnot F\\)-regions are ranked as before,\nG is true. The lexicographic upgrade by F is just the\nrevisable public announcement of F\n (Figure 9):\n \n\n\t \\[M,w\\models[\\Up F]G\n\t     \\quad\\text{ iff  }\n\t M,w\\models[\\rPub(F),e]G.\\]\n\n \n The conservative upgrade \\([\\up F]G\\) (Boutilier 1993;\nvan Benthem 2007): after changing the plausibility relation so that\nthe best F-worlds are ranked over all other worlds but the\nrankings are otherwise left unchanged, G is true. We note that\nin the case where the set \\(\\sA\\) of agents consists of just the one\nagent a, we have \n\n\\[\\begin{align*}\n\t  M,w\\models[\\up F]G\\quad &\t  \\text{ iff } \t  M,w\\models[\\Up*_aF]G\t  \\\\\n\t                          &\t  \\text{ iff } \t  M,w\\models[\\rPub(*_aF),e]\n\\end{align*}\\]\n\n which says that the conservative\nupgrade by F is equal to the lexicographic upgrade by \\(*_aF\\)\nin the case of a single agent a. This makes sense: \\(*_aF\\)\npicks out the most plausible F-worlds, and then the\nlexicographic upgrade \\(\\Up *_aF\\) ranks these most plausible\nF-worlds as most plausible overall and leaves all other\nrankings as before. In the multi-agent case with n agents, we\nobserve that a plausibility action model with \\(2^n\\) actions is\nequivalent to \\(\\Up F\\). In particular, let \n\n\t\\[\n\t\\CU(F) \\coloneqq (E,\\geq,\\pre)\n\t\\]\n\n be the\nplausibility action model defined as follows:\n\n\n \\(E\\coloneqq\\{e_I \\mid I\\subseteq\\sA\\}\\) \u2014 there is one\nevent \\(e_I\\) for each (possibly empty) subset \\(I\\subseteq\\sA\\) of\nagents, \n \\(e_I\\geq_a e_J\\) if and only if \\(a\\in J\\) \u2014 event \\(e_J\\)\nis of equal or grader plausibility according to a iff a\nis a member of J, and \n \\(\\pre(e_I) \\coloneqq (\\bigwedge_{i\\in I}*_i F)\\land\n(\\bigwedge_{j\\in(\\sA-I)}\\lnot *_jF)\\) \u2014 event \\(e_I\\) picks out\nthe worlds that are best F-worlds for agents in I and\nnot best F-worlds for agents not in I. \n Intuitively, this plausibility action model has each agent\na split the events into two categories: those that are best\nF-worlds according to a make up the first category and\nare ranked highest, and those that are not best F-worlds\naccording to a make up the second category and are ranked\nstrictly less plausible than the first category. In particular, since\nwe have \\(e_I\\leq_a e_J\\) if and only if a is in I, it\nfollows that:\n\n\nif \\(i\\in I\\cap J\\), then \\(e_I\\simeq_a e_J\\);\nif \\(i\\in I-J\\), then \\(e_I\\lt_a e_J\\);\nif \\(i\\in J-I\\), then \\(e_I\\gt_a e_J\\);\nif \\(i\\in \\sA-(I\\cup J)\\), then \\(e_I\\simeq_a e_J\\).\n So the \\(e_I\\)\u2019s having i in I make up the\nfirst category and are all ranked most plausible overall by a,\nand the \\(e_I\\)\u2019s not having i in I make up the\nsecond category are ranked strictly less plausible by a. The\npreconditions are arranged so that any two events are pairwise\ninconsistent: if \\(I\\neq J\\), then I and J differ on at\nleast one agent a and therefore they differ on whether their\nprecondition asserts \\(*_aF\\) or its negation \\(\\lnot *_aF\\). Further,\nthe preconditions of the events exhaust all possibilities: given a\nworld w of a plausibility model, there is a (possibly empty)\nset of agents I such that the agents in I rank w\nas a best F-world and the agents not in I do not rank\nw as a best F-world; as such, world w satisfies\nthe precondition of \\(e_I\\) for the set I in question.\nTherefore, the events in \\(\\CU(F)\\) partition the worlds of a given\ninput plausibility model into a number of pieces, one piece for each\nsubset \\(I\\subseteq\\sA\\). The piece of the given model corresponding\nto the subset I is picked out by event \\(e_I\\) and consists of\nthose worlds in the given model that satisfy the precondition\n\\(\\pre(e_I)\\); these are the worlds that are best F-worlds\naccording to the agents in I and not best F-worlds\naccording to the agents not in I. So we see that \\(\\CU(F)\\)\nbreaks up the model into various pieces based on which of the agents\nthink the worlds in the given piece are best F-worlds, has the\nagents rank the pieces so that each agent has her best F-worlds\noutrank all other worlds, and otherwise leaves the ranking as it was.\nAccordingly, it is not too hard to see that we have \n\n\t  \\[\nM,w\\models[\\up F]G\n\t      \\quad\\text{ iff }\n\t  M,w\\models\\bigvee_{I\\subseteq\\sA}[\\CU(F),e_I]G\n\t      \n\\mbox{ (general case),}\n\\]\n\n which\nsays that the conservative upgrade by F is equal to the\naction-priority update brought about by the pointed plausibility\naction model \\((\\CU(F),e_I)\\) for some subset \\(I\\subseteq\\sA\\). As\nalready stated, a world in the initial model will satisfy the\nprecondition of exactly one event \\(e_J\\). Therefore, the truth at\nw of the disjunction \\(\\bigvee_{I\\subseteq\\sA}[\\CU(F),e_I]G\\)\nis determined by evaluating the truth at w of the disjunct\n\\([\\CU(F),e_J]G\\) for the particular J corresponding to\nw. \n\n\nWe now study the axiomatic theory of Action-Priority Update Logic.\n\n\n\nThe axiomatic theory \\(\\APUL\\).\n\n Axiom schemes and rules for the theory\n \\(\\KBox\\)\n\n Reduction axioms:\n\n\n \\([A,e]p\\leftrightarrow(\\pre(e)\\to p)\\) for letters \\(p\\in\\sP\\)\n\n\u201cAfter a non-executable action, every letter holds\u2014a\ncontradiction. After an executable action, letters retain their truth\nvalues.\u201d \n \\([A,e](G\\land H)\\leftrightarrow([A,e]G\\land[A,e]H)\\)\n\n\u201cA conjunction is true after an action iff each conjunct\nis.\u201d \n \\([A,e]\\lnot G\\leftrightarrow(\\pre(e)\\to\\lnot[A,e]G)\\)\n\n\u201cG is false after an action iff the action, whenever\nexecutable, does not make G true.\u201d \n \\([A,e]K_aG\\leftrightarrow(\\pre(e)\\to\\bigwedge_{e\\simeq_a\nf}K_a[A,f]G)\\)\n\n\u201ca has information that G after an action iff the\naction, whenever executable, provides a with information that\nG will become true despite the uncertainty in her information\nas to the actual event.\u201d \n \\([A,e]\\Box_a G\\leftrightarrow(\\pre(e)\\to (\\bigwedge_{e\\gt_a\nf}K_a[A,f]G) \\land (\\bigwedge_{e\\simeq_a f}\\Box_a[A,f]G))\\)\n\n\u201ca defeasibly knows G after an action iff the\naction, whenever executable, provides a with information that\nG will become true after all more plausible events and,\nfurther, gives a defeasible knowledge that G will become\ntrue after all equi-plausible events.\u201d \n \nAction Necessitation Rule: from G, infer \\([A,e]G\\)\n\n\u201cA validity holds after any action.\u201d \n\n\n\nThe first three reduction axioms are identical to the corresponding\nreduction axioms for \\(\\EAL\\). The fourth \\(\\APUL\\) reduction axiom is\nalmost identical to the fourth \\(\\EAL\\) reduction axiom. In\nparticular, the fourth \\(\\EAL\\) reduction axiom, which reads \n\n\\[\n\\textstyle\n[A,e]K_aG\\leftrightarrow(\\pre(e)\\to\\bigwedge_{e R_af}K_a[A,f]G),\n\\]\n\n\ndiffers only in the conjunction on the right-hand side: the \\(\\EAL\\)\naxiom has its conjunction over events related to e via the\nKripke model-style relation \\(R_a\\), whereas the \\(\\APUL\\) axiom has\nits conjunction over events related to e via the plausibility\nmodel-style relation \\(\\simeq_a\\). \n\nThe fifth \\(\\APUL\\) reduction axiom is new. This axiom captures the\nessence of the action-priority update: for an agent to have defeasible\nknowledge after an action, she must have information about what\nhappens as a result of more plausible actions and, further, she must\nhave defeasible knowledge about the outcome of equi-plausible actions.\nThe reason for this follows from the definition of the resulting\nplausibility relation \\({\\geq}[A]_a\\). As a reminder, this is defined\nby setting \\((v_1,f_1)\\mathrel{{\\geq}[A]_a}(v_2,f_2)\\) if and only if\nwe have one of the following: \n\n \\(f_1\\gt_a f_2\\) and \\(\\cc_a(v_1)=\\cc_a(v_2)\\) \u2014 events of\nstrictly differing plausibility are applied to informationally\nequivalent worlds; or \n\\(f_1\\simeq_a f_2\\) and \\(v_1\\geq_a v_2\\) \u2014 equi-plausible\nevents are applied to informationally equivalent worlds of differing\nplausibility. \n\n\nLooking to the fifth \\(\\APUL\\) reduction axiom, the conjunct\n\\(\\bigwedge_{e\\gt_a f}K_a[A,f]G\\) says that G is true whenever\nan event of plausibility strictly greater than e is applied to\na world within a\u2019s current connected component. This\ntells us that G is true at worlds having greater plausibility\nin light of the first bulleted item above. The other conjunct\n\\(\\bigwedge_{e\\simeq_a f}\\Box_a[A,f]G)\\) of the fifth \\(\\APUL\\)\nreduction axiom says that G is true whenever an event\nequi-plausible with e is applied to world of equal or greater\nplausibility within a\u2019s current connected component. This\ntells us that G is true at worlds having greater or equal\nplausibility in light of the second bulleted item above. Taken\ntogether, since these two bulleted items define when it is that a\nworld has equal or greater plausibility in the resultant model\n\\(M[A]\\), the truth of these two conjuncts at an initial situation\n\\((M,w)\\) at which \\((A,e)\\) is executable implies that G is\ntrue at all worlds of equal or greater plausibility than the actual\nworld \\((w,e)\\) of the resultant model \\(M[A]\\). That is, we have\n\\(M[A],(w,e)\\models\\Box_a G\\) and therefore that \\(M,w\\models[A,e]G\\).\nThis explains the right-to-left direction of the fifth \\(\\APUL\\)\nreduction axiom. The left-to-right direction is explained similarly.\n\n\nAs was the case for \\(\\EAL\\), the \\(\\APUL\\) reduction axioms allow us\nto \u201creduce\u201d each formula containing plausibility action\nmodels to a provably equivalent formula whose plausibility action\nmodel modalities appear before formulas of lesser complexity, allowing\nus to eliminate plausibility action model modalities completely via a\nsequence of provable equivalences. As a consequence, we have the\nfollowing. \n\n\nAPUL Reduction Theorem. Every F in the\nlanguage \\eqref{APUL} is \\(\\APUL\\)-provably equivalent to a formula\n\\(F^\\circ\\) coming from the plausibility action model-free modal\nlanguage \\eqref{KBox}.\n\n\nOnce we have proved \\(\\APUL\\) is sound, the Reduction Theorem leads us\nto axiomatic completeness via the known completeness of the underlying\nmodal theory \\(\\KBox\\). \n\n\n\\(\\APUL\\) Soundness and Completeness. \\(\\APUL\\) is\nsound and complete with respect to the collection \\(\\sC_*\\) of pointed\nplausibility action models. That is, for each \\eqref{APUL}-formula\nF, we have that \\(\\APUL\\vdash F\\) if and only if \\(\\sC_*\\models\nF\\).\n\n\nAs is the case for \\(\\EAL\\), it is possible to combine two consecutive\nactions into a single action. All that is required is an appropriate\nnotion of plausibility action model composition. \n\n\nPlausibility action model composition. The\ncomposition \\(A\\circ B=(E,\\geq,\\pre)\\) of plausibility action\nmodels \\(A=(E^A,\\geq^A,\\pre^A)\\) and \\(B=(E^B,\\geq^B,\\pre^B)\\) is\ndefined as follows:\n\n \\(E=E^A\\times E^B\\) \u2014 composed events are pairs \\((e,f)\\)\nof constituent events; \n\\((e_1,f_1)\\geq_a (e_2,f_2)\\) if and only if one of the following\nobtains:\n\n\n \\(e_1\\geq_a e_2\\) and \\(\\cc_a(f_1)=\\cc_a(f_2)\\) \u2014 events of\ndiffering plausibility are followed by informationally equivalent\nevents, or \n \\(e_1\\simeq_a e_2\\) and \\(f_1\\geq_a f_2\\) \u2014 equi-plausible\nevents are followed by informationally equivalent events of differing\nplausibility; \n \n\\(\\pre((e_1,e_2)) = \\pre^A(e_1)\\land[A,e_1]\\pre^B(e_2)\\) \u2014 a\ncomposed event is executable iff the first constituent is executable\nand, after it occurs, the second constituent is executable as well.\n\n\n\n\n\nComposition Theorem. Each instance of the following\nschemes is \\(\\APUL\\)-derivable.\n\n Composition Scheme: \\([A,e][B,f]G\\leftrightarrow[A\\circ\nB,(e,f)]G\\) \n Associativity Scheme: \\([A\\circ B,(e,f)][C,g]H \\leftrightarrow\n[A,e][B\\circ C,(f,g)]H]\\)\n\n\n\nIt is also possible to add valuation-changing substitutions (i.e.,\n\u201cfactual changes\u201d) to plausibility action models. This is\ndone exactly as it is done for action models proper: substitutions are\nadded to plausibility action models, the action-priority update is\nmodified to account for substitutions in the semantics, and the first\nreduction axiom is changed to account for substitutions in the\naxiomatics. See\n Appendix G\n for details.  \n4.5 Evidential dynamics and justified belief\n\nOne development in DEL is work aimed toward building logics of\nevidence, belief, and knowledge for use in Formal Epistemology. \n\n Vel\u00e1zquez-Quesada (2009) and van Benthem and\nVel\u00e1zquez-Quesada (2010) study logics of inference and update.\nThese have models containing worlds that explicitly list the formulas\nof which agents are \u201caware\u201d, like awareness logics (Fagin\net al. 1995), except that DEL-style modalities can change these\nawareness sets, allowing agents to increase the formulas of which they\nare aware and make inferences with these formulas over time. In this\nsense, the \u201cawareness sets\u201d may be though of as evidence\nfor the formulas the agents presently know. \n Baltag, Renne, and Smets (2014) study a logic of\n\u201cconclusive\u201d (or \u201cgood\u201d) evidence based on a\ncombination of plausibility models with an adaptation of the syntactic\nbookkeeping mechanisms of Justification Logic (Artemov 2008; Artemov\nand Fitting 2012). They argue that their work generalizes the\nawareness logics of Vel\u00e1zquez-Quesada (2009) and van Benthem\nand Vel\u00e1zquez-Quesada (2010) and better addresses updates with\nhigher-order information. \n A different approach to evidence in Dynamic Epistemic Logic was\nproposed by van Benthem and Pacuit (2011a,b) and studied further in\nvan Benthem, Ferna\u0301ndez-Dunque, and Pacuit (2012, 2014). This\napproach is much less syntactic than the Justification Logic-style\napproaches, focusing instead on the semantic notion of modal\n\u201cneighborhood\u201d (or \u201cminimal\u201d) models that have\nbeen repurposed with an evidential twist. \n\n\nWe refer the reader to\n Appendix K\n for further details. \n5. Probabilistic update in Dynamic Epistemic Logic\n\nDynamic Epistemic Logics that incorporate probability have been\nstudied by a number of authors. Van Benthem (2003), Kooi (2003),\nBaltag and Smets (2008a), and van Benthem, Gerbrandy, and Kooi (2009b)\nstudied logics of finite probability spaces. Sack (2009) extended the\nwork of Kooi (2003) and van Benthem, Gerbrandy, and Kooi (2009b) to\nfull probability spaces (based on \u03c3-algebras of events). Of\nthese, we mention two in particular: \n\n Baltag and Smets (2008a) develop logics of finite probability\nspaces that connect three areas of work: the\nPopper\u2013R\u00e9yni\u2013de Finetti extension of Bayesian\nprobabilistic conditionalization, the theory of Belief Revision, and\nDynamic Epistemic Logic. This leads to a definition of an\naction-model-style probabilistic product update that permits update on\nevents of probability zero (which is required by belief revision).\n\nVan Benthem, Gerbrandy, and Kooi (2009b) have a different approach\nwith action-model-style probabilistic update that takes into account\nthree sources of probabilistic information: prior probabilities,\noccurrence probabilities, and observation probabilities. \n\n\nWe refer the reader to\n Appendix L\n for further details. \n6. Applications of Dynamic Epistemic Logic\n6.1 Preference dynamics\n\nDEL-style model-changing operators have been applied by a number of\nresearchers to the study of preferences, preference change, and\nrelated notions. We refer the reader to\n Appendix M\n for further information, which mentions the work of van Benthem et\nal. (2009), van Benthem and Liu (2007), Liu (2008), Yamada (2007a,b,\n2008), van Eijck (2008), van Eijck and Sietsma (2010), van Benthem,\nGirard, and Roy (2009c), and Liu (2011). \n6.2 Connections with Temporal Logic\n\nAction model-style modalities \\([A,e]\\) of Dynamic Epistemic Logic\nhave a temporally suggestive reading: \u201cafter action\n\\((A,e)\\), formula F is true\u201d. This\n\u201cbefore-after\u201d reading suggests, naturally enough, that\ntime passes as actions occur. The semantics of action models supports\nthis suggestion: determining the truth of an action model formula\n\\([A,e]F\\) in a model\u2014the model \u201cbefore\u201d the\naction\u2014requires us to apply the model-transforming operation\ninduced by the action \\((A,e)\\) and then see whether F holds in\nthe model that results \u201cafter\u201d the action. Channeling\nParikh and Ramanujam (2003) some DEL authors further this suggestion\nby using the temporally charged word \u201chistory\u201d to refer to\na sequence of pointed Kripke models brought about by the occurrence of\na sequence of model-transforming operations. All of this seems to\npoint to the existence of a direct relationship between the occurrence\nof model-transforming actions and the passage of time: time passes as\nthese actions occur. However, the formal languages introduced so far\ndo not have a built-in means for directly expressing the passage of\ntime, and so, as a consequence, the axiomatic theories developed above\nare silent on the relationship between the flow of time and the\noccurrence of model-changing actions. This leaves open the possibility\nthat, within the context of these theories, the passage of time and\nthe occurrence of actions need not necessarily relate as we might\notherwise suspect. \n\nFor more on this, we refer the interested reader to\n Appendix N,\n which mentions a number of studies that bring some method of\ntime-keeping within the scope of the Dynamic Epistemic Logic approach:\nthe work of Sack (2007, 2008, 2010), Yap (2006, 2011), Hoshi (2009),\nHoshi and Yap (2009), van Benthem, Gerbrandy, and Pacuit (2007), van\nBenthem et al. (2009a), D\u00e9gremont, Lo\u0308we, and Witzel\n(2011), and Renne, Sack, and Yap (2009, 2015). \n6.3 Connections to mainstream Epistemology\n\nA number of works utilize tools and techniques from Dynamic Epistemic\nLogic for formal reasoning on topics in mainstream Epistemology. \n\n Baltag and Smets (2008b) use plausibility models\n (Section 4.3)\n and The Logic of Doxastic Actions\n (Section 4.4)\n to capture a number of notions of knowledge, including Aumann\u2019s\npartition-based notion and Stalnaker\u2019s (2006) formalization of\nLehrer\u2019s (1990, 2000) defeasibility analysis of knowledge. \nBuilding on the work mentioned in the previous item, Baltag,\nRenne, and Smets (2014) show that a theory \\(\\JBG\\) of Justified\nBelief with \u201cGood\u201d Evidence can be used to reason about\ncertain examples from mainstream Epistemology. For example, Gettier\n(1963) constructs a famous counterexample to the claim that\n\u201cknowledge\u201d may be equated with \u201cjustified true\nbelief\u201d (i.e., justified correct belief). In this\nexample, an agent\u2014let us call her a\u2014has evidence\nfor a propositional letter f, concludes via logical deduction\nthat \\(b\\lor f\\), and therefore has evidence for this disjunction;\nhowever, unknown to the agent, f is false but b is true.\nShe therefore has justified true belief but not knowledge that \\(b\\lor\nf\\) is true (since her reason for believing this disjunction is based\non her belief in the wrong disjunct). This example is easily\nreconstructed in \\(\\JBG\\), providing one formal account of an agent\nwhose justified belief is correct and yet the agent does not have\nknowledge (even in a weakly defeasible sense). See\n Appendix K\n for additional details. \nBaltag, Renne, and Smets (2012) analyze a Gettier-like example due\nto Lehrer (1990, 2000) in a variant of \\(\\JBG\\) that includes dynamic\noperations for addition of evidence, stepwise logical reasoning,\nannouncement-like addition of evidence with world elimination, and\nevidence-based plausibility upgrades of worlds. \nFitch\u2019s paradox (Fitch 1963) concerns the seemingly strange\nresult that the existence of unknown truths implies not all truths are\nknowable. Following the suggestion of van Benthem (2004), Balbiani et\nal. (2008) equate \u201cknowability\u201d with \u201cbeing known\nafter some announcement\u201d and show using Arbitrary Public\nAnnouncement Logic (see\n Appendix E)\n that it is jointly inconsistent to assume that \u201cp is an\nunknown truth\u201d and that \u201call truths are knowable\u201d.\nWe refer the reader to the discussions in van Benthem (2004), Balbiani\net al. (2008), and Brogaard and Salerno (2012) for further details.\n\n\n7. Conclusion\n\nWe have surveyed the literature of Dynamic Epistemic Logic, from its\nearly development in the Public Announcement Logic to the generalized\ncommunication operations of action models, work on qualitative and\nquantitative belief revision, and applications in a variety of areas.\nDynamic Epistemic Logic is an active and expanding area, and we have\nhighlighted a number of open problems and directions for further\nresearch. \nAppendices\n\nA. Kripke models for modal logic\nB. Solutions to Cheryl\u2019s Birthday, Muddy Children, and Sum and Least Common Multiple\nC. Properties of binary relations\nD. Normal modal logic\nE. Technical details of Public Announcement Logic\nF. The axiomatic theories of Relativized Common Knowledge\nG. More on action models and the Logic of Epistemic Actions\nH. Recursive definition of languages with action models\nI. Variants of the action model approach to Dynamic Epistemic Logic\nJ. Conditional Doxastic Logic\nK. Evidential dynamics and justified belief\nL. Probabilistic update in Dynamic Epistemic Logic\nM. Preference dynamics\nN. Temporal aspects of Dynamic Epistemic Logic\n\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "\u00c5gotnes, T., P. Balbiani, H. van Ditmarsch, and P. Seban,\n2010, \u201cGroup announcement logic\u201d, <em>Journal of Applied\nLogic</em>, 8(1): 62\u201381. <span class=\"doi\">doi:10.1016/j.jal.2008.12.002</span>",
                "Alchourr\u00f3n, C.E., P. G\u00e4rdenfors, and D. Makinson,\n1985, \u201cOn the logic of theory change: Partial meet contraction\nand revision functions\u201d, <em>Journal of Symbolic Logic</em>,\n50(2): 510\u2013530. <span class=\"doi\">doi:10.2307/2274239</span>",
                "Andr\u00e9ka, H., I. N\u00e9meti, and J. van Benthem, 1998,\n\u201cModal languages and bounded fragments of predicate\nlogic\u201d, <em>Journal of Philosophical Logic</em>, 27(3):\n217\u2013274. <span class=\"doi\">doi:10.1023/A:1004275029985</span>",
                "Areces, C., R. Fervari, and G. Hoffmann, 2012, \u201cMoving\narrows and four model checking results\u201d, in Ong and Queiroz\n2012: 142\u2013153. <span class=\"doi\">doi:10.1007/978-3-642-32621-9_11</span>",
                "Arl\u00f3-Costa, H. and R. Parikh, 2005, \u201cConditional\nprobability and defeasible inference\u201d, <em>Journal of\nPhilosophical Logic</em>, 34(1): 97\u2013119. <span class=\"doi\">doi:10.1007/s10992-004-5553-6</span>",
                "Artemov, S.N., 2008, \u201cThe logic of justification\u201d,\n<em>The Review of Symbolic Logic</em>, 1(4): 477\u2013513. <span class=\"doi\">doi:10.1017/S1755020308090060</span>",
                "Artemov, S.N. and M. Fitting, 2012, \u201cJustification\nlogic\u201d, in E.N. Zalta (ed.), <em>The Stanford Encyclopedia of\nPhilosophy</em> (Fall 2012 Edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2012/entries/logic-justification/\" target=\"other\">https://plato.stanford.edu/archives/fall2012/entries/logic-justification/</a>&gt;",
                "Aucher, G., 2003, \u201cA combined system for update logic and\nbelief revision\u201d, Master's thesis, University of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Reports/MoL-2003-03.text.pdf\" target=\"other\">Aucher 2003 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2005, \u201cA combined system for update\nlogic and belief revision\u201d, in <em>Intelligent Agents and\nMulti-Agent Systems: 7th Pacific Rim International Workshop on\nMulti-Agents, PRIMA 2004, Auckland, New Zealand, August 8\u201313,\n2004, Revised Selected Papers</em>, Volume 3371 of <em> Lecture Notes\nin Computer Science</em>, pp. 1\u201317, Berlin/Heidelberg: Springer.\n<span class=\"doi\">doi:10.1007/b107183</span>",
                "\u2013\u2013\u2013, 2008, \u201cConsistency preservation and\ncrazy formulas in BMS\u201d, in S. H\u00f6lldobler, C. Lutz, and H.\nWansing (eds.), <em>Logics in Artificial Intelligence: 11th European\nConference, JELIA 2008, Dresden, Germany, September 28\u2013October\n1, 2008. Proceedings</em>, Volume 5293 of <em>Lecture Notes in\nComputer Science</em>, pp. 21\u201333, Berlin/Heidelberg: Springer.\n<span class=\"doi\">doi:10.1007/978-3-540-87803-2_4</span>",
                "Aucher, G., P. Balbiani, L. Fari\u00f1as del Cerro, and A.\nHerzig, 2009, \u201cGlobal and local graph modifiers\u201d, in C.\nAreces and S. Demri (eds.), <em>Proceedings of the 5th Workshop on\nMethods for Modalities (M4M5 2007)</em>, Volume 231 of <em> Electronic\nNotes in Theoretical Computer Science</em>, Cachan, France, pp.\n293\u2013307. <span class=\"doi\">doi:10.1016/j.entcs.2009.02.042</span>",
                "Aucher, G. and F. Schwarzentruber, 2013, \u201cOn the complexity\nof dynamic epistemic logic\u201d, in B.C. Schipper (ed.),\n<em>Proceedings of the 14th Conference of Theoretical Aspects of\nRationality and Knowledge (TARK XIV)</em>, Chennai, India, pp.\n19\u201328.\n [<a href=\"http://tark.org/proceedings/tark_jan7_13/p19-aucher.pdf\" target=\"other\">Aucher and Schwarzentruber 2013 available online (pdf)</a>]",
                "Balbiani, P., A. Baltag, H. van Ditmarsch, A. Herzig, T. Hoshi,\nand T. de Lima, 2007, \u201cWhat can we achieve by arbitrary\nannouncements? A dynamic take on Fitch's knowability\u201d, in D.\nSamet (ed.), <em>Proceedings of the 11th Conference on Theoretical\nAspects of Rationality and Knowledge (TARK XI)</em>, Brussels,\nBelgium, pp. 42\u201351.\n [<a href=\"http://tark.org/proceedings/tark_jun25_07/p42-balbiani.pdf\" target=\"other\">Balbiani et al. 2007 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2008, \u201c\u2018Knowable\u2019 as\n\u2018known after an announcement\u2019\u201d, <em>The Review of\nSymbolic Logic</em>, 1(3): 305\u2013334. <span class=\"doi\">doi:10.1016/j.entcs.2006.05.034</span>\n|\n [<a href=\"http://dare.uva.nl/document/2/63109\" target=\"other\">Balbiani et al. 2008 available online (pdf)</a>]",
                "Balbiani, P., H. van Ditmarsch, A. Herzig, and T. De Lima, 2012,\n\u201cSome truths are best left unsaid\u201d, in Bolander et al.\n2012: Vol. 9, pp. 36\u201354.\n [<a href=\"http://www.aiml.net/volumes/volume9/Balbiani-Ditmarsch-Herzig-Lima.pdf\" target=\"other\">Balbiani et al. 2012 available online (pdf)</a>]",
                "Ballarin, R., 2010, \u201cModern origins of modal logic\u201d,\nin E.N. Zalta (ed.), <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2014 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/win2014/entries/logic-modal-origins/\" target=\"other\">https://plato.stanford.edu/archives/win2014/entries/logic-modal-origins/</a>&gt;",
                "Baltag, A. and L.S. Moss, 2004, \u201cLogics for epistemic\nprograms\u201d, <em>Synthese</em>, 139(2): 165\u2013224. <span class=\"doi\">doi:10.1023/B:SYNT.0000024912.56773.5e</span>",
                "Baltag, A., L.S. Moss, and S. Solecki, 1998, \u201cThe logic of\npublic announcements, common knowledge, and private suspicions\u201d,\nin I. Gilboa (ed.), <em>Proceedings of the 7th Conference on\nTheoretical Aspects of Rationality and Knowledge (TARK VII)</em>,\nEvanston, Illinois, USA, pp. 43\u201356.\n [<a href=\"http://www.tark.org/proceedings/tark_jul22_98/p43-baltag.pdf\" target=\"other\">Baltag, Moss, and Solecki 1998 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 1999, \u201cThe logic of public\nannouncements, common knowledge, and private suspicions\u201d,\nTechnical Report TR534 (November), Indiana University.\n [<a href=\"http://www.cs.indiana.edu/pub/techreports/TR534.pdf\" target=\"other\">Baltag, Moss, and Solecki 1999 available online (pdf)</a>]",
                "Baltag, A., B. Renne, and S. Smets, 2012, \u201cThe logic of\njustified belief change, soft evidence and defeasible\nknowledge\u201d, in Ong and Queiroz 2012: 168\u2013190. <span class=\"doi\">doi:10.1007/978-3-642-32621-9_13</span>",
                "\u2013\u2013\u2013, 2014, \u201cThe logic of justified belief,\nexplicit knowledge, and conclusive evidence\u201d, <em>Annals of Pure\nand Applied Logic</em>, 165(1): 49\u201381. <span class=\"doi\">doi:10.1016/j.apal.2013.07.005</span>",
                "\u2013\u2013\u2013, 2015, \u201cRevisable justified belief:\nPreliminary report\u201d, E-print, arXiv.org. arXiv:1503.08141\n[cs.LO].\n [<a href=\"http://arxiv.org/abs/1503.08141\" target=\"other\">Baltag, Renne, and Smets 2015 available online (html)</a> |\n \n <a href=\"http://arxiv.org/pdf/1503.08141.pdf\" target=\"other\">Baltag, Renne, and Smets 2015 available online (pdf)</a>]",
                "Baltag, A. and S. Smets, 2008a, \u201cProbabilistic dynamic\nbelief revision\u201d, <em>Synthese</em>, 165(2): 179\u2013202.\n<span class=\"doi\">doi:10.1007/s11229-008-9369-8</span>",
                "\u2013\u2013\u2013, 2008b, \u201cA qualitative theory of\ndynamic interactive belief revision\u201d, in G. Bonanno, W. van der\nHoek, and M. Wooldridge (eds.), <em>TLG 3: Logic and the Foundations\nof Game and Decision Theory (LOFT 7)</em>, Volume 3 of <em>Texts in\nlogic and games</em>, pp. 11\u201358, Amsterdam: Amsterdam University\nPress.\n [<a href=\"http://www.vub.ac.be/CLWF/SS/BeliefRevision-Smets.pdf\" target=\"other\">Baltag and Smets 2008a available online (pdf)</a>]",
                "Blackburn, P., M. de Rijke, and Y. Venema, 2002, <em>Modal\nLogic</em>, Volume 53 of <em>Cambridge Tracts in Theoretical Computer\nScience</em>, Cambridge: Cambridge University Press.",
                "Board, O., 2004, \u201cDynamic interactive epistemology\u201d,\n<em>Games and Economic Behavior</em>, 49(1): 49\u201380. <span class=\"doi\">doi:10.1016/j.geb.2003.10.006</span>",
                "Bolander, T., T. Bra\u00fcner, S. Ghilardi, and L.S. Moss (eds.),\n2012, <em>Advances in Modal Logic (AiML)</em>, Copenhagen, Denmark:\nCollege Publications.",
                "Boutilier, C., 1993, \u201cRevision sequences and nested\nconditionals\u201d, in <em>Proceedings of the 13th International\nJoint Conference on Artificial Intelligence (IJCAI 2011)</em>, Volume\n93, Chamb\u00e9ry, France, pp. 519\u2013531.\n [<a href=\"http://www.ijcai.org/Past%20Proceedings/IJCAI-93-VOL1/PDF/073.pdf\" target=\"other\">Boutilier 1993 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 1995, \u201cOn the revision of\nprobabilistic belief states\u201d, <em>Notre Dame Journal of Formal\nLogic</em>, 36(1): 158\u2013183. <span class=\"doi\">doi:10.1305/ndjfl/1040308833</span>",
                "Brogaard, B. and J. Salerno, 2012, \u201cFitch's paradox of\nknowability\u201d, in E.N. Zalta (ed.), <em>The Stanford Encyclopedia\nof Philosophy</em> (Winter 2013 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/win2013/entries/fitch-paradox/\" target=\"other\">https://plato.stanford.edu/archives/win2013/entries/fitch-paradox/</a>&gt;",
                "Bucheli, S., R. Kuznets, J. Sack, and T. Studer, 2010,\n\u201cJustified belief change\u201d, in X. Arrazola and M. Ponte\n(eds.), <em>LogKCA-10: Proceedings of the 2nd ILCLI International\nWorkshop on Logic and Philosophy of Knowledge, Communication and\nAction</em>, pp. 135\u2013155. The University of the Basque Country\nPress.\n [<a href=\"http://www.iam.unibe.ch/~tstuder/papers/bkrss-justifiedBeliefChange.pdf\" target=\"other\">Bucheli et al. available online (pdf)</a>]",
                "Bucheli, S., R. Kuznets, and T. Studer, 2011, \u201cPartial\nrealization in dynamic justification logic\u201d, in L.D. Beklemishev\nand R. de Queiroz (eds.), <em>Logic, Language, Information and\nComputation: 18th International Workshop, WoLLIC 2011, Philadelphia,\nPA, USA, Proceedings</em>, Volume 6642 of <em>Lecture Notes in\nComputer Science</em>, pp. 35\u201351, Berlin/Heidelberg: Springer.\n<span class=\"doi\">doi:10.1007/978-3-642-20920-8_9</span> |\n [<a href=\"http://www.iam.unibe.ch/~tstuder/papers/wollic2011.pdf\" target=\"other\">Bucheli et al. 2011 available online (pdf)</a>]",
                "Chang, K., 2015, \u201cA math problem from Singapore goes viral:\nWhen is Cheryl's birthday?\u201d <em>The New York Times</em> (15\nApril 2015).\n [<a href=\"http://nyti.ms/1CVmkuP\" target=\"other\">Chang 2015 available online (html)</a>]",
                "D\u00e9gr\u00e9mont, C., B. L\u00f6we, and A. Witzel, 2011,\n\u201cThe synchronicity of dynamic epistemic logic\u201d, in K.R.\nApt (ed.), <em>Proceedings of the 13th Conference of Theoretical\nAspects of Rationality and Knowledge (TARK XIII)</em>, Groningen, The\nNetherlands, pp. 145\u2013152.\n [<a href=\"http://tark.org/proceedings/tark_jul11_11/p145-degremont.pdf\" target=\"other\">D\u00e9gr\u00e9mont et al. 2011 available online (pdf)</a>]",
                "Demey, L., B. Kooi, and J. Sack, 2013, \u201cLogic and\nprobability\u201d, in E.N. Zalta (ed.), <em>The Stanford Encyclopedia\nof Philosophy</em> (Fall 2014 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2014/entries/logic-probability/\" target=\"other\">https://plato.stanford.edu/archives/fall2014/entries/logic-probability/</a>&gt;",
                "Fagin, R., J.Y. Halpern, and N. Megiddo, 1990, \u201cA logic for\nreasoning about probabilities\u201d, <em>Information and\nComputation</em>, 87, 78\u2013128. <span class=\"doi\">doi:10.1016/0890-5401(90)90060-U</span>",
                "Fagin, R., J.Y. Halpern, Y. Moses, and M. Vardi, 1995,\n<em>Reasoning About Knowledge</em>, Cambridge, MA: MIT Press.",
                "Fervari, R., 2014, <em>Relation-Changing Modal Logics</em>, Ph. D.\nthesis, Facultad de Matem\u00e1tica Astronom\u00eda y\nF\u00edsica, Universidad Nacional de C\u00f3rdoba, C\u00f3rdoba,\nArgentina.",
                "Fitch, F.B., 1963, \u201cA logical analysis of some value\nconcepts\u201d, <em>The Journal of Symbolic Logic</em>, 28(2):\n135\u2013142.",
                "French, T., W. van der Hoek, P. Iliev, and B. Kooi, 2011,\n\u201cSuccinctness of epistemic languages\u201d, in <em>Proceedings\nof the 22nd International Joint Conference on Artificial Intelligence\n(IJCAI 2011)</em>, Barcelona, Spain, pp. 881\u2013886. <span class=\"doi\">doi:10.5591/978-1-57735-516-8/IJCAI11-153</span>\n|\n [<a href=\"http://ijcai.org/papers11/Papers/IJCAI11-153.pdf\" target=\"other\">French et al. 2011 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2013, \u201cOn the succinctness of some\nmodal logics\u201d, <em>Artificial Intelligence</em>, 197:\n56\u201385. <span class=\"doi\">doi:10.1016/j.artint.2013.02.003</span>",
                "French, T. and H. van Ditmarsch, 2008, \u201cUndecidability for\narbitrary public announcement logic\u201d, in L. Beklemishev, V.\nGoranko, and V. Shehtman (eds.), <em>Advances in Modal Logic\n(AiML)</em>, Volume 7, Nancy, France, pp. 23\u201342. College\nPublications.\n [<a href=\"http://www.aiml.net/volumes/volume7/French-vanDitmarsch.pdf\" target=\"other\">French and van Ditmarsch 2008 available online (pdf)</a>]",
                "G\u00e4rdenfors, P., 1988, <em>Knowledge in Flux: Modeling the\nDynamics of Epistemic States</em>, Cambridge, MA: MIT Press.",
                "Garson, J., 2014, \u201cModal logic\u201d, in E.N. Zalta (ed.),\n<em>The Stanford Encyclopedia of Philosophy</em> (Summer 2014\nedition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/sum2014/entries/logic-modal/\" target=\"other\">https://plato.stanford.edu/archives/sum2014/entries/logic-modal/</a>&gt;",
                "Gerbrandy, J., 1999, <em>Bisimulations on Planet Kripke</em>, Ph.\nD. thesis, University of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Dissertations/DS-1999-01.text.pdf\" target=\"other\">Gerbrandy 1999 available online (pdf)</a>]",
                "Gerbrandy, J. and W. Groeneveld, 1997, \u201cReasoning about\ninformation change\u201d, <em>Journal of Logic, Language and\nInformation</em>, 6(2): 147\u2013169. <span class=\"doi\">doi:10.1023/A:1008222603071</span>",
                "Gettier, E., 1963, \u201cIs justified true belief\nknowledge?\u201d <em>Analysis</em>, 23, 121\u2013123.",
                "Girard, P., 2008, <em>Modal Logic for Belief and Preference\nChange</em>, Ph. D. thesis, University of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Dissertations/DS-2008-04.text.pdf\" target=\"other\">Girard 2008 available online (pdf)</a>]",
                "Girard, P., O. Roy, and M. Marion (eds.), 2011, <em>Dynamic Formal\nEpistemology</em>, Volume 351 of <em>Synthese Library</em>,\nBerlin/Heidelberg: Springer.",
                "Girard, P., J. Seligman, and F. Liu, 2012, \u201cGeneral dynamic\ndynamic logic\u201d, in Bolander et al. 2012: Vol. 8, pp.\n239\u2013260.\n [<a href=\"http://www.aiml.net/volumes/volume9/Girard-Seligman-Liu.pdf\" target=\"other\">Girard, Seligman, and Liu 2012 available online (pdf)</a>]",
                "Grove, A., 1988, \u201cTwo modellings for theory change\u201d,\n<em>Journal of Philosophical Logic</em>, 17(2): 157\u2013170. <span class=\"doi\">doi:10.1007/BF00247909</span>",
                "Halpern, J.Y., 2001, \u201cLexicographic probability, conditional\nprobability, and nonstandard probability\u201d, in J. van Benthem\n(ed.), <em>Proceedings of the 8th Conference on Theoretical Aspects of\nRationality and Knowledge (TARK VIII)</em>, Certosa di Pontignano,\nItaly, pp. 17\u201330.\n [<a href=\"http://tark.org/proceedings/tark_jul8_01/p17-halpern.pdf\" target=\"other\">Halpern 2001 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2003, <em>Reasoning about Uncertainty</em>,\nCambridge, MA: MIT Press.",
                "Hansson, S.O., 2012, \u201cLogic of belief revision\u201d, in\nE.N. Zalta (ed.), <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2014 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/win2014/entries/logic-belief-revision/\" target=\"other\">https://plato.stanford.edu/archives/win2014/entries/logic-belief-revision/</a>&gt;",
                "Hendricks, V. and J. Symons, 2006, \u201cEpistemic logic\u201d,\nin E.N. Zalta (ed.), <em>The Stanford Encyclopedia of Philosophy</em>\n(Fall 2015 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2015/entries/logic-epistemic/\" target=\"other\">https://plato.stanford.edu/archives/fall2015/entries/logic-epistemic/</a>&gt;",
                "Hintikka, J., 1962, <em>Knowledge and belief: an introduction to\nthe logic of the two notions</em>, Cornell: Cornell University\nPress.",
                "Holliday, W.H., T. Hoshi, and T.F. Icard, III, 2012, \u201cA\nuniform logic of information dynamics\u201d, in Bolander et al. 2012:\nVol. 8, pp. 348\u2013367.\n [<a href=\"http://www.aiml.net/volumes/volume9/Holliday-Hoshi-Icard.pdf\" target=\"other\">Holliday et al. 2012 available online (pdf)</a>]",
                "Holliday, W.H. and T.F. Icard, III, 2010, \u201cMoorean phenomena\nin epistemic logic\u201d, in L. Beklemishev, V. Goranko, and V.\nShehtman (eds.), <em>Advances in Modal Logic (AiML)</em>, Volume 8,\nMoscow, Russia, pp. 178\u2013199. College Publications.\n [<a href=\"http://www.aiml.net/volumes/volume8/Holliday-Icard.pdf\" target=\"other\">Holliday and Icard 2010 available online (pdf)</a>]",
                "Hoshi, T., 2008, \u201cPublic announcement logics with\nconstrained protocols\u201d, in <em>Proceedings of the 8th Conference\non Logic and the Foundations of Game and Decision Theory (LOFT\n8)</em>, Amsterdam, The Netherlands.\n [<a href=\"http://www.illc.uva.nl/LOFT2008/Papers/Hoshi.pdf\" target=\"other\">Hoshi 2008 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2009, <em>Epistemic dynamics and protocol\ninformation</em>, Ph. D. thesis, Stanford University.\n [<a href=\"http://www.illc.uva.nl/Research/Dissertations/DS-2009-08.text.pdf\" target=\"other\">Hoshi 2009 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2010, \u201cMerging DEL and ETL\u201d,\n<em>Journal of Logic, Language and Information</em>, 19(4):\n413\u2013430. <span class=\"doi\">doi:10.1007/s10849-009-9116-7</span>",
                "Hoshi, T. and A. Yap, 2009, \u201cDynamic epistemic logic with\nbranching temporal structures\u201d, <em>Synthese</em>, 169(2):\n259\u2013281. <span class=\"doi\">doi:10.1007/s11229-009-9552-6</span>",
                "Katsuno, H. and A.O. Mendelzon, 1991, \u201cPropositional\nknowledge base revision and minimal change\u201d, <em>Artificial\nIntelligence</em>, 52(3): 263\u2013294. <span class=\"doi\">doi:10.1016/0004-3702(91)90069-V</span>",
                "Kooi, B., 2003, \u201cProbabilistic dynamic epistemic\nlogic\u201d, <em>Journal of Logic, Language and Information</em>,\n12(4): 381\u2013408. <span class=\"doi\">doi:10.1023/A:1025050800836</span>",
                "\u2013\u2013\u2013, 2007, \u201cExpressivity and completeness\nfor public update logics via reduction axioms\u201d, <em>Journal of\nApplied Non-Classical Logics</em>, 17(2): 231\u2013253. <span class=\"doi\">doi:10.3166/jancl.17.231-253</span>",
                "Kooi, B. and B. Renne, 2011a, \u201cArrow update logic\u201d,\n<em>Review of Symbolic Logic</em>, 4(4): 536\u2013559. <span class=\"doi\">doi:10.1017/S1755020311000189</span>\n",
                "\u2013\u2013\u2013, 2011b, \u201cGeneralized arrow update\nlogic\u201d, in K.R. Apt (ed.), <em>Proceedings of the 13th\nConference of Theoretical Aspects of Rationality and Knowledge (TARK\nXIII)</em>, Groningen, The Netherlands, pp. 205\u2013211.\n [<a href=\"http://www.tark.org/proceedings/tark_jul11_11/p205-kooi.pdf\" target=\"other\">Kooi and Renne 2011b available online (pdf)</a>]",
                "Kooi, B. and J. van Benthem, 2004, \u201cReduction axioms for\nepistemic actions\u201d, in R. Schmidt, I. Pratt-Hartmann, M.\nReynolds, and H. Wansing (eds.), <em>AiML-2004: Advances in Modal\nLogic (Preliminary Proceedings)</em>, Manchester, UK, pp.\n197\u2013211.\n [<a href=\"https://www.rug.nl/research/portal/files/2960510/extendedabstract.pdf\" target=\"other\">Kooi and van Benthem 2003 available online (pdf)</a>]",
                "Lehrer, K., 1990, <em>Theory of Knowledge</em>, Routledge.",
                "\u2013\u2013\u2013, 2000, <em>Theory of Knowledge</em>,\nWestview Press.",
                "Lehrer, K. and J. Paxson, T., 1969, \u201cKnowledge: Undefeated\njustified true belief\u201d, <em>Journal of Philosophy</em>, 66,\n225\u2013237.",
                "Liu, F., 2008, <em>Changing for the better: Preference dynamics\nand agent diversity</em>, Ph. D. thesis, University of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Dissertations/DS-2008-02.text.pdf\" target=\"other\">Liu 2008 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2010, \u201cVon Wright's \u2018The logic\nof preference\u2019 revisited\u201d, <em>Synthese</em>, 175(1):\n69\u201388. <span class=\"doi\">doi:10.1007/s11229-009-9530-z</span>",
                "\u2013\u2013\u2013, 2011, <em>Reasoning about preference\ndynamics</em>, Volume 354 of <em> Synthese Library</em>,\nBerlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-94-007-1344-4</span>",
                "Lutz, C., 2006, \u201cComplexity and succinctness of public\nannouncement logic\u201d, in <em>Proceedings of the 5th International\nConference on Autonomous Agents and Multiagent Systems\n(AAMAS-2006)</em>, Hakodate, Japan, pp. 137\u2013144. Association for\nComputing Machinery (ACM), New York, New York, USA. <span class=\"doi\">doi:10.1145/1160633.1160657</span>",
                "Miller, J.S. and L.S. Moss, 2005, \u201cThe undecidability of\niterated modal relativization\u201d, <em>Studia Logica</em>, 79(3):\n373\u2013407. <span class=\"doi\">doi:10.1007/s11225-005-3612-9</span>",
                "Ong, L. and R. de Queiroz (eds.), 2012, <em>Logic, Language,\nInformation and Computation: 19th International Workshop, WoLLIC 2012,\nBuenos Aires, Argentina, September 3\u20136, 2012, Proceedings</em>,\nVolume 7456 of <em> Lecture Notes in Computer Science</em>,\nBerlin/Heidelberg: Springer-Verlag.",
                "Parikh, R. and R. Ramanujam, 2003, \u201cA knowledge based\nsemantics of messages\u201d, <em>Journal of Logic, Language and\nInformation</em>, 12(4): 453\u2013467. <span class=\"doi\">doi:10.1023/A:1025007018583</span>",
                "Peppas, P., 2008, \u201cBelief revision\u201d, in F. van\nHarmelen, V. Lifschitz, and B. Porter (eds.), <em>Handbook of\nKnowledge Representation</em>, Volume 3 of <em>Foundations of\nArtificial Intelligence</em>, Chapter 8, pp. 317\u2013359, Amsterdam,\nThe Netherlands: Elsevier. <span class=\"doi\">doi:10.1016/S1574-6526(07)03008-8</span>",
                "Plaza, J., 1989, \u201cLogics of public communications\u201d, in\nM.L. Emrich, M.S. Pfeifer, M. Hadzikadic, and Z.W. Ras (eds.),\n<em>Proceedings of the 4th International Symposium on Methodologies\nfor Intelligent Systems (ISMIS 1989): Poster Session Program</em>,\nCharlotte, North Carolina, USA, pp. 201\u2013216. Oak Ridge National\nLaboratory ORNL/DSRD-24.",
                "\u2013\u2013\u2013, 2007, \u201cLogics of public\ncommunications\u201d, <em>Synthese</em>, 158(2): 165\u2013179. <span class=\"doi\">doi:10.1007/s11229-007-9168-7</span>",
                "Popper, K., 2002 [1935], <em>The Logic of Scientific\nDiscovery</em>, London, United Kingdom: Routledge Classics. First\npublished in 1935 as <em>Logik der Forschung</em>, Vienna: Verlag von\nJulius Springer.",
                "Renardel de Lavalette, G.R., 2004, \u201cChanging\nmodalities\u201d, <em>Journal of Logic and Computation</em>, 14(2):\n251\u2013275. <span class=\"doi\">doi:10.1093/logcom/14.2.251</span>",
                "Renne, B., 2008, \u201cPublic and private communication are\ndifferent: Results on relative expressivity\u201d, <em>Synthese</em>,\n165(2): 225\u2013245. <span class=\"doi\">doi:10.1007/s11229-008-9395-6</span>",
                "\u2013\u2013\u2013, 2009, \u201cEvidence elimination in\nmulti-agent justification logic\u201d, in A. Heifetz (ed.),\n<em>Proceedings of the 12th Conference of Theoretical Aspects of\nRationality and Knowledge (TARK XII)</em>, Stanford, California, USA,\npp. 227\u2013236. <span class=\"doi\">doi:10.1145/1562814.1562845</span>",
                "\u2013\u2013\u2013, 2011a, \u201cPublic communication in\njustification logic\u201d, <em>Journal of Logic and Computation</em>,\n21(6): 1005\u20131034. <span class=\"doi\">doi:10.1093/logcom/exq026</span>",
                "\u2013\u2013\u2013, 2011b, \u201cSimple evidence elimination\nin justification logic\u201d, in Girard et al. 2011: Chapter 7, pp.\n127\u2013149. <span class=\"doi\">doi:10.1007/978-94-007-0074-1_7</span>",
                "\u2013\u2013\u2013, 2012, \u201cMulti-agent justification\nlogic: Communication and evidence elimination\u201d,\n<em>Synthese</em>, 185(S1), 43\u201382. <span class=\"doi\">doi:10.1007/s11229-011-9968-7</span>\n",
                "Renne, B., J. Sack, and A. Yap, 2009, \u201cDynamic epistemic\ntemporal logic\u201d, in X. He, J. Horty, and E. Pacuit (eds.),\n<em>Logic, Rationality, and Interaction: Second International\nWorkshop, LORI 2009, Chongqing, China, October 8\u201311, 2009,\nProceedings</em>, Volume 5834 of <em>Lecture Notes in Computer\nScience</em>, pp. 263\u2013277, Berlin/Heidelberg: Springer-Verlag.\n<span class=\"doi\">doi:10.1007/978-3-642-04893-7_21</span>",
                "\u2013\u2013\u2013, 2015, \u201cLogics of temporal-epistemic\nactions\u201d, <em>Synthese</em>. <span class=\"doi\">doi:10.1007/s11229-015-0773-6</span>.\n [<a href=\"http://link.springer.com/article/10.1007%2Fs11229-015-0773-6\" target=\"other\">Renne, Sack, and Yap available online</a>]\n <!-- this is open access from SpringerLink-->",
                "R\u00e9nyi, A., 1955, \u201cOn a new axiomatic theory of\nprobability\u201d, <em>Acta Mathematica Hungarica</em>, 6(3\u20134),\n285\u2013335. <span class=\"doi\">doi:10.1007/BF02024393</span>",
                "\u2013\u2013\u2013, 1964, \u201cSur les espaces simples des\nprobabilit\u00e9s conditionnelles\u201d, in <em>Annales de\nl'institut Henri Poincar\u00e9 (B) Probabilit\u00e9s et\nStatistiques</em>, Volume 1, pp. 3\u201321.\n [<a href=\"http://eudml.org/doc/76848\" target=\"other\">R\u00e9nyi 1964 available online</a>]",
                "Roelofsen, F., 2007, \u201cDistributed knowledge\u201d,\n<em>Journal of Applied Non-Classical Logics</em>, 17(2):\n255\u2013273. <span class=\"doi\">doi:10.3166/jancl.17.255-273</span>",
                "Rott, H., 1989, \u201cConditionals and theory change: Revisions,\nexpansions, and additions\u201d, <em>Synthese</em>, 81(1):\n91\u2013113. <span class=\"doi\">doi:10.1007/BF00869346</span>",
                "Sack, J., 2007, <em>Adding Temporal Logic to Dynamic Epistemic\nLogic</em>, Ph. D. thesis, Indiana University.",
                "\u2013\u2013\u2013, 2008, \u201cTemporal languages for\nepistemic programs\u201d, <em>Journal of Logic, Language and\nInformation</em>, 17(2): 183\u2013216. <span class=\"doi\">doi:10.1007/s10849-007-9054-1</span>",
                "\u2013\u2013\u2013, 2009, \u201cExtending probabilistic\ndynamic epistemic logic\u201d, <em>Synthese</em>, 169(2):\n241\u2013257. <span class=\"doi\">doi:10.1007/s11229-009-9555-3</span>",
                "\u2013\u2013\u2013, 2010, \u201cLogic for update products and\nsteps into the past\u201d, <em>Annals of Pure and Applied Logic</em>,\n161(12): 1431\u20131461. <span class=\"doi\">doi:10.1016/j.apal.2010.04.011</span>",
                "Saraf, S. and S. Sourabh, 2012, \u201cCharacterizing successful\nformulas: the multi-agent case\u201d, E-print 1209.0935, arXiv.org.\n [<a href=\"http://arxiv.org/pdf/1209.0935.pdf\" target=\"other\">Saraf and Sourabh 2012 available online (pdf)</a>]",
                "Seligman, J., F. Liu, and P. Girard, 2011, \u201cLogic in the\ncommunity\u201d, in M. Banerjee and A. Seth (eds.), <em>Logic and Its\nApplications: 4th Indian Conference, ICLA 2011, Delhi, India, January\n5\u201311, 2011, Proceedings</em>, Volume 6521 of <em>Lecture Notes\nin Computer Science</em>, pp. 178\u2013188, Berlin/Heidelberg:\nSpringer. <span class=\"doi\">doi:10.1007/978-3-642-18026-2_15</span>",
                "\u2013\u2013\u2013, 2013, \u201cFacebook and the epistemic\nlogic of friendship\u201d, in B.C. Schipper (ed.), <em>Proceedings of\nthe 14th Conference of Theoretical Aspects of Rationality and\nKnowledge (TARK XIV)</em>, Chennai, India, pp. 229\u2013238.\n [<a href=\"http://tark.org/proceedings/tark_jan7_13/p229-seligman.pdf\" target=\"other\">Seligman, Liu, and Girard 2013 available online (pdf)</a>]",
                "Sietsma, F. and J. van Eijck, 2012, \u201cAction emulation\nbetween canonical models\u201d, in <em>Proceedings of the 10th\nConference on Logic and the Foundations of Game and Decision Theory\n(LOFT 10)</em>, Sevilla, Spain.\n [<a href=\"http://homepages.cwi.nl/~jve/papers/13/pdfs/aecmJournal.pdf\" target=\"other\">Sietsma and van Eijck 2012 available online (pdf)</a>]",
                "Sorensen, R., 2011, \u201cEpistemic paradoxes\u201d, in E.N.\nZalta (ed.), <em>The Stanford Encyclopedia of Philosophy</em> (Spring\n2014 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/spr2014/entries/epistemic-paradoxes/\" target=\"other\">https://plato.stanford.edu/archives/spr2014/entries/epistemic-paradoxes/</a>&gt;",
                "Spohn, W., 1988, \u201cOrdinal conditional functions: A dynamic\ntheory of epistemic states\u201d, in W.L. Harper and B. Skyrms\n(eds.), <em>Causation in Decision, Belief Change, and Statistics:\nProceedings of the Irvine Conference on Probability and\nCausation</em>, Volume 42 of <em>The University of Western Ontario\nSeries in Philosophy of Science</em>, pp. 105\u2013134, Netherlands:\nSpringer. <span class=\"doi\">doi:10.1007/978-94-009-2865-7_6</span>",
                "Stalnaker, R.C., 1980, \u201cA theory of conditionals\u201d, in\nW.L. Harper, R. Stalnaker, and G. Pearce (eds.), <em>IFS:\nConditionals, Belief, Decision, Chance and Time</em>, Volume 15 of\n<em>The University of Western Ontario Series in Philosophy of\nScience</em>, pp. 41\u201355, Netherlands: Springer. <span class=\"doi\">doi:10.1007/978-94-009-9117-0_2</span>",
                "\u2013\u2013\u2013, 2006, \u201cOn logics of knowledge and\nbelief\u201d, <em>Philosophical studies</em>, 128(1): 169\u2013199.\n<span class=\"doi\">doi:10.1007/s11098-005-4062-y</span>",
                "Steiner, D., 2006, \u201cA system for consistency preserving\nbelief change\u201d, in S. Artemov and R. Parikh (eds.),\n<em>Proceedings of the Workshop on Rationality and Knowledge, 18th\nEuropean Summer School in Logic, Language, and Information\n(ESSLLI)</em>, M\u00e1laga, Spain, pp. 133\u2013144.\n [<a href=\"http://www.iam.unibe.ch/til/publications/pubitems/pdfs/ste06.pdf\" target=\"other\">Steiner 2006 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2009, <em>Belief Change Functions for\nMulti-Agent Systems</em>, Ph. D. thesis, Universit\u00e4t Bern.\n [<a href=\"http://www.iam.unibe.ch/tilpub/2009/ste09.pdf\" target=\"other\">Steiner 2009 available online (pdf)</a>]",
                "Steiner, D. and T. Studer, 2007, \u201cTotal public\nannouncements\u201d, in <em>Logical Foundations of Computer Science:\nInternational Symposium, LFCS 2007, New York, NY, USA, June 4\u20137,\n2007, Proceedings</em>, Volume 4514 of <em>Lecture Notes in Computer\nScience</em>, pp. 498\u2013511, Berlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-3-540-72734-7_35</span>",
                "Steup, M., 2005, \u201cEpistemology\u201d, in E.N. Zalta (ed.),\n<em>The Stanford Encyclopedia of Philosophy</em> (Spring 2014\nedition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/spr2014/entries/epistemology/\" target=\"other\">https://plato.stanford.edu/archives/spr2014/entries/epistemology/</a>&gt;",
                "van Benthem, J., 2003, \u201cConditional probability meets update\nlogic\u201d, <em>Journal of Logic, Language and Information</em>,\n12(4): 409\u2013421. <span class=\"doi\">doi:10.1023/A:1025002917675</span>",
                "\u2013\u2013\u2013, 2004, \u201cWhat one may come to\nknow\u201d, <em>Analysis</em>, 64(2): 95\u2013105. <span class=\"doi\">doi:10.1111/j.1467-8284.2004.00467.x</span>",
                "\u2013\u2013\u2013, 2005, \u201cAn essay on sabotage and\nobstruction\u201d, in D. Hutter and W. Stephan (eds.),\n<em>Mechanizing Mathematical Reasoning</em>, Volume 2605 of\n<em>Lecture Notes in Computer Science</em>, pp. 268\u2013276,\nBerlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-3-540-32254-2_16</span>",
                "\u2013\u2013\u2013, 2007, \u201cDynamic logic for belief\nrevision\u201d, <em>Journal of Applied Non-Classical Logics</em>,\n17(2): 129\u2013155. <span class=\"doi\">doi:10.3166/jancl.17.129-155</span>",
                "\u2013\u2013\u2013, 2008a, \u201cFor better of for worse:\nDynamic logics of preference\u201d, Technical Report PP-2008-16,\nInstitute for Logic, Language, Information and Computation (ILLC),\nUniversity of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Reports/PP-2008-16.text.pdf\" target=\"other\">van Benthem 2008a available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2008b, \u201cMerging observation and\naccess in dynamic epistemic logic\u201d, <em>Studies in Logic</em>,\n1(1): 1\u201317.",
                "\u2013\u2013\u2013, 2008c, \u201cMerging observation and\naccess in dynamic logic\u201d, Technical Report PP-2008-36, Institute\nfor Logic, Language, Information and Computation (ILLC), University of\nAmsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Reports/PP-2008-36.text.pdf\" target=\"other\">van Benthem 2008c available online (pdf)</a>]",
                "van Benthem, J., D. Fern\u00e1ndez-Dunque, and E. Pacuit, 2012,\n\u201cEvidence logic: A new look at neighborhood structures\u201d,\nin Bolander et al. 2012: Vol. 9, pp. 97\u2013118.\n [<a href=\"http://www.aiml.net/volumes/volume9/Benthem-Fernandez-Duque-Pacuit.pdf\" target=\"other\">van Benthem, Ferna\u0301ndez-Dunque, and Pacuit 2012 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2014, \u201cEvidence and plausibility in\nneighborhood structures\u201d, <em>Annals of Pure and Applied\nLogic</em>, 165(1): 106\u2013133. <span class=\"doi\">doi:10.1016/j.apal.2013.07.007</span>",
                "van Benthem, J., J. Gerbrandy, T. Hoshi, and E. Pacuit, 2009a,\n\u201cMerging frameworks for interaction\u201d, <em>Journal of\nPhilosophical Logic</em>, 38(5): 491\u2013526. <span class=\"doi\">doi:10.1007/s10992-008-9099-x</span>",
                "van Benthem, J., J. Gerbrandy, and B. Kooi, 2009b, \u201cDynamic\nupdate with probabilities\u201d, <em>Studia Logica</em>, 93(1):\n67\u201396. <span class=\"doi\">doi:10.1007/s11225-009-9209-y</span>",
                "van Benthem, J., J. Gerbrandy, and E. Pacuit, 2007, \u201cMerging\nframeworks for interaction: DEL and ETL\u201d, in D. Samet (ed.),\n<em>Proceedings of the 11th Conference on Theoretical Aspects of\nRationality and Knowledge (TARK XI)</em>, Brussels, Belgium, pp.\n43\u201356.\n [<a href=\"http://www.tark.org/proceedings/tark_jun25_07/p72-van_benthem.pdf\" target=\"other\">van Benthem 2007 available online (pdf)</a>]",
                "van Benthem, J., P. Girard, and O. Roy, 2009c, \u201cEverything\nelse being equal: A modal logic for ceteris paribus\npreferences\u201d, <em>Journal of Philosophical Logic</em>, 38(1):\n83\u2013125. <span class=\"doi\">doi:10.1007/s10992-008-9085-3</span>",
                "van Benthem, J. and D. Ikegami, 2008, \u201cModal fixed-point\nlogic and changing models\u201d, in A. Avron, N. Dershowitz, and A.\nRabinovich (eds.), <em>Pillars of Computer Science: Essays Dedicated\nto Boris (Boaz) Trakhtenbrot on the Occasion of His 85th\nBirthday</em>, Volume 4800 of <em>Lecture Notes in Computer\nScience</em>, pp. 146\u2013165, Berlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-3-540-78127-1_9</span>",
                "van Benthem, J. and F. Liu, 2007, \u201cDynamic logic of\npreference upgrade\u201d, <em>Journal of Applied Non-Classical\nLogics</em>, 17(2): 157\u2013182. <span class=\"doi\">doi:10.3166/jancl.17.157-182</span>",
                "van Benthem, J. and E. Pacuit, 2011a, \u201cDynamic logics of\nevidence-based beliefs\u201d, <em>Studia Logica</em>, 99(1\u20133),\n61\u201392. <span class=\"doi\">doi:10.1007/s11225-011-9347-x</span>",
                "\u2013\u2013\u2013, 2011b, \u201cDynamic logics of\nevidence-based beliefs\u201d, Technical Report PP-2011-19, Institute\nfor Logic, Language, Information and Computation (ILLC), University of\nAmsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Reports/PP-2011-19.text.pdf\" target=\"other\">van Benthem and Pacuit 2011b available online (pdf)</a>]",
                "van Benthem, J., J. van Eijck, and B. Kooi, 2006, \u201cLogics of\ncommunication and change\u201d, <em>Information and Computation</em>,\n204(11): 1620\u20131662. <span class=\"doi\">doi:10.1016/j.ic.2006.04.006</span>",
                "van Benthem, J. and F.R. Vel\u00e1zquez-Quesada, 2010,\n\u201cThe dynamics of awareness\u201d, <em>Synthese</em>, 177(1):\n5\u201327. <span class=\"doi\">doi:10.1007/s11229-010-9764-9</span>",
                "van Ditmarsch, H., 2005, \u201cProlegomena to dynamic logic for\nbelief revision\u201d, <em>Synthese</em>, 147(2): 229\u2013275.\n<span class=\"doi\">doi:10.1007/s11229-005-1349-7</span>",
                "van Ditmarsch, H., J. Eijck, I. Hern\u00e1ndez-Ant\u00f3n, F.\nSietsma, S. Simon, and F. Soler-Toscano, 2012a, \u201cModelling\ncryptographic keys in dynamic epistemic logic with demo\u201d, in\nJ.B. P\u00e9rez, M.A. S\u00e1nchez, P. Mathieu, J.M.C.\nRodr\u00edguez, E. Adam, A. Ortega, M.N. Moreno, E. Navarro, B.\nHirsch, H. Lopes-Cardoso, and V. Juli\u00e1n (eds.), <em>Highlights\non Practical Applications of Agents and Multi-Agent Systems: 10th\nInternational Conference on Practical Applications of Agents and\nMulti-Agent Systems</em>, Volume 156 of <em>Advances in Intelligent\nand Soft Computing</em>, pp. 155\u2013162, Berlin/Heidelberg:\nSpringer. <span class=\"doi\">doi:10.1007/978-3-642-28762-6_19</span>",
                "van Ditmarsch, H. and B. Kooi, 2006, \u201cThe secret of my\nsuccess\u201d, <em>Synthese</em>, 151(2): 201\u2013232. <span class=\"doi\">doi:10.1007/s11229-005-3384-9</span>",
                "van Ditmarsch, H. and J. Ruan, 2007, \u201cModel checking logic\npuzzles\u201d, in <em>Proceedings of Quatri\u00e8mes\nJourn\u00e9es Francophones Mod\u00e8ls Formels de l'Interaction\n(MFI'07)</em>.\n [<a href=\"http://hal.archives-ouvertes.fr/docs/00/18/89/53/PDF/AN8LAMSADE_139-150.pdf\" target=\"other\">van Ditmarsch and Ruan 2007 available online (pdf)</a>]",
                "van Ditmarsch, H., J. Ruan, and R. Verbrugge, 2008, \u201cSum and\nproduct in dynamic epistemic logic\u201d, <em>Journal of Logic and\nComputation</em>, 18(4): 563\u2013588. <span class=\"doi\">doi:10.1093/logcom/exm081</span>",
                "van Ditmarsch, H., W. van der Hoek, and P. Iliev, 2012b, \u201c\nEverything is knowable \u2014 how to get to know whether a\nproposition is true\u201d, <em>Theoria</em>, 78(2): 93\u2013114.\n<span class=\"doi\">doi:10.1111/j.1755-2567.2011.01119.x</span>",
                "van Ditmarsch, H., W. van der Hoek, and B. Kooi, 2005,\n\u201cDynamic epistemic logic with assignment\u201d, in\n<em>Proceedings of the 4th International Conference on Autonomous\nAgents and Multiagent Systems (AAMAS-2005)</em>, Utrecht, The\nNetherlands, pp. 141\u2013148. Association for Computing Machinery\n(ACM), New York, New York, USA. <span class=\"doi\">doi:10.1145/1082473.1082495</span>",
                "\u2013\u2013\u2013, 2007, <em>Dynamic Epistemic Logic</em>,\nVolume 337 of <em>Synthese Library</em>, Netherlands: Springer. <span class=\"doi\">doi:10.1007/978-1-4020-5839-4</span>",
                "van Ditmarsch, H., W. van der Hoek, R. van der Meyden, and J.\nRuan, 2006, \u201cModel checking Russian cards\u201d, in C. Pecheur\nand B. Williams (eds.), <em>Proceedings of the Third Workshop on Model\nChecking and Artificial Intelligence (MoChArt 2005)</em>, Volume 149\nof <em>Electronic Notes in Theoretical Computer Science</em>, pp.\n105\u2013123. <span class=\"doi\">doi:10.1016/j.entcs.2005.07.029</span>",
                "van Ditmarsch, H., J. van Eijck, and W. Wu, 2010a, \u201cOne\nhundred prisoners and a lightbulb \u2014 logic and\ncomputation\u201d, in F. Lin, U. Sattler, and M. Truszczynski (eds.),\n<em>Proceedings of the 12th International Conference on the Principles\nof Knowledge Representation and Reasoning (KR 2010)</em>, Toronto,\nCanada, pp. 90\u2013100. AAAI Press.\n [<a href=\"http://aaai.org/ocs/index.php/KR/KR2010/paper/download/1234/1604\" target=\"other\">van Ditmarsch et al. 2010a available online</a>]",
                "\u2013\u2013\u2013, 2010b, \u201cVerifying one hundred\nprisoners and a lightbulb\u201d, <em>Journal of Applied Non-Classical\nLogics</em>, 20(3): 173\u2013191. <span class=\"doi\">doi:10.3166/jancl.20.173-191</span>",
                "van Eijck, J., 2005, \u201cDynamic epistemic modelling\u201d,\nManuscript version 1.03.\n [<a href=\"http://www.cwi.nl/~jve/demo/DEMO.pdf\" target=\"other\">van Eijck 2005 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2008a, \u201cDemo\u2014a demo of\nepistemic modelling\u201d, in J. van Benthem, B. L\u00f6we, and D.M.\nGabbay (eds.), <em> Interactive Logic: Selected Papers from the 7th\nAugustus de Morgan Workshop, London</em>, Number 1 in Texts in Logic\nand Games, pp. 303\u2013362. Amsterdam University Press. <span class=\"doi\">doi:10.5117/9789053563564</span>\n|\n [<a href=\"http://homepages.cwi.nl/~jve/papers/07/pdfs/DEMO_IL.pdf\" target=\"other\">van Eijck 2008a available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2008b, \u201cYet more modal logics of\npreference change and belief revision\u201d, in K.R. Apt and R. van\nRooij (eds.), <em>New Perspectives on Games and Interaction</em>,\nVolume 4 of <em>Texts in Logic and Games</em>, pp. 81\u2013104.\nAmsterdam University Press.\n [<a href=\"http://homepages.cwi.nl/~jve/papers/08/pdfs/ymml.pdf\" target=\"other\">van Eijck 2008b available online (pdf)</a>]",
                "van Eijck, J. and S. Orzan, 2005, \u201cModelling the epistemics\nof communication with functional programming\u201d, in M. van Eekelen\n(ed.), <em>Proceedings of the 6th Symposium on Trends in Functional\nProgramming (TFP 2005)</em>, pp. 44\u201359.\n [<a href=\"http://www.cs.ioc.ee/tfp-icfp-gpce05/tfp-proc/04num.pdf\" target=\"other\">van Eijck and Orzan 2005 available online (pdf)</a>]",
                "van Eijck, J., J. Ruan, and T. Sadzik, 2012, \u201cAction\nemulation\u201d, <em>Synthese</em>, 185(1): 131\u2013151. <span class=\"doi\">doi:10.1007/s11229-012-0083-1</span>",
                "van Eijck, J. and F. Sietsma, 2010, \u201cMulti-agent belief\nrevision with linked preferences\u201d, in G. Bonanno, B. L\u00f6we,\nand W. Hoek (eds.), <em>Logic and the Foundations of Game and Decision\nTheory \u2014 LOFT 8: 8th International Conference, Amsterdam, The\nNetherlands, July 3\u20135, 2008, Revised Selected Papers</em>,\nVolume 6006 of <em>Lecture Notes in Computer Science</em>, pp.\n174\u2013189, Berlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-3-642-15164-4_9</span>",
                "van Eijck, J. and Y. Wang, 2008, \u201cPropositional dynamic\nlogic as a logic of belief revision\u201d, in W. Hodges and R. de\nQueiroz (eds.), <em>Logic, Language, Information and Computation: 15th\nInternational Workshop, WoLLIC 2008 Edinburgh, UK, July 1\u20134,\n2008 Proceedings</em>, Volume 5110 of <em>Lecture Notes in Computer\nScience</em>, pp. 136\u2013148, Berlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-3-540-69937-8_13</span>",
                "van Fraassen, B.C., 1976, \u201cRepresentational of conditional\nprobabilities\u201d, <em>Journal of Philosophical Logic</em>, 5(3):\n417\u2013430.",
                "\u2013\u2013\u2013, 1995, \u201cFine-grained opinion,\nprobability, and the logic of full belief\u201d, <em>Journal of\nPhilosophical Logic</em>, 24(4): 349\u2013377. <span class=\"doi\">doi:10.1007/BF01048352</span>",
                "Vel\u00e1zquez-Quesada, F.R., 2009, \u201cInference and\nupdate\u201d, <em>Synthese</em>, 169(2): 283\u2013300. <span class=\"doi\">doi:10.1007/s11229-009-9556-2</span>",
                "Visser, A., 1994, \u201cActions under Presuppositions\u201d, in\nJ. van Eijck and A. Visser (eds.), <em>Logic and Information\nFlow</em>, pp. 196\u2013233, Cambridge, MA: MIT Press.",
                "von Wright, G.H., 1963, <em>The Logic of Preference</em>,\nEdinburgh University Press.",
                "Wang, Y. and Q. Cao, 2013, \u201cOn axiomatizations of public\nannouncement logic\u201d, <em>Synthese</em>, 190(1): 103\u2013134.\n<span class=\"doi\">doi:10.1007/s11229-012-0233-5</span>",
                "W\u00e1ng, Y.N. and T. \u00c5gotnes, 2011, \u201cPublic\nannouncement logic with distributed knowledge\u201d, in H. Ditmarsch,\nJ. Lang, and S. Ju (eds.), <em>Logic, Rationality, and Interaction:\nThird International Workshop, LORI 2011, Guangzhou, China, October\n10\u201313, 2011, Proceedings</em>, Volume 6953 of <em>Lecture Notes\nin Computer Science</em>, pp. 328\u2013341, Berlin/Heidelberg:\nSpringer. <span class=\"doi\">doi:10.1007/978-3-642-24130-7_24</span>",
                "\u2013\u2013\u2013, 2013, \u201cPublic announcement logic with\ndistributed knowledge: expressivity, completeness and\ncomplexity\u201d, <em>Synthese</em>, 190(1): 135\u2013162. <span class=\"doi\">doi:10.1007/s11229-012-0243-3</span>",
                "Yamada, T., 2007a, \u201cActs of commanding and changing\nobligations\u201d, in K. Inoue, K. Satoh, and F. Toni (eds.),\n<em>Computational Logic in Multi-Agent Systems: 7th International\nWorkshop, CLIMA VII, Hakodate, Japan, May 8\u20139, 2006, Revised\nSelected and Invited Papers</em>, Volume 4371 of <em>Lecture Notes in\nComputer Science</em>, pp. 1\u201319, Berlin/Heidelberg: Springer.\n<span class=\"doi\">doi:10.1007/978-3-540-69619-3_1</span>",
                "\u2013\u2013\u2013, 2007b, \u201cLogical dynamics of some\nspeech acts that affect obligations and preferences\u201d, in J. van\nBenthem, S. Ju, and F. Veltman (eds.), <em>A Meeting of the Minds:\nProceedings of the Workshop on Logic, Rationality and Interaction,\nBeijing, 2007 (LORI-I)</em>, Volume 8 of <em>Texts in Computer\nScience</em>, pp. 275\u2013290. College Publications.",
                "\u2013\u2013\u2013, 2008, \u201cLogical dynamics of some\nspeech acts that affect obligations and preferences\u201d,\n<em>Synthese</em>, 165(2): 295\u2013315. <span class=\"doi\">doi:10.1007/s11229-008-9368-9</span>",
                "Yap, A., 2006, \u201cProduct update and looking backward\u201d,\nTechnical Report PP-2006-39, Institute for Logic, Language,\nInformation and Computation (ILLC), University of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Reports/PP-2006-39.text.pdf\" target=\"other\">Yap 2006 available online (pdf)</a>]",
                "\u2013\u2013\u2013, 2011, \u201cDynamic epistemic logic and\ntemporal modality\u201d, in Girard et al. 2011: Chapter 3, pp.\n33\u201350. <span class=\"doi\">doi:10.1007/978-94-007-0074-1_3</span>"
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<!--pdf exclude begin-->\n<p class=\"smaller\">\nPlease note that the\n <a href=\"http://philpapers.org/sep/dynamic-epistemic/\" target=\"other\">enhanced bibliography for this entry</a>\n at PhilPapers includes direct links to those articles below that\ninclude digital object identifiers (DOIs). </p>\n<!--pdf exclude end-->\n<ul class=\"hanging\">\n<li>\u00c5gotnes, T., P. Balbiani, H. van Ditmarsch, and P. Seban,\n2010, \u201cGroup announcement logic\u201d, <em>Journal of Applied\nLogic</em>, 8(1): 62\u201381. <span class=\"doi\">doi:10.1016/j.jal.2008.12.002</span></li>\n<li>Alchourr\u00f3n, C.E., P. G\u00e4rdenfors, and D. Makinson,\n1985, \u201cOn the logic of theory change: Partial meet contraction\nand revision functions\u201d, <em>Journal of Symbolic Logic</em>,\n50(2): 510\u2013530. <span class=\"doi\">doi:10.2307/2274239</span></li>\n<li>Andr\u00e9ka, H., I. N\u00e9meti, and J. van Benthem, 1998,\n\u201cModal languages and bounded fragments of predicate\nlogic\u201d, <em>Journal of Philosophical Logic</em>, 27(3):\n217\u2013274. <span class=\"doi\">doi:10.1023/A:1004275029985</span></li>\n<li>Areces, C., R. Fervari, and G. Hoffmann, 2012, \u201cMoving\narrows and four model checking results\u201d, in Ong and Queiroz\n2012: 142\u2013153. <span class=\"doi\">doi:10.1007/978-3-642-32621-9_11</span></li>\n<li>Arl\u00f3-Costa, H. and R. Parikh, 2005, \u201cConditional\nprobability and defeasible inference\u201d, <em>Journal of\nPhilosophical Logic</em>, 34(1): 97\u2013119. <span class=\"doi\">doi:10.1007/s10992-004-5553-6</span></li>\n<li>Artemov, S.N., 2008, \u201cThe logic of justification\u201d,\n<em>The Review of Symbolic Logic</em>, 1(4): 477\u2013513. <span class=\"doi\">doi:10.1017/S1755020308090060</span></li>\n<li>Artemov, S.N. and M. Fitting, 2012, \u201cJustification\nlogic\u201d, in E.N. Zalta (ed.), <em>The Stanford Encyclopedia of\nPhilosophy</em> (Fall 2012 Edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2012/entries/logic-justification/\" target=\"other\">https://plato.stanford.edu/archives/fall2012/entries/logic-justification/</a>&gt;</li>\n<li>Aucher, G., 2003, \u201cA combined system for update logic and\nbelief revision\u201d, Master's thesis, University of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Reports/MoL-2003-03.text.pdf\" target=\"other\">Aucher 2003 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2005, \u201cA combined system for update\nlogic and belief revision\u201d, in <em>Intelligent Agents and\nMulti-Agent Systems: 7th Pacific Rim International Workshop on\nMulti-Agents, PRIMA 2004, Auckland, New Zealand, August 8\u201313,\n2004, Revised Selected Papers</em>, Volume 3371 of <em> Lecture Notes\nin Computer Science</em>, pp. 1\u201317, Berlin/Heidelberg: Springer.\n<span class=\"doi\">doi:10.1007/b107183</span></li>\n<li>\u2013\u2013\u2013, 2008, \u201cConsistency preservation and\ncrazy formulas in BMS\u201d, in S. H\u00f6lldobler, C. Lutz, and H.\nWansing (eds.), <em>Logics in Artificial Intelligence: 11th European\nConference, JELIA 2008, Dresden, Germany, September 28\u2013October\n1, 2008. Proceedings</em>, Volume 5293 of <em>Lecture Notes in\nComputer Science</em>, pp. 21\u201333, Berlin/Heidelberg: Springer.\n<span class=\"doi\">doi:10.1007/978-3-540-87803-2_4</span></li>\n<li>Aucher, G., P. Balbiani, L. Fari\u00f1as del Cerro, and A.\nHerzig, 2009, \u201cGlobal and local graph modifiers\u201d, in C.\nAreces and S. Demri (eds.), <em>Proceedings of the 5th Workshop on\nMethods for Modalities (M4M5 2007)</em>, Volume 231 of <em> Electronic\nNotes in Theoretical Computer Science</em>, Cachan, France, pp.\n293\u2013307. <span class=\"doi\">doi:10.1016/j.entcs.2009.02.042</span></li>\n<li>Aucher, G. and F. Schwarzentruber, 2013, \u201cOn the complexity\nof dynamic epistemic logic\u201d, in B.C. Schipper (ed.),\n<em>Proceedings of the 14th Conference of Theoretical Aspects of\nRationality and Knowledge (TARK XIV)</em>, Chennai, India, pp.\n19\u201328.\n [<a href=\"http://tark.org/proceedings/tark_jan7_13/p19-aucher.pdf\" target=\"other\">Aucher and Schwarzentruber 2013 available online (pdf)</a>]</li>\n<li>Balbiani, P., A. Baltag, H. van Ditmarsch, A. Herzig, T. Hoshi,\nand T. de Lima, 2007, \u201cWhat can we achieve by arbitrary\nannouncements? A dynamic take on Fitch's knowability\u201d, in D.\nSamet (ed.), <em>Proceedings of the 11th Conference on Theoretical\nAspects of Rationality and Knowledge (TARK XI)</em>, Brussels,\nBelgium, pp. 42\u201351.\n [<a href=\"http://tark.org/proceedings/tark_jun25_07/p42-balbiani.pdf\" target=\"other\">Balbiani et al. 2007 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2008, \u201c\u2018Knowable\u2019 as\n\u2018known after an announcement\u2019\u201d, <em>The Review of\nSymbolic Logic</em>, 1(3): 305\u2013334. <span class=\"doi\">doi:10.1016/j.entcs.2006.05.034</span>\n|\n [<a href=\"http://dare.uva.nl/document/2/63109\" target=\"other\">Balbiani et al. 2008 available online (pdf)</a>]</li>\n<li>Balbiani, P., H. van Ditmarsch, A. Herzig, and T. De Lima, 2012,\n\u201cSome truths are best left unsaid\u201d, in Bolander et al.\n2012: Vol. 9, pp. 36\u201354.\n [<a href=\"http://www.aiml.net/volumes/volume9/Balbiani-Ditmarsch-Herzig-Lima.pdf\" target=\"other\">Balbiani et al. 2012 available online (pdf)</a>]</li>\n<li>Ballarin, R., 2010, \u201cModern origins of modal logic\u201d,\nin E.N. Zalta (ed.), <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2014 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/win2014/entries/logic-modal-origins/\" target=\"other\">https://plato.stanford.edu/archives/win2014/entries/logic-modal-origins/</a>&gt;</li>\n<li>Baltag, A. and L.S. Moss, 2004, \u201cLogics for epistemic\nprograms\u201d, <em>Synthese</em>, 139(2): 165\u2013224. <span class=\"doi\">doi:10.1023/B:SYNT.0000024912.56773.5e</span></li>\n<li>Baltag, A., L.S. Moss, and S. Solecki, 1998, \u201cThe logic of\npublic announcements, common knowledge, and private suspicions\u201d,\nin I. Gilboa (ed.), <em>Proceedings of the 7th Conference on\nTheoretical Aspects of Rationality and Knowledge (TARK VII)</em>,\nEvanston, Illinois, USA, pp. 43\u201356.\n [<a href=\"http://www.tark.org/proceedings/tark_jul22_98/p43-baltag.pdf\" target=\"other\">Baltag, Moss, and Solecki 1998 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 1999, \u201cThe logic of public\nannouncements, common knowledge, and private suspicions\u201d,\nTechnical Report TR534 (November), Indiana University.\n [<a href=\"http://www.cs.indiana.edu/pub/techreports/TR534.pdf\" target=\"other\">Baltag, Moss, and Solecki 1999 available online (pdf)</a>]</li>\n<li>Baltag, A., B. Renne, and S. Smets, 2012, \u201cThe logic of\njustified belief change, soft evidence and defeasible\nknowledge\u201d, in Ong and Queiroz 2012: 168\u2013190. <span class=\"doi\">doi:10.1007/978-3-642-32621-9_13</span></li>\n<li>\u2013\u2013\u2013, 2014, \u201cThe logic of justified belief,\nexplicit knowledge, and conclusive evidence\u201d, <em>Annals of Pure\nand Applied Logic</em>, 165(1): 49\u201381. <span class=\"doi\">doi:10.1016/j.apal.2013.07.005</span></li>\n<li>\u2013\u2013\u2013, 2015, \u201cRevisable justified belief:\nPreliminary report\u201d, E-print, arXiv.org. arXiv:1503.08141\n[cs.LO].\n [<a href=\"http://arxiv.org/abs/1503.08141\" target=\"other\">Baltag, Renne, and Smets 2015 available online (html)</a> |\n \n <a href=\"http://arxiv.org/pdf/1503.08141.pdf\" target=\"other\">Baltag, Renne, and Smets 2015 available online (pdf)</a>]</li>\n<li>Baltag, A. and S. Smets, 2008a, \u201cProbabilistic dynamic\nbelief revision\u201d, <em>Synthese</em>, 165(2): 179\u2013202.\n<span class=\"doi\">doi:10.1007/s11229-008-9369-8</span></li>\n<li>\u2013\u2013\u2013, 2008b, \u201cA qualitative theory of\ndynamic interactive belief revision\u201d, in G. Bonanno, W. van der\nHoek, and M. Wooldridge (eds.), <em>TLG 3: Logic and the Foundations\nof Game and Decision Theory (LOFT 7)</em>, Volume 3 of <em>Texts in\nlogic and games</em>, pp. 11\u201358, Amsterdam: Amsterdam University\nPress.\n [<a href=\"http://www.vub.ac.be/CLWF/SS/BeliefRevision-Smets.pdf\" target=\"other\">Baltag and Smets 2008a available online (pdf)</a>]</li>\n<li>Blackburn, P., M. de Rijke, and Y. Venema, 2002, <em>Modal\nLogic</em>, Volume 53 of <em>Cambridge Tracts in Theoretical Computer\nScience</em>, Cambridge: Cambridge University Press.</li>\n<li>Board, O., 2004, \u201cDynamic interactive epistemology\u201d,\n<em>Games and Economic Behavior</em>, 49(1): 49\u201380. <span class=\"doi\">doi:10.1016/j.geb.2003.10.006</span></li>\n<li>Bolander, T., T. Bra\u00fcner, S. Ghilardi, and L.S. Moss (eds.),\n2012, <em>Advances in Modal Logic (AiML)</em>, Copenhagen, Denmark:\nCollege Publications.</li>\n<li>Boutilier, C., 1993, \u201cRevision sequences and nested\nconditionals\u201d, in <em>Proceedings of the 13th International\nJoint Conference on Artificial Intelligence (IJCAI 2011)</em>, Volume\n93, Chamb\u00e9ry, France, pp. 519\u2013531.\n [<a href=\"http://www.ijcai.org/Past%20Proceedings/IJCAI-93-VOL1/PDF/073.pdf\" target=\"other\">Boutilier 1993 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 1995, \u201cOn the revision of\nprobabilistic belief states\u201d, <em>Notre Dame Journal of Formal\nLogic</em>, 36(1): 158\u2013183. <span class=\"doi\">doi:10.1305/ndjfl/1040308833</span></li>\n<li>Brogaard, B. and J. Salerno, 2012, \u201cFitch's paradox of\nknowability\u201d, in E.N. Zalta (ed.), <em>The Stanford Encyclopedia\nof Philosophy</em> (Winter 2013 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/win2013/entries/fitch-paradox/\" target=\"other\">https://plato.stanford.edu/archives/win2013/entries/fitch-paradox/</a>&gt;</li>\n<li>Bucheli, S., R. Kuznets, J. Sack, and T. Studer, 2010,\n\u201cJustified belief change\u201d, in X. Arrazola and M. Ponte\n(eds.), <em>LogKCA-10: Proceedings of the 2nd ILCLI International\nWorkshop on Logic and Philosophy of Knowledge, Communication and\nAction</em>, pp. 135\u2013155. The University of the Basque Country\nPress.\n [<a href=\"http://www.iam.unibe.ch/~tstuder/papers/bkrss-justifiedBeliefChange.pdf\" target=\"other\">Bucheli et al. available online (pdf)</a>]</li>\n<li>Bucheli, S., R. Kuznets, and T. Studer, 2011, \u201cPartial\nrealization in dynamic justification logic\u201d, in L.D. Beklemishev\nand R. de Queiroz (eds.), <em>Logic, Language, Information and\nComputation: 18th International Workshop, WoLLIC 2011, Philadelphia,\nPA, USA, Proceedings</em>, Volume 6642 of <em>Lecture Notes in\nComputer Science</em>, pp. 35\u201351, Berlin/Heidelberg: Springer.\n<span class=\"doi\">doi:10.1007/978-3-642-20920-8_9</span> |\n [<a href=\"http://www.iam.unibe.ch/~tstuder/papers/wollic2011.pdf\" target=\"other\">Bucheli et al. 2011 available online (pdf)</a>]</li>\n<li>Chang, K., 2015, \u201cA math problem from Singapore goes viral:\nWhen is Cheryl's birthday?\u201d <em>The New York Times</em> (15\nApril 2015).\n [<a href=\"http://nyti.ms/1CVmkuP\" target=\"other\">Chang 2015 available online (html)</a>]</li>\n<li>D\u00e9gr\u00e9mont, C., B. L\u00f6we, and A. Witzel, 2011,\n\u201cThe synchronicity of dynamic epistemic logic\u201d, in K.R.\nApt (ed.), <em>Proceedings of the 13th Conference of Theoretical\nAspects of Rationality and Knowledge (TARK XIII)</em>, Groningen, The\nNetherlands, pp. 145\u2013152.\n [<a href=\"http://tark.org/proceedings/tark_jul11_11/p145-degremont.pdf\" target=\"other\">D\u00e9gr\u00e9mont et al. 2011 available online (pdf)</a>]</li>\n<li>Demey, L., B. Kooi, and J. Sack, 2013, \u201cLogic and\nprobability\u201d, in E.N. Zalta (ed.), <em>The Stanford Encyclopedia\nof Philosophy</em> (Fall 2014 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2014/entries/logic-probability/\" target=\"other\">https://plato.stanford.edu/archives/fall2014/entries/logic-probability/</a>&gt;</li>\n<li>Fagin, R., J.Y. Halpern, and N. Megiddo, 1990, \u201cA logic for\nreasoning about probabilities\u201d, <em>Information and\nComputation</em>, 87, 78\u2013128. <span class=\"doi\">doi:10.1016/0890-5401(90)90060-U</span></li>\n<li>Fagin, R., J.Y. Halpern, Y. Moses, and M. Vardi, 1995,\n<em>Reasoning About Knowledge</em>, Cambridge, MA: MIT Press.</li>\n<li>Fervari, R., 2014, <em>Relation-Changing Modal Logics</em>, Ph. D.\nthesis, Facultad de Matem\u00e1tica Astronom\u00eda y\nF\u00edsica, Universidad Nacional de C\u00f3rdoba, C\u00f3rdoba,\nArgentina.</li>\n<li>Fitch, F.B., 1963, \u201cA logical analysis of some value\nconcepts\u201d, <em>The Journal of Symbolic Logic</em>, 28(2):\n135\u2013142.</li>\n<li>French, T., W. van der Hoek, P. Iliev, and B. Kooi, 2011,\n\u201cSuccinctness of epistemic languages\u201d, in <em>Proceedings\nof the 22nd International Joint Conference on Artificial Intelligence\n(IJCAI 2011)</em>, Barcelona, Spain, pp. 881\u2013886. <span class=\"doi\">doi:10.5591/978-1-57735-516-8/IJCAI11-153</span>\n|\n [<a href=\"http://ijcai.org/papers11/Papers/IJCAI11-153.pdf\" target=\"other\">French et al. 2011 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2013, \u201cOn the succinctness of some\nmodal logics\u201d, <em>Artificial Intelligence</em>, 197:\n56\u201385. <span class=\"doi\">doi:10.1016/j.artint.2013.02.003</span></li>\n<li>French, T. and H. van Ditmarsch, 2008, \u201cUndecidability for\narbitrary public announcement logic\u201d, in L. Beklemishev, V.\nGoranko, and V. Shehtman (eds.), <em>Advances in Modal Logic\n(AiML)</em>, Volume 7, Nancy, France, pp. 23\u201342. College\nPublications.\n [<a href=\"http://www.aiml.net/volumes/volume7/French-vanDitmarsch.pdf\" target=\"other\">French and van Ditmarsch 2008 available online (pdf)</a>]</li>\n<li>G\u00e4rdenfors, P., 1988, <em>Knowledge in Flux: Modeling the\nDynamics of Epistemic States</em>, Cambridge, MA: MIT Press.</li>\n<li>Garson, J., 2014, \u201cModal logic\u201d, in E.N. Zalta (ed.),\n<em>The Stanford Encyclopedia of Philosophy</em> (Summer 2014\nedition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/sum2014/entries/logic-modal/\" target=\"other\">https://plato.stanford.edu/archives/sum2014/entries/logic-modal/</a>&gt;</li>\n<li>Gerbrandy, J., 1999, <em>Bisimulations on Planet Kripke</em>, Ph.\nD. thesis, University of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Dissertations/DS-1999-01.text.pdf\" target=\"other\">Gerbrandy 1999 available online (pdf)</a>]</li>\n<li>Gerbrandy, J. and W. Groeneveld, 1997, \u201cReasoning about\ninformation change\u201d, <em>Journal of Logic, Language and\nInformation</em>, 6(2): 147\u2013169. <span class=\"doi\">doi:10.1023/A:1008222603071</span></li>\n<li>Gettier, E., 1963, \u201cIs justified true belief\nknowledge?\u201d <em>Analysis</em>, 23, 121\u2013123.</li>\n<li>Girard, P., 2008, <em>Modal Logic for Belief and Preference\nChange</em>, Ph. D. thesis, University of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Dissertations/DS-2008-04.text.pdf\" target=\"other\">Girard 2008 available online (pdf)</a>]</li>\n<li>Girard, P., O. Roy, and M. Marion (eds.), 2011, <em>Dynamic Formal\nEpistemology</em>, Volume 351 of <em>Synthese Library</em>,\nBerlin/Heidelberg: Springer.</li>\n<li>Girard, P., J. Seligman, and F. Liu, 2012, \u201cGeneral dynamic\ndynamic logic\u201d, in Bolander et al. 2012: Vol. 8, pp.\n239\u2013260.\n [<a href=\"http://www.aiml.net/volumes/volume9/Girard-Seligman-Liu.pdf\" target=\"other\">Girard, Seligman, and Liu 2012 available online (pdf)</a>]</li>\n<li>Grove, A., 1988, \u201cTwo modellings for theory change\u201d,\n<em>Journal of Philosophical Logic</em>, 17(2): 157\u2013170. <span class=\"doi\">doi:10.1007/BF00247909</span></li>\n<li>Halpern, J.Y., 2001, \u201cLexicographic probability, conditional\nprobability, and nonstandard probability\u201d, in J. van Benthem\n(ed.), <em>Proceedings of the 8th Conference on Theoretical Aspects of\nRationality and Knowledge (TARK VIII)</em>, Certosa di Pontignano,\nItaly, pp. 17\u201330.\n [<a href=\"http://tark.org/proceedings/tark_jul8_01/p17-halpern.pdf\" target=\"other\">Halpern 2001 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2003, <em>Reasoning about Uncertainty</em>,\nCambridge, MA: MIT Press.</li>\n<li>Hansson, S.O., 2012, \u201cLogic of belief revision\u201d, in\nE.N. Zalta (ed.), <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2014 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/win2014/entries/logic-belief-revision/\" target=\"other\">https://plato.stanford.edu/archives/win2014/entries/logic-belief-revision/</a>&gt;</li>\n<li>Hendricks, V. and J. Symons, 2006, \u201cEpistemic logic\u201d,\nin E.N. Zalta (ed.), <em>The Stanford Encyclopedia of Philosophy</em>\n(Fall 2015 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/fall2015/entries/logic-epistemic/\" target=\"other\">https://plato.stanford.edu/archives/fall2015/entries/logic-epistemic/</a>&gt;</li>\n<li>Hintikka, J., 1962, <em>Knowledge and belief: an introduction to\nthe logic of the two notions</em>, Cornell: Cornell University\nPress.</li>\n<li>Holliday, W.H., T. Hoshi, and T.F. Icard, III, 2012, \u201cA\nuniform logic of information dynamics\u201d, in Bolander et al. 2012:\nVol. 8, pp. 348\u2013367.\n [<a href=\"http://www.aiml.net/volumes/volume9/Holliday-Hoshi-Icard.pdf\" target=\"other\">Holliday et al. 2012 available online (pdf)</a>]</li>\n<li>Holliday, W.H. and T.F. Icard, III, 2010, \u201cMoorean phenomena\nin epistemic logic\u201d, in L. Beklemishev, V. Goranko, and V.\nShehtman (eds.), <em>Advances in Modal Logic (AiML)</em>, Volume 8,\nMoscow, Russia, pp. 178\u2013199. College Publications.\n [<a href=\"http://www.aiml.net/volumes/volume8/Holliday-Icard.pdf\" target=\"other\">Holliday and Icard 2010 available online (pdf)</a>]</li>\n<li>Hoshi, T., 2008, \u201cPublic announcement logics with\nconstrained protocols\u201d, in <em>Proceedings of the 8th Conference\non Logic and the Foundations of Game and Decision Theory (LOFT\n8)</em>, Amsterdam, The Netherlands.\n [<a href=\"http://www.illc.uva.nl/LOFT2008/Papers/Hoshi.pdf\" target=\"other\">Hoshi 2008 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2009, <em>Epistemic dynamics and protocol\ninformation</em>, Ph. D. thesis, Stanford University.\n [<a href=\"http://www.illc.uva.nl/Research/Dissertations/DS-2009-08.text.pdf\" target=\"other\">Hoshi 2009 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2010, \u201cMerging DEL and ETL\u201d,\n<em>Journal of Logic, Language and Information</em>, 19(4):\n413\u2013430. <span class=\"doi\">doi:10.1007/s10849-009-9116-7</span></li>\n<li>Hoshi, T. and A. Yap, 2009, \u201cDynamic epistemic logic with\nbranching temporal structures\u201d, <em>Synthese</em>, 169(2):\n259\u2013281. <span class=\"doi\">doi:10.1007/s11229-009-9552-6</span></li>\n<li>Katsuno, H. and A.O. Mendelzon, 1991, \u201cPropositional\nknowledge base revision and minimal change\u201d, <em>Artificial\nIntelligence</em>, 52(3): 263\u2013294. <span class=\"doi\">doi:10.1016/0004-3702(91)90069-V</span></li>\n<li>Kooi, B., 2003, \u201cProbabilistic dynamic epistemic\nlogic\u201d, <em>Journal of Logic, Language and Information</em>,\n12(4): 381\u2013408. <span class=\"doi\">doi:10.1023/A:1025050800836</span></li>\n<li>\u2013\u2013\u2013, 2007, \u201cExpressivity and completeness\nfor public update logics via reduction axioms\u201d, <em>Journal of\nApplied Non-Classical Logics</em>, 17(2): 231\u2013253. <span class=\"doi\">doi:10.3166/jancl.17.231-253</span></li>\n<li>Kooi, B. and B. Renne, 2011a, \u201cArrow update logic\u201d,\n<em>Review of Symbolic Logic</em>, 4(4): 536\u2013559. <span class=\"doi\">doi:10.1017/S1755020311000189</span>\n</li>\n<li>\u2013\u2013\u2013, 2011b, \u201cGeneralized arrow update\nlogic\u201d, in K.R. Apt (ed.), <em>Proceedings of the 13th\nConference of Theoretical Aspects of Rationality and Knowledge (TARK\nXIII)</em>, Groningen, The Netherlands, pp. 205\u2013211.\n [<a href=\"http://www.tark.org/proceedings/tark_jul11_11/p205-kooi.pdf\" target=\"other\">Kooi and Renne 2011b available online (pdf)</a>]</li>\n<li>Kooi, B. and J. van Benthem, 2004, \u201cReduction axioms for\nepistemic actions\u201d, in R. Schmidt, I. Pratt-Hartmann, M.\nReynolds, and H. Wansing (eds.), <em>AiML-2004: Advances in Modal\nLogic (Preliminary Proceedings)</em>, Manchester, UK, pp.\n197\u2013211.\n [<a href=\"https://www.rug.nl/research/portal/files/2960510/extendedabstract.pdf\" target=\"other\">Kooi and van Benthem 2003 available online (pdf)</a>]</li>\n<li>Lehrer, K., 1990, <em>Theory of Knowledge</em>, Routledge.</li>\n<li>\u2013\u2013\u2013, 2000, <em>Theory of Knowledge</em>,\nWestview Press.</li>\n<li>Lehrer, K. and J. Paxson, T., 1969, \u201cKnowledge: Undefeated\njustified true belief\u201d, <em>Journal of Philosophy</em>, 66,\n225\u2013237.</li>\n<li>Liu, F., 2008, <em>Changing for the better: Preference dynamics\nand agent diversity</em>, Ph. D. thesis, University of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Dissertations/DS-2008-02.text.pdf\" target=\"other\">Liu 2008 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2010, \u201cVon Wright's \u2018The logic\nof preference\u2019 revisited\u201d, <em>Synthese</em>, 175(1):\n69\u201388. <span class=\"doi\">doi:10.1007/s11229-009-9530-z</span></li>\n<li>\u2013\u2013\u2013, 2011, <em>Reasoning about preference\ndynamics</em>, Volume 354 of <em> Synthese Library</em>,\nBerlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-94-007-1344-4</span></li>\n<li>Lutz, C., 2006, \u201cComplexity and succinctness of public\nannouncement logic\u201d, in <em>Proceedings of the 5th International\nConference on Autonomous Agents and Multiagent Systems\n(AAMAS-2006)</em>, Hakodate, Japan, pp. 137\u2013144. Association for\nComputing Machinery (ACM), New York, New York, USA. <span class=\"doi\">doi:10.1145/1160633.1160657</span></li>\n<li>Miller, J.S. and L.S. Moss, 2005, \u201cThe undecidability of\niterated modal relativization\u201d, <em>Studia Logica</em>, 79(3):\n373\u2013407. <span class=\"doi\">doi:10.1007/s11225-005-3612-9</span></li>\n<li>Ong, L. and R. de Queiroz (eds.), 2012, <em>Logic, Language,\nInformation and Computation: 19th International Workshop, WoLLIC 2012,\nBuenos Aires, Argentina, September 3\u20136, 2012, Proceedings</em>,\nVolume 7456 of <em> Lecture Notes in Computer Science</em>,\nBerlin/Heidelberg: Springer-Verlag.</li>\n<li>Parikh, R. and R. Ramanujam, 2003, \u201cA knowledge based\nsemantics of messages\u201d, <em>Journal of Logic, Language and\nInformation</em>, 12(4): 453\u2013467. <span class=\"doi\">doi:10.1023/A:1025007018583</span></li>\n<li>Peppas, P., 2008, \u201cBelief revision\u201d, in F. van\nHarmelen, V. Lifschitz, and B. Porter (eds.), <em>Handbook of\nKnowledge Representation</em>, Volume 3 of <em>Foundations of\nArtificial Intelligence</em>, Chapter 8, pp. 317\u2013359, Amsterdam,\nThe Netherlands: Elsevier. <span class=\"doi\">doi:10.1016/S1574-6526(07)03008-8</span></li>\n<li>Plaza, J., 1989, \u201cLogics of public communications\u201d, in\nM.L. Emrich, M.S. Pfeifer, M. Hadzikadic, and Z.W. Ras (eds.),\n<em>Proceedings of the 4th International Symposium on Methodologies\nfor Intelligent Systems (ISMIS 1989): Poster Session Program</em>,\nCharlotte, North Carolina, USA, pp. 201\u2013216. Oak Ridge National\nLaboratory ORNL/DSRD-24.</li>\n<li>\u2013\u2013\u2013, 2007, \u201cLogics of public\ncommunications\u201d, <em>Synthese</em>, 158(2): 165\u2013179. <span class=\"doi\">doi:10.1007/s11229-007-9168-7</span></li>\n<li>Popper, K., 2002 [1935], <em>The Logic of Scientific\nDiscovery</em>, London, United Kingdom: Routledge Classics. First\npublished in 1935 as <em>Logik der Forschung</em>, Vienna: Verlag von\nJulius Springer.</li>\n<li>Renardel de Lavalette, G.R., 2004, \u201cChanging\nmodalities\u201d, <em>Journal of Logic and Computation</em>, 14(2):\n251\u2013275. <span class=\"doi\">doi:10.1093/logcom/14.2.251</span></li>\n<li>Renne, B., 2008, \u201cPublic and private communication are\ndifferent: Results on relative expressivity\u201d, <em>Synthese</em>,\n165(2): 225\u2013245. <span class=\"doi\">doi:10.1007/s11229-008-9395-6</span></li>\n<li>\u2013\u2013\u2013, 2009, \u201cEvidence elimination in\nmulti-agent justification logic\u201d, in A. Heifetz (ed.),\n<em>Proceedings of the 12th Conference of Theoretical Aspects of\nRationality and Knowledge (TARK XII)</em>, Stanford, California, USA,\npp. 227\u2013236. <span class=\"doi\">doi:10.1145/1562814.1562845</span></li>\n<li>\u2013\u2013\u2013, 2011a, \u201cPublic communication in\njustification logic\u201d, <em>Journal of Logic and Computation</em>,\n21(6): 1005\u20131034. <span class=\"doi\">doi:10.1093/logcom/exq026</span></li>\n<li>\u2013\u2013\u2013, 2011b, \u201cSimple evidence elimination\nin justification logic\u201d, in Girard et al. 2011: Chapter 7, pp.\n127\u2013149. <span class=\"doi\">doi:10.1007/978-94-007-0074-1_7</span></li>\n<li>\u2013\u2013\u2013, 2012, \u201cMulti-agent justification\nlogic: Communication and evidence elimination\u201d,\n<em>Synthese</em>, 185(S1), 43\u201382. <span class=\"doi\">doi:10.1007/s11229-011-9968-7</span>\n</li>\n<li>Renne, B., J. Sack, and A. Yap, 2009, \u201cDynamic epistemic\ntemporal logic\u201d, in X. He, J. Horty, and E. Pacuit (eds.),\n<em>Logic, Rationality, and Interaction: Second International\nWorkshop, LORI 2009, Chongqing, China, October 8\u201311, 2009,\nProceedings</em>, Volume 5834 of <em>Lecture Notes in Computer\nScience</em>, pp. 263\u2013277, Berlin/Heidelberg: Springer-Verlag.\n<span class=\"doi\">doi:10.1007/978-3-642-04893-7_21</span></li>\n<li>\u2013\u2013\u2013, 2015, \u201cLogics of temporal-epistemic\nactions\u201d, <em>Synthese</em>. <span class=\"doi\">doi:10.1007/s11229-015-0773-6</span>.\n [<a href=\"http://link.springer.com/article/10.1007%2Fs11229-015-0773-6\" target=\"other\">Renne, Sack, and Yap available online</a>]\n <!-- this is open access from SpringerLink--></li>\n<li>R\u00e9nyi, A., 1955, \u201cOn a new axiomatic theory of\nprobability\u201d, <em>Acta Mathematica Hungarica</em>, 6(3\u20134),\n285\u2013335. <span class=\"doi\">doi:10.1007/BF02024393</span></li>\n<li>\u2013\u2013\u2013, 1964, \u201cSur les espaces simples des\nprobabilit\u00e9s conditionnelles\u201d, in <em>Annales de\nl'institut Henri Poincar\u00e9 (B) Probabilit\u00e9s et\nStatistiques</em>, Volume 1, pp. 3\u201321.\n [<a href=\"http://eudml.org/doc/76848\" target=\"other\">R\u00e9nyi 1964 available online</a>]</li>\n<li>Roelofsen, F., 2007, \u201cDistributed knowledge\u201d,\n<em>Journal of Applied Non-Classical Logics</em>, 17(2):\n255\u2013273. <span class=\"doi\">doi:10.3166/jancl.17.255-273</span></li>\n<li>Rott, H., 1989, \u201cConditionals and theory change: Revisions,\nexpansions, and additions\u201d, <em>Synthese</em>, 81(1):\n91\u2013113. <span class=\"doi\">doi:10.1007/BF00869346</span></li>\n<li>Sack, J., 2007, <em>Adding Temporal Logic to Dynamic Epistemic\nLogic</em>, Ph. D. thesis, Indiana University.</li>\n<li>\u2013\u2013\u2013, 2008, \u201cTemporal languages for\nepistemic programs\u201d, <em>Journal of Logic, Language and\nInformation</em>, 17(2): 183\u2013216. <span class=\"doi\">doi:10.1007/s10849-007-9054-1</span></li>\n<li>\u2013\u2013\u2013, 2009, \u201cExtending probabilistic\ndynamic epistemic logic\u201d, <em>Synthese</em>, 169(2):\n241\u2013257. <span class=\"doi\">doi:10.1007/s11229-009-9555-3</span></li>\n<li>\u2013\u2013\u2013, 2010, \u201cLogic for update products and\nsteps into the past\u201d, <em>Annals of Pure and Applied Logic</em>,\n161(12): 1431\u20131461. <span class=\"doi\">doi:10.1016/j.apal.2010.04.011</span></li>\n<li>Saraf, S. and S. Sourabh, 2012, \u201cCharacterizing successful\nformulas: the multi-agent case\u201d, E-print 1209.0935, arXiv.org.\n [<a href=\"http://arxiv.org/pdf/1209.0935.pdf\" target=\"other\">Saraf and Sourabh 2012 available online (pdf)</a>]</li>\n<li>Seligman, J., F. Liu, and P. Girard, 2011, \u201cLogic in the\ncommunity\u201d, in M. Banerjee and A. Seth (eds.), <em>Logic and Its\nApplications: 4th Indian Conference, ICLA 2011, Delhi, India, January\n5\u201311, 2011, Proceedings</em>, Volume 6521 of <em>Lecture Notes\nin Computer Science</em>, pp. 178\u2013188, Berlin/Heidelberg:\nSpringer. <span class=\"doi\">doi:10.1007/978-3-642-18026-2_15</span></li>\n<li>\u2013\u2013\u2013, 2013, \u201cFacebook and the epistemic\nlogic of friendship\u201d, in B.C. Schipper (ed.), <em>Proceedings of\nthe 14th Conference of Theoretical Aspects of Rationality and\nKnowledge (TARK XIV)</em>, Chennai, India, pp. 229\u2013238.\n [<a href=\"http://tark.org/proceedings/tark_jan7_13/p229-seligman.pdf\" target=\"other\">Seligman, Liu, and Girard 2013 available online (pdf)</a>]</li>\n<li>Sietsma, F. and J. van Eijck, 2012, \u201cAction emulation\nbetween canonical models\u201d, in <em>Proceedings of the 10th\nConference on Logic and the Foundations of Game and Decision Theory\n(LOFT 10)</em>, Sevilla, Spain.\n [<a href=\"http://homepages.cwi.nl/~jve/papers/13/pdfs/aecmJournal.pdf\" target=\"other\">Sietsma and van Eijck 2012 available online (pdf)</a>]</li>\n<li>Sorensen, R., 2011, \u201cEpistemic paradoxes\u201d, in E.N.\nZalta (ed.), <em>The Stanford Encyclopedia of Philosophy</em> (Spring\n2014 edition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/spr2014/entries/epistemic-paradoxes/\" target=\"other\">https://plato.stanford.edu/archives/spr2014/entries/epistemic-paradoxes/</a>&gt;</li>\n<li>Spohn, W., 1988, \u201cOrdinal conditional functions: A dynamic\ntheory of epistemic states\u201d, in W.L. Harper and B. Skyrms\n(eds.), <em>Causation in Decision, Belief Change, and Statistics:\nProceedings of the Irvine Conference on Probability and\nCausation</em>, Volume 42 of <em>The University of Western Ontario\nSeries in Philosophy of Science</em>, pp. 105\u2013134, Netherlands:\nSpringer. <span class=\"doi\">doi:10.1007/978-94-009-2865-7_6</span></li>\n<li>Stalnaker, R.C., 1980, \u201cA theory of conditionals\u201d, in\nW.L. Harper, R. Stalnaker, and G. Pearce (eds.), <em>IFS:\nConditionals, Belief, Decision, Chance and Time</em>, Volume 15 of\n<em>The University of Western Ontario Series in Philosophy of\nScience</em>, pp. 41\u201355, Netherlands: Springer. <span class=\"doi\">doi:10.1007/978-94-009-9117-0_2</span></li>\n<li>\u2013\u2013\u2013, 2006, \u201cOn logics of knowledge and\nbelief\u201d, <em>Philosophical studies</em>, 128(1): 169\u2013199.\n<span class=\"doi\">doi:10.1007/s11098-005-4062-y</span></li>\n<li>Steiner, D., 2006, \u201cA system for consistency preserving\nbelief change\u201d, in S. Artemov and R. Parikh (eds.),\n<em>Proceedings of the Workshop on Rationality and Knowledge, 18th\nEuropean Summer School in Logic, Language, and Information\n(ESSLLI)</em>, M\u00e1laga, Spain, pp. 133\u2013144.\n [<a href=\"http://www.iam.unibe.ch/til/publications/pubitems/pdfs/ste06.pdf\" target=\"other\">Steiner 2006 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2009, <em>Belief Change Functions for\nMulti-Agent Systems</em>, Ph. D. thesis, Universit\u00e4t Bern.\n [<a href=\"http://www.iam.unibe.ch/tilpub/2009/ste09.pdf\" target=\"other\">Steiner 2009 available online (pdf)</a>]</li>\n<li>Steiner, D. and T. Studer, 2007, \u201cTotal public\nannouncements\u201d, in <em>Logical Foundations of Computer Science:\nInternational Symposium, LFCS 2007, New York, NY, USA, June 4\u20137,\n2007, Proceedings</em>, Volume 4514 of <em>Lecture Notes in Computer\nScience</em>, pp. 498\u2013511, Berlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-3-540-72734-7_35</span></li>\n<li>Steup, M., 2005, \u201cEpistemology\u201d, in E.N. Zalta (ed.),\n<em>The Stanford Encyclopedia of Philosophy</em> (Spring 2014\nedition).\n URL=&lt;<a href=\"https://plato.stanford.edu/archives/spr2014/entries/epistemology/\" target=\"other\">https://plato.stanford.edu/archives/spr2014/entries/epistemology/</a>&gt;</li>\n<li>van Benthem, J., 2003, \u201cConditional probability meets update\nlogic\u201d, <em>Journal of Logic, Language and Information</em>,\n12(4): 409\u2013421. <span class=\"doi\">doi:10.1023/A:1025002917675</span></li>\n<li>\u2013\u2013\u2013, 2004, \u201cWhat one may come to\nknow\u201d, <em>Analysis</em>, 64(2): 95\u2013105. <span class=\"doi\">doi:10.1111/j.1467-8284.2004.00467.x</span></li>\n<li>\u2013\u2013\u2013, 2005, \u201cAn essay on sabotage and\nobstruction\u201d, in D. Hutter and W. Stephan (eds.),\n<em>Mechanizing Mathematical Reasoning</em>, Volume 2605 of\n<em>Lecture Notes in Computer Science</em>, pp. 268\u2013276,\nBerlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-3-540-32254-2_16</span></li>\n<li>\u2013\u2013\u2013, 2007, \u201cDynamic logic for belief\nrevision\u201d, <em>Journal of Applied Non-Classical Logics</em>,\n17(2): 129\u2013155. <span class=\"doi\">doi:10.3166/jancl.17.129-155</span></li>\n<li>\u2013\u2013\u2013, 2008a, \u201cFor better of for worse:\nDynamic logics of preference\u201d, Technical Report PP-2008-16,\nInstitute for Logic, Language, Information and Computation (ILLC),\nUniversity of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Reports/PP-2008-16.text.pdf\" target=\"other\">van Benthem 2008a available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2008b, \u201cMerging observation and\naccess in dynamic epistemic logic\u201d, <em>Studies in Logic</em>,\n1(1): 1\u201317.</li>\n<li>\u2013\u2013\u2013, 2008c, \u201cMerging observation and\naccess in dynamic logic\u201d, Technical Report PP-2008-36, Institute\nfor Logic, Language, Information and Computation (ILLC), University of\nAmsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Reports/PP-2008-36.text.pdf\" target=\"other\">van Benthem 2008c available online (pdf)</a>]</li>\n<li>van Benthem, J., D. Fern\u00e1ndez-Dunque, and E. Pacuit, 2012,\n\u201cEvidence logic: A new look at neighborhood structures\u201d,\nin Bolander et al. 2012: Vol. 9, pp. 97\u2013118.\n [<a href=\"http://www.aiml.net/volumes/volume9/Benthem-Fernandez-Duque-Pacuit.pdf\" target=\"other\">van Benthem, Ferna\u0301ndez-Dunque, and Pacuit 2012 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2014, \u201cEvidence and plausibility in\nneighborhood structures\u201d, <em>Annals of Pure and Applied\nLogic</em>, 165(1): 106\u2013133. <span class=\"doi\">doi:10.1016/j.apal.2013.07.007</span></li>\n<li>van Benthem, J., J. Gerbrandy, T. Hoshi, and E. Pacuit, 2009a,\n\u201cMerging frameworks for interaction\u201d, <em>Journal of\nPhilosophical Logic</em>, 38(5): 491\u2013526. <span class=\"doi\">doi:10.1007/s10992-008-9099-x</span></li>\n<li>van Benthem, J., J. Gerbrandy, and B. Kooi, 2009b, \u201cDynamic\nupdate with probabilities\u201d, <em>Studia Logica</em>, 93(1):\n67\u201396. <span class=\"doi\">doi:10.1007/s11225-009-9209-y</span></li>\n<li>van Benthem, J., J. Gerbrandy, and E. Pacuit, 2007, \u201cMerging\nframeworks for interaction: DEL and ETL\u201d, in D. Samet (ed.),\n<em>Proceedings of the 11th Conference on Theoretical Aspects of\nRationality and Knowledge (TARK XI)</em>, Brussels, Belgium, pp.\n43\u201356.\n [<a href=\"http://www.tark.org/proceedings/tark_jun25_07/p72-van_benthem.pdf\" target=\"other\">van Benthem 2007 available online (pdf)</a>]</li>\n<li>van Benthem, J., P. Girard, and O. Roy, 2009c, \u201cEverything\nelse being equal: A modal logic for ceteris paribus\npreferences\u201d, <em>Journal of Philosophical Logic</em>, 38(1):\n83\u2013125. <span class=\"doi\">doi:10.1007/s10992-008-9085-3</span></li>\n<li>van Benthem, J. and D. Ikegami, 2008, \u201cModal fixed-point\nlogic and changing models\u201d, in A. Avron, N. Dershowitz, and A.\nRabinovich (eds.), <em>Pillars of Computer Science: Essays Dedicated\nto Boris (Boaz) Trakhtenbrot on the Occasion of His 85th\nBirthday</em>, Volume 4800 of <em>Lecture Notes in Computer\nScience</em>, pp. 146\u2013165, Berlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-3-540-78127-1_9</span></li>\n<li>van Benthem, J. and F. Liu, 2007, \u201cDynamic logic of\npreference upgrade\u201d, <em>Journal of Applied Non-Classical\nLogics</em>, 17(2): 157\u2013182. <span class=\"doi\">doi:10.3166/jancl.17.157-182</span></li>\n<li>van Benthem, J. and E. Pacuit, 2011a, \u201cDynamic logics of\nevidence-based beliefs\u201d, <em>Studia Logica</em>, 99(1\u20133),\n61\u201392. <span class=\"doi\">doi:10.1007/s11225-011-9347-x</span></li>\n<li>\u2013\u2013\u2013, 2011b, \u201cDynamic logics of\nevidence-based beliefs\u201d, Technical Report PP-2011-19, Institute\nfor Logic, Language, Information and Computation (ILLC), University of\nAmsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Reports/PP-2011-19.text.pdf\" target=\"other\">van Benthem and Pacuit 2011b available online (pdf)</a>]</li>\n<li>van Benthem, J., J. van Eijck, and B. Kooi, 2006, \u201cLogics of\ncommunication and change\u201d, <em>Information and Computation</em>,\n204(11): 1620\u20131662. <span class=\"doi\">doi:10.1016/j.ic.2006.04.006</span></li>\n<li>van Benthem, J. and F.R. Vel\u00e1zquez-Quesada, 2010,\n\u201cThe dynamics of awareness\u201d, <em>Synthese</em>, 177(1):\n5\u201327. <span class=\"doi\">doi:10.1007/s11229-010-9764-9</span></li>\n<li>van Ditmarsch, H., 2005, \u201cProlegomena to dynamic logic for\nbelief revision\u201d, <em>Synthese</em>, 147(2): 229\u2013275.\n<span class=\"doi\">doi:10.1007/s11229-005-1349-7</span></li>\n<li>van Ditmarsch, H., J. Eijck, I. Hern\u00e1ndez-Ant\u00f3n, F.\nSietsma, S. Simon, and F. Soler-Toscano, 2012a, \u201cModelling\ncryptographic keys in dynamic epistemic logic with demo\u201d, in\nJ.B. P\u00e9rez, M.A. S\u00e1nchez, P. Mathieu, J.M.C.\nRodr\u00edguez, E. Adam, A. Ortega, M.N. Moreno, E. Navarro, B.\nHirsch, H. Lopes-Cardoso, and V. Juli\u00e1n (eds.), <em>Highlights\non Practical Applications of Agents and Multi-Agent Systems: 10th\nInternational Conference on Practical Applications of Agents and\nMulti-Agent Systems</em>, Volume 156 of <em>Advances in Intelligent\nand Soft Computing</em>, pp. 155\u2013162, Berlin/Heidelberg:\nSpringer. <span class=\"doi\">doi:10.1007/978-3-642-28762-6_19</span></li>\n<li>van Ditmarsch, H. and B. Kooi, 2006, \u201cThe secret of my\nsuccess\u201d, <em>Synthese</em>, 151(2): 201\u2013232. <span class=\"doi\">doi:10.1007/s11229-005-3384-9</span></li>\n<li>van Ditmarsch, H. and J. Ruan, 2007, \u201cModel checking logic\npuzzles\u201d, in <em>Proceedings of Quatri\u00e8mes\nJourn\u00e9es Francophones Mod\u00e8ls Formels de l'Interaction\n(MFI'07)</em>.\n [<a href=\"http://hal.archives-ouvertes.fr/docs/00/18/89/53/PDF/AN8LAMSADE_139-150.pdf\" target=\"other\">van Ditmarsch and Ruan 2007 available online (pdf)</a>]</li>\n<li>van Ditmarsch, H., J. Ruan, and R. Verbrugge, 2008, \u201cSum and\nproduct in dynamic epistemic logic\u201d, <em>Journal of Logic and\nComputation</em>, 18(4): 563\u2013588. <span class=\"doi\">doi:10.1093/logcom/exm081</span></li>\n<li>van Ditmarsch, H., W. van der Hoek, and P. Iliev, 2012b, \u201c\nEverything is knowable \u2014 how to get to know whether a\nproposition is true\u201d, <em>Theoria</em>, 78(2): 93\u2013114.\n<span class=\"doi\">doi:10.1111/j.1755-2567.2011.01119.x</span></li>\n<li>van Ditmarsch, H., W. van der Hoek, and B. Kooi, 2005,\n\u201cDynamic epistemic logic with assignment\u201d, in\n<em>Proceedings of the 4th International Conference on Autonomous\nAgents and Multiagent Systems (AAMAS-2005)</em>, Utrecht, The\nNetherlands, pp. 141\u2013148. Association for Computing Machinery\n(ACM), New York, New York, USA. <span class=\"doi\">doi:10.1145/1082473.1082495</span></li>\n<li>\u2013\u2013\u2013, 2007, <em>Dynamic Epistemic Logic</em>,\nVolume 337 of <em>Synthese Library</em>, Netherlands: Springer. <span class=\"doi\">doi:10.1007/978-1-4020-5839-4</span></li>\n<li>van Ditmarsch, H., W. van der Hoek, R. van der Meyden, and J.\nRuan, 2006, \u201cModel checking Russian cards\u201d, in C. Pecheur\nand B. Williams (eds.), <em>Proceedings of the Third Workshop on Model\nChecking and Artificial Intelligence (MoChArt 2005)</em>, Volume 149\nof <em>Electronic Notes in Theoretical Computer Science</em>, pp.\n105\u2013123. <span class=\"doi\">doi:10.1016/j.entcs.2005.07.029</span></li>\n<li>van Ditmarsch, H., J. van Eijck, and W. Wu, 2010a, \u201cOne\nhundred prisoners and a lightbulb \u2014 logic and\ncomputation\u201d, in F. Lin, U. Sattler, and M. Truszczynski (eds.),\n<em>Proceedings of the 12th International Conference on the Principles\nof Knowledge Representation and Reasoning (KR 2010)</em>, Toronto,\nCanada, pp. 90\u2013100. AAAI Press.\n [<a href=\"http://aaai.org/ocs/index.php/KR/KR2010/paper/download/1234/1604\" target=\"other\">van Ditmarsch et al. 2010a available online</a>]</li>\n<li>\u2013\u2013\u2013, 2010b, \u201cVerifying one hundred\nprisoners and a lightbulb\u201d, <em>Journal of Applied Non-Classical\nLogics</em>, 20(3): 173\u2013191. <span class=\"doi\">doi:10.3166/jancl.20.173-191</span></li>\n<li>van Eijck, J., 2005, \u201cDynamic epistemic modelling\u201d,\nManuscript version 1.03.\n [<a href=\"http://www.cwi.nl/~jve/demo/DEMO.pdf\" target=\"other\">van Eijck 2005 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2008a, \u201cDemo\u2014a demo of\nepistemic modelling\u201d, in J. van Benthem, B. L\u00f6we, and D.M.\nGabbay (eds.), <em> Interactive Logic: Selected Papers from the 7th\nAugustus de Morgan Workshop, London</em>, Number 1 in Texts in Logic\nand Games, pp. 303\u2013362. Amsterdam University Press. <span class=\"doi\">doi:10.5117/9789053563564</span>\n|\n [<a href=\"http://homepages.cwi.nl/~jve/papers/07/pdfs/DEMO_IL.pdf\" target=\"other\">van Eijck 2008a available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2008b, \u201cYet more modal logics of\npreference change and belief revision\u201d, in K.R. Apt and R. van\nRooij (eds.), <em>New Perspectives on Games and Interaction</em>,\nVolume 4 of <em>Texts in Logic and Games</em>, pp. 81\u2013104.\nAmsterdam University Press.\n [<a href=\"http://homepages.cwi.nl/~jve/papers/08/pdfs/ymml.pdf\" target=\"other\">van Eijck 2008b available online (pdf)</a>]</li>\n<li>van Eijck, J. and S. Orzan, 2005, \u201cModelling the epistemics\nof communication with functional programming\u201d, in M. van Eekelen\n(ed.), <em>Proceedings of the 6th Symposium on Trends in Functional\nProgramming (TFP 2005)</em>, pp. 44\u201359.\n [<a href=\"http://www.cs.ioc.ee/tfp-icfp-gpce05/tfp-proc/04num.pdf\" target=\"other\">van Eijck and Orzan 2005 available online (pdf)</a>]</li>\n<li>van Eijck, J., J. Ruan, and T. Sadzik, 2012, \u201cAction\nemulation\u201d, <em>Synthese</em>, 185(1): 131\u2013151. <span class=\"doi\">doi:10.1007/s11229-012-0083-1</span></li>\n<li>van Eijck, J. and F. Sietsma, 2010, \u201cMulti-agent belief\nrevision with linked preferences\u201d, in G. Bonanno, B. L\u00f6we,\nand W. Hoek (eds.), <em>Logic and the Foundations of Game and Decision\nTheory \u2014 LOFT 8: 8th International Conference, Amsterdam, The\nNetherlands, July 3\u20135, 2008, Revised Selected Papers</em>,\nVolume 6006 of <em>Lecture Notes in Computer Science</em>, pp.\n174\u2013189, Berlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-3-642-15164-4_9</span></li>\n<li>van Eijck, J. and Y. Wang, 2008, \u201cPropositional dynamic\nlogic as a logic of belief revision\u201d, in W. Hodges and R. de\nQueiroz (eds.), <em>Logic, Language, Information and Computation: 15th\nInternational Workshop, WoLLIC 2008 Edinburgh, UK, July 1\u20134,\n2008 Proceedings</em>, Volume 5110 of <em>Lecture Notes in Computer\nScience</em>, pp. 136\u2013148, Berlin/Heidelberg: Springer. <span class=\"doi\">doi:10.1007/978-3-540-69937-8_13</span></li>\n<li>van Fraassen, B.C., 1976, \u201cRepresentational of conditional\nprobabilities\u201d, <em>Journal of Philosophical Logic</em>, 5(3):\n417\u2013430.</li>\n<li>\u2013\u2013\u2013, 1995, \u201cFine-grained opinion,\nprobability, and the logic of full belief\u201d, <em>Journal of\nPhilosophical Logic</em>, 24(4): 349\u2013377. <span class=\"doi\">doi:10.1007/BF01048352</span></li>\n<li>Vel\u00e1zquez-Quesada, F.R., 2009, \u201cInference and\nupdate\u201d, <em>Synthese</em>, 169(2): 283\u2013300. <span class=\"doi\">doi:10.1007/s11229-009-9556-2</span></li>\n<li>Visser, A., 1994, \u201cActions under Presuppositions\u201d, in\nJ. van Eijck and A. Visser (eds.), <em>Logic and Information\nFlow</em>, pp. 196\u2013233, Cambridge, MA: MIT Press.</li>\n<li>von Wright, G.H., 1963, <em>The Logic of Preference</em>,\nEdinburgh University Press.</li>\n<li>Wang, Y. and Q. Cao, 2013, \u201cOn axiomatizations of public\nannouncement logic\u201d, <em>Synthese</em>, 190(1): 103\u2013134.\n<span class=\"doi\">doi:10.1007/s11229-012-0233-5</span></li>\n<li>W\u00e1ng, Y.N. and T. \u00c5gotnes, 2011, \u201cPublic\nannouncement logic with distributed knowledge\u201d, in H. Ditmarsch,\nJ. Lang, and S. Ju (eds.), <em>Logic, Rationality, and Interaction:\nThird International Workshop, LORI 2011, Guangzhou, China, October\n10\u201313, 2011, Proceedings</em>, Volume 6953 of <em>Lecture Notes\nin Computer Science</em>, pp. 328\u2013341, Berlin/Heidelberg:\nSpringer. <span class=\"doi\">doi:10.1007/978-3-642-24130-7_24</span></li>\n<li>\u2013\u2013\u2013, 2013, \u201cPublic announcement logic with\ndistributed knowledge: expressivity, completeness and\ncomplexity\u201d, <em>Synthese</em>, 190(1): 135\u2013162. <span class=\"doi\">doi:10.1007/s11229-012-0243-3</span></li>\n<li>Yamada, T., 2007a, \u201cActs of commanding and changing\nobligations\u201d, in K. Inoue, K. Satoh, and F. Toni (eds.),\n<em>Computational Logic in Multi-Agent Systems: 7th International\nWorkshop, CLIMA VII, Hakodate, Japan, May 8\u20139, 2006, Revised\nSelected and Invited Papers</em>, Volume 4371 of <em>Lecture Notes in\nComputer Science</em>, pp. 1\u201319, Berlin/Heidelberg: Springer.\n<span class=\"doi\">doi:10.1007/978-3-540-69619-3_1</span></li>\n<li>\u2013\u2013\u2013, 2007b, \u201cLogical dynamics of some\nspeech acts that affect obligations and preferences\u201d, in J. van\nBenthem, S. Ju, and F. Veltman (eds.), <em>A Meeting of the Minds:\nProceedings of the Workshop on Logic, Rationality and Interaction,\nBeijing, 2007 (LORI-I)</em>, Volume 8 of <em>Texts in Computer\nScience</em>, pp. 275\u2013290. College Publications.</li>\n<li>\u2013\u2013\u2013, 2008, \u201cLogical dynamics of some\nspeech acts that affect obligations and preferences\u201d,\n<em>Synthese</em>, 165(2): 295\u2013315. <span class=\"doi\">doi:10.1007/s11229-008-9368-9</span></li>\n<li>Yap, A., 2006, \u201cProduct update and looking backward\u201d,\nTechnical Report PP-2006-39, Institute for Logic, Language,\nInformation and Computation (ILLC), University of Amsterdam.\n [<a href=\"http://www.illc.uva.nl/Research/Reports/PP-2006-39.text.pdf\" target=\"other\">Yap 2006 available online (pdf)</a>]</li>\n<li>\u2013\u2013\u2013, 2011, \u201cDynamic epistemic logic and\ntemporal modality\u201d, in Girard et al. 2011: Chapter 3, pp.\n33\u201350. <span class=\"doi\">doi:10.1007/978-94-007-0074-1_3</span></li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "belief, formal representations of",
            "common knowledge",
            "epistemic paradoxes",
            "epistemology",
            "Fitch\u2019s paradox of knowability",
            "logic, history of: modal logic",
            "logic: and probability",
            "logic: classical",
            "logic: conditionals",
            "logic: epistemic",
            "logic: justification",
            "logic: modal",
            "logic: of belief revision",
            "logic: temporal"
        ],
        "entry_link": [
            {
                "../formal-belief/": "belief, formal representations of"
            },
            {
                "../common-knowledge/": "common knowledge"
            },
            {
                "../epistemic-paradoxes/": "epistemic paradoxes"
            },
            {
                "../epistemology/": "epistemology"
            },
            {
                "../fitch-paradox/": "Fitch\u2019s paradox of knowability"
            },
            {
                "../logic-modal-origins/": "logic, history of: modal logic"
            },
            {
                "../logic-probability/": "logic: and probability"
            },
            {
                "../logic-classical/": "logic: classical"
            },
            {
                "../logic-conditionals/": "logic: conditionals"
            },
            {
                "../logic-epistemic/": "logic: epistemic"
            },
            {
                "../logic-justification/": "logic: justification"
            },
            {
                "../logic-modal/": "logic: modal"
            },
            {
                "../logic-belief-revision/": "logic: of belief revision"
            },
            {
                "../logic-temporal/": "logic: temporal"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<td valign=\"top\"><img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=dynamic-epistemic\" target=\"other\">How to cite this entry</a>.",
            "<td valign=\"top\"><img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/dynamic-epistemic/\" target=\"other\">Preview the PDF version of this entry</a> at the\n<a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<td valign=\"top\"><img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=dynamic-epistemic\u2227redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<td valign=\"top\"><img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"http://philpapers.org/sep/dynamic-epistemic/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"http://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=dynamic-epistemic": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/dynamic-epistemic/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=dynamic-epistemic\u2227redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "http://philpapers.org/sep/dynamic-epistemic/": "Enhanced bibliography for this entry"
            },
            {
                "http://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [],
        "listed_links": []
    }
}