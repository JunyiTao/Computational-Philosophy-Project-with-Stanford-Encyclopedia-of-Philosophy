{
    "url": "reasoning-defeasible",
    "title": "Defeasible Reasoning",
    "authorship": {
        "year": "Copyright \u00a9 2021",
        "author_text": "Robert Koons\n<koons@mail.utexas.edu>",
        "author_links": [
            {
                "https://liberalarts.utexas.edu/philosophy/faculty/koons": "Robert Koons"
            },
            {
                "mailto:koons%40mail%2eutexas%2eedu": "koons@mail.utexas.edu"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2021</a> by\n\n<br/>\n<a href=\"https://liberalarts.utexas.edu/philosophy/faculty/koons\" target=\"other\">Robert Koons</a>\n&lt;<a href=\"mailto:koons%40mail%2eutexas%2eedu\"><em>koons<abbr title=\" at \">@</abbr>mail<abbr title=\" dot \">.</abbr>utexas<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Fri Jan 21, 2005",
        "substantive revision Fri Jun 25, 2021"
    ],
    "preamble": "\n\nReasoning is defeasible when the corresponding argument is\nrationally compelling but not deductively valid. The truth of the\npremises of a good defeasible argument provide support for the\nconclusion, even though it is possible for the premises to be true and\nthe conclusion false. In other words, the relationship of support\nbetween premises and conclusion is a tentative one, potentially\ndefeated by additional information. Philosophers have studied the\nnature of defeasible reasoning since Aristotle\u2019s analysis of\ndialectical reasoning in the Topics and the\nPosterior Analytics, but the subject has been studied with\nunique intensity over the last forty years, largely due to the\ninterest it attracted from the artificial intelligence movement in\ncomputer science. There have been two approaches to the study of\nreasoning: treating it either as a branch of epistemology (the study\nof knowledge) or as a branch of logic. In recent work, the term\ndefeasible reasoning has typically been limited to inferences\ninvolving rough-and-ready, exception-permitting generalizations, that\nis, inferring what has or will happen on the basis of what\nnormally happens. This narrower sense of defeasible\nreasoning, which will be the subject of this article, excludes\nfrom the topic the study of other forms of non-deductive reasoning,\nincluding inference to the best explanation, abduction, analogical\nreasoning, and scientific induction. This exclusion is to some extent\nartificial, but it reflects the fact that the formal study of these\nother forms of non-deductive reasoning remains quite rudimentary. \n",
    "toc": [
        {
            "#Hist": "1. History"
        },
        {
            "#Phil": "1.1 Philosophy"
        },
        {
            "#ArtiInte": "1.2 Artificial Intelligence"
        },
        {
            "#ApplMoti": "2. Applications and Motivation"
        },
        {
            "#DefeConvComm": "2.1 Defeasibility as a Convention of Communication"
        },
        {
            "#AutoReas": "2.2 Autoepistemic Reasoning"
        },
        {
            "#SemaForGeneProg": "2.3 Semantics for Generics and the Progressive"
        },
        {
            "#DefeReas": "2.4 Defeasible Reasons"
        },
        {
            "#DefeObli": "2.5 Defeasible Obligations"
        },
        {
            "#DefeLawsNatuScieProg": "2.6 Defeasible Laws of Nature and Scientific Programs"
        },
        {
            "#DefePrinMetaEpis": "2.7 Defeasible Principles in Metaphysics and Epistemology"
        },
        {
            "#OccaRazoAssuClosWorl": "2.8 Occam\u2019s Razor and the Assumption of a \u201cClosed World\u201d"
        },
        {
            "#VariAppr": "3. Varieties of Approaches"
        },
        {
            "#EpisAppr": "4. Epistemological Approaches"
        },
        {
            "#FormEpis": "4.1 Formal Epistemology"
        },
        {
            "#SemaInheNetw": "4.2 Semantic Inheritance Networks"
        },
        {
            "#BeliReviTheo": "4.3 Belief Revision Theory"
        },
        {
            "#FormArgTheor": "4.4 Formal Argumentation Theory"
        },
        {
            "#LogiAppr": "5. Logical Approaches"
        },
        {
            "#RelaLogiCons": "5.1 Relations of Logical Consequence"
        },
        {
            "#MetaDesi": "5.2 Metalogical Desiderata"
        },
        {
            "#DefaLogi": "5.3 Default Logic"
        },
        {
            "#NonmLogiIAutoLogi": "5.4 Nonmonotonic Logic I and Autoepistemic Logic"
        },
        {
            "#Circ": "5.5 Circumscription"
        },
        {
            "#PrefLogi": "5.6 Preferential Logics"
        },
        {
            "#LogiExtrProb": "5.7 Logics of Extreme Probabilities"
        },
        {
            "#FullExprLangCondLogiHighOrdeProb": "5.8 Fully Expressive Languages: Conditional Logics and Higher-Order Probabilities"
        },
        {
            "#ObjeNonmLogi": "5.9 Objections to Nonmonotonic Logic"
        },
        {
            "#CausDefeReas": "6. Causation and Defeasible Reasoning"
        },
        {
            "#NeedForExplCausInfo": "6.1 The Need for Explicit Causal Information"
        },
        {
            "#CausGrouIndeRela": "6.2 Causally Grounded Independence Relations"
        },
        {
            "#CausCirc": "6.3 Causal Circumscription"
        },
        {
            "#ImplAppl": "7. Implementations and Applications"
        },
        {
            "#ApplLaw": "7.1 Applications to Law"
        },
        {
            "#ReasProb": "7.2 Reasoning about Probabilities"
        },
        {
            "#Software": "7.3 Software Applications"
        },
        {
            "#EffUpdat": "7.4 Efficiency in Updating"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. History\n\nDefeasible reasoning has been the subject of study by both\nphilosophers and computer scientists (especially those involved in the\nfield of artificial intelligence). The philosophical history of the\nsubject goes back to Aristotle, while the field of artificial\nintelligence has greatly intensified interest in it over the last\nforty years.\n1.1 Philosophy\n\nAccording to Aristotle, deductive logic (especially in the form of the\nsyllogism) plays a central role in the articulation of scientific\nunderstanding, deducing observable phenomena from definitions of\nnatures that hold universally and without exception. However, in the\npractical matters of everyday life, we rely upon generalizations that\nhold only \u201cfor the most part\u201d, under normal circumstances,\nand the application of such common sense generalizations involves\nmerely dialectical reasoning, reasoning that is defeasible\nand falls short of deductive validity. Aristotle lays out a large\nnumber and great variety of examples of such reasoning in his work\nentitled the Topics.\n\nInvestigations in logic after Aristotle (from later antiquity through\nthe twentieth century) seem to have focused exclusively on deductive\nlogic. This continued to be true as the predicate logic was developed\nby Peirce, Frege, Russell, Whitehead, and others in the late\nnineteenth and early twentieth centuries. With the collapse of logical\npositivism in the mid-twentieth century (and the abandonment of\nattempts to treat the physical world as a logical construction from\nfacts about sense data), new attention was given to the relationship\nbetween sense perception and the external world. Roderick Chisholm\n(Chisholm 1957; Chisholm 1966) argued that sensory appearances give\ngood, but defeasible, reasons for believing in corresponding facts\nabout the physical world. If I am \u201cappeared to redly\u201d\n(have the sensory experience as of being in the presence of something\nred), then, Chisholm argued, I may presume that I really am in the\npresence of something red. This presumption can, of course, be\ndefeated, if, for example, I learn that my environment is relevantly\nabnormal (for instance, all the ambient light is red).\n\nH. L. A. Hart (Hart 1951), at a 1949 meeting of the Aristotelian\nSociety, noted the centrality of defeasible reasoning in the law,\nespecially within the Anglo-American common law tradition. Hart\npointed out that judges must take into account exceptional\ncircumstances in which a legal principle cannot be applied at all or\nmust be applied in a weakened form. Hart refers explicitly to\nconditions that can  defeat (Hart 1951, p. 175) the claim\nthat a contract exists, even when the standard definition of\n\u2018contract\u2019 is satisfied. A defeasible logic is needed\nbecause a judge is required to make a judgment on the basis of an\nincomplete set of facts: those facts that are presented to the judge\nby the two parties as germane to the claim.\n\nThe idea of defeasibility also showed up in work on the formal theory\nof argumentation, including Stephen Toulmin\u2019s  The Uses of\nArgument (Toulmin 1964). Toulmin, building on Hart\u2019s\nobservations, argues for the importance of distinguishing between\nwarrants and rebuttals (Toulmin 1964, 101ff, 143ff). The formal theory\nof argumentation (van Eemeren et al. 2020; Prakken and Vreeswijk 2002)\nhas proved a fruitful ground for the development of models of\ndefeasible reasoning.\n\nJohn L. Pollock developed Chisholm\u2019s idea into a theory of\nprima facie reasons and defeaters of those reasons\n(Pollock 1967, 1970, 1974, 1987, 1995, 2010). Pollock distinguished\nbetween two kinds of defeaters of a defeasible inference:\nrebutting defeaters (which give one a prima facie reason for\nbelieving the denial of the original conclusion) and\n undercutting defeaters\n (which give one a reason for doubting that the usual relationship\nbetween the premises and the conclusion hold in the given case).\nAccording to Pollock, a conclusion is warranted, given all of\none\u2019s evidence, if it is supported by an ultimately undefeated\nargument whose premises are drawn from that evidence.\n1.2 Artificial Intelligence\n\nAs the subdiscipline of artificial intelligence took shape in the\n1960s, pioneers like John M. McCarthy and Patrick J. Hayes soon\ndiscovered the need to represent and implement the sort of defeasible\nreasoning that had been identified by Aristotle and Chisholm. McCarthy\nand Hayes (McCarthy and Hayes 1969) developed a formal language they\ncalled the \u201csituation calculus,\u201d for use by expert systems\nattempting to model changes and interactions among a domain of objects\nand actors. McCarthy and Hayes encountered what they called the\nframe problem: the problem of deciding which conditions will\nnot change in the wake of an event. They required a\ndefeasible principle of inertia: the presumption that any given\ncondition will not change, unless required to do so by actual events\nand dynamic laws. In addition, they encountered the qualification\nproblem: the need for a presumption that an action can be\nsuccessfully performed, once a short list of essential prerequisites\nhave been met. McCarthy (McCarthy 1977, 1038\u20131044) suggested\nthat the solution lay in a logical principle of\ncircumscription: the presumption that the actual situation is\nas unencumbered with abnormalities and oddities (including unexplained\nchanges and unexpected interferences) as is consistent with our\nknowledge of it. (McCarthy 1982; McCarthy 1986) In effect, McCarthy\nsuggests that it is warranted to believe whatever is true in all the\nminimal (or otherwise preferred) models of\none\u2019s initial information set.\n\nIn the early 1980s, several systems of defeasible reasoning were\nproposed by others in the field of artificial intelligence: Ray\nReiter\u2019s default logic (Reiter 1980; Etherington and Reiter\n1983, 104\u2013108), McDermott and Doyle\u2019s Non-Monotonic Logic\nI (McDermott and Doyle, 1982), Robert C. Moore\u2019s Autoepistemic\nLogic (Moore 1985), and Hector Levesque\u2019s formalization of the\n\u201call I know\u201d operator (Levesque 1990). These early\nproposals involved the search for a kind of fixed point or\ncognitive equilibrium. Special rules (called default rules by\nReiter) permit drawing certain conclusions so long as these\nconclusions are consistent with what one knows, including all that one\nknows on the basis of these very default rules. In some cases, no such\nfixed point exists, and, in others, there are multiple, mutually\ninconsistent fixed points. In addition, these systems were procedural\nor computational in nature, in contrast to the semantic\ncharacterization of warranted conclusions (in terms of preferred\nmodels) in McCarthy\u2019s circumscription system. Later work in\nartificial intelligence has tended to follow McCarthy\u2019s lead in\nthis respect.\n2. Applications and Motivation\n\nPhilosophers and theorists of artificial intelligence have found a\nwide variety of applications for defeasible reasoning. In some cases,\nthe defeasibility seems to be grounded in some aspect of the subject\nor the context of communication, and in other cases in facts about the\nobjective world. The first includes defeasible rules as communicative\nor representational conventions and autoepistemic (reasoning\nabout one\u2019s own knowledge and lack of knowledge). The latter,\nthe objective sources of defeasibility, include defeasible\nobligations, defeasible laws of nature, induction, abduction, and\nOckham\u2019s razor (the presumption that the world is as\nuncomplicated as possible).\n2.1 Defeasibility as a Convention of Communication\n\nMuch of John McCarthy\u2019s early work in artificial intelligence\nconcerned the interpretation of stories and puzzles (McCarthy and\nHayes 1969; McCarthy 1977). McCarthy found that we often make\nassumptions based on what is not said. So, for example, in a puzzle\nabout safely crossing a river by canoe, we assume that there are no\nbridges or other means of conveyance available. Similarly, when using\na database to store and convey information, the information that, for\nexample, no flight is scheduled at a certain time is represented\nsimply by not listing such a flight. Inferences based on\nthese conventions are defeasible, however, because the conventions can\nthemselves be explicitly abrogated or suspended.\n\nNicholas Asher and his collaborators (Lascarides and Asher 1993, Asher\nand Lascarides 2003, Vieu, Bras, Asher, and Aurnague 2005, Txurruka\nand Asher 2008) have argued that defeasible reasoning is useful in\nunpacking the pragmatics of conversational implicature.\n2.2 Autoepistemic Reasoning\n\nRobert C. Moore (Moore 1985) pointed out that we sometimes infer\nthings about the world based on our not knowing certain\nthings. So, for instance, I might infer that I do not have a sister,\nsince, if I did, I would certainly know it, and I do not in fact know\nthat I have a sister. Such an inference is, of course, defeasible,\nsince if I subsequently learn that I have a sister after all, the\nbasis for the original inference is nullified.\n2.3 Semantics for Generics and the Progressive\n\nGeneric terms (like birds in Birds fly) are\nexpressed in English by means of bare common noun phrases (without\ndeterminer). Adverbs like normally and typically are\nalso indicators of generic predication. As Asher and Pelletier (Asher\nand Pelletier 1997) have argued, the semantics for such sentences\nseems to involve intentionality: a generic sentence can be true even\nif the majority of the kind, or even all of the kind, fail to conform\nto the generalization. It can be true that birds fly even if, as a\nresult of a freakish accident, all surviving birds are abnormally\nflightless. A promising semantic theory for the generic is to\nrepresent generic predication by means of a defeasible rule or\nconditional.\n\nThe progressive verb involves a similar kind of intentionality. (Asher\n1992) If Jones is crossing the street, then it would normally\nbe the case that Jones will succeed in crossing the street.\nHowever, this inference is clearly defeasible: Jones might be hit by a\ntruck midway across and never complete the crossing.\n2.4 Defeasible Reasons\n\nJonathan Dancy (Dancy 1993, 2004) has developed and defended an\nanti-Humean conception of practical reasoning, according to which it\nis the facts themselves, and not our desires, aversions, or other\nattitudes towards those facts, that constitute reasons for\nacting. These facts consist of particulars\u2019 having\nproperties, and those properties provide in each such case some reason\nfor acting--as, for example, someone\u2019s need can provide a reason\nfor meeting that need. However, each general property can provide a\nreason only defeasibly: not only can a reason be overwhelmed by\ncontrary considerations, but a property\u2019s valence for action can\nbe completely neutralized or even reversed by further considerations.\nFor example, even if giving pleasure is in general a reason in favor\nof acting in a certain way, the fact that some action would give\npleasure to those pleased by the suffering of others is a reason \nagainst and not for so acting. Dancy has introduced (in Dancy\n2004) the concepts of intensifiers and attenuators,\napplying to facts that strengthen or weaken the force of reasons. In\nthe extreme case, a fact can disable a reason altogether,\ncorresponding to what Joseph Raz had described as an exclusionary\nreason (Raz 1975), and to John Pollock\u2019s idea of an\n undercutting defeater.\n\nTo the extent that our practical reasoning is guided at all by general\nrules or principles (something that Dancy explicitly denies), the\nreasoning must be defeasible, as John Horty has argued (Horty 2007b).\nFrom this perspective, Dancy\u2019s thesis of moral\nparticularism corresponds to the potential defeasibility of all\ngeneral reasons (see Lance and Little 2004, 2007). Defeasible logic\ncan enable general rules to play an indispensable role despite the\nreasons holism that Dancy has uncovered.\n\nIn addition, defeasible reasoning can be used to illuminate moral and\nlegal dilemmas, cases in which general rules come into conflict (see\nHorty 1994, 2003). This can be done without attributing logical\ninconsistency to the conflicting rules and without treating the\nconflict as merely apparent, i.e., as due to an incomplete\nrepresentation of the rules.\n2.5 Defeasible Obligations\n\nPhilosophers have, for quite some time, been interested in defeasible\nobligations, which give rise to defeasible inferences about what we\nare, all things considered, obliged to do. David Ross, in 1930,\ndiscussed the phenomena of prima facie obligations (Ross\n1930, 1939). The existence of a prima facie obligation gives one good,\nbut defeasible grounds, for believing that one ought to fulfill that\nobligation. When formal deontic logic was developed by\nChisholm and others in the 1960s (Chisholm 1963), the use of classical\nlogic gave rise to certain paradoxes, such as Chisholm\u2019s paradox\nof contrary-to-duty imperatives. These paradoxes can be resolved by\nrecognizing that the inference from imperative to actual duty is a\ndefeasible one (Asher and Bonevac 1996; Nute 1997). \n\nSuch defeasible obligations can also appear in the domain of law: see\nPrakken and Sartor 1995 and 1996.\n2.6 Defeasible Laws of Nature and Scientific Programs\n\nPhilosophers David M. Armstrong and Nancy Cartwright have argued that\nthe actual laws of nature are oaken rather than iron\n(to use Armstrong\u2019s terms). (Armstrong 1983; Armstrong 1997,\n230\u2013231; Cartwright 1983). Oaken laws admit of exceptions: they\nhave tacit ceteris paribus (other things being equal) or\nceteris absentibus (other things being absent) conditions. As\nCartwright points out, an inference based on such a law of nature is\nalways defeasible, since we may discover that additional\nphenomenological factors must be added to the law in question\nin special cases. \n\nThere are several reasons to think that deductive logic is not an\nadequate tool for dealing with this phenomenon. In order to apply\ndeduction to the laws and the initial conditions, the laws must be\nrepresented in a form that admits of no exceptions. This would require\nexplicitly stating each potentially relevant condition in the\nantecedent of each law-stating conditional. This is impractical, not\nonly because it makes the statement of each and every law extremely\ncumbersome, but also because we know that there are many exceptional\ncases that we have not yet encountered and may not be able to imagine.\nDefeasible laws enable us to express what we really know to be the\ncase, rather than forcing us to pretend that we can make an exhaustive\nlist of all the possible exceptions.\n\nMore recently, Tohm\u00e9, Delrieux, and Bueno (2011) have argued\nthat defeasible reasoning is crucial to the understanding of\nscientific research programs.\n2.7 Defeasible Principles in Metaphysics and Epistemology\n\nMany classical philosophical arguments, especially those in the\nperennial philosophy that endured from Plato and Aristotle to the end\nof scholasticism, can be fruitfully reconstructed by means of\ndefeasible logic. Metaphysical principles, like the laws of nature,\nmay hold in normal cases, while admitting of occasional exceptions.\nThe principle of causality, for example, that plays a central role in\nthe cosmological argument for God\u2019s existence, can plausibly\nconstrued as a defeasible generalization (Koons 2001).\n\nAs discussed above (in section 1.1), prima facie reasons and defeaters\nof those reasons play a central role in contemporary epistemology, not\nonly in relation to perceptual knowledge, but also in relation to\nevery other source of knowledge: memory, imagination (as an indicator\nof possibility) and testimony, at the very least. In each cases, an\nimpression or appearance provides good but defeasible evidence of a\ncorresponding reality.\n2.8 Occam\u2019s Razor and the Assumption of a \u201cClosed World\u201d\n\nPrediction always involves an element of defeasibility. If one predicts\nwhat will, or what would, under some hypothesis, happen, one must\npresume that there are no unknown factors that might interfere with\nthose factors and conditions that are known. Any prediction can be\nupset by such unanticipated interventions. Prediction thus proceeds\nfrom the assumption that the situation as modeled constitutes a\nclosed world: that nothing outside that situation could\nintrude in time to upset one\u2019s predictions. In addition, we seem\nto presume that any factor that is not known to be causally relevant\nis in fact causally irrelevant, since we are constantly encountering\nnew factors and novel combinations of factors, and it is impossible to\nverify their causal irrelevance in advance. This closed-world\nassumption is one of the principal motivations for McCarthy\u2019s\nlogic of circumscription (McCarthy 1982; McCarthy 1986).\n3. Varieties of Approaches\n\nWe can treat the study of defeasible reasoning either (i) as a branch\nof epistemology (the theory of knowledge), or (ii) as a branch of\nlogic. In the epistemological approach, defeasible reasoning can be\nstudied as a form of inference, that is, as a process by which we add\nto our stock of knowledge. Alternatively, we could\ntreat defeat as a relation between arguments in a\ndisputational discourse.  In either version, the epistemological\napproach is concerned with the obtaining, maintaining, and\ntransmission of warrant, with the question of when an\ninference, starting with justified or warranted beliefs, produces a\nnew belief that is also warranted, given potential defeaters. This\napproach focuses explicitly on the norms of belief persistence and\nchange.\n\nIn contrast, a logical approach to defeasible reasoning fastens on a\nrelationship between propositions or possible bodies of information.\nJust as deductive logic consists of the study of a certain\nconsequence relation between propositions or sets of\npropositions (the relation of valid implication), so defeasible (or\nnonmonotonic) logic consists of the study of a different kind\nof consequence relation. Deductive consequence is monotonic: if a set\nof premises logically entails a conclusion, than any superset (any set\nof premises that includes all of the first set) will also entail that\nsome conclusion. In contrast, defeasible consequence is nonmonotonic.\nA conclusion follows defeasibly or nonmonotonically from a set of\npremises just in case it is true in nearly all of the models\nthat verify the premises, or in the most normal models that\ndo.\n\nThe two approaches are related. In particular, a logical theory of\ndefeasible consequence will have epistemological consequences. It is\npresumably true that an ideally rational thinker will have a set of\nbeliefs that are closed under defeasible, as well as deductive,\nconsequence. However, a logical theory of defeasible consequence would\nhave a wider scope of application than a merely epistemological theory\nof inference. Defeasible logic would provide a mechanism for engaging\nin hypothetical reasoning, not just reasoning from actual\nbeliefs.\n\nConversely, as David Makinson and Peter G\u00e4rdenfors have pointed\nout (Makinson and G\u00e4rdenfors 1991, 185\u2013205; Makinson 2005),\nan epistemological theory of belief change can be used to define a set\nof nonmonotonic consequence relations (one relation for each initial\nbelief state). We can define the consequence relation \\(\\alpha\n\\dproves \\beta\\), for a given set of beliefs \\(T\\), as holding just in\ncase the result of adding belief \\(\\alpha\\) to \\(T\\) would include\nbelief in \\(\\beta\\). However, on this approach, there would be many\ndistinct nonmonotonic consequence relations, instead of a single\nperspective-independent one.\n\nAnd, as Phan Minh Dung has argued (Dung 1995), formal argumentation\ncan also be used to provide a basis for defining a nonmonotonic\nconsequence relation. A formal argument structure \\(F\\) is an ordered\npair \\(\u27e8A, B\u27e9\\), where \\(A\\) is a set of arguments, and \\(B\\) is a\nbinary relation on \\(A\\) (the attack relation). Then we can\nsay that an argument structure \\(F\\) has \\(p\\) has a consequence just\nin case \\(p\\) is the conclusion of some argument in the\noptimal extension of \\(F\\) (which can be defined in a variety\nof ways--see section 4.4).\n4. Epistemological Approaches\n\nThere are have been four versions of the epistemological approach,\neach of which attempts to define how an cognitively ideal agent\narrives at warranted conclusions, given an initial input. The first\ntwo of these, John L. Pollock\u2019s theory of defeasible reasoning\nand the theory of semantic inheritance networks, are explicitly\ncomputational in nature. They take as input a complex, structured\nstate, representing the data available to the agent, and they define a\nprocedure by which new conclusions can be warranted. The third\napproach, based on the theory of belief change (the AGM model)\ndeveloped by Alchourr\u00f3n, G\u00e4rdenfors, and Makinson\n(Alchourr\u00f3n, G\u00e4rdenfors, and Makinson 1982), instead lays\ndown a set of conditions that an ideal process of belief change ought\nto satisfy. The AGM model can be used to define a nonmonotonic\nconsequence relation that is temporary and local. This can represent\nreasoning that is hypothetically or counterfactually defeasible, in\nthe sense that what \u201cfollows\u201d from a conjunctive\nproposition \\((p \\amp q)\\) need not be a superset of what\n\u201cfollows\u201d from \\(p\\) alone. The fourth approach is that of\nformal argumentation theory, in which defeat is treated as a\nrelation between arguments within a dialogue\n4.1 Formal Epistemology\n\nJohn Pollock\u2019s approach to defeasible reasoning consists of\nenumerating a set of rules that are constructive and effectively\ncomputable, and that aim at describing how an ideal cognitive agent\nbuilds up a rich set of beliefs, beginning with a relatively sparse\ndata set (consisting of beliefs about immediate sensory appearances,\napparent memories, and such things). The inferences involved are not,\nfor the most part, deductive. Instead, Pollock defines, first, what it\nis for one belief to be a prima facie reason for believing\nanother proposition. In addition, Pollock defines what it is for one\nbelief, say in \\(p\\), to be a defeater for \\(q\\) as\na prima facie reason for \\(r\\). In fact. Pollock distinguishes\ntwo kinds of defeaters:\n rebutting defeaters,\n which are themselves prima facie reasons for believing the negation\nof the conclusion, and undercutting defeaters, which provide\na reason for doubting that \\(q\\) provides any support, in the actual\ncircumstances, for \\(r\\). (Pollock 1987, 484) A belief is\nultimately warranted in relation to a data set (or\nepistemic basis) just in case it is supported by some\nultimately undefeated argument proceeding from that epistemic\nbasis.\n\nIn Pollock 1995, Pollock uses a directed graph\nto represent the structure of an ideal cognitive state. Each directed\nlink in the network represents the first node\u2019s being a prima\nfacie reason for the second. The new theory includes an account of\nhypothetical, as well as categorical reasoning, since each\nnode of the graph includes a (possibly empty) set of hypotheses.\nSomewhat surprisingly, Pollock assumes a principle of monotonicity\nwith respect to hypotheses: a belief that is warranted relative to a\nset of hypotheses is also warranted with respect to any superset of\nhypotheses. Pollock also permits conditionalization and reasoning by\ncases.\n\nAn argument is self-defeating if it supports a defeater for\none of its own defeasible steps. Here is an interesting example: (1)\nRobert says that the elephant beside him looks pink. (2)\nRobert\u2019s color vision becomes unreliable in the presence of pink\nelephants. Ordinarily, belief 1 would support the conclusion that the\nelephant is pink, but this conclusion undercuts the argument, thanks\nto belief 2. Thus, the argument that the elephant is pink is\nself-defeating. Pollock argues that all self-defeating arguments\nshould be rejected, and that they should not be allowed to defeat\nother arguments. In addition, a set of nodes can experience mutual\ndestruction or collective defeat if each member of the set is\ndefeated by some other member, and no member of the set is defeated by\nan undefeated node that is outside the set.\n\nIn formalizing the undercutting rebuttal, Pollock introduces a new\nconnective, \\(\\otimes\\), where \\(p \\otimes q\\) means that it is not\nthe case that \\(p\\) wouldn\u2019t be true unless \\(q\\) were\ntrue. Pollock uses rules, rather than conditional propositions, to\nexpress the prima facie relation. If he had, instead, introduced a\nspecial connective \\(\\Rightarrow\\), with \\(p \\Rightarrow q\\) meaning\nthat \\(p\\) would be a prima facie reason for \\(q\\), then undercutting\ndefeaters could be represented by means of negating this\nconditional. To express the fact that \\(r\\) is an undercutting\ndefeater of \\(p\\) as a prima facie reason for \\(q\\), we could state\nboth that \\((p \\Rightarrow q)\\) and \\(\\neg((p \\amp r) \\Rightarrow\nq)\\).\n\nIn the case of conflicting prima facie reasons, Pollock rejects the\nprinciple of specificity, a widely accepted principle\naccording to which the defeasible rule with the more specific\nantecedent takes priority over conflicting rules with less specific\nantecedents. Pollock does, however, accept a special case of\nspecificity in the area of statistical syllogisms with projectible\nproperties. (Pollock 1995, 64\u201366) So, if I know that most\n\\(A\\)s are \\(B\\)s, and the most \\(AC\\)s are not\n\\(B\\)s, then I should, upon learning that individual \\(b\\)\nis both \\(A\\) and \\(C\\), give priority to the \\(AC\\)\ngeneralization over the \\(A\\) generalization (concluding that\n\\(b\\) is not a \\(B)\\).\n\nPollock\u2019s theory of warrant is intended to provide normative\nrules for belief, of the form: if you have warranted beliefs that are\nprima facie reasons for some further belief, and you have no\nultimately undefeated defeaters for those reasons, then that further\nbelief is warranted and should be believed. For more details of\nPollock\u2019s theory, see the following supplementary document:\n\nJohn Pollock\u2019s System\n\n\nWolfgang Spohn (Spohn 2002) has argued that Pollock\u2019s system is\nnormatively defective because, in the end, Pollock has no\nnormative standard to appeal to, other than ad hoc intuitions about\nhow a reasonable person would respond to this or that cognitive\nsituation. Spohn suggests that, with respect to the state of\ndevelopment of the study of defeasible reasoning, Pollock\u2019s\ntheory corresponds to C. I. Lewis\u2019s early investigations into\nmodal logic. Lewis suggested a number of possible axiom systems, but\nlacked an adequate semantic theory that could provide an independent\ncheck on the correctness or completeness of any given list (of the\nkind that was later provided by Kripke and Kanger). Analogously, Spohn\nargues that Pollock\u2019s system is in need of a unifying normative\nstandard. This very same criticism can be lodged, with equal justice,\nagainst a number of other theories of defeasible reasoning, including\nsemantic inheritance networks and default logic.\n4.2 Semantic Inheritance Networks\n\nThe system of semantic inheritance networks, developed by Horty,\nThomason, and Touretzky (1990), is similar to Pollock\u2019s system.\nBoth represent cognitive states by means of directed graphs, with\nlinks representing defeasible inferences. The semantic inheritance\nnetwork theory has a intentionally narrower scope: the initial nodes\nof the network represent particular individuals, and all non-initial\nnodes represent kinds, categories or properties. A link from an\ninitial (individual) node to a category node represents simply\npredication: that Felix (initial node) is a cat (category node), for\nexample. Links between category nodes represent defeasible or generic\ninclusion: that birds (normally or usually) are flying things. To be\nmore precise, there are both positive (\u201cis a\u201d) and\nnegative (\u201cis not a\u201d) links. The negative links are\nusually represented by means of a slash through the body of the\narrow.\n\nSemantic inheritance networks differ from Pollock\u2019s system in\ntwo important ways. First, they cannot represent one fact\u2019s\nconstituting an undercutting defeater of an inference,\nalthough they can represent rebutting defeaters. For example,\nthey do not allow an inference from the apparent color of an elephant\nto its actual color to be undercut by the information that my color\nvision is unreliable, unless I have information about the actual color\nof the elephant that contradicts its apparent color. Secondly, they do\nincorporate the principle of specificity (the principle that rules\nwith more specific antecedents take priority in case of conflict) into\nthe very definition of a warranted conclusion. In fact, in contrast to\nPollock, the semantic inheritance approach gives priority to rules\nwhose antecedents are weakly or defeasibly more specific. That is, if\nthe antecedent of one rule is defeasibly linked to the antecedent of a\nsecond rule, the first rule gains priority. For example, if Quakers\nare typically pacifists, then, when reasoning about a Quaker pacifist,\nrules pertaining to Quakers would override rules pertaining to\npacifists. For the details of semantic inheritance theory, see the\nfollowing supplementary document:\n\nSemantic Inheritance Networks.\n \n\nDavid Makinson (Makinson 1994) has pointed out that semantic network\ntheory is very sensitive to the form in which defeasible information\nis represented. There is a great difference between having a direct\nlink between two nodes and having a path between the two nodes being\nsupported by the graph as a whole. The notion of preemption gives\nspecial powers to explicitly given premises over conclusions. Direct\nlinks always take priority over longer paths. Consequently,\ninheritance networks lack two desirable metalogical properties: cut\nand cautious monotony (which will be covered in more detail in the\nsection on Logical Approaches).\n\nCut: If \\(G\\) is a subgraph of \\(G'\\), and every\nlink in \\(G'\\) corresponds to a path supported by\n\\(G\\), then every path supported by \\(G\\) is also supported\nby \\(G'\\).\nCautious Monotony: If \\(G\\) is a subgraph of\n\\(G'\\), and every link in \\(G'\\) corresponds to\na path supported by \\(G\\), then every path supported by\n\\(G'\\) is also supported by \\(G\\).\n\n\nCumulativity (Cut plus Cautious Monotony) corresponds to reasoning by\nlemmas or subconclusions. The Horty-Thomason-Touretzky system does\nsatisfy special cases of Cut and Cautious Monotony: if \\(A\\) is\nan atomic statement (a link from an individual to a category), then if\ngraph \\(G\\) supports \\(A\\), then for any statement\n\\(B, G \\cup \\{A\\}\\) supports \\(B\\) if and\nonly if \\(G\\) supports \\(B\\).\n\nAnother form of inference that is not supported by semantic\ninheritance networks is that of reasoning by cases or by dilemma. In\naddition, semantic networks do not license modus-tollens-like\ninferences: from the fact that birds normally fly and Tweety does not\nfly, we are not licensed to infer that Tweety is not a bird. (This\nfeature is also lacking in Pollock\u2019s system.)\n4.3 Belief Revision Theory\n\nAlchourr\u00f3n, G\u00e4rdenfors, and Makinson (1982) developed a\nformal theory of belief revision and contraction, drawing largely on\nWillard van Orman Quine\u2019s model of the web of belief\n(Quine and Ullian 1970). The cognitive agent is modelled as believing\na set of propositions that are ordered by their degree of\nentrenchment. This model provides the basis for a set of normative\nconstraints on belief contraction (subtracting a belief) and belief\nrevision (adding a new belief that is inconsistent with the original\nset). When a belief is added that is logically consistent with the\noriginal belief set, the agent is supposed to believe the logical\nclosure of the original set plus the new belief. When a belief is\nadded that is inconsistent with the original set, the agent retreats\nto the most entrenched of the maximal subsets of the set that are\nconsistent with the new belief, adding the new proposition to that set\nand closing under logical consequence. For the axioms of the AGM\nmodel, see the following supplementary document:\n\nAGM Postulates\n\n\nAGM belief revision theory can be used as the basis for a system of\ndefeasible reasoning or nonmonotonic logic, as G\u00e4rdenfors and\nMakinson have recognized (Makinson and G\u00e4rdenfors 1991). If\n\\(K\\) is an epistemic state, then a nonmonotonic consequence\nrelation\n\\(\\dproves\\)\ncan be defined as follows: \\(A \\dproves B\\) iff \\(B \\in K * A\\). Unlike\nPollock\u2019s system or semantic inheritance networks, this\ndefeasible consequence relation depends upon a background epistemic\nstate. Thus, the belief revision approach gives rise, not to a single\nnonmonotonic consequence relation, but to family of relations. Each\nbackground state \\(K\\) gives rise to its own characteristic\nconsequence relation.\n\nOne significant limitation of the belief-revision approach is that\nthere is no representation in the object-language of a defeasible or\ndefault rule or conditional (that is, of a conditional of the form\nIf p, then normally q or That p would be a prima facie\nreason for accepting that q). In fact, G\u00e4rdenfors\n(G\u00e4rdenfors 1978; G\u00e4rdenfors 1986) proved that no\nconditional satisfying the Ramsey test can be added to the AGM system\nwithout trivializing the revision\n relation.[1]\n (A conditional \\(\\Rightarrow\\) satisfies the Ramsey test just in\ncase, for every epistemic state \\(K, K\\) includes \\((A \\Rightarrow\nB)\\) iff \\(K * A\\) includes \\(B\\).)\n\nSince the AGM system cannot include conditional beliefs, it cannot\nelucidate the question of what logical relationships hold between\nconditional defaults.\n\nThe lack of a representation of conditional beliefs is closely\nconnected to another limitation of the AGM system: its inability to\nmodel repeated or iterated belief revision. The input to a\nbelief change is an epistemic state, consisting both of a set of\npropositions believed and an entrenchment relation on that set. The\noutput of an AGM revision, in contrast, consists simply of a set of\nbeliefs. The system provides no guidance on the question of what would\nbe the result of revising an epistemic state in two or more steps. If\nthe entrenchment relation could be explicitly represented by means of\nconditional propositions, then it would be possible to define the new\nentrenchment relation that would result from a single belief revision,\nmaking iterated belief revision representable. A number of proposals\nalong these lines have been made. The difficulty lies in defining\nexactly what would constitute a minimal change in the\nrelative entrenchment or epistemic ranking of a set of beliefs. To\nthis point, no clear consensus has emerged on this question. (See\nSpohn 1988; Nayak 1994; Wobcke 1995; Bochman 2001.)\n\nOn the larger question of the relation between belief revision and\ndefeasible reasoning, there are two possibilities: that a theory of\ndefeasible reasoning should be grounded in a theory of belief\nrevision, and that a theory of belief revision should be grounded in a\ntheory of defeasible reasoning. The second view has been defended by\nJohn Pollock (Pollock 1987; Pollock 1995) and by Hans Rott (Rott\n1989). On this second view, we must make a sharp distinction between\nbasic or foundational beliefs on the one hand and inferred or derived\nbeliefs on the other. We can then model belief change on the\nassumption that new beliefs are added to the foundation (and are\nlogically consistent with the existing set of those beliefs). Beliefs\ncan be added which are inconsistent with previous inferred beliefs,\nand the new belief state consists simply in the closure of the new\nfoundational set under the relation of defeasible consequence. On such\nan approach, default conditionals can be explicitly represented among\nthe agent\u2019s beliefs. G\u00e4rdenfors\u2019s triviality result\nis then avoided by rejecting one of the assumptions of the theorem,\npreservation:\n\nPreservation:\nIf \\(\\neg A \\not\\in K\\),then \\(K \\subseteq K * A\\).\n\nFrom the perspective that uses defeasible reasoning to define belief\nrevision, there is no good reason to accept Preservation. One can add\na belief that is consistent with what one already believes and thereby\nlose beliefs, since the new information might be an\nundercutting defeater to some defeasible inference that had been\nsuccessful.\n4.4 Formal Argumentation Theory\n\nPhan Minh Dung (Dung 1995) initiated a new and fruitful approach to\ndefeasible reasoning, one that focuses on the structure of\narguments. Dung defines an argument structure as an ordered\npair \\( \u27e8 A, B \u27e9 \\), in which \\(A\\) is a set of arguments and \\(B\\) is\na binary relation on \\(A\\), representing the attacks\nrelation. In other words, if \\( \u27e8 x, y \u27e9 \\in B\\), then argument \\(x\\)\nis representing as attacking argument \\(y\\) in some way. An argument\nis a sequence of propositions, with the last proposition designated as\nits conclusion. (The premises of an argument can be null, in which\ncase we can treat the argument as equivalent to the assertion of the\nsingle proposition it contains.) \n\nDung\u2019s approach doesn\u2019t distinguish between the various ways in which\none argument can attack another, such as rebutting, undermining, or\nundercutting, although this additional information can be added by\ndifferentiating several types of attack relations. One\nargument rebuts another when their conclusions are\ncontradictories. An argument undermines a second argument\nwhen the conclusion of the first contradicts one of the premises of\nthe second. And an argument undercuts another when its\nconclusion provides reason for doubting that the premises of the\nsecond are in the actual circumstances reliable indicators of the\ntruth of the conclusion. In many applications, these distinctions can\nbe ignored. However, Henry Prakken (Prakken 2010) makes use of all\nthree forms of attack in his ASPIC+ system.\n\nCentral to Dung\u2019s approach is the idea of an admissible\nset of arguments relative to an argument structure. A set of arguments\n\\(A\\) is admissible if and only if it is conflict free (no argument in\n\\(A\\) attacks another argument in \\(A\\)), and there is every argument\nthat attacks something in \\(A\\) is itself attacked by something in\n\\(A\\). In other words, \\(A\\) can defeat everything that defeats one of\nits members. Dung\u2019s approach incorporates the principle: \u201cthe\none who laughs last, laughs best.\u201d\nA preferred extension of an argument structure is a\nmaximal admissible set of the structure. Every structure possesses at\nleast one preferred extension. A stable extension of a\nstructure is a conflict-free set \\(S\\) that attacks each argument that\ndoes not belong to \\(S\\). Every stable extension is a preferred\nextension, but not vice versa. Some structures do not have stable\nextensions. Leendert van der Torre and Srdjan Vesic (van der Torre and\nVesic 2018) outline the full range of definitions of extensions, along\nwith the principles of rationality they embody.\nThe characteristic function \\(F_{AS}\\) of an argument structure\n\\(AF\\) is defined as follows:\n\n\\(F_{AS}\\)(\\(S\\)) = {\\(A\\): \\(A\\) is acceptable with respect to \\(S\\)}\n\n\nThe grounded extension of an argument structure is the\nleast fixed point of its characteristic function. An extension \\(S\\)\nis complete if it contains every argument that is admissible\nwith respect to \\(S\\). The grounded extension is the minimal complete\nextension of a structure. If a structure is well-founded (with no\ninfinite regress of attack relations, then the structure has a unique\ncomplete extension that is grounded, preferred, and stable (Dung 1995,\n331).\n\nThese various notions of optimal extension can be used to define when\na proposition has been proved or refuted in a particular structure,\ndepending on whether the proposition or its negation belongs to the\noptimal extension of the structure.\n\nGerald Vreeswijk (Vreeswijk 1997) has built upon Dung\u2019s\nframework by introducing preference relations among arguments. The\nrelation of relative conclusive force could be determined by such\nfactors as the presence or absence of defeasible rules, the occurrence\nof a premise of one argument as the conclusion of another, the number\nof steps in the argument, or the use in the arguments of defeasible\nrules with varying degrees of reliability. The HERMES system of\nKaracapilidis and Papadias (Karacapilidis and Papadias 2001)\nimplements numeric weights for reasons for and against a\nconclusion.\n\nHenry Prakken (Prakken 2010) has expanded Dung\u2019s model by\nincluding support as well as attack relations between arguments. Bart\nVerheij\u2019s DefLog system (Verheij 2003, 2005) makes use of a\nconditional to represent support and a negation operator to represent\nattack. Anthony Hunter, Sylwia Polberg, and Matthias Thimm (Hunter et\nal. 2020) have recently used epistemic graphs to represent both\npositive and negative interactions among arguments.\n\nOthers have used probabilities to measure the comparative strength of\narguments: Dung and Thang (2010), Verheij (2012), and Hunter\n(2013).\n5. Logical Approaches\n\nLogical approaches to defeasible reasoning treat the subject as a part\nof logic: the study of nonmonotonic consequence relations (in\ncontrast to the monotonicity of classical logic). These relations are\ndefined on propositions, not on the beliefs of an agent, so the focus\nis not on epistemology per se, although a theory of nonmonotonic logic\nwill certainly have implications for epistemology.\n5.1 Relations of Logical Consequence\n\nA consequence relation is a mathematical relation that models what\nfollows logically from what. Consequence relations can be defined in a\nvariety of ways, such as Hilbert, Tarski, and Scott relations. A\nHilbert consequence relation is a relation between pairs of formulas,\na Tarski relation is a relation between sets of formulas (possibly\ninfinite) and individual formulas, and a Scott relation is a relation\nbetween two sets of formulas. In the case of Hilbert and Tarski\nrelations, \\(A \\vDash B\\) or \\(\\Gamma \\vDash B\\) mean\nthat the formula \\(B\\) follows from formula \\(A\\) or from\nset of formulas \\(\\Gamma\\). In the case of Scott consequence relations,\n\\(\\Gamma \\vDash \\Delta\\) means that the joint truth of all the members\nof \\(\\Gamma\\) implies (in some sense) the truth of at least one member of\n\\(\\Delta\\). To this point, studies of nonmonotonic logic have defined\nnonmonotonic consequence relations in the style of Hilbert or Tarski,\nrather than Scott.\n\nA (Tarski) consequence relation is monotonic just in case it\nsatisfies the following condition, for all formulas \\(p\\) and all\nsets \\(\\Gamma\\) and \\(\\Delta\\):\n\nMonotonicity:\nIf \\(\\Gamma \\vDash p\\), then \\(\\Gamma \\cup \\Delta \\vDash p\\).\n\nAny consequence relation that fails this condition is\nnonmonotonic. A relation of defeasible consequence clearly\nmust be nonmonotonic, since a defeasible inference can be defeated by\nadding additional information that constitutes a rebutting or\nundercutting defeater.\n5.2 Metalogical Desiderata\n\nOnce monotonicity is given up, the question arises: why call the\nrelation of defeasible consequence a logical consequence\nrelation at all? What properties do defeasible consequence and\nclassical logical consequence have in common, that would justify\ntreating them as sub-classes of the same category? What justifies\ncalling nonmonotonic consequence logical?\n\nTo count as logical, there are certain minimal properties\nthat a relation must satisfy. First, the relation ought to permit\nreasoning by lemmas or subconclusions. That is, if a proposition\n\\(p\\) already follows from a set \\(\\Gamma\\), then it should make no\ndifference to add \\(p\\) to \\(\\Gamma\\) as an additional premise.\nRelations that satisfy this condition are called cumulative.\nCumulative relations satisfy the following two conditions (where\n\u201c\\(C(\\Gamma)\\)\u201d represents the set of defeasible\nconsequences of \\(\\Gamma)\\):\n\nCut:\nIf \\(\\Gamma \\subseteq \\Delta \\subseteq C(\\Gamma)\\), then \\(C(\\Delta) \\subseteq C(\\Gamma)\\).\n\nCautious Monotony: \nIf \\(\\Gamma \\subseteq \\Delta\n\\subseteq C(\\Gamma)\\), then \\(C(\\Gamma) \\subseteq C(\\Delta)\\).\n\nIn addition, a defeasible consequence relation ought to be\nsupraclassical: if \\(p\\) follows from \\(q\\) in\nclassical logic, then it ought to be included in the defeasible\nconsequences of \\(q\\) as well. A formula \\(q\\) ought to\ncount as an (at least) defeasible consequence of itself, and anything\nincluded in the content of \\(q\\) (any formula \\(p\\) that\nfollows from \\(q\\) in classical logic) ought to count as a\ndefeasible consequence of \\(q\\) as well. Moreover, the defeasible\nconsequences of a set \\(\\Gamma\\) ought to depend only on the content of\nthe formulas in \\(\\Gamma\\), not in how that content is represented.\nConsequently, the defeasible consequence relation ought to treat\n\\(\\Gamma\\) and the classical logical closure of \\(\\Gamma\\) (which we\u2019ll\nrepresent as \u201c\\(Cn(\\Gamma)\\)\u201d) in exactly the same\nway. A consequence relation that satisfies these two conditions is\nsaid to satisfy full absorption (see Makinson 1994, 47).\n\nFull Absorption:\n\\(Cn(C(\\Gamma)) = C(\\Gamma) = C(Cn(\\Gamma))\\)\n\nFinally, a genuinely logical consequence relation ought to enable us\nto reason by cases. So, it should satisfy a principle called\ndistribution: if a formula \\(p\\) follows defeasibly from both\n\\(q\\) and \\(r\\), then it ought to follow from their\ndisjunction. (To require the converse principle would be to reinstate\nmonotonicity.) The relevant principle is this:\n\nDistribution:\n\\(C(\\Gamma) \\cap C(\\Delta) \\subseteq C(Cn(\\Gamma) \\cap Cn(\\Delta))\\).\n\nConsequence relations that are cumulative, strongly absorptive, and\ndistributive satisfy a number of other desirable properties, including\nconditionalization: If a formula \\(p\\) is a defeasible\nconsequence of \\(\\Gamma \\cup \\{q\\}\\), then the material\nconditional \\((q \\rightarrow p)\\) is a defeasible consequence\nof \\(\\Gamma\\) alone. In addition, such logics satisfy the property of\nloop: if \\(p_1 \\dproves p_2 \\ldots p_{n-1} \\dproves p_n\\) (where \u201c\n\\(\\dproves\\)\n\u201d represents the defeasible consequence relation), then the\ndefeasible consequences of \\(p_i\\) and\n\\(p_j\\) are exactly the same, for any\n\\(i\\) or\n \\(j\\).[2]\n\nThere are three further conditions that have been much discussed in\nthe literature, but whose status remains controversial:\ndisjunctive rationality, rational monotony, and\nconsistency preservation.\n\n\nDisjunctive Rationality:\nIf \\(\\Gamma \\cup \\{p\\} \\notdproves r\\), and \\(\\Gamma \\cup \\{q\\}\n\\notdproves r\\), then \\(\\Gamma \\cup \\{\\)(p \\(\\vee\\) q)\\(\\} \\notdproves\nr\\).\n\nRational Monotony:\nIf \\(\\Gamma \\dproves A\\), then either \\(\\Gamma \\cup \\{B\\} \\dproves A\\)\nor \\(\\Gamma \\dproves \\neg B\\).\n\nConsistency Preservation:\nIf \\(\\Gamma\\) is classically consistent, then so is \\(C(\\Gamma)\\) (the\nset of defeasible consequences of \\(\\Gamma)\\).\n\n\nAll three properties seem desirable, but they set a very hight\nstandard for the defeasible reasoner.\n5.3 Default Logic\n\nRay Reiter\u2019s default logic (Reiter 1980; Etherington and Reiter\n1983) was part of the first generation of defeasible systems developed\nin the field of artificial intelligence. The relative ease of\ncomputing default extensions has made it one of the more popular\nsystems.\n\nReiter\u2019s system is based on the use of default rules. A\ndefault rule consists of three formulas: the prerequisite,\nthe justification, and the consequent. If one\naccepts the prerequisite of a default rule, and the justification is\nconsistent with all one knows (including what one knows on the basis\nof the default rules themselves), then one is entitled to accept the\nconsequent. The most popular use of default logic relies solely on\nnormal defaults, in which the justification and the\nconsequent are identical. Thus, a normal default of the form\n\\((p\\); \\(q \\therefore q)\\) allows one to infer\n\\(q\\) from \\(p\\), so long as \\(q\\) is consistent with\none\u2019s endpoint (the extension of the default\ntheory).\n\nA default theory consists of a set of formulas (the facts), together\nwith a set of default rules. An extension of a default theory\nis a fixed point of a particular inferential process: an extension\n\\(E\\) must be a consistent theory (a consistent set closed under\nclassical consequence) that contains all of the facts of the default\ntheory \\(T\\), and, in addition, for each normal default\n\\((p \\Rightarrow q)\\), if \\(p\\) belongs to \\(E\\),\nand \\(q\\) is consistent with \\(E\\), then \\(q\\) must\nbelong to \\(E\\) also.\n\nSince the consequence relation is defined by a fixed-point condition,\nthere are default theories that have no extension at all, and other\ntheories that have multiple, mutually inconsistent extensions. For\nexample, the theory consisting of the fact \\(p\\) and the pair of\ndefaults \\((p\\) ; \\((q \\amp r) \\therefore q)\\) and \\((q\\) ; \\(\\neg r\n\\therefore \\neg r)\\) has no extension. If the first default is\napplied, then the second must be, and if the second default is not\napplied, the first must be. However, the conclusion of the second\ndefault contradicts the prerequisite of the first, so the first cannot\nbe applied if the second is. There are many default theories that have\nmultiple extensions. Consider the theory consisting of the facts \\(q\\)\nand r and the pair of defaults \\((q\\) ; \\(p \\therefore p)\\) and \\((r\\)\n; \\(\\neg p \\therefore \\neg p)\\). One or the other, but not both,\ndefaults must be applied. \n\nFurthermore, there is no guarantee that if \\(E\\) and\n\\(E'\\) are both extensions of theory \\(T\\), then the\nintersection of \\(E\\) and \\(E'\\) is also an extension\n(the intersection of two fixed points need not be itself a fixed\npoint). Default logic is usually interpreted as a credulous\nsystem: as a system of logic that allows the reasoner to select\nany extension of the theory and believe all of the members of\nthat theory, even though many of the resulting beliefs will involve\npropositions that are missing from other extensions (and may even be\ncontradicted in some of those extensions).\n\nDefault logic fails many of the tests for a logical relation that were\nintroduced in the previous section. It satisfied Cut and Full\nAbsorption, but it fails Cautious Monotony (and thus fails to be\ncumulative). In addition, it fails Distribution, a serious limitation\nthat rules out reasoning by cases. For example, if one knows that\nSmith is either Amish or Quaker, and both Quakers and Amish are\nnormally pacifists, one cannot infer that Smith is a pacifist. Default\nlogic also fails to represent Pollock\u2019s undercutting\ndefeaters. Finally, default logic does not incorporate any form\nof the principle of Specificity, the principle that defaults\nwith more specific prerequisites ought, in cases of conflict, to take\npriority over defaults with less specific prerequisites. Recently,\nJohn Horty (Horty 2007a, 2007b) has examined the implications of\nadding priorities among defaults (in the form of a partial ordering),\nwhich would permit the recognition of specificity and other grounds\nfor preferring one default to another. In addition, Horty allows for\ndefeasible reasoning about these priorities (the relative weights of\nvarious defaults) by means of higher-order default rules. Such\ndefeasible reasoning about relative weights enables Horty to give an\naccount of Pollock\u2019s\n undercutting defeaters:\n an undercutting defeater is a triggered default rule that lowers the\nweight of the undercut rule below some threshold, with the result that\nthe undercut rule can no longer be triggered.\n5.4 Nonmonotonic Logic I and Autoepistemic Logic\n\nIn both McDermott-Doyle\u2019s Nonmonotonic Logic I and Moore\u2019s\nAutoepistemic logic (McDermott and Doyle, 1982; Moore, 1985; Konolige\n1994), a modal operator \\(M\\) (representing a kind of epistemic\npossibility) is used. Default rules take the following form: \\(((p\n\\amp Mq) \\rightarrow q)\\), that is, if \\(p\\) is true and \\(q\\) is\n\u201cpossible\u201d (in the relevant sense), then \\(q\\) is also\ntrue. In both cases, the extension of a theory is defined, as in\nReiter\u2019s default logic, by means of a fixed-point\noperation. \\(Mp\\) represents the fact that \\(\\neg p\\) does not belong\nto the extension. For example, in Moore\u2019s case, a set \\(\\Delta\\)\nis a stable expansion of a theory \\(\\Gamma\\) just in case\n\\(\\Delta\\) is the set of classical consequences of the set \\(\\Gamma\n\\cup \\{\\neg Mp: p \\in \\Delta \\} \\cup \\{Mp: p \\not\\in \\Delta \\}\\). As\nin the case of Reiter\u2019s default logic, some theories will lack a\nstable expansion, or have more than one. In addition, these systems\nfail to incorporate Specificity.\n5.5 Circumscription\n\nIn circumscription (McCarthy 1982; McCarthy 1986; Lifschitz 1988), one\nor more predicates of the language are selected for minimization\n(there is, in addition, a further technical question of which\npredicates to treat as fixed and which to treat as variable). The\nnonmonotonic consequences of a theory \\(T\\) then consist of all\nthe formulas that are true in every model of \\(T\\) that minimizes\nthe extensions of the selected predicates. One model \\(M\\) of\n\\(T\\) is preferred to another, \\(M'\\), if and only if,\nfor each designated predicate \\(F\\), the extension of \\(F\\)\nin \\(M\\) is a subset of the extension of \\(F\\) in\n\\(M'\\), and, for some such predicate, the extension in\n\\(M\\) is a proper subset of the extension in\n\\(M'\\).\n\nThe relation of circumscriptive consequence has all the desirable\nmeta-logical properties. It is cumulative (satisfies Cut and Cautious\nMonotony), strongly absorptive, and distributive. In addition, it\nsatisfies Consistency Preservation, although not Rational\nMonotony.\n\nThe most critical problem in applying circumscription is that of\ndeciding on what predicates to minimize (there is, in addition, a\nfurther technical question about which predicates to treat as fixed\nand which as variable in extension). Most often what is done is to\nintroduce a family of abnormality predicates \\(ab_1, ab_2\\),\netc. A default rule then can be written in the form: \\(\\forall x((F(x)\n\\amp \\neg ab_i (x) ) \\rightarrow G(x))\\), where\n\u201c\\(\\rightarrow\\)\u201d is the ordinary material conditional of\nclassical logic. To derive the consequences of a theory, all of the\nabnormality predicates are simultaneously minimized. This simple\napproach fails to satisfy the principle of Specificity, since each\ndefault is given its own, independent abnormality predicate, and each\nis therefore treated with the same priority. It is possible to add\nspecial rules for the prioritizing of circumscription, but these are,\nof necessity, ad hoc and exogenous, rather than a natural result of\nthe definition of the consequence relation.\n\nCircumscription does have the capacity of representing the existence\nof undercutting defeaters. Suppose that satisfying predicate\n\\(F\\) provides a prima facie reason for supposing something to be\na \\(G\\), and suppose that we use the abnormality predicate\n\\(ab_1\\) in representing this default rule. We can\nstate that the predicate \\(H\\) provides an undercutting defeater\nto this inference by simply adding the rule: \\(\\forall x\n(H(x) \\rightarrow ab_1 (x))\\),\nstating that all \\(H\\)s are abnormal in respect number 1.\n5.6 Preferential Logics\n\nCircumscription is a special case of a wider class of defeasible\nlogics, the preferential logics (Shoham 1987). In\npreferential logics, \\(\\Gamma \\dproves p\\) iff \\(p\\) is true in all of the most\npreferred models of \\(\\Gamma\\). In the case of circumscription, the\nmost preferred models are those that minimize the extension of certain\npredicates, but many other kinds of preference relations can be used\ninstead, so long as the preference relations are transitive and\nirreflexive (a strict partial order). A structure consisting of a set\nof models of a propositional or first-order language, together with a\npreference order on those models, is called a preferential\nstructure. The symbol \\(\\prec\\) shall represent the preference\nrelation. \\(M \\prec M'\\) means that \\(M\\)\nis strictly preferred to \\(M'\\). A most preferred model is\none that is minimal in the ordering.\n\nIn order to give rise to a cumulative logic (one that satisfies Cut\nand Cautious Monotony), we must add an additional condition to the\npreferential structures, a Limit Assumption (also known as the\ncondition of stopperedness or smoothness:\n\nLimit Assumption: Given a theory \\(T\\), and\n\\(M\\), a non-minimal model of \\(T\\), there exists a model\n\\(M'\\) which is preferred to \\(M\\) and which is a\nminimal model of \\(T\\).\n\nThe Limit Assumption is satisfied if the preferential structure does\nnot contain any infinite descending chains of more and more preferred\nmodels, with no minimal member. This is a difficult condition to\nmotivate as natural, but without it, we can find preferential\nstructures that give rise to nonmonotonic consequence relations that\nfail to be cumulative.\n\nOnce we have added the Limit Assumption, it is easy to show that any\nconsequence relation based upon a preferential model is not only\ncumulative but also supraclassical, strongly absorptive, and\ndistributive. Let\u2019s call such logics preferential. In\nfact, Kraus, Lehmann, and Magidor (Kraus, Lehmann, and Magidor 1990;\nMakinson 1994, 77; Makinson 2005, PAGE) proved the following\nrepresentation theorem for preferential logics:\n\nRepresentation Theorem for Preferential Logics: if\n\\(\\dproves\\) is a cumulative, supraclassical, strongly absorptive, and\ndistributive consequence relation (i.e., a preferential relation) then\nthere is a preferential structure \\(\\mathcal{M}\\) satisfying the Limit\nAssumption such that for all finite theories \\(T\\), the set\nof \\(\\dproves\\) -consequences of \\(T\\) is exactly the set of formulas\ntrue in every preferred model of \\(T\\)\n in M.[3]\n\nThere are preferential logics that fail to satisfy consistency\npreservation, as well as disjunctive rationality and rational\nmonotony:\n\nDisjunctive Rationality:\nIf \\(\\Gamma \\cup \\{p\\} \\notdproves r\\), and \\(\\Gamma \\cup \\{q\\}\n\\notdproves r\\), then \\(\\Gamma \\cup \\{(p \\vee q)\\} \\notdproves\nr\\).\n\nRational Monotony: \nIf \\(\\Gamma \\dproves p\\), then either \\(\\Gamma \\cup \\{q\\} \\dproves p\\)\nor \\(\\Gamma \\dproves \\neg q\\).\n\nA very natural condition has been found by Kraus, Lehmann, and Magidor\nthat corresponds to Rational Monotony: that of ranked models.\n(No condition on preference structures has been found that ensures\ndisjunctive rationality without also ensuring rational monotony.) A\npreferential structure \\(\\mathcal{M}\\) satisfies the\nRanked Models condition just in case there is a function \\(r\\)\nthat assigns an ordinal number to each model in such a way that\n\\(M \\prec M'\\) iff \\(r(M) \\lt r(M')\\). Let\u2019s say that a preferential\nconsequence relation is a rational relation just in case it\nsatisfies Rational Monotony, and that a preferential structure is a\nrational structure just in case it satisfies the ranked\nmodels condition. Kraus, Lehmann, and Magidor (Kraus, Lehmann, and\nMagidor 1990; Makinson 1994, 71\u201381) also proved the following\nrepresentation theorem:\n\nRepresentation Theorem for Rational Logics: if\n\\(\\dproves\\) is a rational consequence relation (i.e., a preferential\nrelation that satisfies Rational Monotony) then there is a\npreferential structure \\(\\mathcal{M}\\) satisfying the Limit Assumption\nand the Ranked Models Assumption such that for all finite theories\n\\(T\\), the set of \\(\\dproves\\) -consequences of \\(T\\) is exactly the\nset of formulas true in every preferred model of \\(T\\) in\n\\(\\mathcal{M}\\).\n\nFreund proved an analogous representation result for preferential\nlogics that satisfy disjunctive rationality, replacing the\nranking condition with a weaker condition of filtered models:\na filtered model is one such that, for every formula, if two worlds\nnon-minimally satisfy the formula, then there is a world less than\nboth of them that also satisfies the formula (Freund 1993).\n5.7 Logics of Extreme Probabilities\n\nLehmann and Magidor (Lehmann and Magidor 1992) noticed an interesting\ncoincidence: the metalogical conditions for preferential consequence\nrelations correspond exactly to the axioms for a logic of conditionals\ndeveloped by Ernest W. Adams (Adams\n1975).[4]\nAdams\u2019s logic was based on a conditional, \\(\\Rightarrow\\),\nintended to represent a relation of very high conditional probability:\n\\((p \\Rightarrow q)\\) means that the conditional probability\n\\(Pr(q/p)\\) is extremely close to 1. Adams used the standard\ndelta-epsilon definition of the calculus to make this idea\nprecise. Let us suppose that a theory \\(T\\) consists of a set of\nconditional-free formulas (the facts) and a set of probabilistic\nconditionals. A conclusion \\(p\\) follows defeasibly from \\(T\\) if and\nonly if every probability function satisfies the following\ncondition:\n\nFor every \\(\\delta\\), there is an \\(\\varepsilon\\) such that, if the probability\nof every fact in \\(T\\) is assigned a probability at least as high\nas \\(1 - \\varepsilon\\), and every conditional in \\(T\\) is\nassigned a conditional probability at least as high as \\(1 -\n\\varepsilon\\), then the probability of the conclusion \\(p\\) is at\nleast \\(1 - \\delta\\).\n\nThe resulting defeasible consequence relation is a preferential\nrelation. (It need not, however, be consistency-preserving.) This\nconsequence relation also corresponds to a relation, 0-entailment,\ndefined by Judea Pearl (Pearl 1990), as the common core to all\ndefeasible consequence relations.\n\nLehmann and Magidor (1992) proposed a variation on Adams\u2019s idea.\nInstead of using the delta-epsilon construction, they made use of\nnonstandard measure theory, that is, a theory of probability functions\nthat can take values that are infinitesimals (infinitely\nsmall numbers). In addition, instead of defining the consequence\nrelation by quantifying over all probability functions,\nLehmann and Magidor assume that we can select a single probability\nfunction (representing something like the ideally rational, or\nobjective probability). On their construction, a conclusion \\(p\\)\nfollows from \\(T\\) just in case the probability of \\(p\\) is\ninfinitely close to 1, on the assumption that the probabilities\nassigned to members of \\(T\\) are infinitely close to 1. Lehmann\nand Magidor proved that the resulting consequence relation is always\nnot only preferential: it is also rational. The logic defined\nby Lehmann and Magidor also corresponds exactly to the theory of\nPopper functions, another extension of probability theory designed to\nhandle cases of conditioning on propositions with infinitesimal\nprobability (see Harper 1976; van Fraassen 1995; Hawthorne 1998). For\na brief discussion of Popper functions, see the following\nsupplementary document:\n\nPopper Functions\n\n\nArl\u00f3 Costa and Parikh, using van Fraassen\u2019s account (van\nFraassen, 1995) of primitive conditional probabilities (a variant of\nPopper functions), proved a representation result for both finite and\ninfinite languages (Arl\u00f3 Costa and Parikh, 2005). For infinite\nlanguages, they assumed an axiom of countable additivity for\nprobabilities.\n\nKraus, Lehmann, and Magidor proved that, for every preferential\nconsequence relation \\(\\dproves\\) that is probabilistically\n admissible,[5]\n there is a unique rational consequence relation \\(\\dproves^*\\) that\nminimally extends it (that is, that the intersection of all the\nrational consequence relations extending \\(\\dproves\\) is also a\nrational consequence relation). This relation, \\(\\dproves^*\\), is\ncalled the rational closure of \\(\\dproves\\). To find the\nrational closure of a preferential relation, one can perform the\nfollowing operation on a preferential structure that supports that\nrelation: assign to each model in the structure the smallest number\npossible, respecting the preference relation. Judea Pearl also\nproposed the very same idea under the name\n1-entailment or System \\(Z\\) (Pearl 1990).\n\nA critical advantage to the Lehmann-Magidor-Pearl 1-entailment system\nover Adams\u2019s epsilon-entailment lies in the way in which\n1-entailment handles irrelevant information. Suppose, for example,\nthat we know that birds fly \\((B \\Rightarrow F)\\), Tweety is\na bird \\((B)\\), and Nemo is a whale \\((W)\\). These premises\ndo not epsilon-entail \\(F\\) (that Tweety flies), since there is\nno guarantee that a probability function assign a high probability to\n\\(F\\), given the conjunction of \\(B\\) and\n\\(W\\). In contrast, 1-entailment does give us the conclusion\n\\(F\\).\n\nMoreover, 1-entailment satisfies a condition of weak independence\nof defaults: conditionals with logically unrelated antecedents\ncan \u201cfire\u201d independently of each other: one can warrant a\nconclusion even though we are given an explicit exception to the\nother. Consider, for example, the following case: birds fly \\((B\n\\Rightarrow F)\\), Tweety is a bird that doesn\u2019t fly \\((B \\amp\n\\neg F)\\), whales are large \\((W \\Rightarrow L)\\), and Nemo is a whale\n\\((W)\\). These premises 1-entail that Nemo is large \\((L)\\). In\naddition, 1-entailment automatically satisfies the principle of\nSpecificity: conditionals with more specific antecedents are always\ngiven priority over those with less specific antecedents.\n\nThere is another form of independence, strong independence,\nthat even 1-entailment fails to satisfy. If we are given one exception\nto a rule involving a given antecedent, then we are unable to use any\nconditional with the same antecedent to derive any conclusion\nwhatsoever. Suppose, for example, that we know that birds fly \\((B\n\\Rightarrow F)\\), Tweety is a bird that doesn\u2019t fly \\((B \\amp\n\\neg F)\\), and birds lay eggs \\((B \\Rightarrow E)\\). Even under\n1-entailment, the conclusion that Tweety lays eggs \\((E)\\) fails to\nfollow. This failure to satisfy Strong Independence is also known\nas the Drowning Problem (since all conditionals with the same\nantecedent are \u201cdrowned\u201d by a single exception).\n\nA consensus is growing that the Drowning Problem should not be\n\u201csolved\u201d (see Pelletier and Elio 1994; Wobcke 1995, 85;\nBonevac, 2003, 461\u2013462). Consider the following variant on the\nproblem: birds fly, Tweety is a bird that doesn\u2019t fly, and birds\nhave strong forelimb muscles. Here it seems we should refrain from\nconcluding that Tweety has strong forelimb muscles, since there is\nreason to doubt that the strength of wing muscles is causally (and\nhence, probabilistically) independent of capacity for flight. Once we\nknow that Tweety is an exceptional bird, we should refrain from\napplying other conditionals with Tweety is a bird as their\nantecedents, unless we know that these conditionals are independent of\nflight, that is, unless we know that the conditional with the stronger\nantecedent, Tweety is a non-flying bird, is also true.\n\nNonetheless, several proposals have been made for securing strong\nindependence and solving the Drowning Problem. Geffner and Pearl\n(Geffner and Pearl 1992) proposed a system of conditional\nentailment, a variant of circumscription, in which the preference\nrelation on models is defined in terms of the sets of defaults that\nare satisfied. This enables Geffner and Pearl to satisfy both the\nSpecificity principle and Strong Independence. Another proposal is the\nmaximum entropy approach (Pearl 1988, 490\u2013496; Goldszmidt,\nMorris and Pearl, 1993; Pearl 1990). A theory \\(T\\), consisting\nof defaults \\(\\Delta\\) and facts \\(F\\), entails \\(p\\) just in\ncase the probability of \\(p\\), conditional on \\(F\\),\napproaches 1 as the probabilities associated with \\(\\Delta\\) approach 1,\nusing the\n entropy-maximizing[6]\n probability function that respects the defaults in \\(\\Delta\\). The\nmaximum-entropy approaches satisfies both Specificity and Strong\nIndependence.\n\nEvery attempt to solve the drowning problem (including conditional\nentailment and the maximum-entropy approach) comes at the cost of\nsacrificing cumulativity. Securing strong independence makes the\nsystems very sensitive to the exact form in which the default\ninformation is stored. Consider, for example the following case:\nSwedes are (normally) fair, Swedes are (normally) tall, Jon is a short\nSwede. Conditional entailment and maximum-entropy entailment would\npermit the conclusion that Jon is fair in this case. However, if we\nreplace the first two default conditionals by the single default,\nSwedes are normally both tall and fair, then the conclusion\nno longer follows, despite the fact that the new conditional is\nlogically equivalent to the conjunction of the two original\nconditionals.\n\nApplying the logic of extreme probabilities to real-world defeasible\nreasoning generates an obvious problem, however. We know perfectly\nwell that, in the case of the default rules we actually use, the\nconditional probability of the conclusion on the premises is nowhere\nnear 1. For example, the probability that an arbitrary bird can fly is\ncertainly not infinitely close to 1. This problem resembles that of\nusing idealizations in science, such as frictionless planes and ideal\ngases. It seems reasonable to think that, in deploying the machinery\nof defeasible logic, we indulge in the degree of make-believe\nnecessary to make the formal models applicable. Nonetheless, this is\nclearly a problem warranting further attention.\n5.8 Fully Expressive Languages: Conditional Logics and Higher-Order Probabilities\n\nWith relatively few exceptions, the logical approaches to defeasible\nreasoning developed so far put severe restrictions on the logical form\nof propositions included in a set of premises. In particular, they\nrequire the default conditional operator, \\(\\Rightarrow\\), to have\nwide scope in every formula in which it appears. Default conditionals\nare not allowed to be nested within other default conditionals, or\nwithin the scope of the usual Boolean operators of propositional logic\n(negation, conjunction, disjunction, material conditional). This is a\nvery severe restriction and one that is quite difficult to defend. For\nexample, in representing undercutting defeaters, it would be\nvery natural to use a negated default conditional of the form\n\\(\\neg((p \\amp q) \\Rightarrow r)\\) to signify that \\(q\\) defeats \\(p\\)\nas a prima facie reason for \\(r\\). In addition, it seems plausible\nthat one might come gain\ndisjunctive default information: for example, that either\ncustomers are gullible or salesman are wily.\n\nAsher and Pelletier (Asher and Pelletier 1997) have argued that, when\ntranslating generic sentences in natural language, it is essential\nthat we be allowed to nest default conditionals. For example, consider\nthe following English sentences:\n\n\nClose friends are (normally) people who (normally) trust one\nanother.\n\nPeople who (normally) rise early (normally) go to bed early.\n\n\nIn the first case, a conditional is nested within the consequent of\nanother conditional:\n\n\\(\\forall x \\forall y (\\textit{Friend}(x,y) \\Rightarrow \\forall z\n(\\textit{Time}(z) \\Rightarrow \\textit{Trust}(x,y,z)))\\)\n\nIn the second case, we seem to have conditionals nested within both\nthe antecedent and the consequent of a third conditional, something\nlike:\n\n\n\\(\\forall x (\\textit{Person}(x) \\rightarrow\\) \\(\\ \\ (\\forall\n  y(\\textit{Day}(y) \\Rightarrow \\textit{Rise-early}(x,y)) \\Rightarrow\n  \\forall z (\\textit{Day}(z) \\Rightarrow\n  \\textit{Bed-early}(x,z))))\\)\n\nThis nesting of conditionals can be made possible by borrowing and\nmodifying the semantics of the subjunctive or counterfactual\nconditional, developed by Robert Stalnaker and David K. Lewis (Lewis\n1973). For an axiomatization of Lewis\u2019s conditional logic, see\nthe following supplementary document:\n\nDavid Lewis\u2019s Conditional Logic\n\n\nThe only modification that is essential is to drop the condition of\nCentering (both strong and weak), a condition that makes modus ponens\n(affirming the antecedent) logically valid. If the conditional \\(\\Rightarrow\\)\nis to represent a default conditional, we do not want modus ponens to\nbe valid: we do not want \\((p \\Rightarrow q)\\) and \\(p\\)\nto entail \\(q\\) classically (i.e., monotonically). If Centering\nis dropped, the resulting logic can be made to correspond exactly to\neither a preferential or a rational defeasible entailment relation.\nFor example, the condition of Rational Monotony is the exact\ncounterpart of the CV axiom of Lewis\u2019s logic:\n\nCV: \n\\((p \\Rightarrow q) \\rightarrow [((p \\amp r) \\Rightarrow q) \\vee(p\n\\Rightarrow \\neg r )]\\)\n\n\nSomething like this was proposed first by James Delgrande (Delgrande\n1987), and the idea has been most thoroughly developed by Nicholas\nAsher and his collaborators (Asher and Morreau 1991; Asher 1995; Asher\nand Bonevac 1996; Asher and Mao 2001) under the name Commonsense\n Entailment.[7]\n Commonsense Entailment is a preferential (although not a rational)\nconsequence relation, and it automatically satisfies the Specificity\nprinciple. It permits the arbitrary nesting of default conditionals\nwithin other logical operators, and it can be used to represent\nundercutting defeaters, through the use of negated defaults (Asher and\nMao 2001).\n\nThe models of Commonsense Entailment differ significantly from those\nof preferential logic and the logic of extreme probabilities. Instead\nof having structures that contain sets of models of a\nstandard, default-free language, a model of the language of\nCommonsense Entailment includes a set of possible worlds,\ntogether with a function that assigns standard interpretation (a model\nof the default-free language) to each world. In addition, to each pair\nconsisting of a world \\(w\\) and a set of worlds (proposition) \\(A\\),\nthere is a function \\(*\\) that assigns a set of worlds \\({*}(w,A)\\) to\nthe pair. The set \\({*}(w,A)\\) is the set of most normal \\(A\\)-worlds,\nfrom the perspective of \\(w\\). A default conditional \\((p \\Rightarrow\nq)\\) is true in a world \\(w\\) (in such a model) just in case all of\nthe most normal \\(p\\) worlds (from \\(w\\)\u2019s perspective) are\nworlds in which \\(q\\) is also true. Since we can assign\ntruth-conditions to each such conditional, we can define the truth of\nnested conditionals, whether the conditionals are nested within\nBoolean operators or within other conditionals. Moreover, we can\ndefine both a classical, monotonic consequence relation for this class\nof models and a defeasible, nonmonotonic relation (in fact, the\nnonmonotonic consequence relation can be defined in a variety of\nways). We can then distinguish between a default conditional\u2019s\nfollowing with logical necessity from a default theory and\nits following defeasibly from that same theory.\nContraposition, for example \u2014 inferring \\((\\neg q \\Rightarrow\n\\neg p)\\) from \\((p \\Rightarrow q)\\) \u2014 is not logically valid\nfor default conditionals, but it might be a defeasibly correct\n inference.[8]\n\nThe one critical drawback to Commonsense Entailment, when compared to\nthe logic of extreme probabilities, is that it lacks a single, clear\nstandard of normativity. The truth-conditions of the default\nconditional and the definition of nonmonotonic consequence can be\nfine-tuned to match many of our intuitions, but in the end of the day,\nthe theory of Commonsense Entailment offers no simple answer to the\nquestion of what its conditional or its consequence relation are\nsupposed (ideally) to represent.\n\nLogics of extreme probability (beginning with the work of Ernest\nAdams) did not permit the nesting of default conditionals for this\nreason: the conditionals were supposed to represent something like\nsubjective conditional probabilities of the agent, to which the agent\nwas supposed to have perfect introspective access. Consequently, it\nmade no sense to nest this conditionals within disjunctions (as though\nthe agent couldn\u2019t tell which disjunct represented his actual\nprobability assignment) or within other conditionals (since the\nsubjective probability of a subjective probability is always trivial\n\u2014 either exactly 1 or exactly 0). However, there is no reason\nwhy the logic of extreme probabilities couldn\u2019t be given a\ndifferent interpretation, with \\((p \\Rightarrow q)\\)\nrepresenting something like the objective probability of\n\\(q\\), conditional on \\(p\\), is infinitely close to 1.\nIn this case, it makes perfect sense to nest such statements of\nobjective conditional probability within Boolean operators (either the\nprobability of \\(q\\) on \\(p\\) is close to 1, or the\nprobability of \\(r\\) on \\(s\\) is close to 1), or within\noperators of objective probability (the objective probability that the\nobjective probability of \\(p\\) is close to 1 is itself close to\n1). What is required in the latter case is a theory of\nhigher-order probabilities.\n\nFortunately, such a theory of higher-order probabilities is available\n(see Skyrms 1980; Gaifman 1988). The central principle of this theory\nis Miller\u2019s principle. For a description of the models of the\nlogic of extreme, higher-order probability, see the following\nsupplementary document:\n\nModels of Higher-Order Probability\n\n\nThe following proposition is logically valid in this logic,\nrepresenting the presence of a defeasible modus ponens rule:\n\n\\(((p \\amp(p \\Rightarrow q)) \\Rightarrow q)\\)\n\n\nThis system can be the basis for a family of rational nonmonotonic\nconsequence relations that include the Adams \\(\\varepsilon\\)-entailment\nsystem as a proper part (see Koons 2000, 298\u2013319).\n5.9 Objections to Nonmonotonic Logic\n5.9.1 Confusing Logic and Epistemology?\n\nIn an early paper (Israel 1980), David Israel raised a number of\nobjections to the very idea of nonmonotonic logic. First, he\npointed out that the nonmonotonic consequences of a finite theory are\ntypically not semi-decidable (recursively enumerable). This remains\ntrue of most current systems, but it is also true of second-order\nlogic, infinitary logic, and a number of other systems that are now\naccepted as logical in nature.\n\nSecondly, and more to the point, Israel argued that the concept of\nnonmonotonic logic evinces a confusion between the rules of\nlogic and rules of inference. In other words, Israel accused defenders\nof nonmonotonic logic of confusing a theory of defeasible inference (a\nbranch of epistemology) with a theory of genuine consequence relations\n(a branch of logic). Inference is nonmonotonic, but logic (according\nto Israel) is essentially monotonic.\n\nThe best response to Israel is to point out that, like deductive\nlogic, a theory of nonmonotonic or defeasible consequence has a number\nof applications besides that of guiding actual inference. Defeasible\nlogic can be used as part of a theory of scientific explanation, and\nit can be used in hypothetical reasoning, as in planning. It can be\nused to interpret implicit features of stories, even fantastic ones,\nso long as it is clear which actual default rules to suspend. Thus,\ndefeasible logic extends far beyond the boundaries of the theory of\nepistemic justification. Moreover, as we have seen, nonmonotonic\nconsequence relations (especially the preferential ones) share a\nnumber of very significant formal properties with classical\nconsequence, warranting the inclusion of them all in a larger family\nof logics. From this perspective, classical deductive logic is simply\na special case: the study of indefeasible consequence.\n5.9.2 Problems with the Deduction Theorem\n\nIn a recent paper, Charles Morgan (Morgan 2000) has argued that\nnonmonotonic logic is impossible. Morgan offers a series of\nimpossibility proofs. All of Morgan\u2019s proofs turn on the fact\nthat nonmonotonic logics cannot support a generalized deduction\ntheorem, i.e., something of the following form:\n\n\\(\\Gamma \\cup \\{p\\} \\dproves q\\) iff \\(\\Gamma \\dproves\n(p \\Rightarrow q)\\)\n\n\nMorgan is certainly right about this.\n\nHowever, there are good grounds for thinking that a system of\nnonmonotonic logic should fail to include a generalized\ndeduction theorem. The very nature of defeasible consequence ensures\nthat it must be so. Consider, for example, the left-to-right\ndirection: suppose that \\(\\Gamma \\cup \\{p\\} \\dproves q\\). Should it\nfollow that \\(\\Gamma \\dproves (p \\Rightarrow q)\\)? Not at all. It may\nbe that, normally, if \\(p\\) then \\(\\neg q\\), but \\(\\Gamma\\) may\ncontain defaults and information that defeat and override this\ninference. For instance, it might contain the fact \\(r\\) and the\ndefault \\(((r \\amp p) \\Rightarrow q)\\). Similarly, consider the\nright-to-left direction: suppose that \\(\\Gamma \\dproves (p \\Rightarrow\nq)\\). Should it follow that \\(\\Gamma \\cup \\{p\\} \\dproves q\\)? Again,\nclearly not. \\(\\Gamma\\) might contain both \\(r\\) and a default \\(((p\n\\amp r) \\Rightarrow \\neg q)\\), in which case \\(\\Gamma \\cup \\{p\\}\n\\dproves \\neg q\\).\n\nIt would be reasonable, however, to demand that a system of\nnonmonotonic logic satisfy the following special deduction\ntheorem:\n\n\\(\\{p\\} \\dproves q\\) iff \\(\\varnothing \\dproves (p \\Rightarrow q)\\)\n\n\nThis is certainly possible. The special deduction theorem holds\ntrivially; if we define\\(\\{p\\} \\dproves q\\) as \\(\\varnothing \\vDash(p\n\\Rightarrow q)\\); that is, \\(\\{p\\}\\) defeasibly entails \\(q\\) if and\nonly if (by definition) \\((p \\Rightarrow q)\\) is a theorem of the\nclassical conditional\n logic.[9]\n6. Causation and Defeasible Reasoning\n6.1 The Need for Explicit Causal Information\n\nHanks and McDermott, computer scientists at Yale, demonstrated that\nthe existing systems of nonmonotonic logic were unable to give the\nright solution to a simple problem about predicting the course of\nevents (Hanks and McDermott 1987). The problem became known as the\nYale shooting problem. Hanks and McDermott assume that some sort\nof law of inertia can be assumed: that normally properties of\nthings do not change. In the Yale shooting problem, there are two\nrelevant properties: being loaded (a property of a gun) and being\nalive (a property of the intended victim of the shooting). Let\u2019s\nassume that in the initial situation, \\(s_0\\), the gun\nis loaded and the victim is alive,\nLoaded\\((s_0)\\) and\nAlive\\((s_0)\\), and that two actions are\nperformed in sequence: Wait and Shoot. Let\u2019s\ncall the situation that results from a moment of waiting\n\\(s_1\\), and the situation that follows both waiting\nand then shooting \\(s_2\\). There are then three\ninstances of the law of inertia that are relevant:\n\nAlive\\((s_0) \\Rightarrow\\)\nAlive\\((s_1)\\)\nLoaded\\((s_0) \\Rightarrow\\)\nLoaded\\((s_1)\\)\nAlive\\((s_1) \\Rightarrow\\)\nAlive\\((s_2)\\)\n\n\nWe need to make one final assumption: that shooting the victim with a\nloaded gun results in death (not being alive):\n\n((Alive\\((s_1)\\) &\nLoaded\\((s_1)) \\rightarrow \\neg\\)Alive\\((s_2)\\)\n\n\nIntuitively, we should be able to derive the defeasible conclusion\nthat the victim is still alive after waiting, but dead after waiting\nand shooting: Alive\\((s_1) \\amp\n\\neg\\)Alive\\((s_2)\\). However, none of the nonmonotonic\nlogics described above give us this result, since each of the three\ninstances of the law of inertia can be violated: by the victim\u2019s\ninexplicably dying while we are waiting, by the gun\u2019s\nmiraculously becoming unloaded while we are waiting, or by the\nvictim\u2019s dying as a result of the shooting. Nothing introduced\ninto nonmonotonic logic up to this point provides us with a basis for\npreferring the second exception to the law of inertia to the first or\nthird. What\u2019s missing is a recognition of the importance of\ncausal structure to defeasible\nconsequence.[10]\n\nThere are several even simpler examples that illustrate the need to\ninclude explicitly causal information in the input to defeasible\nreasoning. Consider, for instance, this problem of Judea Pearl\u2019s\n(Pearl 1988): if the sprinkler is on, then normally the sidewalk is\nwet, and, if the sidewalk is wet, then normally it is raining.\nHowever, we should not infer that it is raining from the fact that the\nsprinkler is on. (See Lifschitz 1990 and Lin and Reiter 1994 for\nadditional examples of this kind.) Similarly, if we also know that if\nthe sidewalk is wet, then it is slippery, we should be able to infer\nthat the sidewalk is slippery if the sprinkler is on and it is\nnot raining.\n\nThe distinction between causal and evidential rules has been used in\nthe argumentative-narrative model of reasoning with evidence developed\nby Floris Bex and his colleagues (Bex et al. 2010; Bex 2011).\n6.2 Causally Grounded Independence Relations\n\nHans Reichenbach, in his analysis of the interaction of causality and\nprobability (Reichenbach 1956), observed that the immediate causes of\nan event probabilistically screen off from that event any\nother event that is not causally posterior to it. This means that,\ngiven the immediate causal antecedents of an event, the occurrence of\nthat event is rendered probabilistically independent of any\ninformation about non-posterior events. When this insight is applied\nto the nonmonotonic logic of extreme probabilities, we can use causal\ninformation to identify which defaults function independently of\nothers: that is, we can decide when the fact that one default\nconditional has an exception is irrelevant to the question of whether\na second conditional is also violated (see Koons 2000, 320\u2013323).\nIn effect, we have a selective version of Independence of Defaults\nthat is grounded in causal information, enabling us to dissolve the\nDrowning Problem.\n\nFor example, in the case of Pearl\u2019s sprinkler, since rain is\ncausally prior to the sidewalk\u2019s being wet, the causal structure\nof the situation does not ensure that the rain is probabilistically\nindependent of whether the sprinkler is on, given the fact that the\nsidewalk is wet. That is, we have no grounds for thinking that the\nprobability of rain, conditional on the sidewalk\u2019s being wet, is\nidentical to the probability of rain, conditional on the\nsidewalk\u2019s being wet and the sprinkler\u2019s being on\n(presumably, the former is higher than the latter). This failure of\nindependence prevents us from using the (Wet \\(\\Rightarrow\\)\nRain) default, in the presence of the additional fact that\nthe sprinkler is on. \n\nIn the case of the Yale shooting problem, the state of the gun\u2019s\nbeing loaded in the aftermath of waiting,\nLoaded\\((s_1)\\), has at its only causal\nantecedent the fact that the gun is loaded in \\(s_0\\).\nThe fact of Loaded\\((s_0)\\) screens off the\nfact that the victim is alive in \\(s_0\\) from the\nconclusion Loaded\\((s_1)\\). Similarly, the\nfact that the victim is alive in \\(s_0\\) screens off\nthe fact that the gun is loaded in \\(s_0\\) from the\nconclusion that the victim is still alive in \\(s_1\\).\nIn contrast, the fact that the victim is alive at\n\\(s_1\\) does not screen off the fact that the\ngun is loaded at \\(s_1\\) from the conclusion that the\nvictim is still alive at \\(s_2\\). Thus, we can assign\nhigher priority to the law of inertia with respect to both\nLoad and Alive at \\(s_0\\), and we can\nconclude that the victim is alive and the gun is loaded at\n\\(s_1\\). The causal law for shooting then gives us the\ndesired conclusion, namely, that the victim is dead at\n\\(s_2\\).\n6.3 Causal Circumscription\n\nOur knowledge of causal relatedness is itself very partial. In\nparticular, it is difficult for us to verify conclusively that any two\nrandomly selected facts are or are not causally related. It seems that\nin practice we apply something like Occam\u2019s razor, assuming that\ntwo randomly selected facts are not causally related unless we have\npositive reason for thinking otherwise. This invites the use of\nsomething like circumscription, minimizing the extension of the\npredicate causes. (This is in fact exactly what Fangzhen Lin\ndoes in his 1995 papers [Lin 1995].)\n\nOnce we have a set of tentative conclusions about the causal structure\nof the world, we can use Reichenbach\u2019s insight to enable us to\nlocalize the problem of reasoning by default in the presence of known\nabnormality. If a known abnormality is screened off from a\ndefault\u2019s rule\u2019s consequent by constituent of its\nantecedent, then the rule may legitimately be deployed. \n\nSince circumscription is itself a nonmonotonic logical system, there\nare at least two independent sources of nonmonotonicity, or\ndefeasibility: the minimization or circumscription of causal\nrelevance, and the application of defeasible causal laws and laws of\ninertia.\n\nA number of researchers in artificial intelligence have recently\ndeployed one version of circumscription (namely, the stable\nmodels of Gelfond and Lifschitz [1988]) to problems of causal\nreasoning, building on an idea of Norman McCain and Hudson\nTurner\u2019s [McCain and Turner 1997]. McCain and Turner employ\ncausal rules that specify when an atomic fact is adequately caused and\nwhen it is exogenous and not in need of causal explanation. They then\nassume a principle of universal causation, permitting only\nthose models that provide adequate causal explanations for all\nnon-exempt atomic facts, while in effect circumscribing the extension\nof the causally explained. This approach has been extended and applied\nby Giunchiglia, Lee, Lifschitz, McCain and Turner [2004], Ferraris\n[2007], and Ferraris, Lee, Lierler, Lifschitz and Yang [2012]. Joohyung\nLee and Yi Wang (Lee and Wang 2016) have focused on introducing\nrelative weights to the rules.\n7. Implementations and Applications\n7.1 Applications to Law\n\nPrakken (1997) book provides an extensive treatment of the\ncontributions of techniques from nonmonotonic logic to the formal\nmodeling of legal reasoning. See also Prakken and Sartor (1996, 1998),\nHage et al. (1993), Hage (1997), Lodder (1999), and Bench-Capon et\nal. (2004, 2009). Kevin Ashley\u2019s HYPO system (Ashley 1990) employs\ndefeasible reasoning in the study of case-based reasoning in the\nlaw.\n7.2 Reasoning about Probabilities\n\nSections 5.7\nand 5.8 above\ndiscussed probabilistic semantics for defeasible logics. It is also\npossible to reason defeasibly about propositions\nthat explicitly involve numerical probabilities. We can\nreason defeasibly about propositions that assign specific\nprobabilities to the other propositions or that assert numerical\nrelations (identity, inequalities) between such propositions.\n\nChitta Baral, Michael Gelfond, and Nelson Rushton (Baral et al. 2009)\nhave developed a declarative language P-Log, which combines defeasible\nlogic with Bayesian probability nets. They use Answer Set Prolog to\nprovide the logical foundations. They make use of a version of the\nprinciple of indifference. Belief revision occurs by means of Bayesian\nconditioning. Baral et al. demonstrate that P-log can reason correctly\nabout the Monty Hall problem and Simpson\u2019s paradox. See Gelfond and\nKahl 2014, pp. 235\u2013270 for the syntax and semantics of P-log.\n\nJoohyung Lee and Yi Wang (Lee and Wang 2016) take a somewhat different\napproach, using the log-linear models of Markov Logic (Richardson and\nDomingos 2006), which they argue is a natural way to add probabilistic\ninformation to stable semantics for logic programming languages. A\nMarkov Logic network is a way of finding the probability distribution\nto a Markov chain that is stationary, i.e., stable with\nrespect to updating. Their approach incorporates the ProbLog model of\nFierens et al. 2015 as a special case.\n\nAnthony Hunter has developed a strategy for using argumentation theory\nto reason with incomplete and even inconsistent information about\nprobabilities (Hunter 2020). Once inconsistencies have been eliminated\nby belief contraction, Hunter relies on the maximum entropy\ndistribution that is consistent with the remaining constraints to\ndefine the optimal probability function.\n7.3 Software Implementations\n\nArguMed by Verheij (Verheij 2005) computes a version of\nstable semantics. Chris Reed and Glenn Rowe (Reed and Rowe 2004) have\ndeveloped Araucaria, an application for analyzing and\ndiagramming legal arguments. Prakken\u2019s ASPIC+ system (Prakken\n2010) can be used in analyzing formal argumentative structures.\n\nMichael Gelfond and Yulia Kahl (Gelfond and Kahl 2014, 131\u2013151)\ndiscuss how to develop algorithms for efficiently computing answer\nsets for logic programming. They describe inference engines that can\nact as answer-set programming solvers.\n7.4 Efficiency in Updating\n\nAn important practical problem that arises from applying formal models\nof defeasible reasoning is that of updating in light of new or\nretracted information. Must we re-compute the nonmonotonic\nconsequences from scratch each time updating is required?\n\nBeishui Liao and his collaborators (Liao et al. 2011) addressed the\nissue of the computational dynamics of argument systems by\ninvestigating under which conditions an argument system can be divided\ninto modules, so that the implications of new information can be\nefficiently computed by updating only the affected module. They\ndiscovered that such modularity is possible for any semantics that has\nthe property of directionality. A semantics is directional if\nand only if, for every argument structure AS, the\nintersection of any extension prescribed for AS with an\nunattacked set /(U/) is identical to one of the extensions prescribed\nfor the restriction of AS to \\(U\\), and vice versa. See also\nBaroni et al. 2018.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Adams, Ernest W., 1975, <em>The Logic of Conditionals</em>,\nDordrecht: Reidel.",
                "Alchourr\u00f3n, C., G\u00e4rdenfors, P. and Makinson, D., 1982,\n\u201cOn the logic of theory change: contraction functions and their\nassociated revision functions\u201d, <em>Theoria</em>, 48:\n14\u201337.",
                "Arl\u00f3 Costa, Horacio and Parikh, Rohit, 2005,\n\u201cConditional Probability and Defeasible Inference\u201d,\n<em>Journal of Philosophical Logic</em>, 34: 97\u2013119.",
                "Armstrong, David M., 1983, <em>What is a law of nature?</em>, New\nYork: Cambridge University Press.",
                "\u2013\u2013\u2013, 1997, <em>A world of states of\naffairs</em>, Cambridge: Cambridge University Press.",
                "Asher, Nicholas, 1992, \u201cA Truth Conditional, Default\nSemantics for Progressive\u201d, <em>Linguistics and Philosophy</em>,\n15: 469\u2013508.",
                "\u2013\u2013\u2013, 1995, \u201cCommonsense Entailment: a\nlogic for some conditionals\u201d, in <em>Conditionals in Artificial\nIntelligence</em>, G. Crocco, L. Farinas del Cerro, and A. Hertzig\n(eds.), Oxford: Oxford University Press.",
                "Asher, Nicholas and Daniel Bonevac, 1996, \u201cPrima Facie\nObligations\u201d, <em>Studia Logica</em>, 57: 19\u201345.",
                "Asher, Nicholas, and Alex Lascarides,  2003, <em>Logics of\nConversation</em>, Cambridge: Cambridge University Press.",
                "Asher, N.. and Y. Mao, 2001, \u201cNegated Defaults in\nCommonsense Entailment\u201d, <em>Bulletin of the Section of\nLogic</em>, 30: 4\u201360.",
                "Asher, Nicholas, and Michael Morreau, 1991, \u201cCommonsense\nEntailment: A Modal, Nonmonotonic Theory of Reasoning\u201d, in\n<em>Proceedings of the Twelfth International Joint Conference on\nArtificial Intelligence</em>, John Mylopoulos and Ray Reiter (eds.),\nSan Mateo, Calif.: Morgan Kaufmann.",
                "Asher, N., and F.J. Pelletier, 1997, \u201cGenerics and\nDefaults\u201d, in <em>Handbook of Logic and Language</em>, J. van\nBentham and A. ter Meulen (eds.), Amsterdam: Elsevier.",
                "Ashley, Kevin D., 1990, <em>Modeling legal argument: Reasoning\nwith cases and hypotheticals</em>, Cambridge, MA: MIT Press. ",
                "Baker, A. B., 1988, \u201cA simple solution to the Yale shooting\nproblem\u201d, in <em>Proceedings of the First International\nConference on Knowledge Representation and Reasoning</em>, Ronald J.\nBrachman, Hector Levesque and Ray Reiter (eds.), San Mateo, Calif.:\nMorgan Kaufmann.",
                "Bamber, Donald, 2000, \u201cEntailment with Near Surety of Scaled\nAssertions of High Conditional Probability\u201d, <em>Journal of\nPhilosophical Logic</em>, 29: 1\u201374.",
                "Baroni, Pietro, Massimiliano Giacomin, and Beishui Liao, 2018,\n\u201cLocality and Modularity in Abstract Argumentation\u201d, in\nP. Baroni, D. Gabbay, Massimiliano Giacomin, and Leendert van der\nTorre (eds.), <em>The Handbook of Formal Argumentation</em>, London:\nCollege Publications, 937\u2013979.",
                "Bench-Capon, T. J. M., H. Prakken, and G Sartor, 2009,\n\u201cArgumentation in legal reasoning\u201d, in I. Rahwan and\nG. R. Simari (eds.), <em>Argumentation in Artificial\nIntelligence</em>, Dordrecht: Springer, pp. 363\u2013382.",
                "Bex, F. J., 2011, <em>Arguments, stories and criminal evidence: A\nformal hybrid theory</em>, Dordrecht: Springer. ",
                "Bex, F. J., P. van Koppen, H. Prakken, and B. Verheij, 2010,\n\u201cA hybrid formal theory of arguments, stories and criminal\nevidence\u201d, <em>Artificial Intelligence and Law</em>, 18(2):\n123\u2013152.",
                "Bochman, Alexander, 2001, <em>A Logical Theory of Nonmonotonic\nInference and Belief Change</em>, Berlin: Springer.",
                "Bodanza, Gustavo A. and F. Tohm\u00e9, 2005, \u201cLocal\nLogics, Non-Monotonicity and Defeasible Argumentation\u201d,\n<em>Journal of Logic, Language and Information</em>, 14:\n1\u201312.",
                "Bonevac, Daniel, 2003, <em>Deduction: Introductory Symbolic\nLogic</em>, Malden, Mass.: Blackwell, 2nd edition.",
                "Carnap, Rudolf, 1962, <em>Logical Foundations of Probability</em>,\nChicago: University of Chicago Press.",
                "Carnap, Rudolf and Richard C. Jeffrey, 1980, <em>Studies in\ninductive logic and probability</em>, Berkeley: University of\nCalifornia Press.",
                "Cartwright, Nancy, 1983, <em>How the laws of physics lie</em>,\nOxford: Clarendon Press.",
                "Chisholm, Roderick, 1957, <em>Perceiving</em>, Princeton:\nPrinceton University Press.",
                "\u2013\u2013\u2013, 1963, \u201cContrary-to-Duty Imperatives\nand Deontic Logic\u201d, <em>Analysis</em>, 24: 33\u201336.",
                "\u2013\u2013\u2013, 1966, <em>Theory of Knowledge</em>,\nEnglewood Cliffs: Prentice-Hall.",
                "Dancy, Jonathan, 1993, <em>Moral Reasons</em>, Malden, MA:\nWiley-Blackwell.",
                "\u2013\u2013\u2013, 2004, <em>Ethics without Principles</em>,\nOxford: Clarendon Press.",
                "Delgrande, J. P., 1987, \u201cA first-order conditional logic for\nprototypical properties\u201d, <em>Artificial Intelligence</em>, 33:\n105\u2013130.",
                "Dung, Phan Minh, 1995, \u201cOn the acceptability of arguments\nand its fundamental role in non-monotonic reasoning logic programming\nand n-person games\u201d, <em>Artificial Intelligence</em>, 77:\n321\u2013357.",
                "Dung, Phan Minh and Phan Minh Thang, 2010, \u201cTowards\n(probabilistic) argumentation for jury-based dispute\nresolution\u201d, in P. Baroni, F. Cerutti, M. Giacomin, and\nG. R. Simari (eds.), <em>Computational Models of Argument: Proceedings\nof COMMA 2010</em>, Amsterdam: Ios Press, 171\u2013182).",
                "\u2013\u2013\u2013, 2018, \u201cFundamental properties of\nattack relations in structured argumentation with\npriorities\u201d, <em>Artificial Intelligence</em>, 255:\n1\u201342.",
                "Etherington, D. W. and R. Reiter, 1983, \u201cOn Inheritance\nHierarchies and Exceptions\u201d, in <em>Proceedings of the National\nConference on Artificial Intelligence</em>, Los Altos, Calif.: Morgan\nKaufmann.",
                "Ferraris, Paolo, 2007, \u201cA Logic Programming Characterization\nof Causal Theories\u201d, <em>Proceedings of the Twentieth\nInternational Joint Conference on Artificial Intelligence</em>, San\nFrancisco, Calif.: Morgan Kaufmann.",
                "Ferraris, Paolo, with J. Lee, Y. Lierler, V. Lifschitz, and F.\nYang, 2012, \u201cRepresenting first-order causal theories by logic\nprograms\u201d, <em>Theory and Practice of Logic Programming</em>,\n12(3): 383\u2013412.",
                "Fierens, D, G. van den Broeck, J. Renkens, D. Shterionov,\nB. Guttman, I. Thon, G. Janssens, and L. de Readt, 2015,\n\u201cInference and learning in probabilistic logic using weighted\nBoolean formulas\u201d, <em>Theory and Practice of Logic\nProgramming</em>, 15(03): 358\u2013401.",
                "Freund, M., with D. Lehmann, and D. Makinson, 1990,\n\u201cCanonical extensions to the infinite case of finitary\nnonmonotonic inference relations\u201d, in <em>Proceedings of the\nWorkshop on Nonmonotonic Reasoning</em>, G. Brewka and H. Freitag\n(eds.), Sankt Augustin: Gesellschaft f\u00fcr Mathematic und\nDatenverarbeitung mbH.",
                "Freund, M., 1993, \u201cInjective models and disjunctive\nrelations\u201d, <em>Journal of Logic and Computation</em>, 3:\n231\u2013347.",
                "Gabbay, D. M., 1985, \u201cTheoretical foundations for\nnon-monotonic reasoning in expert systems\u201d, in <em>Logics and\nModels of Concurrent Systems</em>, K. R. Apt (ed.), Berlin:\nSpringer-Verlag.",
                "Gaifman, Haim, 1988, \u201cA theory of higher-order\nprobabilities\u201d, in <em>Causation, Chance and Credence</em>,\nBrian Skyrms and William Harper (eds.), London, Ontario: University of\nWestern Ontario Press.",
                "G\u00e4rdenfors, P., 1978, \u201cConditionals and Changes of\nBelief\u201d, <em>Acta Fennica</em>, 30: 381\u2013404.",
                "\u2013\u2013\u2013, 1986, \u201cBelief revisions and the\nRamsey test for conditionals\u201d, <em>Philosophical Review</em>,\n95: 81\u201393.",
                "Geffner, H. A., 1992, <em>Default Reasoning: Causal and\nConditional Theories</em>, Cambridge, MA: MIT Press.",
                "Geffner, H. A., and J. Pearl, 1992, \u201cConditional entailment:\nbridging two approaches to default reasoning\u201d, <em>Artificial\nIntelligence</em>, 53: 209\u2013244.",
                "Gelfond, Michael and Yulia Kahl, 2014, <em>Knowledge\nRepresentation, Reasoning, and the Design of Intelligent Agents: The\nAnswer-Set Programming Approach</em>, Cambridge: Cambridge University\nPress.",
                "Gelfond, Michael and Leone, N., 2002, \u201cLogic programming and\nknowledge representation\u2014the A-prolog perspective\u201d,\n<em>Artificial Intelligence</em>, 138: 37\u201338.",
                "Gelfond, Michael and Lifschitz, Vladimir, 1988, \u201cThe stable\nmodel semantics for logic programming\u201d, <em>Logic Programming:\nProceedings of the Fifth International Conference and Symposium</em>,\nRobert A. Kowalski and Kenneth A. Bowen (eds.), Cambridge, Mass.: The\nMIT Press, pp. 1070\u20131080.",
                "Gilio, Angelo, 2005, \u201cProbabilistic Logic under Coherence,\nConditional Interpretations, and Default Reasoning\u201d,\n<em>Synthese</em>, 146: 139\u2013152.",
                "Ginsberg, M. L., 1987, <em>Readings in Nonmonotonic\nReasoning</em>, San Mateo, Calif.: Morgan Kaufmann.",
                "Giunchiglia, E., with J. Lee, V. Lifschitz, N. McCain, and H.\nTurner, 2004, \u201cNonmonotonic Causal Theories\u201d, <em>Artificial\nIntelligence</em>, 153: 49\u2013104.",
                "Goldszmidt, M. and J. Pearl, 1992, \u201cRank-Based Systems: A\nSimple Approach to Belief Revision, Belief Update, and Reasoning about\nEvidence and Action\u201d, in <em>Proceedings of the Third\nInternational Conference on Principles of Knowledge Representation and\nReasoning</em>, San Mateo, Calif.: Morgan Kaufmann.",
                "Goldszmidt, M., with P. Morris, and J. Pearl, 1993, \u201cA\nmaximum entropy approach to nonmonotonic reasoning\u201d, <em>IEEE\nTransactions on Pattern Analysis and Machine Intelligence</em>, 15:\n220\u2013232.",
                "Grove, A., 1988, \u201cTwo modellings for theory change\u201d,\n<em>Journal of Philosophical Logic</em>, 17: 157\u2013170.",
                "Hage, J. C., 1997, <em>Reasoning with rules: An essay on legal\nreasoning and its underlying logic</em>, Dordrecht: Kluwer\nAcademic.",
                "\u2013\u2013\u2013, 2000, \u201cDialectical models in\nartificial intelligence and law\u201d, <em>Artificial Intelligence\nand Law</em>, 8: 137\u2013172.",
                "Hanks, Steve and Drew McDermott, 1987, \u201cNonmonotonic Logic\nand Temporal Projection\u201d, <em>Artificial Intelligence</em>, 33:\n379\u2013412.",
                "Hansson, B., 1969, \u201cAn analysis of some deontic\nlogics\u201d, <em>No\u00fbs</em>, 3: 373\u2013398. ",
                "Hansson, S. O. and Makinson, D., 1997, \u201cApplying normative\nrules with restraint\u201d, in <em>Logic and Scientific Methods</em>,\nM. Dalla Chiara (ed.), Dordrecht: Kluwer. ",
                "Harper, W. L., 1976, \u201cRational Belief Change, Popper\nFunctions and Counterfactuals\u201d, in <em>Foundations of\nProbability Theory, Statistical Inference, and Statistical Theories of\nScience, Volume I</em>, Dordrecht: Reidel.",
                "Hart, H. L. A., 1949, \u201cThe ascription of responsibility and\nrights\u201d, <em>Proceedings of the Aristotelian Society</em>,\n49(1): 171\u2013194.",
                "Hawthorne, James, 1998, \u201cOn the Logic of Nonmonotonic\nConditionals and Conditional Probabilities: Predicate Logic\u201d,\n<em>Journal of Philosophical Logic</em>, 27: 1\u201334.",
                "Horty, J. F., with R.H. Thomason, and D.S. Touretzky, 1990,\n\u201cA sceptical theory of inheritance in nonmonotonic semantic\nnetworks\u201d, <em>Artificial Intelligence</em>, 42:\n311\u2013348.",
                "Horty, John, 1994, \u201cMoral dilemmas and nonmonotonic\nlogic\u201d, <em>Journal of Philosophical Logic</em>, 23:\n35\u201365. ",
                "\u2013\u2013\u2013, 2003, \u201cReasoning with moral\nconflicts\u201d, <em>No\u00fbs</em>, 37: 557\u2013605. ",
                "\u2013\u2013\u2013, 2007a, \u201cDefaults with\nPriorities\u201d, <em>Journal of Philosophical Logic</em>, 36:\n367\u2013413.",
                "\u2013\u2013\u2013, 2007b, \u201cReasons as defaults\u201d,\n<em>Philosophers\u2019 Imprints</em>, 7: 1\u201328. ",
                "Hunter, Anthony, 2013, \u201cA probabilistic approach to\nmodelling uncertain logical arguments\u201d, <em>International\nJournal of Approximate Reasoning</em>, 54(1): 47\u201381.",
                "\u2013\u2013\u2013, \u201cReasoning with Inconsistent\nKnowledge using the Epistemic Approach to Probabilistic\nArgumentation\u201d, <em>Proceedings of the 17th International\nConference on Principles of Knowledge Representation and Reasoning\n(KR\u201920)</em>, Palo Alto: AAAI Press.",
                "Israel, David, 1986, \u201cWhat\u2019s Wrong with Non-monotonic\nLogic\u201d, in <em>Proceedings of the First National Conference on\nArtificial Intelligence</em>, Palo Alto: AAAI Press.",
                "Karacapilidis, N., and D. Papadias, 2001, \u201cComputer\nsupported argumentation and collaborative decision making: The HERMES\nsystem\u201d, <em>Information Systems</em>, 26: 259\u2013277.",
                "Konolige, Kurt, 1994, \u201cAutoepistemic Logic\u201d, in\n<em>Handbook of Logic in Artificial Intelligence and Logic\nProgramming, Volume III: Nonmonotonic Reasoning and Uncertain\nReasoning</em>, D. M. Gabbay, C. J. Hogger, and J. A. Robinson (eds.),\nOxford: Clarendon Press.",
                "Koons, Robert C., 2000, <em>Realism Regained: An Exact Theory of\nCausation, Teleology and the Mind</em>, New York: Oxford University\nPress.",
                "\u2013\u2013\u2013, 2001, \u201cDefeasible Reasoning, Special\nPleading and the Cosmological Argument: Reply to Oppy\u201d,\n<em>Faith and Philosophy</em>, 18: 192\u2013203.",
                "Kraus, S., with D. Lehmann, and M. Magidor, 1990,\n\u201cNonmonotonic Reasoning, Preferential Models and Cumulative\n\nLogics\u201d, <em>Artificial Intelligence</em>, 44:\n167\u2013207.",
                "Kyburg, Henry E., 1983, <em>Epistemology and Inference</em>,\nMinneapolis: University of Minnesota Press.",
                "\u2013\u2013\u2013, 1990, <em>Knowledge Representation and\nDefeasible Reasoning</em>, Dordrecht: Kluwer.",
                "Lance, Mark and Margaret Little, 2004, \u201cDefeasibility and\nthe normative grasp of context\u201d, <em>Erkenntnis</em>, 61:\n435\u201355. ",
                "\u2013\u2013\u2013, 2007, \u201cWhere the laws are\u201d,\n<em>Oxford Studies in Metaethics</em>, 2: 149\u2013171.",
                "Lascarides, Alex and Nicholas Asher, 1993, \u201cTemporal\nInterpretation, Discourse Relations and Commonsense Entailment\u201d,\n<em>Linguistics and Philosophy</em>, 16: 437\u2013493.",
                "Lee, Joohyung and Yi Wang, 2016, \u201cWeighted Rules under the\nStable Model Semantics\u201d, in <em>Proceedings of the 15th\nInternational Conference on Principles of Knowledge Representation and\nReasoning (KR 2016)</em>, Palo Alto: AAAI Press,\npp. 145\u2013154.",
                "Lehmann, D., and M. Magidor, 1992, \u201cWhat does a conditional\nknowledge base entail?\u201d, <em>Artificial Intelligence</em>, 55:\n1\u201360.",
                "Levesque, H., 1990, \u201cA study in autoepistemic logic\u201d,\n<em>Artificial Intelligence</em>, 42: 263\u2013309.",
                "Lewis, David K., 1973, <em>Counterfactuals</em>, Cambridge, Mass.:\nHarvard University Press.",
                "Liao, Beishui, Li Jin, and Robert C. Koons, 2011, \u201cDynamics\nof argumentation systems: A division-based\nmethod\u201d, <em>Artificial Intelligence</em>, 175(11):\n1790\u20131814.",
                "Liao, Beishui, Nir Oren, Leendert van der Torre, and Serena\nVillata, 2019, \u201cPrioritized Norms in Formal\nArgumentation\u201d, <em>Journal of Logic and Computation</em>, 29(2):\n215\u2013240.",
                "Lifschitz, V., 1988, \u201cCircumscriptive theories: a\nlogic-based framework for knowledge representation\u201d, <em>Journal\nof Philosophical Logic</em>, 17: 391\u2013441.",
                "\u2013\u2013\u2013, 1989, \u201cBenchmark Problems for Formal\nNonmonotonic Reasoning\u201d, in <em>Non-Monotonic Reasoning</em>, M.\nReinfrank, J. de Kleer, M. L. Ginsberg and E. Sandewall (eds.),\nBerlin: Springer-Verlag.",
                "\u2013\u2013\u2013, 1990, \u201cFrames in the space of\nsituations\u201d, <em>Artificial Intelligence</em>, 46:\n365\u2013376.",
                "Lin, Fangzhen, 1995, \u201cEmbracing causality in specifying the\nindirect effects of actions\u201d, <em>Proceedings of the Fourteenth\nInternational Joint Conference on Artificial Intelligence</em>, San\nMateo, Calif.: Morgan Kaufmann, pp. 1985\u20131993.",
                "Lin, Fangzhen, and Robert Reiter, 1994, \u201cState constraints\nrevisited\u201d, <em>Journal of Logic and Computation</em>, 4:\n655\u2013678.",
                "Lukasiewicz, Thomas, 2005, \u201cNonmonotonic Probabilistic\nReasoning under Variable-Strength Inheritance with Overriding\u201d,\n<em>Synthese</em>, 146: 153\u2013169.",
                "McCain, Norman and Hudson Turner, 1997, \u201cCausal theories of\naction and change\u201d, in <em>Proceedings of the Fourteenth\nNational Conference on Artificial Intelligence (AAAI)</em>, Cambridge,\nMass.: The MIT Press, pp. 460\u20135.",
                "McCarthy, John M. and Patrick J. Hayes, 1969, \u201cSome\nPhilosophical Problems from the Standpoint of Artificial\nIntelligence\u201d, in <em>Machine Intelligence 4</em>, B. Meltzer\nand D. Mitchie (eds.), Edinburgh: Edinburgh University Press.",
                "\u2013\u2013\u2013, 1977, \u201cEpistemological Problems of\nArtificial Intelligence\u201d, in <em>Proceedings of the 5th\nInternational Joint Conference on Artificial Intelligence</em>,\nPittsburgh: Computer Science Department, Carnegie-Mellon\nUniversity.",
                "\u2013\u2013\u2013, 1982, \u201cCircumscription \u2014 A Form\nof Non-Monotonic Reasoning\u201d, <em>Artificial Intelligence</em>,\n13: 27\u201339, 171\u2013177.",
                "\u2013\u2013\u2013, 1986, \u201cApplication of Circumscription\nto Formalizing Common-Sense Knowledge\u201d, <em>Artificial\nIntelligence</em>, 28: 89\u2013111.",
                "McDermott, Drew and Jon Doyle, 1982, \u201cNon-Monotonic Logic\nI\u201d, <em>Artificial Intelligence</em>, 13: 41\u201372.",
                "Makinson, David, 1994, \u201cGeneral Patterns in Nonmonotonic\nReasoning\u201d, in <em>Handbook of Logic in Artificial Intelligence\nand Logic Programming, Volume III: Nonmonotonic Reasoning and\nUncertain Reasoning</em>, D. M. Gabbay, C. J. Hogger, and J. A.\nRobinson (eds.), Oxford: Clarendon Press.",
                "\u2013\u2013\u2013, 2005, <em>Bridges from Classical to\nNonmonotonic Logic</em>, London: King\u2019s College\nPublications.",
                "Makinson, David and G\u00e4rdenfors, Peter, 1991, \u201cRelations\nbetween the logic of theory change and Nonmonotonic Logic\u201d, in\n<em>Logic of Theory Change</em>, A. Fuhrmann and M. Morreau (eds.),\nBerlin: Springer-Verlag.",
                "Makinson, David and van der Torre, L., 2000, \u201cInput/output\nlogics\u201d, <em>Journal of Philosophical Logic</em>, 29:\n155\u201385. ",
                "Morgan, Charles, 2000, \u201cThe Nature of Nonmonotonic\nReasoning\u201d, <em>Minds and Machines</em>, 10: 321\u2013360.",
                "Moore, Robert C., 1985, \u201cSemantic Considerations on\nNonmonotonic Logic\u201d, <em>Artificial Intelligence</em>, 25:\n75\u201394.",
                "Morreau, M., and N. Asher, 1995, \u201cWhat some generic\nsentences mean\u201d, in <em>The Generic Book</em>, J. Pelletier\n(ed.), Chicago: University of Chicago Press.",
                "Nayak, A. C., 1994, \u201cIterated belief change based on\nepistemic entrenchment\u201d, <em>Erkenntnis</em>, 41:\n353\u2013390.",
                "Nute, Donald, 1988, \u201cConditional Logic\u201d, in\n<em>Handbook of Philosophical Logic, Volume II: Extensions of\nClassical Logic</em>, D. Gabbay and F. Guenthner (eds.), Dordrecht: D.\nReidel.",
                "\u2013\u2013\u2013, 1997, <em>Defeasible Deontic Logic</em>,\nDordrecht: Kluwer.",
                "Pearl, Judea, 1988, <em>Probabilistic Reasoning in Intelligent\nSystems: Networks of Plausible Inference</em>, San Mateo, Calif.:\nMorgan Kaufmann.",
                "\u2013\u2013\u2013, 1990, \u201cSystem Z: A Natural Ordering\nof Defaults with Tractable Applications to Default Reasoning\u201d,\nProceedings of the Third Conference on Theoretical Aspects of\nReasoning about Knowledge, Rohit Parikh (ed.), San Mateo, Calif.:\nMorgan Kaufmann.",
                "Pelletier, F. J. and R. Elio, \u201cOn Relevance in Nonmonotonic\nReasoning: Some Empirical Studies\u201d, in R. Greiner &amp; D.\nSubramanian (eds) <em>Relevance: AAAI 1994 Fall Symposium Series</em>,\nPalo Alto: AAAI Press.",
                "Pollock, John L., 1967, \u201cCriteria and our knowledge of the\nmaterial world\u201d, <em>Philosophical Review</em>, 76:\n28\u201362.",
                "\u2013\u2013\u2013, 1970, \u201cThe structure of epistemic\njustification\u201d, <em>American Philosophical Quarterly</em>\n(Monograph Series), 4: 62\u201378.",
                "\u2013\u2013\u2013, 1974, <em>Knowledge and Justification</em>,\nPrinceton: Princeton University Press.",
                "\u2013\u2013\u2013, 1987, \u201cDefeasible Reasoning\u201d,\n<em>Cognitive Science</em>, 11: 481\u2013518.",
                "\u2013\u2013\u2013, 1995, <em>Cognitive Carpentry</em>,\nCambridge, Mass.: MIT Press.",
                "\u2013\u2013\u2013, 2010, \u201cDefeasible reasoning and\ndegrees of justification\u201d, <em>Argument &amp; Computation</em>,\n1(1): 7\u201322.",
                "Prakken, Henry, 2010, \u201cAn abstract framework for\nargumentation with structured arguments\u201d, <em>Argument and\nComputation</em>, 1: 93\u2013124.",
                "Prakken, Henry and Giovanni Sartor, 1995, \u201cOn the relation\nbetween legal language and legal argument: assumptions, applicability,\nand dynamic priorities\u201d, in <em>Proceedings of the Fifth\nInternational Conference on Artificial Intelligence and the Law\n(ICAIL-95)</em>, New York: The ACM Press.",
                "\u2013\u2013\u2013, 1996, \u201cA dialectical model of\nassessing conflicting arguments in legal reasoning\u201d,\n<em>Artificial Intelligence and the Law</em>, 4: 331\u2013368.",
                "Prakken, H., and Vreeswijk, G. A. W., 2002, \u201cLogics for\ndefeasible argumentation\u201d, in D. Gabbay and F. Guenthner\n(eds.), <em>Handbook of philosophical logic</em> (2nd edition, Volume\n4), Dordrecht: Kluwer, pp. 219\u2013318.",
                "Quine, Willard van Orman, and J.S. Ullian, 1982, <em>The Web of\nBelief</em>, New York: Random House.",
                "Raz, Joseph, 1975, <em>Practical Reasoning and Norms</em>, London:\nHutchinson and Company.",
                "Reed, Christopher A. and Rowe, G. W. A., 2004, \u201cAraucaria:\nSoftware for argument analysis, diagramming and\nrepresentation\u201d, <em>International Journal on Artificial\nIntelligence Tools</em>, 13(4): 961\u2013979. ",
                "Reiter, Ray, 1980, \u201cA logic for default reasoning\u201d,\n<em>Artificial Intelligence</em>, 13: 81\u2013137.",
                "Richardson, M. and P. Domingos, 2006, \u201cMarkov logic\nnetworks\u201d, <em>Machine Learning</em>, 62(1\u20133):\n107\u2013136.",
                "Ross, David, 1930, <em>The Right and the Good</em>, Oxford: Oxford\nUniversity Press.",
                "\u2013\u2013\u2013, 1939, <em>Foundations of Ethics</em>,\nOxford: Clarendon Press.",
                "Rott, Hans, 1989, \u201cConditionals and Theory Change:\nRevisions, Expansions and Additions\u201d, <em>Synthese</em>, 81:\n91\u2013113.",
                "Schlechta, Karl, 1997, <em>Nonmonotonic Logics: Basic Concepts,\nResults and Techniques</em>, Berlin: Springer-Verlag.",
                "Shoham, Yoav, 1987, \u201cA Semantical Approach to Nonmonotonic\nLogic\u201d, in <em>Proceedings of the Tenth International Conference\non Artificial Intelligence</em>, John McDermott (ed.), Los Altos,\nCalif.: Morgan Kaufmann.",
                "Skyrms, Brian, 1980, \u201cHigher order degrees of belief\u201d,\nin <em>Prospects for Pragmatism</em>, Hugh Mellor (ed.), Cambridge:\nCambridge University Press.",
                "Spohn, Wolfgang, 1988, \u201cOrdinal Conditional\nFunctions\u201d, in <em>Causation, Decision, Belief Change and\nStatistics, Volume III</em>, W. L. Harper and B. Skyrms (eds.),\nDordrecht: Kluwer.",
                "\u2013\u2013\u2013, 2002, \u201cA Brief Comparison of\nPollock\u2019s Defeasible Reasoning and Ranking Functions\u201d,\n<em>Synthese</em>, 13: 39\u201356.",
                "Tohm\u00e9, Fernando, with Claudio Delrieux and Ot\u00e1vio\nBueno, 2011, \u201cDefeasible Reasoning + Partial Models: A Formal\nFramework for the Methodology of Research Programs\u201d,\n<em>Foundations of Science</em>, 16: 47\u201365.",
                "Toulmin, Stephen E., 1964, <em>The Uses of Argument</em>,\nCambridge: Cambridge University Press.",
                "Txurruka, I. and N. Asher, 2008, \u201cA discourse-based approach\nto Natural Language Disjunction (revisited)\u201d, in M. Aunargue, K.\nKorta and J. Lazzarabal (eds.), <em>Language, Representation and\nReasoning</em>, University of the Basque Country Press.",
                "van der Torre, Leendert and Srdjan Vesic, 2018, \u201cThe\nPrinciple-Based Approach to Abstract Argumentation Semantics\u201d,\nin P. Baroni, D. Gabbay, Massimiliano Giacomin, and Leendert van der\nTorre (eds.), <em>The Handbook of Formal Argumentation</em>, London:\nCollege Publications, 797\u2013838.",
                "van Eemeron, Frans H., Bart Garssen, Erik C. W. Krabbe,\nA. Francisca Snoeck Henkemans, Bart Verheij, and Jean H. M. Wagemans,\n2020, <em>Handbook of Argumentation Theory</em>, Dordrecht: Springer\nNetherlands.",
                "van Fraassen, Bas, 1973, \u201cValues and the heart\u2019s\ncommand\u201d, <em>The Journal of Philosophy</em>, 70: 5\u201319.\n",
                "\u2013\u2013\u2013, 1995, \u201cFine-grained opinion,\nprobability, and the logic of folk belief\u201d, <em>Journal of\nPhilosophical Logic</em>, 24: 349\u2013377.",
                "Verheij, B., 2003, \u201cDefLog: On the logical interpretation of\nprima facie justified assumptions\u201d, <em>Journal of Logic and\nComputation</em>, 13(3): 319\u2013346. ",
                "\u2013\u2013\u2013, 2005, <em>Virtual arguments: On the design\nof argument assistants for lawyers and other arguers</em>, The Hague:\nT. M. C. Asser Press. ",
                "\u2013\u2013\u2013, 2012, \u201cJumping to conclusions: A\nlogico-probabilistic foundation for defeasible rule-based\narguments\u201d, in L. Fari\u00f1as del Cerro, A. Herzig &amp; J. Mengin\n(eds.), <em>Logics in Artificial Intelligence. 13th European\nconference, JELIA 2012</em>, Dordrecht: Springer, 411\u2013423.",
                "\u2013\u2013\u2013, 2017, \u201cProof with and without\nprobabilities: Correct evidential reasoning with presumptive\narguments, coherent hypotheses and degrees of\nuncertainty\u201d, <em>Artificial Intelligence and Law</em>, 25 (1):\n127\u2013154.",
                "Vieu, L., with M. Bras, N. Asher, and M. Aurnague, 2005,\n\u201cLocating adverbials in discourse\u201d, <em>Journal of French\nLanguage Studies</em>, 15(2): 173\u2013193.",
                "Vreeswijk, Gerard, 1997, \u201cAbstract argumentation\nsystems\u201d, <em>Artificial Intelligence</em>, 90: 225\u201327.",
                "Wobcke, Wayne, 1995, \u201cBelief Revision, Conditional Logic and\nNonmonotonic Reasoning\u201d, <em>Notre Dame Journal of Formal\nLogic</em>, 36: 55\u2013103."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Adams, Ernest W., 1975, <em>The Logic of Conditionals</em>,\nDordrecht: Reidel.</li>\n<li>Alchourr\u00f3n, C., G\u00e4rdenfors, P. and Makinson, D., 1982,\n\u201cOn the logic of theory change: contraction functions and their\nassociated revision functions\u201d, <em>Theoria</em>, 48:\n14\u201337.</li>\n<li>Arl\u00f3 Costa, Horacio and Parikh, Rohit, 2005,\n\u201cConditional Probability and Defeasible Inference\u201d,\n<em>Journal of Philosophical Logic</em>, 34: 97\u2013119.</li>\n<li>Armstrong, David M., 1983, <em>What is a law of nature?</em>, New\nYork: Cambridge University Press.</li>\n<li>\u2013\u2013\u2013, 1997, <em>A world of states of\naffairs</em>, Cambridge: Cambridge University Press.</li>\n<li>Asher, Nicholas, 1992, \u201cA Truth Conditional, Default\nSemantics for Progressive\u201d, <em>Linguistics and Philosophy</em>,\n15: 469\u2013508.</li>\n<li>\u2013\u2013\u2013, 1995, \u201cCommonsense Entailment: a\nlogic for some conditionals\u201d, in <em>Conditionals in Artificial\nIntelligence</em>, G. Crocco, L. Farinas del Cerro, and A. Hertzig\n(eds.), Oxford: Oxford University Press.</li>\n<li>Asher, Nicholas and Daniel Bonevac, 1996, \u201cPrima Facie\nObligations\u201d, <em>Studia Logica</em>, 57: 19\u201345.</li>\n<li>Asher, Nicholas, and Alex Lascarides,  2003, <em>Logics of\nConversation</em>, Cambridge: Cambridge University Press.</li>\n<li>Asher, N.. and Y. Mao, 2001, \u201cNegated Defaults in\nCommonsense Entailment\u201d, <em>Bulletin of the Section of\nLogic</em>, 30: 4\u201360.</li>\n<li>Asher, Nicholas, and Michael Morreau, 1991, \u201cCommonsense\nEntailment: A Modal, Nonmonotonic Theory of Reasoning\u201d, in\n<em>Proceedings of the Twelfth International Joint Conference on\nArtificial Intelligence</em>, John Mylopoulos and Ray Reiter (eds.),\nSan Mateo, Calif.: Morgan Kaufmann.</li>\n<li>Asher, N., and F.J. Pelletier, 1997, \u201cGenerics and\nDefaults\u201d, in <em>Handbook of Logic and Language</em>, J. van\nBentham and A. ter Meulen (eds.), Amsterdam: Elsevier.</li>\n<li>Ashley, Kevin D., 1990, <em>Modeling legal argument: Reasoning\nwith cases and hypotheticals</em>, Cambridge, MA: MIT Press. </li>\n<li>Baker, A. B., 1988, \u201cA simple solution to the Yale shooting\nproblem\u201d, in <em>Proceedings of the First International\nConference on Knowledge Representation and Reasoning</em>, Ronald J.\nBrachman, Hector Levesque and Ray Reiter (eds.), San Mateo, Calif.:\nMorgan Kaufmann.</li>\n<li>Bamber, Donald, 2000, \u201cEntailment with Near Surety of Scaled\nAssertions of High Conditional Probability\u201d, <em>Journal of\nPhilosophical Logic</em>, 29: 1\u201374.</li>\n<li>Baroni, Pietro, Massimiliano Giacomin, and Beishui Liao, 2018,\n\u201cLocality and Modularity in Abstract Argumentation\u201d, in\nP. Baroni, D. Gabbay, Massimiliano Giacomin, and Leendert van der\nTorre (eds.), <em>The Handbook of Formal Argumentation</em>, London:\nCollege Publications, 937\u2013979.</li>\n<li>Bench-Capon, T. J. M., H. Prakken, and G Sartor, 2009,\n\u201cArgumentation in legal reasoning\u201d, in I. Rahwan and\nG. R. Simari (eds.), <em>Argumentation in Artificial\nIntelligence</em>, Dordrecht: Springer, pp. 363\u2013382.</li>\n<li>Bex, F. J., 2011, <em>Arguments, stories and criminal evidence: A\nformal hybrid theory</em>, Dordrecht: Springer. </li>\n<li>Bex, F. J., P. van Koppen, H. Prakken, and B. Verheij, 2010,\n\u201cA hybrid formal theory of arguments, stories and criminal\nevidence\u201d, <em>Artificial Intelligence and Law</em>, 18(2):\n123\u2013152.</li>\n<li>Bochman, Alexander, 2001, <em>A Logical Theory of Nonmonotonic\nInference and Belief Change</em>, Berlin: Springer.</li>\n<li>Bodanza, Gustavo A. and F. Tohm\u00e9, 2005, \u201cLocal\nLogics, Non-Monotonicity and Defeasible Argumentation\u201d,\n<em>Journal of Logic, Language and Information</em>, 14:\n1\u201312.</li>\n<li>Bonevac, Daniel, 2003, <em>Deduction: Introductory Symbolic\nLogic</em>, Malden, Mass.: Blackwell, 2nd edition.</li>\n<li>Carnap, Rudolf, 1962, <em>Logical Foundations of Probability</em>,\nChicago: University of Chicago Press.</li>\n<li>Carnap, Rudolf and Richard C. Jeffrey, 1980, <em>Studies in\ninductive logic and probability</em>, Berkeley: University of\nCalifornia Press.</li>\n<li>Cartwright, Nancy, 1983, <em>How the laws of physics lie</em>,\nOxford: Clarendon Press.</li>\n<li>Chisholm, Roderick, 1957, <em>Perceiving</em>, Princeton:\nPrinceton University Press.</li>\n<li>\u2013\u2013\u2013, 1963, \u201cContrary-to-Duty Imperatives\nand Deontic Logic\u201d, <em>Analysis</em>, 24: 33\u201336.</li>\n<li>\u2013\u2013\u2013, 1966, <em>Theory of Knowledge</em>,\nEnglewood Cliffs: Prentice-Hall.</li>\n<li>Dancy, Jonathan, 1993, <em>Moral Reasons</em>, Malden, MA:\nWiley-Blackwell.</li>\n<li>\u2013\u2013\u2013, 2004, <em>Ethics without Principles</em>,\nOxford: Clarendon Press.</li>\n<li>Delgrande, J. P., 1987, \u201cA first-order conditional logic for\nprototypical properties\u201d, <em>Artificial Intelligence</em>, 33:\n105\u2013130.</li>\n<li>Dung, Phan Minh, 1995, \u201cOn the acceptability of arguments\nand its fundamental role in non-monotonic reasoning logic programming\nand n-person games\u201d, <em>Artificial Intelligence</em>, 77:\n321\u2013357.</li>\n<li>Dung, Phan Minh and Phan Minh Thang, 2010, \u201cTowards\n(probabilistic) argumentation for jury-based dispute\nresolution\u201d, in P. Baroni, F. Cerutti, M. Giacomin, and\nG. R. Simari (eds.), <em>Computational Models of Argument: Proceedings\nof COMMA 2010</em>, Amsterdam: Ios Press, 171\u2013182).</li>\n<li>\u2013\u2013\u2013, 2018, \u201cFundamental properties of\nattack relations in structured argumentation with\npriorities\u201d, <em>Artificial Intelligence</em>, 255:\n1\u201342.</li>\n<li>Etherington, D. W. and R. Reiter, 1983, \u201cOn Inheritance\nHierarchies and Exceptions\u201d, in <em>Proceedings of the National\nConference on Artificial Intelligence</em>, Los Altos, Calif.: Morgan\nKaufmann.</li>\n<li>Ferraris, Paolo, 2007, \u201cA Logic Programming Characterization\nof Causal Theories\u201d, <em>Proceedings of the Twentieth\nInternational Joint Conference on Artificial Intelligence</em>, San\nFrancisco, Calif.: Morgan Kaufmann.</li>\n<li>Ferraris, Paolo, with J. Lee, Y. Lierler, V. Lifschitz, and F.\nYang, 2012, \u201cRepresenting first-order causal theories by logic\nprograms\u201d, <em>Theory and Practice of Logic Programming</em>,\n12(3): 383\u2013412.</li>\n<li>Fierens, D, G. van den Broeck, J. Renkens, D. Shterionov,\nB. Guttman, I. Thon, G. Janssens, and L. de Readt, 2015,\n\u201cInference and learning in probabilistic logic using weighted\nBoolean formulas\u201d, <em>Theory and Practice of Logic\nProgramming</em>, 15(03): 358\u2013401.</li>\n<li>Freund, M., with D. Lehmann, and D. Makinson, 1990,\n\u201cCanonical extensions to the infinite case of finitary\nnonmonotonic inference relations\u201d, in <em>Proceedings of the\nWorkshop on Nonmonotonic Reasoning</em>, G. Brewka and H. Freitag\n(eds.), Sankt Augustin: Gesellschaft f\u00fcr Mathematic und\nDatenverarbeitung mbH.</li>\n<li>Freund, M., 1993, \u201cInjective models and disjunctive\nrelations\u201d, <em>Journal of Logic and Computation</em>, 3:\n231\u2013347.</li>\n<li>Gabbay, D. M., 1985, \u201cTheoretical foundations for\nnon-monotonic reasoning in expert systems\u201d, in <em>Logics and\nModels of Concurrent Systems</em>, K. R. Apt (ed.), Berlin:\nSpringer-Verlag.</li>\n<li>Gaifman, Haim, 1988, \u201cA theory of higher-order\nprobabilities\u201d, in <em>Causation, Chance and Credence</em>,\nBrian Skyrms and William Harper (eds.), London, Ontario: University of\nWestern Ontario Press.</li>\n<li>G\u00e4rdenfors, P., 1978, \u201cConditionals and Changes of\nBelief\u201d, <em>Acta Fennica</em>, 30: 381\u2013404.</li>\n<li>\u2013\u2013\u2013, 1986, \u201cBelief revisions and the\nRamsey test for conditionals\u201d, <em>Philosophical Review</em>,\n95: 81\u201393.</li>\n<li>Geffner, H. A., 1992, <em>Default Reasoning: Causal and\nConditional Theories</em>, Cambridge, MA: MIT Press.</li>\n<li>Geffner, H. A., and J. Pearl, 1992, \u201cConditional entailment:\nbridging two approaches to default reasoning\u201d, <em>Artificial\nIntelligence</em>, 53: 209\u2013244.</li>\n<li>Gelfond, Michael and Yulia Kahl, 2014, <em>Knowledge\nRepresentation, Reasoning, and the Design of Intelligent Agents: The\nAnswer-Set Programming Approach</em>, Cambridge: Cambridge University\nPress.</li>\n<li>Gelfond, Michael and Leone, N., 2002, \u201cLogic programming and\nknowledge representation\u2014the A-prolog perspective\u201d,\n<em>Artificial Intelligence</em>, 138: 37\u201338.</li>\n<li>Gelfond, Michael and Lifschitz, Vladimir, 1988, \u201cThe stable\nmodel semantics for logic programming\u201d, <em>Logic Programming:\nProceedings of the Fifth International Conference and Symposium</em>,\nRobert A. Kowalski and Kenneth A. Bowen (eds.), Cambridge, Mass.: The\nMIT Press, pp. 1070\u20131080.</li>\n<li>Gilio, Angelo, 2005, \u201cProbabilistic Logic under Coherence,\nConditional Interpretations, and Default Reasoning\u201d,\n<em>Synthese</em>, 146: 139\u2013152.</li>\n<li>Ginsberg, M. L., 1987, <em>Readings in Nonmonotonic\nReasoning</em>, San Mateo, Calif.: Morgan Kaufmann.</li>\n<li>Giunchiglia, E., with J. Lee, V. Lifschitz, N. McCain, and H.\nTurner, 2004, \u201cNonmonotonic Causal Theories\u201d, <em>Artificial\nIntelligence</em>, 153: 49\u2013104.</li>\n<li>Goldszmidt, M. and J. Pearl, 1992, \u201cRank-Based Systems: A\nSimple Approach to Belief Revision, Belief Update, and Reasoning about\nEvidence and Action\u201d, in <em>Proceedings of the Third\nInternational Conference on Principles of Knowledge Representation and\nReasoning</em>, San Mateo, Calif.: Morgan Kaufmann.</li>\n<li>Goldszmidt, M., with P. Morris, and J. Pearl, 1993, \u201cA\nmaximum entropy approach to nonmonotonic reasoning\u201d, <em>IEEE\nTransactions on Pattern Analysis and Machine Intelligence</em>, 15:\n220\u2013232.</li>\n<li>Grove, A., 1988, \u201cTwo modellings for theory change\u201d,\n<em>Journal of Philosophical Logic</em>, 17: 157\u2013170.</li>\n<li>Hage, J. C., 1997, <em>Reasoning with rules: An essay on legal\nreasoning and its underlying logic</em>, Dordrecht: Kluwer\nAcademic.</li>\n<li>\u2013\u2013\u2013, 2000, \u201cDialectical models in\nartificial intelligence and law\u201d, <em>Artificial Intelligence\nand Law</em>, 8: 137\u2013172.</li>\n<li>Hanks, Steve and Drew McDermott, 1987, \u201cNonmonotonic Logic\nand Temporal Projection\u201d, <em>Artificial Intelligence</em>, 33:\n379\u2013412.</li>\n<li>Hansson, B., 1969, \u201cAn analysis of some deontic\nlogics\u201d, <em>No\u00fbs</em>, 3: 373\u2013398. </li>\n<li>Hansson, S. O. and Makinson, D., 1997, \u201cApplying normative\nrules with restraint\u201d, in <em>Logic and Scientific Methods</em>,\nM. Dalla Chiara (ed.), Dordrecht: Kluwer. </li>\n<li>Harper, W. L., 1976, \u201cRational Belief Change, Popper\nFunctions and Counterfactuals\u201d, in <em>Foundations of\nProbability Theory, Statistical Inference, and Statistical Theories of\nScience, Volume I</em>, Dordrecht: Reidel.</li>\n<li>Hart, H. L. A., 1949, \u201cThe ascription of responsibility and\nrights\u201d, <em>Proceedings of the Aristotelian Society</em>,\n49(1): 171\u2013194.</li>\n<li>Hawthorne, James, 1998, \u201cOn the Logic of Nonmonotonic\nConditionals and Conditional Probabilities: Predicate Logic\u201d,\n<em>Journal of Philosophical Logic</em>, 27: 1\u201334.</li>\n<li>Horty, J. F., with R.H. Thomason, and D.S. Touretzky, 1990,\n\u201cA sceptical theory of inheritance in nonmonotonic semantic\nnetworks\u201d, <em>Artificial Intelligence</em>, 42:\n311\u2013348.</li>\n<li>Horty, John, 1994, \u201cMoral dilemmas and nonmonotonic\nlogic\u201d, <em>Journal of Philosophical Logic</em>, 23:\n35\u201365. </li>\n<li>\u2013\u2013\u2013, 2003, \u201cReasoning with moral\nconflicts\u201d, <em>No\u00fbs</em>, 37: 557\u2013605. </li>\n<li>\u2013\u2013\u2013, 2007a, \u201cDefaults with\nPriorities\u201d, <em>Journal of Philosophical Logic</em>, 36:\n367\u2013413.</li>\n<li>\u2013\u2013\u2013, 2007b, \u201cReasons as defaults\u201d,\n<em>Philosophers\u2019 Imprints</em>, 7: 1\u201328. </li>\n<li>Hunter, Anthony, 2013, \u201cA probabilistic approach to\nmodelling uncertain logical arguments\u201d, <em>International\nJournal of Approximate Reasoning</em>, 54(1): 47\u201381.</li>\n<li>\u2013\u2013\u2013, \u201cReasoning with Inconsistent\nKnowledge using the Epistemic Approach to Probabilistic\nArgumentation\u201d, <em>Proceedings of the 17th International\nConference on Principles of Knowledge Representation and Reasoning\n(KR\u201920)</em>, Palo Alto: AAAI Press.</li>\n<li>Israel, David, 1986, \u201cWhat\u2019s Wrong with Non-monotonic\nLogic\u201d, in <em>Proceedings of the First National Conference on\nArtificial Intelligence</em>, Palo Alto: AAAI Press.</li>\n<li>Karacapilidis, N., and D. Papadias, 2001, \u201cComputer\nsupported argumentation and collaborative decision making: The HERMES\nsystem\u201d, <em>Information Systems</em>, 26: 259\u2013277.</li>\n<li>Konolige, Kurt, 1994, \u201cAutoepistemic Logic\u201d, in\n<em>Handbook of Logic in Artificial Intelligence and Logic\nProgramming, Volume III: Nonmonotonic Reasoning and Uncertain\nReasoning</em>, D. M. Gabbay, C. J. Hogger, and J. A. Robinson (eds.),\nOxford: Clarendon Press.</li>\n<li>Koons, Robert C., 2000, <em>Realism Regained: An Exact Theory of\nCausation, Teleology and the Mind</em>, New York: Oxford University\nPress.</li>\n<li>\u2013\u2013\u2013, 2001, \u201cDefeasible Reasoning, Special\nPleading and the Cosmological Argument: Reply to Oppy\u201d,\n<em>Faith and Philosophy</em>, 18: 192\u2013203.</li>\n<li>Kraus, S., with D. Lehmann, and M. Magidor, 1990,\n\u201cNonmonotonic Reasoning, Preferential Models and Cumulative\n\nLogics\u201d, <em>Artificial Intelligence</em>, 44:\n167\u2013207.</li>\n<li>Kyburg, Henry E., 1983, <em>Epistemology and Inference</em>,\nMinneapolis: University of Minnesota Press.</li>\n<li>\u2013\u2013\u2013, 1990, <em>Knowledge Representation and\nDefeasible Reasoning</em>, Dordrecht: Kluwer.</li>\n<li>Lance, Mark and Margaret Little, 2004, \u201cDefeasibility and\nthe normative grasp of context\u201d, <em>Erkenntnis</em>, 61:\n435\u201355. </li>\n<li>\u2013\u2013\u2013, 2007, \u201cWhere the laws are\u201d,\n<em>Oxford Studies in Metaethics</em>, 2: 149\u2013171.</li>\n<li>Lascarides, Alex and Nicholas Asher, 1993, \u201cTemporal\nInterpretation, Discourse Relations and Commonsense Entailment\u201d,\n<em>Linguistics and Philosophy</em>, 16: 437\u2013493.</li>\n<li>Lee, Joohyung and Yi Wang, 2016, \u201cWeighted Rules under the\nStable Model Semantics\u201d, in <em>Proceedings of the 15th\nInternational Conference on Principles of Knowledge Representation and\nReasoning (KR 2016)</em>, Palo Alto: AAAI Press,\npp. 145\u2013154.</li>\n<li>Lehmann, D., and M. Magidor, 1992, \u201cWhat does a conditional\nknowledge base entail?\u201d, <em>Artificial Intelligence</em>, 55:\n1\u201360.</li>\n<li>Levesque, H., 1990, \u201cA study in autoepistemic logic\u201d,\n<em>Artificial Intelligence</em>, 42: 263\u2013309.</li>\n<li>Lewis, David K., 1973, <em>Counterfactuals</em>, Cambridge, Mass.:\nHarvard University Press.</li>\n<li>Liao, Beishui, Li Jin, and Robert C. Koons, 2011, \u201cDynamics\nof argumentation systems: A division-based\nmethod\u201d, <em>Artificial Intelligence</em>, 175(11):\n1790\u20131814.</li>\n<li>Liao, Beishui, Nir Oren, Leendert van der Torre, and Serena\nVillata, 2019, \u201cPrioritized Norms in Formal\nArgumentation\u201d, <em>Journal of Logic and Computation</em>, 29(2):\n215\u2013240.</li>\n<li>Lifschitz, V., 1988, \u201cCircumscriptive theories: a\nlogic-based framework for knowledge representation\u201d, <em>Journal\nof Philosophical Logic</em>, 17: 391\u2013441.</li>\n<li>\u2013\u2013\u2013, 1989, \u201cBenchmark Problems for Formal\nNonmonotonic Reasoning\u201d, in <em>Non-Monotonic Reasoning</em>, M.\nReinfrank, J. de Kleer, M. L. Ginsberg and E. Sandewall (eds.),\nBerlin: Springer-Verlag.</li>\n<li>\u2013\u2013\u2013, 1990, \u201cFrames in the space of\nsituations\u201d, <em>Artificial Intelligence</em>, 46:\n365\u2013376.</li>\n<li>Lin, Fangzhen, 1995, \u201cEmbracing causality in specifying the\nindirect effects of actions\u201d, <em>Proceedings of the Fourteenth\nInternational Joint Conference on Artificial Intelligence</em>, San\nMateo, Calif.: Morgan Kaufmann, pp. 1985\u20131993.</li>\n<li>Lin, Fangzhen, and Robert Reiter, 1994, \u201cState constraints\nrevisited\u201d, <em>Journal of Logic and Computation</em>, 4:\n655\u2013678.</li>\n<li>Lukasiewicz, Thomas, 2005, \u201cNonmonotonic Probabilistic\nReasoning under Variable-Strength Inheritance with Overriding\u201d,\n<em>Synthese</em>, 146: 153\u2013169.</li>\n<li>McCain, Norman and Hudson Turner, 1997, \u201cCausal theories of\naction and change\u201d, in <em>Proceedings of the Fourteenth\nNational Conference on Artificial Intelligence (AAAI)</em>, Cambridge,\nMass.: The MIT Press, pp. 460\u20135.</li>\n<li>McCarthy, John M. and Patrick J. Hayes, 1969, \u201cSome\nPhilosophical Problems from the Standpoint of Artificial\nIntelligence\u201d, in <em>Machine Intelligence 4</em>, B. Meltzer\nand D. Mitchie (eds.), Edinburgh: Edinburgh University Press.</li>\n<li>\u2013\u2013\u2013, 1977, \u201cEpistemological Problems of\nArtificial Intelligence\u201d, in <em>Proceedings of the 5th\nInternational Joint Conference on Artificial Intelligence</em>,\nPittsburgh: Computer Science Department, Carnegie-Mellon\nUniversity.</li>\n<li>\u2013\u2013\u2013, 1982, \u201cCircumscription \u2014 A Form\nof Non-Monotonic Reasoning\u201d, <em>Artificial Intelligence</em>,\n13: 27\u201339, 171\u2013177.</li>\n<li>\u2013\u2013\u2013, 1986, \u201cApplication of Circumscription\nto Formalizing Common-Sense Knowledge\u201d, <em>Artificial\nIntelligence</em>, 28: 89\u2013111.</li>\n<li>McDermott, Drew and Jon Doyle, 1982, \u201cNon-Monotonic Logic\nI\u201d, <em>Artificial Intelligence</em>, 13: 41\u201372.</li>\n<li>Makinson, David, 1994, \u201cGeneral Patterns in Nonmonotonic\nReasoning\u201d, in <em>Handbook of Logic in Artificial Intelligence\nand Logic Programming, Volume III: Nonmonotonic Reasoning and\nUncertain Reasoning</em>, D. M. Gabbay, C. J. Hogger, and J. A.\nRobinson (eds.), Oxford: Clarendon Press.</li>\n<li>\u2013\u2013\u2013, 2005, <em>Bridges from Classical to\nNonmonotonic Logic</em>, London: King\u2019s College\nPublications.</li>\n<li>Makinson, David and G\u00e4rdenfors, Peter, 1991, \u201cRelations\nbetween the logic of theory change and Nonmonotonic Logic\u201d, in\n<em>Logic of Theory Change</em>, A. Fuhrmann and M. Morreau (eds.),\nBerlin: Springer-Verlag.</li>\n<li>Makinson, David and van der Torre, L., 2000, \u201cInput/output\nlogics\u201d, <em>Journal of Philosophical Logic</em>, 29:\n155\u201385. </li>\n<li>Morgan, Charles, 2000, \u201cThe Nature of Nonmonotonic\nReasoning\u201d, <em>Minds and Machines</em>, 10: 321\u2013360.</li>\n<li>Moore, Robert C., 1985, \u201cSemantic Considerations on\nNonmonotonic Logic\u201d, <em>Artificial Intelligence</em>, 25:\n75\u201394.</li>\n<li>Morreau, M., and N. Asher, 1995, \u201cWhat some generic\nsentences mean\u201d, in <em>The Generic Book</em>, J. Pelletier\n(ed.), Chicago: University of Chicago Press.</li>\n<li>Nayak, A. C., 1994, \u201cIterated belief change based on\nepistemic entrenchment\u201d, <em>Erkenntnis</em>, 41:\n353\u2013390.</li>\n<li>Nute, Donald, 1988, \u201cConditional Logic\u201d, in\n<em>Handbook of Philosophical Logic, Volume II: Extensions of\nClassical Logic</em>, D. Gabbay and F. Guenthner (eds.), Dordrecht: D.\nReidel.</li>\n<li>\u2013\u2013\u2013, 1997, <em>Defeasible Deontic Logic</em>,\nDordrecht: Kluwer.</li>\n<li>Pearl, Judea, 1988, <em>Probabilistic Reasoning in Intelligent\nSystems: Networks of Plausible Inference</em>, San Mateo, Calif.:\nMorgan Kaufmann.</li>\n<li>\u2013\u2013\u2013, 1990, \u201cSystem Z: A Natural Ordering\nof Defaults with Tractable Applications to Default Reasoning\u201d,\nProceedings of the Third Conference on Theoretical Aspects of\nReasoning about Knowledge, Rohit Parikh (ed.), San Mateo, Calif.:\nMorgan Kaufmann.</li>\n<li>Pelletier, F. J. and R. Elio, \u201cOn Relevance in Nonmonotonic\nReasoning: Some Empirical Studies\u201d, in R. Greiner &amp; D.\nSubramanian (eds) <em>Relevance: AAAI 1994 Fall Symposium Series</em>,\nPalo Alto: AAAI Press.</li>\n<li>Pollock, John L., 1967, \u201cCriteria and our knowledge of the\nmaterial world\u201d, <em>Philosophical Review</em>, 76:\n28\u201362.</li>\n<li>\u2013\u2013\u2013, 1970, \u201cThe structure of epistemic\njustification\u201d, <em>American Philosophical Quarterly</em>\n(Monograph Series), 4: 62\u201378.</li>\n<li>\u2013\u2013\u2013, 1974, <em>Knowledge and Justification</em>,\nPrinceton: Princeton University Press.</li>\n<li>\u2013\u2013\u2013, 1987, \u201cDefeasible Reasoning\u201d,\n<em>Cognitive Science</em>, 11: 481\u2013518.</li>\n<li>\u2013\u2013\u2013, 1995, <em>Cognitive Carpentry</em>,\nCambridge, Mass.: MIT Press.</li>\n<li>\u2013\u2013\u2013, 2010, \u201cDefeasible reasoning and\ndegrees of justification\u201d, <em>Argument &amp; Computation</em>,\n1(1): 7\u201322.</li>\n<li>Prakken, Henry, 2010, \u201cAn abstract framework for\nargumentation with structured arguments\u201d, <em>Argument and\nComputation</em>, 1: 93\u2013124.</li>\n<li>Prakken, Henry and Giovanni Sartor, 1995, \u201cOn the relation\nbetween legal language and legal argument: assumptions, applicability,\nand dynamic priorities\u201d, in <em>Proceedings of the Fifth\nInternational Conference on Artificial Intelligence and the Law\n(ICAIL-95)</em>, New York: The ACM Press.</li>\n<li>\u2013\u2013\u2013, 1996, \u201cA dialectical model of\nassessing conflicting arguments in legal reasoning\u201d,\n<em>Artificial Intelligence and the Law</em>, 4: 331\u2013368.</li>\n<li>Prakken, H., and Vreeswijk, G. A. W., 2002, \u201cLogics for\ndefeasible argumentation\u201d, in D. Gabbay and F. Guenthner\n(eds.), <em>Handbook of philosophical logic</em> (2nd edition, Volume\n4), Dordrecht: Kluwer, pp. 219\u2013318.</li>\n<li>Quine, Willard van Orman, and J.S. Ullian, 1982, <em>The Web of\nBelief</em>, New York: Random House.</li>\n<li>Raz, Joseph, 1975, <em>Practical Reasoning and Norms</em>, London:\nHutchinson and Company.</li>\n<li>Reed, Christopher A. and Rowe, G. W. A., 2004, \u201cAraucaria:\nSoftware for argument analysis, diagramming and\nrepresentation\u201d, <em>International Journal on Artificial\nIntelligence Tools</em>, 13(4): 961\u2013979. </li>\n<li>Reiter, Ray, 1980, \u201cA logic for default reasoning\u201d,\n<em>Artificial Intelligence</em>, 13: 81\u2013137.</li>\n<li>Richardson, M. and P. Domingos, 2006, \u201cMarkov logic\nnetworks\u201d, <em>Machine Learning</em>, 62(1\u20133):\n107\u2013136.</li>\n<li>Ross, David, 1930, <em>The Right and the Good</em>, Oxford: Oxford\nUniversity Press.</li>\n<li>\u2013\u2013\u2013, 1939, <em>Foundations of Ethics</em>,\nOxford: Clarendon Press.</li>\n<li>Rott, Hans, 1989, \u201cConditionals and Theory Change:\nRevisions, Expansions and Additions\u201d, <em>Synthese</em>, 81:\n91\u2013113.</li>\n<li>Schlechta, Karl, 1997, <em>Nonmonotonic Logics: Basic Concepts,\nResults and Techniques</em>, Berlin: Springer-Verlag.</li>\n<li>Shoham, Yoav, 1987, \u201cA Semantical Approach to Nonmonotonic\nLogic\u201d, in <em>Proceedings of the Tenth International Conference\non Artificial Intelligence</em>, John McDermott (ed.), Los Altos,\nCalif.: Morgan Kaufmann.</li>\n<li>Skyrms, Brian, 1980, \u201cHigher order degrees of belief\u201d,\nin <em>Prospects for Pragmatism</em>, Hugh Mellor (ed.), Cambridge:\nCambridge University Press.</li>\n<li>Spohn, Wolfgang, 1988, \u201cOrdinal Conditional\nFunctions\u201d, in <em>Causation, Decision, Belief Change and\nStatistics, Volume III</em>, W. L. Harper and B. Skyrms (eds.),\nDordrecht: Kluwer.</li>\n<li>\u2013\u2013\u2013, 2002, \u201cA Brief Comparison of\nPollock\u2019s Defeasible Reasoning and Ranking Functions\u201d,\n<em>Synthese</em>, 13: 39\u201356.</li>\n<li>Tohm\u00e9, Fernando, with Claudio Delrieux and Ot\u00e1vio\nBueno, 2011, \u201cDefeasible Reasoning + Partial Models: A Formal\nFramework for the Methodology of Research Programs\u201d,\n<em>Foundations of Science</em>, 16: 47\u201365.</li>\n<li>Toulmin, Stephen E., 1964, <em>The Uses of Argument</em>,\nCambridge: Cambridge University Press.</li>\n<li>Txurruka, I. and N. Asher, 2008, \u201cA discourse-based approach\nto Natural Language Disjunction (revisited)\u201d, in M. Aunargue, K.\nKorta and J. Lazzarabal (eds.), <em>Language, Representation and\nReasoning</em>, University of the Basque Country Press.</li>\n<li>van der Torre, Leendert and Srdjan Vesic, 2018, \u201cThe\nPrinciple-Based Approach to Abstract Argumentation Semantics\u201d,\nin P. Baroni, D. Gabbay, Massimiliano Giacomin, and Leendert van der\nTorre (eds.), <em>The Handbook of Formal Argumentation</em>, London:\nCollege Publications, 797\u2013838.</li>\n<li>van Eemeron, Frans H., Bart Garssen, Erik C. W. Krabbe,\nA. Francisca Snoeck Henkemans, Bart Verheij, and Jean H. M. Wagemans,\n2020, <em>Handbook of Argumentation Theory</em>, Dordrecht: Springer\nNetherlands.</li>\n<li>van Fraassen, Bas, 1973, \u201cValues and the heart\u2019s\ncommand\u201d, <em>The Journal of Philosophy</em>, 70: 5\u201319.\n</li>\n<li>\u2013\u2013\u2013, 1995, \u201cFine-grained opinion,\nprobability, and the logic of folk belief\u201d, <em>Journal of\nPhilosophical Logic</em>, 24: 349\u2013377.</li>\n<li>Verheij, B., 2003, \u201cDefLog: On the logical interpretation of\nprima facie justified assumptions\u201d, <em>Journal of Logic and\nComputation</em>, 13(3): 319\u2013346. </li>\n<li>\u2013\u2013\u2013, 2005, <em>Virtual arguments: On the design\nof argument assistants for lawyers and other arguers</em>, The Hague:\nT. M. C. Asser Press. </li>\n<li>\u2013\u2013\u2013, 2012, \u201cJumping to conclusions: A\nlogico-probabilistic foundation for defeasible rule-based\narguments\u201d, in L. Fari\u00f1as del Cerro, A. Herzig &amp; J. Mengin\n(eds.), <em>Logics in Artificial Intelligence. 13th European\nconference, JELIA 2012</em>, Dordrecht: Springer, 411\u2013423.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cProof with and without\nprobabilities: Correct evidential reasoning with presumptive\narguments, coherent hypotheses and degrees of\nuncertainty\u201d, <em>Artificial Intelligence and Law</em>, 25 (1):\n127\u2013154.</li>\n<li>Vieu, L., with M. Bras, N. Asher, and M. Aurnague, 2005,\n\u201cLocating adverbials in discourse\u201d, <em>Journal of French\nLanguage Studies</em>, 15(2): 173\u2013193.</li>\n<li>Vreeswijk, Gerard, 1997, \u201cAbstract argumentation\nsystems\u201d, <em>Artificial Intelligence</em>, 90: 225\u201327.</li>\n<li>Wobcke, Wayne, 1995, \u201cBelief Revision, Conditional Logic and\nNonmonotonic Reasoning\u201d, <em>Notre Dame Journal of Formal\nLogic</em>, 36: 55\u2013103.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "artificial intelligence: logic and",
            "causation: probabilistic",
            "epistemology: Bayesian",
            "logic: modal",
            "logic: non-monotonic",
            "logic: of belief revision",
            "moral particularism",
            "probability, interpretations of"
        ],
        "entry_link": [
            {
                "../logic-ai/": "artificial intelligence: logic and"
            },
            {
                "../causation-probabilistic/": "causation: probabilistic"
            },
            {
                "../epistemology-bayesian/": "epistemology: Bayesian"
            },
            {
                "../logic-modal/": "logic: modal"
            },
            {
                "../logic-nonmonotonic/": "logic: non-monotonic"
            },
            {
                "../logic-belief-revision/": "logic: of belief revision"
            },
            {
                "../moral-particularism/": "moral particularism"
            },
            {
                "../probability-interpret/": "probability, interpretations of"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=reasoning-defeasible\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/reasoning-defeasible/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=reasoning-defeasible&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"http://philpapers.org/sep/reasoning-defeasible/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"http://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=reasoning-defeasible": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/reasoning-defeasible/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=reasoning-defeasible&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "http://philpapers.org/sep/reasoning-defeasible/": "Enhanced bibliography for this entry"
            },
            {
                "http://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "<a href=\"http://bayes.cs.ucla.edu/csl_papers.html\" target=\"other\">Online papers, Cognitive Systems Laboratory, UCLA Computer Science Department</a>",
            "<a href=\"http://www.cs.huji.ac.il/~lehmann/\" target=\"other\">Daniel Lehmann\u2019s home page, Hebrew University</a>"
        ],
        "listed_links": [
            {
                "http://bayes.cs.ucla.edu/csl_papers.html": "Online papers, Cognitive Systems Laboratory, UCLA Computer Science Department"
            },
            {
                "http://www.cs.huji.ac.il/~lehmann/": "Daniel Lehmann\u2019s home page, Hebrew University"
            }
        ]
    }
}