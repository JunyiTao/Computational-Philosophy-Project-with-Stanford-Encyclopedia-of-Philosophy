{"url": "learning-formal", "title": "Formal Learning Theory", "authorship": {"year": "Copyright \u00a9 2022", "author_text": "Oliver Schulte\n<oschulte@sfu.ca>", "author_links": [{"http://www.cs.sfu.ca/~oschulte/": "Oliver Schulte"}, {"mailto:oschulte%40sfu%2eca": "oschulte@sfu.ca"}], "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2022</a> by\n\n<br/>\n<a href=\"http://www.cs.sfu.ca/~oschulte/\" target=\"other\">Oliver Schulte</a>\n&lt;<a href=\"mailto:oschulte%40sfu%2eca\"><em>oschulte<abbr title=\" at \">@</abbr>sfu<abbr title=\" dot \">.</abbr>ca</em></a>&gt;\n    </p>\n</div>"}, "pubinfo": ["First published Sat Feb 2, 2002", "substantive revision Wed Mar 23, 2022"], "preamble": "\n\nFormal learning theory is the mathematical embodiment of a normative\nepistemology. It deals with the question of how an agent should use\nobservations about her environment to arrive at correct and\ninformative conclusions. Philosophers such as Putnam, Glymour and\nKelly have developed learning theory as a normative framework for\nscientific reasoning and inductive inference.\n\nTerminology. Cognitive science and related fields typically\nuse the term \u201clearning\u201d for the process of gaining\ninformation through observation\u2014 hence the name \u201clearning\ntheory\u201d. To most cognitive scientists, the term \u201clearning\ntheory\u201d suggests the empirical study of human and animal\nlearning stemming from the behaviourist paradigm in psychology. The\nepithet \u201cformal\u201d distinguishes the subject of this entry\nfrom behaviourist learning theory. Philosophical terms for\nlearning-theoretic epistemology include \u201clogical\nreliability\u201d (Kelly [1996], Glymour [1991]) and\n\u201cmeans-ends epistemology\u201d (Schulte [1999]).\n\nBecause many developments in, and applications of, formal learning\ntheory come from computer science, the term \u201ccomputational\nlearning theory\u201d is also common. Many results on learning theory\nin computer science are concerned with Valiant\u2019s and\nVapnik\u2019s notion of learning generalizations that are probably\napproximately correct (PAC learning) (Valiant [1984]). This notion of\nempirical success was introduced to philosophers by Gilbert Harmann in\nhis Nicode lectures, and elaborated in a subsequent book [2007].\nValiant himself provides an accessible account of PAC learning and its\nrelationship to the problem of induction in a recent book (Valiant\n[2013, Ch. 5]). The present article describes a nonstatistical\ntradition of learning theory stemming from the seminal work of Hilary\nPutnam [1963] and Mark E. Gold [1967]. Recent research has extended\nthe reliabilist means-ends approach to a statistical setting where\ninductive methods assign probabilities to statistical hypotheses from\nrandom samples. The new statistical framework is described at the end\nof this entry, in the Section on\n Reliable Statistical Inquiry.\n\n\nPhilosophical characteristics. In contrast to other\nphilosophical approaches to inductive inference, learning theory does\nnot aim to describe a universal inductive method or explicate general\naxioms of inductive rationality. Rather, learning theory pursues a\ncontext-dependent means-ends analysis [Steele 2010]: For a given\nempirical problem and a set of cognitive goals, what is the best\nmethod for achieving the goals? Most of learning theory examines \nwhich investigative strategies reliably and efficiently lead to\ncorrect beliefs about the world.\n\nArticle Overview. Compared to traditional philosphical\ndiscussions of inductive inference, learning theory provides a\nradically new way of thinking about induction and scientific method.\nThe main aim of this article is explain the main concepts of the\ntheory through examples. Running examples are repeated throughout the\nentry; at the same time, the sections are meant to be as independent\nof each other as possible. We use the examples to illustrate some\ntheorems of philosophical interest, and to highlight the key\nphilosophical ideas and insights behind learning theory.\n\nReaders interested in the mathematical substance of learning theory\nwill find some references in the\n Bibliography,\n and a summary of the basic definitions in the\n Supplementary Document.\n A text by Jain et al. collects many of the main definitions and\ntheorems [1999]. New results appear in proceedings of annual\nconferences, such as the Conferences on Learning Theory (COLT) and\nAlgorithmic Learning Theory (ALT). The philosophical issues and\nmotivation pertaining to learning-theoretic epistemology are discussed\nextensively in the works of philosophers such as Putnam, Glymour and\nKelly (Putnam [1963], Glymour [1991], Glymour and Kelly [1992], Kelly\n[1996]).\n", "toc": [{"#ConvTrutNothButTrut": "1. Convergence to the Truth and Nothing But the Truth"}, {"#SimpUnivGene": "1.1 Simple Universal Generalization"}, {"#NewRiddIndu": "1.2 The New Riddle of Induction"}, {"#Disc": "1.3 Discussion"}, {"#FalsGeneExce": "1.4 Falsificationism and Generalizations with Exceptions"}, {"#CaseStudSciePrac": "2. Case Studies from Scientific Practice"}, {"#ConsLawsPartPhys": "2.1 Conservation Laws in Particle Physics"}, {"#CausConn": "2.2 Causal Connections"}, {"#ModeCognArch": "2.3 Models of Cognitive Architecture"}, {"#Disc_1": "2.4 Discussion"}, {"#LimiInquCompEmpiProb": "3. The Limits of Inquiry and the Complexity of Empirical Problems"}, {"#VeriRefuHypo": "3.1 Verifiable and Refutable Hypotheses"}, {"#PoinSetTopoAxioVeri": "3.2 Point-Set Topology and the Axioms of Verifiability"}, {"#IdenLimiInqu": "3.3 Identifiability in the Limit of Inquiry"}, {"#LongRunShorRunReliStabBeli": "4. The Long Run in the Short Run: Reliable and Stable Beliefs"}, {"#ExamNewRiddIndu": "4.1 Example: The New Riddle of Induction"}, {"#Exam": "4.2 More Examples"}, {"#RegrMindChan": "4.3 Regressive Mind Changes"}, {"#SimpStabBeliOckhRazo": "5. Simplicity, Stable Belief, and Ockham\u2019s Razor"}, {"#DefiSimp": "5.1 Defining Simplicity"}, {"#Exam_1": "5.2 Examples"}, {"#StabBeliSimpOckhTheo": "5.3 Stable Belief and Simplicity: An Ockham Theorem"}, {"#RegrMindChanSimpAnotOckhTheo": "5.4 Regressive Mind Changes and Simplicity: Another Ockham Theorem"}, {"#ReliLearForStatHypo": "6. Reliable Learning for Statistical Hypotheses"}, {"#OtheApprCateVsHypoImpe": "7. Other Approaches: Categorical vs. Hypothetical Imperatives"}, {"#SuppDocuBasiFormDefi": "Supplementary Document: Basic Formal Definitions"}, {"#Bib": "Bibliography"}, {"#Aca": "Academic Tools"}, {"#Oth": "Other Internet Resources"}, {"#Rel": "Related Entries"}], "main_text": "\n1. Convergence to the Truth and Nothing But the Truth\n\nLearning-theoretic analysis assesses dispositions for forming beliefs.\nSeveral terms for belief acquisition processes are in common use in\nphilosophy; I will use \u201cinductive strategy\u201d,\n\u201cinference method\u201d and most frequently \u201cinductive\nmethod\u201d to mean the same thing. The best way to understand how\nlearning theory evaluates inductive methods is to work through some\nexamples. The following presentation begins with some very simple\ninductive problems and moves on to more complicated and more realistic\nsettings.\n1.1 Simple Universal Generalization\n\nLet\u2019s revisit the classic question of whether all ravens are\nblack. Imagine an ornithologist who tackles this problem by examining\none raven after another. There is exactly one observation sequence in\nwhich only black ravens are found; all others feature at least one\nnonblack raven. The figure below illustrates the possible observation\nsequences. Dots in the figure denote points at which an observation\nmay be made. A black bird to the left of a dot indicates that at this\nstage, a black raven is observed. Similarly, a white bird to the right\nof a dot indicates that a nonblack raven is observed. Given a \ncomplete sequence  of observations, either all observed ravens are\nblack or nonblack; the figure labels complete observation sequences\nwith the statement that is true of them. The gray fan indicates that\nafter the observation of a white raven, the claim that not all ravens\nare black holds on all observation sequences resulting from further\nobservations.\n\n\nFigure 1 [An extended description of figure 1 is in a supplement.]\n\n\nIf the world is such that only black ravens are found, we would like\nthe ornithologist to settle on this generalization. (It may be\npossible that some nonblack ravens remain forever hidden from sight,\nbut even then the generalization \u201call ravens are black\u201d at\nleast gets the observations right.) If the world is such that\neventually a nonblack raven is found, then we would like the\nornithologist to arrive at the conclusion that not all ravens are\nblack. This specifies a set of goals of inquiry. For any given\ninductive method that might represent the ornithologist\u2019s\ndisposition to adopt conjectures in the light of the evidence, we can\nask whether that method measures up to these goals or not. There are\ninfinitely many possible methods to consider; we\u2019ll look at just\ntwo, a skeptical one and one that boldly generalizes. The  bold\nmethod  conjectures that all ravens are black after seeing that\nthe first raven is black. It hangs on to this conjecture unless some\nnonblack raven appears. The skeptical method does not go beyond what\nis entailed by the evidence. So if a nonblack raven is found, the\nskeptical method concludes that not all ravens are black, but\notherwise the method does not make a conjecture one way or another.\nThe figure below illustrates both the bold and the skeptical\nmethod.\n\n\nFigure 2 [An extended description of figure 2 is in a supplement.]\n\n\nDo these methods attain the goals we set out? Consider the bold\nmethod. There are two possibilities: either all observed ravens are\nblack, or some nonblack raven is found. In the first case, the method\nconjectures that all ravens are black and never abandons this\nconjecture. In the second case, the method concludes that not all\nravens are black as soon as the first nonblack raven is found. Hence\nno matter how the evidence comes in, eventually the method\ngives the right answer as to whether all ravens are black and\nsticks with this answer. Learning theorists call such methods\nreliable because they settle on the right answer no matter\nwhat observations the world provides.\n\nThe skeptical method does not measure up so well. If a nonblack raven\nappears, then the method does arrive at the correct conclusion that\nnot all ravens are black. But if all ravens are black, the skeptic\nnever takes an \u201cinductive leap\u201d to adopt this\ngeneralization. So in that case, the skeptic fails to provide the\nright answer to the question of whether all ravens are black.\n\nThis illustrates how means-ends analysis can evaluate methods: the\nbold method meets the goal of reliably arriving at the right answer,\nwhereas the skeptical method does not. Note the character of this\nargument against the skeptic: The problem, in this view, is not that\nthe skeptic violates some canon of rationality, or fails to appreciate\nthe\n \u201c uniformity of nature\u201d.\n The learning-theoretic analysis concedes to the skeptic that no\nmatter how many black ravens have been observed in the past, the next\none could be white. The issue is that if all observed ravens are\nindeed black, then the skeptic never answers the question\n\u201care all ravens black?\u201d. Getting the right answer to that\nquestion requires generalizing from the evidence even though\nthe generalization could be wrong.\n\nAs for the bold method, it\u2019s important to be clear on what it\ndoes and does not achieve. The method will eventually settle on the\nright answer\u2014but it (or we) may never be certain that\nit has done so. As\n William James\n put it, \u201cno bell tolls\u201d when science has found the right\nanswer. We are certain that the method will eventually settle on the\nright answer; but we may never be certain that the current answer is\nthe right one. This is a subtle point; the next example illustrates it\nfurther.\n1.2 The New Riddle of Induction\n\nNelson Goodman posed a famous puzzle about inductive inference known\nas the (New) Riddle of Induction ([Goodman 1983]). Our next example is\ninspired by his puzzle. Goodman considered generalizations about\nemeralds, involving the familiar colours of green and blue, as well as\ncertain unusual ones:\n\nSuppose that all emeralds examined before a certain time \\(t\\)\nare green \u2026. Our evidence statements assert that emerald \\(a\\)\nis green, that emerald \\(b\\) is green, and so on\u2026.\n\n\nNow let us introduce another predicate less familiar than\n\u201cgreen\u201d. It is the predicate \u201cgrue\u201d and it\napplies to all things examined before \\(t\\) just in case they are\ngreen but to other things just in case they are blue. Then at time\n\\(t\\) we have, for each evidence statement asserting that a given\nemerald is green, a parallel evidence statement asserting that emerald\nis grue. The question is whether we should conjecture that all\nemeralds are green rather than that all emeralds are grue when we\nobtain a sample of green emeralds examined before time \\(t\\), and\nif so, why.\n\n\nClearly we have a family of grue predicates in this problem, one for\neach different \u201ccritical time\u201d \\(t\\); let\u2019s\nwrite grue\\((t)\\) to denote these grue predicates. Following\nGoodman, let us refer to methods as  projection rules  in\ndiscussing this example. A projection rule succeeds in a world just in\ncase it settles on a generalization that is correct in that world.\nThus in a world in which all examined emeralds are found to be green,\nwe want our projection rule to converge to the proposition that all\nemeralds are green. If all examined emeralds are grue\\((t)\\), we\nwant our projection rule to converge to the proposition that all\nemeralds are grue\\((t)\\). Note that this stipulation treats green\nand grue predicates completely on a par, with no bias towards either.\nAs before, let us consider two rules: the  natural projection\nrule which conjectures that all emeralds are green as long as only\ngreen emeralds are found, and the gruesome rule which keeps\nprojecting the next grue predicate consistent with the available\nevidence. Expressed in the green-blue vocabulary, the gruesome\nprojection rule conjectures that after observing some number of\n\\(n\\) green emeralds, all future ones will be blue. The figures\nbelow illustrates the possible observation sequences, the natural\nprojection rule, and the gruesome projection rule.\n\n\nFigure 3 [An extended description of figure 3 is in a supplement.]\n\n\nThe following figure shows the gruesome projection rule.\n\n\nFigure 4 [An extended description of figure 4 is in a supplement.]\n\n\nHow do these rules measure up to the goal of arriving at a true\ngeneralization? Suppose for the sake of the example that the only\nserious possibilities under consideration are: (1) Either all emeralds\nare green or (2) all emeralds are grue\\((t)\\) for some critical\ntime \\(t\\). Then the natural projection rule settles on the\ncorrect generalization no matter what the correct generalization is.\nFor if all emeralds are green, the natural projection rule asserts\nthis fact from the beginning. And suppose that all emeralds are\ngrue\\((t)\\) for some critical time \\(t\\). Then at time\n\\(t\\), a blue emerald will be observed. At this point the natural\nprojection rule settles on the conjecture that all emeralds are\ngrue\\((t)\\), which must be correct given our assumption about the\npossible observation sequences. Thus no matter what evidence is\nobtained in the course of inquiry\u2014consistent with our background\nassumptions\u2014the natural projection rule eventually settles on a\ncorrect generalization about the colour of emeralds.\n\nThe gruesome rule does not do as well. For if all emeralds are green,\nthe rule will never conjecture this fact because it keeps projecting\ngrue predicates. Hence there is a possible observation\nsequence\u2014namely those on which all emeralds are green\u2014on\nwhich the gruesome rule fails to converge to the right generalization.\nSo means-ends analysis would recommend the natural projection rule\nover the gruesome rule.\n1.3 Discussion\n\nThe means-ends analysis of the Riddle of Induction illustrates a\nnumber of philosophically important points that holds for\nlearning-theoretic analysis in general.\n\nEqual Treatment of All Hypotheses. As in the previous example,\nnothing in this argument hinges on arguments to the effect that\ncertain possibilities are not to be taken seriously a priori. In\nparticular, nothing in the argument says that generalizations with\ngrue predicates are ill-formed, unlawlike, or in some other way a\npriori inferior to \u201call emeralds are green\u201d. \nLanguage Invariance. The analysis does not depend on the\nvocabulary in which the evidence and generalizations are framed. For\nease of exposition, I have mostly used the green-blue reference frame.\nHowever, grue-bleen speakers would agree that the aim of reliably\nsettling on a correct generalization requires the natural projection\nrule rather than the gruesome one, even if they would want to express\nthe conjectures of the natural rule in their grue-bleen language\nrather than the blue-green language that we have used so far.\n\nDependence on Context. Though the analysis does not depend on\nlanguage, it does depend on assumptions about what the possible\nobservation sequences are. The example as described above seems to\ncomprise the possibilities that correspond to the colour predicates\nGoodman himself discussed. But means-ends analysis applies just as\nmuch to other sets of possible predicates. Schulte [1999] and Chart\n[2000] discuss a number of other versions of the Riddle of Induction,\nin some of which means-ends analysis favours projecting that all\nemeralds are grue on a sample of all green emeralds. \n\n1.4 Falsificationism and Generalizations with Exceptions\n\nOur first two examples feature simple universal generalizations. Some\nsubtle aspects of the concept of long-run reliability, particularly\nits relationship to falsificationism, become apparent if we consider\ngeneralizations that allow for exceptions. To illustrate, let us\nconsider another ornithological example. Two competing hypotheses are\nunder investigation.\n\nAll but finitely many swans are white. That is, basically all\nswans are white, except for a finite number of exceptions to the rule.\n\nAll but finitely many swans are black. That is, basically all\nswans are black, except for a finite number of exceptions to the\nrule.\n\n\nAssuming that one or the other of these hypotheses is correct, is\nthere an inductive method that reliably settles on the right one? What\nmakes this problem more difficult than our first two is that each\nhypothesis under investigation is consistent with any finite amount of\nevidence. If 100 white swans and 50 black swans are found, either the\n50 black swans or the 100 white swans may be the exception to the\nrule. In terminology made familiar by\n Karl Popper\u2019s\n work, we may say that neither hypothesis is falsifiable. As a\nconsequence, the inductive strategy from the previous two examples\nwill not work here. This strategy was basically to adopt a\n\u201cbold\u201d universal generalization, such as \u201call ravens\nare black\u201d or \u201call emeralds are green\u201d, and to hang\non to this conjecture as long as it \u201cpasses muster\u201d.\nHowever, when rules with possible exceptions are under investigation,\nthis strategy is unreliable. For example, suppose that an inquirer\nfirst adopts the hypothesis that \u201call but finitely many swans\nare white\u201d. It may be the case that from then on, only black\nswans are found. But each of these apparent counterinstances can be\n\u201cexplained away\u201d as an exception. If the inquirer follows\nthe principle of hanging on to her conjecture until the evidence is\nlogically inconsistent with the conjecture, she will never abandon her\nfalse belief that all but finitely many swans are white, much less\narrive at the correct belief that all but finitely many swans are\nblack.\n\nReliable inquiry requires a more subtle investigative strategy. Here\nis one (of many). Begin inquiry with either competing hypothesis, say\n\u201call but finitely many swans are black\u201d. Choose some\ncut-off ratio to represent a \u201cclear majority\u201d; for\ndefiniteness, let\u2019s say 70%. If the current conjecture is that\nall but finitely many swans are black, change your mind to conjecture\nthat all but finitely many swans are white just in case over 70% of\nobserved swans are in fact white. Proceed likewise if the current\nconjecture is that all but finitely many swans are white when over 70%\nof observed swans are in fact black.\n\nA bit of thought shows that this rule reliably identifies the correct\nhypothesis in the long run, no matter which of the two competing\nhypotheses is correct. For if all but finitely many swans are black,\neventually the nonblack exceptions to the rule will be exhausted, and\nan arbitrarily large majority of observed swans will be black.\nSimilarly if all but finitely many swans are white.\n\nGeneralizations with exceptions illustrate the relationship between\nPopperian falsificationism and the learning-theoretic idea of reliable\nconvergence to the truth. In some settings of inquiry, notably those\ninvolving universal generalizations, a naively Popperian\n\u201cconjectures-and-refutations\u201d approach of hanging on to\nconjectures until the evidence falsifies them does yield a reliable\ninductive method. In other problems, like the current example, it does\nnot. Relying on falsifications is sometimes, but not always,\nthe best way for inquiry to proceed. Learning theory has provided\nmathematical theorems that clarify the relationship between a\nconjectures-and-refutations approach and reliable inquiry. The details\nare discussed in\n Section 3\n (The Limits of Inquiry and the Complexity of Empirical Problems).\nGenerally speaking methods that solve a learning problem with\nunfalsifiable hypotheses can be represented as employing a refined\nhypothesis space where the original hypotheses are replaced by\nstrengthened hypotheses that  are  falsifiable.\n2. Case Studies from Scientific Practice\n\nThis section provides further examples to illustrate\nlearning-theoretic analysis. The examples in this section are more\nrealistic and address methodological issues arising in scientific\npractice. They are not probabilistic; statistical hypotheses are\ndiscussed in\n Section 6.\n This entry provides an outline of the full analysis; there are\nreferences to more detailed discussions below. More case studies may\nbe found in [Kelly 1996, Ch. 7.7, Harrell 2000]. Readers who wish to\nproceed to the further development of the theory and philosophy of\nmeans-ends epistemology can skip this section without loss of\ncontinuity.\n2.1 Conservation Laws in Particle Physics\n\nOne of the hallmarks of elementary particle physics is the discovery\nof new conservation laws that apply only in the subatomic realm [Ford\n1963, Ne\u2019eman and Kirsh 1983, Feynman 1965]. (Feynman groups one\nof them, the conservation of Baryon Number, with the other\n\u201cgreat conservation laws\u201d of energy, charge and momentum.)\nSimplifying somewhat, conservation principles serve to explain why\ncertain processes involving elementary particles do  not \noccur: the explanation is that some conservation principle was\nviolated (cf. Omnes [1971, Ch.2] and Ford [1963]). So a goal of\nparticle inquiry is to find a set of conservation principles such that\nfor every process that is possible according to the (already known)\nlaws of physics, but fails to be observed experimentally, there is\nsome conservation principle that rules out that process. And if a\nprocess is in fact observed to occur, then it ought to satisfy all\nconservation laws that we have introduced.\n\nThis constitutes an inference problem to which we may apply means-ends\nanalysis. An inference method produces a set of conservation\nprinciples in response to reports of observed processes. Means-ends\nanalysis asks which methods are guaranteed to settle on conservation\nprinciples that account for all observations, that is, that rule out\nunobserved processes and allow observed processes. Schulte [2008]\ndescribes an inductive method that accomplishes this goal. Informally\nthe method may be described as follows.\n\nSuppose we have observed a set of reactions among elementary\nparticles.\nConjecture a set of conservation laws that permits the observed\nreactions and rules out as many unobserved reactions as\npossible.\n\n\nThe logic of conservation laws is such that the observation of some\nreactions entails the possibility of other unobserved ones. The\nlearning-theoretic method rules out all reactions that are not\nentailed. It turns out that the conservation principles that this\nmethod would posit on the currently available evidence are \nempirically equivalent  to the ones that physicists have\nintroduced. Specifically, their predictions agree exactly with the\nconservation of charge, baryon number, muon number, tau number and\nLepton number that is part of the Standard Model of particle\nphysics.\n\nFor some physical processes, the only way to get empirically adequate\nconservation principles is by positing that some hidden particles have\ngone undetected. Schulte [2009] extends the analysis such that an\ninductive method may not only introduce conservation laws, but also\nposit unseen particles. The basic principle is again to posit unseen\nparticles in such a way that we rule out as many unobserved reactions\nas possible. When this method is applied to the known particle data,\nit rediscovers the existence of an electron antineutrino. This is one\nof the particles of key concern in current particle physics.\n2.2 Causal Connections\n\nThere has been a substantive body of research on learning causal\nrelationships as represented in a causal graph [Spirtes et al. 2000].\nKelly suggested a learning-theoretic analysis of inferring causality\nwhere the evidence is provided in the form of observed significant\ncorrelations among variables of interest (a modern version of\nHume\u2019s \u201cconstant conjunctions\u201d). The following\ninductive method is guaranteed to converge to an empirically adequate\ncausal graph as more and more correlations are observed [Schulte, Luo\nand Greiner 2007].\n\nSuppose we have observed a set of correlations or associations\namong a set of variables of interest.\nSelect a causal graph that explains the observed correlations\nwith a minimum number of direct causal links.\n\n2.3 Models of Cognitive Architecture\n\nSome philosophers of mind have argued that the mind is composed of\nfairly independent modules. Each module has its own\n\u201cinput\u201d from other modules and sends \u201coutput\u201d\nto other modules. For example, an \u201cauditory analysis\nsystem\u201d module might take as input a heard word and send a\nphonetic analysis to an \u201cauditory input lexicon\u201d. The idea\nof modular organization raises the empirical question of what mental\nmodules there are and how they are linked to each other. A prominent\ntradition of research in cognitive neuroscience has attempted to\ndevelop a model of mental architecture along these lines by studying\nthe responses of normal and abnormal subjects to various stimuli. The\nidea is to compare normal reactions with abnormal ones\u2014often\ncaused by brain damage\u2014so as to draw inferences about which\nmental capacities depend on each other and how.\n\nGlymour [1994] asked the reliabilist question whether there are\ninference methods that are guaranteed to eventually settle on a true\ntheory of mental organization, given exhaustive evidence about normal\nand abnormal capacities and reactions. He argued that for some\npossible mental architectures, no amount of evidence of the\nstimulus-response kind can distinguish between them. Since the\navailable evidence determines the conjectures of an inductive method,\nit follows that there is no guarantee that a method will settle on the\ntrue model of cognitive architecture. Glymour has also explored to\nwhat extent richer kinds of evidence would resolve underdetermination\nof mental architecture. (One example of richer evidence are double\ndisassocations. An example of a double dissocation would be a pair of\npatients, one who has a normal capacity for understanding spoken\nwords, but fails to understand written ones, and another who\nunderstands written words but not spoken ones.) \n\nIn further discussion, Bub [1994] showed that if we grant certain\nrestrictive assumptions about how mental modules are connected, then a\ncomplete set of behavioural observations would allow a\nneuropsychologist to ascertain the module structure of a (normal)\nmind. In fact, under Bub\u2019s assumptions there is a reliable\nmethod for identifying the modular structure. The high-level idea of\nthe procedure is as follows.\n\nEvery hypothesized modular structure can be identified with a\ngraph \\(G\\) containing an edge from module \\(M_1 \\rightarrow M_2\\) if\nmodule \\(M_1\\) calls on module \\(M_2\\). \nEach module graph \\(G\\) is consistent with a set of possible paths\namong modules. Say that a graph \\(G\\) is more constrained than another\ngraph \\(G'\\) if the paths defined by \\(G\\) are a subset of those\nconstrained by \\(G'\\).\nConjecture any module graph \\(G\\) that is maximally constrained,\nthat is, there is no other graph \\(G'\\) more constrained than\n\\(G\\).\n\n2.4 Discussion\n\nThese studies illustrate some general features of learning theory:\n\nGenerality. The basic notions of the theory are very general.\nEssentially, the theory applies whenever one has a question that\nprompts inquiry, a number of candidate answers, and some evidence for\ndeciding among the answers. Thus means-ends analysis can be applied in\nany discipline aimed at empirical knowledge, for example physics or\npsychology.\nContext Dependence. Learning theory is pure normative a\npriori epistemology in the sense that it deals with standards for\nassessing methods in possible settings of inquiry. But the approach\ndoes not aim for universal, context-free methodological maxims. The\nmethodological recommendations depend on contingent factors, such as\nthe operative methodological norms, the questions under investigation,\nthe background assumptions that the agent brings to inquiry, the\nobservational means at her disposal, her cognitive capacities, and her\nepistemic aims. As a consequence, to evaluate specific methods in a\ngiven domain, as in the case studies mentioned, one has to study the\ndetails of the case in question. The means-ends analysis often rewards\nthis study by pointing out what the crucial methodological features of\na given scientific enterprise are, and by explaining precisely why and\nhow these features are connected to the success of the enterprise in\nattaining its epistemic aims.\nTrade-offs. In the perspective of means-ends epistemology,\ninquiry involves an ongoing struggle with hard choices, rather than\nthe execution of a universal \u201cscientific method\u201d. The\ninquirer has to balance conflicting values, and may consider various\nstrategies such as accepting difficulties in the short run hoping to\nresolve them in the long run. For example in the conservation law\nproblem, there can be conflicts between theoretical parsimony, i.e.,\npositing fewer conservation laws, and ontological parsimony, i.e.,\nintroducing fewer hidden particles. For another example, a particle\ntheorist may accept positing undetected particles in the hopes that\nthey will eventually be observed as science progresses. The search for\nthe Higgs boson illustrates this strategy. An important\nlearning-theoretic project is to examine when such tradeoffs arise and\nwhat the options for resolving them are. Section 4 extends\nlearning-theoretic analysis to consider goals in addition to long-run\nreliability.\n\n3. The Limits of Inquiry and the Complexity of Empirical Problems\n\nAfter seeing a number of examples like the ones described above, one\nbegins to wonder what the pattern is. What is it about an empirical\nquestion that allows inquiry to reliably arrive at the correct answer?\nWhat general insights can we gain into how reliable methods go about\ntesting hypotheses? Learning theorists answer these questions with\ncharacterization theorems. Characterization theorems are\ngenerally of the form \u201cit is possible to attain this standard of\nempirical success in a given inductive problem if and only if the\ninductive problem meets the following conditions\u201d.\n\nWe first cover the case where inquiry can provide certainty as to\nwhether an empirical hypothesis is correct (relative to background\nknowledge). Then we consider when and how inquiry can converge to a\ncorrect hypothesis without ever arriving at certain conclusions, as\ndescribed in\n Section 1.\n We will introduce enough definitions and formal concepts to state the\nresults precisely; the\n supplementary document\n provides a full formalization.\n\nA learning problem is defined by a finite or countably infinite set of\npossible hypotheses \\(\\mathbf{H} = H_1, H_2 , \\ldots\n,H_n,\\ldots\\).  These hypotheses are mutually exclusive and jointly\ncover all possibilities consistent with the inquirer\u2019s\nbackground assumptions.\nExamples\n\nIn the raven color problem of\n Section 1.1,\n there are two hypotheses \\(H_1 =\\) \u201call (observed) ravens\nare black\u201d and \\(H_2 =\\) \u201csome (observed) raven is\nnot black\u201d.\nIn the New Riddle of Induction of from\n Section 1.2,\n there are infinitely many alternative hypotheses: We have\n\\(H_{green} =\\) \u201call (observed) emeralds are green\u201d\nand countably many alternatives of the form \\(H_t =\\) \u201call\n(observed) emeralds are grue\\((t)\\)\u201d where \\(t\\) is a\nnatural number.\n This section defines properties of hypotheses that determine in\nwhich sense inquiry from observations can indicate whether they are\ncorrect. These properties are not absolute but relative to a set of\nalternatives \\(\\mathbf{H}\\), any one of which may obtain for all the\ninquirer knows. The most basic relative property is relative \nentailment.\n\n\nA hypothesis \\(H\\) is consistent with a finite number of\nobservations if \\(H\\) is correct for some complete data sequence\nthat extends the finite observations.\nA finite number of observations falsifies hypothesis\n\\(H\\) if \\(H\\) is inconsistent with the observations.\nA finite number of observations  entails hypothesis\n\\(H\\) relative to a hypothesis set \\(\\mathbf{H}\\) if \\(H\\) is the only\nhypothesis in \\(\\mathbf{H}\\) consistent with the observations.\n\n\nNote that since logical entailment does not depend on the language we\nuse to frame evidence and hypotheses, the concepts of consistency,\nentailment, and falsification do not depend on the language we use to\nframe evidence and hypotheses.\nExamples. Recall the raven scenario from\n Section 1.1\n (diagram repeated for convenience).\n\n\nFigure 1 [An extended description of figure 1 is in a supplement.]\n\n\nThe observation that the first raven is black is consistent with both\nhypotheses \\(H_1 =\\) \u201call (observed) ravens are\nblack\u201d and \\(H_2 =\\) \u201csome (observed) raven is not\nblack\u201d. The observation that the first raven, or any raven, is\nwhite falsifies the hypothesis \\(H_1\\) and entails the\nhypothesis \\(H_2\\). The entailment is illustrated by the gray\nfan structure, which means that after the observation of any white\nraven, the hypothesis \\(H_1\\) is correct for any extending\ncomplete data sequence that records the color of all further observed\nravens.\n3.1 Verifiable and Refutable Hypotheses\n\nThe next set of concepts we need to understand the structure of\nhypotheses that can be settled by reliable inquiry are the notions of\n verifiable and  falsifiable  hypotheses. The\nverifiability and falsifiability of claims have been extensively\ndiscussed in epistemology and the philosophy of science, especially by\nphilosophers concerned with issues in logical empiricism. This\nsubsection describes how these concepts are used in learning theory,\nthen compares the learning-theoretic concepts with discussions in\nbroader epistemology.\n\nA hypothesis \\(H\\) is  verifiable  if whenever \\(H\\)\nis correct, eventually evidence is observed that entails that \\(H\\)\nis correct. More formally: \\(H\\) is verifiable with respect to a\nhypothesis set \\(\\mathbf{H}\\) if for every complete data sequence for which\n\\(H\\) is correct, there is a finite number of observations that\nfalsify all alternative hypotheses \\(H'\\) from \\(\\mathbf{H}\\).\nA hypothesis \\(H\\) is  refutable  if whenever \\(H\\),\neventually evidence is observed that falsifies \\(H\\). More\nformally: \\(H\\) is refutable with respect to a hypothesis set\n\\(\\mathbf{H}\\) if for every complete data sequence for which \\(H\\) is\nnot correct (but some other hypothesis in \\(\\mathbf{H}\\) is), there\nis a finite number of observations that falsifies \\(H\\).\n\nExamples\n\nThe hypothesis \\(H_2 =\\) \u201csome (observed) raven is not\nblack\u201d is verifiable but not refutable. It is verifiable because\nany data sequence for which it is correct, features a non-black raven\nat some finite time. The observation of the non-black raven entails\n\\(H_2\\). The hypothesis \\(H_2\\) is not\nfalsifiable, because if only black ravens are observed forever,\nthen \\(H_2\\) is incorrect, but there is no finite number of\nobservations that falsifies \\(H_2\\).\nThe hypothesis \\(H_1 =\\) \u201call (observed) ravens are\nblack\u201d is refutable but not verifiable. It is refutable because\nany data sequence for which it is not correct, features a non-black\nraven at some finite time. The observation of the non-black raven\nfalsifies \\(H_1\\). \\(H_1\\) is not verifiable,\nbecause if only black ravens are observed forever, then \\(H_1\\)\nis correct, but there is no finite number of observations that entails\n\\(H_1\\).\nIn the New Riddle of Induction of\n Section 1.2\n (diagram repeated below for convenience), the hypothesis \u201call\n(observed) emeralds are green\u201d is falsifiable but not\nverifiable, for the same reason as \u201call (observed) ravens are\nblack\u201d is refutable but not verifiable.\nAny of the grue hypotheses \\(H_t =\\) \u201call (observed)\nemeralds are grue(t) \u201d is verifiable  and  refutable.\n\\(H_t\\) is refutable because any complete data sequence for\nwhich a gruesome generalization is incorrect will feature a\ncounterexample that falsifies it. \\(H_t\\) is verifiable because\nif it is correct, the first observation of a blue emerald at time\n\\(t\\) falsifies the hypothesis \u201call (observed) emeralds are\ngreen \u201d and also falsifies all other \\(H_t\\)\nhypotheses.\n\n\nThe example of the gruesome hypotheses shows that an empirical\nhypothesis can be both verifiable and refutable (sometimes called\n\u201cdecidable\u201d in analogy with\n computation theory).\n Other typical examples of decidable empirical claims are singular\nobservations, such as \u201cthe first raven is black\u201d, and Boolean\ncombinations of singular observations.\n\n\nFigure 4 [An extended description of figure 4 is in a supplement.]\n\n\nWe will briefly discuss similarities and differences to related\nconcepts from epistemology and the philosophy of science.\n\nVerificationism  is part of the philosophy of\n logical empiricism.\n The core idea is that for a claim to be meaningful, it must be\nempirically verifiable. The main difference with our concept is the\nphilosophical objective: the goal of learning theory is not to\nseparate meaningful from meaningless claims, but to characterize the\nstandards of empirical success we can expect from inquiry for a given\nset of hypotheses. A hypothesis that is verifiable according to the\ndefinition above allows inquiry to provide a  positive test :\nwhen the hypothesis is correct, inquiry will eventually indicate its\ncorrectness with certainty (given background knowledge). The specific\ndefinitions of \u201cverifiability\u201d offered by the logical\nempiricists are not equivalent to verifiability in the\nlearning-theoretic sense. For example,\n strict verificationism\n holds that \u201cin order to be meaningful a claim must be implied\nby a finite number of observation sentences.\u201d. No finite number\nof observation sentences is equivalent to the hypothesis that\n\\(H_2 =\\) \u201csome (observed) raven is not black\u201d,\nbecause this hypothesis is equivalent to an infinite disjunction of\nobservation sentences (i.e., a non-black raven at time 1, a non-black\nraven at time 2, \u2026).\n\nFalsificationism\n is a well-known view in the philosophy of science. The core idea is\nthat for a hypothesis to be scientific, rather than pseudo-scientific\nor metaphysical, it must be falsifiable in the following sense:\n\u201cstatements \u2026, in order to be ranked as scientific, must be\ncapable of conflicting with possible, or conceivable\nobservations\u201d. (Popper 1962, 39). The main difference with our\ndevelopment is the philosophical objective: the goal of learning\ntheory is not to demarcate scientific hypotheses from\npseudo-scientific theories, but to characterize the standards of\nempirical success we can expect from inquiry for a given set of\nhypotheses. A hypothesis that is refutable according to the definition\nabove allows inquiry to provide a  negative test: when the\nhypothesis is incorrect, inquiry will eventually indicate its\nincorrectness with certainty (given background knowledge). The\nspecific definition of \u201cfalsifiability\u201d in the Popper\nquote above is not equivalent to refutability in the\nlearning-theoretic sense [Schulte and Juhl 1996]. For example, the\nhypothesis \\(H =\\) \u201cthe first raven is black and some other\nraven is non-black\u201d conflicts with the possible observation that\nthe first raven is white. However, if in fact all observed ravens are\nblack, then \\(H\\) is incorrect but not falsified by any finite\nnumber of observations, hence not refutable according to the\nlearning-theoretic definition. For further discussion of the\nrelationship between Popperian falsification and learning theory see\n[Genin 2018].\n3.2 Point-Set Topology and the Axioms of Verifiability\n\nTo further elucidate the learning-theoretic concepts of verifiability\nand refutability, we note that they satisfy the following fundamental\nproperties. We give informal but rigorous proofs.\n\nA disjunction of verifiable hypotheses is also\nverifiable.\n\n\nProof: Let \\(H = H_1\\) or\n\\(H_2,\\ldots\\) or \\(H_n\\) or \u2026\nbe a disjunction of verifiable hypotheses \\(H_i\\) (the\ndisjunction may be infinite). Suppose that \\(H\\) is correct for a\ncomplete data sequence. Then some \\(H_i\\) is correct\nfor the data sequence. Since \\(H_i\\) is verifiable,\nthere is a finite number of observations that entails\n\\(H_i\\), which entails \\(H\\). So if \\(H\\) is\ncorrect for any complete data sequence, there is a finite number of\nobservations from the sequence that entails \\(H\\), as required\nfor verifiability. For example, let \\(H_i\\) be the\nverifiable hypothesis that there is a non-black raven at time\n\\(i\\). Then the hypothesis \\(H =\\) \u201csome (observed)\nraven is not black\u201d is equivalent to the disjunction\n\\(H_1\\) or \\(H_2,\\ldots\\) or\n\\(H_n\\) or \u2026. Since each hypothesis\n\\(H_i\\) is verifiable, so is \\(H\\).\n \nA finite conjunction of verifiable hypotheses is also\nverifiable.\n\n\nProof: Let \\(H = H_1\\) and \\(H_2,\\ldots\\) and \\(H_n\\) be a finite\nconjunction of verifiable hypotheses \\(H_i\\).  Suppose that \\(H\\) is\ncorrect for a complete data sequence. Then each \\(H_i\\) is correct for\nthe data sequence. Since \\(H_i\\) is verifiable, there is a finite\nnumber of observations that entails \\(H_i\\). Because there are only\nfinite many hypotheses \\(H_i\\), eventually each hypothesis will be\nverified by a finite number of observations, which entails their\nconjunction \\(H\\). So if \\(H\\) is correct for any complete data\nsequence, there is a finite number of observations from the sequence\nthat entails \\(H\\), as required for verifiability. For example, let\n\\(H_1\\) be the verifiable hypothesis that the first raven is non-black\nand let \\(H_2\\) be the verifiable hypothesis that the second raven is\nnon-black. If the conjunction \\(H = H_1\\) and \\(H_2\\) is correct for a\ndata sequence, then the first two ravens are not black. The\nobservation of the first two ravens therefore entails \\(H\\).\n \nA tautology and a contradiction are (trivially)\nverifiable.\n\n\nProof: A tautology (like \u201cthe first observed raven is black or\nis not black\u201d) is correct for any data sequence and entailed by\nany evidence sequence. A contradiction (like \u201cthe first observed\nraven is black and is not black\u201d) is trivially verified if it is\ncorrect because it is never correct.\n \nA hypothesis is verifiable if and only if its negation is\nrefutable.\n\n\nProof: We consider the only-if direction; the converse is similar.\nSuppose that the negation not H of a hypothesis is refutable.\nConsider any complete data sequence for which hypothesis \\(H\\) is\ncorrect. Then not H is incorrect, and will be falsified by a\nfinite number of observations, since it is refutable. This finite\nobservation set entails \\(H\\). So if \\(H\\) is correct for\nany complete data sequence, there is a finite number of observations\nfrom the sequence that entails \\(H\\), as required for\nverifiability. For example, \\( H=\\) \u201csome (observed) raven\nis not black\u201d is the negation of the refutable hypothesis\nnot \\(H =\\) \u201call (observed) ravens are black\u201d. If\nnot \\(H\\) is incorrect for a complete data sequence, it will be\neventually falsified by the observation of a non-black raven. This\nobservation entails \\(H\\).\n \n\n\nRemarkably, the properties listed are exactly the fundamental axioms\nof an important branch of mathematics known as  point-set \ntopology [Abramsky 1987, Vickers 1986]. A topological space is defined\nby a collection of sets known as  open sets or\nneighbourhoods, that satisfy the axiomatic properties of verifiable\nhypotheses (closure under arbitrary union and finite disjunction, both\nthe empty set and the entire space are open). The set-theoretic\ncomplements of open sets are called closed sets, so refutable\nhypotheses correspond exactly to closed sets. Point-set topology was\ninvented to support a kind of generalized functional analysis without\nnumbers (more precisely, without distances). It is striking that the\nfoundational axioms of topology have an exact epistemological\ninterpretation in terms of the properties of empirical hypotheses that\nallow verification or falsification with certainty. Current\nmathematical developments of learning theory often begin by taking as\na basic concept a set of verifiable hypotheses satisfying the\nproperties listed. This approach has two advantages.\n\nLearning theory can draw on, and contribute to, the rich body of\nconcepts and results from one of the most developed branches of modern\nmathematics [Kelly 1996, Baltag et al. 2015, de Brecht and Yamamoto\n2008].\nThe flexibility to adapt the notion of evidence item to the\ncontext of an application makes it easier to apply the general theory\nin different domains. For example, consider the problem of obtaining\nincreasing precisely measurements of a quantity of interest (e.g. the\nspeed of light in physics). We can take the basic set of verifiable\nhypotheses to be (unions of) open intervals around the true value of\nthe quantity [Baltag et al. 2015, MONIST, Genin and Kelly 2017].\nAnother example is the concept of statistical verifiability covered in\n Section 6\n below.\n\n\nFor the sake of concreteness, this entry describes examples where the\nbasic verifiable hypotheses are disjunctions of finite sequences of\nevidence items. We will describe definitions and results in such a way\nthat they assume only the axiomatic properties listed so that they are\neasy to apply in other settings.\n3.3 Identifiability in the Limit of Inquiry\n\nA fundamental result describes the conditions under which a method can\nreliably find the correct hypothesis among a countably infinite or\nfinite number \\(\\mathbf{H}\\) of mutually exclusive hypotheses that\njointly cover all possibilities consistent with the inquirer\u2019s\nbackground assumptions. A learner for \\(\\mathbf{H}\\)\nmaps a finite sequence of observations to a hypothesis in\n\\(\\mathbf{H}\\). For example in the New Riddle of Induction, the\nnatural projection is a learner for the hypothesis set \\(\\mathbf{H}\\)\nthat comprises \u201call emeralds are green\u201d, \\(H_1 =\\)\n\u201call emeralds are grue(1)\u201d, \\(H_2 =\\) \u201call emeralds\nare grue(2)\u201d, etc. for all critical times \\(t\\). A\nlearner reliably identifies, or simply identifies, a\ncorrect hypothesis from \\(\\mathbf{H}\\) if for every complete data\nsequence the following holds: if \\(H\\) from \\(\\mathbf{H}\\) is correct\nhypothesis for the data sequence, then there is a finite number of\nobservations such that the learner conjectures the correct hypothesis\n\\(H\\) for any further observations consistent with the data\nsequence. The generalizing method and the natural projection rule are\nexamples of reliable learners for their hypothesis sets.\n\n\nTheorem. There is a learner that reliably identifies\na correct hypothesis from \\(\\mathbf{H}\\) if and only if each\nhypothesis \\(\\mathbf{H}\\) is a finite or countable disjunction of\nrefutable hypotheses.\n\nFor the proof see Kelly [1996, Ch. 3.3].\n\n\nExample. For illustration, let\u2019s return to the\nornithological example with two alternative hypotheses: (1) all but\nfinitely many swans are white, and (2) all but finitely many swans are\nblack. As we saw, it is possible in the long run to reliably settle\nwhich of these two hypotheses is correct. Hence by the\ncharacterization theorem, each of the two hypotheses must be a\ndisjunction of refutable empirical claims. To see that this indeed is\nso, observe that \u201call but finitely many swans are white\u201d\nis logically equivalent to the disjunction\n\nat most 1 swan is black or at most 2 swans are black \u2026 or at\nmost \\(n\\) swans are black \u2026 or \u2026 ,\n\n\nand similarly for \u201call but finitely many swans are black\u201d.\nEach of the claims in the disjunction is refutable. For example, take\nthe claim that \u201cat most 3 swans are black\u201d. If this is\nfalse, more than 3 black swans will be found, at which point the claim\nis conclusively falsified. The figure below illustrates how the\nidentifiable hypotheses are structured as disjunctions of refutable\nhypotheses.\n\n\nFigure 5 [An extended description of figure 5 is in a supplement.]\n\n\nThe characterization theorem implies that we can think of a reliable\nmethod as adopting internal strengthened versions of the\noriginal hypotheses under investigation that are refutable. As the\nexample above shows, the theorem does not imply that the strengthened\nhypotheses are mutually exclusive (e.g.\u201cat most 3 swans are\nblack\u201d is consistent with \u201cat most 2 swans are\nblack\u201d.). A recent alternative characterization theorem due to\nBaltag, Gierasimczuk, and Smets [2015] provides an alternative\nstructural analysis where identifiable hypotheses are decomposed into\nmutually exclusive components, as follows.\n\nA hypothesis \\(H\\) is  verirefutable  if it is equivalent to\nthe conjunction of a verifiable and a refutable hypothesis (given\nbackground knowledge): \\(H = (V\\) and \\(R)\\) where \\(V\\) is verifiable\nand R is refutable. For example, the hypothesis \u201cexactly 2 swans\nare black\u201d is verirefutable, since it is equivalent to the\nconjunction of the verifiable hypothesis \u201cat least 2 swans are\nwhite\u201d and the refutable hypothesis \u201cat most 2 swans are\nwhite\u201d. The term \u201cverirefutable\u201d is due to [Genin\nand Kelly 2015]; it signifies that when a verirefutable hypothesis is\ntrue, there is some initial condition after which the hypothesis is\nrefutable, that is, the hypothesis will be falsified by data if it is\nfalse. Baltag et al. refer to verirefutable hypotheses as locally\nclosed. They establish the following characterization theorem for\nreliable learning [Baltag et al. 2015].\n\nTheorem. There is a learner that reliably identifies a correct\nhypothesis from \\(\\mathbf{H}\\) if and only if each hypothesis \\(\\mathbf{H}\\) is\nequivalent to a finite or countable disjunction of mutually exclusive\nverirefutable hypotheses.\n\n\nSince the verirefutable hypotheses are mutually exclusive, they\nconstitute a valid  refined  hypothesis space whose members\nentail exactly one of the original hypothesis. The characterization\ntheorem entails that without loss of learning power, inductive methods\ncan transform the original hypothesis space into a verirefutable one.\nThe figure below illustrates the decomposition into verirefutable\nhypotheses.\n\n\nFigure 6 [An extended description of figure 6 is in a supplement.]\n\n\nA few points will help explain the significance of characterization\ntheorems.\n\nStructure of Reliable Methods. Characterization theorems tell\nus how the structure of reliable methods is attuned to the structure\nof the hypotheses under investigation. For example, the theorem\nmentioned establishes a connection between falsifiability and\ntestability, but one that is more attenuated than the na\u00efve\nPopperian envisions: it is not necessary that the hypotheses under\ntest be directly falsifiable; rather, there must be ways of\nstrengthening each hypothesis that yield a countable number of\nrefutable \u201csubhypotheses\u201d. We can think of these refutable\nsubhypotheses as different ways in which the main hypothesis may be\ntrue. (For example, one way in which \u201call but finitely many\nswans are white\u201d is true is if there are are at most 10 black\nswans; another is if there are at most 100 black swans, etc.).\nStrengthening the original hypotheses so they become empirically\nrefutable matches the spirit of\n Lakatos\u2019s methodology\n in which a general scientific paradigm is articulated with auxiliary\nhypotheses to define testable (i.e., falsifiable) claims.\nImport of Background Assumptions. The characterization result\ndraws a line between the solvable and unsolvable problems. Background\nknowledge reduces the inductive complexity of a problem; with enough\nbackground knowledge, the problem crosses the threshold between the\nunsolvable and the solvable. In many domains of empirical inquiry, the\npivotal background assumptions are those that make reliable inquiry\nfeasible. (Kuhn [1970] makes related points about the importance of\nbackground assumptions embodied in a \u201cparadigm\u201d).\nLanguage Invariance. Learning-theoretic characterization\ntheorems concern what Kelly calls the \u201ctemporal\nentanglement\u201d of various observation sequences [Kelly 2000].\nUltimately they rest on entailment relations between given evidence,\nbackground assumptions and empirical claims. Since logical entailment\ndoes not depend on the language we use to frame evidence and\nhypotheses, the inductive complexity of an empirical problem as\ndetermined by the characterization theorems is\nlanguage-invariant.\n\n4. The Long Run in the Short Run: Reliable and Stable Beliefs\n\nA longstanding criticism of convergence to the truth as an aim of\ninquiry is that, while fine in itself, this aim is consistent with any\ncrazy behaviour in the short run [Salmon 1991]. For example, we saw in\nthe New Riddle of Induction that a reliable projection rule can\nconjecture that the next emerald will be blue no matter how many green\nemeralds have been found\u2014as long as eventually the rule\nprojects \u201call emeralds are green\u201d. One response is that if\nmeans-ends analysis takes into account other epistemic aims in\naddition to long-run convergence, then it can provide\nstrong guidance for what to conjecture in the short run.\n\nTo illustrate this point, let us return to the Goodmanian Riddle of\nInduction. Ever since Plato, philosophers have considered the idea\nthat stable true belief is better than unstable true belief,\nand epistemologists such as Sklar [1975] have advocated similar\nprinciples of \u201cepistemic conservatism\u201d. Kuhn tells us that\na major reason for conservatism in paradigm debates is the cost of\nchanging scientific beliefs [Kuhn 1970]. In this spirit, learning\ntheorists have examined methods that minimize the number of times that\nthey change their theories before settling on their final conjecture\n[Putnam 1965, Kelly 1996, Jain 1999]. Such methods are said to\nminimize mind changes.\n4.1 Example: The New Riddle of Induction\n\nThe New Riddle of Induction turns out to be a nice illustration of\nthis idea. Consider the natural projection rule (conjecture that all\nemeralds are green on a sample of green emeralds). If all emeralds are\ngreen, this rule never changes its conjecture. And if all emeralds are\ngrue\\((t)\\) for some critical time \\(t\\), then the natural\nprojection rule abandons its conjecture \u201call emeralds are\ngreen\u201d at time \\(t\\)\u2014one mind change\u2014and\nthereafter correctly projects \u201call emeralds are\ngrue\\((t)\\)\u201d. Remarkably, rules that project grue rather\nthan green do not do as well. For example, consider a rule that\nconjectures that all emeralds are grue(3) after observing one green\nemerald. If two more green emeralds are observed, the rule\u2019s\nconjecture is falsified and it must eventually change its mind, say to\nconjecture that all emeralds are green (supposing that green emeralds\ncontinue to be found). But then at that point, a blue emerald may\nappear, forcing a second mind change. This argument can be generalized\nto show that  the aim of minimizing mind changes allows only the\ngreen predicate to be projected on a sample of all green emeralds \n[Schulte 1999]. We saw in\n Section 1.2\n above how the natural projection rule changes its mind at most once;\nthe figure below illustrates in a typical case how an unnatural\nprojection rule may have to change its mind twice or more.\n\n\nFigure 7 [An extended description of figure 7 is in a supplement.]\n\n4.2 More Examples\n\nThe same reasoning applies to the question about whether all ravens\nare black. The bold generalizer that conjectures that all ravens are\nblack after observing samples of only black ravens succeeds with at\nmost one mind change: if indeed all ravens are black, the generalizer\nnever changes its mind at all. And if there is a nonblack raven, the\nrefutation occasions one mind change, but afterwards the question is\nsettled.\n\nContrast this with the contrary method that asserts that there is a\nnonblack raven after observing a sample of all black ones. If only\nblack ravens continue to be observed, the contrary method has to\neventually change its mind and assert that \u201call ravens are\nblack\u201d, or else it fails to arrive at the correct\ngeneralization. But then at that point, a nonblack raven may appear,\nforcing a second mind change. Thus the goal of stable belief places\nstrong constraints on what a method may conjecture in the short run\nfor this problem: on observing only black ravens, the options are\n\u201call ravens are black\u201d or \u201cno opinion yet\u201d,\nbut not \u201cthere is a nonblack raven\u201d.\n\nIn the conservation law problem, the restrictive method described in\n Section 2.1\n is the only method that minimizes mind changes. Recall that the\nrestrictive method adopts a set of conservation laws that rule out as\nmany unobserved reactions as possible. It can be shown that if there\nare \\(n\\) known elementary particles whose reactions are observed,\nthis method requires at most \\(n\\) mind changes. (The number of\nelementary particles in the Standard Model is around \\(n = 200).\\)\n\nFor learning causal graphs, the following variant of the method\ndescribed in\n Section 2.2\n minimizes the number of mind changes.\n\nSuppose we have observed a set of correlations or associations\namong a set of variables of interest.\nIf there is a unique causal graph that explains the observed\ncorrelations with a minimum number of direct causal links,\nselect this graph.\nIf there is more than one causal graph that explains the observed\ncorrelations with a minimum number of direct causal links, output\n\u201cno opinion yet\u201d (or conjecture the disjunction of the\nminimum edge graphs).\n\n\nThis example illustrates that sometimes minimizing mind changes\nrequires withholding beliefs. Intuitively, this occurs when there are\ntwo or more equally simple explanations of the data, and the inquirer\nhas to wait until further observations decide between these\npossibilities. Jumping to one of the simple conclusions might lead to\nan unnecessary mind change in case an alternative equally simple\nexplanation turns out to be correct. In such cases there is a\ntrade-off between the goals of achieving stable belief, on the one\nhand, and quickly settling on a true belief on the other [Schulte\n1999]. We discuss the connection between simplicity and stable belief\nin the next section on simplicity.\n4.3 Regressive Mind Changes\n\nGenin and Kelly [2015] refine the mind change approach by\ndistinguishing different kinds of mind changes.\n\nAbandoning a true hypothesis in favor of a false one. This is an\nundesirable regressive mind change.\nAbandoning a false hypothesis in favor of a true one. This is a\ndesirable progressive mind change.\nAbandoning a false hypothesis in favor of another false one.\n\n\nThe table below illustrates these distinctions in the New Riddle of\nInduction and the Raven example. Genin and Kelly investigate the\nprinciple that inductive methods should minimize the number of\nregressive mind changes, that is, the number of times new evidence\nleads the method to abandon a true hypothesis in favor of a false one.\nThe notion that regressive mind changes are a mark of epistemic\nfailure matches a long tradition in epistemology.\n Defeasibility theories of knowledge (see the link in the Other\nInternet Resources section below)\n hold that in order for an agent\u2019s true belief to count as\nknowledge, it must be indefeasible in the sense that\naccepting further propositions should not lead the agent to abanon her\nbelief. Translated into the language of mind changes, this means that\nan inquirer\u2019s true current conjecture can count as knowledge\nonly if there is no further evidence that would lead her to change her\nmind and adopt an alternative false conjecture.\n Plato\u2019s Meno\n conveys this point vividly. \n\n\nNow this is an illustration of the nature of true opinions: while they\nabide with us they are beautiful and fruitful, but they run away out\nof the human soul, and do not remain long, and therefore they are not\nof much value \u2026. But when they are bound, in the first place, they\nhave the nature of knowledge; and, in the second place, they are\nabiding.\n\n\n\n\n\nTrue\u00a0Hypothesis\n\u201cAll emeralds are green\u201d\n\u201cThere is a non-black raven\u201d\n\n\nConjecture\u00a00\n\u201cAll emeralds are grue(1)\u201d\n\u201cThere is a non-black raven\u201d\n\n\nObservation\u00a01\nGreen emerald\nBlack raven\n\n\nConjecture\u00a01\n\u201cAll emeralds are grue(2)\u201d false-to-false\n\u201cAll ravens are black\u201d true-to-false\n\n\nObservation\u00a02\nGreen emerald\nWhite raven\n\n\nConjecture\u00a02\n\u201cAll emeralds are green\u201d false-to-true\n\u201cThere is a non-black raven\u201d false-to-true\n\n\n\nIllustrating regressive and progressive mind changes\n\n\nWhile minimizing regressive mind changes is an even more important\nepistemic goal than avoiding mind changes in general, it leads to\nweaker strictures on inductive learning. At the same time any\nstrictures that do follow from it carry even more normative force. The\ntable above illustrates the differences between the two principles in\nthe New Riddle of Induction and the Raven problem. In the New Riddle\nof Induction, if only green emeralds are ever observed, a projection\nrule may keep projecting any number of gruesome predicates without\nproducing a regressive mind change: it simply abandons one false\ngruesome predicate for another false gruesome predicate. Therefore\neven unnatural projection rules incur 0 regressive mind changes,\nprovided they never abandon \u201cthe all green hypothesis\u201d once\nadopted.\n\nThe consequences of minimizing regressive mind changes are different\nfor the question of whether all ravens are black. Consider again the\ncontrary method that asserts that there is a nonblack raven after\nobserving a sample of black ones. As shown in the Table and discussed\nabove, the contrary method has to eventually change its hypothesis\nafter seeing more black ravens to conjecture that all ravens are\nblack, and then, upon observing a white raven, return to its true\ninitial hypothesis that there is a nonblack raven. Thus the contrary\nmethod undergoes at least one regressive mind change in the worst\ncase. On the other hand, the generalizing method that asserts that all\nravens are black after observing a sample of black ones changes its\nconjecture only when a nonblack raven is observed---a progressive mind\nchange from a false hypothesis to a true hypothesis. Therefore the\nprinciple of avoiding regressive mind changes singles out the\ngeneralizing method over the contrary one.\n\nAs the example illustrates, regressive mind changes are associated\nwith cycles of conjectures. This is because a reliable method\nmust eventually return a true hypothesis after adopting a false one,\nso a regressive mind change leads to at least one cycle true\nconjecture-false conjecture-true conjecture. Methods that avoid\nregressive mind changes are therefore studied under the heading of\ncycle-free learning [Genin and Kelly 2015] or minimizing U-turns\n[Carlucci et al. 2005]. Genin and Kelly [2015, 2019] provide a\ngeneral result that elucidates the general methodological import of\navoiding regressive mind changes and cycles of conjectures (described\nin\n Section 5.4).\n Their result belongs to a family of theorems that establish a\nstriking connection between avoiding mind changes and Ockham\u2019s\nrazor, which we discuss in the next section.\n5. Simplicity, Stable Belief, and Ockham\u2019s Razor\n\nA strong intuition about inductive inference and scientific method is\nthat we should prefer simpler hypotheses over complex ones; see the\n entry on simplicity.\n Statisticians, computer scientists, and other researchers concerned\nwith learning from observations have made extensive use of a\npreference for simplicity to solve practical inductive problems\n[Domingos 1999]. From a foundational point of view, simplicity is\nproblematic for at least two reasons.\n\nThe justification problem: Why adopt simple hypotheses? One\nobvious answer is that the world is simple and therefore a complex\ntheory is false. However, the apriori claim that the world is simple\nis highly controversial\u2014see the\n entry on simplicity.\n From a learning-theoretic perspective, dismissing complex hypotheses\nimpairs the reliability of inductive methods. In Kelly\u2019s\nmetaphor, a fixed bias is like a stopped watch: We may happen to use\nthe watch when it is pointing at the right time, but the watch is not\na reliable instrument for telling time [Kelly 2007a, 2010]. \nThe description problem: Epistemologists have worried that\nsimplicity is not an objective feature of a hypothesis, but rather\n\u201cdepends on the mode of presentation\u201d, as Nozick puts it.\nGoodman\u2019s Riddle illustrates this point. If generalizations are\nframed in blue-green terms, \u201call emeralds are green\u201d\nappears simpler than \u201call emeralds are first green and then\nblue\u201d. But in a grue-bleen language, \u201call emeralds are\ngrue\u201d appears simpler than \u201call emeralds are first grue\nand then bleen\u201d. \n\n\nLearning theorists have engaged in recent and ongoing efforts to apply\nmeans-ends epistemology to develop a theory of the connection between\nsimplicity and induction that addresses these concerns [Kelly 2010,\nHarmann and Kulkarni 2007, Luo and Schulte 2006, Steel 2009]. It turns\nout that a fruitful perspective is to examine the relationship between\nthe structure of a hypothesis space and the mind change complexity of\nthe corresponding inductive problem. The fundamental idea is that,\nwhile simplicity does not enjoy an a priori connection with truth,\nchoosing simple hypotheses can help an inquirer find the truth more\nefficiently, in the sense of avoiding mind changes.\nKelly\u2019s road metaphor illustrates the idea. Consider two routes\nto the destination, one via a straight highway, the other via back\nroads. Both routes eventually lead to the same point, but the back\nroads entail more twists and turns [Kelly 2007a, 2010].\n\nA formalization of this idea takes the form of an Ockham\nTheorem: A theorem that shows (under appropriate restrictions)\nthat an inductive method finds the truth as efficiently as possible\nfor a given problem if and only if the method is the Ockham\nmethod, that is, it selects the simplest hypothesis consistent\nwith the data. An Ockham theorem provides a justification for\nOckham\u2019s inductive razor as a means towards epistemic aims.\n\nWhether an Ockham theorem is true depends on the description of the\nOckham method, that is, on the exact definition of simplicity for a\nset of hypotheses. There is a body of mathematical results that\nestablish Ockham theorems using a language-invariant simplicity\nmeasure, which we explain next.\n5.1 Defining Simplicity\n\nSay that a hypothesis \\(H\\) from a background set of possible\nhypotheses \\(\\mathbf{H}\\) is verifiable if there is an evidence\nsequence such that \\(H\\) is the only hypothesis from \\(\\mathbf{H}\\) that\nis consistent with the evidence sequence. For example, in the black\nraven problem above, the hypothesis \u201cthere is a nonblack\nraven\u201d is verifiable since it is entailed by an observation of a\nnonblack raven. The hypothesis \u201call ravens are black\u201d is\nnot verifiable, since it is not entailed by any finite evidence\nsequence. The following procedure assigns a simplicity rank to each\nhypothesis \\(H\\) from a set of hypotheses \\(\\mathbf{H}\\) [Apsitis 1994,\nLuo and Schulte 2006].\n\nAssign all verifiable hypotheses simplicity rank 0.\nRemove the verifiable hypotheses from the hypothesis space to form\na new hypothesis space \\(\\mathbf{H}_1.\\)\nAssign simplicity rank 1 to the hypotheses that are verifiable\ngiven \\(\\mathbf{H}_1.\\)\nRemove the newly verifiable hypotheses with simplicity rank 1 from\nthe hypothesis space to form a new hypothesis space\n\\(\\mathbf{H}_2.\\)\nContinue removing hypotheses until no new hypotheses are\nverifiable given the current hypothesis space.\nThe simplicity rank of each hypothesis \\(H\\) is the first stage\nat which it is removed by this procedure. In other words, it is the\nindex of the first restricted hypothesis space that makes \\(H\\)\nverifiable.\n\n\nHypotheses with higher simplicity rank are regarded as simpler than\nthose with lower ranks. Simplicity ranks are defined in terms of\nlogical entailment relations, hence are language-invariant. Simplicity\nranks as defined can be seen as degrees of falsifiability in\nthe following sense. Consider a hypothesis of simplicity rank 1. Such\na hypothesis is falsifiable because an evidence sequence that verifies\nan alternative hypothesis of rank 0 falsifies it. Moreover, a\nhypothesis of simplicity rank 1 is persistently falsifiable in the\nsense that it remains falsifiable no matter what evidence sequence\nconsistent with it is observed. A hypothesis of simplicity rank\n\\(n+1\\) is persistently falsifiable by hypotheses of rank \\(n.\\)\nLet us illustrate the definition in our running examples.\n5.2 Examples\n\nIn the Riddle of Induction, the verifiable hypotheses are the grue\nhypotheses with critical time t: any sequence of t green emeralds\nfollowed by blue ones entails the corresponding grue(t)\ngeneralization. Thus the grue hypotheses receive simplicity rank 0.\nAfter the grue hypotheses are eliminated, the only remaining\nhypothesis is \u201call emeralds are green\u201d. Given that it is\nthe only possibility in the restricted hypothesis space, \u201call\nemeralds are green\u201d is entailed by any sequence of green\nemeralds. Therefore \u201call emeralds are green\u201d has\nsimplicity rank 1. After removing the all green hypothesis, no\nhypotheses remain. \nIn the raven color problem, the verifiable hypothesis is \u201ca\nnonblack raven will be observed\u201d, which receives simplicity rank\n0. After removing the hypothesis that a nonblack raven will be\nobserved, the only remaining possibility is that only black ravens\nwill be observed, hence this hypothesis is verifiable in the\nrestricted hypothesis space and receives simplicity rank 1. \nThe simplicity rank of a causal graph is given by the number of direct\nlinks not contained in the graph. Therefore the fewer direct\nlinks are posited by the causal model, the higher its simplicity\nrank. \nThe simplicity rank of a set of conservation laws is given by the\nnumber of independent laws. (Independence in the sense of linear\nalgebra.) Therefore the more nonredundant laws are introduced by a\ntheory, the higher its simplicity rank. Each law rules out some\nreactions, so maximizing the number of independent laws given the\nobserved reactions is equivalent to ruling out as many unobserved\nreactions as possible. \n\n5.3 Stable Belief and Simplicity: An Ockham Theorem\n\nThe following theorem shows the connection between the mind-change\ncomplexity of an inductive problem and the simplicity ranking as\ndefined.\n\nTheorem. Let \\(\\mathbf{H}\\) be a set of empirical hypotheses. Then\nthere is a method that reliably identifies a correct hypothesis from\n\\(\\mathbf{H}\\) in the limit with at most n mind changes if and only if the\nelimination procedure defined above terminates with an empty set of\nhypotheses after n stages.\n\n\nThus for an inductive problem to be solvable with at most \\(n\\)\nmind changes, the maximum simplicity rank of any possible hypothesis\nis \\(n.\\) In the Riddle of Induction, the maximum simplicity rank\nis 1, and therefore this problem can be solved with at most 1 mind\nchange. The next result provides an Ockham theorem connecting\nsimplicity and mind change performance.\n\n\nOckham Theorem. Let \\(\\mathbf{H}\\) be a set of empirical hypotheses\nwith optimal mind change bound n. Then an inductive method is mind\nchange optimal if and only if it satisfies the following\nconditions.\n\nWhenever the method adopts one of the hypotheses from \\(\\mathbf{H},\\)\nthis hypothesis is the uniquely simplest one consistent with the\nevidence.\nIf the method changes its mind at inquiry time \\(t+1\\), the\nuniquely simplest hypothesis at time \\(t\\) is falsified at time\n\\(t+1.\\)\n\n\n\nThis theorem says that a mind-change optimal method may withhold a\nconjecture as a skeptic would, but if it does adopt a definite\nhypothesis, the hypothesis must be the simplest one, in the sense of\nhaving the maximum simplicity rank. Thus the mind change optimal\nmethods discussed in\n Section 4\n are all Ockham methods that adopt the simplest hypothesis consistent\nwith the data. The Ockham theorem shows a remarkable reversal from the\nlong-standing objection that long-run reliability imposes too few\nconstraints on short-run conjectures: If we add to long-run\nconvergence to the truth the goal of achieving stable belief, then in\nfact there is a unique inductive method that achieves this goal\nin a given empirical problem. Thus the methodological analysis\nswitches from offering no short-run prescriptions to offering a\ncomplete prescription.\n5.4 Regressive Mind Changes and Simplicity: Another Ockham Theorem\n\nThe previous subsection defines a complete simplicity ranking for\nevery hypothesis under investigation. This means that any hypothesis\ncan be compared to another as simpler or equally simple. A less\ndemanding concept is a partial order, which allows that some\nhypotheses may simply not be comparable, like apples and oranges.\nGenin and Kelly [2015] show that the following partial order leads to\nan Ockham principle for avoiding regressive mind changes (see\n Section 4.3).\n\nAn observation sequence separates hypothesis \\(H_1\\) from\nhypothesis \\(H_2\\) if the observations are consistent with \\(H_1\\) and\nfalsify \\(H_2\\) (given background knowledge). \nHypothesis \\(H_1\\) is inseparable from \\(H_2\\), written \\(H_1 \\lt\nH_2\\), if no observation sequence separates \\(H_1\\) from\n\\(H_2\\). Equivalently, \\(H_1 \\lt H_2\\) if and only if any evidence\nconsistent with \\(H_1\\) is also consistent with \\(H_2.\\)\n\n\nThe separation terminology is due to Smets et al., who relate it to\nseparation principles in point-set topology. In terms of the\nepistemological interpretation of point-set topology from\n Section 3.2,\n we have \\(H_1 \\lt H_2\\) if and only if every complete data sequence\nfor \\(H_1\\) is a boundary point for the data sequences of \\(H_2.\\) In\nan epistemologically resonant phrase, Genin and Kelly say that\nhypothesis \\(H_1\\) \u201cfaces the problem of induction\u201d with respect to\n\\(H_2\\) whenever \\(H_1 \\lt H_2\\). This is because whenever \\(H_1\\) is\ncorrect, a reliable learner will have to take an \u201cinductive leap\u201d and\nconjecture \\(H_1\\) although any finite amount of evidence is also\nconsistent with \\(H_2\\).\nExamples\n\nIn the raven problem, \\(H_1 =\\) \u201call ravens are black\u201d\n\\(\\lt H_2 =\\) \u201csome raven is not black\u201d. But it\nis not the case that \u201csome raven is not black\u201d\n\\(\\lt\\) \u201call ravens are black\u201d because the observation of a\nwhite raven separates \\(H_2\\) from \\(H_1.\\) \nIn\n causal graph learning,\nif graph \\(G_1\\) contains a subset of edges (direct causal links) of\nthose in alternative graph \\(G_2\\), then \\(G_1 \\lt G_2\\). This is\nbecause any correlations that can be explained by \\(G_1\\) can also be\nexplained by the larger graph \\(G_2\\). \nIn curve fitting, \\(L \\lt Q\\) where \\(L\\) is\nthe set of linear functions, and \\(Q\\) is the set of quadratic\nfunctions. This is because any set of points that can be fit by a\nlinear function can also be fit by a quadratic function.\n\n\nThese examples suggest that the \\(\\lt\\) partial order corresponds to\nour intuitive simplicity judgements about empirical hypotheses; Genin\nand Kelly [2019] provide an extensive defense of this claim. It can be\nshown that the \\(\\lt\\) ordering agrees with the simplicity ranks\ndefined in the previous subsection, in the sense that if \\(H_1 \\lt\nH_2\\) but not \\(H_2 \\lt H_1\\), then the simplicity rank of \\(H_1\\) is\nless than the rank of \\(H_2\\). These observations motivate an Ockham\nprinciple: An inductive method satisfies the Ockham principle with\nrespect to separability if it always conjectures a maximally\nsimple hypothesis \\(H\\) consistent with the evidence. In our notation,\nif an Ockham method adopts a hypothesis \\(H\\) given a finite\nobservation sequence, then there is no alternative simpler hypothesis\n\\(H'\\) such that \\(H' \\lt H\\). That is, every alternative hypothesis\n\\(H'\\) will eventually be separated from \\(H\\) by the evidence if\n\\(H'\\) is true. In the raven example, the generalizing method\nsatisfies the Ockham principle, but the contrary method does not,\nbecause it adopts \\(H_2 =\\) \u201csome raven is not black\u201d. The\nfollowing theorem shows that the connection between the Ockham\nprinciple and regressive mind changes is general. \n\nTheorem. If an inductive method avoids conjecture\ncycles (and hence regressive mind changes), it satisfies the Ockham\nprinciple with respect to separability. \n\nFor a proof see Genin and Kelly [2015; Theorem 10]. Genin and Kelly\nalso provide sufficient conditions for avoiding conjecture cycles.\n\n\nWhile the results in this section establish a fruitful connection\nbetween simplicity and mind-change optimality, a limitation of the\napproach is that it requires that some hypotheses must be conclusively\nentailed or falsified by some evidence sequence. This is typically not\nthe case for statistical models, where the probability of a hypothesis\nmay become arbitrarily small but usually not 0. For instance, consider\na coin flip problem and the hypothesis \u201cthe probability of heads\nis 90%\u201d. If we observe one million tails, the probability of the\nhypothesis is very small indeed, but it is not 0, because any number\nof tails is logically consistent with a high probability of heads. The\nnext section discusses how a reliabilist approach can be adapted to\nstatistical hypotheses.\n6. Reliable Learning for Statistical Hypotheses\n\nStatistical hypotheses are the most common in practical data-driven\ndecision making, for example in the sciences and engineering. It is\ntherefore important for a philosophical framework of inductive\ninference to include statistical hypotheses. There are two key\ndifferences between statistical hypotheses and the hypotheses sets we\nhave considered so far [Sober 2015].\n\nThe relationship between observations and a hypothesis is\nprobabilistic, not deductive: A statistical hypothesis assigns a\nprobability to an observation sequence, typically between 0 and 1. A\ndeductive hypothesis is either consistent with an observation sequence\nor falsified.\nThe analysis of statistical hypotheses typically assumes that\nobservations form a random sample: successive observations\nare independent of each other and follow the same distribution. It is\npossible to analyze statistical methods where later observations\ndepend on current observations, but the mathematical complexity of\ninductive methodology is much greater than with independent data.\n\n\nBecause of these properties, learning theory for nonstatistical\nmethods is a more straightforward framework than statistics for\ntraditional philosophical discussions in epistemology, inductive\ninference, and the philosophy of science. For example, epistemological\ndiscussions of justified true belief concern a deductive concept of\nbelief where the inquirer accepts a proposition, rather than assign a\nprobability to data. Scientific theories typically make a\ndeterministic prediction of future data from past observations\n(initial conditions), so an independence requirement makes it more\ndifficult to apply a methodological framework to understand scientific\ninquiry (see our\n case studies).\n\nNormative means-ends epistemology can be applied to statistical\nhypotheses as well as deductive ones. In particular we will discuss\nhow the ideas of reliable convergence to the truth and minimizing\nregressive mind changes can be adapted to the statistical setting. The\nkey idea is to shift the unit of analysis: Whereas previously we\nconsidered the behavior of an inductive method for a specific data\nsequence, in statistical analysis we consider its aggregate\nbehavior over a set of data sequences of the same length. In\nparticular, we consider the probability that a method conjectures\na hypothesis H for a given number of observations \\(n.\\)\nPreliminaries on Statistical Hypotheses\n\nWe will illustrate the main ideas with a classic simple example,\nobserving coin flips, and indicate how they can be generalized to more\ncomplex hypotheses. For more details please see [Genin and Kelly 2017,\nGenin 2018]. Suppose that an investigator has a question about the\nunknown bias \\(p\\) of a coin, where \\(p\\) represents the chance that a\nsingle flip comes out \u201cHeads\u201d. Different possible\nhypotheses correspond to different ranges of the bias \\(p\\), that is,\na partition of [0,1], the range of the bias. Let us say that the\ninvestigator asks a simple point hypothesis: is the coin\nfair? Then we have\n\n\\(H_1 =\\) \u201c\\(p = 0.5\\)\u201d\n\\(H_2 =\\) \u201cit is not the case that \\(p = 0.5\\)\u201d.\nThat is, either \\(p \\lt 0.5\\) or \\(p \\gt 0.5.\\)\n\n\nExtending our previous terminology, we shall say that a true bias\nvalue \\(p\\) is for a hypothesis H if it lies within the\nset specified by \\(H\\). In our example, a bias value p\nis correct for \\(H_1\\) if and only if \\(p = 0.5\\); otherwise\n\\(p\\) is correct for \\(H_2\\). Given a true bias value \\(p\\),\nand assuming independence, we can compute a probability for any\nfinite sequence of observations. This probability is known as the\nsample distribution. For example, for a fair coin with \\(p = 0.5,\\)\nthe probability of observing 3 heads is \\(0.5 \\times 0.5 \\times 0.5 =\n0.125.\\) If the chance of heads is 0.7, the probability of observing 3\nheads is \\(0.7 \\times 0.7 \\times 0.7 = 0.343.\\) Notice how the\nindependence assumption allows us to compute the probability of a\nsequence of observations as the product of single observation\nprobabilities. Without the independence assumption, we cannot infer\nthe probability of multiple observations from the probability of a\nsingle observation, and the sample distribution is not defined. \n\nAs usual in this entry, an inductive method conjectures a hypothesis\nafter observing a finite sequence of observations. A method that\nconjectures a statistical hypothesis is called a statistical\ntest (see the link in the Other Internet Resource section below).\nThe statistical literature provides an extensive collection of\ncomputationally efficient statistical tests for different types of\nstatistical hypothesis. In the following discussion we consider the\ngeneral learning performance of such methods, with respect to reliable\nconvergence to a true hypothesis and avoiding mind changes. Consider a\nfixed observation length \\(n,\\) called the\nsample size. For sample size \\(n\\), there is a set of\nsamples of length \\(n\\) such that the method conjectures\nhypothesis \\(H\\)given the sample. For example, for \\(n =\n3\\), the method might conjecture \\(H_2 =\\) \u201cthe coin is not\nfair\u201d after observing 3 heads. The aggregate probability that\nthe method outputs hypothesis \\(H\\) given some sample of\nlength \\(n\\), is the sum of the sample probabilities of the\nsamples such that the method conjectures \\(H\\) given the sample.\nIn the supplement we give example computations of the aggregate\nprobability. Because this aggregate probability is the key quantity\nfor the methodology of statistical hypotheses, we introduce the\nfollowing notation for it.\n\n\n\\(P_{n,p}(H) =\\) the probability that a given inductive\nmethod conjectures hypothesis \\(H\\) after \\(n\\)\nobservations, given that the true probability of a single observation\nis \\(p\\)\n\n\nIn nonstatistical learning, we required a reliable method to\neventually settle on true hypothesis after sufficiently many\nobservations. The statistical version of this criterion is that after\nsufficiently many observations, the chance of conjecturing the true\nhypothesis should approach 100%. More technically, say that a method\nidentifies a true statistical hypothesis in chance if for\nevery bias value \\(p\\), and for every threshold \\(0\\lt t \\lt 1\\),\nthere is a sample size \\(n\\) such that for all larger sample sizes,\nthe method conjectures the hypothesis \\(H\\) that is true for \\(p\\)\nwith at least probability \\(t\\). In symbols, we have \\(P_{n',p}(H) \\gt\nt\\) for all sample sizes \\(n' \\gt n\\), where \\(H\\) is the hypothesis\nthat is true for \\(p\\). The figure below illustrates how the chance of\nconjecturing the true hypothesis increases with sample size, whereas\nthe chance of conjecturing a false hypothesis decreases with sample\nsize. The definition can be generalized to more complex statistical\nhypotheses by replacing the true bias value \\(p\\) with a list of\nparameters.\n\n\nFigure 8 [An extended description of figure 8 is in a supplement.]\n\n\nThe notion of limiting identification in chance is similar to the\nconcept of limiting convergence to a probability estimate in\n Reichenbach\u2019s pragmatic vindication.\n Translated to our example, Reichenbach considered inductive rules\nthat output an estimate of the true bias value \\(p,\\) and\nrequired that such a rule converges to the true value, in the sense\nthat for every every bias value \\(p\\), and for every threshold\n\\(0\\lt t \\lt 1\\), there is a sample size \\(n\\) such that\nfor all larger sample sizes, with probability 1 the rule outputs an\nestimate that differs from the true value \\(p\\) by at most\n\\(t\\). In statistics, a method is called consistent if\nwith increasing sample size, the method\u2019s chance of conjecturing\na correct answer converges to 100% (see the link in the Other Internet\nResources section below). The terminology is unfortunate in that it\nsuggests to philosophical readers a connection with the consistency of\na formal proof system. In fact, the statistical concept of consistency\nhas nothing to do with deductive logic; rather, it is a probabilistic\nanalogue of the notion of identification in the limit of inquiry that\nis the main subject of this entry. \n\nGenin and Kelly provide a characterization theorem that provides\nnecessary and sufficient conditions for a set of statistical\nhypotheses to be identifiable in chance, analogous to the structural\nconditions we discussed in\n Section 3.3\n [2017; Theorem 4.3]. Genin [2018] discusses a statistical analogue of\nthe requirement of minimizing mind changes. Recall that a regressive\nmind change occurs when an inquirer abandons a true hypothesis in\nfavor of a false one\n Section 4.3.\n The probabilistic analogue is a chance reversal, which\noccurs when the chance of conjecturing a true hypotheses decreases as\nthe sample size increases. For instance, consider the question of\nwhether a vaccine is effective for an infectious disease. Suppose the\nvaccine manufacture runs a trial with 1000 patients and has designed a\nstatistical method that has a chance of 90% of correctly indicating\nthat the vaccine is effective when that is indeed the case. Now\nanother trial is run with 1500 patients using the same statistical\nmethod. A chance reversal would occur if the method\u2019s chance of\ncorrectly indicating that the vaccine is effective drops to 80%. As\nthis example illustrates, a chance reversal corresponds to a failure\nto replicate a true result. A chance reversal is illustrated in the\nFigure above, where the chance of conjecturing the true hypothesis is\nsmaller for 2 samples than for 3. Although chance reversals are\nclearly undesirable, they are difficult to avoid, and in fact commonly\nused statistical methods are liable to such reversals [Genin 2018]. A\nmore feasible goal is to bound the reversals by a threshold \\(t\\),\nsuch that if the chance of conjecturing the truth does decreases with\nincreasing sample size, it decreases by at most \\(t.\\) (In symbols,\n\\(P_{n,p}(H) - P_{n+1,p}(H) \\lt t\\) for all sample sizes \\(n\\) and\ntrue bias values \\(p\\), where \\(H\\) is the hypothesis correct for\n\\(p\\).) Genin [2018] shows that bounded chance reversal are feasible\nin many situations, and provides an Ockham theorem that elucidates the\nconstraints that bounding chance reversals provides on statistical\nhypothesis learning. \n7. Other Approaches: Categorical vs. Hypothetical Imperatives\n\nKant distinguished between categorical imperatives that one ought to\nfollow regardless of one\u2019s personal aim and circumstances, and\nhypothetical imperatives that direct us to employ our means towards\nour chosen end. One way to think of learning theory is as the study of\nhypothetical imperatives for empirical inquiry. Many epistemologists\nhave proposed various categorical imperatives for inductive inquiry,\nfor example in the form of an \u201cinductive logic\u201d or norms\nof \u201cepistemic rationality\u201d. In principle, there are three\npossible relationships between hypothetical and categorical\nimperatives for empirical inquiry.\n\n1. The categorical imperative will lead an inquirer to obtain his\ncognitive goals. In that case means-ends analysis vindicates\nthe categorical imperative. For example, when faced with a simple\nuniversal generalization such as \u201call ravens are black\u201d,\nwe saw above that following the Popperian recipe of adopting the\nfalsifiable generalization and sticking to it until a counterexample\nappears leads to a reliable method.\n\n2. The categorical imperative may prevent an inquirer from\nachieving his aims. In that case the categorical imperative\nrestricts the scope of inquiry. For example, in the case of\nthe two alternative generalizations with exceptions, the principle of\nmaintaining a universal generalization until it is falsified leads to\nan unreliable method (cf. [Kelly 1996, Ch. 9.4]).\n\n3. Some methods meet both the categorical imperative and the\ngoals of inquiry, and others don\u2019t. Then we may take the best of\nboth worlds and choose those methods that attain the goals of inquiry\nand satisfy categorical imperatives. (See the further discussion in\nthis section.)\n\nFor a proposed norm of inquiry, we can apply means-ends analysis to\nask whether the norm helps or hinders the aims of inquiry. This was\nthe spirit of Putnam\u2019s critique of Carnap\u2019s confirmation\nfunctions [Putnam 1963]: the thrust of his essay was that\nCarnap\u2019s methods were not as reliable in detecting general\npatterns as other methods would be. More recently, learning theorists\nhave investigated the power of Bayesian conditioning (see the entry on\n Bayesian epistemology).\n John Earman has conjectured that if there is any reliable method for\na given problem, then there is a reliable method that proceeds by\nBayesian updating [Earman 1992, Ch.9, Sec.6]. Cory Juhl [1997]\nprovided a partial confirmation of Earman\u2019s conjecture: He\nproved that it holds when there are only two potential evidence items\n(e.g., \u201cemerald is green\u201d vs. \u201cemerald is\nblue\u201d). The general case is still open.\n\nEpistemic conservatism is a methodological norm that has been\nprominent in philosophy at least since Quine\u2019s notion of\n\u201cminimal mutilation\u201d of our beliefs [1951]. One version of\nepistemic conservatism, as we saw above, holds that inquiry should\nseek stable belief. Another formulation, closer to Quine\u2019s, is\nthe general precept that belief changes in light of new evidence\nshould be minimal. Fairly recent work in philosophical logic has\nproposed a number of criteria for minimal belief change known\nas the AGM axioms [G\u00e4rdenfors 1988]. Learning theorists have\nshown that whenever there is a reliable method for investigating an\nempirical question, there is one that proceeds via minimal changes (as\ndefined by the AGM postulates). The properties of reliable inquiry\nwith minimal belief changes are investigated in [Martin and Osherson\n1998, Kelly 1999, Baltag et al. 2011, Baltag et al. 2015].\n\nMuch of computational learning theory focuses on inquirers with\nbounded rationality, that is, agents with cognitive\nlimitations such as a finite memory or bounded computational\ncapacities. Many categorical norms that do not interfere with\nempirical success for logically omniscient agents nonetheless limit\nthe scope of cognitively bounded agents. For example, consider the\nnorm of consistency: Believe that a hypothesis is false as soon as the\nevidence is logically inconsistent with it. The consistency principle\nis part of both Bayesian confirmation theory and AGM belief revision.\nKelly and Schulte [1995] show that consistency prevents even agents\nwith infinitely uncomputable cognitive powers from reliably assessing\ncertain hypotheses. The moral is that if a theory is sufficiently\ncomplex, agents who are not logically omniscient may be unable to\ndetermine immediately whether a given piece of evidence is consistent\nwith the theory, and need to collect more data to detect the\ninconsistency. But the consistency principle\u2014and a fortiori,\nBayesian updating and AGM belief revision\u2014 do not acknowledge\nthe usefulness of \u201cwait and see more\u201d as a scientific\nstrategy.\n\nMore reflection on these and other philosophical issues in means-ends\nepistemology can be found in sources such as Huber [2018], [Glymour\n1991], [Kelly 1996, Chs. 2,3], [Glymour and Kelly 1992], [Kelly et\nal. 1997], [Glymour 1994], [Bub 1994]. Of particular interest in\nthe philosophy of science may be learning-theoretic models that\naccommodate historicist and relativist conceptions of inquiry, chiefly\nby expanding the notion of an inductive method so that methods may\nactively select paradigms for inquiry; for more details on this topic,\nsee [Kelly 2000, Kelly 1996, Ch.13]. Booklength introductions to the\nmathematics of learning theory are [Kelly 1996, Martin and Osherson\n1998, Jain et al. 1999]. \u201cInduction, Algorithmic Learning Theory\nand Philosophy\u201d is a recent collection of writings on learning\ntheory [Friend et al. 2007]. Contributions include introductory papers\n(Harizanov, Schulte), mathematical advances (Martin, Sharma, Stephan,\nKalantari), philosophical reflections on the strengths and\nimplications of learning theory (Glymour, Larvor, Friend),\napplications of the theory to philosophical problems (Kelly), and a\ndiscussion of learning-theoretic thinking in the history of philosophy\n(Goethe).\nSupplementary Document: Basic Formal Definitions\n", "bibliography": {"categories": [], "cat_ref_text": {"ref_list": ["Abramsky, S., 1987. <em>Domain Theory and the Logic of Observable\nProperties</em>, Ph.D. Dissertation, University of London.", "Apsitis, K., 1994. \u201cDerived sets and inductive\ninference\u201d, in <em>Proceedings of the 5th International Work on\nAlgorithmic Learning Theory</em>, S. Arikawa, K.P. Jantke (eds.),\nBerlin, Heidelberg: Springer, pp. 26\u201339.", "Baltag, A. and Smets, S., 2011. \u201cKeep changing your beliefs,\naiming for the truth\u201d, <em>Erkenntnis</em>, 75(2):\n255\u2013270.", "Baltag, A., Gierasimczuk, N., Smets, S., 2015. \u201cOn the\nSolvability of Inductive Problems: A Study in Epistemic\nTopology\u201d, <em>Proceedings of the 15th Conference on Theoretical\nAspects of Rationality and Knowledge</em> (TARK 2015), , pp.\n65\u201374. \n <a href=\"https://www.imsc.res.in/tark/TARK2015-proceedings.pdf\" target=\"other\">Electronic Proceedings in Theoretical Computer Science available online</a>.", "Bub, J., 1994. \u201cTesting Models of Cognition Through the\nAnalysis of Brain-Damaged Performance\u201d, <em>British Journal for\nthe Philosophy of Science</em>, 45: 837\u201355.", "Carlucci, L., Case, J., Jain, S. and Stephan, F., 2005. \u201cNon\nU-shaped vacillatory and team learning\u201d, in <em>International\nConference on Algorithmic Learning Theory</em>, Berlin, Heidelberg:\nSpringer, pp. 241\u2013255.", "Chart, D., 2000. \u201cSchulte and Goodman\u2019s Riddle\u201d,\n<em>British Journal for the Philosophy of Science</em>, 51:\n837\u201355.", "de Brecht, M. and Yamamoto, A., 2008. \u201cTopological\nproperties of concept spaces\u201d, in <em>International Conference on\nAlgorithmic Learning Theory</em>, Berlin, Heidelberg: Springer, pp.\n374\u2013388.", "Domingos, P., 1999. \u201cThe role of Occam\u2019s razor in\nknowledge discovery\u201d, <em>Data mining and Knowledge\ndiscovery</em>, 3(4): 409\u2013425.", "Earman, J., 1992. <em>Bayes or Bust?</em>, Cambridge, Mass.: MIT\nPress.", "Feynman, R., 1965. <em>The Character of Physical Law</em>,\nCambridge, Mass.: MIT Press; 19th edition, 1990.", "Friend, M. and N. Goethe and V. Harazinov (eds.), 2007.\n<em>Induction, Algorithmic Learning Theory, and Philosophy</em>,\nDordrecht: Springer, pp. 111\u2013144.", "Ford, K., 1963. <em>The World of Elementary Particles</em>, New\nYork: Blaisdell Publishing.", "G\u00e4rdenfors, P., 1988. <em>Knowledge In Flux: modeling the\ndynamics of epistemic states</em>, Cambridge, Mass.: MIT Press.", "Genin, K., 2018. \u201cThe Topology of Statistical\nInquiry\u201d, Ph.D. Dissertation, Department of Philosophy, Carnegie\nMellon University,\n <a href=\"https://kgenin.github.io/papers/draft4.pdf\" target=\"other\">Genin 2018 available online.</a>", "Genin, K. and Kelly, K., 2015. \u201cTheory Choice, Theory\nChange, and Inductive Truth-Conduciveness\u201d, Proceedings <em>of\nthe 15th Conference on Theoretical Aspects of Rationality and\nKnowledge</em> (TARK 2015). Publisher: Electronic Proceedings in\nTheoretical Computer Science. Extended Abstract,\n <a href=\"https://www.researchgate.net/publication/301957309_Theory_Choice_Theory_Change_and_Inductive_Truth-Conduciveness\" target=\"other\">Genin &amp; Kelly 2015 available online.</a>", "\u2013\u2013\u2013, 2017. \u201cThe Topology of Statistical\nVerifiability\u201d, <em>Proceedings of the 17th Conference on\nTheoretical Aspects of Rationality and Knowledge</em> (TARK 2017).\nElectronic Proceedings in Theoretical Computer Science,\n <a href=\"https://arxiv.org/html/1707.08250\" target=\"other\">preprint available online </a>.", "\u2013\u2013\u2013, 2019. \u201cTheory Choice, Theory Change,\nand Inductive Truth-Conduciveness\u201d, <em>Studia Logica</em>, 107:\n949\u2013989.", "Glymour, C., 1991. \u201cThe Hierarchies of Knowledge and the\nMathematics of Discovery\u201d, <em>Minds and Machines</em>, 1:\n75\u201395.", "\u2013\u2013\u2013, 1994. \u201cOn the Methods of Cognitive\nNeuropsychology\u201d, <em>British Journal for the Philosophy of\nScience</em>, 45: 815\u201335.", "Glymour, C. and Kelly, K., 1992. \u201cThoroughly Modern\nMeno\u201d, in <em>Inference, Explanation and Other\nFrustrations</em>, John Earman (ed.), Berkeley: University of\nCalifornia Press.", "Gold, E., 1967. \u201cLanguage Identification in the\nLimit\u201d, <em>Information and Control</em>, 10:\n447\u2013474.", "Goodman, N., 1983. <em>Fact, Fiction and Forecast</em>, Cambridge,\nMA: Harvard University Press.", "Harrell, M., 2000. <em>Chaos and Reliable Knowledge</em>, Ph.D.\nDissertation, University of California at San Diego.", "Harman, G. and Kulkarni, S., 2007. <em>Reliable Reasoning:\nInduction and Statistical Learning Theory</em>, Cambridge, MA: The MIT\nPress.", "Huber, F., 2018. <em>A Logical Introduction to Probability and\nInduction</em>, Oxford: Oxford University Press.", "Jain, S., et al., 1999. <em>Systems That Learn</em>,\n2<sup>nd</sup> edition, Cambridge, MA: MIT Press.", "James, W., 1982. \u201cThe Will To Believe\u201d, in\n<em>Pragmatism</em>, H.S. Thayer (ed.), Indianapolis: Hackett.", "Juhl, C., 1997. \u201cObjectively Reliable Subjective\nProbabilities\u201d, <em>Synthese</em>, 109: 293\u2013309.", "Kelly, K., 1996. <em>The Logic of Reliable Inquiry</em>, Oxford:\nOxford University Press.", "\u2013\u2013\u2013, 1999. \u201c Iterated Belief Revision,\nReliability, and Inductive Amnesia\u201d, <em>Erkenntnis</em>, 50:\n11\u201358.", "\u2013\u2013\u2013, 2000. \u201cThe Logic of Success\u201d,\n<em>British Journal for the Philosophy of Science</em>, 51(4):\n639\u2013660.", "\u2013\u2013\u2013, 2007a. \u201cHow Simplicity Helps You Find\nthe Truth Without Pointing at it\u201d, in <em> Induction,\nAlgorithmic Learning Theory, and Philosophy</em>, M. Friend, N. Goethe\nand V. Harazinov (eds.), Dordrecht: Springer, pp. 111\u2013144.", "\u2013\u2013\u2013, 2008. \u2018Ockham\u2019s Razor, Truth,\nand Information\u2019, in <em>Handbook of the Philosophy of\nInformation</em>, J. van Behthem and P. Adriaans (eds.), Dordrecht:\nElsevier.", "\u2013\u2013\u2013, 2010. \u201cSimplicity, Truth, and\nProbability\u201d, in <em>Handbook for the Philosophy of\nStatistics</em>, Prasanta S. Bandyopadhyay and Malcolm Forster (eds.),\nDordrecht: Elsevier.", "Kelly, K., and Schulte, O., 1995. \u201cThe Computable\nTestability of Theories Making Uncomputable Predictions\u201d,\n<em>Erkenntnis</em>, 43: 29\u201366.", "Kelly, K., Schulte, O. and Juhl, C., 1997. \u201cLearning Theory\nand the Philosophy of Science\u201d, <em>Philosophy of Science</em>,\n64: 245\u201367.", "Kuhn, T., 1970. <em>The Structure of Scientific Revolutions</em>.\nChicago: University of Chicago Press.", "Luo, W. and Schulte O., 2006. \u201cMind Change Efficient\nLearning\u201d, in <em>Logic and Computation</em>, 204:\n989\u20131011.", "Martin, E. and Osherson, D., 1998. <em>Elements of Scientific\nInquiry</em>, Cambridge, MA: MIT Press.", "Ne\u2019eman, Y. and Kirsh, Y., 1983. <em>The Particle\nHunters</em>, Cambridge: Cambridge University Press.", "Omnes, R., 1971. <em>Introduction to Particle Physics</em>,\nLondon, New York: Wiley Interscience.", "Popper, Karl, 1962. <em>Conjectures and refutations. The growth of\nscientific knowledge</em>, New York: Basic Books.", "Putnam, H., 1963. \u201cDegree of Confirmation and Inductive\nLogic\u201d, in <em>The Philosophy of Rudolf Carnap</em>, P.A.\nSchilpp (ed.), La Salle, Ill: Open Court.", "Putnam, H., 1965. \u201cTrial and Error Predicates and the\nSolution to a Problem of Mostowski\u201d, <em>Journal of Symbolic\nLogic</em>, 30(1): 49\u201357.", "Quine, W., 1951. \u201cTwo Dogmas of Empiricism\u201d,\n<em>Philosophical Review</em>, 60: 20\u201343.", "Salmon, W., 1991. \u201cHans Reichenbach\u2019s Vindication of\nInduction\u201d, <em>Erkenntnis</em>, 35: 99\u2013122.", "Schulte, O., 1999. \u201cMeans-Ends Epistemology\u201d, <em>The\nBritish Journal for the Philosophy of Science</em>, 50:\n1\u201331.", "\u2013\u2013\u2013, 2008. \u201cThe Co-Discovery of\nConservation Laws and Particle Families\u201d, <em>Studies in History\nand Philosophy of Modern Physics</em>, 39(2): 288\u2013314.", "\u2013\u2013\u2013, 2009. \u201cSimultaneous Discovery of\nConservation Laws and Hidden Particles With Smith Matrix\nDecomposition\u201d, in <em>Proceedings of the Twenty-First\nInternational Joint Conference on Artificial Intelligence</em>\n(IJCAI-09), Palo Alto: AAAI Press pp. 1481-1487.", "Schulte, O., Luo, W., and Greiner, R., 2007. \u201cMind Change\nOptimal Learning of Bayes Net Structure\u201d, in <em>Proceedings of\nthe 20th Annual Conference on Learning Theory</em> (COLT\u201907, San\nDiego, CA, June 12\u201315), N. Bshouti and C. Gentile (eds.),\nBerlin, Heidelberg: Springer, pp. 187\u2013202.", "Schulte, O., and Cory Juhl, 1996. \u201cTopology as\nEpistemology\u201d, <em>The Monist</em>, 79(1): 141\u2013147.", "Sklar, L., 1975. \u201cMethodological Conservatism\u201d,\n<em>Philosophical Review</em>, 84: 374\u2013400.", "Sober, E., 2015. <em>Ockham\u2019s Razors</em>, Cambridge:\nCambridge University Press.", "Spirtes, P., Glymour, C., Scheines, R., 2000. <em>Causation,\nprediction, and search</em>, Cambridge, MA: MIT Press.", "Steel, D., 2009. \u201cTestability and Ockham\u2019s Razor: How\nFormal and Statistical Learning Theory Converge in the New Riddle of\nInduction,\u201d <em>Journal of Philosophical Logic</em>, 38:\n471\u2013489.", "\u2013\u2013\u2013, 2010. \u201cWhat if the principle of\ninduction is normative? Formal learning theory and Hume\u2019s\nproblem\u201d, <em>International Studies in the Philosophy of\nScience</em>, 24(2): 171\u2013185.", "Valiant, L. G., 1984. \u201cA theory of the learnable\u201d,\n<em>Proceedings of the Sixteenth Annual ACM Symposium on Theory of\nComputing</em> (STOC 84), New York: ACM Press, pp. 436\u2013445.", "Vickers, S., 1996. <em>Topology Via Logic</em>, Cambridge:\nCambridge University Press."]}, "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Abramsky, S., 1987. <em>Domain Theory and the Logic of Observable\nProperties</em>, Ph.D. Dissertation, University of London.</li>\n<li>Apsitis, K., 1994. \u201cDerived sets and inductive\ninference\u201d, in <em>Proceedings of the 5th International Work on\nAlgorithmic Learning Theory</em>, S. Arikawa, K.P. Jantke (eds.),\nBerlin, Heidelberg: Springer, pp. 26\u201339.</li>\n<li>Baltag, A. and Smets, S., 2011. \u201cKeep changing your beliefs,\naiming for the truth\u201d, <em>Erkenntnis</em>, 75(2):\n255\u2013270.</li>\n<li>Baltag, A., Gierasimczuk, N., Smets, S., 2015. \u201cOn the\nSolvability of Inductive Problems: A Study in Epistemic\nTopology\u201d, <em>Proceedings of the 15th Conference on Theoretical\nAspects of Rationality and Knowledge</em> (TARK 2015), , pp.\n65\u201374. \n <a href=\"https://www.imsc.res.in/tark/TARK2015-proceedings.pdf\" target=\"other\">Electronic Proceedings in Theoretical Computer Science available online</a>.</li>\n<li>Bub, J., 1994. \u201cTesting Models of Cognition Through the\nAnalysis of Brain-Damaged Performance\u201d, <em>British Journal for\nthe Philosophy of Science</em>, 45: 837\u201355.</li>\n<li>Carlucci, L., Case, J., Jain, S. and Stephan, F., 2005. \u201cNon\nU-shaped vacillatory and team learning\u201d, in <em>International\nConference on Algorithmic Learning Theory</em>, Berlin, Heidelberg:\nSpringer, pp. 241\u2013255.</li>\n<li>Chart, D., 2000. \u201cSchulte and Goodman\u2019s Riddle\u201d,\n<em>British Journal for the Philosophy of Science</em>, 51:\n837\u201355.</li>\n<li>de Brecht, M. and Yamamoto, A., 2008. \u201cTopological\nproperties of concept spaces\u201d, in <em>International Conference on\nAlgorithmic Learning Theory</em>, Berlin, Heidelberg: Springer, pp.\n374\u2013388.</li>\n<li>Domingos, P., 1999. \u201cThe role of Occam\u2019s razor in\nknowledge discovery\u201d, <em>Data mining and Knowledge\ndiscovery</em>, 3(4): 409\u2013425.</li>\n<li>Earman, J., 1992. <em>Bayes or Bust?</em>, Cambridge, Mass.: MIT\nPress.</li>\n<li>Feynman, R., 1965. <em>The Character of Physical Law</em>,\nCambridge, Mass.: MIT Press; 19th edition, 1990.</li>\n<li>Friend, M. and N. Goethe and V. Harazinov (eds.), 2007.\n<em>Induction, Algorithmic Learning Theory, and Philosophy</em>,\nDordrecht: Springer, pp. 111\u2013144.</li>\n<li>Ford, K., 1963. <em>The World of Elementary Particles</em>, New\nYork: Blaisdell Publishing.</li>\n<li>G\u00e4rdenfors, P., 1988. <em>Knowledge In Flux: modeling the\ndynamics of epistemic states</em>, Cambridge, Mass.: MIT Press.</li>\n<li>Genin, K., 2018. \u201cThe Topology of Statistical\nInquiry\u201d, Ph.D. Dissertation, Department of Philosophy, Carnegie\nMellon University,\n <a href=\"https://kgenin.github.io/papers/draft4.pdf\" target=\"other\">Genin 2018 available online.</a></li>\n<li>Genin, K. and Kelly, K., 2015. \u201cTheory Choice, Theory\nChange, and Inductive Truth-Conduciveness\u201d, Proceedings <em>of\nthe 15th Conference on Theoretical Aspects of Rationality and\nKnowledge</em> (TARK 2015). Publisher: Electronic Proceedings in\nTheoretical Computer Science. Extended Abstract,\n <a href=\"https://www.researchgate.net/publication/301957309_Theory_Choice_Theory_Change_and_Inductive_Truth-Conduciveness\" target=\"other\">Genin &amp; Kelly 2015 available online.</a></li>\n<li>\u2013\u2013\u2013, 2017. \u201cThe Topology of Statistical\nVerifiability\u201d, <em>Proceedings of the 17th Conference on\nTheoretical Aspects of Rationality and Knowledge</em> (TARK 2017).\nElectronic Proceedings in Theoretical Computer Science,\n <a href=\"https://arxiv.org/html/1707.08250\" target=\"other\">preprint available online </a>.</li>\n<li>\u2013\u2013\u2013, 2019. \u201cTheory Choice, Theory Change,\nand Inductive Truth-Conduciveness\u201d, <em>Studia Logica</em>, 107:\n949\u2013989.</li>\n<li>Glymour, C., 1991. \u201cThe Hierarchies of Knowledge and the\nMathematics of Discovery\u201d, <em>Minds and Machines</em>, 1:\n75\u201395.</li>\n<li>\u2013\u2013\u2013, 1994. \u201cOn the Methods of Cognitive\nNeuropsychology\u201d, <em>British Journal for the Philosophy of\nScience</em>, 45: 815\u201335.</li>\n<li>Glymour, C. and Kelly, K., 1992. \u201cThoroughly Modern\nMeno\u201d, in <em>Inference, Explanation and Other\nFrustrations</em>, John Earman (ed.), Berkeley: University of\nCalifornia Press.</li>\n<li>Gold, E., 1967. \u201cLanguage Identification in the\nLimit\u201d, <em>Information and Control</em>, 10:\n447\u2013474.</li>\n<li>Goodman, N., 1983. <em>Fact, Fiction and Forecast</em>, Cambridge,\nMA: Harvard University Press.</li>\n<li>Harrell, M., 2000. <em>Chaos and Reliable Knowledge</em>, Ph.D.\nDissertation, University of California at San Diego.</li>\n<li>Harman, G. and Kulkarni, S., 2007. <em>Reliable Reasoning:\nInduction and Statistical Learning Theory</em>, Cambridge, MA: The MIT\nPress.</li>\n<li>Huber, F., 2018. <em>A Logical Introduction to Probability and\nInduction</em>, Oxford: Oxford University Press.</li>\n<li>Jain, S., et al., 1999. <em>Systems That Learn</em>,\n2<sup>nd</sup> edition, Cambridge, MA: MIT Press.</li>\n<li>James, W., 1982. \u201cThe Will To Believe\u201d, in\n<em>Pragmatism</em>, H.S. Thayer (ed.), Indianapolis: Hackett.</li>\n<li>Juhl, C., 1997. \u201cObjectively Reliable Subjective\nProbabilities\u201d, <em>Synthese</em>, 109: 293\u2013309.</li>\n<li>Kelly, K., 1996. <em>The Logic of Reliable Inquiry</em>, Oxford:\nOxford University Press.</li>\n<li>\u2013\u2013\u2013, 1999. \u201c Iterated Belief Revision,\nReliability, and Inductive Amnesia\u201d, <em>Erkenntnis</em>, 50:\n11\u201358.</li>\n<li>\u2013\u2013\u2013, 2000. \u201cThe Logic of Success\u201d,\n<em>British Journal for the Philosophy of Science</em>, 51(4):\n639\u2013660.</li>\n<li>\u2013\u2013\u2013, 2007a. \u201cHow Simplicity Helps You Find\nthe Truth Without Pointing at it\u201d, in <em> Induction,\nAlgorithmic Learning Theory, and Philosophy</em>, M. Friend, N. Goethe\nand V. Harazinov (eds.), Dordrecht: Springer, pp. 111\u2013144.</li>\n<li>\u2013\u2013\u2013, 2008. \u2018Ockham\u2019s Razor, Truth,\nand Information\u2019, in <em>Handbook of the Philosophy of\nInformation</em>, J. van Behthem and P. Adriaans (eds.), Dordrecht:\nElsevier.</li>\n<li>\u2013\u2013\u2013, 2010. \u201cSimplicity, Truth, and\nProbability\u201d, in <em>Handbook for the Philosophy of\nStatistics</em>, Prasanta S. Bandyopadhyay and Malcolm Forster (eds.),\nDordrecht: Elsevier.</li>\n<li>Kelly, K., and Schulte, O., 1995. \u201cThe Computable\nTestability of Theories Making Uncomputable Predictions\u201d,\n<em>Erkenntnis</em>, 43: 29\u201366.</li>\n<li>Kelly, K., Schulte, O. and Juhl, C., 1997. \u201cLearning Theory\nand the Philosophy of Science\u201d, <em>Philosophy of Science</em>,\n64: 245\u201367.</li>\n<li>Kuhn, T., 1970. <em>The Structure of Scientific Revolutions</em>.\nChicago: University of Chicago Press.</li>\n<li>Luo, W. and Schulte O., 2006. \u201cMind Change Efficient\nLearning\u201d, in <em>Logic and Computation</em>, 204:\n989\u20131011.</li>\n<li>Martin, E. and Osherson, D., 1998. <em>Elements of Scientific\nInquiry</em>, Cambridge, MA: MIT Press.</li>\n<li>Ne\u2019eman, Y. and Kirsh, Y., 1983. <em>The Particle\nHunters</em>, Cambridge: Cambridge University Press.</li>\n<li>Omnes, R., 1971. <em>Introduction to Particle Physics</em>,\nLondon, New York: Wiley Interscience.</li>\n<li>Popper, Karl, 1962. <em>Conjectures and refutations. The growth of\nscientific knowledge</em>, New York: Basic Books.</li>\n<li>Putnam, H., 1963. \u201cDegree of Confirmation and Inductive\nLogic\u201d, in <em>The Philosophy of Rudolf Carnap</em>, P.A.\nSchilpp (ed.), La Salle, Ill: Open Court.</li>\n<li>Putnam, H., 1965. \u201cTrial and Error Predicates and the\nSolution to a Problem of Mostowski\u201d, <em>Journal of Symbolic\nLogic</em>, 30(1): 49\u201357.</li>\n<li>Quine, W., 1951. \u201cTwo Dogmas of Empiricism\u201d,\n<em>Philosophical Review</em>, 60: 20\u201343.</li>\n<li>Salmon, W., 1991. \u201cHans Reichenbach\u2019s Vindication of\nInduction\u201d, <em>Erkenntnis</em>, 35: 99\u2013122.</li>\n<li>Schulte, O., 1999. \u201cMeans-Ends Epistemology\u201d, <em>The\nBritish Journal for the Philosophy of Science</em>, 50:\n1\u201331.</li>\n<li>\u2013\u2013\u2013, 2008. \u201cThe Co-Discovery of\nConservation Laws and Particle Families\u201d, <em>Studies in History\nand Philosophy of Modern Physics</em>, 39(2): 288\u2013314.</li>\n<li>\u2013\u2013\u2013, 2009. \u201cSimultaneous Discovery of\nConservation Laws and Hidden Particles With Smith Matrix\nDecomposition\u201d, in <em>Proceedings of the Twenty-First\nInternational Joint Conference on Artificial Intelligence</em>\n(IJCAI-09), Palo Alto: AAAI Press pp. 1481-1487.</li>\n<li>Schulte, O., Luo, W., and Greiner, R., 2007. \u201cMind Change\nOptimal Learning of Bayes Net Structure\u201d, in <em>Proceedings of\nthe 20th Annual Conference on Learning Theory</em> (COLT\u201907, San\nDiego, CA, June 12\u201315), N. Bshouti and C. Gentile (eds.),\nBerlin, Heidelberg: Springer, pp. 187\u2013202.</li>\n<li>Schulte, O., and Cory Juhl, 1996. \u201cTopology as\nEpistemology\u201d, <em>The Monist</em>, 79(1): 141\u2013147.</li>\n<li>Sklar, L., 1975. \u201cMethodological Conservatism\u201d,\n<em>Philosophical Review</em>, 84: 374\u2013400.</li>\n<li>Sober, E., 2015. <em>Ockham\u2019s Razors</em>, Cambridge:\nCambridge University Press.</li>\n<li>Spirtes, P., Glymour, C., Scheines, R., 2000. <em>Causation,\nprediction, and search</em>, Cambridge, MA: MIT Press.</li>\n<li>Steel, D., 2009. \u201cTestability and Ockham\u2019s Razor: How\nFormal and Statistical Learning Theory Converge in the New Riddle of\nInduction,\u201d <em>Journal of Philosophical Logic</em>, 38:\n471\u2013489.</li>\n<li>\u2013\u2013\u2013, 2010. \u201cWhat if the principle of\ninduction is normative? Formal learning theory and Hume\u2019s\nproblem\u201d, <em>International Studies in the Philosophy of\nScience</em>, 24(2): 171\u2013185.</li>\n<li>Valiant, L. G., 1984. \u201cA theory of the learnable\u201d,\n<em>Proceedings of the Sixteenth Annual ACM Symposium on Theory of\nComputing</em> (STOC 84), New York: ACM Press, pp. 436\u2013445.</li>\n<li>Vickers, S., 1996. <em>Topology Via Logic</em>, Cambridge:\nCambridge University Press.</li>\n</ul>\n</div>"}, "related_entries": {"entry_list": ["confirmation", "epistemology: Bayesian", "induction: problem of", "James, William", "logic: inductive", "Peirce, Charles Sanders", "Popper, Karl", "simplicity", "underdetermination, of scientific theories"], "entry_link": [{"../confirmation/": "confirmation"}, {"../epistemology-bayesian/": "epistemology: Bayesian"}, {"../induction-problem/": "induction: problem of"}, {"../james/": "James, William"}, {"../logic-inductive/": "logic: inductive"}, {"../peirce/": "Peirce, Charles Sanders"}, {"../popper/": "Popper, Karl"}, {"../simplicity/": "simplicity"}, {"../scientific-underdetermination/": "underdetermination, of scientific theories"}]}, "academic_tools": {"listed_text": ["<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>", "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=learning-formal\" target=\"other\">How to cite this entry</a>.", "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>", "<a href=\"https://leibniz.stanford.edu/friends/preview/learning-formal/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.", "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>", "<a href=\"https://www.inphoproject.org/entity?sep=learning-formal&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).", "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>", "<a href=\"https://philpapers.org/sep/learning-formal/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."], "listed_links": [{"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=learning-formal": "How to cite this entry"}, {"https://leibniz.stanford.edu/friends/preview/learning-formal/": "Preview the PDF version of this entry"}, {"https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"}, {"https://www.inphoproject.org/entity?sep=learning-formal&redirect=True": "Look up topics and thinkers related to this entry"}, {"https://philpapers.org/sep/learning-formal/": "Enhanced bibliography for this entry"}, {"https://philpapers.org/": "PhilPapers"}]}, "other_internet_resources": {"listed_text": ["<a href=\"http://www.learningtheory.org/\" target=\"other\">Learning Theory in Computer Science</a>", "<a href=\"https://scholar.princeton.edu/osherson/four-essays\" target=\"other\">Inductive Logic Website on Formal Learning Theory and Belief Revision</a>", "<a href=\"https://www.rep.routledge.com/articles/thematic/gettier-problems/v-1/sections/defeasibility-analyses\" target=\"other\">Defeasibility analyses</a>, \n Section 2 of the entry on the Gettier Problem in the <em>Routledge \n Encyclopedia of Philosophy</em>.", "<a href=\"https://en.wikipedia.org/wiki/Statistical_hypothesis_testing\" target=\"other\">Statistical hypothesis testing</a>, \n entry in <em>Wikipedia</em>.", "<a href=\"https://en.wikipedia.org/wiki/Consistency_(statistics)\" target=\"other\">Consistency (in Statistics)</a>\n entry in <em>Wikipedia</em>."], "listed_links": [{"http://www.learningtheory.org/": "Learning Theory in Computer Science"}, {"https://scholar.princeton.edu/osherson/four-essays": "Inductive Logic Website on Formal Learning Theory and Belief Revision"}, {"https://www.rep.routledge.com/articles/thematic/gettier-problems/v-1/sections/defeasibility-analyses": "Defeasibility analyses"}, {"https://en.wikipedia.org/wiki/Statistical_hypothesis_testing": "Statistical hypothesis testing"}, {"https://en.wikipedia.org/wiki/Consistency_(statistics)": "Consistency (in Statistics)"}]}, "tokenized_text": ["1", "convergence", "truth", "nothing", "truth", "learningtheoretic", "analysis", "ass", "disposition", "forming", "belief", "several", "term", "belief", "acquisition", "process", "common", "use", "philosophy", "use", "inductive", "strategy", "inference", "method", "frequently", "inductive", "method", "mean", "thing", "best", "way", "understand", "learning", "theory", "evaluates", "inductive", "method", "work", "example", "following", "presentation", "begin", "simple", "inductive", "problem", "move", "complicated", "realistic", "setting", "11", "simple", "universal", "generalization", "let", "revisit", "classic", "question", "whether", "raven", "black", "imagine", "ornithologist", "tackle", "problem", "examining", "one", "raven", "another", "exactly", "one", "observation", "sequence", "black", "raven", "found", "others", "feature", "least", "one", "nonblack", "raven", "figure", "illustrates", "possible", "observation", "sequence", "dot", "figure", "denote", "point", "observation", "may", "made", "black", "bird", "left", "dot", "indicates", "stage", "black", "raven", "observed", "similarly", "white", "bird", "right", "dot", "indicates", "nonblack", "raven", "observed", "given", "complete", "sequence", "observation", "either", "observed", "raven", "black", "nonblack", "figure", "label", "complete", "observation", "sequence", "statement", "true", "gray", "fan", "indicates", "observation", "white", "raven", "claim", "raven", "black", "hold", "observation", "sequence", "resulting", "observation", "figure", "1", "extended", "description", "figure", "1", "supplement", "world", "black", "raven", "found", "would", "like", "ornithologist", "settle", "generalization", "may", "possible", "nonblack", "raven", "remain", "forever", "hidden", "sight", "even", "generalization", "raven", "black", "least", "get", "observation", "right", "world", "eventually", "nonblack", "raven", "found", "would", "like", "ornithologist", "arrive", "conclusion", "raven", "black", "specifies", "set", "goal", "inquiry", "given", "inductive", "method", "might", "represent", "ornithologist", "disposition", "adopt", "conjecture", "light", "evidence", "ask", "whether", "method", "measure", "goal", "infinitely", "many", "possible", "method", "consider", "look", "two", "skeptical", "one", "one", "boldly", "generalizes", "bold", "method", "conjecture", "raven", "black", "seeing", "first", "raven", "black", "hang", "conjecture", "unless", "nonblack", "raven", "appears", "skeptical", "method", "go", "beyond", "entailed", "evidence", "nonblack", "raven", "found", "skeptical", "method", "concludes", "raven", "black", "otherwise", "method", "make", "conjecture", "one", "way", "another", "figure", "illustrates", "bold", "skeptical", "method", "figure", "2", "extended", "description", "figure", "2", "supplement", "method", "attain", "goal", "set", "consider", "bold", "method", "two", "possibility", "either", "observed", "raven", "black", "nonblack", "raven", "found", "first", "case", "method", "conjecture", "raven", "black", "never", "abandon", "conjecture", "second", "case", "method", "concludes", "raven", "black", "soon", "first", "nonblack", "raven", "found", "hence", "matter", "evidence", "come", "eventually", "method", "give", "right", "answer", "whether", "raven", "black", "stick", "answer", "learning", "theorist", "call", "method", "reliable", "settle", "right", "answer", "matter", "observation", "world", "provides", "skeptical", "method", "measure", "well", "nonblack", "raven", "appears", "method", "arrive", "correct", "conclusion", "raven", "black", "raven", "black", "skeptic", "never", "take", "inductive", "leap", "adopt", "generalization", "case", "skeptic", "fails", "provide", "right", "answer", "question", "whether", "raven", "black", "illustrates", "meansends", "analysis", "evaluate", "method", "bold", "method", "meet", "goal", "reliably", "arriving", "right", "answer", "whereas", "skeptical", "method", "note", "character", "argument", "skeptic", "problem", "view", "skeptic", "violates", "canon", "rationality", "fails", "appreciate", "uniformity", "nature", "learningtheoretic", "analysis", "concedes", "skeptic", "matter", "many", "black", "raven", "observed", "past", "next", "one", "could", "white", "issue", "observed", "raven", "indeed", "black", "skeptic", "never", "answer", "question", "raven", "black", "getting", "right", "answer", "question", "requires", "generalizing", "evidence", "even", "though", "generalization", "could", "wrong", "bold", "method", "important", "clear", "achieve", "method", "eventually", "settle", "right", "answerbut", "may", "never", "certain", "done", "william", "james", "put", "bell", "toll", "science", "found", "right", "answer", "certain", "method", "eventually", "settle", "right", "answer", "may", "never", "certain", "current", "answer", "right", "one", "subtle", "point", "next", "example", "illustrates", "12", "new", "riddle", "induction", "nelson", "goodman", "posed", "famous", "puzzle", "inductive", "inference", "known", "new", "riddle", "induction", "goodman", "1983", "next", "example", "inspired", "puzzle", "goodman", "considered", "generalization", "emerald", "involving", "familiar", "colour", "green", "blue", "well", "certain", "unusual", "one", "suppose", "emerald", "examined", "certain", "time", "t", "green", "evidence", "statement", "assert", "emerald", "a", "green", "emerald", "b", "green", "on", "let", "u", "introduce", "another", "predicate", "le", "familiar", "green", "predicate", "grue", "applies", "thing", "examined", "t", "case", "green", "thing", "case", "blue", "time", "t", "evidence", "statement", "asserting", "given", "emerald", "green", "parallel", "evidence", "statement", "asserting", "emerald", "grue", "question", "whether", "conjecture", "emerald", "green", "rather", "emerald", "grue", "obtain", "sample", "green", "emerald", "examined", "time", "t", "clearly", "family", "grue", "predicate", "problem", "one", "different", "critical", "time", "t", "let", "write", "grue", "denote", "grue", "predicate", "following", "goodman", "let", "u", "refer", "method", "projection", "rule", "discussing", "example", "projection", "rule", "succeeds", "world", "case", "settle", "generalization", "correct", "world", "thus", "world", "examined", "emerald", "found", "green", "want", "projection", "rule", "converge", "proposition", "emerald", "green", "examined", "emerald", "grue", "want", "projection", "rule", "converge", "proposition", "emerald", "grue", "note", "stipulation", "treat", "green", "grue", "predicate", "completely", "par", "bias", "towards", "either", "let", "u", "consider", "two", "rule", "natural", "projection", "rule", "conjecture", "emerald", "green", "long", "green", "emerald", "found", "gruesome", "rule", "keep", "projecting", "next", "grue", "predicate", "consistent", "available", "evidence", "expressed", "greenblue", "vocabulary", "gruesome", "projection", "rule", "conjecture", "observing", "number", "n", "green", "emerald", "future", "one", "blue", "figure", "illustrates", "possible", "observation", "sequence", "natural", "projection", "rule", "gruesome", "projection", "rule", "figure", "3", "extended", "description", "figure", "3", "supplement", "following", "figure", "show", "gruesome", "projection", "rule", "figure", "4", "extended", "description", "figure", "4", "supplement", "rule", "measure", "goal", "arriving", "true", "generalization", "suppose", "sake", "example", "serious", "possibility", "consideration", "1", "either", "emerald", "green", "2", "emerald", "grue", "critical", "time", "t", "natural", "projection", "rule", "settle", "correct", "generalization", "matter", "correct", "generalization", "emerald", "green", "natural", "projection", "rule", "asserts", "fact", "beginning", "suppose", "emerald", "grue", "critical", "time", "t", "time", "t", "blue", "emerald", "observed", "point", "natural", "projection", "rule", "settle", "conjecture", "emerald", "grue", "must", "correct", "given", "assumption", "possible", "observation", "sequence", "thus", "matter", "evidence", "obtained", "course", "inquiryconsistent", "background", "assumptionsthe", "natural", "projection", "rule", "eventually", "settle", "correct", "generalization", "colour", "emerald", "gruesome", "rule", "well", "emerald", "green", "rule", "never", "conjecture", "fact", "keep", "projecting", "grue", "predicate", "hence", "possible", "observation", "sequencenamely", "emerald", "greenon", "gruesome", "rule", "fails", "converge", "right", "generalization", "meansends", "analysis", "would", "recommend", "natural", "projection", "rule", "gruesome", "rule", "13", "discussion", "meansends", "analysis", "riddle", "induction", "illustrates", "number", "philosophically", "important", "point", "hold", "learningtheoretic", "analysis", "general", "equal", "treatment", "hypothesis", "previous", "example", "nothing", "argument", "hinge", "argument", "effect", "certain", "possibility", "taken", "seriously", "priori", "particular", "nothing", "argument", "say", "generalization", "grue", "predicate", "illformed", "unlawlike", "way", "priori", "inferior", "emerald", "green", "language", "invariance", "analysis", "depend", "vocabulary", "evidence", "generalization", "framed", "ease", "exposition", "mostly", "used", "greenblue", "reference", "frame", "however", "gruebleen", "speaker", "would", "agree", "aim", "reliably", "settling", "correct", "generalization", "requires", "natural", "projection", "rule", "rather", "gruesome", "one", "even", "would", "want", "express", "conjecture", "natural", "rule", "gruebleen", "language", "rather", "bluegreen", "language", "used", "far", "dependence", "context", "though", "analysis", "depend", "language", "depend", "assumption", "possible", "observation", "sequence", "example", "described", "seems", "comprise", "possibility", "correspond", "colour", "predicate", "goodman", "discussed", "meansends", "analysis", "applies", "much", "set", "possible", "predicate", "schulte", "1999", "chart", "2000", "discus", "number", "version", "riddle", "induction", "meansends", "analysis", "favour", "projecting", "emerald", "grue", "sample", "green", "emerald", "14", "falsificationism", "generalization", "exception", "first", "two", "example", "feature", "simple", "universal", "generalization", "subtle", "aspect", "concept", "longrun", "reliability", "particularly", "relationship", "falsificationism", "become", "apparent", "consider", "generalization", "allow", "exception", "illustrate", "let", "u", "consider", "another", "ornithological", "example", "two", "competing", "hypothesis", "investigation", "finitely", "many", "swan", "white", "basically", "swan", "white", "except", "finite", "number", "exception", "rule", "finitely", "many", "swan", "black", "basically", "swan", "black", "except", "finite", "number", "exception", "rule", "assuming", "one", "hypothesis", "correct", "inductive", "method", "reliably", "settle", "right", "one", "make", "problem", "difficult", "first", "two", "hypothesis", "investigation", "consistent", "finite", "amount", "evidence", "100", "white", "swan", "50", "black", "swan", "found", "either", "50", "black", "swan", "100", "white", "swan", "may", "exception", "rule", "terminology", "made", "familiar", "karl", "popper", "work", "may", "say", "neither", "hypothesis", "falsifiable", "consequence", "inductive", "strategy", "previous", "two", "example", "work", "strategy", "basically", "adopt", "bold", "universal", "generalization", "raven", "black", "emerald", "green", "hang", "conjecture", "long", "pass", "muster", "however", "rule", "possible", "exception", "investigation", "strategy", "unreliable", "example", "suppose", "inquirer", "first", "adopts", "hypothesis", "finitely", "many", "swan", "white", "may", "case", "black", "swan", "found", "apparent", "counterinstances", "explained", "away", "exception", "inquirer", "follows", "principle", "hanging", "conjecture", "evidence", "logically", "inconsistent", "conjecture", "never", "abandon", "false", "belief", "finitely", "many", "swan", "white", "much", "le", "arrive", "correct", "belief", "finitely", "many", "swan", "black", "reliable", "inquiry", "requires", "subtle", "investigative", "strategy", "one", "many", "begin", "inquiry", "either", "competing", "hypothesis", "say", "finitely", "many", "swan", "black", "choose", "cutoff", "ratio", "represent", "clear", "majority", "definiteness", "let", "say", "70", "current", "conjecture", "finitely", "many", "swan", "black", "change", "mind", "conjecture", "finitely", "many", "swan", "white", "case", "70", "observed", "swan", "fact", "white", "proceed", "likewise", "current", "conjecture", "finitely", "many", "swan", "white", "70", "observed", "swan", "fact", "black", "bit", "thought", "show", "rule", "reliably", "identifies", "correct", "hypothesis", "long", "run", "matter", "two", "competing", "hypothesis", "correct", "finitely", "many", "swan", "black", "eventually", "nonblack", "exception", "rule", "exhausted", "arbitrarily", "large", "majority", "observed", "swan", "black", "similarly", "finitely", "many", "swan", "white", "generalization", "exception", "illustrate", "relationship", "popperian", "falsificationism", "learningtheoretic", "idea", "reliable", "convergence", "truth", "setting", "inquiry", "notably", "involving", "universal", "generalization", "naively", "popperian", "conjecturesandrefutations", "approach", "hanging", "conjecture", "evidence", "falsifies", "yield", "reliable", "inductive", "method", "problem", "like", "current", "example", "relying", "falsification", "sometimes", "always", "best", "way", "inquiry", "proceed", "learning", "theory", "provided", "mathematical", "theorem", "clarify", "relationship", "conjecturesandrefutations", "approach", "reliable", "inquiry", "detail", "discussed", "section", "3", "limit", "inquiry", "complexity", "empirical", "problem", "generally", "speaking", "method", "solve", "learning", "problem", "unfalsifiable", "hypothesis", "represented", "employing", "refined", "hypothesis", "space", "original", "hypothesis", "replaced", "strengthened", "hypothesis", "falsifiable", "2", "case", "study", "scientific", "practice", "section", "provides", "example", "illustrate", "learningtheoretic", "analysis", "example", "section", "realistic", "address", "methodological", "issue", "arising", "scientific", "practice", "probabilistic", "statistical", "hypothesis", "discussed", "section", "6", "entry", "provides", "outline", "full", "analysis", "reference", "detailed", "discussion", "case", "study", "may", "found", "kelly", "1996", "ch", "77", "harrell", "2000", "reader", "wish", "proceed", "development", "theory", "philosophy", "meansends", "epistemology", "skip", "section", "without", "loss", "continuity", "21", "conservation", "law", "particle", "physic", "one", "hallmark", "elementary", "particle", "physic", "discovery", "new", "conservation", "law", "apply", "subatomic", "realm", "ford", "1963", "ne", "eman", "kirsh", "1983", "feynman", "1965", "feynman", "group", "one", "conservation", "baryon", "number", "great", "conservation", "law", "energy", "charge", "momentum", "simplifying", "somewhat", "conservation", "principle", "serve", "explain", "certain", "process", "involving", "elementary", "particle", "occur", "explanation", "conservation", "principle", "violated", "cf", "omnes", "1971", "ch2", "ford", "1963", "goal", "particle", "inquiry", "find", "set", "conservation", "principle", "every", "process", "possible", "according", "already", "known", "law", "physic", "fails", "observed", "experimentally", "conservation", "principle", "rule", "process", "process", "fact", "observed", "occur", "ought", "satisfy", "conservation", "law", "introduced", "constitutes", "inference", "problem", "may", "apply", "meansends", "analysis", "inference", "method", "produce", "set", "conservation", "principle", "response", "report", "observed", "process", "meansends", "analysis", "asks", "method", "guaranteed", "settle", "conservation", "principle", "account", "observation", "rule", "unobserved", "process", "allow", "observed", "process", "schulte", "2008", "describes", "inductive", "method", "accomplishes", "goal", "informally", "method", "may", "described", "follows", "suppose", "observed", "set", "reaction", "among", "elementary", "particle", "conjecture", "set", "conservation", "law", "permit", "observed", "reaction", "rule", "many", "unobserved", "reaction", "possible", "logic", "conservation", "law", "observation", "reaction", "entail", "possibility", "unobserved", "one", "learningtheoretic", "method", "rule", "reaction", "entailed", "turn", "conservation", "principle", "method", "would", "posit", "currently", "available", "evidence", "empirically", "equivalent", "one", "physicist", "introduced", "specifically", "prediction", "agree", "exactly", "conservation", "charge", "baryon", "number", "muon", "number", "tau", "number", "lepton", "number", "part", "standard", "model", "particle", "physic", "physical", "process", "way", "get", "empirically", "adequate", "conservation", "principle", "positing", "hidden", "particle", "gone", "undetected", "schulte", "2009", "extends", "analysis", "inductive", "method", "may", "introduce", "conservation", "law", "also", "posit", "unseen", "particle", "basic", "principle", "posit", "unseen", "particle", "way", "rule", "many", "unobserved", "reaction", "possible", "method", "applied", "known", "particle", "data", "rediscovers", "existence", "electron", "antineutrino", "one", "particle", "key", "concern", "current", "particle", "physic", "22", "causal", "connection", "substantive", "body", "research", "learning", "causal", "relationship", "represented", "causal", "graph", "spirtes", "et", "al", "2000", "kelly", "suggested", "learningtheoretic", "analysis", "inferring", "causality", "evidence", "provided", "form", "observed", "significant", "correlation", "among", "variable", "interest", "modern", "version", "hume", "constant", "conjunction", "following", "inductive", "method", "guaranteed", "converge", "empirically", "adequate", "causal", "graph", "correlation", "observed", "schulte", "luo", "greiner", "2007", "suppose", "observed", "set", "correlation", "association", "among", "set", "variable", "interest", "select", "causal", "graph", "explains", "observed", "correlation", "minimum", "number", "direct", "causal", "link", "23", "model", "cognitive", "architecture", "philosopher", "mind", "argued", "mind", "composed", "fairly", "independent", "module", "module", "input", "module", "sends", "output", "module", "example", "auditory", "analysis", "system", "module", "might", "take", "input", "heard", "word", "send", "phonetic", "analysis", "auditory", "input", "lexicon", "idea", "modular", "organization", "raise", "empirical", "question", "mental", "module", "linked", "prominent", "tradition", "research", "cognitive", "neuroscience", "attempted", "develop", "model", "mental", "architecture", "along", "line", "studying", "response", "normal", "abnormal", "subject", "various", "stimulus", "idea", "compare", "normal", "reaction", "abnormal", "onesoften", "caused", "brain", "damageso", "draw", "inference", "mental", "capacity", "depend", "glymour", "1994", "asked", "reliabilist", "question", "whether", "inference", "method", "guaranteed", "eventually", "settle", "true", "theory", "mental", "organization", "given", "exhaustive", "evidence", "normal", "abnormal", "capacity", "reaction", "argued", "possible", "mental", "architecture", "amount", "evidence", "stimulusresponse", "kind", "distinguish", "since", "available", "evidence", "determines", "conjecture", "inductive", "method", "follows", "guarantee", "method", "settle", "true", "model", "cognitive", "architecture", "glymour", "also", "explored", "extent", "richer", "kind", "evidence", "would", "resolve", "underdetermination", "mental", "architecture", "one", "example", "richer", "evidence", "double", "disassocations", "example", "double", "dissocation", "would", "pair", "patient", "one", "normal", "capacity", "understanding", "spoken", "word", "fails", "understand", "written", "one", "another", "understands", "written", "word", "spoken", "one", "discussion", "bub", "1994", "showed", "grant", "certain", "restrictive", "assumption", "mental", "module", "connected", "complete", "set", "behavioural", "observation", "would", "allow", "neuropsychologist", "ascertain", "module", "structure", "normal", "mind", "fact", "bub", "assumption", "reliable", "method", "identifying", "modular", "structure", "highlevel", "idea", "procedure", "follows", "every", "hypothesized", "modular", "structure", "identified", "graph", "g", "containing", "edge", "module", "m_1", "rightarrow", "m_2", "module", "m_1", "call", "module", "m_2", "module", "graph", "g", "consistent", "set", "possible", "path", "among", "module", "say", "graph", "g", "constrained", "another", "graph", "g", "path", "defined", "g", "subset", "constrained", "g", "conjecture", "module", "graph", "g", "maximally", "constrained", "graph", "g", "constrained", "g", "24", "discussion", "study", "illustrate", "general", "feature", "learning", "theory", "generality", "basic", "notion", "theory", "general", "essentially", "theory", "applies", "whenever", "one", "question", "prompt", "inquiry", "number", "candidate", "answer", "evidence", "deciding", "among", "answer", "thus", "meansends", "analysis", "applied", "discipline", "aimed", "empirical", "knowledge", "example", "physic", "psychology", "context", "dependence", "learning", "theory", "pure", "normative", "priori", "epistemology", "sense", "deal", "standard", "assessing", "method", "possible", "setting", "inquiry", "approach", "aim", "universal", "contextfree", "methodological", "maxim", "methodological", "recommendation", "depend", "contingent", "factor", "operative", "methodological", "norm", "question", "investigation", "background", "assumption", "agent", "brings", "inquiry", "observational", "mean", "disposal", "cognitive", "capacity", "epistemic", "aim", "consequence", "evaluate", "specific", "method", "given", "domain", "case", "study", "mentioned", "one", "study", "detail", "case", "question", "meansends", "analysis", "often", "reward", "study", "pointing", "crucial", "methodological", "feature", "given", "scientific", "enterprise", "explaining", "precisely", "feature", "connected", "success", "enterprise", "attaining", "epistemic", "aim", "tradeoff", "perspective", "meansends", "epistemology", "inquiry", "involves", "ongoing", "struggle", "hard", "choice", "rather", "execution", "universal", "scientific", "method", "inquirer", "balance", "conflicting", "value", "may", "consider", "various", "strategy", "accepting", "difficulty", "short", "run", "hoping", "resolve", "long", "run", "example", "conservation", "law", "problem", "conflict", "theoretical", "parsimony", "ie", "positing", "fewer", "conservation", "law", "ontological", "parsimony", "ie", "introducing", "fewer", "hidden", "particle", "another", "example", "particle", "theorist", "may", "accept", "positing", "undetected", "particle", "hope", "eventually", "observed", "science", "progress", "search", "higgs", "boson", "illustrates", "strategy", "important", "learningtheoretic", "project", "examine", "tradeoff", "arise", "option", "resolving", "section", "4", "extends", "learningtheoretic", "analysis", "consider", "goal", "addition", "longrun", "reliability", "3", "limit", "inquiry", "complexity", "empirical", "problem", "seeing", "number", "example", "like", "one", "described", "one", "begin", "wonder", "pattern", "empirical", "question", "allows", "inquiry", "reliably", "arrive", "correct", "answer", "general", "insight", "gain", "reliable", "method", "go", "testing", "hypothesis", "learning", "theorist", "answer", "question", "characterization", "theorem", "characterization", "theorem", "generally", "form", "possible", "attain", "standard", "empirical", "success", "given", "inductive", "problem", "inductive", "problem", "meet", "following", "condition", "first", "cover", "case", "inquiry", "provide", "certainty", "whether", "empirical", "hypothesis", "correct", "relative", "background", "knowledge", "consider", "inquiry", "converge", "correct", "hypothesis", "without", "ever", "arriving", "certain", "conclusion", "described", "section", "1", "introduce", "enough", "definition", "formal", "concept", "state", "result", "precisely", "supplementary", "document", "provides", "full", "formalization", "learning", "problem", "defined", "finite", "countably", "infinite", "set", "possible", "hypothesis", "mathbf", "h", "h_1", "h_2", "ldots", "h_n", "ldots", "hypothesis", "mutually", "exclusive", "jointly", "cover", "possibility", "consistent", "inquirer", "background", "assumption", "example", "raven", "color", "problem", "section", "11", "two", "hypothesis", "h_1", "observed", "raven", "black", "h_2", "observed", "raven", "black", "new", "riddle", "induction", "section", "12", "infinitely", "many", "alternative", "hypothesis", "h_", "green", "observed", "emerald", "green", "countably", "many", "alternative", "form", "h_t", "observed", "emerald", "grue", "t", "natural", "number", "section", "defines", "property", "hypothesis", "determine", "sense", "inquiry", "observation", "indicate", "whether", "correct", "property", "absolute", "relative", "set", "alternative", "mathbf", "h", "one", "may", "obtain", "inquirer", "know", "basic", "relative", "property", "relative", "entailment", "hypothesis", "h", "consistent", "finite", "number", "observation", "h", "correct", "complete", "data", "sequence", "extends", "finite", "observation", "finite", "number", "observation", "falsifies", "hypothesis", "h", "h", "inconsistent", "observation", "finite", "number", "observation", "entail", "hypothesis", "h", "relative", "hypothesis", "set", "mathbf", "h", "h", "hypothesis", "mathbf", "h", "consistent", "observation", "note", "since", "logical", "entailment", "depend", "language", "use", "frame", "evidence", "hypothesis", "concept", "consistency", "entailment", "falsification", "depend", "language", "use", "frame", "evidence", "hypothesis", "example", "recall", "raven", "scenario", "section", "11", "diagram", "repeated", "convenience", "figure", "1", "extended", "description", "figure", "1", "supplement", "observation", "first", "raven", "black", "consistent", "hypothesis", "h_1", "observed", "raven", "black", "h_2", "observed", "raven", "black", "observation", "first", "raven", "raven", "white", "falsifies", "hypothesis", "h_1", "entail", "hypothesis", "h_2", "entailment", "illustrated", "gray", "fan", "structure", "mean", "observation", "white", "raven", "hypothesis", "h_1", "correct", "extending", "complete", "data", "sequence", "record", "color", "observed", "raven", "31", "verifiable", "refutable", "hypothesis", "next", "set", "concept", "need", "understand", "structure", "hypothesis", "settled", "reliable", "inquiry", "notion", "verifiable", "falsifiable", "hypothesis", "verifiability", "falsifiability", "claim", "extensively", "discussed", "epistemology", "philosophy", "science", "especially", "philosopher", "concerned", "issue", "logical", "empiricism", "subsection", "describes", "concept", "used", "learning", "theory", "compare", "learningtheoretic", "concept", "discussion", "broader", "epistemology", "hypothesis", "h", "verifiable", "whenever", "h", "correct", "eventually", "evidence", "observed", "entail", "h", "correct", "formally", "h", "verifiable", "respect", "hypothesis", "set", "mathbf", "h", "every", "complete", "data", "sequence", "h", "correct", "finite", "number", "observation", "falsify", "alternative", "hypothesis", "h", "mathbf", "h", "hypothesis", "h", "refutable", "whenever", "h", "eventually", "evidence", "observed", "falsifies", "h", "formally", "h", "refutable", "respect", "hypothesis", "set", "mathbf", "h", "every", "complete", "data", "sequence", "h", "correct", "hypothesis", "mathbf", "h", "finite", "number", "observation", "falsifies", "h", "example", "hypothesis", "h_2", "observed", "raven", "black", "verifiable", "refutable", "verifiable", "data", "sequence", "correct", "feature", "nonblack", "raven", "finite", "time", "observation", "nonblack", "raven", "entail", "h_2", "hypothesis", "h_2", "falsifiable", "black", "raven", "observed", "forever", "h_2", "incorrect", "finite", "number", "observation", "falsifies", "h_2", "hypothesis", "h_1", "observed", "raven", "black", "refutable", "verifiable", "refutable", "data", "sequence", "correct", "feature", "nonblack", "raven", "finite", "time", "observation", "nonblack", "raven", "falsifies", "h_1", "h_1", "verifiable", "black", "raven", "observed", "forever", "h_1", "correct", "finite", "number", "observation", "entail", "h_1", "new", "riddle", "induction", "section", "12", "diagram", "repeated", "convenience", "hypothesis", "observed", "emerald", "green", "falsifiable", "verifiable", "reason", "observed", "raven", "black", "refutable", "verifiable", "grue", "hypothesis", "h_t", "observed", "emerald", "grue", "verifiable", "refutable", "h_t", "refutable", "complete", "data", "sequence", "gruesome", "generalization", "incorrect", "feature", "counterexample", "falsifies", "h_t", "verifiable", "correct", "first", "observation", "blue", "emerald", "time", "t", "falsifies", "hypothesis", "observed", "emerald", "green", "also", "falsifies", "h_t", "hypothesis", "example", "gruesome", "hypothesis", "show", "empirical", "hypothesis", "verifiable", "refutable", "sometimes", "called", "decidable", "analogy", "computation", "theory", "typical", "example", "decidable", "empirical", "claim", "singular", "observation", "first", "raven", "black", "boolean", "combination", "singular", "observation", "figure", "4", "extended", "description", "figure", "4", "supplement", "briefly", "discus", "similarity", "difference", "related", "concept", "epistemology", "philosophy", "science", "verificationism", "part", "philosophy", "logical", "empiricism", "core", "idea", "claim", "meaningful", "must", "empirically", "verifiable", "main", "difference", "concept", "philosophical", "objective", "goal", "learning", "theory", "separate", "meaningful", "meaningless", "claim", "characterize", "standard", "empirical", "success", "expect", "inquiry", "given", "set", "hypothesis", "hypothesis", "verifiable", "according", "definition", "allows", "inquiry", "provide", "positive", "test", "hypothesis", "correct", "inquiry", "eventually", "indicate", "correctness", "certainty", "given", "background", "knowledge", "specific", "definition", "verifiability", "offered", "logical", "empiricist", "equivalent", "verifiability", "learningtheoretic", "sense", "example", "strict", "verificationism", "hold", "order", "meaningful", "claim", "must", "implied", "finite", "number", "observation", "sentences", "finite", "number", "observation", "sentence", "equivalent", "hypothesis", "h_2", "observed", "raven", "black", "hypothesis", "equivalent", "infinite", "disjunction", "observation", "sentence", "ie", "nonblack", "raven", "time", "1", "nonblack", "raven", "time", "2", "falsificationism", "wellknown", "view", "philosophy", "science", "core", "idea", "hypothesis", "scientific", "rather", "pseudoscientific", "metaphysical", "must", "falsifiable", "following", "sense", "statement", "order", "ranked", "scientific", "must", "capable", "conflicting", "possible", "conceivable", "observation", "popper", "1962", "39", "main", "difference", "development", "philosophical", "objective", "goal", "learning", "theory", "demarcate", "scientific", "hypothesis", "pseudoscientific", "theory", "characterize", "standard", "empirical", "success", "expect", "inquiry", "given", "set", "hypothesis", "hypothesis", "refutable", "according", "definition", "allows", "inquiry", "provide", "negative", "test", "hypothesis", "incorrect", "inquiry", "eventually", "indicate", "incorrectness", "certainty", "given", "background", "knowledge", "specific", "definition", "falsifiability", "popper", "quote", "equivalent", "refutability", "learningtheoretic", "sense", "schulte", "juhl", "1996", "example", "hypothesis", "h", "first", "raven", "black", "raven", "nonblack", "conflict", "possible", "observation", "first", "raven", "white", "however", "fact", "observed", "raven", "black", "h", "incorrect", "falsified", "finite", "number", "observation", "hence", "refutable", "according", "learningtheoretic", "definition", "discussion", "relationship", "popperian", "falsification", "learning", "theory", "see", "genin", "2018", "32", "pointset", "topology", "axiom", "verifiability", "elucidate", "learningtheoretic", "concept", "verifiability", "refutability", "note", "satisfy", "following", "fundamental", "property", "give", "informal", "rigorous", "proof", "disjunction", "verifiable", "hypothesis", "also", "verifiable", "proof", "let", "h", "h_1", "h_2", "ldots", "h_n", "disjunction", "verifiable", "hypothesis", "h_i", "disjunction", "may", "infinite", "suppose", "h", "correct", "complete", "data", "sequence", "h_i", "correct", "data", "sequence", "since", "h_i", "verifiable", "finite", "number", "observation", "entail", "h_i", "entail", "h", "h", "correct", "complete", "data", "sequence", "finite", "number", "observation", "sequence", "entail", "h", "required", "verifiability", "example", "let", "h_i", "verifiable", "hypothesis", "nonblack", "raven", "time", "i", "hypothesis", "h", "observed", "raven", "black", "equivalent", "disjunction", "h_1", "h_2", "ldots", "h_n", "since", "hypothesis", "h_i", "verifiable", "h", "finite", "conjunction", "verifiable", "hypothesis", "also", "verifiable", "proof", "let", "h", "h_1", "h_2", "ldots", "h_n", "finite", "conjunction", "verifiable", "hypothesis", "h_i", "suppose", "h", "correct", "complete", "data", "sequence", "h_i", "correct", "data", "sequence", "since", "h_i", "verifiable", "finite", "number", "observation", "entail", "h_i", "finite", "many", "hypothesis", "h_i", "eventually", "hypothesis", "verified", "finite", "number", "observation", "entail", "conjunction", "h", "h", "correct", "complete", "data", "sequence", "finite", "number", "observation", "sequence", "entail", "h", "required", "verifiability", "example", "let", "h_1", "verifiable", "hypothesis", "first", "raven", "nonblack", "let", "h_2", "verifiable", "hypothesis", "second", "raven", "nonblack", "conjunction", "h", "h_1", "h_2", "correct", "data", "sequence", "first", "two", "raven", "black", "observation", "first", "two", "raven", "therefore", "entail", "h", "tautology", "contradiction", "trivially", "verifiable", "proof", "tautology", "like", "first", "observed", "raven", "black", "black", "correct", "data", "sequence", "entailed", "evidence", "sequence", "contradiction", "like", "first", "observed", "raven", "black", "black", "trivially", "verified", "correct", "never", "correct", "hypothesis", "verifiable", "negation", "refutable", "proof", "consider", "onlyif", "direction", "converse", "similar", "suppose", "negation", "h", "hypothesis", "refutable", "consider", "complete", "data", "sequence", "hypothesis", "h", "correct", "h", "incorrect", "falsified", "finite", "number", "observation", "since", "refutable", "finite", "observation", "set", "entail", "h", "h", "correct", "complete", "data", "sequence", "finite", "number", "observation", "sequence", "entail", "h", "required", "verifiability", "example", "h", "observed", "raven", "black", "negation", "refutable", "hypothesis", "h", "observed", "raven", "black", "h", "incorrect", "complete", "data", "sequence", "eventually", "falsified", "observation", "nonblack", "raven", "observation", "entail", "h", "remarkably", "property", "listed", "exactly", "fundamental", "axiom", "important", "branch", "mathematics", "known", "pointset", "topology", "abramsky", "1987", "vickers", "1986", "topological", "space", "defined", "collection", "set", "known", "open", "set", "neighbourhood", "satisfy", "axiomatic", "property", "verifiable", "hypothesis", "closure", "arbitrary", "union", "finite", "disjunction", "empty", "set", "entire", "space", "open", "settheoretic", "complement", "open", "set", "called", "closed", "set", "refutable", "hypothesis", "correspond", "exactly", "closed", "set", "pointset", "topology", "invented", "support", "kind", "generalized", "functional", "analysis", "without", "number", "precisely", "without", "distance", "striking", "foundational", "axiom", "topology", "exact", "epistemological", "interpretation", "term", "property", "empirical", "hypothesis", "allow", "verification", "falsification", "certainty", "current", "mathematical", "development", "learning", "theory", "often", "begin", "taking", "basic", "concept", "set", "verifiable", "hypothesis", "satisfying", "property", "listed", "approach", "two", "advantage", "learning", "theory", "draw", "contribute", "rich", "body", "concept", "result", "one", "developed", "branch", "modern", "mathematics", "kelly", "1996", "baltag", "et", "al", "2015", "de", "brecht", "yamamoto", "2008", "flexibility", "adapt", "notion", "evidence", "item", "context", "application", "make", "easier", "apply", "general", "theory", "different", "domain", "example", "consider", "problem", "obtaining", "increasing", "precisely", "measurement", "quantity", "interest", "eg", "speed", "light", "physic", "take", "basic", "set", "verifiable", "hypothesis", "union", "open", "interval", "around", "true", "value", "quantity", "baltag", "et", "al", "2015", "monist", "genin", "kelly", "2017", "another", "example", "concept", "statistical", "verifiability", "covered", "section", "6", "sake", "concreteness", "entry", "describes", "example", "basic", "verifiable", "hypothesis", "disjunction", "finite", "sequence", "evidence", "item", "describe", "definition", "result", "way", "assume", "axiomatic", "property", "listed", "easy", "apply", "setting", "33", "identifiability", "limit", "inquiry", "fundamental", "result", "describes", "condition", "method", "reliably", "find", "correct", "hypothesis", "among", "countably", "infinite", "finite", "number", "mathbf", "h", "mutually", "exclusive", "hypothesis", "jointly", "cover", "possibility", "consistent", "inquirer", "background", "assumption", "learner", "mathbf", "h", "map", "finite", "sequence", "observation", "hypothesis", "mathbf", "h", "example", "new", "riddle", "induction", "natural", "projection", "learner", "hypothesis", "set", "mathbf", "h", "comprises", "emerald", "green", "h_1", "emerald", "grue", "1", "h_2", "emerald", "grue", "2", "etc", "critical", "time", "t", "learner", "reliably", "identifies", "simply", "identifies", "correct", "hypothesis", "mathbf", "h", "every", "complete", "data", "sequence", "following", "hold", "h", "mathbf", "h", "correct", "hypothesis", "data", "sequence", "finite", "number", "observation", "learner", "conjecture", "correct", "hypothesis", "h", "observation", "consistent", "data", "sequence", "generalizing", "method", "natural", "projection", "rule", "example", "reliable", "learner", "hypothesis", "set", "theorem", "learner", "reliably", "identifies", "correct", "hypothesis", "mathbf", "h", "hypothesis", "mathbf", "h", "finite", "countable", "disjunction", "refutable", "hypothesis", "proof", "see", "kelly", "1996", "ch", "33", "example", "illustration", "let", "return", "ornithological", "example", "two", "alternative", "hypothesis", "1", "finitely", "many", "swan", "white", "2", "finitely", "many", "swan", "black", "saw", "possible", "long", "run", "reliably", "settle", "two", "hypothesis", "correct", "hence", "characterization", "theorem", "two", "hypothesis", "must", "disjunction", "refutable", "empirical", "claim", "see", "indeed", "observe", "finitely", "many", "swan", "white", "logically", "equivalent", "disjunction", "1", "swan", "black", "2", "swan", "black", "n", "swan", "black", "similarly", "finitely", "many", "swan", "black", "claim", "disjunction", "refutable", "example", "take", "claim", "3", "swan", "black", "false", "3", "black", "swan", "found", "point", "claim", "conclusively", "falsified", "figure", "illustrates", "identifiable", "hypothesis", "structured", "disjunction", "refutable", "hypothesis", "figure", "5", "extended", "description", "figure", "5", "supplement", "characterization", "theorem", "implies", "think", "reliable", "method", "adopting", "internal", "strengthened", "version", "original", "hypothesis", "investigation", "refutable", "example", "show", "theorem", "imply", "strengthened", "hypothesis", "mutually", "exclusive", "eg", "3", "swan", "black", "consistent", "2", "swan", "black", "recent", "alternative", "characterization", "theorem", "due", "baltag", "gierasimczuk", "smets", "2015", "provides", "alternative", "structural", "analysis", "identifiable", "hypothesis", "decomposed", "mutually", "exclusive", "component", "follows", "hypothesis", "h", "verirefutable", "equivalent", "conjunction", "verifiable", "refutable", "hypothesis", "given", "background", "knowledge", "h", "v", "r", "v", "verifiable", "r", "refutable", "example", "hypothesis", "exactly", "2", "swan", "black", "verirefutable", "since", "equivalent", "conjunction", "verifiable", "hypothesis", "least", "2", "swan", "white", "refutable", "hypothesis", "2", "swan", "white", "term", "verirefutable", "due", "genin", "kelly", "2015", "signifies", "verirefutable", "hypothesis", "true", "initial", "condition", "hypothesis", "refutable", "hypothesis", "falsified", "data", "false", "baltag", "et", "al", "refer", "verirefutable", "hypothesis", "locally", "closed", "establish", "following", "characterization", "theorem", "reliable", "learning", "baltag", "et", "al", "2015", "theorem", "learner", "reliably", "identifies", "correct", "hypothesis", "mathbf", "h", "hypothesis", "mathbf", "h", "equivalent", "finite", "countable", "disjunction", "mutually", "exclusive", "verirefutable", "hypothesis", "since", "verirefutable", "hypothesis", "mutually", "exclusive", "constitute", "valid", "refined", "hypothesis", "space", "whose", "member", "entail", "exactly", "one", "original", "hypothesis", "characterization", "theorem", "entail", "without", "loss", "learning", "power", "inductive", "method", "transform", "original", "hypothesis", "space", "verirefutable", "one", "figure", "illustrates", "decomposition", "verirefutable", "hypothesis", "figure", "6", "extended", "description", "figure", "6", "supplement", "point", "help", "explain", "significance", "characterization", "theorem", "structure", "reliable", "method", "characterization", "theorem", "tell", "u", "structure", "reliable", "method", "attuned", "structure", "hypothesis", "investigation", "example", "theorem", "mentioned", "establishes", "connection", "falsifiability", "testability", "one", "attenuated", "na\u00efve", "popperian", "envisions", "necessary", "hypothesis", "test", "directly", "falsifiable", "rather", "must", "way", "strengthening", "hypothesis", "yield", "countable", "number", "refutable", "subhypotheses", "think", "refutable", "subhypotheses", "different", "way", "main", "hypothesis", "may", "true", "example", "one", "way", "finitely", "many", "swan", "white", "true", "10", "black", "swan", "another", "100", "black", "swan", "etc", "strengthening", "original", "hypothesis", "become", "empirically", "refutable", "match", "spirit", "lakatos", "methodology", "general", "scientific", "paradigm", "articulated", "auxiliary", "hypothesis", "define", "testable", "ie", "falsifiable", "claim", "import", "background", "assumption", "characterization", "result", "draw", "line", "solvable", "unsolvable", "problem", "background", "knowledge", "reduces", "inductive", "complexity", "problem", "enough", "background", "knowledge", "problem", "cross", "threshold", "unsolvable", "solvable", "many", "domain", "empirical", "inquiry", "pivotal", "background", "assumption", "make", "reliable", "inquiry", "feasible", "kuhn", "1970", "make", "related", "point", "importance", "background", "assumption", "embodied", "paradigm", "language", "invariance", "learningtheoretic", "characterization", "theorem", "concern", "kelly", "call", "temporal", "entanglement", "various", "observation", "sequence", "kelly", "2000", "ultimately", "rest", "entailment", "relation", "given", "evidence", "background", "assumption", "empirical", "claim", "since", "logical", "entailment", "depend", "language", "use", "frame", "evidence", "hypothesis", "inductive", "complexity", "empirical", "problem", "determined", "characterization", "theorem", "languageinvariant", "4", "long", "run", "short", "run", "reliable", "stable", "belief", "longstanding", "criticism", "convergence", "truth", "aim", "inquiry", "fine", "aim", "consistent", "crazy", "behaviour", "short", "run", "salmon", "1991", "example", "saw", "new", "riddle", "induction", "reliable", "projection", "rule", "conjecture", "next", "emerald", "blue", "matter", "many", "green", "emerald", "foundas", "long", "eventually", "rule", "project", "emerald", "green", "one", "response", "meansends", "analysis", "take", "account", "epistemic", "aim", "addition", "longrun", "convergence", "provide", "strong", "guidance", "conjecture", "short", "run", "illustrate", "point", "let", "u", "return", "goodmanian", "riddle", "induction", "ever", "since", "plato", "philosopher", "considered", "idea", "stable", "true", "belief", "better", "unstable", "true", "belief", "epistemologist", "sklar", "1975", "advocated", "similar", "principle", "epistemic", "conservatism", "kuhn", "tell", "u", "major", "reason", "conservatism", "paradigm", "debate", "cost", "changing", "scientific", "belief", "kuhn", "1970", "spirit", "learning", "theorist", "examined", "method", "minimize", "number", "time", "change", "theory", "settling", "final", "conjecture", "putnam", "1965", "kelly", "1996", "jain", "1999", "method", "said", "minimize", "mind", "change", "41", "example", "new", "riddle", "induction", "new", "riddle", "induction", "turn", "nice", "illustration", "idea", "consider", "natural", "projection", "rule", "conjecture", "emerald", "green", "sample", "green", "emerald", "emerald", "green", "rule", "never", "change", "conjecture", "emerald", "grue", "critical", "time", "t", "natural", "projection", "rule", "abandon", "conjecture", "emerald", "green", "time", "t", "one", "mind", "changeand", "thereafter", "correctly", "project", "emerald", "grue", "remarkably", "rule", "project", "grue", "rather", "green", "well", "example", "consider", "rule", "conjecture", "emerald", "grue", "3", "observing", "one", "green", "emerald", "two", "green", "emerald", "observed", "rule", "conjecture", "falsified", "must", "eventually", "change", "mind", "say", "conjecture", "emerald", "green", "supposing", "green", "emerald", "continue", "found", "point", "blue", "emerald", "may", "appear", "forcing", "second", "mind", "change", "argument", "generalized", "show", "aim", "minimizing", "mind", "change", "allows", "green", "predicate", "projected", "sample", "green", "emerald", "schulte", "1999", "saw", "section", "12", "natural", "projection", "rule", "change", "mind", "figure", "illustrates", "typical", "case", "unnatural", "projection", "rule", "may", "change", "mind", "twice", "figure", "7", "extended", "description", "figure", "7", "supplement", "42", "example", "reasoning", "applies", "question", "whether", "raven", "black", "bold", "generalizer", "conjecture", "raven", "black", "observing", "sample", "black", "raven", "succeeds", "one", "mind", "change", "indeed", "raven", "black", "generalizer", "never", "change", "mind", "nonblack", "raven", "refutation", "occasion", "one", "mind", "change", "afterwards", "question", "settled", "contrast", "contrary", "method", "asserts", "nonblack", "raven", "observing", "sample", "black", "one", "black", "raven", "continue", "observed", "contrary", "method", "eventually", "change", "mind", "assert", "raven", "black", "else", "fails", "arrive", "correct", "generalization", "point", "nonblack", "raven", "may", "appear", "forcing", "second", "mind", "change", "thus", "goal", "stable", "belief", "place", "strong", "constraint", "method", "may", "conjecture", "short", "run", "problem", "observing", "black", "raven", "option", "raven", "black", "opinion", "yet", "nonblack", "raven", "conservation", "law", "problem", "restrictive", "method", "described", "section", "21", "method", "minimizes", "mind", "change", "recall", "restrictive", "method", "adopts", "set", "conservation", "law", "rule", "many", "unobserved", "reaction", "possible", "shown", "n", "known", "elementary", "particle", "whose", "reaction", "observed", "method", "requires", "n", "mind", "change", "number", "elementary", "particle", "standard", "model", "around", "n", "200", "learning", "causal", "graph", "following", "variant", "method", "described", "section", "22", "minimizes", "number", "mind", "change", "suppose", "observed", "set", "correlation", "association", "among", "set", "variable", "interest", "unique", "causal", "graph", "explains", "observed", "correlation", "minimum", "number", "direct", "causal", "link", "select", "graph", "one", "causal", "graph", "explains", "observed", "correlation", "minimum", "number", "direct", "causal", "link", "output", "opinion", "yet", "conjecture", "disjunction", "minimum", "edge", "graph", "example", "illustrates", "sometimes", "minimizing", "mind", "change", "requires", "withholding", "belief", "intuitively", "occurs", "two", "equally", "simple", "explanation", "data", "inquirer", "wait", "observation", "decide", "possibility", "jumping", "one", "simple", "conclusion", "might", "lead", "unnecessary", "mind", "change", "case", "alternative", "equally", "simple", "explanation", "turn", "correct", "case", "tradeoff", "goal", "achieving", "stable", "belief", "one", "hand", "quickly", "settling", "true", "belief", "schulte", "1999", "discus", "connection", "simplicity", "stable", "belief", "next", "section", "simplicity", "43", "regressive", "mind", "change", "genin", "kelly", "2015", "refine", "mind", "change", "approach", "distinguishing", "different", "kind", "mind", "change", "abandoning", "true", "hypothesis", "favor", "false", "one", "undesirable", "regressive", "mind", "change", "abandoning", "false", "hypothesis", "favor", "true", "one", "desirable", "progressive", "mind", "change", "abandoning", "false", "hypothesis", "favor", "another", "false", "one", "table", "illustrates", "distinction", "new", "riddle", "induction", "raven", "example", "genin", "kelly", "investigate", "principle", "inductive", "method", "minimize", "number", "regressive", "mind", "change", "number", "time", "new", "evidence", "lead", "method", "abandon", "true", "hypothesis", "favor", "false", "one", "notion", "regressive", "mind", "change", "mark", "epistemic", "failure", "match", "long", "tradition", "epistemology", "defeasibility", "theory", "knowledge", "see", "link", "internet", "resource", "section", "hold", "order", "agent", "true", "belief", "count", "knowledge", "must", "indefeasible", "sense", "accepting", "proposition", "lead", "agent", "abanon", "belief", "translated", "language", "mind", "change", "mean", "inquirer", "true", "current", "conjecture", "count", "knowledge", "evidence", "would", "lead", "change", "mind", "adopt", "alternative", "false", "conjecture", "plato", "meno", "conveys", "point", "vividly", "illustration", "nature", "true", "opinion", "abide", "u", "beautiful", "fruitful", "run", "away", "human", "soul", "remain", "long", "therefore", "much", "value", "bound", "first", "place", "nature", "knowledge", "second", "place", "abiding", "true", "hypothesis", "emerald", "green", "nonblack", "raven", "conjecture", "0", "emerald", "grue", "1", "nonblack", "raven", "observation", "1", "green", "emerald", "black", "raven", "conjecture", "1", "emerald", "grue", "2", "falsetofalse", "raven", "black", "truetofalse", "observation", "2", "green", "emerald", "white", "raven", "conjecture", "2", "emerald", "green", "falsetotrue", "nonblack", "raven", "falsetotrue", "illustrating", "regressive", "progressive", "mind", "change", "minimizing", "regressive", "mind", "change", "even", "important", "epistemic", "goal", "avoiding", "mind", "change", "general", "lead", "weaker", "stricture", "inductive", "learning", "time", "stricture", "follow", "carry", "even", "normative", "force", "table", "illustrates", "difference", "two", "principle", "new", "riddle", "induction", "raven", "problem", "new", "riddle", "induction", "green", "emerald", "ever", "observed", "projection", "rule", "may", "keep", "projecting", "number", "gruesome", "predicate", "without", "producing", "regressive", "mind", "change", "simply", "abandon", "one", "false", "gruesome", "predicate", "another", "false", "gruesome", "predicate", "therefore", "even", "unnatural", "projection", "rule", "incur", "0", "regressive", "mind", "change", "provided", "never", "abandon", "green", "hypothesis", "adopted", "consequence", "minimizing", "regressive", "mind", "change", "different", "question", "whether", "raven", "black", "consider", "contrary", "method", "asserts", "nonblack", "raven", "observing", "sample", "black", "one", "shown", "table", "discussed", "contrary", "method", "eventually", "change", "hypothesis", "seeing", "black", "raven", "conjecture", "raven", "black", "upon", "observing", "white", "raven", "return", "true", "initial", "hypothesis", "nonblack", "raven", "thus", "contrary", "method", "undergoes", "least", "one", "regressive", "mind", "change", "worst", "case", "hand", "generalizing", "method", "asserts", "raven", "black", "observing", "sample", "black", "one", "change", "conjecture", "nonblack", "raven", "observed", "a", "progressive", "mind", "change", "false", "hypothesis", "true", "hypothesis", "therefore", "principle", "avoiding", "regressive", "mind", "change", "single", "generalizing", "method", "contrary", "one", "example", "illustrates", "regressive", "mind", "change", "associated", "cycle", "conjecture", "reliable", "method", "must", "eventually", "return", "true", "hypothesis", "adopting", "false", "one", "regressive", "mind", "change", "lead", "least", "one", "cycle", "true", "conjecturefalse", "conjecturetrue", "conjecture", "method", "avoid", "regressive", "mind", "change", "therefore", "studied", "heading", "cyclefree", "learning", "genin", "kelly", "2015", "minimizing", "uturn", "carlucci", "et", "al", "2005", "genin", "kelly", "2015", "2019", "provide", "general", "result", "elucidates", "general", "methodological", "import", "avoiding", "regressive", "mind", "change", "cycle", "conjecture", "described", "section", "54", "result", "belongs", "family", "theorem", "establish", "striking", "connection", "avoiding", "mind", "change", "ockham", "razor", "discus", "next", "section", "5", "simplicity", "stable", "belief", "ockham", "razor", "strong", "intuition", "inductive", "inference", "scientific", "method", "prefer", "simpler", "hypothesis", "complex", "one", "see", "entry", "simplicity", "statistician", "computer", "scientist", "researcher", "concerned", "learning", "observation", "made", "extensive", "use", "preference", "simplicity", "solve", "practical", "inductive", "problem", "domingo", "1999", "foundational", "point", "view", "simplicity", "problematic", "least", "two", "reason", "justification", "problem", "adopt", "simple", "hypothesis", "one", "obvious", "answer", "world", "simple", "therefore", "complex", "theory", "false", "however", "apriori", "claim", "world", "simple", "highly", "controversialsee", "entry", "simplicity", "learningtheoretic", "perspective", "dismissing", "complex", "hypothesis", "impairs", "reliability", "inductive", "method", "kelly", "metaphor", "fixed", "bias", "like", "stopped", "watch", "may", "happen", "use", "watch", "pointing", "right", "time", "watch", "reliable", "instrument", "telling", "time", "kelly", "2007a", "2010", "description", "problem", "epistemologist", "worried", "simplicity", "objective", "feature", "hypothesis", "rather", "depends", "mode", "presentation", "nozick", "put", "goodman", "riddle", "illustrates", "point", "generalization", "framed", "bluegreen", "term", "emerald", "green", "appears", "simpler", "emerald", "first", "green", "blue", "gruebleen", "language", "emerald", "grue", "appears", "simpler", "emerald", "first", "grue", "bleen", "learning", "theorist", "engaged", "recent", "ongoing", "effort", "apply", "meansends", "epistemology", "develop", "theory", "connection", "simplicity", "induction", "address", "concern", "kelly", "2010", "harmann", "kulkarni", "2007", "luo", "schulte", "2006", "steel", "2009", "turn", "fruitful", "perspective", "examine", "relationship", "structure", "hypothesis", "space", "mind", "change", "complexity", "corresponding", "inductive", "problem", "fundamental", "idea", "simplicity", "enjoy", "priori", "connection", "truth", "choosing", "simple", "hypothesis", "help", "inquirer", "find", "truth", "efficiently", "sense", "avoiding", "mind", "change", "kelly", "road", "metaphor", "illustrates", "idea", "consider", "two", "route", "destination", "one", "via", "straight", "highway", "via", "back", "road", "route", "eventually", "lead", "point", "back", "road", "entail", "twist", "turn", "kelly", "2007a", "2010", "formalization", "idea", "take", "form", "ockham", "theorem", "theorem", "show", "appropriate", "restriction", "inductive", "method", "find", "truth", "efficiently", "possible", "given", "problem", "method", "ockham", "method", "selects", "simplest", "hypothesis", "consistent", "data", "ockham", "theorem", "provides", "justification", "ockham", "inductive", "razor", "mean", "towards", "epistemic", "aim", "whether", "ockham", "theorem", "true", "depends", "description", "ockham", "method", "exact", "definition", "simplicity", "set", "hypothesis", "body", "mathematical", "result", "establish", "ockham", "theorem", "using", "languageinvariant", "simplicity", "measure", "explain", "next", "51", "defining", "simplicity", "say", "hypothesis", "h", "background", "set", "possible", "hypothesis", "mathbf", "h", "verifiable", "evidence", "sequence", "h", "hypothesis", "mathbf", "h", "consistent", "evidence", "sequence", "example", "black", "raven", "problem", "hypothesis", "nonblack", "raven", "verifiable", "since", "entailed", "observation", "nonblack", "raven", "hypothesis", "raven", "black", "verifiable", "since", "entailed", "finite", "evidence", "sequence", "following", "procedure", "assigns", "simplicity", "rank", "hypothesis", "h", "set", "hypothesis", "mathbf", "h", "apsitis", "1994", "luo", "schulte", "2006", "assign", "verifiable", "hypothesis", "simplicity", "rank", "0", "remove", "verifiable", "hypothesis", "hypothesis", "space", "form", "new", "hypothesis", "space", "mathbf", "h", "_1", "assign", "simplicity", "rank", "1", "hypothesis", "verifiable", "given", "mathbf", "h", "_1", "remove", "newly", "verifiable", "hypothesis", "simplicity", "rank", "1", "hypothesis", "space", "form", "new", "hypothesis", "space", "mathbf", "h", "_2", "continue", "removing", "hypothesis", "new", "hypothesis", "verifiable", "given", "current", "hypothesis", "space", "simplicity", "rank", "hypothesis", "h", "first", "stage", "removed", "procedure", "word", "index", "first", "restricted", "hypothesis", "space", "make", "h", "verifiable", "hypothesis", "higher", "simplicity", "rank", "regarded", "simpler", "lower", "rank", "simplicity", "rank", "defined", "term", "logical", "entailment", "relation", "hence", "languageinvariant", "simplicity", "rank", "defined", "seen", "degree", "falsifiability", "following", "sense", "consider", "hypothesis", "simplicity", "rank", "1", "hypothesis", "falsifiable", "evidence", "sequence", "verifies", "alternative", "hypothesis", "rank", "0", "falsifies", "moreover", "hypothesis", "simplicity", "rank", "1", "persistently", "falsifiable", "sense", "remains", "falsifiable", "matter", "evidence", "sequence", "consistent", "observed", "hypothesis", "simplicity", "rank", "n1", "persistently", "falsifiable", "hypothesis", "rank", "n", "let", "u", "illustrate", "definition", "running", "example", "52", "example", "riddle", "induction", "verifiable", "hypothesis", "grue", "hypothesis", "critical", "time", "sequence", "green", "emerald", "followed", "blue", "one", "entail", "corresponding", "grue", "generalization", "thus", "grue", "hypothesis", "receive", "simplicity", "rank", "0", "grue", "hypothesis", "eliminated", "remaining", "hypothesis", "emerald", "green", "given", "possibility", "restricted", "hypothesis", "space", "emerald", "green", "entailed", "sequence", "green", "emerald", "therefore", "emerald", "green", "simplicity", "rank", "1", "removing", "green", "hypothesis", "hypothesis", "remain", "raven", "color", "problem", "verifiable", "hypothesis", "nonblack", "raven", "observed", "receives", "simplicity", "rank", "0", "removing", "hypothesis", "nonblack", "raven", "observed", "remaining", "possibility", "black", "raven", "observed", "hence", "hypothesis", "verifiable", "restricted", "hypothesis", "space", "receives", "simplicity", "rank", "1", "simplicity", "rank", "causal", "graph", "given", "number", "direct", "link", "contained", "graph", "therefore", "fewer", "direct", "link", "posited", "causal", "model", "higher", "simplicity", "rank", "simplicity", "rank", "set", "conservation", "law", "given", "number", "independent", "law", "independence", "sense", "linear", "algebra", "therefore", "nonredundant", "law", "introduced", "theory", "higher", "simplicity", "rank", "law", "rule", "reaction", "maximizing", "number", "independent", "law", "given", "observed", "reaction", "equivalent", "ruling", "many", "unobserved", "reaction", "possible", "53", "stable", "belief", "simplicity", "ockham", "theorem", "following", "theorem", "show", "connection", "mindchange", "complexity", "inductive", "problem", "simplicity", "ranking", "defined", "theorem", "let", "mathbf", "h", "set", "empirical", "hypothesis", "method", "reliably", "identifies", "correct", "hypothesis", "mathbf", "h", "limit", "n", "mind", "change", "elimination", "procedure", "defined", "terminates", "empty", "set", "hypothesis", "n", "stage", "thus", "inductive", "problem", "solvable", "n", "mind", "change", "maximum", "simplicity", "rank", "possible", "hypothesis", "n", "riddle", "induction", "maximum", "simplicity", "rank", "1", "therefore", "problem", "solved", "1", "mind", "change", "next", "result", "provides", "ockham", "theorem", "connecting", "simplicity", "mind", "change", "performance", "ockham", "theorem", "let", "mathbf", "h", "set", "empirical", "hypothesis", "optimal", "mind", "change", "bound", "n", "inductive", "method", "mind", "change", "optimal", "satisfies", "following", "condition", "whenever", "method", "adopts", "one", "hypothesis", "mathbf", "h", "hypothesis", "uniquely", "simplest", "one", "consistent", "evidence", "method", "change", "mind", "inquiry", "time", "t1", "uniquely", "simplest", "hypothesis", "time", "t", "falsified", "time", "t1", "theorem", "say", "mindchange", "optimal", "method", "may", "withhold", "conjecture", "skeptic", "would", "adopt", "definite", "hypothesis", "hypothesis", "must", "simplest", "one", "sense", "maximum", "simplicity", "rank", "thus", "mind", "change", "optimal", "method", "discussed", "section", "4", "ockham", "method", "adopt", "simplest", "hypothesis", "consistent", "data", "ockham", "theorem", "show", "remarkable", "reversal", "longstanding", "objection", "longrun", "reliability", "imposes", "constraint", "shortrun", "conjecture", "add", "longrun", "convergence", "truth", "goal", "achieving", "stable", "belief", "fact", "unique", "inductive", "method", "achieves", "goal", "given", "empirical", "problem", "thus", "methodological", "analysis", "switch", "offering", "shortrun", "prescription", "offering", "complete", "prescription", "54", "regressive", "mind", "change", "simplicity", "another", "ockham", "theorem", "previous", "subsection", "defines", "complete", "simplicity", "ranking", "every", "hypothesis", "investigation", "mean", "hypothesis", "compared", "another", "simpler", "equally", "simple", "le", "demanding", "concept", "partial", "order", "allows", "hypothesis", "may", "simply", "comparable", "like", "apple", "orange", "genin", "kelly", "2015", "show", "following", "partial", "order", "lead", "ockham", "principle", "avoiding", "regressive", "mind", "change", "see", "section", "43", "observation", "sequence", "separate", "hypothesis", "h_1", "hypothesis", "h_2", "observation", "consistent", "h_1", "falsify", "h_2", "given", "background", "knowledge", "hypothesis", "h_1", "inseparable", "h_2", "written", "h_1", "lt", "h_2", "observation", "sequence", "separate", "h_1", "h_2", "equivalently", "h_1", "lt", "h_2", "evidence", "consistent", "h_1", "also", "consistent", "h_2", "separation", "terminology", "due", "smets", "et", "al", "relate", "separation", "principle", "pointset", "topology", "term", "epistemological", "interpretation", "pointset", "topology", "section", "32", "h_1", "lt", "h_2", "every", "complete", "data", "sequence", "h_1", "boundary", "point", "data", "sequence", "h_2", "epistemologically", "resonant", "phrase", "genin", "kelly", "say", "hypothesis", "h_1", "face", "problem", "induction", "respect", "h_2", "whenever", "h_1", "lt", "h_2", "whenever", "h_1", "correct", "reliable", "learner", "take", "inductive", "leap", "conjecture", "h_1", "although", "finite", "amount", "evidence", "also", "consistent", "h_2", "example", "raven", "problem", "h_1", "raven", "black", "lt", "h_2", "raven", "black", "case", "raven", "black", "lt", "raven", "black", "observation", "white", "raven", "separate", "h_2", "h_1", "causal", "graph", "learning", "graph", "g_1", "contains", "subset", "edge", "direct", "causal", "link", "alternative", "graph", "g_2", "g_1", "lt", "g_2", "correlation", "explained", "g_1", "also", "explained", "larger", "graph", "g_2", "curve", "fitting", "l", "lt", "q", "l", "set", "linear", "function", "q", "set", "quadratic", "function", "set", "point", "fit", "linear", "function", "also", "fit", "quadratic", "function", "example", "suggest", "lt", "partial", "order", "corresponds", "intuitive", "simplicity", "judgement", "empirical", "hypothesis", "genin", "kelly", "2019", "provide", "extensive", "defense", "claim", "shown", "lt", "ordering", "agrees", "simplicity", "rank", "defined", "previous", "subsection", "sense", "h_1", "lt", "h_2", "h_2", "lt", "h_1", "simplicity", "rank", "h_1", "le", "rank", "h_2", "observation", "motivate", "ockham", "principle", "inductive", "method", "satisfies", "ockham", "principle", "respect", "separability", "always", "conjecture", "maximally", "simple", "hypothesis", "h", "consistent", "evidence", "notation", "ockham", "method", "adopts", "hypothesis", "h", "given", "finite", "observation", "sequence", "alternative", "simpler", "hypothesis", "h", "h", "lt", "h", "every", "alternative", "hypothesis", "h", "eventually", "separated", "h", "evidence", "h", "true", "raven", "example", "generalizing", "method", "satisfies", "ockham", "principle", "contrary", "method", "adopts", "h_2", "raven", "black", "following", "theorem", "show", "connection", "ockham", "principle", "regressive", "mind", "change", "general", "theorem", "inductive", "method", "avoids", "conjecture", "cycle", "hence", "regressive", "mind", "change", "satisfies", "ockham", "principle", "respect", "separability", "proof", "see", "genin", "kelly", "2015", "theorem", "10", "genin", "kelly", "also", "provide", "sufficient", "condition", "avoiding", "conjecture", "cycle", "result", "section", "establish", "fruitful", "connection", "simplicity", "mindchange", "optimality", "limitation", "approach", "requires", "hypothesis", "must", "conclusively", "entailed", "falsified", "evidence", "sequence", "typically", "case", "statistical", "model", "probability", "hypothesis", "may", "become", "arbitrarily", "small", "usually", "0", "instance", "consider", "coin", "flip", "problem", "hypothesis", "probability", "head", "90", "observe", "one", "million", "tail", "probability", "hypothesis", "small", "indeed", "0", "number", "tail", "logically", "consistent", "high", "probability", "head", "next", "section", "discus", "reliabilist", "approach", "adapted", "statistical", "hypothesis", "6", "reliable", "learning", "statistical", "hypothesis", "statistical", "hypothesis", "common", "practical", "datadriven", "decision", "making", "example", "science", "engineering", "therefore", "important", "philosophical", "framework", "inductive", "inference", "include", "statistical", "hypothesis", "two", "key", "difference", "statistical", "hypothesis", "hypothesis", "set", "considered", "far", "sober", "2015", "relationship", "observation", "hypothesis", "probabilistic", "deductive", "statistical", "hypothesis", "assigns", "probability", "observation", "sequence", "typically", "0", "1", "deductive", "hypothesis", "either", "consistent", "observation", "sequence", "falsified", "analysis", "statistical", "hypothesis", "typically", "assumes", "observation", "form", "random", "sample", "successive", "observation", "independent", "follow", "distribution", "possible", "analyze", "statistical", "method", "later", "observation", "depend", "current", "observation", "mathematical", "complexity", "inductive", "methodology", "much", "greater", "independent", "data", "property", "learning", "theory", "nonstatistical", "method", "straightforward", "framework", "statistic", "traditional", "philosophical", "discussion", "epistemology", "inductive", "inference", "philosophy", "science", "example", "epistemological", "discussion", "justified", "true", "belief", "concern", "deductive", "concept", "belief", "inquirer", "accepts", "proposition", "rather", "assign", "probability", "data", "scientific", "theory", "typically", "make", "deterministic", "prediction", "future", "data", "past", "observation", "initial", "condition", "independence", "requirement", "make", "difficult", "apply", "methodological", "framework", "understand", "scientific", "inquiry", "see", "case", "study", "normative", "meansends", "epistemology", "applied", "statistical", "hypothesis", "well", "deductive", "one", "particular", "discus", "idea", "reliable", "convergence", "truth", "minimizing", "regressive", "mind", "change", "adapted", "statistical", "setting", "key", "idea", "shift", "unit", "analysis", "whereas", "previously", "considered", "behavior", "inductive", "method", "specific", "data", "sequence", "statistical", "analysis", "consider", "aggregate", "behavior", "set", "data", "sequence", "length", "particular", "consider", "probability", "method", "conjecture", "hypothesis", "h", "given", "number", "observation", "n", "preliminary", "statistical", "hypothesis", "illustrate", "main", "idea", "classic", "simple", "example", "observing", "coin", "flip", "indicate", "generalized", "complex", "hypothesis", "detail", "please", "see", "genin", "kelly", "2017", "genin", "2018", "suppose", "investigator", "question", "unknown", "bias", "p", "coin", "p", "represents", "chance", "single", "flip", "come", "head", "different", "possible", "hypothesis", "correspond", "different", "range", "bias", "p", "partition", "01", "range", "bias", "let", "u", "say", "investigator", "asks", "simple", "point", "hypothesis", "coin", "fair", "h_1", "p", "05", "h_2", "case", "p", "05", "either", "p", "lt", "05", "p", "gt", "05", "extending", "previous", "terminology", "shall", "say", "true", "bias", "value", "p", "hypothesis", "h", "lie", "within", "set", "specified", "h", "example", "bias", "value", "p", "correct", "h_1", "p", "05", "otherwise", "p", "correct", "h_2", "given", "true", "bias", "value", "p", "assuming", "independence", "compute", "probability", "finite", "sequence", "observation", "probability", "known", "sample", "distribution", "example", "fair", "coin", "p", "05", "probability", "observing", "3", "head", "05", "times", "05", "times", "05", "0125", "chance", "head", "07", "probability", "observing", "3", "head", "07", "times", "07", "times", "07", "0343", "notice", "independence", "assumption", "allows", "u", "compute", "probability", "sequence", "observation", "product", "single", "observation", "probability", "without", "independence", "assumption", "infer", "probability", "multiple", "observation", "probability", "single", "observation", "sample", "distribution", "defined", "usual", "entry", "inductive", "method", "conjecture", "hypothesis", "observing", "finite", "sequence", "observation", "method", "conjecture", "statistical", "hypothesis", "called", "statistical", "test", "see", "link", "internet", "resource", "section", "statistical", "literature", "provides", "extensive", "collection", "computationally", "efficient", "statistical", "test", "different", "type", "statistical", "hypothesis", "following", "discussion", "consider", "general", "learning", "performance", "method", "respect", "reliable", "convergence", "true", "hypothesis", "avoiding", "mind", "change", "consider", "fixed", "observation", "length", "n", "called", "sample", "size", "sample", "size", "n", "set", "sample", "length", "n", "method", "conjecture", "hypothesis", "h", "given", "sample", "example", "n", "3", "method", "might", "conjecture", "h_2", "coin", "fair", "observing", "3", "head", "aggregate", "probability", "method", "output", "hypothesis", "h", "given", "sample", "length", "n", "sum", "sample", "probability", "sample", "method", "conjecture", "h", "given", "sample", "supplement", "give", "example", "computation", "aggregate", "probability", "aggregate", "probability", "key", "quantity", "methodology", "statistical", "hypothesis", "introduce", "following", "notation", "p_", "n", "p", "h", "probability", "given", "inductive", "method", "conjecture", "hypothesis", "h", "n", "observation", "given", "true", "probability", "single", "observation", "p", "nonstatistical", "learning", "required", "reliable", "method", "eventually", "settle", "true", "hypothesis", "sufficiently", "many", "observation", "statistical", "version", "criterion", "sufficiently", "many", "observation", "chance", "conjecturing", "true", "hypothesis", "approach", "100", "technically", "say", "method", "identifies", "true", "statistical", "hypothesis", "chance", "every", "bias", "value", "p", "every", "threshold", "0lt", "lt", "1", "sample", "size", "n", "larger", "sample", "size", "method", "conjecture", "hypothesis", "h", "true", "p", "least", "probability", "t", "symbol", "p_", "n", "p", "h", "gt", "t", "sample", "size", "n", "gt", "n", "h", "hypothesis", "true", "p", "figure", "illustrates", "chance", "conjecturing", "true", "hypothesis", "increase", "sample", "size", "whereas", "chance", "conjecturing", "false", "hypothesis", "decrease", "sample", "size", "definition", "generalized", "complex", "statistical", "hypothesis", "replacing", "true", "bias", "value", "p", "list", "parameter", "figure", "8", "extended", "description", "figure", "8", "supplement", "notion", "limiting", "identification", "chance", "similar", "concept", "limiting", "convergence", "probability", "estimate", "reichenbach", "pragmatic", "vindication", "translated", "example", "reichenbach", "considered", "inductive", "rule", "output", "estimate", "true", "bias", "value", "p", "required", "rule", "converges", "true", "value", "sense", "every", "every", "bias", "value", "p", "every", "threshold", "0lt", "lt", "1", "sample", "size", "n", "larger", "sample", "size", "probability", "1", "rule", "output", "estimate", "differs", "true", "value", "p", "t", "statistic", "method", "called", "consistent", "increasing", "sample", "size", "method", "chance", "conjecturing", "correct", "answer", "converges", "100", "see", "link", "internet", "resource", "section", "terminology", "unfortunate", "suggests", "philosophical", "reader", "connection", "consistency", "formal", "proof", "system", "fact", "statistical", "concept", "consistency", "nothing", "deductive", "logic", "rather", "probabilistic", "analogue", "notion", "identification", "limit", "inquiry", "main", "subject", "entry", "genin", "kelly", "provide", "characterization", "theorem", "provides", "necessary", "sufficient", "condition", "set", "statistical", "hypothesis", "identifiable", "chance", "analogous", "structural", "condition", "discussed", "section", "33", "2017", "theorem", "43", "genin", "2018", "discus", "statistical", "analogue", "requirement", "minimizing", "mind", "change", "recall", "regressive", "mind", "change", "occurs", "inquirer", "abandon", "true", "hypothesis", "favor", "false", "one", "section", "43", "probabilistic", "analogue", "chance", "reversal", "occurs", "chance", "conjecturing", "true", "hypothesis", "decrease", "sample", "size", "increase", "instance", "consider", "question", "whether", "vaccine", "effective", "infectious", "disease", "suppose", "vaccine", "manufacture", "run", "trial", "1000", "patient", "designed", "statistical", "method", "chance", "90", "correctly", "indicating", "vaccine", "effective", "indeed", "case", "another", "trial", "run", "1500", "patient", "using", "statistical", "method", "chance", "reversal", "would", "occur", "method", "chance", "correctly", "indicating", "vaccine", "effective", "drop", "80", "example", "illustrates", "chance", "reversal", "corresponds", "failure", "replicate", "true", "result", "chance", "reversal", "illustrated", "figure", "chance", "conjecturing", "true", "hypothesis", "smaller", "2", "sample", "3", "although", "chance", "reversal", "clearly", "undesirable", "difficult", "avoid", "fact", "commonly", "used", "statistical", "method", "liable", "reversal", "genin", "2018", "feasible", "goal", "bound", "reversal", "threshold", "t", "chance", "conjecturing", "truth", "decrease", "increasing", "sample", "size", "decrease", "t", "symbol", "p_", "n", "p", "h", "p_", "n1", "p", "h", "lt", "t", "sample", "size", "n", "true", "bias", "value", "p", "h", "hypothesis", "correct", "p", "genin", "2018", "show", "bounded", "chance", "reversal", "feasible", "many", "situation", "provides", "ockham", "theorem", "elucidates", "constraint", "bounding", "chance", "reversal", "provides", "statistical", "hypothesis", "learning", "7", "approach", "categorical", "vs", "hypothetical", "imperative", "kant", "distinguished", "categorical", "imperative", "one", "ought", "follow", "regardless", "one", "personal", "aim", "circumstance", "hypothetical", "imperative", "direct", "u", "employ", "mean", "towards", "chosen", "end", "one", "way", "think", "learning", "theory", "study", "hypothetical", "imperative", "empirical", "inquiry", "many", "epistemologist", "proposed", "various", "categorical", "imperative", "inductive", "inquiry", "example", "form", "inductive", "logic", "norm", "epistemic", "rationality", "principle", "three", "possible", "relationship", "hypothetical", "categorical", "imperative", "empirical", "inquiry", "1", "categorical", "imperative", "lead", "inquirer", "obtain", "cognitive", "goal", "case", "meansends", "analysis", "vindicates", "categorical", "imperative", "example", "faced", "simple", "universal", "generalization", "raven", "black", "saw", "following", "popperian", "recipe", "adopting", "falsifiable", "generalization", "sticking", "counterexample", "appears", "lead", "reliable", "method", "2", "categorical", "imperative", "may", "prevent", "inquirer", "achieving", "aim", "case", "categorical", "imperative", "restricts", "scope", "inquiry", "example", "case", "two", "alternative", "generalization", "exception", "principle", "maintaining", "universal", "generalization", "falsified", "lead", "unreliable", "method", "cf", "kelly", "1996", "ch", "94", "3", "method", "meet", "categorical", "imperative", "goal", "inquiry", "others", "may", "take", "best", "world", "choose", "method", "attain", "goal", "inquiry", "satisfy", "categorical", "imperative", "see", "discussion", "section", "proposed", "norm", "inquiry", "apply", "meansends", "analysis", "ask", "whether", "norm", "help", "hinders", "aim", "inquiry", "spirit", "putnam", "critique", "carnap", "confirmation", "function", "putnam", "1963", "thrust", "essay", "carnap", "method", "reliable", "detecting", "general", "pattern", "method", "would", "recently", "learning", "theorist", "investigated", "power", "bayesian", "conditioning", "see", "entry", "bayesian", "epistemology", "john", "earman", "conjectured", "reliable", "method", "given", "problem", "reliable", "method", "proceeds", "bayesian", "updating", "earman", "1992", "ch9", "sec6", "cory", "juhl", "1997", "provided", "partial", "confirmation", "earman", "conjecture", "proved", "hold", "two", "potential", "evidence", "item", "eg", "emerald", "green", "vs", "emerald", "blue", "general", "case", "still", "open", "epistemic", "conservatism", "methodological", "norm", "prominent", "philosophy", "least", "since", "quine", "notion", "minimal", "mutilation", "belief", "1951", "one", "version", "epistemic", "conservatism", "saw", "hold", "inquiry", "seek", "stable", "belief", "another", "formulation", "closer", "quine", "general", "precept", "belief", "change", "light", "new", "evidence", "minimal", "fairly", "recent", "work", "philosophical", "logic", "proposed", "number", "criterion", "minimal", "belief", "change", "known", "agm", "axiom", "g\u00e4rdenfors", "1988", "learning", "theorist", "shown", "whenever", "reliable", "method", "investigating", "empirical", "question", "one", "proceeds", "via", "minimal", "change", "defined", "agm", "postulate", "property", "reliable", "inquiry", "minimal", "belief", "change", "investigated", "martin", "osherson", "1998", "kelly", "1999", "baltag", "et", "al", "2011", "baltag", "et", "al", "2015", "much", "computational", "learning", "theory", "focus", "inquirer", "bounded", "rationality", "agent", "cognitive", "limitation", "finite", "memory", "bounded", "computational", "capacity", "many", "categorical", "norm", "interfere", "empirical", "success", "logically", "omniscient", "agent", "nonetheless", "limit", "scope", "cognitively", "bounded", "agent", "example", "consider", "norm", "consistency", "believe", "hypothesis", "false", "soon", "evidence", "logically", "inconsistent", "consistency", "principle", "part", "bayesian", "confirmation", "theory", "agm", "belief", "revision", "kelly", "schulte", "1995", "show", "consistency", "prevents", "even", "agent", "infinitely", "uncomputable", "cognitive", "power", "reliably", "assessing", "certain", "hypothesis", "moral", "theory", "sufficiently", "complex", "agent", "logically", "omniscient", "may", "unable", "determine", "immediately", "whether", "given", "piece", "evidence", "consistent", "theory", "need", "collect", "data", "detect", "inconsistency", "consistency", "principleand", "fortiori", "bayesian", "updating", "agm", "belief", "revision", "acknowledge", "usefulness", "wait", "see", "scientific", "strategy", "reflection", "philosophical", "issue", "meansends", "epistemology", "found", "source", "huber", "2018", "glymour", "1991", "kelly", "1996", "chs", "23", "glymour", "kelly", "1992", "kelly", "et", "al", "1997", "glymour", "1994", "bub", "1994", "particular", "interest", "philosophy", "science", "may", "learningtheoretic", "model", "accommodate", "historicist", "relativist", "conception", "inquiry", "chiefly", "expanding", "notion", "inductive", "method", "method", "may", "actively", "select", "paradigm", "inquiry", "detail", "topic", "see", "kelly", "2000", "kelly", "1996", "ch13", "booklength", "introduction", "mathematics", "learning", "theory", "kelly", "1996", "martin", "osherson", "1998", "jain", "et", "al", "1999", "induction", "algorithmic", "learning", "theory", "philosophy", "recent", "collection", "writing", "learning", "theory", "friend", "et", "al", "2007", "contribution", "include", "introductory", "paper", "harizanov", "schulte", "mathematical", "advance", "martin", "sharma", "stephan", "kalantari", "philosophical", "reflection", "strength", "implication", "learning", "theory", "glymour", "larvor", "friend", "application", "theory", "philosophical", "problem", "kelly", "discussion", "learningtheoretic", "thinking", "history", "philosophy", "goethe", "supplementary", "document", "basic", "formal", "definition"]}