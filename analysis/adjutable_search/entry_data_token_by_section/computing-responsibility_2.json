{
    "main_text": "Challenges to moral responsibility || Considering the consequences\n1.2 Considering the consequences\n\nAs computer technologies shape how people perceive and experience the\nworld, they affect the second condition for attributing moral\nresponsibility. In order to make appropriate decisions a person has to\nbe able to consider and deliberate about the consequences of their\nactions. They have to be aware of the possible risks or harms that\ntheir actions might cause. It is unfair to hold someone responsible\nfor something if they could not have reasonably known that their\nactions might lead to harm.\n\nOn the one hand, computer technologies can help users to think through\nwhat their actions or choices may lead to. They help the user to\ncapture, store, organize and analyze data and information (Zuboff\n1982). For example, one often-named advantage of remote-controlled\nrobots used by the armed forces or rescue workers is that they enable\ntheir operators to acquire information that would not be able\navailable without them. They allow their operators to look\n\u201cbeyond the next hill\u201d or \u201caround the next\ncorner\u201d and they can thus help operators to reflect on what the\nconsequences of particular tactical decisions might be (US Department\nof Defense 2009). Similarly, data analysis tools can find patterns in\nlarge volumes of data that human data analysts cannot manually process\n(Boyd and Crawford 2012).\n\nOn the other hand the use of computers can constrain the ability of\nusers to understand or consider the outcomes of their actions. These\ncomplex technologies, which are never fully free from errors,\nincreasingly hide the automated processes behind the interface (Van\nden Hoven 2002). An example that illustrates how computer technologies\ncan limit understanding of the outcomes are the controversial risk\nassessment tools used by judges in several states in the U.S. for\nparole decisions and sentencing. In 2016 a civil society organization\nfound, based on an analysis of the risk scores of 7000 defendants\nproduced by one particular algorithm, that the scores poorly reflected\nthe actual recidivism rate and seemed to have a racial bias (Angwin et\nal. 2016). Regardless of whether its findings were correct or not,\nwhat is particularly relevant here is that the investigation also\nshowed that judges did not have a full understanding of how the\nprobabilities were calculated, in part because the algorithm was\nproprietary. The judges were basing their sentencing on the suggestion\nof an algorithm that they did not fully understand. This is the case\nfor most computer technologies today. Users only see part of the many\ncomputations that a computer performs and are for the most part\nunaware of how it performs them; they usually only have a partial\nunderstanding of the assumptions, models and theories on which the\ninformation on their computer screen is based. The increasing\ncomplexity of computer systems and their reliance on opaque machine\nlearning algorithms makes it even more difficult to understand what is\nhappening behind the interface (Pasquale 2015, Diakopoulos 2020). \n\nThe opacity of many computer systems can get in the way of assessing\nthe validity and relevance of the information and can prevent a user\nfrom making appropriate decisions. People have a tendency to either\nrely too much or not enough on the accuracy automated systems\n(Cummings 2004; Parasuraman & Riley 1997). This tendency is called\nautomation bias. A person\u2019s ability to act responsibly,\nfor example, can suffer when she distrust the automation as result of\na high rate of false alarms. In the Therac 25 case, one of the\nmachine\u2019s operators testified that she had become used to the\nmany cryptic error messages the machine gave and most did not involve\npatient safety (Leveson and Turner 1993, p.24). She tended to ignore\nthem and therefore failed to notice when the machine was set to\noverdose a patient. Too much reliance on automated systems can have\nequally disastrous consequences. In 1988 the missile cruiser U.S.S.\nVincennes shot down an Iranian civilian jet airliner, killing all 290\npassengers onboard, after it mistakenly identified the airliner as an\nattacking military aircraft (Gray 1997). The cruiser was equipped with\nan Aegis defensive system that could automatically track and target\nincoming missiles and enemy aircrafts. Analyses of the events leading\nup to the incident showed that overconfidence in the abilities of the\nAegis system prevented others from intervening when they could have.\nTwo other warships nearby had correctly identified the aircraft as\ncivilian. Yet, they did not dispute the Vincennes\u2019\nidentification of the aircraft as a military aircraft. In a later\nexplanation Lt. Richard Thomas of one of the nearby ships stated,\n\u201cWe called her Robocruiser\u2026 she always seemed to have a\npicture\u2026 She always seemed to be telling everybody to get on or\noff the link as though her picture was better\u201d (as quoted in\nGray 1997, p. 34). The captains of both ships thought that the\nsophisticated Aegis system provided the crew of Vincennes with\ninformation they did not have.\n\nConsidering the possible consequences of one\u2019s actions is\nfurther complicated as computer technologies make it possible for\nhumans to do things that they could not do before. Several decades\nago, the philosopher Ladd pointed out, \u201c[C]omputer technology\nhas created new modes of conduct and new social institutions, new\nvices and new virtues, new ways of helping and new ways of abusing\nother people\u201d (Ladd 1989, p. 210\u201311). Computer\ntechnologies of today have had a similar effect. The social or legal\nconventions that govern what we can do with these technologies take\nsome time to emerge and the initial absence of these conventions\ncontributes to confusion about responsibilities (Taddeo and Floridi\n2015). For example, the ability for users to upload and share text,\nvideos and images publicly on the Internet raised a whole set of\nquestions about who is responsible for the content of the uploaded\nmaterial. Such questions were at the heart of the debate about the\nconviction of three Google executives in Italy for a violation of the\ndata protection act (Sartor and Viola de Azevedo Cunha 2010). The case\nconcerned a video on YouTube of four students assaulting a disabled\nperson. In response to a request by the Italian Postal Police, Google,\nas owner of YouTube, took the video down two months after the students\nuploaded it. The judge, nonetheless, ruled that Google was criminally\nliable for processing the video without taking adequate precautionary\nmeasures to avoid privacy violations. The judge also held Google\nliable for failing to adequately inform the students, who uploaded the\nvideos, of their data protection obligations (p. 367). In the ensuing\ndebate about the verdict, those critical of the ruling insisted that\nit threatened the freedom of expression on the Internet and it sets a\ndangerous precedent that can be used by authoritarian regimes to\njustify web censorship (see also Singel 2010). Moreover, they claimed\nthat platform providers could not be held responsible for the actions\nof their users, as they could not realistically approve every upload\nand it was not their job to censure. Yet, others instead argued that\nit would be immoral for Google to be exempt from liability for the\ndamage that others suffered due to Google\u2019s profitable\ncommercial activity. Cases like this one show that in the confusion\nabout the possibilities and limitations of new technologies it can be\ndifficult to determine one\u2019s moral obligations to others.\n\nThe lack of experience with new technological innovations can also\naffect what counts as negligent use of the technology. In order to\noperate a new computer system, users typically have to go through a\nprocess of training and familiarization with the system. It requires\nskill and experience to understand and imagine how the system will\nbehave (Coeckelbergh and Wackers 2007). Friedman describes the case of\na programmer who invented and was experimenting with a \u2018computer\nworm\u2019, a piece of code that can replicate itself. At the time\nthis was a relatively new computational entity (1990). The programmer\nreleased the worm on the Internet, but the experiment quickly got out\nof the control when the code replicated much faster than he had\nexpected (see also Denning 1989). Today we would not find this a\nsatisfactory excuse, familiar as we have become with computer worms,\nviruses and other forms of malware. However, Friedman poses the\nquestion of whether the programmer really acted in a negligent way if\nthe consequences were truly unanticipated. Does the computer\ncommunity\u2019s lack of experience with a particular type of\ncomputational entity influence what we judge to be negligent\nbehavior?\n",
    "section_title": "1.2 Considering the consequences",
    "entry_title": "Computing and Moral Responsibility",
    "hierarchy_title": "Computing and Moral Responsibility || Challenges to moral responsibility || Considering the consequences",
    "tokenized_text": [
        "challenge",
        "moral",
        "responsibility",
        "considering",
        "consequence",
        "considering",
        "consequence",
        "computer",
        "technology",
        "shape",
        "people",
        "perceive",
        "experience",
        "world",
        "affect",
        "second",
        "condition",
        "attributing",
        "moral",
        "responsibility",
        "order",
        "make",
        "appropriate",
        "decision",
        "person",
        "able",
        "consider",
        "deliberate",
        "consequence",
        "action",
        "aware",
        "possible",
        "risk",
        "harm",
        "action",
        "might",
        "cause",
        "unfair",
        "hold",
        "someone",
        "responsible",
        "something",
        "could",
        "reasonably",
        "known",
        "action",
        "might",
        "lead",
        "harm",
        "one",
        "hand",
        "computer",
        "technology",
        "help",
        "user",
        "think",
        "action",
        "choice",
        "may",
        "lead",
        "help",
        "user",
        "capture",
        "store",
        "organize",
        "analyze",
        "data",
        "information",
        "zuboff",
        "example",
        "one",
        "oftennamed",
        "advantage",
        "remotecontrolled",
        "robot",
        "used",
        "armed",
        "force",
        "rescue",
        "worker",
        "enable",
        "operator",
        "acquire",
        "information",
        "would",
        "able",
        "available",
        "without",
        "allow",
        "operator",
        "look",
        "beyond",
        "next",
        "hill",
        "around",
        "next",
        "corner",
        "thus",
        "help",
        "operator",
        "reflect",
        "consequence",
        "particular",
        "tactical",
        "decision",
        "might",
        "u",
        "department",
        "defense",
        "similarly",
        "data",
        "analysis",
        "tool",
        "find",
        "pattern",
        "large",
        "volume",
        "data",
        "human",
        "data",
        "analyst",
        "manually",
        "process",
        "boyd",
        "crawford",
        "hand",
        "use",
        "computer",
        "constrain",
        "ability",
        "user",
        "understand",
        "consider",
        "outcome",
        "action",
        "complex",
        "technology",
        "never",
        "fully",
        "free",
        "error",
        "increasingly",
        "hide",
        "automated",
        "process",
        "behind",
        "interface",
        "van",
        "den",
        "hoven",
        "example",
        "illustrates",
        "computer",
        "technology",
        "limit",
        "understanding",
        "outcome",
        "controversial",
        "risk",
        "assessment",
        "tool",
        "used",
        "judge",
        "several",
        "state",
        "us",
        "parole",
        "decision",
        "sentencing",
        "civil",
        "society",
        "organization",
        "found",
        "based",
        "analysis",
        "risk",
        "score",
        "defendant",
        "produced",
        "one",
        "particular",
        "algorithm",
        "score",
        "poorly",
        "reflected",
        "actual",
        "recidivism",
        "rate",
        "seemed",
        "racial",
        "bias",
        "angwin",
        "et",
        "al",
        "regardless",
        "whether",
        "finding",
        "correct",
        "particularly",
        "relevant",
        "investigation",
        "also",
        "showed",
        "judge",
        "full",
        "understanding",
        "probability",
        "calculated",
        "part",
        "algorithm",
        "proprietary",
        "judge",
        "basing",
        "sentencing",
        "suggestion",
        "algorithm",
        "fully",
        "understand",
        "case",
        "computer",
        "technology",
        "today",
        "user",
        "see",
        "part",
        "many",
        "computation",
        "computer",
        "performs",
        "part",
        "unaware",
        "performs",
        "usually",
        "partial",
        "understanding",
        "assumption",
        "model",
        "theory",
        "information",
        "computer",
        "screen",
        "based",
        "increasing",
        "complexity",
        "computer",
        "system",
        "reliance",
        "opaque",
        "machine",
        "learning",
        "algorithm",
        "make",
        "even",
        "difficult",
        "understand",
        "happening",
        "behind",
        "interface",
        "pasquale",
        "diakopoulos",
        "opacity",
        "many",
        "computer",
        "system",
        "get",
        "way",
        "assessing",
        "validity",
        "relevance",
        "information",
        "prevent",
        "user",
        "making",
        "appropriate",
        "decision",
        "people",
        "tendency",
        "either",
        "rely",
        "much",
        "enough",
        "accuracy",
        "automated",
        "system",
        "cummings",
        "parasuraman",
        "riley",
        "tendency",
        "called",
        "automation",
        "bias",
        "person",
        "ability",
        "act",
        "responsibly",
        "example",
        "suffer",
        "distrust",
        "automation",
        "result",
        "high",
        "rate",
        "false",
        "alarm",
        "therac",
        "case",
        "one",
        "machine",
        "operator",
        "testified",
        "become",
        "used",
        "many",
        "cryptic",
        "error",
        "message",
        "machine",
        "gave",
        "involve",
        "patient",
        "safety",
        "leveson",
        "turner",
        "p",
        "tended",
        "ignore",
        "therefore",
        "failed",
        "notice",
        "machine",
        "set",
        "overdose",
        "patient",
        "much",
        "reliance",
        "automated",
        "system",
        "equally",
        "disastrous",
        "consequence",
        "missile",
        "cruiser",
        "us",
        "vincennes",
        "shot",
        "iranian",
        "civilian",
        "jet",
        "airliner",
        "killing",
        "passenger",
        "onboard",
        "mistakenly",
        "identified",
        "airliner",
        "attacking",
        "military",
        "aircraft",
        "gray",
        "cruiser",
        "equipped",
        "aegis",
        "defensive",
        "system",
        "could",
        "automatically",
        "track",
        "target",
        "incoming",
        "missile",
        "enemy",
        "aircraft",
        "analysis",
        "event",
        "leading",
        "incident",
        "showed",
        "overconfidence",
        "ability",
        "aegis",
        "system",
        "prevented",
        "others",
        "intervening",
        "could",
        "two",
        "warship",
        "nearby",
        "correctly",
        "identified",
        "aircraft",
        "civilian",
        "yet",
        "dispute",
        "vincennes",
        "identification",
        "aircraft",
        "military",
        "aircraft",
        "later",
        "explanation",
        "lt",
        "richard",
        "thomas",
        "one",
        "nearby",
        "ship",
        "stated",
        "called",
        "robocruiser",
        "always",
        "seemed",
        "picture",
        "always",
        "seemed",
        "telling",
        "everybody",
        "get",
        "link",
        "though",
        "picture",
        "better",
        "quoted",
        "gray",
        "p",
        "captain",
        "ship",
        "thought",
        "sophisticated",
        "aegis",
        "system",
        "provided",
        "crew",
        "vincennes",
        "information",
        "considering",
        "possible",
        "consequence",
        "one",
        "action",
        "complicated",
        "computer",
        "technology",
        "make",
        "possible",
        "human",
        "thing",
        "could",
        "several",
        "decade",
        "ago",
        "philosopher",
        "ladd",
        "pointed",
        "c",
        "omputer",
        "technology",
        "created",
        "new",
        "mode",
        "conduct",
        "new",
        "social",
        "institution",
        "new",
        "vice",
        "new",
        "virtue",
        "new",
        "way",
        "helping",
        "new",
        "way",
        "abusing",
        "people",
        "ladd",
        "p",
        "computer",
        "technology",
        "today",
        "similar",
        "effect",
        "social",
        "legal",
        "convention",
        "govern",
        "technology",
        "take",
        "time",
        "emerge",
        "initial",
        "absence",
        "convention",
        "contributes",
        "confusion",
        "responsibility",
        "taddeo",
        "floridi",
        "example",
        "ability",
        "user",
        "upload",
        "share",
        "text",
        "video",
        "image",
        "publicly",
        "internet",
        "raised",
        "whole",
        "set",
        "question",
        "responsible",
        "content",
        "uploaded",
        "material",
        "question",
        "heart",
        "debate",
        "conviction",
        "three",
        "google",
        "executive",
        "italy",
        "violation",
        "data",
        "protection",
        "act",
        "sartor",
        "viola",
        "de",
        "azevedo",
        "cunha",
        "case",
        "concerned",
        "video",
        "youtube",
        "four",
        "student",
        "assaulting",
        "disabled",
        "person",
        "response",
        "request",
        "italian",
        "postal",
        "police",
        "google",
        "owner",
        "youtube",
        "took",
        "video",
        "two",
        "month",
        "student",
        "uploaded",
        "judge",
        "nonetheless",
        "ruled",
        "google",
        "criminally",
        "liable",
        "processing",
        "video",
        "without",
        "taking",
        "adequate",
        "precautionary",
        "measure",
        "avoid",
        "privacy",
        "violation",
        "judge",
        "also",
        "held",
        "google",
        "liable",
        "failing",
        "adequately",
        "inform",
        "student",
        "uploaded",
        "video",
        "data",
        "protection",
        "obligation",
        "p",
        "ensuing",
        "debate",
        "verdict",
        "critical",
        "ruling",
        "insisted",
        "threatened",
        "freedom",
        "expression",
        "internet",
        "set",
        "dangerous",
        "precedent",
        "used",
        "authoritarian",
        "regime",
        "justify",
        "web",
        "censorship",
        "see",
        "also",
        "singel",
        "moreover",
        "claimed",
        "platform",
        "provider",
        "could",
        "held",
        "responsible",
        "action",
        "user",
        "could",
        "realistically",
        "approve",
        "every",
        "upload",
        "job",
        "censure",
        "yet",
        "others",
        "instead",
        "argued",
        "would",
        "immoral",
        "google",
        "exempt",
        "liability",
        "damage",
        "others",
        "suffered",
        "due",
        "google",
        "profitable",
        "commercial",
        "activity",
        "case",
        "like",
        "one",
        "show",
        "confusion",
        "possibility",
        "limitation",
        "new",
        "technology",
        "difficult",
        "determine",
        "one",
        "moral",
        "obligation",
        "others",
        "lack",
        "experience",
        "new",
        "technological",
        "innovation",
        "also",
        "affect",
        "count",
        "negligent",
        "use",
        "technology",
        "order",
        "operate",
        "new",
        "computer",
        "system",
        "user",
        "typically",
        "go",
        "process",
        "training",
        "familiarization",
        "system",
        "requires",
        "skill",
        "experience",
        "understand",
        "imagine",
        "system",
        "behave",
        "coeckelbergh",
        "wackers",
        "friedman",
        "describes",
        "case",
        "programmer",
        "invented",
        "experimenting",
        "computer",
        "worm",
        "piece",
        "code",
        "replicate",
        "time",
        "relatively",
        "new",
        "computational",
        "entity",
        "programmer",
        "released",
        "worm",
        "internet",
        "experiment",
        "quickly",
        "got",
        "control",
        "code",
        "replicated",
        "much",
        "faster",
        "expected",
        "see",
        "also",
        "denning",
        "today",
        "would",
        "find",
        "satisfactory",
        "excuse",
        "familiar",
        "become",
        "computer",
        "worm",
        "virus",
        "form",
        "malware",
        "however",
        "friedman",
        "pose",
        "question",
        "whether",
        "programmer",
        "really",
        "acted",
        "negligent",
        "way",
        "consequence",
        "truly",
        "unanticipated",
        "computer",
        "community",
        "lack",
        "experience",
        "particular",
        "type",
        "computational",
        "entity",
        "influence",
        "judge",
        "negligent",
        "behavior"
    ]
}