{
    "url": "game-theory",
    "title": "Game Theory",
    "authorship": {
        "year": "Copyright \u00a9 2023",
        "author_text": "Don Ross\n<don.ross@uct.ac.za>",
        "author_links": [
            {
                "http://uct.academia.edu/DonRoss": "Don Ross"
            },
            {
                "mailto:don%2eross%40uct%2eac%2eza": "don.ross@uct.ac.za"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2023</a> by\n\n<br/>\n<a href=\"http://uct.academia.edu/DonRoss\" target=\"other\">Don Ross</a>\n&lt;<a href=\"mailto:don%2eross%40uct%2eac%2eza\"><em>don<abbr title=\" dot \">.</abbr>ross<abbr title=\" at \">@</abbr>uct<abbr title=\" dot \">.</abbr>ac<abbr title=\" dot \">.</abbr>za</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Sat Jan 25, 1997",
        "substantive revision Sun Sep 3, 2023"
    ],
    "preamble": "\n\nGame theory is the study of the ways in which interacting\nchoices of economic agents produce outcomes\nwith respect to the preferences (or utilities) of\nthose agents, where the outcomes in question might have been intended\nby none of the agents. The meaning of this statement will not be clear\nto the non-expert until each of the italicized words and phrases has\nbeen explained and featured in some examples. Doing this will be the\nmain business of this article. First, however, we provide some\nhistorical and philosophical context in order to motivate the reader\nfor the technical work ahead. \n",
    "toc": [
        {
            "#Mot": "1. Philosophical and Historical Motivation"
        },
        {
            "#Bas": "2. Basic Elements and Assumptions of Game Theory"
        },
        {
            "#Util": "2.1 Utility"
        },
        {
            "#Games": "2.2 Games and Rationality"
        },
        {
            "#trees": "2.3 Trees and Matrices"
        },
        {
            "#PD": "2.4 The Prisoner\u2019s Dilemma as an Example of Strategic-Form vs. Extensive-Form Representation"
        },
        {
            "#SolConEqu": "2.5 Solution Concepts and Equilibria"
        },
        {
            "#Subgame": "2.6 Subgame Perfection"
        },
        {
            "#IP": "2.7 On Interpreting Payoffs: Morality and Efficiency in Games"
        },
        {
            "#trembling": "2.8 Trembling Hands and Quantal Response Equilibria"
        },
        {
            "#Uncer": "3. Uncertainty, Risk and Sequential Equilibria"
        },
        {
            "#Beliefs": "3.1 Beliefs and Subjective Probabilities"
        },
        {
            "#Repeat": "4. Repeated Games and Coordination"
        },
        {
            "#Team": "5. Team reasoning and conditional games"
        },
        {
            "#Com": "6. Commitment"
        },
        {
            "#Evo": "7. Evolutionary Game Theory"
        },
        {
            "#Behav": "8. Game Theory and Behavioral Evidence"
        },
        {
            "#Lab": "8.1 Game Theory in the Laboratory"
        },
        {
            "#Neuro": "8.2 Neuroeconomics and Game Theory"
        },
        {
            "#Human": "8.3 Game Theoretic Models of Human Nature"
        },
        {
            "#Future": "9. Looking Ahead: Areas of Current Innovation"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. Philosophical and Historical Motivation\n\nGame theory in the form known to economists, social scientists, and\nbiologists, was given its first general mathematical formulation by\nJohn von Neumann and Oskar Morgenstern\n (1944).\n For reasons to be discussed later, limitations in their formal\nframework initially made the theory applicable only under special and\nlimited conditions. This situation has dramatically changed, in ways\nwe will examine as we go along, over the past seven decades, as the\nframework has been deepened and generalized. Refinements are still\nbeing made, and we will review a few outstanding problems that lie\nalong the advancing front edge of these developments towards the end\nof the article. However, since at least the late 1970s it has been\npossible to say with confidence that game theory is the most important\nand useful tool in the analyst\u2019s kit whenever she confronts\nsituations in which what counts as one agent\u2019s best action (for\nher) depends on expectations about what one or more other agents will\ndo, and what counts as their best actions (for them) similarly depend\non expectations about her. \n\nDespite the fact that game theory has been rendered mathematically and\nlogically systematic only since 1944, game-theoretic insights can be\nfound among commentators going back to ancient times. For example, in\ntwo of Plato\u2019s texts, the Laches and the\nSymposium, Socrates recalls an episode from the Battle of\nDelium that some commentators have interpreted (probably\nanachronistically) as involving the following situation. Consider a\nsoldier at the front, waiting with his comrades to repulse an enemy\nattack. It may occur to him that if the defense is likely to be\nsuccessful, then it isn\u2019t very probable that his own personal\ncontribution will be essential. But if he stays, he runs the risk of\nbeing killed or wounded\u2014apparently for no point. On the other\nhand, if the enemy is going to win the battle, then his chances of\ndeath or injury are higher still, and now quite clearly to no point,\nsince the line will be overwhelmed anyway. Based on this reasoning, it\nwould appear that the soldier is better off running away regardless of\nwho is going to win the battle. But if all of the soldiers reason this\nway\u2014as they all apparently should, since they\u2019re\nall in identical situations\u2014then this will certainly bring\nabout the outcome in which the battle is lost. Of course, this\npoint, since it has occurred to us as analysts, can occur to the\nsoldiers too. Does this give them a reason for staying at their posts?\nJust the contrary: the greater the soldiers\u2019 fear that the\nbattle will be lost, the greater their incentive to get themselves out\nof harm\u2019s way. And the greater the soldiers\u2019 belief that\nthe battle will be won, without the need of any particular\nindividual\u2019s contributions, the less reason they have to stay\nand fight. If each soldier anticipates this sort of reasoning\non the part of the others, all will quickly reason themselves into a\npanic, and their horrified commander will have a rout on his hands\nbefore the enemy has even engaged.\n\nLong before game theory had come along to show analysts how to think\nabout this sort of problem systematically, it had occurred to some\nactual military leaders and influenced their strategies. Thus the\nSpanish conqueror Cortez, when landing in Mexico with a small force\nwho had good reason to fear their capacity to repel attack from the\nfar more numerous Aztecs, removed the risk that his troops might think\ntheir way into a retreat by burning the ships on which they had\nlanded. With retreat having thus been rendered physically impossible,\nthe Spanish soldiers had no better course of action than to stand and\nfight\u2014and, furthermore, to fight with as much determination as\nthey could muster. Better still, from Cortez\u2019s point of view,\nhis action had a discouraging effect on the motivation of the Aztecs.\nHe took care to burn his ships very visibly, so that the Aztecs would\nbe sure to see what he had done. They then reasoned as follows: Any\ncommander who could be so confident as to willfully destroy his own\noption to be prudent if the battle went badly for him must have good\nreasons for such extreme optimism. It cannot be wise to attack an\nopponent who has a good reason (whatever, exactly, it might be) for\nbeing sure that he can\u2019t lose. The Aztecs therefore retreated\ninto the surrounding hills, and Cortez had the easiest possible\nvictory.\n\nThese two situations, at Delium and as manipulated by Cortez, have a\ncommon and interesting underlying logic. Notice that the soldiers are\nnot motivated to retreat just, or even mainly, by their\nrational assessment of the dangers of battle and by their\nself-interest. Rather, they discover a sound reason to run away by\nrealizing that what it makes sense for them to do depends on what it\nwill make sense for others to do, and that all of the others can\nnotice this too. Even a quite brave soldier may prefer to run rather\nthan heroically, but pointlessly, die trying to stem the oncoming tide\nall by himself. Thus we could imagine, without contradiction, a\ncircumstance in which an army, all of whose members are brave, flees\nat top speed before the enemy makes a move. If the soldiers really\nare brave, then this surely isn\u2019t the outcome any of\nthem wanted; each would have preferred that all stand and fight. What\nwe have here, then, is a case in which the interaction of\nmany individually rational decision-making processes\u2014one process\nper soldier\u2014produces an outcome intended by no one. (Many armies\ntry to avoid this problem just as Cortez did. Since they can\u2019t\nusually make retreat physically impossible, they make it\neconomically irrational: for most of history, it was standard\nmilitary practice to execute deserters. In that context standing and\nfighting is each soldier\u2019s individually rational course of\naction after all, because the expected cost of running is at least as\nhigh as the cost of staying.)\n\nAnother classic source that invites this sequence of reasoning is\nfound in Shakespeare\u2019s Henry V. During the Battle of\nAgincourt Henry decided to slaughter his French prisoners, in full\nview of the enemy and to the surprise of his subordinates, who\ndescribe the action as being out of moral character. The reasons Henry\ngives allude to non-strategic considerations: he is afraid that the\nprisoners may free themselves and threaten his position. However, a\ngame theorist might have furnished him with supplementary strategic\n(and similarly prudential, though perhaps not moral) justification.\nHis own troops observe that the prisoners have been killed, and\nobserve that the enemy has observed this. Therefore, they know what\nfate will await them at the enemy\u2019s hand if they don\u2019t\nwin. Metaphorically, but very effectively, their boats have been\nburnt. The slaughter of the prisoners plausibly sent a signal to the\nsoldiers of both sides, thereby changing their incentives in ways that\nfavoured English prospects for victory.\n\nThese examples might seem to be relevant only for those who find\nthemselves in situations of cut-throat competition. Perhaps, one might\nthink, it is important for generals, politicians, mafiosi, sports\ncoaches and others whose jobs involve strategic manipulation of\nothers, but the philosopher should only deplore its amorality. Such a\nconclusion would be highly premature, however. The study of the\nlogic that governs the interrelationships amongst incentives,\nstrategic interactions and outcomes has been fundamental in modern\npolitical philosophy, since centuries before anyone had an explicit\nname for this sort of logic. Philosophers share with social scientists\nthe need to be able to represent and systematically model not only\nwhat they think people normatively ought to do, but what they\noften actually do in interactive situations.\n\nHobbes\u2019s Leviathan is often regarded as the founding\nwork in modern political philosophy, the text that began the\ncontinuing round of analyses of the function and justification of the\nstate and its restrictions on individual liberties. The core of\nHobbes\u2019s reasoning can be given straightforwardly as follows.\nThe best situation for all people is one in which each is free to do\nas she pleases. (One may or may not agree with this as a matter of\npsychology or ideology, but it is Hobbes\u2019s assumption.) Often,\nsuch free people will wish to cooperate with one another in order to\ncarry out projects that would be impossible for an individual acting\nalone. But if there are any immoral or amoral agents around, they will\nnotice that their interests might at least sometimes be best served by\ngetting the benefits from cooperation and not returning them. Suppose,\nfor example, that you agree to help me build my house in return for my\npromise to help you build yours. After my house is finished, I can\nmake your labour free to me simply by reneging on my promise. I then\nrealize, however, that if this leaves you with no house, you will have\nan incentive to take mine. This will put me in constant fear of you,\nand force me to spend valuable time and resources guarding myself\nagainst you. I can best minimize these costs by striking first and\nkilling you at the first opportunity. Of course, you can anticipate\nall of this reasoning by me, and so have good reason to try to beat me\nto the punch. Since I can anticipate this reasoning by\nyou, my original fear of you was not paranoid; nor was yours\nof me. In fact, neither of us actually needs to be immoral to get this\nchain of mutual reasoning going; we need only think that there is some\npossibility that the other might try to cheat on bargains.\nOnce a small wedge of doubt enters any one mind, the incentive induced\nby fear of the consequences of being preempted\u2014hit\nbefore hitting first\u2014quickly becomes overwhelming on both sides.\nIf either of us has any resources of our own that the other might\nwant, this murderous logic can take hold long before we are so silly\nas to imagine that we could ever actually get as far as making deals\nto help one another build houses in the first place. Left to their own\ndevices, agents who are at least sometimes narrowly self-interested\ncan repeatedly fail to derive the benefits of cooperation, and instead\nbe trapped in a state of \u2018war of all against all\u2019, in\nHobbes\u2019s words. In these circumstances, human life, as he\nvividly and famously put it, will be \u201csolitary, poor, nasty,\nbrutish and short.\u201d\n\nHobbes\u2019s proposed solution to this problem was tyranny. The\npeople can hire an agent\u2014a government\u2014whose job is to\npunish anyone who breaks any promise. So long as the threatened\npunishment is sufficiently dire then the cost of reneging on promises\nwill exceed the cost of keeping them. The logic here is identical to\nthat used by an army when it threatens to shoot deserters. If all\npeople know that these incentives hold for most others, then\ncooperation will not only be possible, but can be the expected norm,\nso that the war of all against all becomes a general peace.\n\nHobbes pushes the logic of this argument to a very strong conclusion,\narguing that it implies not only a government with the right and the\npower to enforce cooperation, but an \u2018undivided\u2019\ngovernment in which the arbitrary will of a single ruler must impose\nabsolute obligation on all. Few contemporary political theorists think\nthat the particular steps by which Hobbes reasons his way to this\nconclusion are both sound and valid. Working through these issues\nhere, however, would carry us away from our topic into details of\ncontractarian political philosophy. What is important in the present\ncontext is that these details, as they are in fact pursued in\ncontemporary debates, involve sophisticated interpretation of the\nissues using the resources of modern game theory (see, for example,\n Hampton 1986).\n Furthermore, Hobbes\u2019s most basic point, that the fundamental\njustification for the coercive authority and practices of governments\nis peoples\u2019 own need to protect themselves from what game\ntheorists call \u2018social dilemmas\u2019, is accepted by many, if\nnot most, political theorists. Notice that Hobbes has not\nargued that tyranny is a desirable thing in itself. The structure of\nhis argument is that the logic of strategic interaction leaves only\ntwo general political outcomes possible: tyranny and anarchy. Sensible\nagents then choose tyranny as the lesser of two evils.\n\nThe reasoning of the Athenian soldiers, of Cortez, and of\nHobbes\u2019s political agents has a common logic, one derived from\ntheir situations. In each case, the aspect of the environment that is\nmost important to the agents\u2019 achievement of their preferred\noutcomes is the set of expectations and possible reactions to their\nstrategies by other agents. The distinction between acting\nparametrically on a passive world and acting\nnon-parametrically on a world that tries to act in\nanticipation of these actions is fundamental. If you want to kick a\nrock down a hill, you need only concern yourself with the rock\u2019s\nmass relative to the force of your blow, the extent to which it is\nbonded with its supporting surface, the slope of the ground on the\nother side of the rock, and the expected impact of the collision on\nyour foot. The values of all of these variables are independent of\nyour plans and intentions, since the rock has no interests of its own\nand takes no actions to attempt to assist or thwart you. By contrast,\nif you wish to kick a person down the hill, then unless that person is\nunconscious, bound or otherwise incapacitated, you will likely not\nsucceed unless you can disguise your plans until it\u2019s too late\nfor him to take either evasive or forestalling action. Furthermore,\nhis probable responses should be expected to visit costs upon you,\nwhich you would be wise to consider. Finally, the relative\nprobabilities of his responses will depend on his expectations about\nyour probable responses to his responses. (Consider the difference it\nwill make to both of your reasoning if one or both of you are armed,\nor one of you is bigger than the other, or one of you is the\nother\u2019s boss.) The logical issues associated with the second\nsort of situation (kicking the person as opposed to the rock) are\ntypically much more complicated, as a simple hypothetical example will\nillustrate.\n\nSuppose first that you wish to cross a river that is spanned by three\nbridges. (Assume that swimming, wading or boating across are\nimpossible.) The first bridge is known to be safe and free of\nobstacles; if you try to cross there, you will succeed. The second\nbridge lies beneath a cliff from which large rocks sometimes fall. The\nthird is inhabited by deadly cobras. Now suppose you wish to\nrank-order the three bridges with respect to their preferability as\ncrossing-points. Unless you get positive enjoyment from risking your\nlife\u2014which, without violating any economist\u2019s conception\nof rationality, you might well (a complication we\u2019ll take up\nlater in this article)\u2014then your decision problem here is\nstraightforward. The first bridge is obviously best, since it is\nsafest. To rank-order the other two bridges, you require information\nabout their relative levels of danger. If you can study the frequency\nof rock-falls and the movements of the cobras for awhile, you might be\nable to calculate that the probability of your being crushed by a rock\nat the second bridge is 10% and of being struck by a cobra at the\nthird bridge is 20%. Your reasoning here is strictly parametric\nbecause neither the rocks nor the cobras are trying to influence your\nactions, by, for example, concealing their typical patterns of\nbehaviour because they know you are studying them. It is obvious what\nyou should do here: cross at the safe bridge. Now let us complicate\nthe situation a bit. Suppose that the bridge with the rocks is\nimmediately before you, while the safe bridge is a day\u2019s\ndifficult hike upstream. Your decision-making situation here is\nslightly more complicated, but it is still strictly parametric. You\nhave to decide whether the cost of the long hike is worth exchanging\nfor the penalty of a 10% chance of being hit by a rock. However, this\nis all you must decide, and your probability of a successful crossing\nis entirely up to you; the environment is not interested in your\nplans.\n\nHowever, if we now complicate the situation by adding a non-parametric\nelement, it becomes more challenging. Suppose that you are a fugitive\nof some sort, and waiting on the other side of the river with a gun is\nyour pursuer. She will catch and shoot you, let us suppose, only if\nshe waits at the bridge you try to cross; otherwise, you will escape.\nAs you reason through your choice of bridge, it occurs to you that she\nis over there trying to anticipate your reasoning. It will seem that,\nsurely, choosing the safe bridge straight away would be a mistake,\nsince that is just where she will expect you, and your chances of\ndeath rise to certainty. So perhaps you should risk the rocks, since\nthese odds are much better. But wait \u2026 if you can reach this\nconclusion, your pursuer, who is just as well-informed as you are, can\nanticipate that you will reach it, and will be waiting for you if you\nevade the rocks. So perhaps you must take your chances with the\ncobras; that is what she must least expect. But, then, no \u2026 if\nshe expects that you will expect that she will least expect this, then\nshe will most expect it. This dilemma, you realize with dread, is\ngeneral: you must do what your pursuer least expects; but whatever you\nmost expect her to least expect is automatically what she will most\nexpect. You appear to be trapped in indecision. But what should\nconsole you somewhat here is that, on the other side of the river,\nyour pursuer is trapped in exactly the same quandary, unable to decide\nwhich bridge to wait at because as soon as she imagines committing to\none, she will notice that if she can find a best reason to pick a\nbridge, you can anticipate that same reason and then avoid her.\n\nWe know from experience that, in situations such as this, people do\nnot usually stand and dither in circles forever. As we\u2019ll see\nlater, there is a unique best solution available to each\nplayer. However, until the 1940s neither philosophers nor economists\nknew how to find it mathematically. As a result, economists were\nforced to treat non-parametric influences as if they were\ncomplications on parametric ones. This is likely to strike the reader\nas odd, since, as our example of the bridge-crossing problem was meant\nto show, non-parametric features are often fundamental features of\ndecision-making problems. Part of the explanation for game\ntheory\u2019s relatively late entry into the field lies in the\nproblems with which economists had historically been concerned.\nClassical economists, such as Adam Smith and David Ricardo, were\nmainly interested in the question of how agents in very large\nmarkets\u2014whole nations\u2014could interact so as to bring about\nmaximum monetary wealth for themselves. Smith\u2019s basic insight,\nthat efficiency is best maximized by agents first differentiating\ntheir potential contributions and then freely seeking mutually\nadvantageous bargains, was mathematically verified in the twentieth\ncentury. However, the demonstration of this fact applies only in\nconditions of \u2018perfect competition,\u2019 that is, when\nindividuals or firms face no costs of entry or exit into markets, when\nthere are no economies of scale, and when no agents\u2019 actions\nhave unintended side-effects on other agents\u2019 well-being.\nEconomists always recognized that this set of assumptions is purely an\nidealization for purposes of analysis, not a possible state of affairs\nanyone could try (or should want to try) to institutionally establish.\nBut until the mathematics of game theory matured near the end of the\n1970s, economists had to hope that the more closely a market\napproximates perfect competition, the more efficient it will\nbe. No such hope, however, can be mathematically or logically\njustified in general; indeed, as a strict generalization the\nassumption was shown to be false as far back as the 1950s.\n\nThis article is not about the foundations of economics, but it is\nimportant for understanding the origins and scope of game theory to\nknow that perfectly competitive markets have built into them a feature\nthat renders them susceptible to parametric analysis. Because agents\nface no entry costs to markets, they will open shop in any given\nmarket until competition drives all profits to zero. This implies that\nif production costs are fixed and demand is exogenous, then agents\nhave no options about how much to produce if they are trying to\nmaximize the differences between their costs and their revenues. These\nproduction levels can be determined separately for each agent, so none\nneed pay attention to what the others are doing; each agent treats her\ncounterparts as passive features of the environment. The other kind of\nsituation to which classical economic analysis can be applied without\nrecourse to game theory is that of a monopoly facing many customers.\nHere, as long as no customer has a share of demand large enough to\nexert strategic leverage, non-parametric considerations drop out and\nthe firm\u2019s task is only to identify the combination of price and\nproduction quantity at which it maximizes profit. However, both\nperfect and monopolistic competition are very special and unusual\nmarket arrangements. Prior to the advent of game theory, therefore,\neconomists were severely limited in the class of circumstances to\nwhich they could straightforwardly apply their models.\n\nPhilosophers share with economists a professional interest in the\nconditions and techniques for the maximization of welfare. In\naddition, philosophers have a special concern with the logical\njustification of actions, and often actions are justified by reference\nto their expected outcomes. (One tradition in moral philosophy,\nutilitarianism, is based on the idea that all morally significant\nactions are best justified in this way.) Without game theory, both of\nthese problems resist analysis wherever non-parametric aspects are\nrelevant. We will demonstrate this shortly by reference to the most\nfamous (though not the most typical) game, the so-called\nPrisoner\u2019s Dilemma, and to other, more typical, games.\nIn doing this, we will need to introduce, define and illustrate the\nbasic elements and techniques of game theory.\n2. Basic Elements and Assumptions of Game Theory\n2.1 Utility\n\nAn economic agent is, by definition, an entity with\npreferences. Game theorists, like economists and philosophers\nwho study practical choice, describe these by means of an abstract\nconcept called utility. This refers to some ranking, on some\nspecified scale, of the subjective welfare or change in subjective\nwelfare that an agent derives from an event. By \u2018welfare\u2019\nwe refer to some normative index of relative alignment between states\nof the world and agents\u2019 valuations of the states in question,\njustified by reference to some background framework. For example, we\nmight evaluate the relative welfare of countries (which we might model\nas agents for some purposes) by reference to their per capita incomes,\nand we might evaluate the relative welfare of an animal, in the\ncontext of predicting and explaining its behavioral dispositions, by\nreference to its expected evolutionary fitness. In the case of people,\nit is most typical in economics and applications of game theory to\nevaluate their relative welfare by reference to their own implicit or\nexplicit judgments of it. This is why we referred above to\nsubjective welfare. Consider a person who adores the taste of\npickles but dislikes onions. She might be said to associate higher\nutility with states of the world in which, all else being equal, she\nconsumes more pickles and fewer onions than with states in which she\nconsumes more onions and fewer pickles. Examples of this kind suggest\nthat \u2018utility\u2019 denotes a measure of subjective\npsychological fulfillment, and this is indeed how the concept\nwas originally interpreted by economists and philosophers influenced\nby the utilitarianism of Jeremy Bentham. However, economists in the\nearly 20th century recognized increasingly clearly that their main\ninterest was in the market property of decreasing marginal demand,\nregardless of whether that was produced by satiated individual\nconsumers or by some other factors. In the 1930s this motivation of\neconomists fit comfortably with the dominance of behaviourism and\nradical empiricism in psychology and in the philosophy of science\nrespectively. Behaviourists and radical empiricists objected to the\ntheoretical use of such unobservable entities as \u2018psychological\nfulfillment quotients.\u2019 The intellectual climate was thus\nreceptive to the efforts of the economist Paul Samuelson\n (1938)\n to redefine utility in such a way that it becomes a purely technical\nconcept rather than one rooted in speculative psychology. Since\nSamuelson\u2019s redefinition became standard in the 1950s, when we\nsay that an agent acts so as to maximize her utility, we mean by\n\u2018utility\u2019 simply whatever it is that the agent\u2019s\nbehavior suggests her to consistently act so as to make more probable.\nIf this looks circular to you, it should: theorists who follow\nSamuelson intend the statement \u2018agents act so as to\nmaximize their utility\u2019 as a tautology, where an\n\u2018(economic) agent\u2019 is any entity that can be accurately\ndescribed as acting to maximize a utility function, an\n\u2018action\u2019 is any utility-maximizing selection from a set of\npossible alternatives, and a\u2018utility function\u2019 is what an\neconomic agent maximizes. Like other tautologies occurring in the\nfoundations of scientific theories, this interlocking (recursive)\nsystem of definitions is useful not in itself, but because it helps to\nfix our contexts of inquiry.\n\nThough the behaviourism of the 1930s has since been displaced by\nwidespread interest in cognitive processes, many theorists continue to\nfollow Samuelson\u2019s way of understanding utility because they\nthink it important that game theory apply to any kind of\nagent\u2014a person, a bear, a bee, a firm or a country\u2014and not\njust to agents with human minds. When such theorists say that agents\nact so as to maximize their utility, they want this to be part of the\ndefinition of what it is to be an agent, not an empirical\nclaim about possible inner states and motivations. Samuelson\u2019s\nconception of utility, defined by way of Revealed Preference\nTheory (RPT) introduced in his classic paper\n (Samuelson (1938))\n satisfies this demand.\n\nEconomists and others who interpret game theory in terms of RPT should\nnot think of game theory as an empirical account of the motivations of\nsome flesh-and-blood actors (such as actual people). Rather, they\nshould regard game theory as part of the body of mathematics that is\nused to model those entities who consistently select elements from\nmutually exclusive action sets, resulting in patterns of choices,\nwhich, allowing for some stochasticity and noise, can be statistically\nmodeled as maximization of utility functions. On this interpretation,\ngame theory could not be refuted by any empirical observations, since\nit is not an empirical theory in the first place. Of course,\nobservation and experience could lead someone favoring this\ninterpretation to conclude that game theory is of little help\nin describing actual human behavior.\n\nSome other theorists understand the point of game theory differently.\nThey view game theory as providing an explanatory account of actual\nhuman strategic reasoning processes. For this idea to be applicable,\nwe must suppose that agents at least sometimes do what they do in\nnon-parametric settings because game-theoretic logic\nrecommends certain actions as the \u2018rational\u2019 ones. Such an\nunderstanding of game theory incorporates a normative aspect,\nsince \u2018rationality\u2019 is taken to denote a property that an\nagent should at least generally want to have. These two very general\nways of thinking about the possible uses of game theory are compatible\nwith the tautological interpretation of utility maximization. The\nphilosophical difference is not idle from the perspective of the\nworking game theorist, however. As we will see in a later section,\nthose who hope to use game theory to explain strategic\nreasoning, as opposed to merely strategic behavior,\nface some special philosophical and practical problems.\n\nSince game theory is a technology for formal modeling, we must have a\ndevice for thinking of utility maximization in mathematical terms.\nSuch a device is called a utility function. We will introduce\nthe general idea of a utility function through the special case of an\nordinal utility function. (Later, we will encounter utility\nfunctions that incorporate more information.) The utility-map for an\nagent is called a \u2018function\u2019 because it maps ordered\npreferences onto the real numbers. Suppose that agent \\(x\\)\nprefers bundle \\(a\\) to bundle \\(b\\) and bundle \\(b\\) to bundle \\(c\\).\nWe then map these onto a list of numbers, where the function maps the\nhighest-ranked bundle onto the largest number in the list, the\nsecond-highest-ranked bundle onto the next-largest number in the list,\nand so on, thus: \n\\[\\begin{align}\n\\text{bundle } a &\\gg 3 \\\\\n\\text{bundle } b &\\gg 2 \\\\\n\\text{bundle } c &\\gg 1\n\\end{align}\\]\n\n\nThe only property mapped by this function is order. The\nmagnitudes of the numbers are irrelevant; that is, it must not be\ninferred that \\(x\\) gets 3 times as much utility from bundle \\(a\\) as\nshe gets from bundle \\(c\\). Thus we could represent exactly the\nsame utility function as that above by  \n\\[\\begin{align}\n\\text{bundle } a &\\gg 7,326 \\\\\n\\text{bundle } b &\\gg 12.6 \\\\\n\\text{bundle } c &\\gg -1,000,000\n\\end{align}\\]\n\n\nThe numbers featuring in an ordinal utility function are thus not\nmeasuring any quantity of anything. A utility-function in\nwhich magnitudes do matter is called \u2018cardinal\u2019.\nWhenever someone refers to a utility function without specifying which\nkind is meant, you should assume that it\u2019s ordinal. These are\nthe sorts we\u2019ll need for the first set of games we\u2019ll\nexamine. Later, when we come to seeing how to solve games that involve\n(ex ante) uncertainty\u2014our river-crossing game from Part\n1 above, for example\u2014we\u2019ll need to build cardinal utility\nfunctions. The technique for doing this was given by\n von Neumann & Morgenstern (1944),\n and was an essential aspect of their invention of game theory. For\nthe moment, however, we will need only ordinal functions.\n2.2 Games and Rationality\n\nAll situations in which at least one agent can only act to maximize\nher utility through anticipating (either consciously, or just\nimplicitly in his behavior) the responses to her actions by one or\nmore other agents is called a game. Agents involved in games\nare referred to as players. If all agents have optimal\nactions regardless of what the others do, as in purely parametric\nsituations or conditions of monopoly or perfect competition (see\n Section 1\n above) we can model this without appeal to game theory; otherwise, we\nneed it.\n\nGame theorists assume that players have sets of capacities that are\ntypically referred to in the literature of economics as comprising\n\u2018rationality\u2019. Usually this is formulated by simple\nstatements such as \u2018it is assumed that players are\nrational\u2019. In literature critical of economics in general, or of\nthe importation of game theory into humanistic disciplines, this kind\nof rhetoric has increasingly become a magnet for attack. There is a\ndense and intricate web of connections associated with\n\u2018rationality\u2019 in the Western cultural tradition, and\nhistorically the word was often used to normatively marginalize\ncharacteristics as normal and important as emotion, femininity and\nempathy. Game theorists\u2019 use of the concept need not, and\ngenerally does not, implicate such ideology. For present purposes we\nwill use \u2018economic rationality\u2019 as a strictly technical,\nnot normative, term to refer to a narrow and specific set of\nrestrictions on preferences that are shared by von Neumann and\nMorgenstern\u2019s original version of game theory, and RPT.\nEconomists use a second, equally important (to them) concept of\nrationality when they are modeling markets, which they call\n\u2018rational expectations\u2019. In this phrase,\n\u2018rationality\u2019 refers not to restrictions on preferences\nbut to non-restrictions on information processing: rational\nexpectations are idealized beliefs that reflect statistically\naccurately weighted use of all information available to an agent. The\nreader should note that these two uses of one word within the same\ndiscipline are technically unconnected. Furthermore, original RPT has\nbeen specified over the years by several different sets of axioms for\ndifferent modeling purposes. Once we decide to treat rationality as a\ntechnical concept, each time we adjust the axioms we effectively\nmodify the concept. Consequently, in any discussion involving\neconomists and philosophers together, we can find ourselves in a\nsituation where different participants use the same word to refer to\nsomething different. For readers new to economics, game theory,\ndecision theory and the philosophy of action, this situation naturally\npresents a challenge.\n\nIn this article, \u2018economic rationality\u2019 will be used in\nthe technical sense shared within game theory, microeconomics and\nformal decision theory, as follows. An economically rational player is\none who can (i) assess outcomes, in the sense of rank-ordering them\nwith respect to their contributions to her welfare; (ii) calculate\npaths to outcomes, in the sense of recognizing which sequences of\nactions are probabilistically associated with which outcomes; and\n(iii) select actions from sets of alternatives (which we\u2019ll\ndescribe as \u2018choosing\u2019 actions) that yield her\nmost-preferred outcomes, given the actions of the other players. We\nmight summarize the intuition behind all this as follows: an entity is\nusefully modeled as an economically rational agent to the extent that\nit has alternatives, and chooses from amongst these in a way that is\nmotivated, at least more often than not, by what seems best for its\npurposes. For readers who are antecedently familiar with the work of\nthe philosopher Daniel Dennett, we could equate the idea of an\neconomically rational agent with the kind of entity Dennett\ncharacterizes as intentional, and then say that we can\nusefully predict an economically rational agent\u2019s behavior from\n\u2018the intentional stance\u2019. As will be discussed later, the\nintentional stance can be made precise for application to\nquantitatively specified choices by drawing, sometimes with special\nmodifications, on the subjective rationality axioms of\n Savage (1954)\n (Harrison and Ross forthcoming).\n\nEconomic rationality might in some cases be satisfied by internal\ncomputations performed by an agent, and she might or might not be\naware of computing or having computed its conditions and implications.\nIn other cases, economic rationality might simply be embodied in\nbehavioral dispositions built by natural, cultural or market\nselection. In particular, in calling an action \u2018chosen\u2019 we\nimply no necessary deliberation, conscious or otherwise. We mean\nmerely that the action was taken when an alternative action was\navailable, in some sense of \u2018available\u2019 normally\nestablished by the context of the particular analysis.\n(\u2018Available\u2019, as used by game theorists and economists,\nshould never be read as if it meant merely\n\u2018metaphysically\u2019 or \u2018logically\u2019 available; it\nis almost always pragmatic, contextual and revisable by more refined\nmodeling.)\n\nEach player in a game faces a choice among two or more possible\nstrategies. A strategy is a predetermined \u2018program of\nplay\u2019 that tells her what actions to take in response to\nevery possible strategy other players might use. The\nsignificance of the italicized phrase here will become clear when we\ntake up some sample games below.\n\nA crucial aspect of the specification of a game involves the\ninformation that players have when they choose strategies. The\nsimplest games (from the perspective of logical structure) are those\nin which agents have perfect information, meaning that at\nevery point where each agent\u2019s strategy tells her to take an\naction, she knows everything that has happened in the game up to that\npoint. A board-game of sequential moves in which both players watch\nall the action (and know the rules in common), such as chess, is an\ninstance of such a game. By contrast, the example of the\nbridge-crossing game from Section 1 above illustrates a game of\nimperfect information, since the fugitive must choose a\nbridge to cross without knowing the bridge at which the pursuer has\nchosen to wait, and the pursuer similarly makes her decision in\nignorance of the choices of her quarry. Since game theory is about\neconomically rational action given the strategically significant\nactions of others, it should not surprise you to be told that what\nagents in games believe, or fail to believe, about each others\u2019\nactions makes a considerable difference to the logic of our analyses,\nas we will see.\n2.3 Trees and Matrices\n\nThe difference between games of perfect and of imperfect information\nis related to (though certainly not identical with!) a distinction\nbetween ways of representing games that is based on order\nof play. Let us begin by distinguishing between sequential-move\nand simultaneous-move games in terms of information. It is natural, as\na first approximation, to think of sequential-move games as being ones\nin which players choose their strategies one after the other, and of\nsimultaneous-move games as ones in which players choose their\nstrategies at the same time. This isn\u2019t quite right, however,\nbecause what is of strategic importance is not the temporal\norder of events per se, but whether and when players know\nabout other players\u2019 actions relative to having to choose\ntheir own. For example, if two competing businesses are both planning\nmarketing campaigns, one might commit to its strategy months before\nthe other does; but if neither knows what the other has committed to\nor will commit to when they make their decisions, this is a\nsimultaneous-move game. Chess, by contrast, is normally played as a\nsequential-move game: you see what your opponent has done before\nchoosing your own next action. (Chess can be turned into a\nsimultaneous-move game if the players each call moves on a common\nboard while isolated from one another; but this is a very different\ngame from conventional chess.)\n\nIt was said above that the distinction between sequential-move and\nsimultaneous-move games is not identical to the distinction between\nperfect-information and imperfect-information games. Explaining why\nthis is so is a good way of establishing full understanding of both\nsets of concepts. As simultaneous-move games were characterized in the\nprevious paragraph, it must be true that all simultaneous-move games\nare games of imperfect information. However, some games may contain\nmixes of sequential and simultaneous moves. For example, two firms\nmight commit to their marketing strategies independently and in\nsecrecy from one another, but thereafter engage in pricing competition\nin full view of one another. If the optimal marketing strategies were\npartially or wholly dependent on what was expected to happen in the\nsubsequent pricing game, then the two stages would need to be analyzed\nas a single game, in which a stage of sequential play followed a stage\nof simultaneous play. Whole games that involve mixed stages of this\nsort are games of imperfect information, however temporally staged\nthey might be. Games of perfect information (as the name implies)\ndenote cases where no moves are simultaneous (and where no\nplayer ever forgets what has gone before).\n\nAs previously noted, games of perfect information are the (logically)\nsimplest sorts of games. This is so because in such games (as long as\nthe games are finite, that is, terminate after a known number of\nactions) players and analysts can use a straightforward procedure for\npredicting outcomes. A player in such a game chooses her first action\nby considering each series of responses and counter-responses that\nwill result from each action open to her. She then asks herself which\nof the available final outcomes brings her the highest utility, and\nchooses the action that starts the chain leading to this outcome. This\nprocess is called backward induction (because the reasoning\nworks backwards from eventual outcomes to present choice\nproblems).\n\nThere will be much more to be said about backward induction and its\nproperties in a later section (when we come to discuss equilibrium and\nequilibrium selection). For now, it has been described just so we can\nuse it to introduce one of the two types of mathematical objects used\nto represent games: game trees. A game tree is an example of\nwhat mathematicians call a directed graph. That is, it is a\nset of connected nodes in which the overall graph has a direction. We\ncan draw trees from the top of the page to the bottom, or from left to\nright. In the first case, nodes at the top of the page are interpreted\nas coming earlier in the sequence of actions. In the case of a tree\ndrawn from left to right, leftward nodes are prior in the sequence to\nrightward ones. An unlabelled tree has a structure of the following\nsort:\n\n\n\nFigure 1\n\n\nThe point of representing games using trees can best be grasped by\nvisualizing the use of them in supporting backward-induction\nreasoning. Just imagine the player (or analyst) beginning at the end\nof the tree, where outcomes are displayed, and then working backwards\nfrom these, looking for sets of strategies that describe paths leading\nto them. Since a player\u2019s utility function indicates which\noutcomes she prefers to which, we also know which paths she will\nprefer. Of course, not all paths will be possible because the other\nplayer has a role in selecting paths too, and won\u2019t take actions\nthat lead to less preferred outcomes for her. We will present some\nexamples of this interactive path selection, and detailed techniques\nfor reasoning through these examples, after we have described a\nsituation we can use a tree to model.\n\nTrees are used to represent sequential games, because they\nshow the order in which actions are taken by the players. However,\ngames are sometimes represented on matrices rather than\ntrees. This is the second type of mathematical object used to\nrepresent games. Matrices, unlike trees, simply show the outcomes,\nrepresented in terms of the players\u2019 utility functions, for\nevery possible combination of strategies the players might use. For\nexample, it makes sense to display the river-crossing game from\n Section 1\n on a matrix, since in that game both the fugitive and the hunter have\njust one move each, and each chooses their move in ignorance of what\nthe other has decided to do. Here, then, is part of the\nmatrix:\n\n\n\n\nHunter\n\nSafe Bridge\nRocky Bridge\nCobra Bridge\n\nFugitive\nSafe Bridge\n0,1\n1,0\n1,0\n\nRocky Bridge\n?\n0,1\n?\n\nCobra Bridge\n?\n?\n0,1\n\n\nFigure 2\n\n\nThe fugitive\u2019s three possible strategies\u2014cross at the safe\nbridge, risk the rocks, or risk the cobras\u2014form the rows of the\nmatrix. Similarly, the hunter\u2019s three possible\nstrategies\u2014waiting at the safe bridge, waiting at the rocky\nbridge and waiting at the cobra bridge\u2014form the columns of the\nmatrix. Each cell of the matrix shows\u2014or, rather would\nshow if our matrix was complete\u2014an outcome defined in\nterms of the players\u2019 payoffs. A player\u2019s payoff\nis simply the number assigned by her ordinal utility function to the\nstate of affairs corresponding to the outcome in question. For each\noutcome, Row\u2019s payoff is always listed first, followed by\nColumn\u2019s. Thus, for example, the upper left-hand corner above\nshows that when the fugitive crosses at the safe bridge and the hunter\nis waiting there, the fugitive gets a payoff of 0 and the hunter gets\na payoff of 1. We interpret these by reference to the two\nplayers\u2019 utility functions, which in this game are very simple.\nIf the fugitive gets safely across the river he receives a payoff of\n1; if he doesn\u2019t he gets 0. If the fugitive doesn\u2019t make\nit, either because he\u2019s shot by the hunter or hit by a rock or\nbitten by a cobra, then the hunter gets a payoff of 1 and the fugitive\ngets a payoff of 0.\n\nWe\u2019ll briefly explain the parts of the matrix that have been\nfilled in, and then say why we can\u2019t yet complete the rest.\nWhenever the hunter waits at the bridge chosen by the fugitive, the\nfugitive is shot. These outcomes all deliver the payoff vector (0, 1).\nYou can find them descending diagonally across the matrix above from\nthe upper left-hand corner. Whenever the fugitive chooses the safe\nbridge but the hunter waits at another, the fugitive gets safely\nacross, yielding the payoff vector (1, 0). These two outcomes are\nshown in the second two cells of the top row. All of the other cells\nare marked, for now, with question marks. Why? The problem\nhere is that if the fugitive crosses at either the rocky bridge or the\ncobra bridge, he introduces parametric factors into the game. In these\ncases, he takes on some risk of getting killed, and so producing the\npayoff vector (0, 1), that is independent of anything the hunter does.\nWe don\u2019t yet have enough concepts introduced to be able to show\nhow to represent these outcomes in terms of utility\nfunctions\u2014but by the time we\u2019re finished we will, and this\nwill provide the key to solving our puzzle from\n Section 1.\n\nMatrix games are referred to as \u2018normal-form\u2019 or\n\u2018strategic-form\u2019 games, and games as trees are referred to\nas \u2018extensive-form\u2019 games. The two sorts of games are not\nequivalent, because extensive-form games contain\ninformation\u2014about sequences of play and players\u2019 levels of\ninformation about the game structure\u2014that strategic-form games\ndo not. In general, a strategic-form game could represent any one of\nseveral extensive-form games, so a strategic-form game is best thought\nof as being a set of extensive-form games. When order of play\nis irrelevant to a game\u2019s outcome, then you should study its\nstrategic form, since it\u2019s the whole set you want to know about.\nWhere order of play is relevant, the extensive form\nmust be specified or your conclusions will be unreliable.\n2.4 The Prisoner\u2019s Dilemma as an Example of Strategic-Form vs. Extensive-Form Representation\n\nThe distinctions described above are difficult to fully grasp if all\none has to go on are abstract descriptions. They\u2019re best\nillustrated by means of an example. For this purpose, we\u2019ll use\nthe most famous of all games: the Prisoner\u2019s Dilemma. It in fact\ngives the logic of the problem faced by Cortez\u2019s and Henry\nV\u2019s soldiers (see\n Section 1 above),\n and by Hobbes\u2019s agents before they empower the tyrant. However,\nfor reasons which will become clear a bit later, you should not take\nthe PD as a typical game; it isn\u2019t. We use it as an\nextended example here only because it\u2019s particularly helpful for\nillustrating the relationship between strategic-form and\nextensive-form games (and later, for illustrating the relationships\nbetween one-shot and repeated games; see\n Section 4\n below). \n\nThe name of the Prisoner\u2019s Dilemma game is derived from the\nfollowing situation typically used to exemplify it. Suppose that the\npolice have arrested two people whom they know have committed an armed\nrobbery together. Unfortunately, they lack enough admissible evidence\nto get a jury to convict. They do, however, have enough\nevidence to send each prisoner away for two years for theft of the\ngetaway car. The chief inspector now makes the following offer to each\nprisoner: If you will confess to the robbery, implicating your\npartner, and she does not also confess, then you\u2019ll go free and\nshe\u2019ll get ten years. If you both confess, you\u2019ll each get\n5 years. If neither of you confess, then you\u2019ll each get two\nyears for the auto theft.\n\nOur first step in modeling the two prisoners\u2019 situation as a\ngame is to represent it in terms of utility functions. Following the\nusual convention, let us name the prisoners \u2018Player I\u2019 and\n\u2018Player II\u2019. Both Player I\u2019s and Player II\u2019s\nordinal utility functions are identical: \n\\[\\begin{align}\n\\text{Go free } &\\gg 4 \\\\\n2 \\text{ years } &\\gg 3 \\\\\n5 \\text{ years } &\\gg 2 \\\\\n10 \\text{ years } &\\gg 0\n\\end{align}\\]\n\n\nThe numbers in the function above are now used to express each\nplayer\u2019s payoffs in the various outcomes possible in\nthe situation. We can represent the problem faced by both of them on a\nsingle matrix that captures the way in which their separate choices\ninteract; this is the strategic form of their game:\n\n\n\n\nPlayer II\n\nConfess\nRefuse\n\nPlayer I\nConfess\n2,2\n4,0\n\nRefuse\n0,4\n3,3 \n\n\nFigure 3\n\n\nEach cell of the matrix gives the payoffs to both players for each\ncombination of actions. Player I\u2019s payoff appears as the first\nnumber of each pair, Player II\u2019s as the second. So, if both\nplayers confess then they each get a payoff of 2 (5 years in prison\neach). This appears in the upper-left cell. If neither of them\nconfess, they each get a payoff of 3 (2 years in prison each). This\nappears as the lower-right cell. If Player I confesses and Player II\ndoesn\u2019t then Player I gets a payoff of 4 (going free) and Player\nII gets a payoff of 0 (ten years in prison). This appears in the\nupper-right cell. The reverse situation, in which Player II confesses\nand Player I refuses, appears in the lower-left cell.\n\nEach player evaluates his or her two possible actions here by\ncomparing their personal payoffs in each column, since this shows you\nwhich of their actions is preferable, just to themselves, for each\npossible action by their partner. So, observe: If Player II confesses\nthen Player I gets a payoff of 2 by confessing and a payoff of 0 by\nrefusing. If Player II refuses, then Player I gets a payoff of 4 by\nconfessing and a payoff of 3 by refusing. Therefore, Player I is\nbetter off confessing regardless of what Player II does. Player II,\nmeanwhile, evaluates her actions by comparing her payoffs down each\nrow, and she comes to exactly the same conclusion that Player I does.\nWherever one action for a player is superior to her other actions for\neach possible action by the opponent, we say that the first action\nstrictly dominates the second one. In the PD, then,\nconfessing strictly dominates refusing for both players. Both players\nknow this about each other, thus entirely eliminating any temptation\nto depart from the strictly dominated path. Thus both players will\nconfess, and both will go to prison for 5 years.\n\nThe players, and analysts, can predict this outcome using a mechanical\nprocedure, known as iterated elimination of strictly dominated\nstrategies. Player 1 can see by examining the matrix that his payoffs\nin each cell of the top row are higher than his payoffs in each\ncorresponding cell of the bottom row. Therefore, it can never be\nutility-maximizing for him to play his bottom-row strategy, viz.,\nrefusing to confess, regardless of what Player II does. Since\nPlayer I\u2019s bottom-row strategy will never be played, we can\nsimply delete the bottom row from the matrix. Now it is\nobvious that Player II will not refuse to confess, since her payoff\nfrom confessing in the two cells that remain is higher than her payoff\nfrom refusing. So, once again, we can delete the one-cell column on\nthe right from the game. We now have only one cell remaining, that\ncorresponding to the outcome brought about by mutual confession. Since\nthe reasoning that led us to delete all other possible outcomes\ndepended at each step only on the premise that both players are\neconomically rational\u2014that is, will choose strategies that lead\nto higher payoffs over strategies that lead to lower ones\u2014there\nare strong grounds for viewing joint confession as the\nsolution to the game, the outcome on which its play\nmust converge to the extent that economic rationality\ncorrectly models the behavior of the players. You should note that the\norder in which strictly dominated rows and columns are deleted\ndoesn\u2019t matter. Had we begun by deleting the right-hand column\nand then deleted the bottom row, we would have arrived at the same\nsolution.\n\nIt\u2019s been said a couple of times that the PD is not a typical\ngame in many respects. One of these respects is that all its rows and\ncolumns are either strictly dominated or strictly dominant. In any\nstrategic-form game where this is true, iterated elimination of\nstrictly dominated strategies is guaranteed to yield a unique\nsolution. Later, however, we will see that for many games this\ncondition does not apply, and then our analytic task is less\nstraightforward.\n\nThe reader will probably have noticed something disturbing about the\noutcome of the PD. Had both players refused to confess, they\u2019d\nhave arrived at the lower-right outcome in which they each go to\nprison for only 2 years, thereby both earning higher utility\nthan either receives when both confess. This is the most important\nfact about the PD, and its significance for game theory is quite\ngeneral. We\u2019ll therefore return to it below when we discuss\nequilibrium concepts in game theory. For now, however, let us stay\nwith our use of this particular game to illustrate the difference\nbetween strategic and extensive forms.\n\nWhen people introduce the PD into popular discussions, one will often\nhear them say that the police inspector must lock his prisoners into\nseparate rooms so that they can\u2019t communicate with one another.\nThe reasoning behind this idea seems obvious: if the players could\ncommunicate, they\u2019d surely see that they\u2019re each better\noff if both refuse, and could make an agreement to do so, no? This,\none presumes, would remove each player\u2019s conviction that he or\nshe must confess because they\u2019ll otherwise be sold up the river\nby their partner. In fact, however, this intuition is misleading and\nits conclusion is false.\n\nWhen we represent the PD as a strategic-form game, we implicitly\nassume that the prisoners can\u2019t attempt collusive agreement\nsince they choose their actions simultaneously. In this case,\nagreement before the fact can\u2019t help. If Player I is convinced\nthat his partner will stick to the bargain then he can seize the\nopportunity to go scot-free by confessing. Of course, he realizes that\nthe same temptation will occur to Player II; but in that case he again\nwants to make sure he confesses, as this is his only means of avoiding\nhis worst outcome. The prisoners\u2019 agreement comes to naught\nbecause they have no way of enforcing it; their promises to each other\nconstitute what game theorists call \u2018cheap talk\u2019.\n\nBut now suppose that the prisoners do not move\nsimultaneously. That is, suppose that Player II can choose\nafter observing Player I\u2019s action. This is the sort of\nsituation that people who think non-communication important must have\nin mind. Now Player II will be able to see that Player I has remained\nsteadfast when it comes to her choice, and she need not be concerned\nabout being suckered. However, this doesn\u2019t change anything, a\npoint that is best made by re-representing the game in extensive form.\nThis gives us our opportunity to introduce game-trees and the method\nof analysis appropriate to them.\n\nFirst, however, here are definitions of some concepts that will be\nhelpful in analyzing game-trees:\n\nNode: a point at which a player chooses an action.\n\n\nInitial node: the point at which the first action in the game\noccurs.\n\nTerminal node: any node which, if reached, ends the game.\nEach terminal node corresponds to an outcome.\n\nSubgame: any connected set of nodes and branches descending\nuniquely from one node.\n\nPayoff: an ordinal utility number assigned to a player at an\noutcome.\n\nOutcome: an assignment of a set of payoffs, one to each\nplayer in the game.\n\nStrategy: a program instructing a player which action to take\nat every node in the tree where she could possibly be called on to\nmake a choice.\n\n\nThese quick definitions may not mean very much to you until you follow\nthem being put to use in our analyses of trees below. It will probably\nbe best if you scroll back and forth between them and the examples as\nwe work through them. By the time you understand each example,\nyou\u2019ll find the concepts and their definitions natural and\nintuitive. \n\nTo make this exercise maximally instructive, let\u2019s suppose that\nPlayers I and II have studied the matrix above and, seeing that\nthey\u2019re both better off in the outcome represented by the\nlower-right cell, have formed an agreement to cooperate. Player I is\nto commit to refusal first, after which Player II will reciprocate\nwhen the police ask for her choice. We will refer to a strategy of\nkeeping the agreement as \u2018cooperation\u2019, and will denote it\nin the tree below with \u2018C\u2019. We will refer to a strategy of\nbreaking the agreement as \u2018defection\u2019, and will denote it\non the tree below with \u2018D\u2019. Each node is numbered 1, 2, 3,\n\u2026 , from top to bottom, for ease of reference in discussion.\nHere, then, is the tree:\n\n\n\nFigure 4\n\n\nLook first at each of the terminal nodes (those along the bottom).\nThese represent possible outcomes. Each is identified with an\nassignment of payoffs, just as in the strategic-form game, with Player\nI\u2019s payoff appearing first in each set and Player II\u2019s\nappearing second. Each of the structures descending from the nodes 1,\n2 and 3 respectively is a subgame. We begin our backward-induction\nanalysis\u2014using a technique called Zermelo\u2019s\nalgorithm\u2014with the sub-games that arise last in the\nsequence of play. If the subgame descending from node 3 is played,\nthen Player II will face a choice between a payoff of 4 and a payoff\nof 3. (Consult the second number, representing her payoff, in each set\nat a terminal node descending from node 3.) II earns her higher payoff\nby playing D. We may therefore replace the entire subgame with an\nassignment of the payoff (0,4) directly to node 3, since this is the\noutcome that will be realized if the game reaches that node. Now\nconsider the subgame descending from node 2. Here, II faces a choice\nbetween a payoff of 2 and one of 0. She obtains her higher payoff, 2,\nby playing D. We may therefore assign the payoff (2,2) directly to\nnode 2. Now we move to the subgame descending from node 1. (This\nsubgame is, of course, identical to the whole game; all games are\nsubgames of themselves.) Player I now faces a choice between outcomes\n(2,2) and (0,4). Consulting the first numbers in each of these sets,\nhe sees that he gets his higher payoff\u20142\u2014by playing D. D\nis, of course, the option of confessing. So Player I confesses, and\nthen Player II also confesses, yielding the same outcome as in the\nstrategic-form representation.\n\nWhat has happened here intuitively is that Player I realizes that if\nhe plays C (refuse to confess) at node 1, then Player II will be able\nto maximize her utility by suckering him and playing D. (On the tree,\nthis happens at node 3.) This leaves Player I with a payoff of 0 (ten\nyears in prison), which he can avoid only by playing D to begin with.\nHe therefore defects from the agreement.\n\nWe have thus seen that in the case of the Prisoner\u2019s Dilemma,\nthe simultaneous and sequential versions yield the same outcome. This\nwill often not be true of other games, however. Furthermore, only\nfinite extensive-form (sequential) games of perfect information can be\nsolved using Zermelo\u2019s algorithm.\n\nAs noted earlier in this section, sometimes we must represent\nsimultaneous moves within games that are otherwise\nsequential. (In all such cases the game as a whole will be one of\nimperfect information, so we won\u2019t be able to solve it using\nZermelo\u2019s algorithm.) We represent such games using the device\nof information sets. Consider the following tree:\n\n\n\nFigure 5\n\n\nThe oval drawn around nodes \\(b\\) and \\(c\\) indicates that they lie\nwithin a common information set. This means that at these nodes\nplayers cannot infer back up the path from whence they came; Player II\ndoes not know, in choosing her strategy, whether she is at \\(b\\) or\n\\(c\\). (For this reason, what properly bear numbers in extensive-form\ngames are information sets, conceived as \u2018action points\u2019,\nrather than nodes themselves; this is why the nodes inside the oval\nare labelled with letters rather than numbers.) Put another way,\nPlayer II, when choosing, does not know what Player I has done at node\n\\(a\\). But you will recall from earlier in this section that this is\njust what defines two moves as simultaneous. We can thus see that the\nmethod of representing games as trees is entirely general. If no node\nafter the initial node is alone in an information set on its tree, so\nthat the game has only one subgame (itself), then the whole game is\none of simultaneous play. If at least one node shares its information\nset with another, while others are alone, the game involves both\nsimultaneous and sequential play, and so is still a game of imperfect\ninformation. Only if all information sets are inhabited by just one\nnode do we have a game of perfect information.\n2.5 Solution Concepts and Equilibria\n\nIn the Prisoner\u2019s Dilemma, the outcome we\u2019ve represented\nas (2,2), indicating mutual defection, was said to be the\n\u2018solution\u2019 to the game. Following the general practice in\neconomics, game theorists refer to the solutions of games as\nequilibria. Philosophically minded readers will want to pose\na conceptual question right here: What is \u2018equilibrated\u2019\nabout some game outcomes such that we are motivated to call them\n\u2018solutions\u2019? When we say that a physical system is in\nequilibrium, we mean that it is in a stable state, one in\nwhich all the causal forces internal to the system balance each other\nout and so leave it \u2018at rest\u2019 until and unless it is\nperturbed by the intervention of some exogenous (that is,\n\u2018external\u2019) force. This is what economists have\ntraditionally meant in talking about \u2018equilibria\u2019; they\nread economic systems as being networks of mutually constraining\n(often causal) relations, just like physical systems, and the\nequilibria of such systems are then their endogenously stable states.\n(Note that, in both physical and economic systems, endogenously stable\nstates might never be directly observed because the systems in\nquestion are never isolated from exogenous influences that move and\ndestabilize them. In both classical mechanics and in economics,\nequilibrium concepts are tools for analysis, not predictions\nof what we expect to observe.) As we will see in later sections, it is\npossible to maintain this understanding of equilibria in the case of\ngame theory. However, as we noted in Section 2.1, some people\ninterpret game theory as being an explanatory theory of strategic\nreasoning. For them, a solution to a game must be an outcome that a\nrational agent would predict using the mechanisms of rational\ncomputation alone. Such theorists face some puzzles about\nsolution concepts that are less important to the theorist who\nisn\u2019t trying to use game theory to under-write a general\nanalysis of rationality. The interest of philosophers in game theory\nis more often motivated by this ambition than is that of the economist\nor other scientist. \n\nIt\u2019s useful to start the discussion here from the case of the\nPrisoner\u2019s Dilemma because it\u2019s unusually simple from the\nperspective of the puzzles about solution concepts. What we referred\nto as its \u2018solution\u2019 is the unique Nash\nequilibrium of the game. (The \u2018Nash\u2019 here refers to\nJohn Nash, the Nobel Laureate mathematician who in\n Nash (1950)\n did most to extend and generalize von Neumann &\nMorgenstern\u2019s pioneering work.) Nash equilibrium (henceforth\n\u2018NE\u2019) applies (or fails to apply, as the case may be) to\nwhole sets of strategies, one for each player in a game. A\nset of strategies is a NE just in case no player could improve her\npayoff, given the strategies of all other players in the game, by\nchanging her strategy. Notice how closely this idea is related to the\nidea of strict dominance: no strategy could be a NE strategy if it is\nstrictly dominated. Therefore, if iterative elimination of strictly\ndominated strategies takes us to a unique outcome, we know that the\nvector of strategies that leads to it is the game\u2019s unique NE.\nNow, almost all theorists agree that avoidance of strictly dominated\nstrategies is a minimum requirement of economic rationality.\nA player who knowingly chooses a strictly dominated strategy directly\nviolates clause (iii) of the definition of economic agency as given in\n Section 2.2.\n This implies that if a game has an outcome that is a unique\nNE, as in the case of joint confession in the PD, that must be its\nunique solution. This is one of the most important respects in which\nthe PD is an \u2018easy\u2019 (and atypical) game.\n\nWe can specify one class of games in which NE is always not only\nnecessary but sufficient as a solution concept. These are\nfinite perfect-information games that are also zero-sum. A\nzero-sum game (in the case of a game involving just two players) is\none in which one player can only be made better off by making the\nother player worse off. (Tic-tac-toe is a simple example of such a\ngame: any move that brings one player closer to winning brings her\nopponent closer to losing, and vice-versa.) We can determine whether a\ngame is zero-sum by examining players\u2019 utility functions: in\nzero-sum games these will be mirror-images of each other, with one\nplayer\u2019s highly ranked outcomes being low-ranked for the other\nand vice-versa. In such a game, if I am playing a strategy such that,\ngiven your strategy, I can\u2019t do any better, and if you are\nalso playing such a strategy, then, since any change of\nstrategy by me would have to make you worse off and vice-versa, it\nfollows that our game can have no solution compatible with our mutual\neconomic rationality other than its unique NE. We can put this another\nway: in a zero-sum game, my playing a strategy that maximizes my\nminimum payoff if you play the best you can, and your simultaneously\ndoing the same thing, is just equivalent to our both playing\nour best strategies, so this pair of so-called \u2018maximin\u2019\nprocedures is guaranteed to find the unique solution to the game,\nwhich is its unique NE. (In tic-tac-toe, this is a draw. You\ncan\u2019t do any better than drawing, and neither can I, if both of\nus are trying to win and trying not to lose.)\n\nHowever, most games do not have this property. It won\u2019t be\npossible, in this one article, to enumerate all of the ways\nin which games can be problematic from the perspective of their\npossible solutions. (For one thing, it is highly unlikely that\ntheorists have yet discovered all of the possible problems.) However,\nwe can try to generalize the issues a bit.\n\nFirst, there is the problem that in most non-zero-sum games, there is\nmore than one NE, but not all NE look equally plausible as the\nsolutions upon which strategically alert players would hit. Consider\nthe strategic-form game below (taken from\n (Kreps 1990, p. 403)\n (and which we\u2019ll encounter again later under the name\n\u2018Hi-lo\u2019):\n\n\n\n\nII\n\n\\(t_1\\)\n\\(t_2\\)\n\nI\n\\(s_1\\)\n10,10\n0,0\n\n\\(s_2\\)\n0,0\n1,1 \n\n\nFigure 6\n\n\nThis game has two NE: \\(s_1\\)-\\(t_1\\) and \\(s_2\\)-\\(t_2\\). (Note that\nno rows or columns are strictly dominated here. But if Player I is\nplaying \\(s_1\\) then Player II can do no better than \\(t_1,\\) and\nvice-versa; and similarly for the \\(s_2\\)-\\(t_2\\) pair.) If NE is our\nonly solution concept, then we shall be forced to say that either of\nthese outcomes is equally persuasive as a solution. However, if game\ntheory is regarded as an explanatory and/or normative theory of\nstrategic reasoning, this seems to be leaving something out: surely\nsensible players with perfect information would converge on\n\\(s_1\\)-\\(t_1\\)? (Note that this is not like the situation in\nthe PD, where the socially superior situation is unachievable because\nit is not a NE. In the case of the game above, both players have every\nreason to try to converge on the NE in which they are better off.)\n\nThis illustrates the fact that NE is a relatively (logically)\nweak solution concept, often failing to predict intuitively\nsensible solutions because, if applied alone, it refuses to allow\nplayers to use principles of equilibrium selection that, if not\ndemanded by economic rationality\u2014or a more ambitious\nphilosopher\u2019s concept of rationality\u2014at least seem both\nsensible and computationally accessible. Consider another example from\n Kreps (1990),\n p. 397:\n\n\n\n\nII\n\n\\(t_1\\)\n\\(t_2\\)\n\nI\n\\(s_1\\)\n10,0\n5,2\n\n\\(s_2\\)\n10,1\n2,0 \n\n\nFigure 7\n\n\nHere, no strategy strictly dominates another. However, Player\nI\u2019s top row, \\(s_1,\\) weakly dominates \\(s_2,\\) since I\ndoes at least as well using \\(s_1\\) as \\(s_2\\) for any reply\nby Player II, and on one reply by II (\\(t_2\\)), I does better. So\nshould not the players (and the analyst) delete the weakly dominated\nrow \\(s_2\\)? When they do so, column \\(t_1\\) is then strictly\ndominated, and the NE \\(s_1\\)-\\(t_2\\) is selected as the unique\nsolution. However, as Kreps goes on to show using this example, the\nidea that weakly dominated strategies should be deleted just like\nstrict ones has odd consequences.\n Suppose\n we change the payoffs of the game just a bit, as follows:\n\n\n\n\nII\n\n\\(t_1\\)\n\\(t_2\\)\n\nI\n\\(s_1\\)\n10,10\n5,2\n\n\\(s_2\\)\n10,11\n2,0 \n\n\nFigure 8\n\n\n\\(s_2\\) is still weakly dominated as before; but of our two NE,\n\\(s_2\\)-\\(t_1\\) is now the most attractive for both players; so why\nshould the analyst eliminate its possibility? (Note that this game,\nagain, does not replicate the logic of the PD. There, it\nmakes sense to eliminate the most attractive outcome, joint refusal to\nconfess, because both players have incentives to unilaterally deviate\nfrom it, so it is not an NE. This is not true of \\(s_2\\)-\\(t_1\\) in\nthe present game. You should be starting to clearly see why we called\nthe PD game \u2018atypical\u2019.) The argument for\neliminating weakly dominated strategies is that Player 1 may be\nnervous, fearing that Player II is not completely sure to be\neconomically rational (or that Player II fears that Player I\nisn\u2019t completely reliably economically rational, or that Player\nII fears that Player I fears that Player II isn\u2019t completely\nreliably economically rational, and so on ad infinitum) and so might\nplay \\(t_2\\) with some positive probability. If the possibility of\ndepartures from reliable economic rationality is taken seriously, then\nwe have an argument for eliminating weakly dominated strategies:\nPlayer I thereby insures herself against her worst outcome,\n\\(s_2\\)-\\(t_2\\). Of course, she pays a cost for this insurance,\nreducing her expected payoff from 10 to 5. On the other hand, we might\nimagine that the players could communicate before playing the game and\nagree to coordinate on \\(s_2\\)-\\(t_1\\), thereby removing\nsome, most or all of the uncertainty that encourages elimination of\nthe weakly dominated row \\(s_1\\), and eliminating \\(s_1\\)-\\(t_2\\) as a\nviable solution instead!\n\nAny proposed principle for solving games that may have the effect of\neliminating one or more NE from consideration as solutions is referred\nto as a refinement of NE. In the case just discussed,\nelimination of weakly dominated strategies is one possible refinement,\nsince it refines away the NE \\(s_2\\)-\\(t_1\\), and correlation is\nanother, since it refines away the other NE, \\(s_1\\)-\\(t_2\\), instead.\nSo which refinement is more appropriate as a solution concept? People\nwho think of game theory as an explanatory and/or normative theory of\nstrategic rationality have generated a substantial literature in which\nthe merits and drawbacks of a large number of refinements are debated.\nIn principle, there seems to be no limit on the number of refinements\nthat could be considered, since there may also be no limits on the set\nof philosophical intuitions about what principles a rational agent\nmight or might not see fit to follow or to fear or hope that other\nplayers are following.\n\nWe now digress briefly to make a point about terminology. Theorists\nwho adopt the revealed preference interpretation of the utility\nfunctions in game theory are sometimes referred to in the philosophy\nof economics literature as \u2018behaviorists\u2019. This reflects\nthe fact the revealed preference approaches equate choices with\neconomically consistent actions, rather than being intended to refer\nto mental constructs. Historically, there was a relationship of\ncomfortable alignment, though not direct theoretical co-construction,\nbetween revealed preference in economics and the methodological and\nontological behaviorism that dominated scientific psychology during\nthe middle decades of the twentieth century. However, this usage is\nincreasingly likely to cause confusion due to the more recent rise of\nbehavioral game theory\n (Camerer 2003).\n This program of research aims to directly incorporate into\ngame-theoretic models generalizations, derived mainly from experiments\nwith people, about ways in which people differ from purer economic\nagents in the inferences they draw from information\n(\u2018framing\u2019). Applications also typically incorporate\nspecial assumptions about utility functions, also derived from\nexperiments. For example, players may be taken to be willing to make\ntrade-offs between the magnitudes of their own payoffs and\ninequalities in the distribution of payoffs among the players. We will\nturn to some discussion of behavioral game theory in\n Section 8.1,\n Section 8.2 and\n Section 8.3.\n For the moment, note that this use of game theory crucially rests on\nassumptions about psychological representations of value thought to be\ncommon among people. Thus it would be misleading to refer to\nbehavioral game theory as \u2018behaviorist\u2019. But then it just\nwould invite confusion to continue referring to conventional economic\ngame theory that relies on revealed preference as\n\u2018behaviorist\u2019 game theory. We will therefore refer to it\nas \u2018non-psychological\u2019 game theory. We mean by this the\nkind of game theory used by most economists who are not\nrevisionist behavioral economists. (We use the qualifier\n\u2018revisionist\u2019 to reflect the further complication that\nincreasingly many economists who apply revealed preference concepts\nconduct experiments, and some of them call themselves\n\u2018behavioral economists\u2019! For a proposed new set of\nconventions to reduce this labeling chaos, see\n Ross (2014),\n pp. 200\u2013201.) These \u2018establishment\u2019 economists\ntreat game theory as the abstract mathematics of strategic\ninteraction, rather than as an attempt to directly characterize\nspecial psychological dispositions that might be typical in\nhumans.\n\nNon-psychological game theorists tend to take a dim view of much of\nthe refinement program. This is for the obvious reason that it relies\non intuitions about which kinds of inferences people should\nfind sensible. Like most scientists, non-psychological game theorists\nare suspicious of the force and basis of philosophical assumptions as\nguides to empirical and mathematical modeling.\n\nBehavioral game theory, by contrast, can be understood as a refinement\nof game theory, though not necessarily of its solution concepts, in a\ndifferent sense. It restricts the theory\u2019s underlying axioms for\napplication to a special class of agents, individual, psychologically\ntypical humans. It motivates this restriction by reference to\ninferences, along with preferences, that people do find\nnatural, regardless of whether these seem rational,\nwhich they frequently do not. Non-psychological and behavioral game\ntheory have in common that neither is intended to be\nnormative\u2014though both are often used to try to describe\nnorms that prevail in groups of players, as well to explain\nwhy norms might persist in groups of players even when they appear to\nbe less than fully rational to philosophical intuitions. Both see the\njob of applied game theory as being to predict outcomes of\nempirical games given some distribution of strategic\ndispositions, and some distribution of expectations about the\nstrategic dispositions of others, that are shaped by dynamics in\nplayers\u2019 environments, including institutional pressures and\nstructures and evolutionary selection. Let us therefore group\nnon-psychological and behavioral game theorists together, just for\npurposes of contrast with normative game theorists, as\ndescriptive game theorists.\n\nDescriptive game theorists are often inclined to doubt that the goal\nof seeking a general theory of rationality makes sense as a\nproject. Institutions and evolutionary processes build many\nenvironments, and what counts as rational procedure in one environment\nmay not be favoured in another. On the other hand, an entity that does\nnot at least stochastically (i.e., perhaps noisily but statistically\nmore often than not) satisfy the minimal restrictions of economic\nrationality cannot, except by accident, be accurately characterized as\naiming to maximize a utility function. To such entities game theory\nhas no application in the first place. \n\nThis does not imply that non-psychological game theorists abjure all\nprincipled ways of restricting sets of NE to subsets based on their\nrelative probabilities of arising. In particular, non-psychological\ngame theorists tend to be sympathetic to approaches that shift\nemphasis from rationality onto considerations of the informational\ndynamics of games. We should perhaps not be surprised that NE analysis\nalone often fails to tell us much of applied, empirical interest about\nstrategic-form games (e.g., Figure 6 above), in which informational\nstructure is suppressed. Equilibrium selection issues are often more\nfruitfully addressed in the context of extensive-form games.\n2.6 Subgame Perfection\n\nIn order to deepen our understanding of extensive-form games, we need\nan example with more interesting structure than the PD offers. \n\nConsider the game described by this tree:\n\n\n\nFigure 9\n\n\nThis game is not intended to fit any preconceived situation; it is\nsimply a mathematical object in search of an application. (L and R\nhere just denote \u2018left\u2019 and \u2018right\u2019\nrespectively.) \n\nNow consider the strategic form of this game:\n\n\n\n\nII\n\nLL\nLR\nRL\nRR\n\n\nLL\n3,3\n3,3\n0,5\n0,5\n\nLR\n3,3\n3,3\n0,5\n0,5\n\nRL\n\u22121,0\n4,5\n\u22121,0\n4,5\n\nRR\n\u22121,0\n5,\u22121\n\u22121,0\n5,\u22121\n\n\nFigure 10\n\n\nIf you are confused by this, remember that a strategy must tell a\nplayer what to do at every information set where that player\nhas an action. Since each player chooses between two actions at each\nof two information sets here, each player has four strategies in\ntotal. The first letter in each strategy designation tells each player\nwhat to do if he or she reaches their first information set, the\nsecond what to do if their second information set is reached. I.e., LR\nfor Player II tells II to play L if information set 5 is reached and R\nif information set 6 is reached. \n\nIf you examine the matrix in Figure 10, you will discover that (LL,\nRL) is among the NE. This is a bit puzzling, since if Player I reaches\nher second information set (7) in the extensive-form game, she would\nhardly wish to play L there; she earns a higher payoff by playing R at\nnode 7. Mere NE analysis doesn\u2019t notice this because NE is\ninsensitive to what happens off the path of play. Player I,\nin choosing L at node 4, ensures that node 7 will not be reached; this\nis what is meant by saying that it is \u2018off the path of\nplay\u2019. In analyzing extensive-form games, however, we\nshould care what happens off the path of play, because\nconsideration of this is crucial to what happens on the path.\nFor example, it is the fact that Player I would play R if\nnode 7 were reached that would cause Player II to play L if\nnode 6 were reached, and this is why Player I won\u2019t choose R at\nnode 4. We are throwing away information relevant to game solutions if\nwe ignore off-path outcomes, as mere NE analysis does. Notice that\nthis reason for doubting that NE is a wholly satisfactory equilibrium\nconcept in itself has nothing to do with intuitions about rationality,\nas in the case of the refinement concepts discussed in Section\n2.5.\n\nNow apply Zermelo\u2019s algorithm to the extensive form of our\ncurrent example. Begin, again, with the last subgame, that descending\nfrom node 7. This is Player I\u2019s move, and she would choose R\nbecause she prefers her payoff of 5 to the payoff of 4 she gets by\nplaying L. Therefore, we assign the payoff \\((5, -1)\\) to node 7. Thus\nat node 6 II faces a choice between \\((-1, 0)\\) and \\((5, -1)\\). He\nchooses L. At node 5 II chooses R. At node 4 I is thus choosing\nbetween (0, 5) and \\((-1, 0)\\), and so plays L. Note that, as in the\nPD, an outcome appears at a terminal node\u2014(4, 5) from node\n7\u2014that is Pareto superior to the NE. Again, however, the\ndynamics of the game prevent it from being reached.\n\nThe fact that Zermelo\u2019s algorithm picks out the strategy vector\n(LR, RL) as the unique solution to the game shows that it\u2019s\nyielding something other than just an NE. In fact, it is generating\nthe game\u2019s subgame perfect equilibrium (SPE). It gives\nan outcome that yields a NE not just in the whole game but in\nevery subgame as well. This is a persuasive solution concept because,\nagain unlike the refinements of Section 2.5, it does not demand\n\u2018extra\u2019 rationality of agents in the sense of expecting\nthem to have and use philosophical intuitions about \u2018what makes\nsense\u2019. It does, however, assume that players not only know\neverything strategically relevant to their situation but also\nuse all of that information. In arguments about the\nfoundations of economics, this is often referred to as an aspect of\nrationality, as in the phrase \u2018rational expectations\u2019.\nBut, as noted earlier, it is best to be careful not to confuse the\ngeneral normative idea of rationality with computational power and the\npossession of budgets, in time and energy, to make the most of it.\n\nAn agent playing a subgame perfect strategy simply chooses, at every\nnode she reaches, the path that brings her the highest payoff in\nthe subgame emanating from that node. SPE predicts a game\u2019s\noutcome just in case, in solving the game, the players foresee that\nthey will all do that.\n\nA main value of analyzing extensive-form games for SPE is that this\ncan help us to locate structural barriers to social optimization. In\nour current example, Player I would be better off, and Player II no\nworse off, at the left-hand node emanating from node 7 than at the SPE\noutcome. But Player I\u2019s economic rationality, and Player\nII\u2019s awareness of this, blocks the socially efficient outcome.\nIf our players wish to bring about the more socially efficient outcome\n(4, 5) here, they must do so by redesigning their institutions so as\nto change the structure of the game. The enterprise of changing\ninstitutional and informational structures so as to make efficient\noutcomes more likely in the games that agents (that is, people,\ncorporations, governments, etc.) actually play is known as\nmechanism design, and is one of the leading areas of\napplication of game theory. The main techniques are reviewed in\n Hurwicz and Reiter (2006),\n the first author of which was awarded the Nobel Prize for his\npioneering work in the area.\n2.7 On Interpreting Payoffs: Morality and Efficiency in Games\n\nMany readers, but especially philosophers, might wonder why, in the\ncase of the example taken up in the previous section, mechanism design\nshould be necessary unless players are morbidly selfish sociopaths.\nSurely, the players might be able to just see that outcome\n(4, 5) is socially and morally superior; and since the whole problem\nalso takes for granted that they can also see the path of actions that\nleads to this efficient outcome, who is the game theorist to announce\nthat, unless their game is changed, it\u2019s unattainable? This\nobjection, which applies the distinctive idea of rationality urged by\nImmanuel Kant, indicates the leading way in which many philosophers\nmean more by \u2018rationality\u2019 than descriptive game theorists\ndo. This theme is explored with great liveliness and polemical force\nin Binmore\n (1994,\n 1998).\n\nThis weighty philosophical controversy about rationality is sometimes\nconfused by misinterpretation of the meaning of \u2018utility\u2019\nin non-psychological game theory. To root out this mistake, consider\nthe Prisoner\u2019s Dilemma again. We have seen that in the unique NE\nof the PD, both players get less utility than they could have through\nmutual cooperation. This may strike you, even if you are not a Kantian\n(as it has struck many commentators) as perverse. Surely, you may\nthink, it simply results from a combination of selfishness and\nparanoia on the part of the players. To begin with they have no regard\nfor the social good, and then they shoot themselves in the feet by\nbeing too untrustworthy to respect agreements.\n\nThis way of thinking is very common in popular discussions, and badly\nmixed up. To dispel its influence, let us first introduce some\nterminology for talking about outcomes. Welfare economists typically\nmeasure social good in terms of Pareto efficiency. A\ndistribution of utility \\(\\beta\\) is said to be Pareto\nsuperior over another distribution \\(\\delta\\) just in case from\nstate \\(\\delta\\) there is a possible redistribution of utility to\n\\(\\beta\\) such that at least one player is better off in \\(\\beta\\)\nthan in \\(\\delta\\) and no player is worse off. Failure to move from a\nPareto-inferior to a Pareto-superior distribution is\ninefficient because the existence of \\(\\beta\\) as a\npossibility, at least in principle, shows that in \\(\\delta\\) some\nutility is being wasted. Now, the outcome (3,3) that represents mutual\ncooperation in our model of the PD is clearly Pareto superior to\nmutual defection; at (3,3) both players are better off than\nat (2,2). So it is true that PDs lead to inefficient outcomes. This\nwas true of our example in Section 2.6 as well.\n\nHowever, inefficiency should not be associated with immorality. A\nutility function for a player is supposed to represent everything\nthat player cares about, which may be anything at all. As we have\ndescribed the situation of our prisoners they do indeed care only\nabout their own relative prison sentences, but there is nothing\nessential in this. What makes a game an instance of the PD is strictly\nand only its payoff structure. Thus we could have two Mother Theresa\ntypes here, both of whom care little for themselves and wish only to\nfeed starving children. But suppose the original Mother Theresa wishes\nto feed the children of Calcutta while Mother Juanita wishes to feed\nthe children of Bogota. And suppose that the international aid agency\nwill maximize its donation if the two saints nominate the same city,\nwill give the second-highest amount if they nominate each\nothers\u2019 cities, and the lowest amount if they each nominate\ntheir own city. Our saints are in a PD here, though hardly selfish or\nunconcerned with the social good.\n\nTo return to our prisoners, suppose that, contrary to our assumptions,\nthey do value each other\u2019s well-being as well as their\nown. In that case, this must be reflected in their utility functions,\nand hence in their payoffs. If their payoff structures are changed so\nthat, for example, they would feel so badly about contributing to\ninefficiency that they\u2019d rather spend extra years in prison than\nendure the shame, then they will no longer be in a PD. But all this\nshows is that not every possible situation is a PD; it does\nnot show that selfishness is among the assumptions of game\ntheory. It is the logic of the prisoners\u2019 situation,\nnot their psychology, that traps them in the inefficient outcome, and\nif that really is their situation then they are stuck in it\n(barring further complications to be discussed below). Agents who wish\nto avoid inefficient outcomes are best advised to prevent certain\ngames from arising; the defender of the possibility of Kantian\nrationality is really proposing that they try to dig themselves out of\nsuch games by turning themselves into different agents.\n\nIn general, then, a game is partly defined by the payoffs\nassigned to the players. In any application, such assignments should\nbe based on sound empirical evidence. If a proposed solution involves\ntacitly changing these payoffs, then this \u2018solution\u2019 is in\nfact a disguised way of changing the subject and evading the\nimplications of best modeling practice.\n2.8 Trembling Hands and Quantal Response Equilibria\n\nOur last point above opens the way to a philosophical puzzle, one of\nseveral that still preoccupy those concerned with the logical\nfoundations of game theory. It can be raised with respect to any\nnumber of examples, but we will borrow an elegant one from C.\nBicchieri\n (1993).\n Consider the following game: \n\n\n\nFigure 11\n\n\nThe NE outcome here is at the single leftmost node descending from\nnode 8. To see this, backward induct again. At node 10, I would play L\nfor a payoff of 3, giving II a payoff of 1. II can do better than this\nby playing L at node 9, giving I a payoff of 0. I can do better than\nthis by playing L at node 8; so that is what I does, and the game\nterminates without II getting to move. A puzzle is then raised by\nBicchieri (along with other authors, including\n Binmore (1987)\n and\n Pettit and Sugden (1989))\n by way of the following reasoning. Player I plays L at node 8 because\nshe knows that Player II is economically rational, and so would, at\nnode 9, play L because Player II knows that Player I is economically\nrational and so would, at node 10, play L. But now we have the\nfollowing paradox: Player I must suppose that Player II, at node 9,\nwould predict Player I\u2019s economically rational play at node 10\ndespite having arrived at a node (9) that could only be reached if\nPlayer I is not economically rational! If Player I is not economically\nrational then Player II is not justified in predicting that Player I\nwill not play R at node 10, in which case it is not clear that Player\nII shouldn\u2019t play R at 9; and if Player II plays R at 9, then\nPlayer I is guaranteed of a better payoff then she gets if she plays L\nat node 8. Both players use backward induction to solve the game;\nbackward induction requires that Player I know that Player II knows\nthat Player I is economically rational; but Player II can solve the\ngame only by using a backward induction argument that takes as a\npremise the failure of Player I to behave in accordance with economic\nrationality. This is the paradox of backward induction.\n\nA standard way around this paradox in the literature is to invoke the\nso-called \u2018trembling hand\u2019 due to\n Selten (1975).\n The idea here is that a decision and its consequent act may\n\u2018come apart\u2019 with some nonzero probability, however small.\nThat is, a player might intend to take an action but then slip up in\nthe execution and send the game down some other path instead. If there\nis even a remote possibility that a player may make a\nmistake\u2014that her \u2018hand may tremble\u2019\u2014then no\ncontradiction is introduced by a player\u2019s using a backward\ninduction argument that requires the hypothetical assumption that\nanother player has taken a path that an economically rational player\ncould not choose. In our example, Player II could reason about what to\ndo at node 9 conditional on the assumption that Player I chose L at\nnode 8 but then slipped.\n\nGintis (2009a)\n points out that the apparent paradox does not arise merely from our\nsupposing that both players are economically rational. It rests\ncrucially on the additional premise that each player must know, and\nreasons on the basis of knowing, that the other player is economically\nrational. This is the premise with which each player\u2019s\nconjectures about what would happen off the equilibrium path of play\nare inconsistent. A player has reason to consider out-of-equilibrium\npossibilities if she either believes that her opponent is economically\nrational but his hand may tremble or she attaches some\nnonzero probability to the possibility that he is not economically\nrational or she attaches some doubt to her conjecture about\nhis utility function. As Gintis also stresses, this issue with solving\nextensive-form games games for SEP by Zermelo\u2019s algorithm\ngeneralizes: a player has no reason to play even a Nash\nequilibrium strategy unless she expects other players to also play\nNash equilibrium strategies. We will return to this issue in\n Section 7\n below.\n\nThe paradox of backward induction, like the puzzles raised by\nequilibrium refinement, is mainly a problem for those who view game\ntheory as contributing to a normative theory of rationality\n(specifically, as contributing to that larger theory the theory of\nstrategic rationality). The non-psychological game theorist\ncan give a different sort of account of apparently\n\u201cirrational\u201d play and the prudence it encourages. This\ninvolves appeal to the empirical fact that actual agents, including\npeople, must learn the equilibrium strategies of games they\nplay, at least whenever the games are at all complicated. Research\nshows that even a game as simple as the Prisoner\u2019s Dilemma\nrequires learning by people\n (Ledyard 1995,\n Sally 1995,\n Camerer 2003,\n p. 265). What it means to say that people must learn equilibrium\nstrategies is that we must be a bit more sophisticated than was\nindicated earlier in constructing utility functions from behavior in\napplication of Revealed Preference Theory. Instead of constructing\nutility functions on the basis of single episodes, we must do so on\nthe basis of observed runs of behavior once it has\nstabilized, signifying maturity of learning for the subjects in\nquestion and the game in question. Once again, the Prisoner\u2019s\nDilemma makes a good example. People encounter few one-shot\nPrisoner\u2019s Dilemmas in everyday life, but they encounter many\nrepeated PD\u2019s with non-strangers. As a result, when set\ninto what is intended to be a one-shot PD in the experimental\nlaboratory, people tend to initially play as if the game were a single\nround of a repeated PD. The repeated PD has many Nash equilibria that\ninvolve cooperation rather than defection. Thus experimental subjects\ntend to cooperate at first in these circumstances, but learn after\nsome number of rounds to defect. The experimenter cannot infer that\nshe has successfully induced a one-shot PD with her experimental setup\nuntil she sees this behavior stabilize.\n\nIf players of games realize that other players may need to learn game\nstructures and equilibria from experience, this gives them reason to\ntake account of what happens off the equilibrium paths of\nextensive-form games. Of course, if a player fears that other players\nhave not learned equilibrium, this may well remove her incentive to\nplay an equilibrium strategy herself. This raises a set of deep\nproblems about social learning\n (Fudenberg and Levine 1998).\n How can ignorant players learn to play equilibria if sophisticated\nplayers don\u2019t show them, because the sophisticated are not\nincentivized to play equilibrium strategies until the ignorant have\nlearned? The crucial answer in the case of applications of game theory\nto interactions among people is that young people are\nsocialized by growing up in networks of\ninstitutions, including cultural norms. Most complex\ngames that people play are already in progress among people who were\nsocialized before them\u2014that is, have learned game structures and\nequilibria\n (Ross 2008a).\n Novices must then only copy those whose play appears to be expected\nand understood by others. Institutions and norms are rich with\nreminders, including homilies and easily remembered rules of thumb, to\nhelp people remember what they are doing\n (Clark 1997).\n\nAs noted in\n Section 2.7\n above, when observed behavior does not stabilize around\nequilibria in a game, and there is no evidence that learning is still\nin process, the analyst should infer that she has incorrectly modeled\nthe situation she is studying. Chances are that she has either\nmis-specified players\u2019 utility functions, the strategies\navailable to the players, or the information that is available to\nthem. Given the complexity of many of the situations that social\nscientists study, we should not be surprised that mis-specification of\nmodels happens frequently. Applied game theorists must do lots of\nlearning, just like their subjects. \n\nThe paradox of backward induction is one of a family of paradoxes that\narise if one builds possession and use of literally complete\ninformation into a concept of rationality. (Consider, by analogy, the\nstock market paradox that arises if we suppose that economically\nrational investment incorporates literally rational expectations:\nassume that no individual investor can beat the market in the long run\nbecause the market always knows everything the investor knows; then no\none has incentive to gather knowledge about asset values; then no one\nwill ever gather any such information and so from the assumption that\nthe market knows everything it follows that the market cannot know\nanything!)As we will see in detail in various discussions below, most\napplications of game theory explicitly incorporate uncertainty and\nprospects for learning by players. The extensive-form games with SPE\nthat we looked at above are really conceptual tools to help us prepare\nconcepts for application to situations where complete and perfect\ninformation is unusual. We cannot avoid the paradox if we think, as\nsome philosophers and normative game theorists do, that one of the\nconceptual tools we want to use game theory to sharpen is a fully\ngeneral idea of rationality itself. But this is not a concern\nentertained by economists and other scientists who put game theory to\nuse in empirical modeling. In real cases, unless players have\nexperienced play at equilibrium with one another in the past, even if\nthey are all economically rational and all believe this about one\nanother, we should predict that they will attach some positive\nprobability to the conjecture that understanding of game structures\namong some players is imperfect. This then explains why people, even\nif they are economically rational agents, may often, or even usually,\nplay as if they believe in trembling hands.\n\nLearning of equilibria may take various forms for different agents and\nfor games of differing levels of complexity and risk. Incorporating it\ninto game-theoretic models of interactions thus introduces an\nextensive new set of technicalities. For the most fully developed\ngeneral theory, the reader is referred to\n Fudenberg and Levine (1998);\n the same authors provide a non-technical overview of the issues in\n Fudenberg and Levine (2016).\n A first important distinction is between learning specific parameters\nbetween rounds of a repeated game (see\n Section 4)\n with common players, and learning about general strategic\nexpectations across different games. The latter can include learning\nabout players if the learner is updating expectations based on her\nmodels of types of players she recurrently encounters. Then\nwe can distinguish between passive learning, in which a\nplayer merely updates her subjective priors based on her\nobservation of moves and outcomes, and strategic choices she infers\nfrom these, and active learning, in which she probes\u2014in\ntechnical language screens\u2014for information about other\nplayers\u2019 strategies by choosing strategies that test her\nconjectures about what will occur off what she believes to be the\ngame\u2019s equilibrium path. A major difficulty for both players and\nmodelers is that screening moves might be misinterpreted if players\nare also incentivized to make moves to signal information to\none another (see\n Section 4).\n In other words: trying to learn about strategies can under some\ncircumstances interfere with players\u2019 abilities to learn\nequilibria. Finally, the discussion so far has assumed that all\npossible learning in a game is about the structure of the game itself.\n Wilcox (2008)\n shows that if players are learning new information about causal\nprocesses occurring outside a game while simultaneously trying to\nupdate expectations about other players\u2019 strategies, the modeler\ncan find herself reaching beyond the current limits of technical\nknowledge.\n\nIt was said above that people might usually play as if they\nbelieve in trembling hands. A very general reason for this is that\nwhen people interact, the world does not furnish them with cue-cards\nadvising them about the structures of the games they\u2019re playing.\nThey must make and test conjectures about this from their social\ncontexts. Sometimes, contexts are fixed by institutional rules. For\nexample, when a person walks into a retail shop and sees a price tag\non something she\u2019d like to have, she knows without needing to\nconjecture or learn anything that she\u2019s involved in a simple\n\u2018take it or leave it\u2019 game. In other markets, she might\nknow she is expected to haggle, and know the rules for that too. \n\nGiven the unresolved complex relationship between learning theory and\ngame theory, the reasoning above might seem to imply that game theory\ncan never be applied to situations involving human players that are\nnovel for them. Fortunately, however, we face no such impasse. In a\npair of influential papers, McKelvey and Palfrey\n (1995,\n 1998) developed the solution concept of quantal response\nequilibrium (QRE). QRE is not a refinement of NE, in the sense of\nbeing a philosophically motivated effort to strengthen NE by reference\nto normative standards of rationality. It is, rather, a method for\ncalculating the equilibrium properties of choices made by players\nwhose conjectures about possible errors in the choices of other\nplayers are uncertain. QRE is thus standard equipment in the toolkit\nof experimental economists who seek to estimate the distribution of\nutility functions in populations of real people placed in situations\nmodeled as games. QRE would not have been practically serviceable in\nthis way before the development of econometrics packages such as Stata\n(TM) allowed computation of QRE given adequately powerful observation\nrecords from interestingly complex games. QRE is rarely utilized by\nbehavioral economists, and is almost never used by psychologists, in\nanalyzing laboratory data. In consequence, many studies by researchers\nof these types make dramatic rhetorical points by\n\u2018discovering\u2019 that real people often fail to converge on\nNE in experimental games. But NE, though it is a minimalist solution\nconcept in one sense because it abstracts away from much informational\nstructure, is simultaneously a demanding empirical expectation if it\nis imposed categorically (that is, if players are expected to play as\nif they are all certain that all others are playing NE strategies).\nPredicting play consistent with QRE is consistent with\u2014indeed,\nis motivated by\u2014the view that NE captures the core general\nconcept of a strategic equilibrium. One way of framing the\nphilosophical relationship between NE and QRE is as follows. NE\ndefines a logical principle that is well adapted for\ndisciplining thought and for conceiving new strategies for generic\nmodeling of new classes of social phenomena. For purposes of\nestimating real empirical data one needs to be able to define\nequilibrium statistically. QRE represents one way of doing\nthis, consistently with the logic of NE. The idea is sufficiently rich\nthat its depths remain an open domain of investigation by game\ntheorists. The current state of understanding of QRE is\ncomprehensively reviewed in\n Goeree, Holt and Palfrey (2016).\n\n3. Uncertainty, Risk and Sequential Equilibria\n\nThe games we\u2019ve modeled to this point have all involved players\nchoosing from amongst pure strategies, in which each seeks a\nsingle optimal course of action at each node that constitutes a best\nreply to the actions of others. Often, however, a player\u2019s\nutility is optimized through use of a mixed strategy, in\nwhich she flips a weighted coin amongst several possible actions. (We\nwill see later that there is an alternative interpretation of mixing,\nnot involving randomization at a particular information set; but we\nwill start here from the coin-flipping interpretation and then build\non it in\n Section 3.1.)\n Mixing is called for whenever no pure strategy maximizes the\nplayer\u2019s utility against all opponent strategies. Our\nriver-crossing game from\n Section 1\n exemplifies this. As we saw, the puzzle in that game consists in the\nfact that if the fugitive\u2019s reasoning selects a particular\nbridge as optimal, his pursuer must be assumed to be able to duplicate\nthat reasoning. The fugitive can escape only if his pursuer cannot\nreliably predict which bridge he\u2019ll use. Symmetry of logical\nreasoning power on the part of the two players ensures that the\nfugitive can surprise the pursuer only if it is possible for him to\nsurprise himself.\n\nSuppose that we ignore rocks and cobras for a moment, and imagine that\nthe bridges are equally safe. Suppose also that the fugitive has no\nspecial knowledge about his pursuer that might lead him to venture a\nspecially conjectured probability distribution over the\npursuer\u2019s available strategies. In this case, the\nfugitive\u2019s best course is to roll a three-sided die, in which\neach side represents a different bridge (or, more conventionally, a\nsix-sided die in which each bridge is represented by two sides). He\nmust then pre-commit himself to using whichever bridge is selected by\nthis randomizing device. This fixes the odds of his survival\nregardless of what the pursuer does; but since the pursuer has no\nreason to prefer any available pure or mixed strategy, and since in\nany case we are presuming her epistemic situation to be symmetrical to\nthat of the fugitive, we may suppose that she will roll a three-sided\ndie of her own. The fugitive now has a 2/3 probability of escaping and\nthe pursuer a 1/3 probability of catching him. Neither the fugitive\nnor the pursuer can improve their chances given the other\u2019s\nrandomizing mix, so the two randomizing strategies are in Nash\nequilibrium. Note that if one player is randomizing then the\nother does equally well on any mix of probabilities over\nbridges, so there are infinitely many combinations of best replies.\nHowever, each player should worry that anything other than a random\nstrategy might be coordinated with some factor the other player can\ndetect and exploit. Since any non-random strategy is exploitable by\nanother non-random strategy, in a zero-sum game such as our example,\nonly the vector of randomized strategies is a NE.\n\nNow let us re-introduce the parametric factors, that is, the falling\nrocks at bridge #2 and the cobras at bridge #3. Again, suppose that\nthe fugitive is sure to get safely across bridge #1, has a 90% chance\nof crossing bridge #2, and an 80% chance of crossing bridge #3. We can\nsolve this new game if we make certain assumptions about the two\nplayers\u2019 utility functions. Suppose that Player 1, the fugitive,\ncares only about living or dying (preferring life to death) while the\npursuer simply wishes to be able to report that the fugitive is dead,\npreferring this to having to report that he got away. (In other words,\nneither player cares about how the fugitive lives or dies.)\nSuppose also for now that neither player gets any utility or\ndisutility from taking more or less risk. In this case, the fugitive\nsimply takes his original randomizing formula and weights it according\nto the different levels of parametric danger at the three bridges.\nEach bridge should be thought of as a lottery over the\nfugitive\u2019s possible outcomes, in which each lottery has a\ndifferent expected payoff in terms of the items in his\nutility function.\n\nConsider matters from the pursuer\u2019s point of view. She will be\nusing her NE strategy when she chooses the mix of probabilities over\nthe three bridges that makes the fugitive indifferent among his\npossible pure strategies. The bridge with rocks is 1.1 times more\ndangerous for him than the safe bridge. Therefore, he will be\nindifferent between the two when the pursuer is 1.1 times more likely\nto be waiting at the safe bridge than the rocky bridge. The cobra\nbridge is 1.2 times more dangerous for the fugitive than the safe\nbridge. Therefore, he will be indifferent between these two bridges\nwhen the pursuer\u2019s probability of waiting at the safe bridge is\n1.2 times higher than the probability that she is at the cobra bridge.\nSuppose we use \\(s_1\\), \\(s_2\\) and \\(s_3\\) to represent the\nfugitive\u2019s parametric survival rates at each bridge. Then the\npursuer minimizes the net survival rate across any pair of bridges by\nadjusting the probabilities p1 and p2 that she will wait at them so\nthat \n\\[\ns_1 (1 - p_1) = s_2 (1 - p_2)\n\\]\n\n\nSince \\(p_1 + p_2 = 1\\), we can rewrite this as \n\\[\ns_1 \\times p_2 = s_2 \\times p_1\n\\]\n\n\nso \n\\[\n\\frac{p_1}{s_1} = \\frac{p_2}{s_2}.\n\\]\n\n\nThus the pursuer finds her NE strategy by solving the following\nsimultaneous equations: \n\\[\\begin{align}\n1(1-p_1) &= 0.9(1-p_2) \\\\\n&=0.8(1-p_3)\n\\end{align}\\]\n \n\\[\np_1 + p_2 + p_3 = 1\n\\]\n\n\nThen \n\\[\\begin{align}\np_1 &= \\frac{49}{121} \\\\\np_2 &= \\frac{41}{121} \\\\\np_3 &= \\frac{31}{121}\n\\end{align}\\]\n\n\nNow let \\(f_1\\), \\(f_2\\), \\(f_3\\) represent the probabilities with\nwhich the fugitive chooses each respective bridge. Then the fugitive\nfinds his NE strategy by solving \n\\[\\begin{align}\ns_1 \\times f_1 &= s_2 \\times f_2 \\\\\n               &= s_3 \\times f_3\n\\end{align}\\]\n\n\nso \n\\[\\begin{align}\n1 \\times f_1 &= 0.9 \\times f_2 \\\\\n             &= 0.8 \\times f_3\n\\end{align}\\]\n\n\nsimultaneously with \n\\[\nf_1 + f_2 + f_3 = 1\n\\]\n\n\nThen \n\\[\\begin{align}\nf_1 &= \\frac{36}{121} \\\\\nf_2 &= \\frac{40}{121} \\\\\nf_3 &= \\frac{45}{121}\n\\end{align}\\]\n\n\nThese two sets of NE probabilities tell each player how to weight his\nor her die before throwing it. Note the\u2014perhaps\nsurprising\u2014result that the fugitive, though by hypothesis he\ngets no enjoyment from gambling, uses riskier bridges with  higher\n probability. This is the only way of making the pursuer\nindifferent over which bridge she stakes out, which in turn is what\nmaximizes the fugitive\u2019s probability of survival.\n\nWe were able to solve this game straightforwardly because we set the\nutility functions in such a way as to make it zero-sum, or\nstrictly competitive. That is, every gain in expected utility\nby one player represents a precisely symmetrical loss by the other.\nHowever, this condition may often not hold. Suppose now that the\nutility functions are more complicated. The pursuer most prefers an\noutcome in which she shoots the fugitive and so claims credit for his\napprehension to one in which he dies of rockfall or snakebite; and she\nprefers this second outcome to his escape. The fugitive prefers a\nquick death by gunshot to the pain of being crushed or the terror of\nan encounter with a cobra. Most of all, of course, he prefers to\nescape. Suppose, plausibly, that the fugitive cares more\nstrongly about surviving than he does about getting killed\none way rather than another. We cannot solve this game, as before,\nsimply on the basis of knowing the players\u2019 ordinal utility\nfunctions, since the intensities of their respective\npreferences will now be relevant to their strategies.\n\nPrior to the work of\n von Neumann & Morgenstern (1947),\n situations of this sort were inherently baffling to analysts. This is\nbecause utility does not denote a hidden psychological variable such\nas pleasure. As we discussed in\n Section 2.1,\n utility is merely a measure of relative behavioural dispositions\ngiven certain consistency assumptions about relations between\npreferences and choices. It therefore makes no sense to imagine\ncomparing our players\u2019 cardinal\u2014that is,\nintensity-sensitive\u2014preferences with one another\u2019s, since\nthere is no independent, interpersonally constant yardstick we could\nuse. How, then, can we model games in which cardinal information is\nrelevant? After all, modeling games requires that all players\u2019\nutilities be taken simultaneously into account, as we\u2019ve\nseen.\n\nA crucial aspect of\n von Neumann & Morgenstern\u2019s (1947)\n work was the solution to this problem. Here, we will provide a brief\noutline of their ingenious technique for building cardinal utility\nfunctions out of ordinal ones. It is emphasized that what follows is\nmerely an outline, so as to make cardinal utility\nnon-mysterious to you as a student who is interested in knowing about\nthe philosophical foundations of game theory, and about the range of\nproblems to which it can be applied. Providing a manual you could\nfollow in building your own cardinal utility functions would\nrequire many pages. Such manuals are available in many textbooks.\n\nSuppose that we now assign the following ordinal utility function to\nthe river-crossing fugitive: \n\\[\\begin{align}\n\\text{Escape} &\\gg 4 \\\\\n\\text{Death by shooting} &\\gg 3 \\\\\n\\text{Death by rockfall} &\\gg 2 \\\\\n\\text{Death by snakebite} &\\gg 1\n\\end{align}\\]\n\n\nWe are supposing that his preference for escape over any form\nof death is stronger than his preferences between causes of death.\nThis should be reflected in his choice behaviour in the following way.\nIn a situation such as the river-crossing game, he should be willing\nto run greater risks to increase the relative probability of escape\nover shooting than he is to increase the relative probability of\nshooting over snakebite. This bit of logic is the crucial insight\nbehind\n von Neumann & Morgenstern\u2019s (1947)\n solution to the cardinalization problem. \n\nSuppose we asked the fugitive to pick, from the available set of\noutcomes, a best one and a worst one.\n\u2018Best\u2019 and \u2018worst\u2019 are defined in terms of\nexpected payoffs as illustrated in our current zero-sum game example:\na player maximizes his expected payoff if, when choosing among\nlotteries that contain only two possible prizes, he always chooses so\nas to maximize the probability of the best outcome\u2014call this\n\\(\\mathbf{W}\\)\u2014and to minimize the probability of the worst\noutcome\u2014call this \\(\\mathbf{L}\\). Now imagine expanding the set\nof possible prizes so that it includes prizes that the agent values as\nintermediate between \\(\\mathbf{W}\\) and \\(\\mathbf{L}\\). We find, for a\nset of outcomes containing such prizes, a lottery over them such that\nour agent is indifferent between that lottery and a lottery including\nonly \\(\\mathbf{W}\\) and \\(\\mathbf{L}\\). In our example, this is a\nlottery that includes being shot and being crushed by rocks. Call this\nlottery \\(\\mathbf{T}\\) . We define a utility function \\(q =\nu(\\mathbf{T})\\) from outcomes to the real (as opposed to ordinal)\nnumber line such that if \\(q\\) is the expected prize in\n\\(\\mathbf{T}\\), the agent is indifferent between winning\n\\(\\mathbf{T}\\) and winning a lottery \\(\\mathbf{T}^*\\) in which\n\\(\\mathbf{W}\\) occurs with probability \\(u(\\mathbf{T})\\) and\n\\(\\mathbf{L}\\) occurs with probability \\(1-u(\\mathbf{T})\\). Assuming\nthat the agent\u2019s behaviour respects the principle of\nreduction of compound lotteries (ROCL)\u2014that is, he does\nnot gain or lose utility from considering more complex lotteries\nrather than simple ones\u2014the set of mappings of outcomes in\n\\(\\mathbf{T}\\) to \\(u\\mathbf{T}^*\\) gives a von Neumann-Morgenstern\nutility function (vNMuf) with cardinal structure over all outcomes in\n\\(\\mathbf{T}\\). \n\nWhat exactly have we done here? We\u2019ve given our agent choices\nover lotteries, instead of directly over resolved outcomes, and\nobserved how much extra risk of death he\u2019s willing to run to\nchange the odds of getting one form of death relative to an\nalternative form of death. Note that this cardinalizes the\nagent\u2019s preference structure only relative to agent-specific\nreference points \\(\\mathbf{W}\\) and \\(\\mathbf{L}\\); the procedure\nreveals nothing about comparative extra-ordinal preferences\nbetween agents, which helps to make clear that constructing a\nvNMuf does not introduce a potentially objective psychological\nelement. Furthermore, two agents in one game, or one agent under\ndifferent sorts of circumstances, may display varying attitudes to\nrisk. Perhaps in the river-crossing game the pursuer, whose life is\nnot at stake, will enjoy gambling with her glory while our fugitive is\ncautious. In analyzing the river-crossing game, however, we\ndon\u2019t have to be able to compare the pursuer\u2019s\ncardinal utilities with the fugitive\u2019s. Both agents, after all,\ncan find their NE strategies if they can estimate the probabilities\neach will assign to the actions of the other. This means that each\nmust know both vNMufs; but neither need try to comparatively value the\noutcomes over which they\u2019re choosing.\n\nWe can now fill in the rest of the matrix for the bridge-crossing game\nthat we started to draw in Section 2. If both players are risk-neutral\nand their revealed preferences respect ROCL, then we have enough\ninformation to be able to assign expected utilities, expressed by\nmultiplying the original payoffs by the relevant probabilities, as\noutcomes in the matrix. Suppose that the hunter waits at the cobra\nbridge with probability \\(x\\) and at the rocky bridge with probability\n\\(y\\). Since her probabilities across the three bridges must sum to 1,\nthis implies that she must wait at the safe bridge with probability\n\\(1 - (x + y)\\). Then, continuing to assign the fugitive a payoff of 0\nif he dies and 1 if he escapes, and the hunter the reverse payoffs,\nour complete matrix is as follows:\n\n\n\n\nHunter\n\nSafe Bridge\nRocky Bridge\nCobra Bridge\n\nFugitive\nSafe Bridge\n0,1\n1,0\n1,0\n\nRocky Bridge\n0.9,0.1\n0,1\n0.9,0.1\n\nCobra Bridge\n0.8,0.2\n0.8,0.2\n0,1\n\n\nFigure 12\n\n\nWe can now read the following facts about the game directly from the\nmatrix. No pair of pure strategies is a pair of best replies to the\nother. Therefore, the game\u2019s only NE require at least one player\nto use a mixed strategy.\n3.1 Beliefs and Subjective Probabilities\n\nIn all of our examples and workings to this point, we have presupposed\nthat players\u2019 beliefs about probabilities in lotteries match\nobjective probabilities. But in real interactive choice situations,\nagents must often rely on their subjective estimations or perceptions\nof probabilities. In one of the greatest contributions to\ntwentieth-century behavioral and social science,\n Savage (1954)\n showed how to incorporate subjective probabilities, and their\nrelationships to preferences over risk, within the framework of von\nNeumann-Morgenstern expected utility theory. Indeed, Savage\u2019s\nachievement amounts to the formal completion of EUT. Then, just over a\ndecade later,\n Harsanyi (1967)\n showed how to solve games involving maximizers of Savage expected\nutility. This is often taken to have marked the true maturity of game\ntheory as a tool for application to behavioral and social science, and\nwas recognized as such when Harsanyi joined Nash and Selten as a\nrecipient of the first Nobel prize awarded to game theorists in\n1994.\n\nAs we observed in considering the need for people playing games to\nlearn trembling hand equilibria and QRE, when we model the strategic\ninteractions of people we must allow for the fact that people are\ntypically uncertain about their models of one another. This\nuncertainty is reflected in their choices of strategies. Furthermore,\nsome actions might be taken specifically for the sake of learning\nabout the accuracy of a player\u2019s conjectures about other\nplayers. Harsanyi\u2019s extension of game theory incorporates these\ncrucial elements.\n\nConsider the three-player imperfect-information game below known as\n\u2018Selten\u2019s horse\u2019 (for its inventor, Nobel Laureate\nReinhard Selten, and because of the shape of its tree; taken from\n Kreps (1990),\n p. 426):\n\n\n\nFigure 13\n\n\nThis game has four NE: \\((\\mathrm{L}, l_2, l_3),\\) \\((\\mathrm{L}, r_2,\nl_3),\\) \\((\\mathrm{R}, r_2, l_3)\\) and \\((\\mathrm{R}, r_2, r_3).\\)\nConsider the fourth of these NE. It arises because when Player I plays\nR and Player II plays \\(r_2\\), Player III\u2019s entire information\nset is off the path of play, and it doesn\u2019t matter to the\noutcome what Player III does. But Player I would not play R if Player\nIII could tell the difference between being at node 13 and being at\nnode 14. The structure of the game incentivizes efforts by Player I to\nsupply Player III with information that would open up her closed\ninformation set. Player III should believe this information because\nthe structure of the game shows that Player I has incentive to\ncommunicate it truthfully. The game\u2019s solution would then be the\nSPE of the (now) perfect information game: \\((\\mathrm{L}, r_2, l_3).\\)\n\n\nTheorists who think of game theory as part of a normative theory of\ngeneral rationality, for example most philosophers, and refinement\nprogram enthusiasts among economists, have pursued a strategy that\nwould identify this solution on general principles. Notice what Player\nIII in Selten\u2019s Horse might wonder about as he selects his\nstrategy. \u201cGiven that I get a move, was my action node reached\nfrom node 11 or from node 12?\u201d What, in other words, are the\nconditional probabilities that Player III is at node 13 or 14\ngiven that he has a move? Now, if conditional probabilities are what\nPlayer III wonders about, then what Players I and II might make\nconjectures about when they select their strategies are\nPlayer III\u2019s beliefs about these conditional\nprobabilities. In that case, Player I must conjecture about Player\nII\u2019s beliefs about Player III\u2019s beliefs, and Player\nIII\u2019s beliefs about Player II\u2019s beliefs and so on. The\nrelevant beliefs here are not merely strategic, as before, since they\nare not just about what players will do given a set of\npayoffs and game structures, but about what understanding of\nconditional probability they should expect other players to operate\nwith.\n\nWhat beliefs about conditional probability is it reasonable for\nplayers to expect from each other? If we follow\n Savage (1954)\n we would suggest as a normative principle that they should reason and\nexpect others to reason in accordance with Bayes\u2019s\nrule. This tells them how to compute the probability of an event\n\\(F\\) given information \\(E\\) (written \u2018\\(pr(F\\mid\nE)\\)\u2019): \n\\[\npr(F\\mid E) = \\frac{pr(E\\mid F) \\times pr(F)}{pr(E)}\n\\]\n\n\nWe will put Bayes\u2019s Rule to work on an example immediately\nbelow. But first some theoretical discussion of its general\nsignificance in game theory is in order. In Section 2.8 we saw that a\nrange of complications are introduced into game theory when players\nhave scope for learning. This is an understatement: the\nmajority of the purely theoretical literature in game theory over the\npast four decades has concerned the complications in question. This is\npartly because the issues are deep and difficult, and partly because\nmost actual strategic situations to which game theory is most usefully\napplied do in fact call upon players to learn. When people (or other\nanimals) get embroiled in strategic interactions, the world\ndoesn\u2019t typically furnish unambiguous information about game\nstructures. In particular, it doesn\u2019t, so to speak, stamp\nplayers\u2019 utility functions on their foreheads. When players are\nunsure of the structure of the games they play, which depends on the\nutility vectors of all players, we say that their information is\nincomplete.\n\nIn addition, players might not know some parametric probability\ndistributions that are relevant to their strategy choices. In the\nexample of the river-crossing game just discussed, we supposed that\nboth players know ex ante (i.e., when they select their\nstrategies) the probabilities with which rocks fall and cobras strike.\nIn an actual situation of the kind imagined, this is unlikely. Both\nplayers might study both risk bridges for awhile to gather information\nabout the probability distributions of the dangerous (to the fugitive)\nevents. But estimates may be biased unless samples are very large and\nprobabilities are stationary (e.g., rockfalls don\u2019t become less\nfrequent as more exposed rocks fall). When players are uncertain about\nparametric contingencies, we model this in an extensive-form game by\nadding an additional player, usually called \u2018Nature\u2019, that\nhas no utility function, and hence no stake in the game\u2019s\noutcome, and that draws actions randomly relative to some specified\nprobability distribution. We can allow that strategic players (i.e.,\nplayers other than Nature) might have to make choices without knowing\nwhat Nature has drawn for them by putting Nature\u2019s range of\nmoves within a single information set, just as we do for strategic\nchoices in an extensive-form game where some moves are simultaneous,\nas in Figure 13 above. Then players\u2019uncertainty about parametric\nfactors is modelled as imperfect information.\n\nFinally, if strategic players\u2019estimates of uncertain parameters\nare independent, each player\u2019s estimate is potentially\ninformative to the other player. In a repeated game, players can\nacquire information about one anothers\u2019estimates of the\nparametric probabilities by observing one anothers\u2019choices.\nSuppose, for example, that in our river-crossing game there is a\nsuccession of fugitives, and successful escapees send reports back to\nthose who follow them. Now imagine that the Pursuer is surprised to\nfind Fugitives choosing the rocky bridge much less often than she\nexpected. If she assumes that the Fugitives are economically rational,\nthen she should update her estimate of the probability of\nrockfalls; evidently it was too low. Then, of course, she should\nadjust her strategy accordingly. This information is available to both\nthe Pursuer and the Fugitives, so as updating is effected the\nequilibria of the game change. In particular, because the\nextent of prior uncertainty is reduced by updating, the range\nof outcomes compatible with equilibrium shrinks, and so an equilibrium\nis more likely to be found by real-life agents.\n\nBecause Bayes\u2019s Rule is a principle to govern learning, it can\nbe relevant to games where at least some players have information that\nis either imperfect or incomplete. Where only imperfect information is\nconcerned, a theory of subjective expected utility that follows or\nmodifies Savage\u2019s axioms applies directly. This is the subject\nof the remainder of this section. Incomplete information raises deeper\nchallenges, which we will consider in later sections. But our\nrepeated-game example above allows for a particularly interesting and\npowerful application of Bayes\u2019s Rule. If players know that other\nplayers follow Bayes\u2019s Rule in updating their beliefs,\nand utility depends exclusively on information, then when\nplayers received shared signals they can jointly solve their strategic\nproblems by identifying what Aumann\n (1974,\n 1987) called \u2018correlated equilibrium\u2019. \n\nFor now, to illustrate use of Bayes\u2019s Rule in the most\nstraightforward kind of case, imperfect information without Nature in\nextensive-form games, we\u2019ll start with Selten\u2019s Horse\n(i.e., Figure 13). If we assume that players\u2019 beliefs are\nconsistent with Bayes\u2019s Rule, then we may define a\nsequential equilibrium as a solution to the game. A SE has\ntwo parts: (1) a strategy profile \u00a7 for each player, as before,\nand (2) a system of beliefs \\(\\mu\\) for each player. \\(\\mu\\)\nassigns to each information set \\(h\\) a probability distribution over\nthe nodes in \\(h\\), with the interpretation that these are the beliefs\nof player \\(i(h)\\) about where in her information set she is, given\nthat information set \\(h\\) has been reached. Then a sequential\nequilibrium is a profile of strategies \u00a7 and a system of beliefs\n\\(\\mu\\) consistent with Bayes\u2019s rule such that starting from\nevery information set \\(h\\) in the tree player \\(i(h)\\) plays\noptimally from then on, given that what she believes to have\ntranspired previously is given by \\(\\mu(h)\\) and what will transpire\nat subsequent moves is given by \u00a7.\n\nConsider again the NE that we previously identified for Selten\u2019s\nHorse, \\((\\mathrm{R}, r_2, r_3).\\) Suppose that Player III assigns\npr(1) to her belief that if she gets a move she is at node 13. Then\nPlayer I, given a consistent \\(\\mu(I),\\) must believe that Player III\nwill play \\(l_3\\), in which case her only SE strategy is L. So\nalthough \\((\\mathrm{R}, r_2, l_3)\\) is a NE, it is not a SE. \n\nThe use of the consistency requirement in this example is somewhat\ntrivial, so consider now a second case (also taken from\n Kreps (1990),\n p. 429):\n\n\n\nFigure 14\n\n\nSuppose that Player I plays L, Player II plays \\(l_2\\) and Player III\nplays \\(l_3\\). Suppose also that \\(\\mu\\)(II) assigns \\(pr(.3)\\) to\nnode 16. In that case, \\(l_2\\) is not a SE strategy for Player II,\nsince \\(l_2\\) returns an expected payoff of \\(.3(4) + .7(2) = 2.6,\\)\nwhile \\(r_2\\) brings an expected payoff of 3.1. Notice that if we\nfiddle the strategy profile for player III while leaving everything\nelse fixed, \\(l_2\\) could become a SE strategy for Player II.\nIf \u00a7(III) yielded a play of \\(l_3\\) with \\(pr(.5)\\) and \\(r_3\\)\nwith \\(pr(.5),\\) then if Player II plays \\(r_2\\) his expected payoff\nwould now be 2.2, so \\((\\mathrm{L},l_2,l_3)\\) would be a SE. Now\nimagine setting \\(\\mu\\)(III) back as it was, but change \\(\\mu\\)(II) so\nthat Player II thinks the conditional probability of being at node 16\nis greater than .5; in that case, \\(l_2\\) is again not a SE\nstrategy.\n\nThe idea of SE is hopefully now clear. We can apply it to the\nriver-crossing game in a way that avoids the necessity for the pursuer\nto flip any coins of we modify the game a bit. Suppose now that the\npursuer can change bridges twice during the fugitive\u2019s passage,\nand will catch him just in case she meets him as he leaves the bridge.\nThen the pursuer\u2019s SE strategy is to divide her time at the\nthree bridges in accordance with the proportion given by the equation\nin the third paragraph of Section 3 above.\n\nIt must be noted that since Bayes\u2019s rule cannot be applied to\nevents with probability 0, its application to SE requires that players\nassign non-zero probabilities to all actions available in extensive\nform. This requirement is captured by supposing that all strategy\nprofiles be strictly mixed, that is, that every action at\nevery information set be taken with positive probability. You will see\nthat this is just equivalent to supposing that all hands sometimes\ntremble, or alternatively that no expectations are quite certain. A SE\nis said to be trembling-hand perfect if all strategies played\nat equilibrium are best replies to strategies that are strictly mixed.\nYou should also not be surprised to be told that no weakly dominated\nstrategy can be trembling-hand perfect, since the possibility of\ntrembling hands gives players the most persuasive reason for avoiding\nsuch strategies.\n\nHow can the non-psychological game theorist understand the concept of\nan NE that is an equilibrium in both actions and beliefs? Decades of\nexperimental study have shown that when human subjects play games,\nespecially games that ideally call for use of Bayes\u2019s rule in\nmaking conjectures about other players\u2019 beliefs, we should\nexpect significant heterogeneity in strategic responses.\nMultiple kinds of informational channels typically link different\nagents with the incentive structures in their environments. Some\nagents may actually compute equilibria, with more or less error.\nOthers may settle within error ranges that stochastically drift around\nequilibrium values through more or less myopic conditioned learning.\nStill others may select response patterns by copying the behavior of\nother agents, or by following rules of thumb that are embedded in\ncultural and institutional structures and represent historical\ncollective learning. Note that the issue here is specific to game\ntheory, rather than merely being a reiteration of a more general\npoint, which would apply to any behavioral science, that people behave\nnoisily from the perspective of ideal theory. In a given game, whether\nit would be rational for even a trained, self-aware, computationally\nwell resourced agent to play NE would depend on the frequency with\nwhich he or she expected others to do likewise. If she expects some\nother players to stray from NE play, this may give her a reason to\nstray herself. Instead of predicting that human players will reveal\nstrict NE strategies, the experienced experimenter or modeler\nanticipates that there will be a relationship between their play and\nthe expected costs of departures from NE. Consequently, maximum\nlikelihood estimation of observed actions typically identifies a QRE\nas providing a better fit than any NE. \n\nAn analyst handling empirical data in this way should not be\ninterpreted as \u2018testing the hypothesis\u2019 that the agents\nunder analysis are \u2018rational\u2019. Rather, she conjectures\nthat they are agents, that is, that there is a systematic relationship\nbetween changes in statistical patterns in their behavior and some\nrisk-weighted cardinal rankings of possible goal-states. If the agents\nare people or institutionally structured groups of people that monitor\none another and are incentivized to attempt to act collectively, these\nconjectures will often be regarded as reasonable by critics, or even\nas pragmatically beyond question, even if always defeasible given the\nnon-zero possibility of bizarre unknown circumstances of the kind\nphilosophers sometimes consider (e.g., the apparent people are\npre-programmed unintelligent mechanical simulacra that would be\nrevealed as such if only the environment incentivized responses not\nwritten into their programs). The analyst might assume that all of the\nagents respond to incentive changes in accordance with Savage\nexpected-utility theory, particularly if the agents are firms that\nhave learned response contingencies under normatively demanding\nconditions of market competition with many players. If the\nanalyst\u2019s subjects are individual people, and especially if they\nare in a non-standard environment relative to their cultural and\ninstitutional experience, she might more wisely estimate a maximum\nlikelihood mixture model that allows that a range of different utility\nstructures govern different subsets of her choice data. The way to\nthink about this is as follows. Each utility model that applies to\nsome people in the sample describes a data-generating process (DGP).\nThese various DGPs interact in the game to produce outcomes. When the\ndata are used to estimate the mixture model, she learns which\nproportions of the data are best estimated by which of her\nhypothesised DGPs (provided she specified her models well enough given\nher data to identify them). All this is to say that use of game theory\ndoes not force a scientist to empirically apply a model that is likely\nto be too precise and narrow in its specifications to plausibly fit\nthe messy complexities of real strategic interaction. A good applied\ngame theorist should also be a well-schooled econometrician.\n\nOne crucial caveat, to which we will return in\n Section 8,\n is that when we apply game theory to a situation in which agents have\nopportunities to learn, because their information is imperfect or\nincomplete, then we must decide whether it is or is not reasonable to\nexpect the agents to update their beliefs using Bayes\u2019s Rule. If\nwe do not think we are empirically justified in such an\nexpectation, then we might expect agents to take actions that have no\nstrategic purpose other than to directly probe the parametric or\nstrategic environment. This presents all players with a special source\nof additional uncertainty: was the function of another player\u2019s\naction\u2019s to probe or to directly harvest utility? Handling\napplications that must allow for this kind of uncertainty requires\nconsiderable mathematical expertise, as reviewed in\n Fudenberg and Levine (1998)\n and updated in\n Fudenberg and Levine (2008).\n The consequent range of modelling discretion makes situations\ninvolving non-Bayesian learning treacherous for the applied game\ntheorist to try to predict; often, the best she can expect to usefully\ndo is explain what happened after the fact. (It should be added that\nsuch explanation is often essential for generalization to new cases,\nand, at least as importantly, to intervening if participants or\nregulators want to change outcomes.) The reader might suppose that\nthis must be the standard case: how likely can it be that people, most\nof whom have never heard of Bayes\u2019s Rule, let alone used it\ncalculate predictions, will both learn according to the rule and\nanticipate that those with whom they interact will do so too? But\nthere is a response to this basis for scepticism. Most animals,\nincluding people, have no explicit knowledge of why they behave as\nthey do. Where Bayesian learning specifically is concerned, there is\ngrowing evidence from neuroscience that what distinguishes\nneuro-cortical learning from learning in older brain regions is that\nthe former is fundamentally Bayesian\n (Clark 2016;\n Parr et al 2022). This makes explanatory sense: Bayesian learning is\nsituationally flexible learning, and supplying capacity for such\nlearning is almost certainly the function that caused neocortex to\ngrow over time in a number of socially intelligent animals, and to\nacquire a significantly larger battery of cerebral cortical neurons in\nthe case of modern humans\n (Godfrey-Smith 1996).\n It is a plausible conjecture that people are Bayesian learners\nwhether they know it or not.\n\nThe game theorist can directly exploit Bayesian learning at the\nmeta-level of her own modelling. Above it was suggested that applied\ngame theorists should estimate maximum-likelihood mixture models to\ncapture heterogeneous risk-preference structures in groups of people.\nIn the existing literature this is the current state of the art. But\nit has a limitation: results are sensitive to the modeller\u2019s\ndiscretion concerning which models she includes in her mixtures, and\nthere is no settled typology of such models. The need for such\nunprincipled discretion is potentially eliminated if the theorist\ninstead uses a Hierarchical Bayesian model (see\n Kruschke 2014;\n McElreath 2020). Advice to take up this resource does not call upon the\ngame theorist to become an expert coder, as a routine for such models\nis now included in the economist\u2019s standard econometrics\npackage, Stata (TM). This promises a substantial potential improvement\nin the power and accuracy of game-theoretic models of real strategic\ninteractions, and is an attractive target for future research.\n4. Repeated Games and Coordination\n\nSo far we\u2019ve restricted our attention to one-shot\ngames, that is, games in which players\u2019 strategic concerns\nextend no further than the terminal nodes of their single interaction.\nHowever, games are often played with future games in mind,\nand this can significantly alter their outcomes and equilibrium\nstrategies. Our topic in this section is repeated games, that\nis, games in which sets of players expect to face each other in\nsimilar situations on multiple occasions. We approach these first\nthrough the limited context of repeated prisoner\u2019s dilemmas.\n\n\nWe\u2019ve seen that in the one-shot PD the only NE is mutual\ndefection. This may no longer hold, however, if the players expect to\nmeet each other again in future PDs. Imagine that four firms, all\nmaking widgets, agree to maintain high prices by jointly restricting\nsupply. (That is, they form a cartel.) This will only work if each\nfirm maintains its agreed production quota. Typically, each firm can\nmaximize its profit by departing from its quota while the others\nobserve theirs, since it then sells more units at the higher market\nprice brought about by the almost-intact cartel. In the one-shot case,\nall firms would share this incentive to defect and the cartel would\nimmediately collapse. However, the firms expect to face each other in\ncompetition for a long period. In this case, each firm knows that if\nit breaks the cartel agreement, the others can punish it by\nunderpricing it for a period long enough to more than eliminate its\nshort-term gain. Of course, the punishing firms will take short-term\nlosses too during their period of underpricing. But these losses may\nbe worth taking if they serve to reestablish the cartel and bring\nabout maximum long-term prices.\n\nOne simple, and famous (but not, contrary to widespread myth,\nnecessarily optimal) strategy for preserving cooperation in repeated\nPDs is called Tit-for-tat. This strategy tells each player to\nbehave as follows:\n\nAlways cooperate in the first round.\nThereafter, take whatever action your opponent took in the\nprevious round.\n\n\nA group of players all playing Tit-for-tat will never see any\ndefections. Since, in a population where others play tit-for-tat, no\ntit-for-tat player could do (strictly) better by adopting an\nalternative strategy, everyone playing tit-for-tat is a NE. You may\nfrequently hear people who know a little (but not enough)\ngame theory talk as if this is the end of the story. It is not at all.\nThere are three major complications.\n\nFirst, and most fundamentally, everyone playing Tit-for-tat is not a\nunique NE. Many other strategies, such as Grim (cooperate\nuntil defected against by a player, then defect against that defector\nunconditionally forever) and Tit-for-two-tats (cooperate until\ndefected against twice by a player, then defect once before reverting\nto cooperation) occur in various NE combinations. In general, it is\nnot a requirement for equilibrium that all players use the same\nstrategy. The more limited virtue that can be claimed for Tit-for-tat\nis that it is a simple strategy that does well on average\nagainst the strategies that people tend, based on evidence from actual\ntournaments with real people, to choose. But this can also be claimed\nfor Grim. Whereas Tit-for-tat might be said to be \u2018nice\u2019\nbecause it is forgiving of offence, the opposite is true of Grim. In\ngeneral, there is an infinite set of combinations of strategies in a\nlarge population that are equilibria in repeated games if\nplayers don\u2019t know which round of the game will be the final one\nuntil they get there.\n\nThis last point is the second complication I promised to indicate. To\ncooperate in a repeated PD players must be uncertain as to when their\ninteraction ends. Suppose the players know when the last round comes.\nIn that round, it will be utility-maximizing for players to defect,\nsince no punishment will be possible. Now consider the second-last\nround. In this round, players also face no punishment for defection,\nsince they expect to defect in the last round anyway. So they defect\nin the second-last round. But this means they face no threat of\npunishment in the third-last round, and defect there too. We can\nsimply iterate this backwards through the game tree until we reach the\nfirst round. Since cooperation is not a NE strategy in that round,\ntit-for-tat is no longer a NE strategy in the repeated game, and we\nget the same outcome\u2014mutual defection\u2014as in the one-shot\nPD. Therefore, cooperation is only possible in repeated PDs where the\nexpected number of repetitions is indeterminate. (Of course, this does\napply to many real-life games.) Note that in this context any amount\nof uncertainty in expectations, or possibility of trembling hands,\nwill be conducive to cooperation, at least for awhile. When people in\nexperiments play repeated PDs with known end-points, they indeed tend\nto cooperate for awhile, but learn to defect earlier as they gain\nexperience.\n\nNow we introduce a third complication. Suppose that players\u2019\nability to distinguish defection from cooperation is imperfect.\nConsider our case of the widget cartel. Suppose the players observe a\nfall in the market price of widgets. Perhaps this is because a cartel\nmember cheated. Or perhaps it has resulted from an exogenous drop in\ndemand. If Tit-for-tat players mistake the second case for the first,\nthey will defect, thereby setting off a chain-reaction of mutual\ndefections from which they can never recover, since every player will\nreply to the first encountered defection with defection, thereby\nbegetting further defections, and so on.\n\nIf players know that such miscommunication is possible, they have\nincentive to resort to more sophisticated strategies. In particular,\nthey may be prepared to sometimes risk following defections with\ncooperation in order to test their inferences. However, if they are\ntoo forgiving, then other players can exploit them through\nadditional defections. In general, as strategies become more\nsophisticated, players of games in which they occur encounter more\ndifficult learning challenges. Because more sophisticated strategies\nare more difficult for other players to infer (because they are\ncompatible with more variable and complicated patterns of observable\nbehavior), their use increases the probability of miscommunication.\nBut miscommunication is what causes repeated-game cooperative\nequilibria to unravel in the first place. The complexities surrounding\ninformation signaling, screening and inference in repeated PDs help to\nintuitively explain the folk theorem, so called because no\none is sure who first recognized it, that in repeated PDs, for\nany strategy \\(S\\) there exists a possible distribution of\nstrategies among other players such that the vector of \\(S\\) and these\nother strategies is a NE. When critics of applications of game theory\nto behavioral and social science and business cases complain that the\napplications in question assume implausible levels of inferential\ncapacity on the part of people, this is what they have in mind. In\n Section 5\n we will consider a way of responding to this kind of concern.\n\nReal, complex, social and political dramas are seldom straightforward\ninstantiations of simple games such as PDs.\n Hardin (1995)\n offers an analysis of two tragically real political cases, the\nYugoslavian civil war of 1991\u201395, and the 1994 Rwandan genocide,\nas PDs that were nested inside coordination games.\n\nA coordination game occurs whenever the utility of two or more players\nis maximized by their doing the same thing as one another, and where\nsuch correspondence is more important to them than whatever it is, in\nparticular, that they both do. A standard example arises with rules of\nthe road: \u2018All drive on the left\u2019 and \u2018All drive on\nthe right\u2019 are both outcomes that are NEs, and neither is more\nefficient than the other. In games of \u2018pure\u2019 coordination,\nit doesn\u2019t even help to use more selective equilibrium criteria.\nFor example, suppose that we require our players to reason in\naccordance with Bayes\u2019s rule (see Section 3 above). In these\ncircumstances, any strategy that is a best reply to any vector of\nmixed strategies available in NE is said to be\nrationalizable. That is, a player can find a set of systems\nof beliefs for the other players such that any history of the game\nalong an equilibrium path is consistent with that set of systems. Pure\ncoordination games are characterized by non-unique vectors of\nrationalizable strategies. The Nobel laureate Thomas\n Schelling (1978)\n conjectured, and empirically demonstrated, that in such situations,\nplayers may try to predict equilibria by searching for focal\npoints, that is, features of some strategies that they believe\nwill be salient to other players, and that they believe other players\nwill believe to be salient to them. For example, if two people want to\nmeet on a given day in a big city but can\u2019t contact each other\nto arrange a specific time and place, both might sensibly go to the\ncity\u2019s most prominent downtown plaza at noon. In general, the\nbetter players know one another, or the more often they have been able\nto observe one another\u2019s strategic behavior, the more likely\nthey are to succeed in finding focal points on which to coordinate.\n\n\nCoordination was, indeed, the first topic of game-theoretic\napplication that came to the widespread attention of philosophers. In\n1969, the philosopher\n David Lewis (1969)\n published Convention, in which the conceptual framework of\ngame-theory was applied to one of the fundamental issues of\ntwentieth-century epistemology, the nature and extent of conventions\ngoverning semantics and their relationship to the justification of\npropositional beliefs. The basic insight can be captured using a\nsimple example. The word \u2018chicken\u2019 denotes chickens and\n\u2018ostrich\u2019 denotes ostriches. We would not be better or\nworse off if \u2018chicken\u2019 denoted ostriches and\n\u2018ostrich\u2019 denoted chickens; however, we would be\nworse off if half of us used the pair of words the first way and half\nthe second, or if all of us randomized between them to refer to\nflightless birds generally. This insight, of course, well preceded\nLewis; but what he recognized is that this situation has the logical\nform of a coordination game. Thus, while particular conventions may be\narbitrary, the interactive structures that stabilize and maintain them\nare not. Furthermore, the equilibria involved in coordinating on noun\nmeanings appear to have an arbitrary element only because we cannot\nPareto-rank them; but\n Millikan (1984)\n shows implicitly that in this respect they are atypical of linguistic\ncoordinations. They are certainly atypical of coordinating conventions\nin general, a point on which Lewis was misled by over-valuing\n\u2018semantic intuitions\u2019 about \u2018the meaning\u2019of\n\u2018convention\u2019\n (Bacharach 2006,\n Ross 2008a).\n\nRoss & LaCasse (1995)\n present the following example of a real-life coordination game in\nwhich the NE are not Pareto-indifferent, but the Pareto-inferior NE is\nmore frequently observed. In a city, drivers must coordinate on one of\ntwo NE with respect to their behaviour at traffic lights. Either all\nmust follow the strategy of rushing to try to race through lights that\nturn yellow (or amber) and pausing before proceeding when red lights\nshift to green, or all must follow the strategy of slowing down on\nyellows and jumping immediately off on shifts to green. Both patterns\nare NE, in that once a community has coordinated on one of them then\nno individual has an incentive to deviate: those who slow down on\nyellows while others are rushing them will get rear-ended, while those\nwho rush yellows in the other equilibrium will risk collision with\nthose who jump off straightaway on greens. Therefore, once a\ncity\u2019s traffic pattern settles on one of these equilibria it\nwill tend to stay there. And, indeed, these are the two patterns that\nare observed in the world\u2019s cities. However, the two equilibria\nare not Pareto-indifferent, since the second NE allows more cars to\nturn left on each cycle in a left-hand-drive jurisdiction, and right\non each cycle in a right-hand jurisdiction, which reduces the main\ncause of bottlenecks in urban road networks and allows all drivers to\nexpect greater efficiency in getting about. Unfortunately, for reasons\nabout which we can only speculate pending further empirical work and\nanalysis, far more cities are locked onto the Pareto-inferior NE than\non the Pareto-superior one.\n\nIn cases such as this one, maintenance of coordination game equilibria\nlikely must be supported by stable social norms, because\nplayers are anonymous and encounter regular opportunities to gain\nonce-off advantages by defecting from supporting the prevailing\nequilibrium. As many authors have observed (but see particularly\n Bicchieri 2006\n and\n Binmore 2005a),\n a stable norm must itself describe what players do in an equilibrium\nof the game, or at least one player would be incentivised to violate\nthe norm. But, as\n Guala (2016)\n argues, to perform a special role in helping players jointly find\nequilibrium in a coordination game, a norm must be more than\nan equilibrium description; it must also function as a rule.\nWhat Guala means by this is that it must encode expectations, which\nplayers know, about which behaviors in the relevant society will be\nrewarded by social approval if followed, and punished by social\nsanctions (e.g. gossip, ostracism, prosecution, vigilante violence) if\nviolated. The human biological inheritance causes most people to\ninternalize some norms, that is, learn to experience\nunpleasant feelings of guilt or shame when they violate norms they\nendorse, and feelings of satisfaction when they follow norms in the\nface of temptations to break them for selfish gain. Thus norms can\nhelp people find equilibria in coordination games even when some\nindividual choices in these games aren\u2019t observed by any other\npeople.\n\nOf course, norms are far from perfectly reliable mechanisms. Every\nreal society has many norms that some people don\u2019t endorse, and\ntherefore probably don\u2019t internalize, and therefore might break\nwhenever they think they can do so unobserved, or in return for a\npunishment they don\u2019t consider too costly. This provides endless\nfuel for conflict in any social setting with much degree of\ncomplexity. In addition, if its norms don\u2019t evolve with changing\ntechnology and other circumstances, a society will find itself trapped\nby conservatism in growing inefficiencies. But evolution of norms\nover time implies disagreements about norms at at\ntime, unless everyone switches norms at the same time. But\nthat would itself require solving a coordination game for which\nmeta-norms are typically absent! As\n Kuran (1995)\n empirically reviews and models, normative change often works through\ncycles of preference falsification and discovery. That is, increasing\nnumbers of people might privately come to dislike a norm but continue\nto publicly support and follow it because they assume that most others\nstill support it, and that conforming with it, and even helping to\nenforce it, is their equilibrium strategy. At a given time, a majority\nmight be behaving in this way, which prevents anyone from recognizing\nthat a new equilibrium without the norm, or with an opposed norm, is\navailable. Such concealed preferences tend to leak, however, and\nsooner or later publicly visible signals of widespread dissatisfaction\nwith the norm will be publicly observable. This often has the effect\nof suggesting that a whole society changed its mind suddenly and\ndramatically as the equilibrium flips. For example, in North American\nbusiness culture, executives went from norms favouring convivial\n\u2018liquid lunches\u2019 to strongly enforced norms against any\ndrinking during working hours within about two years during the\nmid-1980s. We can infer from this that many executives had considered\nboozy mid-day meals a bad thing while still engaging in them, before\nrealizing that this was the majority\u2019s hidden opinion. (Such\npreference falsification should not be confused with the superficially\nsimilar phenomenon of \u2018pluralistic ignorance\u2019. These are\ncases where many people have false beliefs about the statistical\nfrequency of a pattern of behavior, and are motivated to conform their\nown behavior to the norm suggested by this false belief. Pluralistic\nignorance tends to erode only slowly and gradually, as errors of\nstatistical perception are chipped away. not displaying the whipsaw\ninstability of equilibria sustained by preference falsification.\nPreference falsification is a directly strategic phenomenon and\ntherefore a topic for game theorists. Pluralistic ignorance has at\nbest a derivative game-theoretic element in some instances.)\n\nConventions on standards of evidence and scientific rationality, the\ntopics from philosophy of science that set up the context for\nLewis\u2019s analysis, are likely to be of the Pareto-rankable\ncharacter. While various arrangements might be NE in the social game\nof science, as followers of Thomas Kuhn like to remind us, it is\nhighly improbable that all of these lie on a single\nPareto-indifference curve. These themes, strongly represented in\ncontemporary epistemology, philosophy of science and philosophy of\nlanguage, are all at least implicit applications of game theory. (The\nreader can find a broad sample of applications, and references to the\nlarge literature, in\n Nozick (1998).)\n\nMost of the social and political coordination games played by people\nalso have this feature. Unfortunately for us all, inefficiency traps\nrepresented by Pareto-inferior NE are extremely common in them. And\nsometimes dynamics of this kind give rise to the most terrible of all\nrecurrent human collective behaviors. Hardin\u2019s analysis of two\nrecent genocidal episodes relies on the idea that the biologically\nshallow properties by which people sort themselves into racial and\nethnic groups serve highly efficiently as focal points in coordination\ngames, which in turn produce deadly PDs between them.\n\nAccording to Hardin, neither the Yugoslavian nor the Rwandan disasters\nwere PDs to begin with. That is, in neither situation, on either side,\ndid most people begin by preferring their exclusive ethnic interests\nto general mutual cooperation and regulated competition among\nindividuals and multi-ethnic associations. However, the deadly logic\nof coordination, deliberately abetted by self-serving politicians,\ndynamically created PDs. Some individual Serbs (Hutus) were\nencouraged to perceive their individual interests as best served\nthrough identification with Serbian (Hutu) group-interests. That is,\nthey found that some of their circumstances, such as those involving\ncompetition for jobs, had the form of coordination games\nwithin their respective ethnic communities. This incentivised\nincreasing numbers of people to put pressure on their ethnic\ncompatriots to take up coordinating strategies. Eventually, once\nenough Serbs (Hutus) identified self-interest with group-interest, the\nidentification became almost universally correct, because (1)\nthe most important goal for each Serb (Hutu) was to do roughly what\nevery other Serb (Hutu) would, and (2) the most distinctively\nSerbian thing to do, the doing of which signalled\ncoordination, was to exclude Croats (Tutsi). That is, strategies\ninvolving such exclusionary behavior were selected as a result of\nhaving efficient focal points. This situation made it the case that an\nindividual\u2014and individually threatened\u2014Croat\u2019s\n(Tutsi\u2019s) self-interest was best maximized by coordinating on\nassertive Croat (Tutsi) group-identity, which further increased\npressures on Serbs (Hutus) to coordinate, and so on. Note that it is\nnot an aspect of this analysis to suggest that Serbs or Hutus started\nthings; the process could have been (even if it wasn\u2019t in fact)\nperfectly reciprocal. But the outcome is ghastly: Serbs and Croats\n(Hutus and Tutsis) seem progressively more threatening to each other\nas they rally together for self-defense, until both see it as\nimperative to preempt their rivals and strike before being struck. If\nHardin is right\u2014and the point here is not to claim that he\nis, but rather to point out the worldly importance of\ndetermining which games agents are in fact playing\u2014then the mere\npresence of an external enforcer (NATO?) would not have changed the\ngame, pace the Hobbesian analysis, since the enforcer could not have\nthreatened either side with anything worse than what each feared from\nthe other. What was needed was recalibration of evaluations of\ninterests, which (arguably) happened in Yugoslavia when the Croatian\narmy began to decisively win, at which point Bosnian Serbs decided\nthat their self/group interests were better served by the arrival of\nNATO peacekeepers. The Rwandan genocide likewise ended with a military\nsolution, in this case a Tutsi victory. (But this became the seed for\nthe most deadly international war on earth since 1945, the Congo War\nof 1998\u20132006.)\n\nThis dynamic of coordinating polarization is frequently invoked by\npolitical scientists to explain escalating conflict within countries.\nIts basis need not be ethnicity. For another example, the widely\nobserved increase in polarization of party-political identities in the\nUnited States over the past three decades is often modelled using\ngame-theoretic logic along Hardin\u2019s lines. In a two-party system\nsuch as America\u2019s, if supporters of one party come to believe\nthat having their party in power is more important than its policies\non particular issues, and so begin behaving overwhelmingly\nstrategically and opportunistically, this behavior incentivises\nsupporters of the other party to adopt the same attitude. The beliefs\nin question are thus self-ratifying, making it true that the\nhighest interest stakes for both sets of supporters is in the victory\nof their own faction. Relentless zero-sum competition conditioned on\nparty affiliation erodes cross-party associations, and in the US was\nobserved as early as 2009\n (Bishop 2009)\n to be causing Americans to separate geographically and culturally\ninto blocks that recognise and define themselves mainly by contrast\nwith one another\u2019s symbols and icons. Once people incorporate\npolitical preferences into their conceptions of their identities, it\nbecomes extremely difficult to present anyone with effectively\ncompeting counter-incentives; as discussed in\n Ross (2005a),\n most people rank maintenance of their social identities near or at\nthe top of their effective preference orderings, for reasons that\ngame-theoretic models explain well: a person whose social identity\nappears as indeterminate or unsteady to others will have difficulty\nfinding coordination partners. Forming teams to carry out group\nprojects is the basic human survival strategy. Thus the game-theoretic\nlens helps us to see that the roots of our ecological success as a\nspecies are also the roots of our tendency to form mutually hostile\nethnic or purely cultural tribes, which is in turn the most\nbasic source of large-scale, generally destructive, human conflict.\n\n\nOf course, it is not the case that most repeated games lead to\ndisasters. The biological basis of friendship in people and other\nanimals is partly a function of the logic of repeated games. The\nimportance of payoffs achievable through cooperation in future games\nleads those who expect to interact in them to be less selfish than\ntemptation would otherwise encourage in present games. The fact that\nsuch equilibria become more stable through learning gives friends the\nlogical character of built-up investments, which most people take\ngreat pleasure in sentimentalizing. Furthermore, cultivating shared\ninterests and sentiments provides networks of focal points around\nwhich coordination can be increasingly facilitated. Coordination is in\nturn the foundation of both cooperation and the controlled\ncompetition that drives material and cultural innovation.\n\nA key sub-theme of coordination is specialization of labor within\nteams. Because the first extended commentary on this topic was given\nby Adam Smith, who is associated with the origin of rigorous\neconomics, specialization of labor is strongly culturally associated,\neverywhere in the world, with commercial production. However, it has\nbeen a fundamental feature of human life since the dawn of our\nspecies. The paleoeconomist\n Haim Ofek (2001)\n argues persuasively that our immediate pre-Sapiens ancestors\nwere able to control fire because they learned to divide labor between\nspecialist fire-maintainers, and, on the other side of the market,\nthose who gathered and hunted. Cooking, which vastly increased the\nefficiency of food consumption and freed proto-people to devote time\nto other things such as cultivation of tools and social enrichment,\nwas in turn an essential triggering condition for the explosive growth\nof the human brain\n (Wrangham 2009),\n and subsequently, as argued by\n Planer and Sterelny (2009),\n for the emergence of language. Thus on Ofek\u2019s account,\ncoordinated specialisation of labor in the most narrowly and literally\neconomic sense lay at the very foundation of the human career; the\nfirst people who maintained fire station services that they bartered\nfor the kills and tools of their customers were the first business\nenterprises. Perhaps paleolithic fire station operators competed for\ncustomers and for accessible sites protected from rain by overhead\nrock ledges or cave ceilings; if so, the logic of industrial\norganization theory, the first sub-field of economics taken over by\ngame theory, would have applied to their strategizing.\n\nIn the simplest models of specialization of labor, the different roles\ncan be assigned by chance. If two of us are making pizza, who grates\nthe cheese and who slices the mushrooms might be decided by who\nhappens to be standing closer to which implement. But this kind of\nsituation isn\u2019t typical. More often, role assignments are a\nfunction of differential abilities. If two of us will row a boat, and\none of us is right-handed while the other is left-handed, it\u2019s\nobvious who should sit on which side. In this case there should be no\ncall for strategic bargaining over who does what, because benefits\narising from getting where we want to go as quickly as possible are\nsymmetrically shared. But this is also an atypical kind of\ncase. More frequently, some roles are less costly to perform than\nothers, or attract greater expected rewards. Everyone who has formed a\nrock band knows that a disproportionate share of fame and fringe\nbenefits tends to go to the lead guitarist rather than the drummer or\nthe bass player. For decades after the birth of rock, there was a\nnotable absence of female lead guitarists among successful bands, and\nmuch consequent commentary by female musicians and fans about pompous\nmacho posturing in the common stage attitudes of \u2018guitar\nheroes\u2019. Bands like Sleater-Kinney and the Breeders have been\nnotable for pushing back against this cultural trope. This example\ndraws attention to a much more general and deeply important aspect of\nspecialization of labor, on which game theory sheds crucial light.\n\nAs discussed above, specialization of labor was foundational for the\nevolution and rise to ecological dominance of the human species. And\nthe most pervasive and significant basis for assigning differentiated\nroles, observed in every naturally arising human population, is sex.\nThe original basis for this is almost certainly some asymmetries in\nrelative performance advantages on different tasks, as in the case of\nthe boat rowers. Hunting large game is more efficiently carried out by\npeople with bigger muscles. Furthermore, hunting requires mobility and\noften silence, so is best not done while carrying babies. Thus a very\ncommon, though not universal, pattern of specialization in\nhunter-gatherer communities, including surviving contemporary ones, is\nfor men to hunt while women gather and perform tasks, such as mending\nand food processing, that can be carried out at home base and combined\nwith child-minding. The consequences of this are politically profound.\nHunters become masters of weapons. Masters of weapons tend to exercise\ndisproportionate power, especially if, as in later stages of human\necological history, the communities they belong to periodically engage\nin violent conflict with other groups. It has long been understood\nthat the roots of male political and social dominance that is the\npredominant pattern across human history and cultures has its roots in\nthis ancient division of productive roles.\n\nIn modern societies, hunting is fringe activity and the most powerful\npeople are not those who are most adept at throwing spears. This has\nbeen so, in most cultural lines, for a very long time, so there has\nbeen plenty of scope for cultural evolution to wash away traditional\nsources of power imbalance. This makes the stubborn persistence of\ngendered inequality puzzling at first glance. It has often fostered\nspeculation about possible innate male dispositions to be more\neffective, or at least more ruthless, executives and presidents. Or\nperhaps, it is sometimes suggested, the ultimate source of the power\nasymmetry is asymmetry of threats of physical violence in households.\n(This is certainly real, and a genuine basis for male tyranny in many\ndomestic partnerships. But what is at issue is whether it suffices to\nexplain pervasive patterns.) Recent work by the game theorist\n Cailin O\u2019Connor (2019)\n suggests a deeper and much more powerful explanation. It is more\nscientifically powerful partly because it fits a range of evidence\nmore closely than the reductive stories just mentioned, but also\nbecause it accounts for more specific side-effects of the general\nphenomenon. In particular, it explains the stabilization of culturally\nlearned gender characteristics that help people signal awareness and\nacceptance of roles expected to be associated with their biological\nsexes. Of course, this cultural code, since it can be strategically\nmanipulated, also allows some people to signal rejection of\nthese roles, and to coordinate this rejection with other women, men,\nor non-binary people, who seek reformed equilibria.\n\nO\u2019Connor\u2019s game-theoretic analysis comes in two parts.\nFirst, she uses evolutionary game theory, the topic of\n Section 7\n below, to show how relatively functionally minor asymmetries\nin role effectiveness can foster extremely robust use of group\ndifference markers that entrench unequal outcomes. Selecting\nequilibria for role specialization is, as we\u2019ve seen earlier in\nthis section, logically difficult in the absence of correlation\nsignals. A society will tend to seize on any such signal that is\nfrequently and reliably available, and following equilibrium\nstrategies based on such signals is in each player\u2019s marginal\nself-interest from game to game, even if, as in the PD, many or even\nall could be better off if the whole set of agents could flip to an\nalternative equilibrium. Then, as we have also discussed, the signals\nin question will tend to culturally evolve into the basis for norms,\nso that, as in the phenomenon under discussion, women who \u2018walk\nlike men\u2019or \u2018talk like men\u2019or show interest in\n\u2018male\u2019activities or sexual partners are subject to\nsanctions, including by many other women. Thus does sex beget gender.\n(Notice that if women really were less competent leaders than\nmen, then, given that leadership is typically earned through\ncompetition in functional settings, it is not clear why sexually\ndifferentiated roles would need to be sustained by normative\ngenders in the first place.) In effect, O\u2019Connor\u2019s first\napplication of game theory shows that women are assigned different\nsocial roles from men, which leads to inequality, simply because\n\u2018sex\u2019is a group assignment we can usually (not quite\nalways) determine about a person at birth, before we embark on\nsocializing them. (The reader will note that similar logic based on\ncorrelated equilibrium applies to the normative construct of race,\nwhich has no basis in expected functional capacities at all. This\npartly explains why discrimination against people whose\n\u2018race\u2019can be assigned at a glance, such as Black people in\nthe US, has been vastly harder to overcome than earlier racist\ndiscrimination against Irish people in the same country.)\n\nSexual inequality arising as an equilibrium selection effect may (and\nshould) be criticized on moral grounds, but at least we can recognize\nthat it arose due to (partly) compensating efficiencies. Against this\nstandard, the second part of O\u2019Connor\u2019s analysis suggests\nno such trade-off.\n\nAt the dawn of the development of game theory,\n Nash (1950b)\n modelled a general case of two agents bargaining over the division of\na surplus they could obtain together. Obviously, this is as central a\nphenomenon for economists as anything else it is their job to think\nabout, as important in a simple bartering society as in a capitalist\none. The core of the so-called \u2018Nash bargaining solution\u2019\nis that the equilibria for such negotiations are conditional on the\nrelative values of their fall-back positions should they fail to reach\nagreement. You can get me to pay more for your house if you know that,\nshould we not reach a deal, I\u2019ll have nowhere to put my\nfurniture when my my boat arrives in port. As discussed in depth by\nKen Binmore\n (1994,\n 1998,\n 2005a),\n superior fall-backs in bargaining contexts are the basic source of\npower differentials in a society. Furthermore, as Binmore also argues,\na society\u2019s specific norms tend to evolve to accommodate these\nasymmetries, since failures of alignment in expectations about\n\u2018fairness\u2019in bargaining are every community\u2019s most\nfrequent cause of conflict and of investment failures. O\u2019Connor\napplies this element of game theory to inequality of sex and\ngender.\n\nShe begins where the first part of her analysis leaves off: with\nnormatively entrenched gendered roles that evolve as equilibrium\nselection devices but produce inequality. Note that this is a feature\nof the social macrostructure, the domain of application for\nevolutionary game theory. She then examines the\nmicro-dynamics of a statistically typical household from the\nperspective of Nash bargaining theory (and also using tools from\nstrategic network theory, as touched upon in\n Section 5).\n Evidence from wealthy countries shows that in the subset of\nhouseholds in which men\u2019s and women\u2019s levels of education\nand income have converged, women continue on average to do\ndisproportionate shares of home maintenance work, and their leisure\nhours have declined. Nash bargaining theory can explain why. Suppose\nwe interpret the meaning of a general bargaining breakdown in the case\nof a marriage as divorce. If men spend more time and energy outside\nthe home than women, they thereby build larger flows and stocks of the\nsocial networking assets that make the inefficiencies of single life\nless costly, and are more likely to advance their earning power. Thus\nthey enjoy stronger fall-back positions where bargaining over the\ndivision of household responsibilities is concerned. The unequal\nequilibrium is thus self-amplifying over time, as men\u2019s networks\nprogressively deepen and become more relatively valuable over the\ncourse of both partners\u2019 careers. To accept the relevance of the\nmodel, we need not imagine husbands and wives literally haggling over\nexplicit shares of time, with calculations of expected marginal\ncontributions to household income cited as arguments. We need merely\npicture women repeatedly leaving their offices earlier to pick up\nchildren or receive home service calls because their husbands are\ncontinuously tied up in meetings or business trips with higher stakes\non the immediate line. Unlike the games in the first part of\nO\u2019Connor\u2019s analysis, there are no social efficiencies\nachieved in exchange for this dynamic inequity, since there is no\nreason to suppose that women are intrinsically likely to have less\neconomically productive careers than similarly educated men. And the\npattern of falling female leisure time may increase with\nwomen\u2019s educational advancement, as more demanding professional\nactivities are piled atop stationary levels of household\nresponsibility. (Past a certain level of a household\u2019s wealth we\nmight expect this effect to reverse, as women can hire in-home\nservice. But this applies only to a small upper share of the income\ndistribution.) This part of O\u2019Connor\u2019s model has direct\npolicy implications. Efforts to improve women\u2019s access to\nvaluable credentials, and to encourage companies to increase female\nrepresentation at executive levels, may have muted or even negative\neffects on welfare equality between the sexes. Societies might also\nneed to devote more substantial resources to subsidising childcare\nprovision outside of homes, and living assistance to ageing parents,\nas measures that increase women\u2019s intra-household bargaining\npower. \n\nThe first part of O\u2019Connor\u2019s analysis also has important\nimplications for policy. As she stresses, if inequalities between\ndifferentiable groups arise naturally through equilibrium dynamics in\ncoordination games, then we should not expect to be able to find\npolicies that eradicate them once and for all. Controlling inequality,\nO\u2019Connor concludes, calls for persistent and recurrently applied\npolitical effort by egalitarians. \n\nIn general, coordination dynamics constitute the analytical core of\nthe majority of human social patterns. Examples considered\nhere are merely illustrative of a limitless array of such phenomena,\nwhich cannot be fully understood without empirically guided\nconstruction and application of game-theoretic models. \n5. Team Reasoning and Conditional Games\n\nFollowing\n Lewis\u2019s (1969)\n introduction of coordination games into the philosophical literature,\nthe philosopher Margaret\n Gilbert (1989)\n argued, as against Lewis, that game theory is the wrong kind of\nanalytical technology for thinking about human conventions because,\namong other problems, it is too \u2018individualistic\u2019, whereas\nconventions are essentially social phenomena. More directly, her claim\nwas that conventions are not merely the products of decisions of many\nindividual people, as might be suggested by a theorist who modeled a\nconvention as an equilibrium of an \\(n\\)-person game in which each\nplayer was a single person. Similar concerns about allegedly\nindividualistic foundations of game theory have been echoed by another\nphilosopher, Martin\n Hollis (1998)\n and economists Robert Sugden\n (1993,\n 2000,\n 2003)\n and Michael\n Bacharach (2006).\n In particular, it motivated Bacharach to propose a theory of team\nreasoning, which was completed by Sugden, along with Nathalie\nGold, after Bacharach\u2019s death. In this section we will review\nthe idea of team reasoning, along with an alternative way of applying\ngame theory to sociological topics, the theory of conditional\ngames\n (Stirling (2012);\n Ross and Stirling 2021). \n\nConsider again the one-shot Prisoner\u2019s Dilemma as discussed in\n Section 2.4\n and produced, with an inverted matrix for ease of subsequent\ndiscussion, as follows:\n\n\n\n\nII\n\n\\(C\\)\n\\(D\\)\n\nI\n\\(C\\)\n2,2\n0,3\n\n\\(D\\)\n3,0\n1,1 \n\n\n\n(C denotes the strategy of cooperating with one\u2019s opponent\n(i.e., refusing to confess) and D denotes the strategy of defecting on\na deal with one\u2019s opponent (i.e., confessing).) Many people find\nit incredible when a game theorist tells them that players designated\nwith the honorific \u2018rational\u2019 must choose in this game in\nsuch a way as to produce the outcome (D,D). The explanation seems to\nrequire appeal to very strong forms of both descriptive and normative\nindividualism. After all, if the players attached higher value to the\nsocial good (for their 2-person society of thieves) than to their\nindividual welfare, they could then do better individually too;\nobstinate individualism, it is objected, yields behavior that is\nperverse from the individually optimizing point of view, and so seems\nincoherent. The players undermine their own welfare, one might argue,\nbecause they obstinately refuse to pay any attention to the social\ncontext of their choices.\n Sugden (1993)\n seems to have been the first to suggest that even non-altruistic\nplayers in the one-shot PD might jointly see that they could reason\nas a team, that is, arrive at their choices of strategies by\nasking \u2018What is best for us?\u2019 instead of\n\u2019What is best for me?\u2019.\n\nBinmore (1994)\n forcefully argues that this line of criticism confuses game theory as\nmathematics with questions about which game theoretic models are most\ntypically applicable to situations in which people find themselves. If\nplayers value the utility of a team they\u2019re part of over and\nabove their more narrowly individualistic interests, then this should\nbe represented in the payoffs associated with a game theoretic model\nof their choices. In the situation modeled as a PD above, if the two\nplayers\u2019 concern for \u2018the team\u2019 were strong enough\nto induce a switch in strategies from D to C, then the payoffs in the\n(cardinally interpreted) upper left cell would have to be raised to at\nleast 3. (At 3, players would be indifferent between\ncooperating and defecting.) Then we get the following transformation\nof the game: \n\n\n\n\nII\n\n\\(C\\)\n\\(D\\)\n\nI\n\\(C\\)\n4,4\n0,3\n\n\\(D\\)\n3,0\n1,1 \n\n\n\nThis is no longer a PD; it is an Assurance game, which has\ntwo NE at (C,C) and (D,D), with the former being Pareto superior to\nthe latter. Thus if the players find this equilibrium, we should not\nsay that they have played non-NE strategies in a PD. Rather, we should\nsay that the PD was the wrong model of their situation.\n\nThe critic of individualism can acknowledge Binmore\u2019s logical\npoint but accommodate it by arguing that changing the game is exactly\nwhat people should try to do if they find themselves in situations\nthat, when the relevant interpretation of economic agency is\nindividualistic, have the structure of PDs. This is precisely\nBacharach\u2019s theoretical proposal. His scientific executors,\nSugden and Gold, in\n Bacharach (2006),\n pp. 171\u2013173), unlike\n Hollis and Sugden (1993),\n use the standard convention for payoff interpretation, under which\nplayers can only be modeled as cooperating in a one-shot PD if at\nleast one player makes an error. Under this assumption, Bacharach,\nSugden and Gold argue, human game players will often or usually avoid\nframing situations in such a way that a one-shot PD is the right model\nof their circumstances. A situation that \u2018individualistic\u2019\nagents would frame as a PD might be framed by \u2018team\nreasoning\u2019 agents as the Assurance game transformation above.\nNote that the welfare of the team might make a difference to\n(cardinal) payoffs without making enough of a difference to\ntrump the lure of unilateral defection. Suppose it bumped them up to\n2.5 for each player; then the game would remain a PD. This point is\nimportant, since in experiments in which subjects play sequences of\none-shot PDs (not repeated PDs, since opponents in the\nexperiments change from round to round), majorities of subjects begin\nby cooperating but learn to defect as the experiments progress. On\nBacharach\u2019s account of this phenomenon, these subjects initially\nframe the game as team reasoners. However, a minority of subjects\nframe it as individualistic reasoners and defect, taking free\nriders\u2019 profits. The team reasoners then re-frame the situation\nto defend themselves. This introduces a crucial aspect of\nBacharach\u2019s account. Individualistic reasoners and team\nreasoners are not claimed to be different types of people. People,\nBacharach maintains, tend to flip back and forth between\nindividualistic agency and participation in team agency.\n\nNow consider the following Pure Coordination game:\n\n\n\n\nII\n\n\\(C\\)\n\\(D\\)\n\nI\n\\(C\\)\n1,1\n0,0\n\n\\(D\\)\n0,0\n1,1 \n\n\n\nWe can interpret this as representing a situation in which players are\nnarrowly individualistic, and thus each indifferent between the two NE\nof (U, L) and (D, R), or are team reasoners but haven\u2019t\nrecognized that their team is better off if they stabilize around one\nof the NE rather than the other. If they do come to such recognition,\nperhaps by finding a focal point, then the Pure Coordination game is\ntransformed into the following game known as Hi-Lo:\n\n\n\n\nII\n\n\\(t_1\\)\n\\(t_2\\)\n\nI\n\\(s_1\\)\n10,10\n0,0\n\n\\(s_2\\)\n0,0\n1,1 \n\n\n\nCrucially, here the transformation requires more than mere\nteam reasoning. The players also need focal points to know which of\nthe two Pure Coordination equilibria offers the less risky prospect\nfor social stabilization\n (Binmore 2008).\n In fact, Bacharach and his executors are interested in the\nrelationship between Pure Coordination games and Hi-Lo games for a\nspecial reason. It does not seem to imply any criticism of NE as a\nsolution concept that it doesn\u2019t favor one strategy vector over\nanother in a Pure Coordination game. However, NE also\ndoesn\u2019t favor the choice of (U, L) over (D, R) in the Hi-Lo game\ndepicted, because (D, R) is also a NE. At this point Bacharach and his\nfriends adopt the philosophical reasoning of the refinement program.\nSurely, they complain, \u2018rationality\u2019 recommends (U, L).\nTherefore, they conclude, axioms for team reasoning should be built\ninto refined foundations of game theory.\n\nWe need not endorse the idea that game theoretic solution concepts\nshould be refined to accommodate an intuitive general concept of\nrationality to motivate interest in Bacharach\u2019s contribution.\nThe non-psychological game theorist can propose a subtle shift of\nemphasis: instead of worrying about whether our models should respect\na team-centred norm of rationality, we might simply point to empirical\nevidence that people, and perhaps other agents, seem to often make\nchoices that reveal preferences that are conditional on the welfare of\ngroups with which they are associated. To this extent their agency is\npartly or wholly\u2014and perhaps stochastically\u2014identified\nwith these groups, and this will need to be reflected when we model\ntheir agency using utility functions. Then we could better describe\nthe theory we want as a theory of team-centred choice rather than as a\ntheory of team reasoning. Note that this philosophical\ninterpretation is consistent with the idea that some of our evidence,\nperhaps even our best evidence, for the existence of team-centred\nchoice is psychological. It is also consistent with the suggestion\nthat the processes that flip people between individualized and\nteam-centred agency are often not deliberative or consciously\nrepresented. The point is simply that we need not follow Bacharach in\nthinking of game theory as a model of reasoning or rationality in\norder to be persuaded that he has identified a gap we would like to\nhave formal resources to fill.\n\nSo, do people\u2019s choices seem to reveal team-centred\npreferences? Standard examples, including Bacharach\u2019s own, are\ndrawn from team sports. Members of such teams are under considerable\nsocial pressure to choose actions that maximize prospects for victory\nover actions that augment their personal statistics. The problem with\nthese examples is that they embed difficult identification problems\nwith respect to the estimation of utility functions; a narrowly\nself-interested player who wants to be popular with fans might behave\nidentically to a team-centred player. Soldiers in battle conditions\nprovide more persuasive examples. Though trying to convince soldiers\nto sacrifice their lives in the interests of their countries is often\nineffective, most soldiers can be induced to take extraordinary risks\nin defense of their buddies, or when enemies directly menace their\nhome towns and families. It is easy to think of other kinds of teams\nwith which most people plausibly identify some or most of the time:\nproject groups, small companies, political constituency committees,\nlocal labor unions, clans and households. Strongly individualistic\nsocial theory tries to construct such teams as equilibria in games\namongst individual people, but no assumption built into game theory\n(or, for that matter, mainstream economic theory) forces this\nperspective (see\n Guala (2016)\n for a critical review of options). We can instead suppose that teams\nare often exogenously welded into being by complex interrelated\npsychological and institutional processes. This invites the game\ntheorist to conceive of a mathematical mission that consists not in\nmodeling team reasoning, but rather in modeling choice that is\nconditional on the existence of team dynamics.\n\nStirling (2012)\n formalizes such conditional interactions for use in a special\napplication context: an AI system with a distributed-control\narchitecture. Such systems achieve processing efficiencies by\ndevolving aspects of problems to specialized sub-systems. The\nefficiencies in question are not achievable unless the sub-systems\noperate their own utility functions; otherwise the system is really\njust a standard computer with an executive control bottleneck that\ncalls sub-routines. But if the sub-systems are, then, distinct\neconomic agents, risk of incoherence arises at the level of the whole\nsystem. It might, that is, behave like a typical democratic political\ncommunity, pursuing contradictory policies or falling into gridlock\nand paralysis. An engineer of such a system would include avoidance of\nsuch problems in her design specs. Is there a way in which the design\ncould implement the advantages of genuine distributed control among\nsub-agents while also ensuring consistency at the whole-system level?\nThis is the problem Stirling set out to solve. The resemblance to\nBacharach\u2019s conception emerges if we frame Stirling\u2019s\nchallenge as follows: we want the sub-agents to interact\nwith\u2014that is, play games amongst\u2014one another as\nindividuals, but then we want to allow only solutions that would be\nproducts of team reasoning. \n\nOne of Stirling\u2019s two basic innovations is to have players\ncondition their choices on one another\u2019s action profiles rather\nthan on outcomes. The motivation for this is that while the sub-agents\nare choosing as individuals, they cannot simultaneously know what\nutilities will be assigned to outcomes at the team level. (If they\ndid, we would again assume away what makes the problem interesting,\nand the sub-agents would just be sub-routines.) Here Stirling\nconsiders an analogy from human social psychology, which will turn out\nto be the germ of a conceptual innovation when we shift the\napplication context away from AI design and back to social\nscience.\n\nStirling\u2019s analogy to a human phenomenon draws on the point that\npeople often encounter contexts of interaction with others in which\ntheir preferences are not fully formed in advance. Psychologists study\nthis under the label of \u2018preference construction\u2019\n (Lichtenstein and Slovic 2006),\n reflecting the intuition that people build their preferences\nthrough interaction. Stirling provides a simple (arguably too\nsimple) example from\n Keeney and Raiffa (1976),\n in which a farmer forms a clear preference among different climate\nconditions for a land purchase only after, and partly in light of,\nlearning the preferences of his wife. This little thought experiment\nis plausible, but not ideal as an illustration because it is easily\nconflated with vague notions we might entertain about fusion\nof agency in the ideal of marriage\u2014and it is important to\ndistinguish the dynamics of preference conditionalization in teams of\ndistinct agents from the simple collapse of individual\nagency. So let us construct a better example, drawn from\n Hofmeyr and Ross (2019).\n Imagine a corporate Chairperson consulting her risk-averse Board\nabout whether they should pursue a dangerous hostile takeover bid.\nCompare two possible procedures she might use: in process (i) she\nsends each Board member an individual e-mail about the idea a week\nprior to the meeting; in process (ii) she springs it on them\ncollectively at the meeting. Most people will agree that the\ntwo processes might yield different outcomes, and that a main reason\nfor this is that on process (i), but not (ii), some members might\nentrench personal opinions that they would not have time to settle\ninto if they received information about one another\u2019s\nwillingness to challenge the Chair in public at the same time as they\nheard the proposal for the first time. In both imagined processes\nthere are, at the point of voting, sets of individual preferences to\nbe aggregated by the vote. But it is more likely that some preferences\nin the set generated by the second process were conditional\non preferences of others. A conditional preference as Stirling defines\nit is a preference (over actions) that is influenced by information\nabout the preferences (over actions) of (specified) others.\n\nA second notion formalized in Stirling\u2019s theory is\nconcordance. This refers to the extent of controversy or\ndiscord to which a set of preferences, including a set of conditional\npreferences, would generate if equilibrium among them were\nimplemented. Members or leaders of teams do not always want to\nmaximize concordance by engineering all internal games as Assurance or\nHi-lo (though they will always likely want to eliminate PDs). For\nexample, a manager might want to encourage a degree of competition\namong profit centers in a firm, while wanting the cost centers to\nidentify completely with the team as a whole.\n\nStirling formally defines representation theorems for three kinds of\nordered utility functions: conditional utility, concordant utility and\nconditional concordant utility. These may be applied recursively, i.e.\nto individuals, to teams and to teams of teams. Then the core of the\nformal development is the theory that aggregates individuals\u2019\nconditional concordant preferences to build models of team choice that\nare not exogenously imposed on team members, but instead derive from\ntheir several preferences. In stating Stirling\u2019s aggregation\nprocedure in the present context, it is useful to change his\nterminology, and therefore paraphrase him rather than quote directly.\nThis is because Stirling refers to \u201cgroups\u201d rather than to\n\u201cteams\u201d. Stirling\u2019s initial work on CGT was entirely\nindependent of Bacharach\u2019s work,so was not configured within the\ncontext of team reasoning (or what we might reinterpret as\nteam-centred choice). But Bacharach\u2019s ideas provide a natural\nsetting in which to frame Stirling\u2019s technical achievement as an\nenrichment of the applicability of game theory in social science (see\n Hofmeyr and Ross (2019)).\n We can then paraphrase his five constraints on aggregation as\nfollows:\n\n\n(1) Conditioning: A team member\u2019s preference ordering\nmay be influenced by the preferences of other team members, i.e. may\nbe conditional. (Influence may be set to zero, in which case the\nconditional preference ordering collapses to the categorical\npreference ordering to standard RPT.)\n\n(2) Endogeny: A concordant ordering for a team must be\ndetermined by the social interactions of its sub-teams. (This\ncondition ensures that team preferences are not simply imposed on\nindividual preferences.)\n\n(3) Acyclicity: Social influence relations are not\nreciprocal. (This will likely look at first glance to be a strange\nrestriction: surely most social influence relationships, among people\nat any rate, are reciprocal. But, as noted earlier, we need\nto keep conditional preference distinct from agent fusion, and this\ncondition helps to do that. More importantly, as a matter of\nmathematics it allows teams to be represented in directed graphs. The\ncondition is not as restrictive, where modeling flexibility is\nconcerned, as one might at first think, for two reasons. First, it\nonly bars us from representing an agent \\(j\\) influenced by another\nagent \\(i\\) from directly influencing \\(i\\). We are free to\nrepresent \\(j\\) as influencing \\(k\\) who in turn influences \\(i\\).)\nSecond, and more importantly, in light of the exchangeability\nconstraint below, aggregation is insensitive to the ordering of pairs\nof players between whom there is a social influence relationship.)\n\n(4) Exchangeability: Concordant preference orderings are\ninvariant under representational transformations that are equivalent\nwith respect to information about conditional preferences.\n\n(5) Monotonicity: If one sub-team prefers choice alternative\n\\(A\\) to \\(B\\) and all other sub-teams are indifferent between \\(A\\)\nand \\(B\\), then the team does not prefer \\(B\\) to \\(A\\).\n\n\nUnder these restrictions, Stirling proves an aggregation theorem which\nfollows a general result for updating utility in light of new\ninformation that was developed by\n Abbas (2003, Other Internet Resources).\n Individual team members each calculate the team preference by\naggregating conditional concordant preferences. Then the analyst\napplies marginalization. Let \\(X^n\\) be a team. Let\n\\(X^m=\\{X_{j1},\\ldots,X_{jm}\\}\\) and \\(X = \\{X_{i1},\\ldots, X_{ik}\\}\\)\nbe disjoint sub-teams of \\(X^n\\). Then the marginal concordant utility\nof \\(X^m\\) with respect to the sub-team \\(\\{X^m, X^k\\}\\) is obtained\nby summing over \\(\\mathcal{A}^k\\), yielding  \n\\[\nU_{x_m}(\\alpha_m) = \\sum_{\\alpha_k} Ux_m x_k (\\alpha_m, \\alpha_k)\n\\]\n\n\nand the marginal utility of the individual team member \\(X_i\\) is\ngiven by  \n\\[\nU_{x_m}(\\alpha_m) = \\sum_{\\sim \\mathbb{a}_i} Ux_n (\\mathbb{a}_1, \\ldots, \\mathbb{a}_n)\n\\]\n\n\nwhere the notation \\(\\sum_{\\sim \\mathbb{a}_i}\\) means that the sum is\ntaken over all arguments except \\(\\mathbb{a}_i\\)\n (Stirling (2012),\n p. 62). This operation produces the non-conditional\npreferences of individual \\(i\\) ex post\u2014that is, updated in\nlight of her conditional concordant preferences and the information on\nwhich they are conditioned, namely, the conditional concordant\npreferences of the team. Once all ex post preferences of agents have\nbeen calculated, the resulting games in which they are involved can be\nsolved by standard analysis.\n\nStirling\u2019s construction is, as he says, a true generalization of\nstandard utility theory so as to make non-conditioned\n(\u201ccategorical\u201d) utility a special case. It provides a\nbasis for formalization of team utility, which can be compared with\nany of the following: the pre-conditioned categorical utility of an\nindividual or sub-team; the conditional utility of an individual or\nsub-team; or the conditional concordant utility of an individual or\nsub-team. Once every individual\u2019s preferences in a team choice\nproblem have been marginalized, NE, SPE or QRE analyses can be\nproposed as solutions to the problem given full information about\nsocial influences. Situations of incomplete information can be solved\nusing Byes-Nash or sequential equilibrium.\n\nIn case the reader has struggled to follow the overall point of the\ntechnical constructions above, we can summarize the achievement of\nconditional game theory (CGT) in higher-level terms as follows. CGT\nmodels the propagation of influence flows by applying the formal\nsyntax of probability theory (through the operation of\nmarginalization) to game theory, and constructing graph theoretical\nrepresentations. As social influence propagates through a group and\nplayers modulate their preferences on the basis of other\nplayers\u2019 preferences, a group preference may emerge. Group\npreferences are not a direct basis for action, but encapsulate a\nsocial model incorporating the relationships and interdependencies\namong the agents. CGT shows us how to derive a coordination ordering\nfor a group which combines the conditional and categorical preferences\nof its members, in much the same way as, in probability theory, the\njoint probability of an event is determined by conditional and\nmarginal probabilities. So, just as the conventional application of\nthe probability syntax is a means of expressing a cognizer\u2019s\nepistemological uncertainty regarding belief, so extending this syntax\nto game theory allows us to represent an agent\u2019s practical\nuncertainty regarding preference.\n\nThe key achievement of this initial interpretation of CGT lies in\nrepresenting the influence of concordance considerations on\nequilibrium determination. The social model can be used to generate an\noperational definition of group preference, and to define truly\ncoordinated choices. There is no assumption that groups necessarily\noptimize their preferences or that individual agents always coordinate\ntheir choices. The point is merely that we can formally represent\nconditions under which agents in games can do what actual people often\nseem to: adapt and settle their individual preferences in\nlight both of what others prefer, and of what promotes a group\u2019s\nstability and efficiency. Team agency is thus incorporated into game\ntheory instead of being left as an exogenous psychological construct\nthat the analyst must investigate in advance of building a\ngame-theoretic model of socially embedded agents.\n\nBecause agents in a CGT analysis condition their preferences on\nactions rather than on outcomes, conditional games cannot be\nrepresented in extensive form. (An extensive-form model must derive\nutility indices at all non-terminal nodes from those assigned to the\nterminal nodes, i.e., to outcomes.) A game theorist should therefore\nconceive of team utility as resulting from a pre-play\nprocess, a concept extensively used in the literature on learning in\ngames, as discussed in\n Section 3.1.\n In that literature, pre-play is used for generating commonly observed\nsignals that are the basis for identification of correlated equilibria\nin \u2018real\u2019 play. This raises an interesting possibility:\nmight we be able to use CGT for that same purpose?\n\nThere is a philosophical reason why we might want to. In a standard\nmodel of learning in a game, players are naturally interpreted as\ninferring private preferences and beliefs of others from observations\nof actions. This comports intuitively with the idea, which has been\nvery popular in cognitive science, that humans achieve their special\n(by comparison with other animals) feats of complex coordination in\npart because we have capacities to \u2018read\u2019 one\nanother\u2019s minds\n (Nichols and Stich 2003).\n However, this hypothesis has recently come under strong critical\nchallenge, from two closely related directions.\n\nFirst, it incorporates the highly questionable idea that beliefs and\npreferences are \u2018inner\u2019 (brain?) states that can be known\nfrom the inside but only inferred from the outside. Cognitive\nscientists are increasingly coming around to the view, first developed\nin detail by\n Dennett (1987),\n and since extended by (among many others)\n Clark (1997)\n and\n Hutto (2008),\n that beliefs and preferences are socially constructed interpretations\nof people\u2019s behavior conditioned on their circumstances and\nhistories, which children are taught to apply automatically, first to\nothers and then to themselves\n (McGeer 2001,\n 2002). Game-theoretic reasoning explains why this\nconstruction is universal practice among humans: it is the essential\nbasis of coordination on what really matters for practical purposes,\nwhich are not people\u2019s specific thoughts but\nprojects into which they can mutually recruit one another\n (Ross 2005a).\n Second,\n Zawidzki (2013)\n argues persuasively that the kinds of rapid inferences presupposed by\nmindreading theory are not computationally feasible except among\npeople who know one another very closely, or are interacting within\ntightly constrained institutional rules, such as playing a team sport\nor transacting in an established market (so, just the kinds of\nsettings where team reasoning is most plausible). So how do people\ncoordinate, at least much of the time, so smoothly? This apparently\nintractable problem dissolves once we take on board the point of the\npreceding paragraph, that people do not need to infer\n\u2018hidden\u2019 beliefs and preferences because there are no such\nthings in the first place. Instead, they co-construct beliefs\nand preferences on the fly through ongoing micro-negotiations. A\nparadigm case is two people avoiding a collision on a crowded\nsidewalk. I don\u2019t need to try to infer which way you intend to\nveer while you simultaneously attempt a similar inference about my\nintention; instead, we exchange quick signals that allow us to jointly\ncreate complementary plans. (In some cultures we may be aided by\nnormative conventions, such as that if one person is a man and the\nother is a woman, the man is to step in the direction of the street.\nThis norm, where it works, may have sexist origins, but it might not\nbe abandoned among people who come to recognize that, because it is\nuseful to have some convention, and this one, where it\napplies, can be used on the basis of quick glances. One can imagine\ngender-fluid people extending it to be cued by how they happen to be\ndressed, perhaps with some smiling and laughing to signal richer\nshared awareness.) Zawidzki refers to such processes as\nmindshaping, and shows that they are the basis of most\nquotidian coordination success. Mindreading, where it can occur, is\nparasitic on mindshaping.\n\nMindshaping clearly has a strategic dimension, as revealed by the fact\nthat it frequently involves micro-scale power dimensions\u2014if it\nis your boss you are at risk of bumping into, or a police officer, you\nmight step backwards instead of to one side. Therefore, game theory\nshould apply to it. But this is problematic in light of the fact that\napplications of standard game theory require that utilities be\npre-specified. The reader should immediately see that CGT seems built\nto order for this challenge.\n\nCGT as it is presented in\n Stirling (2012)\n needs some modification to serve as a game-theoretic model of\nmindshaping. In Stirling\u2019s original intended setting for AI,\ncontrol is hierarchical, and influence on preferences therefore can\nflow from an origin through a network to terminating values.\nMindshaping processes, however, are typically multi-directional.\n Ross and Stirling (2021)\n therefore propose the application of so-called \u2018Markov-chain\nmodeling\u2019, which exploits the mathematical isomorphism between\nCGT and the theory of Bayesian networks, to incorporate influence\nflows without fixed direction. Because this relaxes a property that an\nAI engineer would likely prefer to keep fixed, what is proposed is\neffectively a new theory. Ross and Stirling therefore refer to it as\n\u2018CGT 2.0\u2019. A first application of it, to analysis of\nexperimental games for identifying norms used by laboratory subjects,\nand for estimating the influence of norms on subjects\u2019 behavior,\ncan be found in\n Ross, Stirling, and Tummolini (2023).\n\nCGT 2.0, unlike CGT 1.0, is not best conceptualised as a way of\nformalizing team utility. Its reach is broader. In effect it is a\ngeneral model of any pre-play that facilitates identification of\nutility functions by players with incomplete information. Therefore,\nas shown by\n Ross and Stirling (2023),\n it can be used to identify correlated equilibrium (see\n Section 3.1).\n In fact, it yields something stronger. The \u2018Harsanyi\nDoctrine\u2019is the name of the idea, from\n Harsanyi (1977),\n that any differences in subjective probability assignments by\nBayesian players should result exclusively from different information.\nThis depends only on observations of actions, not on observations of\noutcomes. Since CGT conditions on actions, the transition matrices\nthat represent results of CGT pre-play also identify shared signals\nthat constitute common priors for \u2018real\u2019 play. Therefore,\ninsofar as CGT 2.0 successfully models mindshaping, we can say that\nthe mindshaping hypothesis motivates confidence in the empirical\nrelevance of the Harsanyi Doctrine to at least some behavioral games.\nThis gives formal expression to Zawidzki\u2019s contention that\nmindshaping can strongly support coordination, including in strategic\nsettings. Finally, a limitation of correlated equilibrium for\nempirical purposes is that it relies on the assumption that all\nplayers conform with, and know that all conform with, the axioms of\nExpected Utility Theory.\n Aumann (1987)\n notes that this assumption breaks down if agents operate with\nsubjective probability weightings on beliefs. But this is in fact how\nmajorities of human laboratory subjects do behave\n (Harrison and Ross (2016)).\n CGT 2.0 allows this restriction to be defused by pre-play. It\nincorporates the theory of subjective probability weighting as\ndeveloped by\n Quiggin (1982)\n and\n Prelec (1998)\n in its general model of utility. Such beliefs are therefore reflected\nin the transition matrices that represent the knowledge that licenses\napplication of the Harsanyi Doctrine to \u2018real\u2019 play. The\nderivation of correlated equilibrium can therefore proceed as if\nplayers were expected utility maximizers.\n6. Commitment\n\nIn some games, a player can improve her outcome by taking an action\nthat makes it impossible for her to take what would be her best action\nin the corresponding simultaneous-move game. Such actions are referred\nto as commitments, and they can serve as alternatives to\nexternal enforcement in games which would otherwise settle on\nPareto-inefficient equilibria.\n\nConsider the following hypothetical example (which is not a\nPD). Suppose you own a piece of land adjacent to mine, and I\u2019d\nlike to buy it so as to expand my lot. Unfortunately, you don\u2019t\nwant to sell at the price I\u2019m willing to pay. If we move\nsimultaneously\u2014you post a selling price and I independently give\nmy agent an asking price\u2014there will be no sale. So I might try\nto change your incentives by playing an opening move in which I\nannounce that I\u2019ll build a putrid-smelling sewage disposal plant\non my land beside yours unless you sell, thereby inducing you to lower\nyour price. I\u2019ve now turned this into a sequential-move game.\nHowever, this move so far changes nothing. If you refuse to sell in\nthe face of my threat, it is then not in my interest to carry it out,\nbecause in damaging you I also damage myself. Since you know this you\nshould ignore my threat. My threat is incredible, a case of\ncheap talk.\n\nHowever, I could make my threat credible by committing\nmyself. For example, I could sign a contract with some farmers\npromising to supply them with treated sewage (fertilizer) from my\nplant, but including an escape clause in the contract releasing me\nfrom my obligation only if I can double my lot size and so put it to\nsome other use. Now my threat is credible: if you don\u2019t sell,\nI\u2019m committed to building the sewage plant. Since you know this,\nyou now have an incentive to sell me your land in order to escape its\nruination.\n\nThis sort of case exposes one of many fundamental differences between\nthe logic of non-parametric and parametric maximization. In parametric\nsituations, an agent can never be made worse off by having more\noptions. (Even if a new option is worse than the options with which\nshe began, she can just ignore it.) But where circumstances are\nnon-parametric, one agent\u2019s strategy can be influenced in\nanother\u2019s favour if options are visibly restricted.\nCortez\u2019s burning of his boats (see\n Section 1)\n is, of course, an instance of this, one which serves to make the\nusual metaphor literal.\n\nAnother example will illustrate this, as well as the applicability of\nprinciples across game-types. Here we will build an imaginary\nsituation that is not a PD\u2014since only one player has an\nincentive to defect\u2014but which is a social dilemma insofar as its\nNE in the absence of commitment is Pareto-inferior to an outcome that\nis achievable with a commitment device. Suppose that two of\nus wish to poach a rare antelope from a national park in order to sell\nthe trophy. One of us must flush the animal down towards the second\nperson, who waits in a blind to shoot it and load it onto a truck. You\npromise, of course, to share the proceeds with me. However, your\npromise is not credible. Once you\u2019ve got the buck, you have no\nreason not to drive it away and pocket the full value from it. After\nall, I can\u2019t very well complain to the police without getting\nmyself arrested too. But now suppose I add the following opening move\nto the game. Before our hunt, I rig out the truck with an alarm that\ncan be turned off only by punching in a code. Only I know the code. If\nyou try to drive off without me, the alarm will sound and we\u2019ll\nboth get caught. You, knowing this, now have an incentive to wait for\nme. What is crucial to notice here is that you prefer that I\nrig up the alarm, since this makes your promise to give me my share\ncredible. If I don\u2019t do this, leaving your promise\nincredible, we\u2019ll be unable to agree to try the crime\nin the first place, and both of us will lose our shot at the profit\nfrom selling the trophy. Thus, you benefit from my preventing you from\ndoing what\u2019s optimal for you in a subgame.\n\nWe may now combine our analysis of PDs and commitment devices in\ndiscussion of the application that first made game theory famous\noutside of the academic community. The nuclear stand-off between the\nsuperpowers during the Cold War was intensively studied by the first\ngeneration of game theorists, many of whom received direct or indirect\nfunding support from the US military.\n Poundstone 1992\n provides the relatively \u2018sanitized\u2019 history of this\ninvolvement that has long been available to the casual historian who\nrelies on secondary sources in addition to theorists\u2019 public\nreminiscences. Recently, a more skeptically alert and professional\nhistorical study has been produced by\n Amadae (2016),\n which provides scholarly context for the still more hair-raising\nmemoir of a pioneer of applied game theory, participant in the\ndevelopment of Cold War nuclear strategy, and famous leaker of the\nPentagon\u2019s secret files on the Vietnam War, Daniel Ellsberg\n (Ellsberg 2017).\n History consistent with these accounts but stimulating less pupil\ndilation in the reader is\n Erickson (2015).\n \n\nIn the conventional telling of the tale, the nuclear stand-off between\nthe USA and the USSR attributes the following policy to both parties.\nEach threatened to answer a first strike by the other with a\ndevastating counter-strike. This pair of reciprocal strategies, which\nby the late 1960s would effectively have meant blowing up the world,\nwas known as \u2018Mutually Assured Destruction\u2019, or\n\u2018MAD\u2019. Game theorists at the time objected that MAD was\nmad, because it set up a PD as a result of the fact that the\nreciprocal threats were incredible. The reasoning behind this\ndiagnosis went as follows. Suppose the USSR launches a first strike\nagainst the USA. At that point, the American President finds his\ncountry already destroyed. He doesn\u2019t bring it back to life by\nnow blowing up the world, so he has no incentive to carry out his\noriginal threat to retaliate, which has now manifestly failed to\nachieve its point. Since the Russians can anticipate this, they should\nignore the threat to retaliate and strike first. Of course, the\nAmericans are in an exactly symmetric position, so they too should\nstrike first. Each power recognizes this incentive on the part of the\nother, and so anticipates an attack if they don\u2019t rush to\npreempt it. What we should therefore expect, because it is the only NE\nof the game, is a race between the two powers to be the first to\nattack. The clear implication is the destruction of the world.\n\nThis game-theoretic analysis caused genuine consternation and fear on\nboth sides during the Cold War, and is reputed to have produced some\nstriking attempts at setting up strategic commitment devices. Some\nanecdotes, for example, allege that President Nixon had the CIA try to\nconvince the Russians that he was insane or frequently drunk, so that\nthey\u2019d believe that he\u2019d launch a retaliatory strike even\nwhen it was no longer in his interest to do so. Similarly, the Soviet\nKGB is sometimes claimed, during Brezhnev\u2019s later years, to to\nhave fabricated medical reports exaggerating the extent of his\nsenility with the same end in mind. Even if these stories aren\u2019t\ntrue, their persistent circulation indicates understanding of the\nlogic of strategic commitment. Ultimately, the strategic symmetry that\nconcerned the Pentagon\u2019s analysts was complicated and perhaps\nbroken by changes in American missile deployment tactics. They\nequipped a worldwide fleet of submarines with enough missiles to\nlaunch a devastating counterattack by themselves. This made the\nreliability of the US military communications network less\nstraightforward, and in so doing introduced an element of\nstrategically relevant uncertainty. The President probably could be\nless sure to be able to reach the submarines and cancel their orders\nto attack if prospects of American survival had become hopeless. Of\ncourse, the value of this in breaking symmetry depended on the\nRussians being aware of the potential problem. In Stanley\nKubrick\u2019s classic film Dr. Strangelove, the world is\ndestroyed by accident because the Soviets build a doomsday machine\nthat will automatically trigger a retaliatory strike regardless of\ntheir leadership\u2019s resolve to follow through on the implicit MAD\nthreat but then keep it a secret. As a result, when an\nunequivocally mad American colonel launches missiles at Russia on his\nown accord, and the American President tries to convince his Soviet\ncounterpart that the attack was unintended, the latter sheepishly\ntells him about the secret doomsday machine. Now the two leaders can\ndo nothing but watch in dismay as the world is blown up due to a\ngame-theoretic mistake.\n\nThis example of the Cold War standoff, while famous and of\nconsiderable importance in the history of game theory and its popular\nreception, relied at the time on analyses that weren\u2019t very\nsubtle. The military game theorists were almost certainly mistaken to\nthe extent that they modeled the Cold War as a one-shot PD in the\nfirst place. For one thing, the nuclear balancing game was enmeshed in\nlarger global power games of great complexity. For another, it is far\nfrom clear that, for either superpower, annihilating the other while\navoiding self-annihilation was in fact the highest-ranked outcome. If\nit wasn\u2019t, in either or both cases, then the game wasn\u2019t a\nPD. A cynic might suggest that the operations researchers on both\nsides were playing a cunning strategy in a game over funding, one that\ninvolved them cooperating with one another in order to convince their\npoliticians to allocate more resources to weapons. \n\nIn more mundane circumstances, most people exploit a ubiquitous\ncommitment device that Adam Smith long ago made the centerpiece of his\ntheory of social order: the value to people of their own\nreputations. Even if I am secretly stingy, I may wish to\ncause others to think me generous by tipping in restaurants, including\nrestaurants in which I never intend to eat again. The more I do this\nsort of thing, the more I invest in a valuable reputation which I\ncould badly damage through a single act of obvious, and observed,\nmean-ness. Thus my hard-earned reputation for generosity functions as\na commitment mechanism in specific games, itself enforcing continued\nre-investment. In time, my benevolence may become habitual, and\nconsequently insensitive to circumstantial variations, to the point\nwhere an analyst has no remaining empirical justification for\ncontinuing to model me as having a preference for stinginess. There is\na good deal of evidence that the hyper-sociality of humans is\nsupported by evolved biological dispositions (found in most but not\nall people) to suffer emotionally from negative gossip and the fear of\nit. People are also naturally disposed to enjoy gossiping,\nwhich means that punishing others by spreading the news when their\ncommitment devices fail is a form of social policing they don\u2019t\nfind costly and happily take up. A nice feature of this form of\npunishment is that it can, unlike (say) hitting people with sticks, be\nwithdrawn without leaving long-term damage to the punished. This is a\nhappy property of a device that has as its point the maintenance of\nincentives to contribute to joint social projects; collaboration is\ngenerally more fruitful with team-mates whose bones aren\u2019t\nbroken. Thus forgiveness conventions also play a strategic role in\nthis elegant commitment mechanism that natural selection built for us.\nA \u2018forgiveness convention\u2019 is itself an instance of a\nnorm, as discussed in\n Section 4,\n and a community\u2019s norms provide crucial social scaffolding for\nreputation management. As an approximate generalization, people as\nthey move into adulthood choose between investments in one of three\nbroad kinds of reputational profiles: (i) upholder of most majority\nnorms (which may involve preference falsification), (ii)\ndiscriminating upholder of mixes of majority and novel, minority norms\n(a \u2018trendsetter\u2019, to use the terminology of\n Bicchieri (2017)),\n or (iii) individualistic rebel. People tend to find all three of\nthese normative personality types decipherable, which is the crucial\nrequirement for a useful reputation. The idea of a useful\nreputation should be distinguished from the idea of a generally\napproved reputation. Trendsetters and rebels are typically widely\ndisapproved of, but this can itself help them to avoid games in which\nthey would have to choose between undermining their reputations and\nearning low material payoffs; social disapprobation typically helps\ntrendsetters and rebels coordinate with one another.\nReligious stories, or philosophical ones involving Kantian moral\n\u2018rationality\u2019, are especially likely to be told in\nexplanation of norms because the underlying game-theoretic basis\ndoesn\u2019t occur to people; and the norms in question may function\nto support reputations more effectively for that very reason, because\nthe religious or philosophical stories hide the extent to which\nreputations are under individuals\u2019 strategic control.\n(Existentialist philosophers call this mechanism \u2018bad\nfaith\u2019). The stories trigger sincere emotions, particularly\nanger, which are direct commitment mechanisms that mutually reinforce\nthe investment value of reputations.\n\nThough the so-called \u2018moral emotions\u2019are extremely useful\nfor maintaining commitment, they are not necessary for it. Larger\nhuman institutions are, famously, highly morally obtuse; however,\ncommitment is typically crucial to their functional logic. For\nexample, a government tempted to negotiate with terrorists to secure\nthe release of hostages on a particular occasion may commit to a\n\u2018line in the sand\u2019 strategy for the sake of maintaining a\nreputation for toughness intended to reduce terrorists\u2019\nincentives to launch future attacks. A different sort of example is\nprovided by Qantas Airlines of Australia. Qantas has never suffered a\nfatal accident, and for a time (until it suffered some embarrassing\nnon-fatal accidents to which it likely feared drawing attention) made\nmuch of this in its advertising. This means that its planes, at least\nduring that period, probably were safer than average even if\nthe initial advantage was merely a bit of statistical good fortune,\nbecause the value of its ability to claim a perfect record rose the\nlonger it lasted, and so gave the airline continuous incentives to\nincur greater costs in safety assurance. It likely still has incentive\nto take extra care to prevent its record of fatalities from crossing\nthe magic reputational line between 0 and 1.\n\nCertain conditions must hold if reputation effects are to underwrite\ncommitment. A person\u2019s reputation can have a standing value\nacross a range of games she plays, but in that case her concern for\nits value should be factored into payoffs in specifying each specific\ngame into which she enters. Reputation can be built up\nthrough play of a game only in a case of a repeated game.\nThen the value of the reputation must be greater to its cultivator\nthan the value to her of sacrificing it in any particular\nround of the repeated game. Thus players may establish commitment by\nreducing the value of each round so that the temptation to defect in\nany round never gets high enough to constitute a hard-to-resist\ntemptation. For example, parties to a contract may exchange their\nobligations in small increments to reduce incentives on both sides to\nrenege. Thus builders in construction projects may be paid in weekly\nor monthly installments. Similarly, the International Monetary Fund\noften dispenses loans to governments in small tranches, thereby\nreducing governments\u2019 incentives to violate loan conditions once\nthe money is in hand; and governments may actually prefer such\narrangements in order to remove domestic political pressure for\nnon-compliant use of the money. Of course, we are all familiar with\ncases in which the payoff from a defection in a current round becomes\ntoo great relative to the longer-run value of reputation to future\ncooperation, and we awake to find that the society treasurer has\nabsconded overnight with the funds. Commitment through concern for\nreputation is the cement of society, but any such natural bonding\nagent will be far from perfectly effective.\n7. Evolutionary Game Theory\n\nGintis (2009b,\n 2009b) feels justified in stating that \u201cgame theory is a\nuniversal language for the unification of the behavioral\nsciences.\u201d There are good examples of such unifying work.\nBinmore\n (1998,\n 2005a) models history of increasing social complexity as a\nseries of convergences on increasingly efficient equilibria in\ncommonly encountered transaction games, interrupted by episodes in\nwhich some people try to shift to new equilibria by moving off stable\nequilibrium paths, resulting in periodic catastrophes. (Stalin, for\nexample, tried to shift his society to a set of equilibria in which\npeople cared more about the future industrial, military and political\npower of their state than they cared about their own lives. He was not\nsuccessful in the long run; however, his efforts certainly created a\nsituation in which, for a few decades, many Soviet people attached far\nless importance to other people\u2019s lives than usual.) A\ngame-theoretic perspective indeed seems pervasively useful in\nunderstanding phenomena across the full range of social sciences. In\n Section 4,\n for example, we considered Lewis\u2019s recognition that each human\nlanguage amounts to a network of Nash equilibria in coordination games\naround conveyance of information.\n\nGiven his work\u2019s vintage, Lewis restricted his attention to\nstatic game theory, in which agents are modeled as deliberately\nchoosing strategies given exogenously fixed\nutility-functions. As a result of this restriction, his account\ninvited some philosophers to pursue a misguided quest for a general\nanalytic theory of the rationality of conventions (as noted by\n Bickhard 2008).\n Though Binmore has criticized this focus repeatedly through a\ncareer\u2019s worth of contributions (see the references for a\nselection),\n Gintis (2009a)\n has recently isolated the underlying problem with particular clarity\nand tenacity. NE and SPE are brittle solution concepts when\napplied to naturally evolved computational mechanisms like animal\n(including human) brains. As we saw in\n Section 3\n above, in coordination (and other) games with multiple NE, what it is\neconomically rational for a player to do is highly sensitive to the\nlearning states of other players. In general, when players find\nthemselves in games where they do not have strictly dominant\nstrategies, they only have uncomplicated incentives to play NE or SPE\nstrategies to the extent that other players can be expected to find\ntheir NE or SPE strategies. Can a general theory of\nstrategic rationality, of the sort that philosophers have sought, be\nreasonably expected to cover the resulting contingencies? Resort to\nBayesian reasoning principles, as we reviewed in\n Section 3.1,\n is the standard way of trying to incorporate such uncertainty into\ntheories of rational, strategic decision. However, as\n Binmore (2009)\n argues following the lead of\n Savage (1954),\n Bayesian principles are only plausible as principles of\nrationality itself in so-called \u2018small worlds\u2019, that\nis, environments in which distributions of risk are quantified in a\nset of known and enumerable parameters, as in the solution to our\nriver crossing game from\n Section 3.\n In large worlds, where utility functions, strategy sets and\ninformational structure are difficult to estimate and subject to\nchange by contingent exogenous influences, the idea that Bayes\u2019s\nrule tells players how to \u2018be rational\u2019 is quite\nimplausible. But then why should we expect players to choose NE or SPE\nor sequential-equilibrium strategies in wide ranges of social\ninteractions?\n\nAs\n Binmore (2009)\n and\n Gintis (2009a)\n both stress, if game theory is to be used to model actual, natural\nbehavior and its history, outside of the small-world settings on which\nmicroeconomists (but not macroeconomists or political scientists or\nsociologists or philosophers of science) mainly traffic, then we need\nsome account of what is attractive about equilibria in games even when\nno analysis can identify them by taming all uncertainty in such a way\nthat it can be represented as pure risk. To make reference again to\nLewis\u2019s topic, when human language developed there was no\nexternal referee to care about and arrange for Pareto-efficiency by\nproviding focal points for coordination. Yet somehow people agreed,\nwithin linguistic communities, to use roughly the same words and\nconstructions to say similar things. It seems unlikely that any\nexplicit, deliberate strategizing on anyone\u2019s part played a role\nin these processes. Nevertheless, game theory has turned out to\nfurnish the essential concepts for understanding stabilization of\nlanguages. This is a striking point of support for Gintis\u2019s\noptimism about the reach of game theory. To understand it, we must\nextend our attention to evolutionary games.\n\nGame theory has been fruitfully applied in evolutionary biology, where\nspecies and/or genes are treated as players, since pioneering work by\n Maynard Smith (1982)\n and his collaborators. Evolutionary (or dynamic) game theory\nsubsequently developed into a significant mathematical extension, with\nseveral distinct sub-extensions, applicable to many settings apart\nfrom the biological.\n Skyrms (1996)\n uses evolutionary game theory to try to answer questions Lewis could\nnot even ask, about the conditions under which language, concepts of\njustice, the notion of private property, and other non-designed,\ngeneral phenomena of interest to philosophers would be likely to\narise. What is novel about evolutionary game theory is that moves are\nnot chosen through deliberation by the individual agents. Instead,\nagents are typically hard-wired with particular strategies, and\nsuccess for a strategy is defined in terms of the number of copies of\nitself that it will leave to play in the games of succeeding\ngenerations, given a population in which other strategies with which\nit acts are distributed at particular frequencies. In this kind of\nproblem setting, the strategies themselves are the players, and\nindividuals who play these strategies are their relatively blind\nexecutors, who receive the immediate-run costs and benefits associated\nwith outcomes not because they choose the outcomes in question, but\nbecause ancestors from whom they inherited their strategic\ndispositions recurrently benefited from the outcomes of their\nsimilar games.\n\nThe discussion here will closely follow Skyrms\u2019s. This involves\na restriction in generality. Reference was made above to evolutionary\ngame theory as including \u2018distinct sub-extensions\u2019. What\nwas meant by that is that, like classical game theory, it features a\nplurality of \u2018solution\u2019 concepts. Strictly speaking, these\nare different concepts of dynamic stability, which is a\ndifferent idea of equilibrium from the economic equilibrium notion\nrepresented by classical game-theoretic literal solution\nconcepts. An extensive literature (see immediately below) maps the\nstability concepts for evolutionary games onto the classical solution\nconcepts. Reviewing the range of stability concepts would involve\nredundancy in the present context, because that is the main task of a\nsister entry in the Stanford Encyclopedia of Philosophy by J.\nMcKenzie Alexander:\n Game Theory, Evolutionary.\n This complements a fuller exposition with emphasis on philosophical\nissues in\n Alexander (2023),\n which in turn rests on formal foundations reviewed in classic texts\nby\n Weibull (1995)\n and\n Samuelson (1997).\n The Skyrms analysis summarized here relies on just one of the\nstability concepts, the replicator dynamics.\n\nConsider how natural selection works to change lineages of animals,\nmodifying, creating and destroying species. The basic mechanism is\ndifferential reproduction. Any animal with heritable\nfeatures that increase its expected relative frequency of\noffspring in a population of organisms will tend to increase in\nprevalence so long as the environment remains relatively stable. These\noffspring will typically inherit the features in question (with some\nvariation due to mutations, and some variation in frequencies due to\nstatistical noise). Therefore, the proportion of these features in the\npopulation will gradually increase as generations pass. Some of these\nfeatures may go to fixation, that is, eventually take over\nthe entire population (until the environment changes).\n\nHow does game theory enter into this? Often, one of the most important\naspects of an organism\u2019s environment will be the behavioural\ntendencies of other organisms. We can think of each lineage as\n\u2018trying\u2019 to maximize its reproductive fitness (i.e.,\nfuture frequencies of its distinctive genetic structures) through\nfinding strategies that are optimal given the strategies of other\nlineages. So evolutionary theory is another domain of application for\nnon-parametric analysis.\n\nIn evolutionary game theory, we no longer think of individuals as\nchoosing strategies as they move from one game to another. This is\nbecause our interests are different. We\u2019re now concerned less\nwith finding the equilibria of single games than with discovering\nwhich equilibria are stable, and how they will change over time. So we\nnow model the strategies themselves as playing against each\nother. One strategy is \u2018better\u2019 than another if it is\nlikely to leave more copies of itself in the next generation, when the\ngame will be played again. We study the changes in distribution of\nstrategies in the population as the sequence of games unfolds.\n\nFor the replicator dynamics, we introduce a new dynamic stability\n(\u2018equilibrium\u2019) concept, due to\n Maynard Smith (1982).\n A set of strategies, in some particular proportion (e.g., 1/3:2/3,\n1/2:1/2, 1/9:8/9, 1/3:1/3:1/6:1/6\u2014always summing to 1) is at an\nESS (Evolutionary Stable Strategy) equilibrium just in case\n(1) no individual playing one strategy could improve its reproductive\nfitness by switching to one of the other strategies in the proportion,\nand (2) no mutant playing a different strategy altogether could\nestablish itself (\u2018invade\u2019) in the population.\n\nThe principles of evolutionary game theory are best explained through\nexamples. Skyrms begins by investigating the conditions under which a\nsense of justice\u2014understood for purposes of his specific\nanalysis as a disposition to view equal divisions of resources as fair\nunless efficiency considerations suggest otherwise in special\ncases\u2014might arise. He asks us to consider a population in which\nindividuals regularly meet each other and must bargain over resources.\nBegin with three types of individuals:\n\nFairmen always demand exactly half the resource.\nGreedies always demand more than half the resource. When\na greedy encounters another greedy, they waste the resource in\nfighting over it.\nModests always demand less than half the resource. When a\nmodest encounters another modest, they take less than all of the\navailable resource and waste some.\n\n\nEach single encounter where the total demands sum to 100% is\na NE of that individual game. Similarly, there can be many dynamic\nequilibria. Suppose that Greedies demand 2/3 of the resource and\nModests demand 1/3. Then, given random pairing for interaction, the\nfollowing two proportions are ESSs: \n\nHalf the population is greedy and half is modest. We can calculate\nthe average payoff here. Modest gets 1/3 of the resource in every\nencounter. Greedy gets 2/3 when she meets Modest, but nothing when she\nmeets another Greedy. So her average payoff is also 1/3. This is an\nESS because Fairman can\u2019t invade. When Fairman meets Modest he\ngets 1/2. But when Fairman meets Greedy he gets nothing. So his\naverage payoff is only 1/4. No Modest has an incentive to change\nstrategies, and neither does any Greedy. A mutant Fairman arising in\nthe population would do worst of all, and so selection will not\nencourage the propagation of any such mutants.\nAll players are Fairmen. Everyone always gets half the resource,\nand no one can do better by switching to another strategy. Greedies\nentering this population encounter Fairmen and get an average payoff\nof 0. Modests get 1/3 as before, but this is less than Fairman\u2019s\npayoff of 1/2.\n\n\nNotice that equilibrium (i) is inefficient, since the average payoff\nacross the whole population is smaller. However, just as inefficient\noutcomes can be NE of static games, so they can be ESSs of\nevolutionary ones. \n\nWe refer to equilibria in which more than one strategy occurs as\npolymorphisms. In general, in Skyrms\u2019s game, any\npolymorphism in which Greedy demands \\(x\\) and Modest demands \\(1-x\\)\nis an ESS. The question that interests the student of justice concerns\nthe relative likelihood with which these different equilibria\narise.\n\nThis depends on the proportions of strategies in the original\npopulation state. If the population begins with more than one Fairman,\nthen there is some probability that Fairmen will encounter each other,\nand get the highest possible average payoff. Modests by themselves do\nnot inhibit the spread of Fairmen; only Greedies do. But Greedies\nthemselves depend on having Modests around in order to be viable. So\nthe more Fairmen there are in the population relative to\npairs of Greedies and Modests, the better Fairmen do on\naverage. This implies a threshold effect. If the proportion of Fairmen\ndrops below 33%, then the tendency will be for them to fall to\nextinction because they don\u2019t meet each other often enough. If\nthe population of Fairmen rises above 33%, then the tendency will be\nfor them to rise to fixation because their extra gains when they meet\neach other compensates for their losses when they meet Greedies. You\ncan see this by noticing that when each strategy is used by 33% of the\npopulation, all have an expected average payoff of 1/3. Therefore, any\nrise above this threshold on the part of Fairmen will tend to push\nthem towards fixation.\n\nThis result shows that and how, given certain relatively general\nconditions, justice as we have defined it can arise\ndynamically. The news for the fans of justice gets more cheerful still\nif we introduce correlated play (not to be confused with the\ncorrelated equilibrium concept mentioned in\n Section 3.1\n and elsewhere in this article).\n\nThe model we just considered assumes that strategies are not\ncorrelated, that is, that the probability with which every strategy\nmeets every other strategy is a simple function of their relative\nfrequencies in the population. We now examine what happens in our\ndynamic resource-division game when we introduce correlation. Suppose\nthat Fairmen have a slight ability to distinguish and seek out other\nFairmen as interaction partners. In that case, Fairmen on average do\nbetter, and this must have the effect of lowering their threshold for\ngoing to fixation.\n\nAn evolutionary game modeler studies the effects of correlation and\nother parametric constraints by means of running large computer\nsimulations in which the strategies compete with one another, round\nafter round, in the virtual environment. The starting proportions of\nstrategies, and any chosen degree of correlation, can simply be set in\nthe program. One can then watch its dynamics unfold over time, and\nmeasure the proportion of time it stays in any one equilibrium. These\nproportions are represented by the relative sizes of the basins of\nattraction for different possible equilibria. Equilibria are\nattractor points in a dynamic space; a basin of attraction for each\nsuch point is then the set of points in the space from which the\npopulation will converge to the equilibrium in question.\n\nIn introducing correlation into his model, Skyrms first sets the\ndegree of correlation at a very small .1. This causes the basin of\nattraction for equilibrium (i) to shrink by half. When the degree of\ncorrelation is set to .2, the polymorphic basin reduces to the point\nat which the population starts in the polymorphism. Thus very small\nincreases in correlation produce large proportionate increases in the\nstability of the equilibrium where everyone plays Fairman. A small\namount of correlation is a reasonable assumption in most populations,\ngiven that neighbours tend to interact with one another and to mimic\none another (either genetically or because of tendencies to\ndeliberately copy each other), and because genetically and culturally\nsimilar animals are more likely to live in common environments. Thus\nif justice can arise at all it will tend to be dominant and\nstable.\n\nMuch of political philosophy consists in attempts to produce deductive\nnormative arguments intended to convince an unjust agent that she has\nreasons to act justly. Skyrms\u2019s analysis suggests a quite\ndifferent approach. Fairman will do best of all in the dynamic game if\nhe takes active steps to preserve correlation. Therefore, there is\nevolutionary pressure for both moral approval of justice and\njust institutions to arise. Most people may think that\n50\u201350 splits are \u2018fair\u2019, and worth maintaining by\nmoral and institutional reward and sanction, because we are\nthe products of a dynamic game that promoted our tendency to think\nthis way.\n\nThe topic that has received most attention from evolutionary game\ntheorists is altruism, defined as any behaviour by an\norganism that decreases its own expected fitness in a single\ninteraction but increases that of the other interactor. It is arguably\ncommon in nature. How can it arise, however, given Darwinian\ncompetition?\n\nSkyrms studies this question using the dynamic Prisoner\u2019s\nDilemma as his example. This is simply a series of PD games played in\na population, some of whose members are defectors and some of whom are\ncooperators. Payoffs, as always in evolutionary games, are measured in\nterms of expected numbers of copies of each strategy in future\ngenerations.\n\nLet \\(\\mathbf{U}(A)\\) be the average fitness of strategy \\(A\\) in the\npopulation. Let \\(\\mathbf{U}\\) be the average fitness of the whole\npopulation. Then the proportion of strategy \\(A\\) in the next\ngeneration is just the ratio \\(\\mathbf{U}(A)/\\mathbf{U}\\). So if \\(A\\)\nhas greater fitness than the population average \\(A\\) increases. If\n\\(A\\) has lower fitness than the population average then \\(A\\)\ndecreases.\n\nIn the dynamic PD where interaction is random (i.e., there\u2019s no\ncorrelation), defectors do better than the population average as long\nas there are cooperators around. This follows from the fact that, as\nwe saw in\n Section 2.4,\n defection is always the dominant strategy in a single game. 100%\ndefection is therefore the ESS in the dynamic game without\ncorrelation, corresponding to the NE in the one-shot static PD.\n\nHowever, introducing the possibility of correlation radically changes\nthe picture. We now need to compute the average fitness of a strategy\ngiven its probability of meeting each other possible\nstrategy. In the evolutionary PD, cooperators whose probability\nof meeting other cooperators is high do better than defectors whose\nprobability of meeting other defectors is high. Correlation thus\nfavours cooperation.\n\nIn order to be able to say something more precise about this\nrelationship between correlation and cooperation (and in order to be\nable to relate evolutionary game theory to issues in decision theory,\na matter falling outside the scope of this article), Skyrms introduces\na new technical concept. He calls a strategy adaptively\nratifiable if there is a region around its fixation point in the\ndynamic space such that from anywhere within that region it will go to\nfixation. In the evolutionary PD, both defection and cooperation are\nadaptively ratifiable. The relative sizes of basins of attraction are\nhighly sensitive to the particular mechanisms by which correlation is\nachieved. To illustrate this point, Skyrms builds several\nexamples.\n\nOne of Skyrms\u2019s models introduces correlation by means of a\nfilter on pairing for interaction. Suppose that in round 1 of\na dynamic PD individuals inspect each other and interact, or not,\ndepending on what they find. In the second and subsequent rounds, all\nindividuals who didn\u2019t pair in round 1 are randomly paired. In\nthis game, the basin of attraction for defection is large\nunless there is a high proportion of cooperators in round\none. In this case, defectors fail to pair in round 1, then get paired\nmostly with each other in round 2 and drive each other to extinction.\nA model which is more interesting, because its mechanism is less\nartificial, does not allow individuals to choose their partners, but\nrequires them to interact with those closest to them. Because of\ngenetic relatedness (or cultural learning by copying) individuals are\nmore likely to resemble their neighbours than not. If this (finite)\npopulation is arrayed along one dimension (i.e., along a line), and\nboth cooperators and defectors are introduced into positions along it\nat random, then we get the following dynamics. Isolated cooperators\nhave lower expected fitness than the surrounding defectors and are\ndriven locally to extinction. Members of groups of two cooperators\nhave a 50% probability of interacting with each other, and a 50%\nprobability of each interacting with a defector. As a result, their\naverage expected fitness remains smaller than that of their\nneighbouring defectors, and they too face probable extinction. Groups\nof three cooperators form an unstable point from which both extinction\nand expansion are equally likely. However, in groups of four or more\ncooperators at least one encounter of a cooperator with a cooperator\nsufficient to at least replace the original group is guaranteed. Under\nthis circumstance, the cooperators as a group do better than the\nsurrounding defectors and increase at their expense. Eventually\ncooperators go almost to fixation\u2014but nor quite. Single\ndefectors on the periphery of the population prey on the cooperators\nat the ends and survive as little \u2018criminal communities\u2019.\nWe thus see that altruism can not only be maintained by the dynamics\nof evolutionary games, but, with correlation, can even spread and\ncolonize originally non-altruistic populations.\n\nDarwinian dynamics thus offers qualified good news for cooperation.\nNotice, however, that this holds only so long as individuals are stuck\nwith their natural or cultural programming and can\u2019t re-evaluate\ntheir utilities for themselves. If our agents get too smart and\nflexible, they may notice that they\u2019re in PDs and would each be\nbest off defecting. In that case, they\u2019ll eventually drive\nthemselves to extinction\u2014unless they develop stable, and\neffective, norms that work to reinforce cooperation. But, of course,\nthese are just what we would expect to evolve in populations of\nanimals whose average fitness levels are closely linked to their\ncapacities for successful social cooperation. Even given this, these\npopulations will go extinct unless they care about future generations\nfor some reason. But there\u2019s no non-sentimental reason that\ndoesn\u2019t already presuppose altruistic morality as to why agents\nshould care about future generations if each new generation\nwholly replaces the preceding one at each change of cohorts. For this\nreason, economists use \u2018overlapping generations\u2019 models\nwhen modeling intertemporal distribution games. Individuals in\ngeneration 1 who will last until generation 5 save resources for the\ngeneration 3 individuals with whom they\u2019ll want to cooperate;\nand by generation 3 the new individuals care about generation 6; and\nso on.\n\nGintis (2009a)\n argues that when we set out to use evolutionary game theory to unify\nthe behavioral sciences, we should begin by using it to unify game\ntheory itself. We have pointed out at several earlier points in the\npresent article that NE and SPE are problematic solution concepts in\nmany applications where stable norms or explicit institutional rules\nare missing because agents only have incentives to play NE or SPE to\nthe extent that they are confident that other agents will do likewise.\nTo the extent that agents do not have such confidence, what should be\npredicted is general disorder and social confusion. But now we can\npull together a number of strands from earlier sections. From\n Aumann (1974),\n we have the result that correlated equilibrium can solve this problem\nfor Bayesian learners under certain conditions. Gintis makes this\nconcrete by imagining the presence of what he calls a\n\u2018choreographer\u2019. Evolutionary game theory shows how a\nDarwinian selection process can serve as such a choreographer.\n\nBut then where intelligent strategic agents, such as humans, are\nconcerned, the natural choreographer can be usurped, because the\nagents might aim to optimize utility functions where the arguments do\nnot correspond to the fitness criteria on which their selection\nhistory operated. Then the players need equilibrium selection\nmechanisms of some kind to avoid miscoordination. Cultural evolution,\nanother Darwinian selection process, might provide them with norms\nthat serve as focal points. This is not sufficient to ensure\napplication of the Harsanyi Doctrine, which is needed to ensure\nidentification of correlated equilibrium\n (Aumann 1987).\n A main problem is that norms can unravel if they depend on preference\nfalsification. But people can negotiate new norms on the fly through\nmindshaping. Conditional game theory (2.0) provides one model of the\nstrategic aspect of such mindshaping, which also allows players to\nlearn about one another\u2019s systematic departures from expected\nutility theory and thus recover the conditions for the Harsanyi\nDoctrine to apply.\n\nBut, of course, real humans often encounter one another as cultural\nstrangers, who \u2018play for real\u2019 without prior opportunities\nfor fully informative pre-play. When we wonder about the value of\ngame-theoretic models in application to human behavior outside of\nwell-structured markets or tightly regulated institutional settings,\nmuch hinges on what we take to be plausible and empirically validated\nsources of coordinated information and beliefs. When and how can we\nsuppose that people have incentives to access such information and\nbeliefs, which typically involves costs? This has been a subject of\nextensive recent debate, which we will review in\n Section 8.3\n below.\n8. Game Theory and Behavioral Evidence\n\nIn earlier sections, we reviewed some problems that arise from\ntreating classical (non-evolutionary) game theory as a normative\ntheory that tells people what they ought to do if they wish to be\nrational in strategic situations. The difficulty, as we saw, is that\nthere seems to be no one solution concept we can unequivocally\nrecommend for all situations, particularly where agents have private\ninformation. However, in the previous section we showed how appeal to\nevolutionary foundations sheds light on conditions under which utility\nfunctions that have been explicitly formulated by theorists can\nplausibly be applied to groups of people, leading to game-theoretic\nmodels with plausible and stable solutions. So far, however, we have\nnot reviewed any actual empirical evidence from behavioral\nobservations or experiments. Has game theory indeed helped empirical\nresearchers make new discoveries about behavior (human or otherwise)?\nIf so, what in general has the content of these discoveries been?\n\nIn addressing these questions, an immediate epistemological issue\nconfronts us. There is no way of applying game theory \u2018all by\nitself\u2019, independently of other modelling technologies. Using\nterminology standard in the philosophy of science, one can test a\ngame-theoretic model of a phenomenon only in tandem with\n\u2018auxiliary assumptions\u2019 about the phenomenon in question.\nAt least, this follows if one is strict about treating game theory\npurely as mathematics, with no empirical content of its own. In one\nsense, a theory with no empirical content is never open to testing at\nall; one can only worry about whether the axioms on which the theory\nis based are mutually consistent. A mathematical theory can\nnevertheless be evaluated with respect to empirical\nusefulness. One kind of philosophical criticism that has\nsometimes been made of game theory, interpreted as a mathematical tool\nfor modelling behavioral phenomena, is that its application always or\nusually requires resort to false, misleading or badly simplistic\nassumptions about those phenomena. We would expect this criticism to\nhave different degrees of force in different contexts of application,\nas the auxiliary assumptions vary.\n\nSo matters turn out. There is no interesting domain in which\napplications of game theory have been completely uncontroversial.\nHowever, there has been generally easier consensus on how to use game\ntheory (both classical and evolutionary) to understand non-human\nanimal behavior than on how to deploy it for explanation and\nprediction of the strategic activities of people. Let us first briefly\nconsider philosophical and methodological issues that have arisen\naround application of game theory in non-human biology, before\ndevoting fuller attention to game-theoretic social science.\n\nThe least controversial game-theoretic modelling has applied the\nclassical form of the theory to consideration of strategies by which\nnon-human animals seek to acquire the basic resource relevant to their\nevolutionary tournament: opportunities to produce offspring that are\nthemselves likely to reproduce. In order to thereby maximize their\nexpected fitness, animals must find optimal trade-offs among various\nintermediate goods, such as nutrition, security from predation and\nability to out-compete rivals for mates. Efficient trade-off points\namong these goods can often be estimated for particular species in\nparticular environmental circumstances, and, on the basis of these\nestimations, both parametric and non-parametric equilibria can be\nderived. Models of this sort have an impressive track record in\npredicting and explaining independent empirical data on such strategic\nphenomena as competitive foraging, mate selection, nepotism, sibling\nrivalry, herding, collective anti-predator vigilance and signaling,\nreciprocal grooming, and interspecific mutuality (symbiosis). (For\nexamples see\n Krebs and Davies 1984,\n Bell 1991,\n Dugatkin and Reeve 1998,\n Dukas 1998, and\n Noe, van Hoof and Hammerstein 2001.)\n On the other hand, as\n Hammerstein (2003)\n observes, reciprocity, and its exploitation and metaexploitation, are\nmuch more rarely seen in social non-human animals than game-theoretic\nmodeling would lead us to anticipate. One explanation for this\nsuggested by Hammerstein is that non-human animals typically have less\nability to restrict their interaction partners than do people. Our\ndiscussion in the previous section of the importance of correlation\nfor stabilizing game solutions lends theoretical support to this\nsuggestion.\n\nWhy has classical game theory helped to predict non-human animal\nbehavior more straightforwardly than it has done most human behavior?\nThe answer is presumed to lie in different levels of complication\namongst the relationships between auxiliary assumptions and phenomena.\n Ross (2005a)\n offers the following account. Utility optimization problems are the\ndomain of economics. Economic theory identifies the optimizing\nunits\u2014economic agents\u2014with unchanging preference fields.\nIdentification of whole biological individuals with such agents is\nmore plausible the less cognitively sophisticated the organism. Thus\ninsects (for example) are tailor-made for easy application of Revealed\nPreference Theory (see\n Section 2.1).\n As nervous systems become more complex, however, we encounter animals\nthat learn. Learning can cause a sufficient degree of permanent\nmodification in an animal\u2019s behavioral patterns that we can\npreserve the identification of the biological individual with a single\nagent across the modification only at the cost of explanatory\nemptiness (because assignments of utility functions become\nincreasingly ad hoc). Furthermore, increasing complexity confounds\nsimple modeling on a second dimension: cognitively sophisticated\nanimals not only change their preferences over time, but are governed\nby distributed control processes that make them sites of competition\namong internal agents\n (Schelling 1980;\n Ainslie 1992,\n Ainslie 2001).\n Thus they are not straightforward economic agents even at a\ntime. In setting out to model the behavior of people using any part of\neconomic theory, including game theory, we must recognize that the\nrelationship between any given person and an economic agent we\nconstruct for modeling purposes will always be more complicated than\nsimple identity.\n\nThere is no sharp crossing point at which an animal becomes too\ncognitively sophisticated to be modeled as a single economic agent,\nand for all animals (including humans) there are contexts in which we\ncan usefully ignore the synchronic dimension of complexity. However,\nwe encounter a phase shift in modeling dynamics when we turn from\nasocial animals to non-eusocial social ones. (This refers to animals\nthat are social but that don\u2019t, like ants, bees, wasps, termites\nand naked mole rats, achieve cooperation thanks to fundamental changes\nin their population genetics that make individuals within groups into\nnear clones. Some known instances are parrots, corvids, bats, rats,\ncanines, hyenas, pigs, raccoons, otters, elephants, hyraxes,\ncetaceans, and primates.) In their cases stabilization of internal\ncontrol dynamics is partly located outside the individuals,\nat the level of group dynamics. With these creatures, modeling an\nindividual as an economic agent, with a single comprehensive utility\nfunction, is a drastic idealization, which can only be done with the\ngreatest methodological caution and attention to specific contextual\nfactors relevant to the particular modeling exercise. Applications of\ngame theory here can only be empirically adequate to the extent that\nthe economic modeling is empirically adequate.\n\nH. sapiens is the extreme case in this respect. Individual\nhumans are socially controlled to an extreme degree by comparison with\nmost other non-eusocial species. At the same time, their great\ncognitive plasticity allows them to vary significantly between\ncultures. People are thus the least straightforward economic agents\namong all organisms. (It might thus be thought ironic that they were\ntaken, originally and for many years, to be the exemplary instances of\neconomic agency, on account of their allegedly superior\n\u2018rationality\u2019.) We will consider the implications of this\nfor applications of game theory below.\n\nFirst, however, comments are in order concerning the empirical\nadequacy of evolutionary game theory to explain and predict\ndistributions of strategic dispositions in populations of agents. Such\nmodeling is applied both to animals as products of natural selection\n (Hofbauer and Sigmund 1998),\n and to non-eusocial social animals (but especially humans) as\nproducts of cultural selection\n (Boyd and Richerson 1985;\n Young 1998). There are two main kinds of auxiliary assumptions one\nmust justify, relative to a particular instance at hand, in\nconstructing such applications. First, one must have grounds for\nconfidence that the dispositions one seeks to explain are (either\nbiological or cultural, as the case may be)\nadaptations\u2014that is, dispositions that were selected\nand are maintained because of the way in which they promote their own\nfitness or the fitness of the wider system, rather than being\naccidents or structurally inevitable byproducts of other adaptations.\n(See\n Dennett 1995\n for a general discussion of this issue.) Second, one must be able to\nset the modeling enterprise in the context of a justified set of\nassumptions about interrelationships among nested evolutionary\nprocesses on different time scales. (For example, in the case of a\nspecies with cultural dynamics, how does slow genetic evolution\nconstrain fast cultural evolution? How does cultural evolution feed\nback into genetic evolution, if it feeds back at all? For a masterful\ndiscussion of these issues, see\n Sterelny 2003.)\n Conflicting views over which such assumptions should be made about\nhuman evolution are the basis for lively current disputes in the\nevolutionary game-theoretic modeling of human behavioral dispositions\nand institutions. This is where issues in evolutionary game theory\nmeet issues in the booming field of behavioral-experimental\ngame theory. We will therefore first consider the second field before\ngiving a sense of the controversies just alluded to, which now\nconstitute the liveliest domain of philosophical argument in the\nfoundations of game theory and its applications.\n8.1 Game Theory in the Laboratory\n\nEconomists have been testing theories by running laboratory\nexperiments with human and other animal subjects since pioneering work\nby\n Thurstone (1931).\n In recent decades, the volume of such work has become gigantic. The\nvast majority of it sets subjects in microeconomic problem\nenvironments that are imperfectly competitive. Since this is precisely\nthe condition in which microeconomics collapses into game theory, most\nexperimental economics has been experimental game theory. It is thus\ndifficult to distinguish between experimentally motivated questions\nabout the empirical adequacy of microeconomic theory and questions\nabout the empirical adequacy of game theory.\n\nWe can here give only a broad overview of an enormous and complicated\nliterature. Readers are referred to critical surveys in\n Kagel and Roth (1995),\n Camerer (2003),\n Samuelson (2005),\n and the methodological review by\n Guala (2005).\n A useful high-level principle for sorting the literature indexes it\nto the different auxiliary assumptions with which game-theoretic\naxioms are applied. It is often said in popular presentations (e.g.,\n Ormerod 1994)\n that the experimental data generally refute the hypothesis that\npeople are rational economic agents. Such claims are too imprecise to\nbe sustainable interpretations of the results. All data are consistent\nwith the view that people are approximate economic agents, at\nleast for stretches of time long enough to permit game-theoretic\nanalysis of particular scenarios, in the minimal sense that their\nbehavior can be modeled compatibly with Revealed Preference Theory\n(see\n Section 2.1).\n However, RPT makes so little in the way of empirical demands that\nthis is not nearly as surprising as many non-economists suppose\n (Ross 2005a).\n What is really at issue in many of the debates around the general\ninterpretation of experimental evidence is the extent to which people\nare maximizers of expected utility. As we saw in\n Section 3,\n expected utility theory (EUT) is generally applied in tandem with\ngame theory in order to model situations involving\nuncertainty\u2014which is to say, most situations of interest in\nbehavioral science. However, a variety of alternative structural\nmodels of utility lend themselves to Von Neumann-Morgenstern\ncardinalization of preferences and are definable in terms of subsets\nof the\n Savage (1954)\n axioms of subjective utility. The empirical usefulness of game theory\nwould be called into question only if we thought that people\u2019s\nbehavior is not generally describable by means of cardinal vNMufs.\n\nWhat the experimental literature truly appears to show is a world of\nbehavior that is usually noisy from the theorist\u2019s point of\nview. The noise in question arises from substantial heterogeneity,\nboth among people and among (person, situation) vectors. There is no\nsingle structural utility function such that all people act so as to\nmaximize a function of that structure in all circumstances. Faced with\nwell-learned problems in contexts that are not unduly demanding, or\nthat are highly institutionally structured people often behave like\nexpected utility maximizers. For general reviews of theoretical issues\nand evidence, see\n Smith (2008)\n and\n Binmore (2007).\n For an extended sequence of examples of empirical studies, see the\nso-called \u2018continuous double auction\u2019 experiments\ndiscussed in\n Plott and Smith 1978\n and Smith\n 1962,\n 1964,\n 1965,\n 1976,\n 1982.\n As a result, classical game theory can be used in such domains with\nhigh reliability to predict behavior and implement public policy, as\nis demonstrated by the dozens of extremely successful government\nauctions of utilities and other assets designed by game theorists to\nincrease public revenue\n (Binmore and Klemperer 2002).\n\nIn other contexts, interpreting people\u2019s behavior as\ngenerally expected-utility maximizing requires undue violence\nto the need for generality in theory construction. We get better\nprediction using fewer case-specific restrictions if we suppose that\nsubjects are maximizing according to one or (typically) more\nof several alternatives (which will not be described here because they\nare not directly about game theory): rank-dependent utility theory\n (Quiggin 1982,\n Yaari 1987), or alpha-nu utility theory\n (Chew and MacCrimmon 1979).\n The first alternative in fact denotes a family of alternative\nspecifications. One of these, the specification of\n Prelec (1998),\n has emerged in an accumulating mass of empirical estimations as the\nstatistically most useful model of observed human choice under risk\nand uncertainty.\n Harrison and Rutstrom (2008)\n show how to design and code maximum likelihood mixture\nmodels, which allow an empirical modeler to apply a range of\nthese decision functions to a single set of choice data. The resulting\nanalysis identifies the proportion of the total choice set best\nexplained by each model in the mixture.\n Andersen et al (2014)\n take this approach to the current state of the art, demonstrating the\nempirical value of including a model of non-maximizing psychological\nprocesses in a mixture along with maximizing economic models. This\neffective flexibility with respect to the decision modeling that can\nbe deployed in empirical applications of game theory relieves most\npressure to seek adjustments in the game theoretic structures\nthemselves. Thus it fits well with the interpretation of game theory\nas part of the behavioral scientist\u2019s mathematical toolkit,\nrather than as a first-order empirical model of human psychology.\n\nA more serious threat to the usefulness of game theory is evidence of\nsystematic reversal of preferences, in both humans and other animals.\nThis is more serious both because it extends beyond the human case,\nand because it challenges Revealed Preference Theory (RPT) rather than\njust unnecessarily rigid commitment to EUT. As explained in\n Section 2.1,\n RPT, unlike EUT, is among the axiomatic foundations of game theory\ninterpreted non-psychologically. (Not all writers agree that apparent\npreference reversal phenomena threaten RPT rather than EUT; but see\nthe discussions in\n Camerer (1995),\n pp. 660\u2013665, and\n Ross (2005a),\n pp. 177\u2013181.) A basis for preference reversals that seems to be\ncommon in animals with brains is hyperbolic discounting of the\nfuture\n (Strotz 1956,\n Ainslie 1992). This is the phenomenon whereby agents discount future\nrewards more steeply in close temporal distances from the current\nreference point than at more remote temporal distances. This is best\nunderstood by contrast with the idea found in most traditional\neconomic models of exponential discounting, in which there is\na linear relationship between the rate of change in the distance to a\npayoff and the rate at which the value of the payoff from the\nreference point declines. The figure below shows exponential and\nhyperbolic curves for the same interval from a reference point to a\nfuture payoff. The bottom one graphs the hyperbolic function; the\nbowed shape results from the change in the rate of discounting.\n\n\n\nFigure 15\n\n\nA result of this is that, as later prospects come closer to the point\nof possible consumption, people and other animals will sometimes spend\nresources undoing the consequences of previous actions that also cost\nthem resources. For example: deciding today whether to mark a pile of\nundergraduate essays or watch a baseball game, I procrastinate,\ndespite knowing that by doing so I put out of reach some even more fun\npossibility that might come up for tomorrow (when there\u2019s an\nequally attractive ball game on if the better option doesn\u2019t\narise). So far, this can be accounted for in a way that preserves\nconsistency of preferences: if the world might end tonight, with a\ntiny but nonzero probability, then there\u2019s some level of risk\naversion at which I\u2019d rather leave the essays unmarked. The\nfigure below compares two exponential discount curves, the lower one\nfor the value of the game I watch before finishing my marking, and the\nhigher one for the more valuable game I enjoy after completing the\njob. Both have higher value from the reference point the closer they\nare to it; but the curves do not cross, so my revealed preferences are\nconsistent over time no matter how impatient I might be.\n\n\n\nFigure 16\n\n\nHowever, if I bind myself against procrastination by buying a ticket\nfor tomorrow\u2019s game, when in the absence of the awful task I\nwouldn\u2019t have done so, then I\u2019ve violated intertemporal\npreference consistency. More vividly, had I been in a position to\nchoose last week whether to procrastinate today, I\u2019d have chosen\nnot to. In this case, my discount curve drawn from the reference point\nof last week crosses the curve drawn from the perspective of today,\nand my preferences reverse. The figure below shows this situation.\n\n\n\nFigure 17\n\n\nThis phenomenon complicates applications of classical game theory to\nintelligent animals. However, it clearly doesn\u2019t vitiate it\naltogether, since people (and other animals) often\ndon\u2019t reverse their preferences. (If this weren\u2019t\ntrue, the successful auction models and other s-called\n\u2018mechanism designs\u2019 would be mysterious.) Interestingly,\nthe leading theories that aim to explain why hyperbolic discounters\nmight often behave in accordance with RPT themselves appeal to game\ntheoretic principles.\n Ainslie (1992,\n 2001) has produced an account of people as communities of\ninternal bargaining interests, in which subunits based on short-term,\nmedium-term and long-term interests face conflict that they must\nresolve because if they don\u2019t, and instead generate an internal\nHobbesian breakdown\n (Section 1),\n outside agents who avoid the Hobbesian outcome can ruin them all. The\ndevice of the Hobbesian tyrant is unavailable to the brain. Therefore,\nits behavior (when system-level insanity is avoided) is a sequence of\nself-enforcing equilibria of the sort studied by game-theoretic public\nchoice literature on coalitional bargaining in democratic\nlegislatures. That is, the internal politics of the brain consists in\n\u2018logrolling\u2019\n (Stratmann 1997).\n These internal dynamics are then partly regulated and stabilized by\nthe wider social games in which coalitions (people as wholes over\ntemporal subparts of their biographies) are embedded\n (Ross 2005a ,\n pp. 334\u2013353). (For example: social expectations about\nsomeone\u2019s role as a salesperson set behavioral equilibrium\ntargets for the logrolling processes in their brain.) This potentially\nadds further relevant elements to the explanation of why and how\nstable institutions with relatively transparent rules are key\nconditions that help people more closely resemble straightforward\neconomic agents, such that classical game theory finds reliable\napplication to them as entire units.\n\nOne important note of caution is in order here. Much of the recent\nbehavioral literature takes for granted that temporally inconsistent\ndiscounting is the standard or default case for people. However,\n Andersen et al (2008)\n show empirically that this arises from (i) assuming that groups of\npeople are homogenous with respect to which functional forms best\ndescribe their discounting behavior, and (ii) failure to independently\nelicit and control for people\u2019s differing levels of risk\naversion in estimating their discount functions. In a range of\npopulations that have been studied with these two considerations in\nmind, data suggest that temporally consistent discounting describes\nsubstantially higher proportions of choices than does temporally\ninconsistent choices. Over-generalization of hyperbolic discounting\nmodels should thus be avoided. \n8.2 Neuroeconomics and Game Theory\n\nThe idea that game theory can find novel application to the internal\ndynamics of brains, as suggested in the previous section, has been\ndeveloped from independent motivations by the research program known\nas neuroeconomics\n (Montague and Berns 2002,\n Glimcher 2003,\n Ross 2005a,\n pp. 320\u2013334,\n Camerer, Loewenstein and Prelec 2005).\n Thanks to new non-invasive scanning technologies, especially\nfunctional magnetic resonance imaging (fMRI), it has recently become\npossible to study synaptic activity in working brains while they\nrespond to controlled cues. This has allowed a new path of\naccess\u2014though still a highly indirect one\n (Harrison and Ross 2010)\u2014\n to the brain\u2019s computation of expected values of rewards, which\nare (naturally) taken to play a crucial role in determining behavior.\nEconomic theory is used to frame the derivation of the functions\nmaximized by synaptic-level computation of these expected values;\nhence the name \u2018neuroeconomics\u2019.\n\nGame theory plays a leading role in neuroeconomics at two levels.\nFirst, game theory has been used to predict the computations that\nindividual neurons and groups of neurons serving the reward system\nmust perform. In the best publicized example,\n Glimcher (2003)\n and colleagues have fMRI-scanned monkeys they had trained to play\nso-called \u2018inspection games\u2019 against computers. In an\ninspection game, one player faces a series of choices either to work\nfor a reward, in which case he is sure to receive it, or to perform\nanother, easier action (\u201cshirking\u201d), in which case he will\nreceive the reward only if the other player (the\n\u201cinspector\u201d) is not monitoring him. Assume that the first\nplayer\u2019s (the \u201cworker\u2019s\u201d) behavior reveals a\nutility function bounded on each end as follows: he will work on every\noccasion if the inspector always monitors and he will shirk on every\noccasion if the inspector never monitors. The inspector prefers to\nobtain the highest possible amount of work for the lowest possible\nmonitoring rate. In this game, the only NE for both players are in\nmixed strategies, since any pattern in one player\u2019s strategy\nthat can be detected by the other can be exploited. For any given pair\nof specific utility functions for the two players meeting the\nconstraints described above, any pair of strategies in which, on each\ntrial, either the worker is indifferent between working and shirking\nor the inspector is indifferent between monitoring and not monitoring,\nis a NE.\n\nApplying inspection game analyses to pairs or groups of agents\nrequires us to have either independently justified their\nutility functions over all variables relevant to their play, in which\ncase we can define NE and then test to see whether they successfully\nmaximize expected utility; or to assume that they maximize\nexpected utility, or obey some other rule such as a matching function,\nand then infer their utility functions from their behavior. Either\nsuch procedure can be sensible in different empirical contexts. But\nepistemological leverage increases greatly if the utility function of\nthe inspector is exogenously determined, as it often is. (Police\nimplementing random roadside inspections to catch drunk drivers, for\nexample, typically have a maximum incidence of drunk driving assigned\nto them as a target by policy, and an exogenously set budget. These\ndetermine their utility function, given a distribution of preferences\nand attitudes to risk among the population of drivers.) In the case of\nGlimcher\u2019s experiments the inspector is a computer, so its\nprogram is under experimental control and its side of the payoff\nmatrix is known. Proxies for the subjects\u2019 expected utility, in\nthis case squirts of fruit juice for the monkeys, can be antecedently\ndetermined in parametric test settings. The computer is then\nprogrammed with the economic model of the monkeys, and can search the\ndata in their behavior in game conditions for exploitable patterns,\nvarying its strategy accordingly. With these variables fixed,\nexpected-utility-maximizing NE behavior by the monkeys can be\ncalculated and tested by manipulating the computer\u2019s utility\nfunction in various runs of the game.\n\nMonkey behavior after training tracks NE very robustly (as does the\nbehavior of people playing similar games for monetary prizes;\n Glimcher 2003,\n pp. 307\u2013308). Working with trained monkeys, Glimcher and\ncolleagues could then perform the experiments of significance here.\nWorking and shirking behaviors for the monkeys had been associated by\ntheir training with staring either to the right or to the left on a\nvisual display. In earlier experiments,\n Platt and Glimcher (1999)\n had established that, in parametric settings, as juice rewards varied\nfrom one block of trials to another, firing rates of each parietal\nneuron that controls eye movements could be trained to encode the\nexpected utility to the monkey of each possible movement relative to\nthe expected utility of the alternative movement. Thus\n\u201cmovements that were worth 0.4 ml of juice were represented\ntwice as strongly [in neural firing probabilities] as movements worth\n0.2 ml of juice\u201d (p. 314). Unsurprisingly, when amounts of juice\nrewarded for each movement were varied from one block of trials to\nanother, firing rates also varied.\n\nAgainst this background, Glimcher and colleagues could investigate the\nway in which monkeys\u2019 brains implemented the tracking of NE.\nWhen the monkeys played the inspection game against the computer, the\ntarget associated with shirking could be set at the optimal location,\ngiven the prior training, for a specific neuron under study, while the\nwork target would appear at a null location. This permitted Glimcher\nto test the answer to the following question: did the monkeys maintain\nNE in the game by keeping the firing rate of the neuron constant while\nthe actual and optimal behavior of the monkey as a whole varied? The\ndata robustly gave the answer \u2018yes\u2019. Glimcher reasonably\ninterprets these data as suggesting that neural firing rates, at least\nin this cortical region for this task, encode expected utility in both\nparametric and nonparametric settings. Here we have an apparent\nvindication of the empirical applicability of classical game theory in\na context independent of institutions or social conventions.\n\nFurther analysis pushed the hypothesis deeper. The computer playing\nInspector was presented with the same sequence of outcomes as its\nmonkey opponent had received on the previous day\u2019s play, and for\neach move was asked to assess the relative expected values of the\nshirking and working actions available on the next move. Glimcher\nreports a positive correlation between small fluctuations around the\nstable NE firing rates in the individual neuron and the expected\nvalues estimated by the computer trying to track the same NE. Glimcher\ncomments on this finding as follows:\n\nThe neurons seemed to be reflecting, on a play-by-play basis, a\ncomputation close to the one performed by our computer \u2026 [A]t a\n\u2026 [relatively] \u2026 microscopic scale, we were able to use\ngame theory to begin to describe the decision-by-decision computations\nthat the neurons in area LIP were performing.\n (Glimcher 2003,\n p. 317)\n\n\nThus we find game theory reaching beyond its traditional role as a\ntechnology for framing high-level constraints on evolutionary dynamics\nor on behavior by well-informed agents operating in institutional\nstraitjackets. In Glimcher\u2019s hands, it is used to directly model\nactivity in a monkey\u2019s brain.\n Ross (2005a)\n argues that groups of neurons thus modeled should not be identified\nwith the sub-personal game-playing units found in Ainslie\u2019s\ntheory of intra-personal bargaining described earlier; that would\ninvolve a kind of straightforward reduction that experience in the\nbehavioral and life sciences has taught us not to expect. This issue\nhas since arisen in a direct dispute between neuroeconomists over\nrival interpretations of fMRI observations of intertemporal choice and\ndiscounting\n (McClure et al. 2004),\n Glimcher et al. 2007). The weight of evidence so far favors the view that if\nit is sometimes useful to analyze people\u2019s choices as equilibria\nin games amongst sub-personal agents, the sub-personal agents in\nquestion should not be identified with separate brain areas. The\nopposite interpretation is unfortunately still most common in less\nspecialized literature. \n\nWe have now seen the first level at which neuroeconomics applies game\ntheory. A second level involves seeking conditioning variables in\nneural activity that might impact people\u2019s choices of strategies\nwhen they play games. This has typically involved repeating protocols\nfrom the behavioral game theory literature with research subjects who\nare lying in fMRI scanners during play.\n Harrison (2008)\n and\n Ross (2008b)\n have argued for skepticism about the value of work of this kind,\nwhich involves various uncomfortably large leaps of inference in\nassociating the observed behavior with specific imputed neural\nresponses. It can also be questioned whether much generalizable new\nknowledge is gained to the extent that such associations can\nbe successfully identified.\n\nLet us provide an example of this kind of \u201cgame in a\nscanner\u201d\u2014that directly involves strategic interaction.\n King-Casas et al. (2005)\n took a standard protocol from behavioral game theory, the so-called\n\u2018trust\u2019 game, and implemented it with subjects whose\nbrains were jointly scanned using a technology for linking the\nfunctional maps of their respective brains, known as\n\u2018hyperscanning\u2019). This game involves two players. In its\nrepeated format as used in the King-Casas et al. experiment,\nthe first player is designated the \u2018investor\u2019 and the\nsecond the \u2018trustee\u2019. The investor begins with $20, of\nwhich she can keep any portion of her choice while investing the\nremainder with the trustee. In the trustee\u2019s hands the invested\namount is tripled by the experimenter. The trustee may then return as\nmuch or as little of this profit to the investor as he deems fit. The\nprocedure is run for ten rounds, with players\u2019 identities kept\nanonymous from one another.\n\nThis game has an infinite number of NE. Previous data from behavioral\neconomics are consistent with the claim that the modal NE in human\nplay approximates both players using\n\u2018Tit-for-tat\u2019 strategies (see\n Section 4)\n modified by occasional defections to probe for information, and some\npost-defection cooperation that manifests (limited) toleration of such\nprobes. This is a very weak result, since it is compatible with a wide\nrange of hypotheses on exactly which variations of Tit-for-tat are\nused and sustained, and thus licenses no inferences about potential\ndynamics under different learning conditions, institutions, or\ncross-cultural transfers.\n\nWhen they ran this game under hyperscanning, the researchers\ninterpreted their observations as follows. Neurons in the\ntrustee\u2019s caudate nucleus (generally thought to implement\ncomputations or outputs of midbrain dopaminergic systems) were thought\nto show strong response when investors benevolently reciprocated\ntrust\u2014that is, responded to defection with increased generosity.\nAs the game progressed, these responses were believed to have shifted\nfrom being reactionary to being anticipatory. Thus reputational\nprofiles as predicted by classical game-theoretic models were inferred\nto have been constructed directly by the brain. A further aspect of\nthe findings not predictable by theoretical modeling alone, and which\npurely behavioral observation had not been sufficient to discriminate,\nwas taken to be that responses by the caudate neurons to malevolent\nreciprocity\u2014that is, reduced generosity in response to\ncooperation\u2014were significantly smaller in amplitude. This was\nhypothesized to be a mechanism by which the brain implements\nmodification of Tit-for-tat so as to prevent occasional defections for\ninformational probing from unraveling cooperation permanently. \n\nThe advance in understanding for which practitioners of this style of\nneuroeconomics hope consists not in what it tells us about particular\ntypes of games, but rather in comparative inferences it facilitates\nabout the ways in which contextual framing influences people\u2019s\nconjectures about which games they\u2019re playing. fMRI or other\nkinds of probes of working brains might, it is conjectured, enable us\nto quantitatively estimate degrees of strategic surprise.\nReciprocally interacting expectations about surprise may themselves be\nsubject to strategic manipulation, but this is an idea that has barely\nbegun to be theoretically explored by game theorists (see\n Ross and Dumouchel 2004).\n The view of some neuroeconomists that we now have the prospect of\nempirically testing such new theories, as opposed to just\nhypothetically modeling them, has stimulated growth in this line of\nresearch.\n8.3 Game Theoretic Models of Human Nature\n\nThe developments reviewed in the previous section bring us up to the\nmoving frontier of experimental / behavioral applications of classical\ngame theory. We can now return to the branch point left off several\nparagraphs back, where this stream of investigation meets that coming\nfrom evolutionary game theory. There is no serious doubt that, by\ncomparison to other non-eusocial animals\u2014including our nearest\nrelatives, chimpanzees and bonobos\u2014humans achieve prodigious\nfeats of coordination (see\n Section 4)\n (Tomasello et al. 2004). A lively controversy, with important philosophical\nimplications and fought on both sides with game-theoretic arguments,\nwent on for some time over whether this capacity can be wholly\nexplained by cultural adaptation, or is better explained by inference\nto a genetic change early in the career of H. sapiens.\n\nHenrich et al.\n (2004,\n 2005) have run a series of experimental games with\npopulations drawn from fifteen small-scale human societies in South\nAmerica, Africa, and Asia, including three groups of foragers, six\ngroups of slash-and-burn horticulturists, four groups of nomadic\nherders, and two groups of small-scale agriculturists. The games\n(Ultimatum, Dictator, Public Goods) they implemented all place\nsubjects in situations broadly resembling that of the Trust game\ndiscussed in the previous section. That is, Ultimatum and Public Goods\ngames are scenarios in which both social welfare and each\nindividual\u2019s welfare are optimized (Pareto efficiency achieved)\nif and only if at least some players use strategies that are not\nsub-game perfect equilibrium strategies (see\n Section 2.6).\n In Dictator games, a narrowly selfish first mover would capture all\navailable profits. Thus in each of the three game types, SPE players\nwho cared only about their own monetary welfare would get outcomes\nthat would involve highly inegalitarian payoffs. In none of the\nsocieties studied by Henrich et al. (or any other society in\nwhich games of this sort have been run) are such outcomes observed.\nThe players whose roles are such that they would take away all but\nepsilon of the monetary profits if they and their partners played SPE\nalways offered the partners substantially more than epsilon, and even\nthen partners sometimes refused such offers at the cost of receiving\nno money. Furthermore, unlike the traditional subjects of experimental\neconomics\u2014university students in industrialized\ncountries\u2014Henrich et al.\u2019s subjects did not even\nplay Nash equilibrium strategies with respect to monetary\npayoffs. (That is, strategically advantaged players offered larger\nprofit splits to strategically disadvantaged ones than was necessary\nto induce agreement to their offers.) Henrich et al.\ninterpret these results by suggesting that all actual people, unlike\n\u2018rational economic man\u2019, value egalitarian outcomes to\nsome extent. However, their experiments also show that this extent\nvaries significantly with culture, and is correlated with variations\nin two specific cultural variables: typical payoffs to cooperation\n(the extent to which economic life in the society depends on\ncooperation with non-immediate kin) and aggregate market integration\n(a construct built out of independently measured degrees of social\ncomplexity, anonymity, privacy, and settlement size). As the values of\nthese two variables increase, game behavior shifts (weakly) in the\ndirection of Nash equilibrium play. Thus the researchers conclude that\npeople are naturally endowed with preferences for egalitarianism, but\nthat the relative weight of these preferences is programmable by\nsocial learning processes conditioned on local cultural cues.\n\nIn evaluating Henrich et al.\u2019s interpretation of these\ndata, we should first note that no axioms of RPT, or of the various\nmodels of decision mentioned in\n Section 8.1,\n which are applied jointly with game theoretic modeling to human\nchoice data, specify or entail the property of narrow selfishness.\n(See\n Ross (2005a)\n ch. 4;\n Binmore (2005b)\n and\n (2009);\n and any economics or game theory text that lets the mathematics speak\nfor itself.) Orthodox game theory thus does not predict that people\nwill play SPE or NE strategies derived by treating their own monetary\npayoffs as equivalent to utility.\n Binmore (2005b)\n is therefore justified in criticizing Henrich et al for\nrhetoric suggesting that their empirical work embarrasses orthodox\ntheory. \n\nThis is not to suggest that the anthropological interpretation of the\nempirical results should be taken as uncontroversial. Binmore\n (1994,\n 1998,\n 2005a,\n 2005b) has argued for many years, based on a wide range of\nbehavioral data, that when people play games with non-relatives they\ntend to learn to play Nash equilibrium with respect to utility\nfunctions that approximately correspond to income functions. As he\npoints out in\n Binmore (2005b),\n Henrich et al.\u2019s data do not test this hypothesis for\ntheir small-scale societies, because their subjects were not exposed\nto the test games for the (quite long, in the case of the Ultimatum\ngame) learning period that theoretical and computational models\nsuggest are required for people to converge on NE. When people play\nunfamiliar games, they tend to model them by reference to games they\nare used to in everyday experience. In particular, they tend to play\none-shot laboratory games as though they were familiar\nrepeated games, since one-shot games are rare in normal\nsocial life outside of special institutional contexts. Many of the\ninterpretive remarks made by Henrich et al. are consistent\nwith this hypothesis concerning their subjects, though they\nnevertheless explicitly reject the hypothesis itself. What is\ncontroversial here\u2014the issues of spin around\n\u2018orthodox\u2019 theory aside\u2014is less about what the\nparticular subjects in this experiment were doing than about what\ntheir behavior should lead us to infer about human evolution.\n\nGintis (2004),\n (2009a) argues that data of the sort we have been discussing\nsupport the following conjecture about human evolution. Our ancestors\napproximated maximizers of individual fitness. Somewhere along the\nevolutionary line these ancestors arrived in circumstances where\nenough of them optimized their individual fitness by acting so as to\noptimize the welfare of their group\n (Sober and Wilson 1998)\n that a genetic modification went to fixation in the species: we\ndeveloped preferences not just over our own individual welfare, but\nover the relative welfare of all members of our communities, indexed\nto social norms programmable in each individual by cultural\nlearning. Thus the contemporary researcher applying game theory to\nmodel a social situation is advised to unearth her subjects\u2019\nutility functions by (i) finding out what community (or communities)\nthey are members of, and then (ii) inferring the utility function(s)\nprogrammed into members of that community (communities) by studying\nrepresentatives of each relevant community in a range of games and\nassuming that the outcomes are correlated equilibria. Since the\nutility functions are the dependent variables here, the games must be\nindependently determined. We can typically hold at least the strategic\nforms of the relevant games fixed, Gintis supposes, by virtue of (a)\nour confidence that people prefer egalitarian outcomes, all else being\nequal, to inegalitarian ones within the culturally evolved\n\u2018insider groups\u2019 to which they perceive themselves as\nbelonging and (b) a requirement that game equilibria are drawn from\nstable attractors in plausible evolutionary game-theoretic models of\nthe culture\u2019s historical dynamics.\n\nRequirement (b) as a constraint on game-theoretic modeling of general\nhuman strategic dispositions is no longer very controversial\u2014or,\nat least, is no more controversial than the generic adaptationism in\nevolutionary anthropology of which it is one expression. However, many\ncommentators are skeptical of Gintis\u2019s suggestion that there was\na genetic discontinuity in the evolution of human sociality. (For a\ncognitive-evolutionary anthropology that explicitly denies such\ndiscontinuity, see\n Sterelny 2003.)\n Based partly on such skepticism (but more directly on behavioral\ndata) Binmore\n (2005a,\n 2005b) resists modeling people as having built-in preferences\nfor egalitarianism. According to Binmore\u2019s\n (1994,\n 1998,\n 2005a)\n model, the basic class of strategic problems facing non-eusocial\nsocial animals are coordination games. Human communities evolve\ncultural norms to select equilibria in these games, and many of these\nequilibria will be compatible with high levels of apparently\naltruistic behavior in some (but not all) games. Binmore argues that\npeople adapt their conceptions of fairness to whatever happen to be\ntheir locally prevailing equilibrium selection rules. However, he\nmaintains that the dynamic development of such norms must be\ncompatible, in the long run, with bargaining equilibria among\nself-regarding individuals. Indeed, he argues that as societies evolve\ninstitutions that encourage what Henrich et al. call\naggregate market integration (discussed above), their utility\nfunctions and social norms tend to converge on self-regarding economic\nrationality with respect to welfare. This does not mean that Binmore\nis pessimistic about the prospects for egalitarianism: he develops a\nmodel showing that societies of broadly self-interested bargainers can\nbe pulled naturally along dynamically stable equilibrium paths towards\nnorms of distribution corresponding to Rawlsian justice\n (Rawls 1971).\n The principal barriers to such evolution, according to Binmore, are\nprecisely the kinds of other-regarding preferences that conservatives\nvalorize as a way of discouraging examination of more egalitarian\nbargaining equilibria that are within reach along societies\u2019\nequilibrium paths.\n\nResolution of this debate between Gintis and Binmore fortunately need\nnot wait upon discoveries about the deep human evolutionary past that\nwe may never have. The models make rival empirical predictions of some\ntestable phenomena. If Gintis is right then there are limits, imposed\nby the discontinuity in hominin evolution, on the extent to which\npeople can learn to be self-regarding. This is the main significance\nof the controversy discussed above over Henrich et\nal.\u2019s interpretation of their field data. Binmore\u2019s\nmodel of social equilibrium selection also depends, unlike\nGintis\u2019s, on widespread dispositions among people to inflict\nsecond-order punishment on members of society who fail to sanction\nviolators of social norms.\n Gintis (2005)\n shows using a game theory model that this is implausible if\npunishment costs are significant. However,\n Ross (2008a)\n argues that the widespread assumption in the literature that\npunishment of norm-violation must be costly results from failure to\nadequately distinguish between models of the original evolution of\nsociality, on the one hand, and models of the maintenance and\ndevelopment of norms and institutions once an initial set of them has\nstabilized. Finally, Ross also points out that Binmore\u2019s\nobjectives are as much normative as descriptive: he aims to show\negalitarians how to diagnose the errors in conservative\nrationalisations of the status quo without calling for revolutions\nthat put equilibrium path stability (and, therefore, social welfare)\nat risk. It is a sound principle in constructing reform proposals that\nthey should be \u2018knave-proof\u2019 (as Hume put it), that is,\nshould be compatible with less altruism than might prevail in\npeople.\n9. Looking Ahead: Areas of Current Innovation\n\nIn 2016 the Journal of Economic Perspectives published a\nsymposium on \u201cWhat is Happening in Game Theory?\u201d Each of\nthe participants noted independently that game theory has become so\ntightly entangled with microeconomic theory in general that the\nquestion becomes difficult to distinguish from inquiry into the moving\nfrontier of that entire sub-discipline, which is in turn the largest\npart of economics as a whole. Thus the boundary between the\nphilosophy of game theory and the philosophy of\nmicroeconomics is now similarly indistinct. Of course, as has been\nstressed, applications of game theory extend beyond the traditional\ndomain of economics, into all of the behavioral and social sciences.\nBut as the methods of game theory have fused with the methods of\nmicroeconomics, a commentator might equally view these extensions as\nbeing exported applications of microeconomics.\n\nFollowing decades of development (incompletely) surveyed in the\npresent article, the past few years have been relatively quiet ones\nwhere foundational innovations of the kind that invite contributions\nfrom philosophers are concerned. Some parts of the original\nfoundations are being newly revisited, however.\n\nvon Neumann and Morgenstern\u2019s (1944)\n introduction of game theory divided the inquiry into two parts.\nNoncooperative game theory analyzes cases built on the\nassumption that each player maximizes her own utility function while\ntreating the expected strategic responses of other players as\nconstraints. As discussed above, the specific game to which von\nNeumann and Morgenstern applied their modeling was poker, which is a\nzero-sum game. Most of the present article has focused on the many\ntheoretical challenges and insights that arose from extending\nnoncooperative game theory beyond the zero-sum domain. But this in\nfact develops only half of von Neumann and Morgenstern\u2019s\nclassic. The other half developed cooperative game theory,\nabout which nothing has so far been said here. The reason for this\nsilence is that for most game theorists cooperative game theory is a\ndistraction at best and at worst a technology that confuses\nthe point of game theory by bypassing the aspect of games that mainly\nmakes them potentially interesting and insightful in application,\nnamely, the requirement that equilibria be selected endogenously under\nthe restrictions imposed by\n Nash (1950a).\n This, after all, is what makes equilibria self-enforcing, just in the\nway that prices in competitive markets are, and thus renders them\nstable unless shocked from outside.\n Nash (1953)\n argued that solutions to cooperative games should always be verified\nby showing that they are also solutions to formally equivalent\nnoncooperative games. Nash\u2019s accomplishment in the paper wa the\nanalytical identification of the relevant equivalence. One way of\ninterpreting this was as demonstrating the ultimate redundancy of\ncooperative game theory. \n\nCooperative game theory begins from the assumption that players have\nalready, by some unspecified process, agreed on a vector of\nstrategies, and thus on an outcome. Then the analyst deploys the\ntheory to determine the minimal set of conditions under which the\nagreement remains stable. The idea is typically illustrated by the\nexample of a parliamentary coalition. Suppose that there is one\ndominant party that must be a member of any coalition if it is to\ncommand a majority of parliamentary votes on legislation and\nconfidence. There might then be a range of alternative possible\ngroupings of other parties that could sustain it. Imagine, to make the\nexample more structured and interesting, that some parties will not\nserve in a coalition that includes certain specific others; so the\nproblem faced by the coalition organizers is not simply a matter of\nsumming potential votes. The cooperative game theorist identifies the\nset of possible coalitions. There may be some other parties, in\naddition to the dominant party, that turn out to be needed in every\npossible coalition. Identifying these parties would, in this example,\nreveal the core of the game, the elements shared by all\nequilibria. The core is the key solution concept of cooperative game\ntheory, for which Shapley shared the Nobel prize.\n (Shapley (1953)\n is the great paper.)\n Nash (1953)\n defined the \u201cNash program\u201d as consisting of verifying a\nparticular cooperative equilibrium by showing that noncooperative\nplayers could arrive at it through the sequential bargaining\nprocess specified in\n Nash (1950b),\n and that all outcomes of such bargaining would include the\ncore.\n\nIn light of the example, it is no surprise that political scientists\nwere the primary users of cooperative theory during the years while\nnoncooperative game theory was still being fully developed. It has\nalso been applied usefully by labor economists studying settlement\nnegotiations between firms and unions, and by analysts of\ninternational trade negotiations. We might illustrate the value of\nsuch application by reference to the second example. Suppose that,\ngiven the weight of domestic lobbies in South Africa, the South\nAfrican government will never agree to any trade agreement that does\nnot allow it to protect its automative assembly sector. (This has in\nfact been the case so far.) Then allowance for such protection is part\nof the core of any trade treaty another country or bloc might conclude\nwith South Africa. Knowing this can help the parties during\nnegotiations avoid rhetoric or commitments to other lobbies, in any of\nthe negotiating countries, that would put the core out of reach and\nthus guarantee negotiation failure. This example also helps us\nillustrate the limitations of cooperative game theory. South Africa\nwill have to trade off the interests of some other lobbies to protect\nits automative industry. Which others will get traded off\nwill be a function of the extensive-form play of non-cooperative\nsequential proposals and counter-proposals, and the South African\nbargainers, if they have done their due diligence, must be attentive\nto which paths through the tree throw which specific domestic\ninterests under the proverbial bus. Thus carrying out the cooperative\nanalysis does not relieve them of the need to also conduct the\nnoncooperative analysis. Their game theory consultants might as well\nsimply code the non-cooperative parameters into their Gambit software,\nwhich will output the core if asked.\n\nBut cooperative game theory did not die, or become confined to\npolitical science applications. There has turned out to be a range of\npolicy problems, involving many players whose attributes vary but\nwhose ordinal utility functions are symmetrical, for which\nnoncooperative modeling, while possible in principle, is absurdly\ncumbersome and computationally demanding, but for which cooperative\nmodeling is beautifully suited. That we be dealing with ordinal\nutility functions is important, because in the relevant markets there\nare often no prices. The classic example\n (Gale and Shapley 1962)\n is a marriage market. Abstracting from the scale of individual\nromantic dramas and comedies, society features, as it were, a vast set\nof people who want to form into pairs, but care very much who they end\nup paired with. Suppose we have a finite set of such people. Imagine\nthat the match-maker, or app, first splits the set into two proper\nsubsets, and announces a rule that everyone in subset \\(A\\) will\npropose to someone in subset \\(B\\). Each of those in \\(B\\) who receive\na proposal knows that she is the first choice of someone in \\(A\\). She\nselects her first choice from the proposals she has received and\nthrows the rest back into the pool. Those in \\(A\\) whose initial\nproposals were not accepted now each propose to someone they did not\npropose to before, but possibly including people who are holding\nproposals from a previous round\u2014Nkosi knows that Barbara\npreferred Amalia in round 1, but Nkosi wasn\u2019t part of that\nchoice set and so might displace Amalia in round 2). Provably there\nexists a terminal round after which no further proposals will be made,\nand the matchmaking app will have found the core of the cooperative\ngame because no person \\(i\\) in set \\(B\\) will prefer to pair with\nsomeone from set \\(A\\) who prefers \\(i\\) to whoever is holding that\n\\(A\\)-set dreamboat\u2019s proposal. Everyone from set B will now\naccept the proposal they are holding, and, if the two sets had the\nsame cardinality and everyone would rather pair with someone than pair\nwith no one, then nobody will go off alone.\n\nThis is not a directly applicable model of a marriage market, so there\nis no money to be made in selling the simple matchmaking app described\nabove. The problem is that we have no guarantee that, in the example,\nNkosi and Amalia aren\u2019t one another\u2019s partners of destiny,\nbut cannot get paired because they both began in subset \\(A\\). In game\ntheory textbooks this problem is often finessed by assuming that Set\n\\(A\\) contains men and Set \\(B\\) contains women, and that everyone is\nso committed to heterosexuality that they\u2019d rather pair with\nanyone of the opposite sex than anyone of their own sex. On the other\nhand, the model provides some insight, in the way that models\ntypically do, if we don\u2019t insist on applying it too literally.\nAfter working through it, one sees the logic of facts about society\nthat someone designing a real matchmaking app had better understand:\nthat the app will have to log proposals under consideration but not\nyet accepted, leave people holding proposals under consideration on\nthe market, and remember who has previously rejected whom (without\ncreating a generalised emotional catastrophe by publicly posting this\ninformation). The real app will not be able to reliably find the core\nof the cooperative game, unless the set of people in the market is\nsmall, restricted, and has self-sorted into subsets to at least some\nextent by providing such information as \u201c\\(X\\)-type person seeks\n\\(Y\\)-type person\u201d for \\(X\\) and \\(Y\\) properties that everyone\nprioritizes. (Are there such properties, at least as an\napproximation?) But the real matchmaking apps seem to work well enough\nto be transforming the way in which most young people now find mates\nin countries with generally available internet access. Relationships\nbetween theoretically idealized and real marriage markets are\ncomprehensively reviewed in\n Chiappori (2017).\n \n\nThe revival of cooperative game theory as site of renewed interest has\noccurred because policy problems have been encountered that, unlike\nthe original toy illustration using the all-straights marriage market,\nsatisfy the model\u2019s crucial assumptions. Leading instances are\nmatching university applicants and universities, and matching people\nneeding organ transplants with donors (see\n Roth 2015).\n In these markets, there is no ambivalence about partitioning the sets\nto be matched. Ordinal preferences are the relevant ones: universities\ndon\u2019t auction off places to the highest bidder (or at least not\nin general), and organs are not for sale (or at least not legally).\nThe models are really applied, and they demonstrably have improved\nefficiency and saved lives.\n\nIt is common in science for models that are practically clumsy fits to\ntheir original problems to turn out to furnish highly efficient\nsolutions to new problems thrown up by technological change. The\ninternet has created an environment for applications of matching\nalgorithms\u2014travellers and flat renters, diners and restaurants,\nstudents and tutors, and (regrettably) socially alienated people and\npurveyors of propaganda and fanaticism\u2014that could have been\ndesigned by a theorist at any time since Shapley\u2019s original\ninnovations, but would previously have been practically impossible to\nimplement. These applications of cooperative game theory are often\napplied conjointly with the noncooperative game theory of auctions\n (Klemperer 2004)\n to drive market designs for goods and services so efficient as to be\nannihilating the once mighty shopping mall in even the suburban USA.\nWhy are hotels more profitable and easily available than was the case\nin all but the largest cities before about 2007? The answer is that\ndynamic pricing algorithms\n (Gershkov and Moldovanu 2014)\n blend matching theory and auction theory to allow hotels, combined\nwith online travel service aggregators, to find customers willing to\npay premium rates for their ideal locations and times, and then fill\nthe remaining rooms with bargain hunters whose preferences are more\nflexible. Airlines operate similar technology. Game theory thus\ncontinues to be one of the 20th-century inventions that is driving\nsocial revolutions in the 21st, and\n Samuelson (2016)\n predicts a coming surge of renewed interest in the deeper mathematics\nof cooperative games and their relationships to noncooperative games.\n\n\nA range of further applications of both classical and evolutionary\ngame theory have been developed, but we have hopefully now provided\nenough to convince the reader of the tremendous, and constantly\nexpanding, utility of this analytical tool. The reader whose appetite\nfor more has been aroused should find that she now has sufficient\ngrasp of fundamentals to be able to work through the large literature,\nof which some highlights are listed below.\n",
    "bibliography": {
        "categories": [
            "Annotations on General Sources",
            "References"
        ],
        "cat_ref_text": {
            "Annotations on General Sources": "</h3>\n<p>\nIn the following section, books and articles which no one seriously\ninterested in game theory can afford to miss are marked with (**).\n</p>\n<p>\nThe most accessible textbook that covers all of the main branches of\ngame theory is\n <a href=\"#Dix14\">Dixit, Skeath and Reiley (2014)</a>.\n A student entirely new to the field should work through this before\nmoving on to anything else.</p>\n<p>\nGame theory has countless applications, of which this article has been\nable to suggest only a few. Readers in search of more, but not wishing\nto immerse themselves in mathematics, can find a number of good\nsources.\n <a href=\"#Dix91\">Dixit and Nalebuff (1991)</a>\n and\n <a href=\"#Dix08\">(2008)</a>\n are especially strong on political and social examples.\n <a href=\"#McM91\">McMillan (1991)</a>\n emphasizes business applications. </p>\n<p>\nThe great historical breakthrough that officially launched game theory\nis\n <a href=\"#Neu44\">von Neumann and Morgenstern (1944)</a>,\n which those with scholarly interest in game theory should read with\nclassic papers of\n <a href=\"#Nas50a\">John Nash (1950a, 1950b, 1951)</a>.\n A very useful collection of key foundational papers, all classics, is\n <a href=\"#Kuhn97\">Kuhn (1997)</a>.\n For a contemporary mathematical treatment that is unusually\nphilosophically sophisticated,\n <a href=\"#Bin05b\">Binmore (2005c)</a>\n (**) is in a class by itself. The second half of\n <a href=\"#Kre90\">Kreps (1990)</a>\n (**) is the best available starting point for a tour of the\nphilosophical worries surrounding equilibrium selection for\nnormativists.\n <a href=\"#Koo92\">Koons (1992)</a>\n takes these issues further.\n <a href=\"#Fud91\">Fudenberg and Tirole (1991)</a>\n remains the most thorough and complete mathematical text available.\n <a href=\"#Gin09b\">Gintis (2009b)</a>\n (**) provides a text crammed with terrific problem exercises, which\nis also unique in that it treats evolutionary game theory as providing\nthe foundational basis for game theory in general. Recent developments\nin fundamental theory are well represented in\n <a href=\"#Bin93\">Binmore, Kirman and Tani (1993)</a>.\n Anyone who wants to apply game theory to real human choices, which\nare generally related stochastically rather than deterministically to\naxioms of optimization, needs to understand quantal response theory\n(QRE) as a solution concept. The original development of this is found\nin\n <a href=\"#McK95\">McKelvey and Palfrey (1995)</a>\n and\n <a href=\"#McK98\">McKelvey and Palfrey (1998)</a>.\n <a href=\"#Goe16\">Goeree, Holt, and Palfrey (2016)</a> provide a comprehensive and up-to-date review of QRE and\nits leading applications.</p>\n<p>\nThe philosophical foundations of the basic game-theoretic concepts as\neconomists understand them are presented in\n <a href=\"#LaC94\">LaCasse and Ross (1994)</a>.\n <a href=\"#Ros95\">Ross and LaCasse (1995)</a> outline the relationships between games and the\naxiomatic assumptions of microeconomics and macroeconomics.\nPhilosophical puzzles at this foundational level are critically\ndiscussed in\n <a href=\"#Bic93\">Bicchieri (1993)</a>.\n <a href=\"#Lew69\">Lewis (1969)</a> puts game-theoretic equilibrium concepts to wider\napplication in philosophy, though making some foundational assumptions\nthat economists generally do not share. His program is carried a good\ndeal further, and without the contested assumptions, by\n <a href=\"#Sky96\">Skyrms (1996)</a>\n (**) and\n <a href=\"#Sky04\">(2004)</a>.\n (See also\n <a href=\"#Noz98\">Nozick [1998]</a>.)\n <a href=\"#Gau86\">Gauthier (1986)</a> launches a literature not surveyed in this article, in\nwhich the possibility of game-theoretic foundations for contractarian\nethics is investigated. This work is critically surveyed in\n <a href=\"#Val91\">Vallentyne (1991)</a>,\n and extended into a dynamic setting in\n <a href=\"#Dan92\">Danielson (1992)</a>.\n <a href=\"#Bin94\">Binmore (1994, 1998)</a> (**), however, sharply criticizes this project as\ninconsistent with natural psychology. Philosophers will also find\n <a href=\"#Hol98\">Hollis (1998)</a>\n to be of interest.</p>\n<p>\nIn a class by themselves for insight, originality, readability and\ncross-disciplinary importance are the works of the Nobel laureate\nThomas Schelling. He is the fountainhead of the huge literature that\napplies game theory to social and political issues of immediate\nrelevance, and shows how lightly it is possible to wear one\u2019s\nmathematics if the logic is sufficiently sure-footed. There are four\nvolumes, all essential:\n <a href=\"#Sch60\">Schelling (1960)</a>\n (**),\n <a href=\"#Sch78\">Schelling (1978 / 2006)</a>\n (**),\n <a href=\"#Sch84\">Schelling (1984)</a>\n (**),\n <a href=\"#Sch06\">Schelling (2006)</a>\n (**).</p>\n<p>\n<a href=\"#Har95\">Hardin (1995)</a>\n is one of many examples of the application of game theory to problems\nin applied political theory.\n <a href=\"#Bai94\">Baird, Gertner and Picker (1994)</a>\n review uses of game theory in legal theory and jurisprudence.\n <a href=\"#Mue97\">Mueller (1997)</a>\n surveys applications in public choice.\n <a href=\"#Ghe97\">Ghemawat (1997)</a>\n provides case studies intended to serve as a methodological template\nfor practical application of game theory to business strategy\nproblems.\n <a href=\"#Pou92\">Poundstone (1992)</a>\n provides a lively history of the Prisoner\u2019s Dilemma and its use\nby Cold War strategists.\n <a href=\"#Ama16\">Amadae (2016)</a>\n tells the same story, based on original scholarly sleuthing, with\nless complacency concerning its implications. The memoir of\n <a href=\"#Ell17\">Ellsberg (2017)</a>\n largely confirms Amadae\u2019s perspective.\n <a href=\"#Dur01\">Durlauf and Young (2001)</a>\n is a useful collection on applications to social structures and\nsocial change.</p>\n<p>\nEvolutionary game theory owes its explicit genesis to\n <a href=\"#May82\">Maynard Smith (1982)</a>\n (**). For a text that integrates game theory directly with biology,\nsee\n <a href=\"#Hof98\">Hofbauer and Sigmund (1998)</a>\n (**).\n <a href=\"#Sig93\">Sigmund (1993)</a>\n presents this material in a less technical and more accessible\nformat. Some exciting applications of evolutionary game theory to a\nrange of philosophical issues, on which this article has drawn\nheavily, is\n <a href=\"#Sky96\">Skyrms (1996)</a>\n (**). These issues and others are critically discussed from various\nangles in\n <a href=\"#Dan98\">Danielson (1998)</a>.\n Mathematical foundations for evolutionary games are presented in\n <a href=\"#Wei95\">Weibull (1995)</a>,\n and pursued further in\n <a href=\"#Sam97\">Samuelson (1997)</a>.\n These foundations are examined with special attention to issues for\nphilosophers by\n <a href=\"#Alex23\">Alexander (2023)</a>.\n As noted above,\n <a href=\"#Gin09b\">Gintis (2009b)</a>\n (**) now provides an introductory textbook that takes evolutionary\nmodeling to be foundational to all of game theory.\n <a href=\"#Young98\">H.P. Young (1998)</a>\n gives sophisticated models of the evolutionary dynamics of cultural\nnorms through the game-theoretic interactions of agents with limited\ncognitive capacities but dispositions to imitate one another.\n <a href=\"#Fud98\">Fudenberg and Levine (1998)</a>\n gives the technical foundations for modeling of this kind.</p>\n<p>\nMany philosophers will also be interested in Binmore\n (<a href=\"#Bin94\">1994</a>\n<a href=\"#Bin98\">1998</a>,\n <a href=\"#Bin05a\">2005a</a>)\n (**), which shows that application of game-theoretic analysis can\nunderwrite a Rawlsian conception of justice that does not require\nrecourse to Kantian presuppositions about what rational agents would\ndesire behind a veil of ignorance concerning their identities and\nsocial roles. (In addition, Binmore offers excursions into a range of\nother issues both central and peripheral to both the foundations and\nthe frontiers of game theory; these books are particularly rich on\nproblems that interest philosophers.) Almost everyone will be\ninterested in\n <a href=\"#Fra88\">Frank (1988)</a>\n (**), where evolutionary game theory is used to illuminate basic\nfeatures of human nature and emotion; though readers of this can find\ncriticism of Frank\u2019s model in\n <a href=\"#Ross04\">Ross and Dumouchel (2004)</a>.\n <a href=\"#Ocon19\">O\u2019Connor (2019)</a> uses evolutionary game theory to understand the deep\nroots and persistence of human inequality, particularly between the\nsexes. Her book is an exemplary instance of the essential value of\ngame theory to core questions in general social science and social\nphilosophy.</p>\n<p>\nBehavioral and experimental applications of game theory are surveyed\nin\n <a href=\"#Kag95\">Kagel and Roth (1995)</a>.\n <a href=\"#Cam03\">Camerer (2003)</a> (**) is a comprehensive and more recent study of this\nliterature, and cannot be missed by anyone interested in these issues.\nA shorter survey that emphasizes philosophical and methodological\ncriticism is\n <a href=\"#Sam05\">Samuelson (2005)</a>.\n Philosophical foundations are also carefully examined in\n <a href=\"#Gua05\">Guala (2005)</a>.</p>\n<p>\nTwo volumes from leading theorists that offer comprehensive views on\nthe philosophical foundations of game theory were published in 2009.\nThese are\n <a href=\"#Bin09\">Binmore (2009)</a>\n (**) and\n <a href=\"#Gin09a\">Gintis (2009a)</a>\n (**). Both are indispensable to philosophers who aim to participate\nin critical discussions of foundational issues.</p>\n<p>\nA volume of interviews with nineteen leading game theorists, eliciting\ntheir views on motivations and foundational topics, is\n <a href=\"#Hen07\">Hendricks and Hansen (2007)</a>.</p>\n<p>\nGame-theoretic dynamics of the sub-person receive deep but accessible\nreflection in\n <a href=\"#Ain01\">Ainslie (2001)</a>.\n Seminal texts in neuroeconomics, with extensive use of and\nimplications for behavioral game theory, are\n <a href=\"#Mon02\">Montague and Berns (2002)</a>,\n <a href=\"#Gli03\">Glimcher 2003</a> (**), and\n <a href=\"#Cam05\">Camerer, Loewenstein and Prelec (2005)</a>.\n <a href=\"#Ross05a\">Ross (2005a)</a> studies the game-theoretic foundations of microeconomics\nin general, but especially behavioral economics and neuroeconomics,\nfrom the perspective of cognitive science and in close alignment with\nAinslie.</p>\n<p>\nThe theory of cooperative games is consolidated in\n <a href=\"#Cha15\">Chakravarty, Mitra and Sarkar (2015)</a>.\n An accessible and non-technical review of applications of matching\ntheory, by the economist whose work on it earned a Nobel Prize, is\n <a href=\"#Rot15\">Roth (2015)</a>.</p>\n<h3>",
            "References": [
                "</h3>\n<ul class=\"hanging\">",
                "<a name=\"Ain92\">Ainslie, G. (1992)</a>.\n <em>Picoeconomics</em>, Cambridge: Cambridge University Press.",
                "<a name=\"Ain01\">\u2013\u2013\u2013 (2001)</a>.\n <em>Breakdown of Will</em>, Cambridge: Cambridge University\nPress.",
                "<a name=\"Alex23\">Alexander, J.M. (2023)</a>.\n <em>Evolutionary Game Theory</em>, Cambridge: Cambridge University\nPress.",
                "<a name=\"Ama16\">Amadae, S. (2016)</a>.\n <em>Prisoners of Reason</em>, Cambridge: Cambridge University\nPress.",
                "<a name=\"And08\">Andersen, S., Harrison, G., Lau, M., and Rutstrom, E. (2008)</a>.\n Eliciting risk and time preferences. <em>Econometrica</em>, 76:\n583\u2013618.",
                "<a name=\"And14\">\u2013\u2013\u2013 (2014)</a>.\n Dual criteria decisions. <em>Journal of Economic Psychology</em>,\nforthcoming.",
                "<a name=\"Aum74\">Aumann, R. (1974)</a>.\n Subjectivity and Correlation in Randomized Strategies. <em>Journal of\nMathematical Economics</em>, 1: 67\u201396.",
                "<a name=\"Aum87\">\u2013\u2013\u2013 (1987)</a>.\n Correlated Equilibrium as an Expression of Bayesian Rationality.\n<em>Econometrica</em>, 55: 1\u201318.",
                "<a name=\"Bac06\">Bacharach, M. (2006)</a>.\n <em>Beyond Individual Choice: Teams and Frames in Game Theory</em>,\nPrinceton: Princeton University Press.",
                "<a name=\"Bai94\">Baird, D., Gertner, R., and Picker, R. (1994)</a>.\n <em>Game Theory and the Law</em>, Cambridge, MA: Harvard University\nPress.",
                "<a name=\"Bell91\">Bell, W., (1991)</a>.\n <em>Searching Behaviour</em>, London: Chapman and Hall.",
                "<a name=\"Bic93\">Bicchieri, C. (1993)</a>.\n <em>Rationality and Coordination</em>, Cambridge: Cambridge\nUniversity Press.",
                "<a name=\"Bic06\">\u2013\u2013\u2013 (2006)</a>.\n <em>The Grammar of Society</em>, Cambridge: Cambridge University\nPress.",
                "<a name=\"Bic17\">\u2013\u2013\u2013 (2017)</a>.\n <em>Norms in the Wild</em>. Oxford: Oxford University Press.",
                "<a name=\"Bic08\">Bickhard, M. (2008)</a>.\n Social Ontology as Convention. <em>Topoi</em>, 27:\n139\u2013149.",
                "<a name=\"Bin87\">Binmore, K. (1987)</a>.\n Modeling Rational Players I. <em>Economics and Philosophy</em>, 3:\n179\u2013214.",
                "<a name=\"Bin94\">\u2013\u2013\u2013 (1994)</a>.\n <em>Game Theory and the Social Contract</em> (v. 1): <em>Playing\nFair</em>, Cambridge, MA: MIT Press.",
                "<a name=\"Bin98\">\u2013\u2013\u2013 (1998).</a>\n<em>Game Theory and the Social Contract</em> (v. 2): <em>Just\nPlaying</em>, Cambridge, MA: MIT Press.",
                "<a name=\"Bin05a\">\u2013\u2013\u2013 (2005a)</a>.\n <em>Natural Justice</em>, Oxford: Oxford University Press.",
                "<a name=\"Bin05b\">\u2013\u2013\u2013 (2005b)</a>.\n Economic Man\u2014or Straw Man? <em>Behavioral and Brain\nSciences</em> 28: 817\u2013818.",
                "<a name=\"Bin05c\">\u2013\u2013\u2013 (2005c)</a>.\n <em>Playing For Real</em>, Oxford: Oxford University Press.",
                "<a name=\"Bin07\">\u2013\u2013\u2013 (2007)</a>.\n <em>Does Game Theory Work? The Bargaining Challenge</em>, Cambridge,\nMA: MIT Press.",
                "<a name=\"Bin08\">\u2013\u2013\u2013 (2008)</a>.\n Do Conventions Need to be Common Knowledge? <em>Topoi</em> 27:\n17\u201327.",
                "<a name=\"Bin09\">\u2013\u2013\u2013 (2009)</a>.\n <em>Rational Decisions</em>, Princeton: Princeton University\nPress.",
                "<a name=\"Bin93\">Binmore, K., Kirman, A., and Tani, P. (eds.) (1993)</a>.\n <em>Frontiers of Game Theory</em>, Cambridge, MA: MIT Press",
                "<a name=\"Bin02\">Binmore, K., and Klemperer, P. (2002)</a>.\n The Biggest Auction Ever: The Sale of British 3G Telcom Licenses.\n<em>Economic Journal</em>, 112: C74\u2013C96.",
                "<a name=\"Bis09\">Bishop, B.(2009)</a>.\n <em>The Big Sort</em>. New York: Mariner.",
                "<a name=\"Boy85\">Boyd, R., and Richerson, P. (1985)</a>.\n <em>Culture and the Evolutionary Process</em>, Chicago: University of\nChicago Press.",
                "<a name=\"Cam95\">Camerer, C. (1995)</a>.\n Individual Decision Making. In J. Kagel and A. Roth, eds.,\n<em>Handbook of Experimental Economics</em>, 587\u2013703. Princeton:\nPrinceton University Press.",
                "<a name=\"Cam03\">\u2013\u2013\u2013 (2003)</a>.\n <em>Behavioral Game Theory: Experiments in Strategic\nInteraction</em>, Princeton: Princeton University Press.",
                "<a name=\"Cam05\">Camerer, C., Loewenstein, G., and Prelec, D. (2005)</a>.\n Neuroeconomics: How Neuroscience Can Inform Economics. <em>Journal of\nEconomic Literature</em>, 40: 9\u201364.",
                "<a name=\"Cha15\">Chakravarty, S., Mitra, M., and Sarkar, P. (2015)</a>.\n <em>A Course on Cooperative Game Theory</em>, Cambridge: Cambridge\nUniversity Press.",
                "<a name=\"Chew79\">Chew, S., and MacCrimmon, K. (1979)</a>.\n Alpha-nu Choice Theory: A Generalization of Expected Utility Theory.\nWorking Paper No. 686, University of Columbia Faculty of Commerce and\nBusiness Administration.",
                "<a name=\"Chi17\">Chiappori, P.-A. (2017)</a>.\n <em>Matching With Transfers: The Economics of Love and Marriage</em>,\nPrinceton: Princeton University Press.",
                "<a name=\"Cla97\">Clark, A. (1997)</a>.\n <em>Being There</em>, Cambridge, MA: MIT Press.",
                "<a name=\"Cla16\">\u2013\u2013\u2013 (2016)</a>.<em>\n Surfing Uncertainty</em>, Cambridge, MA: MIT Press.",
                "<a name=\"Dan92\">Danielson, P. (1992)</a>.\n <em>Artificial Morality</em>, London: Routledge",
                "<a name=\"Dan98\">\u2013\u2013\u2013 (ed.) (1998)</a>.\n <em>Modelling Rationality, Morality and Evolution</em>, Oxford:\nOxford University Press.",
                "<a name=\"Den87\">Dennett, D. (1987)</a>.\n <em>The Intentional Stance</em>, Cambridge, MA: MIT Press.",
                "<a name=\"Den95\">\u2013\u2013\u2013 (1995)</a>.\n <em>Darwin\u2019s Dangerous Idea</em>, New York: Simon and\nSchuster.",
                "<a name=\"Dix91\">Dixit, A., and Nalebuff, B. (1991)</a>.\n <em>Thinking Strategically</em>, New York: Norton.",
                "<a name=\"Dix08\">\u2013\u2013\u2013 (2008)</a>.\n <em>The Art of Strategy</em>, New York: Norton.",
                "<a name=\"Dix14\">Dixit, A., Skeath, S., and Reiley, D. (2014)</a>.\n <em>Games of Strategy</em>, fourth edition. New York: W. W. Norton\nand Company.",
                "<a name=\"Dug98\">Dugatkin, L., and Reeve, H., eds. (1998)</a>.\n <em>Game Theory and Animal Behavior</em>, Oxford: Oxford University\nPress.",
                "<a name=\"Duk98\">Dukas, R., ed. (1998)</a>.\n <em>Cognitive Ecology.</em>, Chicago: University of Chicago\nPress.",
                "<a name=\"Dur01\">Durlauf, S., and Young, H.P., eds. (2001)</a>.\n <em>Social Dynamics</em>, Cambridge, MA: MIT Press.",
                "<a name=\"Ell17\">Ellsberg, D. (2017)</a>.\n <em>The Doomsday Machine</em>, New York: Bloomsbury.",
                "<a name=\"Eri15\">Erickson, P. (2015)</a>.\n <em>The World the Game Theorists Made</em>, Chicago: University of\nChicago Press.",
                "<a name=\"Fra88\">Frank, R. (1988)</a>.\n <em>Passions Within Reason</em>, New York: Norton.",
                "<a name=\"Fud98\">Fudenberg, D., and Levine, D. (1998)</a>.\n <em>The Theory of Learning in Games</em>, Cambridge, MA: MIT\nPress.",
                "<a name=\"Fud08\">\u2013\u2013\u2013 (2008)</a>.\n <em>A Long-Run Collaboration on Long-Run Games</em>. Singapore: World\nScientific.",
                "<a name=\"Fud16\">\u2013\u2013\u2013 (2016)</a>.\n Whither Game Theory? Towards a Theory of Learning in Games.\n<em>Journal of Economic Perspectives</em>, 30(4): 151\u2013170",
                "<a name=\"Fud91\">Fudenberg, D., and Tirole, J. (1991)</a>.\n <em>Game Theory</em>, Cambridge, MA: MIT Press.",
                "<a name=\"Gal62\">Gale, D., and Shapley, L. (1962)</a>.\n College Admissions and the Stability of Marriage. <em>American\nMathematical Monthly</em>, 69 :9\u201315.",
                "<a name=\"Gau86\">Gauthier, D. (1986)</a>.\n <em>Morals By Agreement</em>, Oxford: Oxford University Press.",
                "<a name=\"Ger14\">Gershkov, A., and Moldovanu, B. (2014)</a>.\n <em>Dynamic Allocation and Pricing: A Mechanism Design Approach</em>,\nCambridge, MA: MIT Press.",
                "<a name=\"Ghe97\">Ghemawat, P. (1997)</a>.\n <em>Games Businesses Play</em>, Cambridge, MA: MIT Press.",
                "<a name=\"Gil89\">Gilbert, M. (1989)</a>.\n <em>On Social Facts</em>, Princeton: Princeton University Press.",
                "<a name=\"Gin04\">Gintis, G.(2004)</a>.\n Towards the Unity of the Human Behavioral Sciences. <em>Philosophy,\nPolitics and Economics</em>, 31: 37\u201357.",
                "<a name=\"Gin05\">\u2013\u2013\u2013 (2005)</a>.\n Behavioral Ethics Meets Natural Justice. <em>Politics, Philosophy and\nEconomics</em>, 5: 5\u201332.",
                "<a name=\"Gin09a\">\u2013\u2013\u2013 (2009a)</a>.\n <em>The Bounds of Reason</em>, Princeton: Princeton University\nPress.",
                "<a name=\"Gin09b\">\u2013\u2013\u2013 (2009b)</a>.\n <em>Game Theory Evolving.</em> Second edition. Princeton: Princeton\nUniversity Press.",
                "<a name=\"Gli03\">Glimcher, P. (2003)</a>.\n <em>Decisions, Uncertainty and the Brain</em>, Cambridge, MA: MIT\nPress.",
                "<a name=\"Gli07\">Glimcher, P., Kable, J., and Louie, K. (2007)</a>.\n Neuroeconomic Studies of Impulsivity: Now or Just as Soon as\nPossible? <em>American Economic Review (Papers and Proceedings)</em>,\n97: 142\u2013147.",
                "<a name=\"God96\">Godfrey-Smith, P. (1996)</a>.\n <em>Complexity and the Function of Mind in Nature</em>. Cambridge,\nUK: Cambridge University Press.",
                "<a name=\"Goe16\">Goeree, J., Holt, C., and Palfrey, T. (2016)</a>.\n <em>Quantal Response Equilibrium</em>, Princeton: Princeton\nUniversity Press.",
                "<a name=\"Gua05\">Guala, F. (2005)</a>.\n <em>The Methodology of Experimental Economics</em>, Cambridge:\nCambridge University Press.",
                "<a name=\"Gua16\">\u2013\u2013\u2013 (2016)</a>.\n <em>Understanding Institutions</em>, Princeton: Princeton University\nPress.",
                "<a name=\"Ham03\">Hammerstein, P. (2003)</a>.\n Why is Reciprocity so Rare in Social Animals? A Protestant Appeal. In\nP. Hammerstein, ed., <em>Genetic and Cultural Evolution of\nCooperation</em>, 83\u201393. Cambridge, MA: MIT Press.",
                "<a name=\"Ham86\">Hampton, J. (1986)</a>,\n <em>Hobbes and the Social Contract Tradition</em>. Cambridge:\nCambridge University Press.",
                "<a name=\"Har95\">Hardin, R. (1995)</a>.\n <em>One For All</em>, Princeton: Princeton University Press.",
                "<a name=\"Har08b\">Harrison, G.W. (2008)</a>.\n Neuroeconomics: A Critical Reconsideration. <em>Economics and\nPhilosophy</em> 24: 303\u2013344.",
                "<a name=\"Har08\">Harrison, G.W., and Rutstrom, E. (2008)</a>.\n Risk aversion in the laboratory. In <em>Risk Aversion in\nExperiments</em>, J. Cox and G. Harrison eds., Bingley, UK: Emerald,\n41\u2013196.",
                "<a name=\"Har10\">Harrison, G.W., and Ross, D. (2010)</a>.\n The Methodologies of Neuroeconomics. <em>Journal of Economic\nMethodology</em>, 17: 185\u2013196.",
                "<a name=\"Har16\">\u2013\u2013\u2013 (2016)</a>.\n The Psychology of Human Risk Preferences and Vulnerability to\nScare-mongers: Experimental Economic Tools for Hypothesis Formulation\nand Testing. <em>Journal of Cognition and Culture</em>, 16:\n383\u2013414.",
                "<a name=\"Har23\">\u2013\u2013\u2013 forthcoming</a>.\n Behavioral Welfare Economics and the Quantitative Intentional Stance.\nIn G.W. Harrison &amp; D. Ross, eds., <em>Models of Risk Preferences:\nDescriptive and Normative Challenges</em>. Bingley, UK: Emerald.",
                "<a name=\"Har67\">Harsanyi, J. (1967)</a>.\n Games With Incomplete Information Played by \u2018Bayesian\u2019\nPlayers, Parts I\u2013III. <em>Management Science</em> 14:\n159\u2013182.",
                "<a name=\"Har77\">\u2013\u2013\u2013 (1977)</a>.\n <em>Rational Behavior and Bargaining Equilibrium in Games and Social\nSituations</em>, Cambridge: Cambridge University Press.",
                "<a name=\"Hen04\">Henrich, J., Boyd, R., Bowles, S., Camerer, C., Fehr, E., and Gintis, H., eds. (2004)</a>.\n <em>Foundations of Human Sociality: Economic Experiments and\nEthnographic Evidence From 15 Small-Scale Societies</em>, Oxford:\nOxford University Press.",
                "<a name=\"Hen05\">Henrich, J.</a>,\n Boyd, R., Bowles, S., Camerer, C., Fehr, E., Gintis, H., McElreath,\nR., Alvard, M., Barr, A., Ensminger, J., Henrich, N., Hill, K.,\nGil-White, F., Gurven, M., Marlowe, F., Patton, J., and Tracer, D.\n(2005). \u2018Economic Man\u2019 in Cross-Cultural Perspective.\n<em>Behavioral and Brain Sciences</em>, 28: 795\u2013815.",
                "<a name=\"Hen07\">Hendricks, V., and Hansen, P., eds. (2007)</a>.\n <em>Game Theory: 5 Questions</em>, Copenhagen: Automatic Press.",
                "<a name=\"Hof98\">Hofbauer, J., and Sigmund, K. (1998)</a>.\n <em>Evolutionary Games and Population Dynamics</em>, Cambridge:\nCambridge University Press.",
                "<a name=\"Hof19\">Hofmeyr, A., and Ross, D. (2019)</a>.\n Team Agency and Conditional Games. In M. Nagatsu, ed., <em>Philosophy\nand Social Science: An Interdisciplinary Dialogue</em>, London:\nBloomsbury, 67\u201392.",
                "<a name=\"Hol98\">Hollis, M. (1998)</a>.\n <em>Trust Within Reason</em>, Cambridge: Cambridge University\nPress.",
                "<a name=\"Hol93\">Hollis, M., and Sugden, R. (1993)</a>.\n Rationality in Action. <em>Mind</em>, 102: 1\u201335.",
                "<a name=\"Hur06\">Hurwicz, L., and Reiter, S. (2006)</a>.\n <em>Designing Economic Mechanisms</em>, Cambridge: Cambridge\nUniversity Press.",
                "<a name=\"Hut08\">Hutto, D. (2008)</a>.\n <em>Folk Psychological Narratives</em>, Cambridge, MA: MIT\nPress.",
                "<a name=\"Kag95\">Kagel, J., and Roth, A., eds. (1995)</a>.\n <em>Handbook of Experimental Economics</em>, Princeton: Princeton\nUniversity Press.",
                "<a name=\"Kee76\">Keeney, R., and Raiffa, H. (1976)</a>.\n <em>Decisions With Multiple Objectives</em>, New York: Wiley.",
                "<a name=\"Kin05\">King-Casas, B., Tomlin, D., Anen, C., Camerer, C., Quartz, S., and Montague, P.R. (2005)</a>.\n Getting to Know You: Reputation and Trust in a Two-Person Economic\nExchange. <em>Science</em>, 308: 78\u201383.",
                "<a name=\"Kle04\">Klemperer, P. (2004)</a>.\n <em>Auctions: Theory and Practice</em>, Princeton: Princeton\nUniversity Press.",
                "<a name=\"Koo92\">Koons, R. (1992)</a>.\n <em>Paradoxes of Belief and Strategic Rationality</em>, Cambridge:\nCambridge University Press.",
                "<a name=\"Krebs84\">Krebs, J., and Davies, N. (1984)</a>.\n <em>Behavioral Ecology: An Evolutionary Approach</em>, Second\nedition. Sunderland: Sinauer.",
                "<a name=\"Kre90\">Kreps, D. (1990)</a>.\n <em>A Course in Microeconomic Theory</em>, Princeton: Princeton\nUniversity Press.",
                "<a name=\"Kru14\">Kruschke, J. (2014)</a>.\n <em>Doing Bayesian Data Analysis</em>, 2nd Edition. Cambridge, MA:\nAcademic Press.",
                "<a name=\"Kuhn97\">Kuhn, H., ed., (1997)</a>.\n <em>Classics in Game Theory</em>, Princeton: Princeton University\nPress.",
                "<a name=\"Kur95\">Kuran, T. (1995)</a>.\n <em>Private Truths, Public Lies</em>. Cambridge, MA: Harvard\nUniversity Press.",
                "<a name=\"LaC94\">LaCasse, C., and Ross, D. (1994)</a>.\n \u2018The Microeconomic Interpretation of Games\u2019. <em>PSA\n1994, Volume 1</em>, D. Hull, S. Forbes and R. Burien (eds.), East\nLansing, MI: Philosophy of Science Association, pp.\n479\u2013387.",
                "<a name=\"Led95\">Ledyard, J. (1995)</a>.\n Public Goods: A Survey of Experimental Research. In J. Kagel and A.\nRoth, eds., <em>Handbook of Experimental Economics</em>, Princeton:\nPrinceton University Press.",
                "<a name=\"Lew69\">Lewis, D. (1969)</a>.\n <em>Convention</em>, Cambridge, MA: Harvard University Press.",
                "<a name=\"Lich06\">Lichtenstein, S., and Slovic, P., eds. (2006)</a>.\n <em>The Construction of Preference</em>, Cambridge, UK: Cambridge\nUniversity Press.",
                "<a name=\"May82\">Maynard Smith, J. (1982)</a>.\n <em>Evolution and the Theory of Games</em>, Cambridge: Cambridge\nUniversity Press.",
                "<a name=\"McC04\">McClure, S., Laibson, D., Loewenstein, G., and Cohen, J. (2004)</a>.\n Separate Neural Systems Value Immediate and Delayed Monetary Rewards.\n<em>Science</em>, 306: 503\u2013507.",
                "<a name=\"McE20\">McElreath, R. (2020)</a>.\n <em>Statistical Rethinking</em>, 2nd Edition. London: Chapman &amp;\nHall.",
                "<a name=\"McGeer01\">McGeer, V. (2001)</a>.\n Psycho-practice, Psycho-theory, and the Contrastive Case of Autism:\nHow Processes of Mind Become Second Nature, <em>Journal of\nConsciousness Studies</em>, 8: 109\u2013132.",
                "<a name=\"McGeer02\">\u2013\u2013\u2013(2002).</a>\n Enculturating Folk-Psychologists, <em>Synthese</em>, 199:\n1039\u20131063.",
                "<a name=\"McK95\">McKelvey, R., and Palfrey, T. (1995)</a>.\n Quantal Response Equilibria for Normal Form Games. <em>Games and\nEconomic Behavior</em> 10: 6\u201338.",
                "<a name=\"McK98\">\u2013\u2013\u2013 (1998)</a>.\n Quantal Response Equilibria for Extensive Form Games.\n<em>Experimental Economics</em> 1: 9\u201341.",
                "<a name=\"McM91\">McMillan, J. (1991)</a>.\n <em>Games, Strategies and Managers</em>, Oxford: Oxford University\nPress.",
                "<a name=\"Mil84\">Millikan, R. (1984)</a>.\n <em>Language, Thought and Other Biological Categories</em>,\nCambridge, MA: MIT Press.",
                "<a name=\"Mon02\">Montague,P. R., and Berns, G. (2002)</a>.\n Neural Economics and the Biological Substrates of Valuation.\n<em>Neuron</em>, 36: 265\u2013284.",
                "<a name=\"Mue97\">Mueller, D. (1997)</a>.\n <em>Perspectives on Public Choice</em>, Cambridge: Cambridge\nUniversity Press.",
                "<a name=\"Nas50a\">Nash, J. (1950a)</a>.\n \u2018Equilibrium Points in \\(n\\)-Person Games.\u2019\n<em>Proceedings of the National Academy of Science</em>, 36:\n48\u201349.",
                "<a name=\"Nas50b\">\u2013\u2013\u2013 (1950b)</a>.\n \u2018The Bargaining Problem.\u2019 <em>Econometrica</em>, 18:\n155\u2013162.",
                "<a name=\"Nas51\">\u2013\u2013\u2013 (1951)</a>.\n \u2018Non-cooperative Games.\u2019 <em>Annals of Mathematics\nJournal</em>, 54: 286\u2013295.",
                "<a name=\"Nas53\">\u2013\u2013\u2013 (1953)</a>.\n Two-Person Cooperative Games. <em>Econometrica</em>, 21:\n128\u2013140.",
                "<a name=\"Nic03\">Nichols, S., and Stich, S. (2003).</a>\n<em>Mindreading</em>, Oxford: Oxford University Press.",
                "<a name=\"Noe01\">Noe, R., van Hoof, J., and Hammerstein, P., eds. (2001)</a>.\n <em>Economics in Nature</em>, Cambridge: Cambridge University\nPress.",
                "<a name=\"Noz98\">Nozick, R. (1998)</a>.\n <em>Socratic Puzzles</em>, Cambridge, MA: Harvard University\nPress.",
                "<a name=\"Ocon19\">O\u2019Connor, C. (2019)</a>.\n <em>The Origins of Unfairness</em>, Oxford: Oxford University\nPress.",
                "<a name=\"Ofek01\">Ofek, H. (2001)</a>.\n <em>Second Nature</em>. Cambridge: Cambridge University Press.",
                "<a name=\"Orm94\">Ormerod, P. (1994)</a>.\n <em>The Death of Economics</em>, New York: Wiley.",
                "<a name=\"Par22\">Parr, T., Pezzulo, G., &amp; Friston, K. (2022)</a>.\n <em>Active Inference</em>. Cambridge, MA: MIT Press.",
                "<a name=\"Pet89\">Pettit, P., and Sugden, R. (1989)</a>.\n The Backward Induction Paradox. <em>Journal of Philosophy</em>, 86:\n169\u2013182.",
                "<a name=\"Plan21\">Planer, R., &amp; Sterelny, K. (2021)</a>.\n <em> From Signal to Symbol</em>. Cambridge, MA: MIT Press.",
                "<a name=\"Pla99\">Platt, M., and Glimcher, P. (1999)</a>.\n Neural Correlates of Decision Variables in Parietal Cortex.\n<em>Nature</em>, 400: 233\u2013238.",
                "<a name=\"Plott78\">Plott, C., and Smith, V. (1978)</a>.\n An Experimental Examination of Two Exchange Institutions. <em>Review\nof Economic Studies</em>, 45: 133\u2013153.",
                "<a name=\"Pou92\">Poundstone, W. (1992)</a>.\n <em>Prisoner\u2019s Dilemma</em>, New York: Doubleday.",
                "<a name=\"Pre98\">Prelec, D. (1998)</a>.\n The Probability Weighting Function. <em>Econometrica</em>, 66:\n497\u2013527.",
                "<a name=\"Qui82\">Quiggin,J. (1982)</a>.\n A Theory of Anticipated Utility. <em>Journal of Economic Behavior and\nOrganization</em>, 3: 323\u2013343.",
                "<a name=\"Raw71\">Rawls, J. (1971)</a>.\n <em>A Theory of Justice</em>, Cambridge, MA: Harvard University\nPress.",
                "<a name=\"Rob31\">Robbins, L. (1931)</a>.\n <em>An Essay on the Nature and Significance of Economic Science</em>,\nLondon: Macmillan.",
                "<a name=\"Ross05a\">Ross, D. (2005a)</a>.\n <em>Economic Theory and Cognitive Science: Microexplanation.</em>,\nCambridge, MA: MIT Press.",
                "<a name=\"Ross05b\">\u2013\u2013\u2013 (2006)</a>.\n Evolutionary Game Theory and the Normative Theory of Institutional\nDesign: Binmore and Behavioral Economics. <em>Politics, Philosophy and\nEconomics</em>, 5(1): 51\u201379.",
                "<a name=\"Ros08a\">\u2013\u2013\u2013 (2008a)</a>.\n Classical Game Theory, Socialization and the Rationalization of\nConventions. <em>Topoi</em>, 27: 57\u201372.",
                "<a name=\"Ros08b\">\u2013\u2013\u2013 (2008b)</a>.\n Two Styles of Neuroeconomics. <em>Economics and Philosophy</em> 24:\n473\u2013483.",
                "<a name=\"Ros14\">\u2013\u2013\u2013 (2014)</a>.\n <em>Philosophy of Economics</em>, Houndmills, Basingstoke: Palgrave\nMacmillan.",
                "<a name=\"Ross04\">Ross, D., and Dumouchel, P. (2004)</a>.\n Emotions as Strategic Signals. <em>Rationality and Society</em>, 16:\n251\u2013286.",
                "<a name=\"Ros95\">Ross, D., and LaCasse, C. (1995)</a>.\n \u2018Towards a New Philosophy of Positive Economics\u2019.\n<em>Dialogue</em>, 34: 467\u2013493.",
                "<a name=\"Ros21\">Ross, D., and Stirling, W. (2021)</a>.\n Economics, Social Neuroscience, and Mindshaping. In J. Harbeckeand C.\nHerrmann-Pillath, eds., <em>Social Neuroeconomics</em>, London:\nRoutledge, 174\u2013201.",
                "<a name=\"Ros23\">Ross, D., Stirling, W., and Tummolini, L. (2023)</a>.\n Strategic Theory of Norms for Empirical Applications in Political\nScience and Political Economy. In H. Kincaid and J. van Bouwel, eds.,\n<em>The Oxford Handbook of Philosophy of Political Science</em>,\nOxford: Oxford University Press, 86\u2013121.",
                "<a name=\"Rot15\">Roth, A. (2015)</a>.\n <em>Who Gets What and Why?</em>, New York: Houghton Mifflin\nHarcourt.",
                "<a name=\"Sal95\">Sally, J. (1995)</a>.\n Conversation and Cooperation in Social Dilemmas: A Meta-analysis of\nExperiments From 1958 to 1992. <em>Rationality and Society</em>, 7:\n58\u201392.",
                "<a name=\"Sam97\">Samuelson, L. (1997)</a>.\n <em>Evolutionary Games and Equilibrium Selection</em>, Cambridge, MA:\nMIT Press.",
                "<a name=\"Sam05\">\u2013\u2013\u2013 (2005)</a>.\n Economic Theory and Experimental Economics. <em>Journal of Economic\nLiterature</em>, 43: 65\u2013107.",
                "<a name=\"Sam16\">\u2013\u2013\u2013 (2016)</a>.\n Game Theory in Economics and Beyond. <em>Journal of Economic\nPerspectives</em>, 30(4): 107\u2013130.",
                "<a name=\"Sam38\">Samuelson, P. (1938)</a>.\n \u2018A Note on the Pure Theory of Consumers\u2019\nBehaviour.\u2019 <em>Economica</em>, 5: 61\u201371.",
                "<a name=\"Sav54\">Savage, L. (1954)</a>.\n <em>The Foundations of Statistics</em>, New York: Wiley.",
                "<a name=\"Sch60\">Schelling, T. (1960)</a>.\n Schelling, T (1960). <em>Strategy of Conflict</em>, Cambridge, MA:\nHarvard University Press.",
                "<a name=\"Sch78\">\u2013\u2013\u2013 (1978)</a>.\n <em>Micromotives and Macrobehavior</em>, New York: Norton. Second\nedition 2006.",
                "<a name=\"Sch80\">\u2013\u2013\u2013 (1980)</a>.\n The Intimate Contest for Self-Command. <em>Public Interest</em>, 60:\n94\u2013118.",
                "<a name=\"Sch84\">\u2013\u2013\u2013 (1984)</a>.\n <em>Choice and Consequence</em>, Cambridge, MA: Harvard University\nPress.",
                "<a name=\"Sch06\">\u2013\u2013\u2013 (2006)</a>.\n <em>Strategies of Commitment</em>, Cambridge, MA: Harvard University\nPress.",
                "<a name=\"Sel75\">Selten, R. (1975)</a>.\n \u2018Re-examination of the Perfectness Concept for Equilibrium\nPoints in Extensive Games.\u2019 <em>International Journal of Game\nTheory</em>, 4: 22\u201355.",
                "<a name=\"Sig93\">Sigmund, K. (1993)</a>.\n <em>Games of Life</em>, Oxford: Oxford University Press.",
                "<a name=\"Sha53\">Shapley, L. (1953)</a>.\n A Value of n-Person Games. In H, Kuhn and A. Tucker, eds.,\n<em>Contributions to the Theory of Games II</em>, 307\u2013317.\nPrinceton: Princeton University Press.",
                "<a name=\"Sky96\">Skyrms, B. (1996)</a>.\n <em>Evolution of the Social Contract</em>, Cambridge: Cambridge\nUniversity Press.",
                "<a name=\"Sky04\">\u2013\u2013\u2013 (2004)</a>.\n <em>The Stag Hunt and the Evolution of Social Structure</em>,\nCambridge: Cambridge University Press.",
                "<a name=\"Smi62\">Smith, V. (1962)</a>.\n An Experimental Study of Competitive Market Behavior. <em>Journal of\nPolitical Economy</em>, 70: 111\u2013137.",
                "<a name=\"Smi64\">\u2013\u2013\u2013 (1964)</a>.\n Effect of Market Organization on Competitive Equilibrium.\n<em>Quarterly Journal of Economics</em>, 78: 181\u2013201.",
                "<a name=\"Smi65\">\u2013\u2013\u2013 (1965)</a>.\n Experimental Auction Markets and the Walrasian Hypothesis.\n<em>Journal of Political Economy</em>, 73: 387\u2013393.",
                "<a name=\"Smi76\">\u2013\u2013\u2013 (1976)</a>.\n Bidding and Auctioning Institutions: Experimental Results. In Y.\nAmihud, ed., <em>Bidding and Auctioning for Procurement and\nAllocation</em>, 43\u201364. New York: New York University\nPress.",
                "<a name=\"Smi82\">\u2013\u2013\u2013 (1982)</a>.\n Microeconomic Systems as an Experimental Science. <em>American\nEconomic Review</em>, 72: 923\u2013955.",
                "<a name=\"Smi08\">\u2013\u2013\u2013 (2008)</a>.\n <em>Rationality in Economics</em>, Cambridge: Cambridge University\nPress.",
                "<a name=\"Sob98\">Sober, E., and Wilson, D.S. (1998)</a>.\n <em>Unto Others</em>, Cambridge, MA: Harvard University Press.",
                "<a name=\"Ste03\">Sterelny, K. (2003)</a>.\n <em>Thought in a Hostile World</em>, Oxford: Blackwell.",
                "<a name=\"Sti12\">Stirling, W. (2012)</a>.\n <em>Theory of Conditional Games</em>, Cambridge: Cambridge University\nPress.",
                "<a name=\"Strat97\">Stratmann, T. (1997)</a>.\n Logrolling. In D. Mueller, ed., <em>Perspectives on Public\nChoice</em>, Cambridge: Cambridge University Press,\n322\u2013341.",
                "<a name=\"Str56\">Strotz, R. (1956)</a>.\n Myopia and Inconsistency in Dynamic Utility Maximization. <em>The\nReview of Economic Studies</em>, 23: 165\u2013180.",
                "<a name=\"Sug93\">Sugden, R. (1993)</a>.\n Thinking as a Team: Towards an Explanation of Nonselfish Behavior.\n<em>Social Philosophy and Policy</em> 10: 69\u201389.",
                "<a name=\"Sug00\">\u2013\u2013\u2013 (2000)</a>.\n Team Preferences. <em>Economics and Philosophy</em> 16:\n175\u2013204.",
                "<a name=\"Sug03\">\u2013\u2013\u2013 (2003)</a>.\n The Logic of Team Reasoning. <em>Philosophical Explorations</em> 6:\n165\u2013181.",
                "<a name=\"Sug18\">\u2013\u2013\u2013 (2018)</a>.\n <em>The Community of Advantage</em>, Oxford: Oxford University\nPress.",
                "<a name=\"Thu31\">Thurstone, L. (1931)</a>.\n The Indifference Function. <em>Journal of Social Psychology</em>, 2:\n139\u2013167.",
                "<a name=\"Tom04\">Tomasello, M.</a>,\n M. Carpenter, J. Call, T. Behne and H. Moll (2004). Understanding and\nSharing Intentions: The Origins of Cultural Cognition. <em>Behavioral\nand Brain Sciences</em>, 28: 675\u2013691.",
                "<a name=\"Val91\">Vallentyne, P. (ed.). (1991)</a>.\n <em>Contractarianism and Rational Choice</em>, Cambridge: Cambridge\nUniversity Press.",
                "<a name=\"Neu44\">von Neumann, J., and Morgenstern, O., (1944)</a>.\n <em>The Theory of Games and Economic Behavior</em>, Princeton:\nPrinceton University Press.",
                "<a name=\"Neu47\">\u2013\u2013\u2013, (1947)</a>.\n <em>The Theory of Games and Economic Behavior</em>, second edition,\nPrinceton: Princeton University Press.",
                "<a name=\"Wei95\">Weibull, J. (1995)</a>.\n <em>Evolutionary Game Theory</em>, Cambridge, MA: MIT Press.",
                "<a name=\"Wil08\">Wilcox, N. (2008)</a>.\n Stochastic Models for Binary Discrete Choice Under Risk: A Critical\nPrimer and Econometric Comparison. In J. Cox and G. Harrison, eds.,\n<em>Risk Aversion and Experiments</em>, Bingley, UK: Emeraldn,\n197\u2013292.",
                "<a name=\"Wran09\">Wrangham, R. (2009)</a>.\n <em>Catching Fire</em>. London: Profile.",
                "<a name=\"Yaa87\">Yaari, M. (1987)</a>.\n The Dual Theory of Choice Under Risk. <em>Econometrica</em>, 55:\n95\u2013115.",
                "<a name=\"Young98\">Young, H.P. (1998)</a>.\n <em>Individual Strategy and Social Structure</em>, Princeton:\nPrinceton University Press.",
                "<a name=\"Zaw13\">Zawidzki, T. (2013)</a>.\n <em>Mindshaping</em>, Cambridge, MA: MIT Press.\n</ul>\n</div>"
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2><a name=\"Bib\">Bibliography</a></h2>\n<h3>Annotations on General Sources</h3>\n<p>\nIn the following section, books and articles which no one seriously\ninterested in game theory can afford to miss are marked with (**).\n</p>\n<p>\nThe most accessible textbook that covers all of the main branches of\ngame theory is\n <a href=\"#Dix14\">Dixit, Skeath and Reiley (2014)</a>.\n A student entirely new to the field should work through this before\nmoving on to anything else.</p>\n<p>\nGame theory has countless applications, of which this article has been\nable to suggest only a few. Readers in search of more, but not wishing\nto immerse themselves in mathematics, can find a number of good\nsources.\n <a href=\"#Dix91\">Dixit and Nalebuff (1991)</a>\n and\n <a href=\"#Dix08\">(2008)</a>\n are especially strong on political and social examples.\n <a href=\"#McM91\">McMillan (1991)</a>\n emphasizes business applications. </p>\n<p>\nThe great historical breakthrough that officially launched game theory\nis\n <a href=\"#Neu44\">von Neumann and Morgenstern (1944)</a>,\n which those with scholarly interest in game theory should read with\nclassic papers of\n <a href=\"#Nas50a\">John Nash (1950a, 1950b, 1951)</a>.\n A very useful collection of key foundational papers, all classics, is\n <a href=\"#Kuhn97\">Kuhn (1997)</a>.\n For a contemporary mathematical treatment that is unusually\nphilosophically sophisticated,\n <a href=\"#Bin05b\">Binmore (2005c)</a>\n (**) is in a class by itself. The second half of\n <a href=\"#Kre90\">Kreps (1990)</a>\n (**) is the best available starting point for a tour of the\nphilosophical worries surrounding equilibrium selection for\nnormativists.\n <a href=\"#Koo92\">Koons (1992)</a>\n takes these issues further.\n <a href=\"#Fud91\">Fudenberg and Tirole (1991)</a>\n remains the most thorough and complete mathematical text available.\n <a href=\"#Gin09b\">Gintis (2009b)</a>\n (**) provides a text crammed with terrific problem exercises, which\nis also unique in that it treats evolutionary game theory as providing\nthe foundational basis for game theory in general. Recent developments\nin fundamental theory are well represented in\n <a href=\"#Bin93\">Binmore, Kirman and Tani (1993)</a>.\n Anyone who wants to apply game theory to real human choices, which\nare generally related stochastically rather than deterministically to\naxioms of optimization, needs to understand quantal response theory\n(QRE) as a solution concept. The original development of this is found\nin\n <a href=\"#McK95\">McKelvey and Palfrey (1995)</a>\n and\n <a href=\"#McK98\">McKelvey and Palfrey (1998)</a>.\n <a href=\"#Goe16\">Goeree, Holt, and Palfrey (2016)</a> provide a comprehensive and up-to-date review of QRE and\nits leading applications.</p>\n<p>\nThe philosophical foundations of the basic game-theoretic concepts as\neconomists understand them are presented in\n <a href=\"#LaC94\">LaCasse and Ross (1994)</a>.\n <a href=\"#Ros95\">Ross and LaCasse (1995)</a> outline the relationships between games and the\naxiomatic assumptions of microeconomics and macroeconomics.\nPhilosophical puzzles at this foundational level are critically\ndiscussed in\n <a href=\"#Bic93\">Bicchieri (1993)</a>.\n <a href=\"#Lew69\">Lewis (1969)</a> puts game-theoretic equilibrium concepts to wider\napplication in philosophy, though making some foundational assumptions\nthat economists generally do not share. His program is carried a good\ndeal further, and without the contested assumptions, by\n <a href=\"#Sky96\">Skyrms (1996)</a>\n (**) and\n <a href=\"#Sky04\">(2004)</a>.\n (See also\n <a href=\"#Noz98\">Nozick [1998]</a>.)\n <a href=\"#Gau86\">Gauthier (1986)</a> launches a literature not surveyed in this article, in\nwhich the possibility of game-theoretic foundations for contractarian\nethics is investigated. This work is critically surveyed in\n <a href=\"#Val91\">Vallentyne (1991)</a>,\n and extended into a dynamic setting in\n <a href=\"#Dan92\">Danielson (1992)</a>.\n <a href=\"#Bin94\">Binmore (1994, 1998)</a> (**), however, sharply criticizes this project as\ninconsistent with natural psychology. Philosophers will also find\n <a href=\"#Hol98\">Hollis (1998)</a>\n to be of interest.</p>\n<p>\nIn a class by themselves for insight, originality, readability and\ncross-disciplinary importance are the works of the Nobel laureate\nThomas Schelling. He is the fountainhead of the huge literature that\napplies game theory to social and political issues of immediate\nrelevance, and shows how lightly it is possible to wear one\u2019s\nmathematics if the logic is sufficiently sure-footed. There are four\nvolumes, all essential:\n <a href=\"#Sch60\">Schelling (1960)</a>\n (**),\n <a href=\"#Sch78\">Schelling (1978 / 2006)</a>\n (**),\n <a href=\"#Sch84\">Schelling (1984)</a>\n (**),\n <a href=\"#Sch06\">Schelling (2006)</a>\n (**).</p>\n<p>\n<a href=\"#Har95\">Hardin (1995)</a>\n is one of many examples of the application of game theory to problems\nin applied political theory.\n <a href=\"#Bai94\">Baird, Gertner and Picker (1994)</a>\n review uses of game theory in legal theory and jurisprudence.\n <a href=\"#Mue97\">Mueller (1997)</a>\n surveys applications in public choice.\n <a href=\"#Ghe97\">Ghemawat (1997)</a>\n provides case studies intended to serve as a methodological template\nfor practical application of game theory to business strategy\nproblems.\n <a href=\"#Pou92\">Poundstone (1992)</a>\n provides a lively history of the Prisoner\u2019s Dilemma and its use\nby Cold War strategists.\n <a href=\"#Ama16\">Amadae (2016)</a>\n tells the same story, based on original scholarly sleuthing, with\nless complacency concerning its implications. The memoir of\n <a href=\"#Ell17\">Ellsberg (2017)</a>\n largely confirms Amadae\u2019s perspective.\n <a href=\"#Dur01\">Durlauf and Young (2001)</a>\n is a useful collection on applications to social structures and\nsocial change.</p>\n<p>\nEvolutionary game theory owes its explicit genesis to\n <a href=\"#May82\">Maynard Smith (1982)</a>\n (**). For a text that integrates game theory directly with biology,\nsee\n <a href=\"#Hof98\">Hofbauer and Sigmund (1998)</a>\n (**).\n <a href=\"#Sig93\">Sigmund (1993)</a>\n presents this material in a less technical and more accessible\nformat. Some exciting applications of evolutionary game theory to a\nrange of philosophical issues, on which this article has drawn\nheavily, is\n <a href=\"#Sky96\">Skyrms (1996)</a>\n (**). These issues and others are critically discussed from various\nangles in\n <a href=\"#Dan98\">Danielson (1998)</a>.\n Mathematical foundations for evolutionary games are presented in\n <a href=\"#Wei95\">Weibull (1995)</a>,\n and pursued further in\n <a href=\"#Sam97\">Samuelson (1997)</a>.\n These foundations are examined with special attention to issues for\nphilosophers by\n <a href=\"#Alex23\">Alexander (2023)</a>.\n As noted above,\n <a href=\"#Gin09b\">Gintis (2009b)</a>\n (**) now provides an introductory textbook that takes evolutionary\nmodeling to be foundational to all of game theory.\n <a href=\"#Young98\">H.P. Young (1998)</a>\n gives sophisticated models of the evolutionary dynamics of cultural\nnorms through the game-theoretic interactions of agents with limited\ncognitive capacities but dispositions to imitate one another.\n <a href=\"#Fud98\">Fudenberg and Levine (1998)</a>\n gives the technical foundations for modeling of this kind.</p>\n<p>\nMany philosophers will also be interested in Binmore\n (<a href=\"#Bin94\">1994</a>\n<a href=\"#Bin98\">1998</a>,\n <a href=\"#Bin05a\">2005a</a>)\n (**), which shows that application of game-theoretic analysis can\nunderwrite a Rawlsian conception of justice that does not require\nrecourse to Kantian presuppositions about what rational agents would\ndesire behind a veil of ignorance concerning their identities and\nsocial roles. (In addition, Binmore offers excursions into a range of\nother issues both central and peripheral to both the foundations and\nthe frontiers of game theory; these books are particularly rich on\nproblems that interest philosophers.) Almost everyone will be\ninterested in\n <a href=\"#Fra88\">Frank (1988)</a>\n (**), where evolutionary game theory is used to illuminate basic\nfeatures of human nature and emotion; though readers of this can find\ncriticism of Frank\u2019s model in\n <a href=\"#Ross04\">Ross and Dumouchel (2004)</a>.\n <a href=\"#Ocon19\">O\u2019Connor (2019)</a> uses evolutionary game theory to understand the deep\nroots and persistence of human inequality, particularly between the\nsexes. Her book is an exemplary instance of the essential value of\ngame theory to core questions in general social science and social\nphilosophy.</p>\n<p>\nBehavioral and experimental applications of game theory are surveyed\nin\n <a href=\"#Kag95\">Kagel and Roth (1995)</a>.\n <a href=\"#Cam03\">Camerer (2003)</a> (**) is a comprehensive and more recent study of this\nliterature, and cannot be missed by anyone interested in these issues.\nA shorter survey that emphasizes philosophical and methodological\ncriticism is\n <a href=\"#Sam05\">Samuelson (2005)</a>.\n Philosophical foundations are also carefully examined in\n <a href=\"#Gua05\">Guala (2005)</a>.</p>\n<p>\nTwo volumes from leading theorists that offer comprehensive views on\nthe philosophical foundations of game theory were published in 2009.\nThese are\n <a href=\"#Bin09\">Binmore (2009)</a>\n (**) and\n <a href=\"#Gin09a\">Gintis (2009a)</a>\n (**). Both are indispensable to philosophers who aim to participate\nin critical discussions of foundational issues.</p>\n<p>\nA volume of interviews with nineteen leading game theorists, eliciting\ntheir views on motivations and foundational topics, is\n <a href=\"#Hen07\">Hendricks and Hansen (2007)</a>.</p>\n<p>\nGame-theoretic dynamics of the sub-person receive deep but accessible\nreflection in\n <a href=\"#Ain01\">Ainslie (2001)</a>.\n Seminal texts in neuroeconomics, with extensive use of and\nimplications for behavioral game theory, are\n <a href=\"#Mon02\">Montague and Berns (2002)</a>,\n <a href=\"#Gli03\">Glimcher 2003</a> (**), and\n <a href=\"#Cam05\">Camerer, Loewenstein and Prelec (2005)</a>.\n <a href=\"#Ross05a\">Ross (2005a)</a> studies the game-theoretic foundations of microeconomics\nin general, but especially behavioral economics and neuroeconomics,\nfrom the perspective of cognitive science and in close alignment with\nAinslie.</p>\n<p>\nThe theory of cooperative games is consolidated in\n <a href=\"#Cha15\">Chakravarty, Mitra and Sarkar (2015)</a>.\n An accessible and non-technical review of applications of matching\ntheory, by the economist whose work on it earned a Nobel Prize, is\n <a href=\"#Rot15\">Roth (2015)</a>.</p>\n<h3>References</h3>\n<ul class=\"hanging\">\n<li><a name=\"Ain92\">Ainslie, G. (1992)</a>.\n <em>Picoeconomics</em>, Cambridge: Cambridge University Press.</li>\n<li><a name=\"Ain01\">\u2013\u2013\u2013 (2001)</a>.\n <em>Breakdown of Will</em>, Cambridge: Cambridge University\nPress.</li>\n<li><a name=\"Alex23\">Alexander, J.M. (2023)</a>.\n <em>Evolutionary Game Theory</em>, Cambridge: Cambridge University\nPress.</li>\n<li><a name=\"Ama16\">Amadae, S. (2016)</a>.\n <em>Prisoners of Reason</em>, Cambridge: Cambridge University\nPress.</li>\n<li><a name=\"And08\">Andersen, S., Harrison, G., Lau, M., and Rutstrom, E. (2008)</a>.\n Eliciting risk and time preferences. <em>Econometrica</em>, 76:\n583\u2013618.</li>\n<li><a name=\"And14\">\u2013\u2013\u2013 (2014)</a>.\n Dual criteria decisions. <em>Journal of Economic Psychology</em>,\nforthcoming.</li>\n<li><a name=\"Aum74\">Aumann, R. (1974)</a>.\n Subjectivity and Correlation in Randomized Strategies. <em>Journal of\nMathematical Economics</em>, 1: 67\u201396.</li>\n<li><a name=\"Aum87\">\u2013\u2013\u2013 (1987)</a>.\n Correlated Equilibrium as an Expression of Bayesian Rationality.\n<em>Econometrica</em>, 55: 1\u201318.</li>\n<li><a name=\"Bac06\">Bacharach, M. (2006)</a>.\n <em>Beyond Individual Choice: Teams and Frames in Game Theory</em>,\nPrinceton: Princeton University Press.</li>\n<li><a name=\"Bai94\">Baird, D., Gertner, R., and Picker, R. (1994)</a>.\n <em>Game Theory and the Law</em>, Cambridge, MA: Harvard University\nPress.</li>\n<li><a name=\"Bell91\">Bell, W., (1991)</a>.\n <em>Searching Behaviour</em>, London: Chapman and Hall.</li>\n<li><a name=\"Bic93\">Bicchieri, C. (1993)</a>.\n <em>Rationality and Coordination</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li><a name=\"Bic06\">\u2013\u2013\u2013 (2006)</a>.\n <em>The Grammar of Society</em>, Cambridge: Cambridge University\nPress.</li>\n<li><a name=\"Bic17\">\u2013\u2013\u2013 (2017)</a>.\n <em>Norms in the Wild</em>. Oxford: Oxford University Press.</li>\n<li><a name=\"Bic08\">Bickhard, M. (2008)</a>.\n Social Ontology as Convention. <em>Topoi</em>, 27:\n139\u2013149.</li>\n<li><a name=\"Bin87\">Binmore, K. (1987)</a>.\n Modeling Rational Players I. <em>Economics and Philosophy</em>, 3:\n179\u2013214.</li>\n<li><a name=\"Bin94\">\u2013\u2013\u2013 (1994)</a>.\n <em>Game Theory and the Social Contract</em> (v. 1): <em>Playing\nFair</em>, Cambridge, MA: MIT Press.</li>\n<li><a name=\"Bin98\">\u2013\u2013\u2013 (1998).</a>\n<em>Game Theory and the Social Contract</em> (v. 2): <em>Just\nPlaying</em>, Cambridge, MA: MIT Press.</li>\n<li><a name=\"Bin05a\">\u2013\u2013\u2013 (2005a)</a>.\n <em>Natural Justice</em>, Oxford: Oxford University Press.</li>\n<li><a name=\"Bin05b\">\u2013\u2013\u2013 (2005b)</a>.\n Economic Man\u2014or Straw Man? <em>Behavioral and Brain\nSciences</em> 28: 817\u2013818.</li>\n<li><a name=\"Bin05c\">\u2013\u2013\u2013 (2005c)</a>.\n <em>Playing For Real</em>, Oxford: Oxford University Press.</li>\n<li><a name=\"Bin07\">\u2013\u2013\u2013 (2007)</a>.\n <em>Does Game Theory Work? The Bargaining Challenge</em>, Cambridge,\nMA: MIT Press.</li>\n<li><a name=\"Bin08\">\u2013\u2013\u2013 (2008)</a>.\n Do Conventions Need to be Common Knowledge? <em>Topoi</em> 27:\n17\u201327.</li>\n<li><a name=\"Bin09\">\u2013\u2013\u2013 (2009)</a>.\n <em>Rational Decisions</em>, Princeton: Princeton University\nPress.</li>\n<li><a name=\"Bin93\">Binmore, K., Kirman, A., and Tani, P. (eds.) (1993)</a>.\n <em>Frontiers of Game Theory</em>, Cambridge, MA: MIT Press</li>\n<li><a name=\"Bin02\">Binmore, K., and Klemperer, P. (2002)</a>.\n The Biggest Auction Ever: The Sale of British 3G Telcom Licenses.\n<em>Economic Journal</em>, 112: C74\u2013C96.</li>\n<li><a name=\"Bis09\">Bishop, B.(2009)</a>.\n <em>The Big Sort</em>. New York: Mariner.</li>\n<li><a name=\"Boy85\">Boyd, R., and Richerson, P. (1985)</a>.\n <em>Culture and the Evolutionary Process</em>, Chicago: University of\nChicago Press.</li>\n<li><a name=\"Cam95\">Camerer, C. (1995)</a>.\n Individual Decision Making. In J. Kagel and A. Roth, eds.,\n<em>Handbook of Experimental Economics</em>, 587\u2013703. Princeton:\nPrinceton University Press.</li>\n<li><a name=\"Cam03\">\u2013\u2013\u2013 (2003)</a>.\n <em>Behavioral Game Theory: Experiments in Strategic\nInteraction</em>, Princeton: Princeton University Press.</li>\n<li><a name=\"Cam05\">Camerer, C., Loewenstein, G., and Prelec, D. (2005)</a>.\n Neuroeconomics: How Neuroscience Can Inform Economics. <em>Journal of\nEconomic Literature</em>, 40: 9\u201364.</li>\n<li><a name=\"Cha15\">Chakravarty, S., Mitra, M., and Sarkar, P. (2015)</a>.\n <em>A Course on Cooperative Game Theory</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li><a name=\"Chew79\">Chew, S., and MacCrimmon, K. (1979)</a>.\n Alpha-nu Choice Theory: A Generalization of Expected Utility Theory.\nWorking Paper No. 686, University of Columbia Faculty of Commerce and\nBusiness Administration.</li>\n<li><a name=\"Chi17\">Chiappori, P.-A. (2017)</a>.\n <em>Matching With Transfers: The Economics of Love and Marriage</em>,\nPrinceton: Princeton University Press. </li>\n<li><a name=\"Cla97\">Clark, A. (1997)</a>.\n <em>Being There</em>, Cambridge, MA: MIT Press.</li>\n<li><a name=\"Cla16\">\u2013\u2013\u2013 (2016)</a>.<em>\n Surfing Uncertainty</em>, Cambridge, MA: MIT Press.</li>\n<li><a name=\"Dan92\">Danielson, P. (1992)</a>.\n <em>Artificial Morality</em>, London: Routledge</li>\n<li><a name=\"Dan98\">\u2013\u2013\u2013 (ed.) (1998)</a>.\n <em>Modelling Rationality, Morality and Evolution</em>, Oxford:\nOxford University Press.</li>\n<li><a name=\"Den87\">Dennett, D. (1987)</a>.\n <em>The Intentional Stance</em>, Cambridge, MA: MIT Press.</li>\n<li><a name=\"Den95\">\u2013\u2013\u2013 (1995)</a>.\n <em>Darwin\u2019s Dangerous Idea</em>, New York: Simon and\nSchuster.</li>\n<li><a name=\"Dix91\">Dixit, A., and Nalebuff, B. (1991)</a>.\n <em>Thinking Strategically</em>, New York: Norton.</li>\n<li><a name=\"Dix08\">\u2013\u2013\u2013 (2008)</a>.\n <em>The Art of Strategy</em>, New York: Norton.</li>\n<li><a name=\"Dix14\">Dixit, A., Skeath, S., and Reiley, D. (2014)</a>.\n <em>Games of Strategy</em>, fourth edition. New York: W. W. Norton\nand Company.</li>\n<li><a name=\"Dug98\">Dugatkin, L., and Reeve, H., eds. (1998)</a>.\n <em>Game Theory and Animal Behavior</em>, Oxford: Oxford University\nPress.</li>\n<li><a name=\"Duk98\">Dukas, R., ed. (1998)</a>.\n <em>Cognitive Ecology.</em>, Chicago: University of Chicago\nPress.</li>\n<li><a name=\"Dur01\">Durlauf, S., and Young, H.P., eds. (2001)</a>.\n <em>Social Dynamics</em>, Cambridge, MA: MIT Press.</li>\n<li><a name=\"Ell17\">Ellsberg, D. (2017)</a>.\n <em>The Doomsday Machine</em>, New York: Bloomsbury.</li>\n<li><a name=\"Eri15\">Erickson, P. (2015)</a>.\n <em>The World the Game Theorists Made</em>, Chicago: University of\nChicago Press.</li>\n<li><a name=\"Fra88\">Frank, R. (1988)</a>.\n <em>Passions Within Reason</em>, New York: Norton.</li>\n<li><a name=\"Fud98\">Fudenberg, D., and Levine, D. (1998)</a>.\n <em>The Theory of Learning in Games</em>, Cambridge, MA: MIT\nPress.</li>\n<li><a name=\"Fud08\">\u2013\u2013\u2013 (2008)</a>.\n <em>A Long-Run Collaboration on Long-Run Games</em>. Singapore: World\nScientific.</li>\n<li><a name=\"Fud16\">\u2013\u2013\u2013 (2016)</a>.\n Whither Game Theory? Towards a Theory of Learning in Games.\n<em>Journal of Economic Perspectives</em>, 30(4): 151\u2013170</li>\n<li><a name=\"Fud91\">Fudenberg, D., and Tirole, J. (1991)</a>.\n <em>Game Theory</em>, Cambridge, MA: MIT Press.</li>\n<li><a name=\"Gal62\">Gale, D., and Shapley, L. (1962)</a>.\n College Admissions and the Stability of Marriage. <em>American\nMathematical Monthly</em>, 69 :9\u201315.</li>\n<li><a name=\"Gau86\">Gauthier, D. (1986)</a>.\n <em>Morals By Agreement</em>, Oxford: Oxford University Press.</li>\n<li><a name=\"Ger14\">Gershkov, A., and Moldovanu, B. (2014)</a>.\n <em>Dynamic Allocation and Pricing: A Mechanism Design Approach</em>,\nCambridge, MA: MIT Press.</li>\n<li><a name=\"Ghe97\">Ghemawat, P. (1997)</a>.\n <em>Games Businesses Play</em>, Cambridge, MA: MIT Press.</li>\n<li><a name=\"Gil89\">Gilbert, M. (1989)</a>.\n <em>On Social Facts</em>, Princeton: Princeton University Press.</li>\n<li><a name=\"Gin04\">Gintis, G.(2004)</a>.\n Towards the Unity of the Human Behavioral Sciences. <em>Philosophy,\nPolitics and Economics</em>, 31: 37\u201357.</li>\n<li><a name=\"Gin05\">\u2013\u2013\u2013 (2005)</a>.\n Behavioral Ethics Meets Natural Justice. <em>Politics, Philosophy and\nEconomics</em>, 5: 5\u201332.</li>\n<li><a name=\"Gin09a\">\u2013\u2013\u2013 (2009a)</a>.\n <em>The Bounds of Reason</em>, Princeton: Princeton University\nPress.</li>\n<li><a name=\"Gin09b\">\u2013\u2013\u2013 (2009b)</a>.\n <em>Game Theory Evolving.</em> Second edition. Princeton: Princeton\nUniversity Press.</li>\n<li><a name=\"Gli03\">Glimcher, P. (2003)</a>.\n <em>Decisions, Uncertainty and the Brain</em>, Cambridge, MA: MIT\nPress.</li>\n<li><a name=\"Gli07\">Glimcher, P., Kable, J., and Louie, K. (2007)</a>.\n Neuroeconomic Studies of Impulsivity: Now or Just as Soon as\nPossible? <em>American Economic Review (Papers and Proceedings)</em>,\n97: 142\u2013147.</li>\n<li><a name=\"God96\">Godfrey-Smith, P. (1996)</a>.\n <em>Complexity and the Function of Mind in Nature</em>. Cambridge,\nUK: Cambridge University Press.</li>\n<li><a name=\"Goe16\">Goeree, J., Holt, C., and Palfrey, T. (2016)</a>.\n <em>Quantal Response Equilibrium</em>, Princeton: Princeton\nUniversity Press.</li>\n<li><a name=\"Gua05\">Guala, F. (2005)</a>.\n <em>The Methodology of Experimental Economics</em>, Cambridge:\nCambridge University Press.</li>\n<li><a name=\"Gua16\">\u2013\u2013\u2013 (2016)</a>.\n <em>Understanding Institutions</em>, Princeton: Princeton University\nPress.</li>\n<li><a name=\"Ham03\">Hammerstein, P. (2003)</a>.\n Why is Reciprocity so Rare in Social Animals? A Protestant Appeal. In\nP. Hammerstein, ed., <em>Genetic and Cultural Evolution of\nCooperation</em>, 83\u201393. Cambridge, MA: MIT Press.</li>\n<li><a name=\"Ham86\">Hampton, J. (1986)</a>,\n <em>Hobbes and the Social Contract Tradition</em>. Cambridge:\nCambridge University Press.</li>\n<li><a name=\"Har95\">Hardin, R. (1995)</a>.\n <em>One For All</em>, Princeton: Princeton University Press.</li>\n<li><a name=\"Har08b\">Harrison, G.W. (2008)</a>.\n Neuroeconomics: A Critical Reconsideration. <em>Economics and\nPhilosophy</em> 24: 303\u2013344.</li>\n<li><a name=\"Har08\">Harrison, G.W., and Rutstrom, E. (2008)</a>.\n Risk aversion in the laboratory. In <em>Risk Aversion in\nExperiments</em>, J. Cox and G. Harrison eds., Bingley, UK: Emerald,\n41\u2013196.</li>\n<li><a name=\"Har10\">Harrison, G.W., and Ross, D. (2010)</a>.\n The Methodologies of Neuroeconomics. <em>Journal of Economic\nMethodology</em>, 17: 185\u2013196. </li>\n<li><a name=\"Har16\">\u2013\u2013\u2013 (2016)</a>.\n The Psychology of Human Risk Preferences and Vulnerability to\nScare-mongers: Experimental Economic Tools for Hypothesis Formulation\nand Testing. <em>Journal of Cognition and Culture</em>, 16:\n383\u2013414.</li>\n<li><a name=\"Har23\">\u2013\u2013\u2013 forthcoming</a>.\n Behavioral Welfare Economics and the Quantitative Intentional Stance.\nIn G.W. Harrison &amp; D. Ross, eds., <em>Models of Risk Preferences:\nDescriptive and Normative Challenges</em>. Bingley, UK: Emerald.</li>\n<li><a name=\"Har67\">Harsanyi, J. (1967)</a>.\n Games With Incomplete Information Played by \u2018Bayesian\u2019\nPlayers, Parts I\u2013III. <em>Management Science</em> 14:\n159\u2013182.</li>\n<li><a name=\"Har77\">\u2013\u2013\u2013 (1977)</a>.\n <em>Rational Behavior and Bargaining Equilibrium in Games and Social\nSituations</em>, Cambridge: Cambridge University Press.</li>\n<li><a name=\"Hen04\">Henrich, J., Boyd, R., Bowles, S., Camerer, C., Fehr, E., and Gintis, H., eds. (2004)</a>.\n <em>Foundations of Human Sociality: Economic Experiments and\nEthnographic Evidence From 15 Small-Scale Societies</em>, Oxford:\nOxford University Press.</li>\n<li><a name=\"Hen05\">Henrich, J.</a>,\n Boyd, R., Bowles, S., Camerer, C., Fehr, E., Gintis, H., McElreath,\nR., Alvard, M., Barr, A., Ensminger, J., Henrich, N., Hill, K.,\nGil-White, F., Gurven, M., Marlowe, F., Patton, J., and Tracer, D.\n(2005). \u2018Economic Man\u2019 in Cross-Cultural Perspective.\n<em>Behavioral and Brain Sciences</em>, 28: 795\u2013815.</li>\n<li><a name=\"Hen07\">Hendricks, V., and Hansen, P., eds. (2007)</a>.\n <em>Game Theory: 5 Questions</em>, Copenhagen: Automatic Press.</li>\n<li><a name=\"Hof98\">Hofbauer, J., and Sigmund, K. (1998)</a>.\n <em>Evolutionary Games and Population Dynamics</em>, Cambridge:\nCambridge University Press.</li>\n<li><a name=\"Hof19\">Hofmeyr, A., and Ross, D. (2019)</a>.\n Team Agency and Conditional Games. In M. Nagatsu, ed., <em>Philosophy\nand Social Science: An Interdisciplinary Dialogue</em>, London:\nBloomsbury, 67\u201392.</li>\n<li><a name=\"Hol98\">Hollis, M. (1998)</a>.\n <em>Trust Within Reason</em>, Cambridge: Cambridge University\nPress.</li>\n<li><a name=\"Hol93\">Hollis, M., and Sugden, R. (1993)</a>.\n Rationality in Action. <em>Mind</em>, 102: 1\u201335.</li>\n<li><a name=\"Hur06\">Hurwicz, L., and Reiter, S. (2006)</a>.\n <em>Designing Economic Mechanisms</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li><a name=\"Hut08\">Hutto, D. (2008)</a>.\n <em>Folk Psychological Narratives</em>, Cambridge, MA: MIT\nPress.</li>\n<li><a name=\"Kag95\">Kagel, J., and Roth, A., eds. (1995)</a>.\n <em>Handbook of Experimental Economics</em>, Princeton: Princeton\nUniversity Press.</li>\n<li><a name=\"Kee76\">Keeney, R., and Raiffa, H. (1976)</a>.\n <em>Decisions With Multiple Objectives</em>, New York: Wiley.</li>\n<li><a name=\"Kin05\">King-Casas, B., Tomlin, D., Anen, C., Camerer, C., Quartz, S., and Montague, P.R. (2005)</a>.\n Getting to Know You: Reputation and Trust in a Two-Person Economic\nExchange. <em>Science</em>, 308: 78\u201383.</li>\n<li><a name=\"Kle04\">Klemperer, P. (2004)</a>.\n <em>Auctions: Theory and Practice</em>, Princeton: Princeton\nUniversity Press.</li>\n<li><a name=\"Koo92\">Koons, R. (1992)</a>.\n <em>Paradoxes of Belief and Strategic Rationality</em>, Cambridge:\nCambridge University Press.</li>\n<li><a name=\"Krebs84\">Krebs, J., and Davies, N. (1984)</a>.\n <em>Behavioral Ecology: An Evolutionary Approach</em>, Second\nedition. Sunderland: Sinauer.</li>\n<li><a name=\"Kre90\">Kreps, D. (1990)</a>.\n <em>A Course in Microeconomic Theory</em>, Princeton: Princeton\nUniversity Press.</li>\n<li><a name=\"Kru14\">Kruschke, J. (2014)</a>.\n <em>Doing Bayesian Data Analysis</em>, 2nd Edition. Cambridge, MA:\nAcademic Press.</li>\n<li><a name=\"Kuhn97\">Kuhn, H., ed., (1997)</a>.\n <em>Classics in Game Theory</em>, Princeton: Princeton University\nPress.</li>\n<li><a name=\"Kur95\">Kuran, T. (1995)</a>.\n <em>Private Truths, Public Lies</em>. Cambridge, MA: Harvard\nUniversity Press.</li>\n<li><a name=\"LaC94\">LaCasse, C., and Ross, D. (1994)</a>.\n \u2018The Microeconomic Interpretation of Games\u2019. <em>PSA\n1994, Volume 1</em>, D. Hull, S. Forbes and R. Burien (eds.), East\nLansing, MI: Philosophy of Science Association, pp.\n479\u2013387.</li>\n<li><a name=\"Led95\">Ledyard, J. (1995)</a>.\n Public Goods: A Survey of Experimental Research. In J. Kagel and A.\nRoth, eds., <em>Handbook of Experimental Economics</em>, Princeton:\nPrinceton University Press.</li>\n<li><a name=\"Lew69\">Lewis, D. (1969)</a>.\n <em>Convention</em>, Cambridge, MA: Harvard University Press.</li>\n<li><a name=\"Lich06\">Lichtenstein, S., and Slovic, P., eds. (2006)</a>.\n <em>The Construction of Preference</em>, Cambridge, UK: Cambridge\nUniversity Press.</li>\n<li><a name=\"May82\">Maynard Smith, J. (1982)</a>.\n <em>Evolution and the Theory of Games</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li><a name=\"McC04\">McClure, S., Laibson, D., Loewenstein, G., and Cohen, J. (2004)</a>.\n Separate Neural Systems Value Immediate and Delayed Monetary Rewards.\n<em>Science</em>, 306: 503\u2013507.</li>\n<li><a name=\"McE20\">McElreath, R. (2020)</a>.\n <em>Statistical Rethinking</em>, 2nd Edition. London: Chapman &amp;\nHall.</li>\n<li><a name=\"McGeer01\">McGeer, V. (2001)</a>.\n Psycho-practice, Psycho-theory, and the Contrastive Case of Autism:\nHow Processes of Mind Become Second Nature, <em>Journal of\nConsciousness Studies</em>, 8: 109\u2013132.</li>\n<li><a name=\"McGeer02\">\u2013\u2013\u2013(2002).</a>\n Enculturating Folk-Psychologists, <em>Synthese</em>, 199:\n1039\u20131063.</li>\n<li><a name=\"McK95\">McKelvey, R., and Palfrey, T. (1995)</a>.\n Quantal Response Equilibria for Normal Form Games. <em>Games and\nEconomic Behavior</em> 10: 6\u201338.</li>\n<li><a name=\"McK98\">\u2013\u2013\u2013 (1998)</a>.\n Quantal Response Equilibria for Extensive Form Games.\n<em>Experimental Economics</em> 1: 9\u201341.</li>\n<li><a name=\"McM91\">McMillan, J. (1991)</a>.\n <em>Games, Strategies and Managers</em>, Oxford: Oxford University\nPress.</li>\n<li><a name=\"Mil84\">Millikan, R. (1984)</a>.\n <em>Language, Thought and Other Biological Categories</em>,\nCambridge, MA: MIT Press.</li>\n<li><a name=\"Mon02\">Montague,P. R., and Berns, G. (2002)</a>.\n Neural Economics and the Biological Substrates of Valuation.\n<em>Neuron</em>, 36: 265\u2013284.</li>\n<li><a name=\"Mue97\">Mueller, D. (1997)</a>.\n <em>Perspectives on Public Choice</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li><a name=\"Nas50a\">Nash, J. (1950a)</a>.\n \u2018Equilibrium Points in \\(n\\)-Person Games.\u2019\n<em>Proceedings of the National Academy of Science</em>, 36:\n48\u201349.</li>\n<li><a name=\"Nas50b\">\u2013\u2013\u2013 (1950b)</a>.\n \u2018The Bargaining Problem.\u2019 <em>Econometrica</em>, 18:\n155\u2013162.</li>\n<li><a name=\"Nas51\">\u2013\u2013\u2013 (1951)</a>.\n \u2018Non-cooperative Games.\u2019 <em>Annals of Mathematics\nJournal</em>, 54: 286\u2013295.</li>\n<li><a name=\"Nas53\">\u2013\u2013\u2013 (1953)</a>.\n Two-Person Cooperative Games. <em>Econometrica</em>, 21:\n128\u2013140.</li>\n<li><a name=\"Nic03\">Nichols, S., and Stich, S. (2003).</a>\n<em>Mindreading</em>, Oxford: Oxford University Press.</li>\n<li><a name=\"Noe01\">Noe, R., van Hoof, J., and Hammerstein, P., eds. (2001)</a>.\n <em>Economics in Nature</em>, Cambridge: Cambridge University\nPress.</li>\n<li><a name=\"Noz98\">Nozick, R. (1998)</a>.\n <em>Socratic Puzzles</em>, Cambridge, MA: Harvard University\nPress.</li>\n<li><a name=\"Ocon19\">O\u2019Connor, C. (2019)</a>.\n <em>The Origins of Unfairness</em>, Oxford: Oxford University\nPress.</li>\n<li><a name=\"Ofek01\">Ofek, H. (2001)</a>.\n <em>Second Nature</em>. Cambridge: Cambridge University Press.</li>\n<li><a name=\"Orm94\">Ormerod, P. (1994)</a>.\n <em>The Death of Economics</em>, New York: Wiley.</li>\n<li><a name=\"Par22\">Parr, T., Pezzulo, G., &amp; Friston, K. (2022)</a>.\n <em>Active Inference</em>. Cambridge, MA: MIT Press.</li>\n<li><a name=\"Pet89\">Pettit, P., and Sugden, R. (1989)</a>.\n The Backward Induction Paradox. <em>Journal of Philosophy</em>, 86:\n169\u2013182.</li>\n<li><a name=\"Plan21\">Planer, R., &amp; Sterelny, K. (2021)</a>.\n <em> From Signal to Symbol</em>. Cambridge, MA: MIT Press.</li>\n<li><a name=\"Pla99\">Platt, M., and Glimcher, P. (1999)</a>.\n Neural Correlates of Decision Variables in Parietal Cortex.\n<em>Nature</em>, 400: 233\u2013238.</li>\n<li><a name=\"Plott78\">Plott, C., and Smith, V. (1978)</a>.\n An Experimental Examination of Two Exchange Institutions. <em>Review\nof Economic Studies</em>, 45: 133\u2013153.</li>\n<li><a name=\"Pou92\">Poundstone, W. (1992)</a>.\n <em>Prisoner\u2019s Dilemma</em>, New York: Doubleday.</li>\n<li><a name=\"Pre98\">Prelec, D. (1998)</a>.\n The Probability Weighting Function. <em>Econometrica</em>, 66:\n497\u2013527.</li>\n<li><a name=\"Qui82\">Quiggin,J. (1982)</a>.\n A Theory of Anticipated Utility. <em>Journal of Economic Behavior and\nOrganization</em>, 3: 323\u2013343.</li>\n<li><a name=\"Raw71\">Rawls, J. (1971)</a>.\n <em>A Theory of Justice</em>, Cambridge, MA: Harvard University\nPress.</li>\n<li><a name=\"Rob31\">Robbins, L. (1931)</a>.\n <em>An Essay on the Nature and Significance of Economic Science</em>,\nLondon: Macmillan.</li>\n<li><a name=\"Ross05a\">Ross, D. (2005a)</a>.\n <em>Economic Theory and Cognitive Science: Microexplanation.</em>,\nCambridge, MA: MIT Press.</li>\n<li><a name=\"Ross05b\">\u2013\u2013\u2013 (2006)</a>.\n Evolutionary Game Theory and the Normative Theory of Institutional\nDesign: Binmore and Behavioral Economics. <em>Politics, Philosophy and\nEconomics</em>, 5(1): 51\u201379.</li>\n<li><a name=\"Ros08a\">\u2013\u2013\u2013 (2008a)</a>.\n Classical Game Theory, Socialization and the Rationalization of\nConventions. <em>Topoi</em>, 27: 57\u201372.</li>\n<li><a name=\"Ros08b\">\u2013\u2013\u2013 (2008b)</a>.\n Two Styles of Neuroeconomics. <em>Economics and Philosophy</em> 24:\n473\u2013483.</li>\n<li><a name=\"Ros14\">\u2013\u2013\u2013 (2014)</a>.\n <em>Philosophy of Economics</em>, Houndmills, Basingstoke: Palgrave\nMacmillan.</li>\n<li><a name=\"Ross04\">Ross, D., and Dumouchel, P. (2004)</a>.\n Emotions as Strategic Signals. <em>Rationality and Society</em>, 16:\n251\u2013286.</li>\n<li><a name=\"Ros95\">Ross, D., and LaCasse, C. (1995)</a>.\n \u2018Towards a New Philosophy of Positive Economics\u2019.\n<em>Dialogue</em>, 34: 467\u2013493.</li>\n<li><a name=\"Ros21\">Ross, D., and Stirling, W. (2021)</a>.\n Economics, Social Neuroscience, and Mindshaping. In J. Harbeckeand C.\nHerrmann-Pillath, eds., <em>Social Neuroeconomics</em>, London:\nRoutledge, 174\u2013201.</li>\n<li><a name=\"Ros23\">Ross, D., Stirling, W., and Tummolini, L. (2023)</a>.\n Strategic Theory of Norms for Empirical Applications in Political\nScience and Political Economy. In H. Kincaid and J. van Bouwel, eds.,\n<em>The Oxford Handbook of Philosophy of Political Science</em>,\nOxford: Oxford University Press, 86\u2013121.</li>\n<li><a name=\"Rot15\">Roth, A. (2015)</a>.\n <em>Who Gets What and Why?</em>, New York: Houghton Mifflin\nHarcourt.</li>\n<li><a name=\"Sal95\">Sally, J. (1995)</a>.\n Conversation and Cooperation in Social Dilemmas: A Meta-analysis of\nExperiments From 1958 to 1992. <em>Rationality and Society</em>, 7:\n58\u201392.</li>\n<li><a name=\"Sam97\">Samuelson, L. (1997)</a>.\n <em>Evolutionary Games and Equilibrium Selection</em>, Cambridge, MA:\nMIT Press.</li>\n<li><a name=\"Sam05\">\u2013\u2013\u2013 (2005)</a>.\n Economic Theory and Experimental Economics. <em>Journal of Economic\nLiterature</em>, 43: 65\u2013107.</li>\n<li><a name=\"Sam16\">\u2013\u2013\u2013 (2016)</a>.\n Game Theory in Economics and Beyond. <em>Journal of Economic\nPerspectives</em>, 30(4): 107\u2013130.</li>\n<li><a name=\"Sam38\">Samuelson, P. (1938)</a>.\n \u2018A Note on the Pure Theory of Consumers\u2019\nBehaviour.\u2019 <em>Economica</em>, 5: 61\u201371.</li>\n<li><a name=\"Sav54\">Savage, L. (1954)</a>.\n <em>The Foundations of Statistics</em>, New York: Wiley.</li>\n<li><a name=\"Sch60\">Schelling, T. (1960)</a>.\n Schelling, T (1960). <em>Strategy of Conflict</em>, Cambridge, MA:\nHarvard University Press.</li>\n<li><a name=\"Sch78\">\u2013\u2013\u2013 (1978)</a>.\n <em>Micromotives and Macrobehavior</em>, New York: Norton. Second\nedition 2006.</li>\n<li><a name=\"Sch80\">\u2013\u2013\u2013 (1980)</a>.\n The Intimate Contest for Self-Command. <em>Public Interest</em>, 60:\n94\u2013118.</li>\n<li><a name=\"Sch84\">\u2013\u2013\u2013 (1984)</a>.\n <em>Choice and Consequence</em>, Cambridge, MA: Harvard University\nPress.</li>\n<li><a name=\"Sch06\">\u2013\u2013\u2013 (2006)</a>.\n <em>Strategies of Commitment</em>, Cambridge, MA: Harvard University\nPress.</li>\n<li><a name=\"Sel75\">Selten, R. (1975)</a>.\n \u2018Re-examination of the Perfectness Concept for Equilibrium\nPoints in Extensive Games.\u2019 <em>International Journal of Game\nTheory</em>, 4: 22\u201355.</li>\n<li><a name=\"Sig93\">Sigmund, K. (1993)</a>.\n <em>Games of Life</em>, Oxford: Oxford University Press.</li>\n<li><a name=\"Sha53\">Shapley, L. (1953)</a>.\n A Value of n-Person Games. In H, Kuhn and A. Tucker, eds.,\n<em>Contributions to the Theory of Games II</em>, 307\u2013317.\nPrinceton: Princeton University Press.</li>\n<li><a name=\"Sky96\">Skyrms, B. (1996)</a>.\n <em>Evolution of the Social Contract</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li><a name=\"Sky04\">\u2013\u2013\u2013 (2004)</a>.\n <em>The Stag Hunt and the Evolution of Social Structure</em>,\nCambridge: Cambridge University Press.</li>\n<li><a name=\"Smi62\">Smith, V. (1962)</a>.\n An Experimental Study of Competitive Market Behavior. <em>Journal of\nPolitical Economy</em>, 70: 111\u2013137.</li>\n<li><a name=\"Smi64\">\u2013\u2013\u2013 (1964)</a>.\n Effect of Market Organization on Competitive Equilibrium.\n<em>Quarterly Journal of Economics</em>, 78: 181\u2013201.</li>\n<li><a name=\"Smi65\">\u2013\u2013\u2013 (1965)</a>.\n Experimental Auction Markets and the Walrasian Hypothesis.\n<em>Journal of Political Economy</em>, 73: 387\u2013393.</li>\n<li><a name=\"Smi76\">\u2013\u2013\u2013 (1976)</a>.\n Bidding and Auctioning Institutions: Experimental Results. In Y.\nAmihud, ed., <em>Bidding and Auctioning for Procurement and\nAllocation</em>, 43\u201364. New York: New York University\nPress.</li>\n<li><a name=\"Smi82\">\u2013\u2013\u2013 (1982)</a>.\n Microeconomic Systems as an Experimental Science. <em>American\nEconomic Review</em>, 72: 923\u2013955.</li>\n<li><a name=\"Smi08\">\u2013\u2013\u2013 (2008)</a>.\n <em>Rationality in Economics</em>, Cambridge: Cambridge University\nPress.</li>\n<li><a name=\"Sob98\">Sober, E., and Wilson, D.S. (1998)</a>.\n <em>Unto Others</em>, Cambridge, MA: Harvard University Press.</li>\n<li><a name=\"Ste03\">Sterelny, K. (2003)</a>.\n <em>Thought in a Hostile World</em>, Oxford: Blackwell.</li>\n<li><a name=\"Sti12\">Stirling, W. (2012)</a>.\n <em>Theory of Conditional Games</em>, Cambridge: Cambridge University\nPress. </li>\n<li><a name=\"Strat97\">Stratmann, T. (1997)</a>.\n Logrolling. In D. Mueller, ed., <em>Perspectives on Public\nChoice</em>, Cambridge: Cambridge University Press,\n322\u2013341.</li>\n<li><a name=\"Str56\">Strotz, R. (1956)</a>.\n Myopia and Inconsistency in Dynamic Utility Maximization. <em>The\nReview of Economic Studies</em>, 23: 165\u2013180.</li>\n<li><a name=\"Sug93\">Sugden, R. (1993)</a>.\n Thinking as a Team: Towards an Explanation of Nonselfish Behavior.\n<em>Social Philosophy and Policy</em> 10: 69\u201389.</li>\n<li><a name=\"Sug00\">\u2013\u2013\u2013 (2000)</a>.\n Team Preferences. <em>Economics and Philosophy</em> 16:\n175\u2013204.</li>\n<li><a name=\"Sug03\">\u2013\u2013\u2013 (2003)</a>.\n The Logic of Team Reasoning. <em>Philosophical Explorations</em> 6:\n165\u2013181.</li>\n<li><a name=\"Sug18\">\u2013\u2013\u2013 (2018)</a>.\n <em>The Community of Advantage</em>, Oxford: Oxford University\nPress.</li>\n<li><a name=\"Thu31\">Thurstone, L. (1931)</a>.\n The Indifference Function. <em>Journal of Social Psychology</em>, 2:\n139\u2013167.</li>\n<li><a name=\"Tom04\">Tomasello, M.</a>,\n M. Carpenter, J. Call, T. Behne and H. Moll (2004). Understanding and\nSharing Intentions: The Origins of Cultural Cognition. <em>Behavioral\nand Brain Sciences</em>, 28: 675\u2013691.</li>\n<li><a name=\"Val91\">Vallentyne, P. (ed.). (1991)</a>.\n <em>Contractarianism and Rational Choice</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li><a name=\"Neu44\">von Neumann, J., and Morgenstern, O., (1944)</a>.\n <em>The Theory of Games and Economic Behavior</em>, Princeton:\nPrinceton University Press.</li>\n<li><a name=\"Neu47\">\u2013\u2013\u2013, (1947)</a>.\n <em>The Theory of Games and Economic Behavior</em>, second edition,\nPrinceton: Princeton University Press.</li>\n<li><a name=\"Wei95\">Weibull, J. (1995)</a>.\n <em>Evolutionary Game Theory</em>, Cambridge, MA: MIT Press.</li>\n<li><a name=\"Wil08\">Wilcox, N. (2008)</a>.\n Stochastic Models for Binary Discrete Choice Under Risk: A Critical\nPrimer and Econometric Comparison. In J. Cox and G. Harrison, eds.,\n<em>Risk Aversion and Experiments</em>, Bingley, UK: Emeraldn,\n197\u2013292. </li>\n<li><a name=\"Wran09\">Wrangham, R. (2009)</a>.\n <em>Catching Fire</em>. London: Profile.</li>\n<li><a name=\"Yaa87\">Yaari, M. (1987)</a>.\n The Dual Theory of Choice Under Risk. <em>Econometrica</em>, 55:\n95\u2013115.</li>\n<li><a name=\"Young98\">Young, H.P. (1998)</a>.\n <em>Individual Strategy and Social Structure</em>, Princeton:\nPrinceton University Press.</li>\n<li><a name=\"Zaw13\">Zawidzki, T. (2013)</a>.\n <em>Mindshaping</em>, Cambridge, MA: MIT Press.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "economics: philosophy of",
            "game theory: and ethics",
            "game theory: evolutionary",
            "logic: and games",
            "preferences",
            "prisoner\u2019s dilemma"
        ],
        "entry_link": [
            {
                "../economics/": "economics: philosophy of"
            },
            {
                "../game-ethics/": "game theory: and ethics"
            },
            {
                "../game-evolutionary/": "game theory: evolutionary"
            },
            {
                "../logic-games/": "logic: and games"
            },
            {
                "../preferences/": "preferences"
            },
            {
                "../prisoner-dilemma/": "prisoner\u2019s dilemma"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=game-theory\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/game-theory/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=game-theory&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/game-theory/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=game-theory": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/game-theory/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=game-theory&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/game-theory/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "<a name=\"Abb03\">Abbas, A., 2003</a>,\n \u201c<a href=\"http://arxiv.org/abs/cs/0310044\" target=\"other\">The Algebra of Utility Inference</a>,\u201d Cornell University working paper. ",
            "<a href=\"http://www.dklevine.com/general/whatis.htm\" target=\"other\">What is Game Theory?</a>,\n David K. Levine, Economics, UCLA.",
            "<a href=\"http://www.stanford.edu/~alroth/alroth.html\" target=\"other\">Game Theory, Experimental Economics, and Market Design</a>,\n page maintained by Al Roth (Economics, Stanford). ",
            "<a name=\"Ross23\"></a><a href=\"https://cear.gsu.edu/files/2023/03/Mindshaping-Conditional-Games-and-the-Harsanyi-Doctrine-March-2.pdf\" target=\"other\"> Mindshapring, Conditional Games, and the Harsanyi Doctrone, Don Ros and Wynn C. Stirling</a>.\n Center for the Economic Analysis of Risk (CEAR) Working Paper\n2023\u201303."
        ],
        "listed_links": [
            {
                "http://arxiv.org/abs/cs/0310044": "The Algebra of Utility Inference"
            },
            {
                "http://www.dklevine.com/general/whatis.htm": "What is Game Theory?"
            },
            {
                "http://www.stanford.edu/~alroth/alroth.html": "Game Theory, Experimental Economics, and Market Design"
            },
            {
                "https://cear.gsu.edu/files/2023/03/Mindshaping-Conditional-Games-and-the-Harsanyi-Doctrine-March-2.pdf": " Mindshapring, Conditional Games, and the Harsanyi Doctrone, Don Ros and Wynn C. Stirling"
            }
        ]
    }
}