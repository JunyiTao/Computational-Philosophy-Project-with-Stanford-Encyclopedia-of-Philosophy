{
    "url": "folkpsych-simulation",
    "title": "Folk Psychology as Mental Simulation",
    "authorship": {
        "year": "Copyright \u00a9 2017",
        "author_text": "Luca Barlassina\n<l.barlassina@sheffield.ac.uk>\nRobert M. Gordon",
        "author_links": [
            {
                "mailto:l%2ebarlassina%40sheffield%2eac%2euk": "l.barlassina@sheffield.ac.uk"
            },
            {
                "https://www.umsl.edu/~philo/People/Faculty/index.html": "Robert M. Gordon"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2017</a> by\n\n<br/>\nLuca Barlassina\n&lt;<a href=\"mailto:l%2ebarlassina%40sheffield%2eac%2euk\"><em>l<abbr title=\" dot \">.</abbr>barlassina<abbr title=\" at \">@</abbr>sheffield<abbr title=\" dot \">.</abbr>ac<abbr title=\" dot \">.</abbr>uk</em></a>&gt;<br/>\n<a href=\"https://www.umsl.edu/~philo/People/Faculty/index.html\" target=\"other\">Robert M. Gordon</a>\n</p>\n</div>"
    },
    "pubinfo": [
        "First published Mon Dec 8, 1997",
        "substantive revision Tue Mar 28, 2017"
    ],
    "preamble": "\n\nThe capacity for \u201cmindreading\u201d is understood in philosophy\nof mind and cognitive science as the capacity to represent, reason\nabout, and respond to others\u2019 mental states. Essentially the\nsame capacity is also known as \u201cfolk psychology\u201d,\n\u201cTheory of Mind\u201d, and \u201cmentalizing\u201d. An\nexample of everyday mindreading: you notice that Tom\u2019s\nfright embarrassed Mary and surprised Bill,\nwho had believed that Tom wanted to try\neverything. Mindreading is of crucial importance for our social life:\nour ability to predict, explain, and/or coordinate with others\u2019\nactions on countless occasions crucially relies on representing their\nmental states. For instance, by attributing to Steve the desire for a\nbanana and the belief that there are no more bananas at home but there\nare some left at the local grocery store, you can: (i)\nexplain why Steve has just left home; (ii) predict\nwhere Steve is heading; and (iii) coordinate your behavior\nwith his (meet him at the store, or prepare a surpise party while he\nis gone). Without mindreading, (i)\u2013(iii) do not come\neasily\u2014if they come at all. That much is fairly uncontroversial.\nWhat is controversial is how to explain mindreading. That is, how do\npeople arrive at representing others\u2019 mental states? This is the\nmain question to which the Simulation (or, mental simulation) Theory\n(ST) of mindreading offers an answer.\n\nCommon sense has it that, in many circumstances, we arrive at\nrepresenting others\u2019 mental states by putting ourselves in their\nshoes, or taking their perspective. For example, I can try to figure\nout my chess opponent\u2019s next decision by imagining what I would\ndecide if I were in her place. (Although we may also speak of this as\na kind of empathy, that term must be understood here without\nany implication of sympathy or benevolence.)\n\nST takes this commonsensical idea seriously and develops it into a\nfully-fledged theory. At the core of the theory, we find the thesis\nthat mental simulation plays a central role in mindreading:\nwe typically arrive at representing others\u2019 mental states by\nsimulating their mental states in our own mind. So, to figure out my\nchess opponent\u2019s next decision, I mentally switch roles with her\nin the game. In doing this, I simulate her relevant beliefs\nand goals, and then feed these simulated mental states into\nmy decision-making mechanism and let the mechanism produce a simulated\ndecision. This decision is projected on or attributed to the\nopponent. In other words, the basic idea of ST is that if the\nresources our own brain uses to guide our own behavior can be modified\nto work as representations of other people\u2019s mental states, then\nwe have no need to store general information about what makes people\ntick: we just do the ticking for them. Accordingly, ST challenges the\nTheory-Theory of mindreading (TT), the view that a tacit psychological\ntheory underlies the ability to represent and reason about\nothers\u2019 mental states. While TT maintains that mindreading is an\ninformation-rich and theory-driven process, ST sees it as\ninformationally poor and process driven (Goldman 1989).\n\nThis entry is organized as follows. In section 1 (The Origins and\nVarieties of ST), we briefly reconstruct ST\u2019s history and\nelaborate further on ST\u2019s main theoretical aims. We then go on\nto explain the very idea of mental simulation (section 2: What is\nMeant by \u201cMental Simulation\u201d?) In section 3 (Two Types of\nSimulation Processes), we consider the cognitive architecture\nunderlying mental simulation and introduce the distinction between\nhigh-level and low-level simulation processes. In section 4 (The Role\nof Mental Simulation in Mindreading), we discuss what role mental\nsimulation is supposed to play in mindreading, according to ST. This\ndiscussion carries over to section 5 (Simulation Theory and\nTheory-Theory), where we contrast the accounts of mindreading given by\nST and TT. Finally, section 6 (Simulation Theory: Pros and Cons)\nexamines some of the main arguments in favour of and against ST as\ntheory of mindreading.\n",
    "toc": [
        {
            "#OrigVariST": "1. The Origins and Varieties of ST"
        },
        {
            "#WhatMeanMentSimu": "2. What is Meant by \u201cMental Simulation\u201d?"
        },
        {
            "#MentSimuRese": "2.1 Mental Simulation as Resemblance"
        },
        {
            "#MentSimuReus": "2.2 Mental Simulation as Reuse"
        },
        {
            "#RelaStatProc": "2.3 Relations, States, and Processes"
        },
        {
            "#FinaWorr": "2.4 Final Worries"
        },
        {
            "#TwoTypeSimuProc": "3. Two Types of Simulation Processes"
        },
        {
            "#HighLeveSimuProc": "3.1 High-Level Simulation Processes"
        },
        {
            "#LowLeveSimuProc": "3.2 Low-Level Simulation Processes"
        },
        {
            "#RoleMentSimuMind": "4. The Role of Mental Simulation in Mindreading"
        },
        {
            "#CentMentSimuMind": "4.1 The Centrality of Mental Simulation in Mindreading"
        },
        {
            "#ConsCaus": "4.2 Constitution or Causation?"
        },
        {
            "#MindWithJudg": "4.3 Mindreading without Judgement "
        },
        {
            "#MindIntr": "4.4 Mindreading and Introspection"
        },
        {
            "#Summ": "4.5 Summary"
        },
        {
            "#SimuTheoTheoTheo": "5. Simulation Theory and Theory-Theory"
        },
        {
            "#TheoTheo": "5.1 The Theory-Theory"
        },
        {
            "#CollCoop": "5.2 Collapse or Cooperation?"
        },
        {
            "#SimuTheoProsCons": "6. Simulation Theory: Pros and Cons"
        },
        {
            "#MirrNeurCont": "6.1 The Mirror Neurons Controversy"
        },
        {
            "#SelfOthe": "6.2 Self and Others"
        },
        {
            "#DeveFind": "6.3 Developmental Findings"
        },
        {
            "#Conc": "7. Conclusion"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. The Origins and Varieties of ST\n\nThe idea that we often arrive at representing other people\u2019s\nmental states by mentally simulating those states in ourselves has a\ndistinguished history in philosophy and the human sciences. Robert\nGordon (1995) traces it back to David Hume (1739) and Adam\nSmith\u2019s (1759) notion of sympathy; Jane Heal (2003) and Gordon\n(2000) find simulationist themes in the Verstehen approach to\nthe philosophy of history (e.g., Dilthey 1894); Alvin Goldman (2006)\nconsiders Theodor Lipps\u2019s (1903) account of empathy\n(Einf\u00fchlung) as a precursor of the notion of mental\nsimulation.\n\nIn its modern guise, ST was established in 1986, with the publication\nof Robert Gordon\u2019s \u201cFolk Psychology as Simulation\u201d\nand Jane Heal\u2019s \u201cReplication and Functionalism\u201d.\nThese two articles criticized the Theory-Theory and introduced ST as a\nbetter account of mindreading. In his article, Gordon discussed\npsychological findings concerning the development of the capacity to\nrepresent others\u2019 false beliefs. This attracted the interest of\ndevelopmental psychologists, especially Paul Harris (1989, 1992), who\npresented empirical support for ST, and Alison Gopnik (Gopnik &\nWellman 1992) and Joseph Perner (Perner & Howes 1992), who argued\nagainst it\u2014Perner has since come to defend a hybrid version of\nST (Perner & K\u00fchberger 2005).\n\nAlvin Goldman was an early and influential defender of ST (1989) and\nhas done much to give the theory its prominence. His work with the\nneuroscientist Vittorio Gallese (Gallese & Goldman 1998) was the\nfirst to posit an important connection between ST and the newly\ndiscovered mirror neurons. Goldman\u2019s 2006 book Simulating\nMinds is the clearest and most comprehensive account to date of\nthe relevant philosophical and empirical issues. Among other\nphilosophical proponents of ST, Gregory Currie and Susan Hurley have\nbeen influential.\n\nSince the late 1980s, ST has been one of the central players in the\nphilosophical, psychological, and neuroscientific discussions of\nmindreading. It has however been argued that the fortunes of ST have\nhad a notable negative consequence: the expression \u201cmental\nsimulation\u201d has come to be used broadly and in a variety of\nways, making \u201cSimulation Theory\u201d a blanket term lumping\ntogether many distinct approaches to mindreading. Stephen Stich and\nShaun Nichols (1997) already urged dropping it in favor of a\nfiner-grained terminology. There is some merit to this. ST is in fact\nbetter conceived of as a family of theories rather than a\nsingle theory. All the members of the family agree on the thesis that\nmental simulation, rather than a body of knowledge about other minds,\nplays a central role in mindreading. However, different members of the\nfamily can differ from one another in significant respects.\n\nOne fundamental area of disagreement among Simulation Theorists is the\nvery nature of ST\u2014what kind of theory ST is supposed to\nbe\u2014and what philosophers can contribute to it. Some Simulation\nTheorists take the question \u201cHow do people arrive at\nrepresenting others\u2019 mental states?\u201d as a straightforward\nempirical question about the cognitive processes and mechanisms\nunderlying mindreading (Goldman 2006; Hurley 2008). According to them,\nST is thus a theory in cognitive science, to which\nphilosophers can contribute exactly as theoretical physicists\ncontribute to physics: \n\n\ntheorists specialize in creating and tweaking theoretical structures\nthat comport with experimental data, whereas experimentalists have the\nprimary job of generating the data. (Goldman 2006: 22) \n\n\nOther philosophical defenders of ST, however, do not conceive of\nthemselves as theoretical cognitive scientists at all. For example,\nHeal (1998) writes that: \n\n\nit is commonly taken that the inquiry into \u2026 the extent of\nsimulation in psychological understanding is empirical, and that\nscientific investigation is the way to tell whether ST \u2026 is\ncorrect. But this perception is confused. It is an a priori\ntruth \u2026 that simulation must be given a substantial role in our\npersonal-level account of psychological understanding. (Heal 1998:\n477\u2013478) \n\n\nAdjudicating this meta-philosophical dispute goes well beyond the aim\nof this entry. To be as inclusive as we can, we shall adopt a\n\u201cbalanced diet\u201d approach: we shall discuss the extent to\nwhich ST is supported by empirical findings from psychology and\nneuroscience, and, at the same time, we shall dwell on\n\u201cpurely philosophical\u201d problems concerning ST. We leave to\nthe reader the task of evaluating which aspects should be put at the\ncentre of the inquiry.\n\nImportantly, even those who agree on the general nature of ST might\ndisagree on other crucial issues. We will focus on what are typically\ntaken to be the three most important bones of contention among\nSimulation Theorists: what is meant by \u201cmental\nsimulation\u201d?\n (section 2).\n What types of simulation processes are there?\n (section 3).\n What is the role of mental simulation in mindreading?\n (section 4).\n After having considered what keeps Simulation Theorists apart, we\nshall move to discuss what holds them together, i.e., the opposition\nto the Theory-Theory of mindreading\n (section 5\n and\n section 6).\n This should give the reader a sense of the \u201cunity amidst\ndiversity\u201d that characterizes ST.\n2. What is Meant by \u201cMental Simulation\u201d?\n\nIn common parlance, we talk of putting ourselves in others\u2019\nshoes, or empathizing with other people. This talk is typically\nunderstood as adopting someone else\u2019s point of view, or\nperspective, in our imagination. For example, it is quite natural to\ninterpret the request \u201cTry to show some empathy for John!\u201d\nas asking you to use your imaginative capacity to consider the world\nfrom John\u2019s perspective. But what is it for someone to\nimaginatively adopt someone else\u2019s perspective? To a first\napproximation, according to Simulation Theorists, it consists of\nmentally simulating, or re-creating, someone\nelse\u2019s mental states. Currie and Ravenscroft (2002) make this\npoint quite nicely: \n\n\nImagination enables us to project ourselves into another situation and\nto see, or think about, the world from another perspective. These\nsituations and perspectives \u2026 might be those of another actual\nperson, [or] the perspective we would have on things if we believed\nsomething we actually don\u2019t believe, [or] that of a fictional\ncharacter. \u2026 Imagination recreates the mental states of\nothers. (Currie & Ravenscroft 2002: 1, emphasis added). \n\n\nThus, according to ST, empathizing with John\u2019s sadness consists\nof mentally simulating his sadness, and adopting Mary\u2019s\npolitical point of view consists of mentally simulating her political\nbeliefs. This is the intuitive and general sense of mental\nsimulation that Simulation Theorists have in mind.\n\nNeedless to say, this intuitive characterization of \u201cmental\nsimulation\u201d is loose. What exactly does it mean to say that a\nmental state is a mental simulation of another mental state? Clearly,\nwe need a precise answer to this question, if the notion of mental\nsimulation is to be the fundamental building block of a theory.\nSimulation Theorists, however, differ over how to answer this\nquestion. The central divide concerns whether \u201cmental\nsimulation\u201d should be defined in terms of resemblance\n(Heal 1986, 2003; Goldman 2006, 2008a) or in terms of reuse\n(Hurley 2004, 2008; Gallese & Sinigaglia 2011). We consider these\ntwo proposals in turn.\n2.1 Mental Simulation as Resemblance\n\nThe simplest interpretation of \u201cmental simulation\u201d in\nterms of resemblance goes like this:\n\n\n(RES-1) Token state M* is a mental simulation of token state\nM if and only if:\n\nBoth M and M* are mental states\n M* resembles M in some significant respects\n\n\n\nTwo clarifications are in order. First, we will elaborate on the\n\u201csignificant respects\u201d in which a mental state has to\nresemble another mental state in due course (see, in particular,\n section 3).\n For the moment, it will suffice to mention some relevant dimensions\nof resemblance: similar functional role; similar content; similar\nphenomenology; similar neural basis (an important discussion of this\ntopic is Fisher 2006). Second, RES-1 defines \u201cmental\nsimulation\u201d as a dyadic relation between\nmental states (the relation being a mental simulation of).\nHowever, the expression \u201cmental simulation\u201d is also often\nused to pick out a monadic property of mental states\n\u2014the property being a simulated mental state (as will\nbecome clear soon, \u201csimulated mental state\u201d does not refer\nhere to the state which is simulated, but to the state that does the\nsimulating). For example, it is common to find in the literature\nsentences like \u201cM* is a mental simulation\u201d. To\navoid ambiguities, we shall adopt the following terminological\nconventions:\n\n We shall use the expression \u201cmental simulation of\u201d to\nexpress the relation being a mental simulation of.\n We shall use the expression \u201csimulated mental state\u201d\nto express the property being a simulated mental state.\n We shall use the expression \u201cmental simulation\u201d in a\nway that is deliberately ambiguous between \u201cmental simulation\nof\u201d and \u201csimulated mental state\u201d.\n\n\nIt follows from this that, strictly speaking,\n RES-1\n is a definition of \u201cmental simulation of\u201d. Throughout\nthis entry, we shall characterize \u201csimulated mental state\u201d\nin terms of \u201cmental simulation of\u201d: we shall say that if\nM* is a mental simulation of M, then\nM* is a simulated mental\n state.[1]\n\nWith these clarifications in place, we will consider the strengths and\nweaknesses of\n RES-1.\n Suppose that Lisa is seeing a yellow banana. At the present moment,\nthere is no yellow banana in my own surroundings; thus, I cannot have\nthat (type of) visual experience. Still, I can visualize what\nLisa is seeing. Intuitively, my visual imagery of a yellow banana is a\nmental simulation of Lisa\u2019s visual experience.\n RES-1\n captures this, given that both my visual imagery and Lisa\u2019s\nvisual experience are mental states and the former resembles the\nlatter.\n\nRES-1,\n however, faces an obvious problem (Goldman 2006). The resemblance\nrelation is symmetric: for any x and y, if x\nresembles y, then y resembles x. Accordingly, it\nfollows from\n RES-1\n that Lisa\u2019s visual experience is a mental simulation of my\nvisual imagery. But this is clearly wrong. There is no sense in which\none person\u2019s perceptual experience can be a mental simulation of\nanother person\u2019s mental imagery (see Ramsey 2010 for other\ndifficulties with\n RES-1).\n\nIn order to solve this problem, Goldman (2006) proposes the following\nresemblance-based definition of \u201cmental simulation\nof\u201d:\n\n\n(RES-2) Token state M* is a mental simulation of token state\nM if and only if:\n\n Both M and M* are mental states\n M* resembles M in some significant respects\n In resembling M, M* fulfils at least one of its\nfunctions\n\n\n\nUnder the plausible assumption that one of the functions of visual\nimagery is to resemble visual experiences, RES-2 correctly predicts\nthat my visual imagery of a yellow banana counts as a mental\nsimulation of Lisa\u2019s visual experience. At the same time, since\nvisual experiences do not have the function of resembling visual\nimages, RES-2 does not run into the trouble of categorizing the former\nas a mental simulation of the latter.\n2.2 Mental Simulation as Reuse\n\nClearly,\n RES-2\n is a better definition of \u201cmental simulation of\u201d than\n RES-1.\n Hurley (2008), however, argued that it won\u2019t do either, since\nit fails to distinguish ST from its main competitor, i.e., the\nTheory-Theory (TT), according to which mindreading depends on a body\nof information about mental states and processes\n (section 5).\n The crux of Hurley\u2019s argument is this. Suppose that a token\nvisual image V* resembles a token visual experience V\nand, in doing so, fulfils one of its functions. In this case,\n RES-2\n is satisfied. But now suppose further that visualization works like a\ncomputer simulation: it generates its outputs on the basis of a body\nof information about vision. On this assumption,\n RES-2\n still categorizes V* as a mental simulation of V,\neven though V* has been generated by exactly the kind of\nprocess described by TT: a theory-driven and information-rich\nprocess.\n\nAccording to Hurley (who follows here a suggestion by Currie &\nRavenscroft 2002), the solution to this difficulty lies in the\nrealization that \u201cthe fundamental \u2026 concept of simulation\nis reuse, not resemblance\u201d (Hurley 2008: 758, emphasis\nadded). Hurley\u2019s reuse-based definition of \u201cmental\nsimulation of\u201d can be articulated as follows:\n\n\n(REU) Token state M* is a mental simulation of token state\nM if and only if:\n\n Both M and M* are mental states\n M is generated by token cognitive process P\n M* is generated by token cognitive process P*\n P is implemented by the use of a token cognitive\nmechanism of type C\n P* is implemented by the reuse of a token\ncognitive mechanism of type C\n\n\n\nTo have a full understanding of REU, we need to answer three\nquestions: (a) What is a cognitive process? (b) What is a\ncognitive mechanism? (c) What is the difference between\nusing and reusing a certain cognitive mechanism?\nLet\u2019s do it!\n\nIt is a commonplace that explanation in cognitive science is\nstructured into different levels. Given our aims, we can illustrate\nthis idea through the classical tri-level hypothesis\nformulated by David Marr (1982). Suppose that one wants to explain a\ncertain cognitive capacity, say, vision (or mindreading, or\nmoral judgment). The first level of explanation, the most abstract\none, consists in describing what the cognitive capacity\ndoes\u2014what task it performs, what problem it solves, what\nfunction it computes. For example, the task performed by vision is\nroughly \u201cto derive properties of the world from images of\nit\u201d (Marr 1982: 23). The second level of analysis specifies\nhow the task is accomplished: what algorithm our mind uses to\ncompute the function. Importantly, this level of analysis abstracts\nfrom the particular physical structures that implement the algorithm\nin our head. It is only at the third level of analysis that the\ndetails of the physical implementation of the algorithm in\nour brain are spelled out.\n\nWith these distinctions at hand, we can answer questions (a) and (b).\nA cognitive process is a cognitive capacity considered as an\ninformation-processing activity and taken in abstraction from its\nphysical implementation. Thus, cognitive processes are individuated in\nterms of what function they perform and/or in terms of what algorithms\ncompute these functions (fair enough, the \u201cand/or\u201d is a\nvery big deal, but it is something we can leave aside here). This\nmeans that the same (type of) cognitive process can be multiply\nrealized in different physical structures. For example, parsing\n(roughly, the cognitive process that assigns a grammatical structure\nto a string of signs) can be implemented both by a human brain and a\ncomputer. On the contrary, cognitive mechanisms are\nparticular (types of) physical structures\u2014e.g., a certain part\nof the brain\u2014implementing certain cognitive processes. More\nprecisely, cognitive mechanisms are organized structures carrying out\ncognitive processes in virtue of how their constituent parts interact\n(Bechtel 2008; Craver 2007; Machamer et al. 2000).\n\nWe now turn to question (c), which concerns the distinction between\nuse and reuse of a cognitive mechanism. At a first approximation, a\ncognitive mechanism is used when it performs its primary\nfunction, while it is reused when it is activated to perform\na different, non-primary function. For example, one is using\none\u2019s visual mechanism when one employs it to see, while one is\nreusing it when one employs it to conjure up a visual image\n(see Anderson 2008, 2015 for further discussion of the notion of\nreuse). All this is a bit sketchy, but it will do.\n\nLet\u2019s now go back to\n REU.\n The main idea behind it is that whether a mental state is a mental\nsimulation of another mental state depends on the cognitive\nprocesses generating these two mental states, and on the\ncognitive mechanisms implementing such cognitive processes.\nMore precisely, in order for mental state M* to be a mental\nsimulation of mental state M, it has to be case that:\n(i) cognitive processes P* and P, which\nrespectively generate M* and M, are both implemented by\nthe same (type of) cognitive mechanism C; (ii) P is\nimplemented by the use of C, while P* is\nimplemented by the reuse of C. \n\nNow that we know what\n REU\n means, we can consider whether it fares better than\n RES-2\n in capturing the nature of the relation of mental simulation. It\nwould seem so. Consider this hypothetical scenario. Lisa is seeing a\nyellow banana, and her visual experience has been generated by\ncognitive process V1, which has been implemented by\nthe use of her visual mechanism. I am visualizing a yellow banana, and\nmy visual image has been generated by cognitive process\nV2, which has been implemented by the reuse of my\nvisual mechanism. Rosanna-the-Super-Reasoner is also visualizing a\nyellow banana, but her visual image has been generated by an\ninformation-rich cognitive process: a process drawing upon\nRosanna\u2019s detailed knowledge of vision and implemented by her\nincredibly powerful reasoning mechanism.\n REU\n correctly predicts that my visual image is a mental simulation of\nLisa\u2019s visual experience, but not vice versa. More importantly,\nit also predicts that Rosanna\u2019s visual image does not count as a\nmental simulation of Lisa\u2019s visual experience, given that\nRosanna\u2019s cognitive process was not implemented by the reuse of\nthe visual mechanism. In this way,\n REU\n solves the problem faced by\n RES-2\n in distinguishing ST from TT.\n\nShould we then conclude that \u201cmental simulation of\u201d has to\nbe defined in terms of reuse, rather than in terms of resemblance?\nGoldman (2008a) is still not convinced. Suppose that while Lisa is\nseeing a yellow banana, I am using my visual mechanism to visualize\nthe Golden Gate Bridge. Now, even though Lisa\u2019s visual\nexperience and my visual image have been respectively generated by the\nuse and the reuse of the visual mechanism, it would be bizarre to say\nthat my mental state is a mental simulation of Lisa\u2019s. Why?\nBecause my mental state doesn\u2019t resemble Lisa\u2019s (she is\nseeing a yellow banana; I am visualizing the Golden Gate Bridge!)\nThus\u2014Goldman concludes\u2014resemblance should be taken as\nthe central feature of mental simulation.\n2.3 Relations, States, and Processes\n\nIn order to overcome the difficulties faced by trying to define\n\u201cmental simulation of\u201d in terms of either\nreplication or reuse, philosophers have built on the insights\nof both RES and\n REU\n and have proposed definitions that combine replication and reuse\nelements (Currie & Ravenscroft 2002; in recent years, Goldman\nhimself seems to have favoured a mixed account; see Goldman 2012a).\nHere is one plausible definition:\n\n\n(RES+REU) Token state M* is a mental simulation of token state\nM if and only if:\n\n Both M and M* are mental states\n M* resembles M in some significant respects\n M is generated by token cognitive process P\n M* is generated by token cognitive process P*\n P is implemented by the use of a token cognitive\nmechanism of type C\n P* is implemented by the reuse of a token\ncognitive mechanism of type C\n\n\n\nRES+REU has at least three important virtues. The first is\nthat it solves all the aforementioned problems for RES and\n REU\u2014we\n leave to the reader the exercise of showing that this is indeed the\ncase.\n\nThe second is that it fits nicely with an idea that loomed\nlarge in the simulationist literature: the idea that simulated\nmental states are \u201cpretend\u201d (\u201cas if\u201d,\n\u201cquasi-\u201d) states\u2014imperfect copies of, surrogates\nfor, the \u201cgenuine\u201d states normally produced by a certain\ncognitive mechanism, obtained by taking this cognitive mechanism\n\u201coff-line\u201d. Consider the following case. Frank is in front\nof Central Caf\u00e9 (and believes that he is\nthere). He desires to drink a beer and believes that\nhe can buy one at Central Caf\u00e9. When he feeds these\nmental states into his decision-making mechanism, the mechanism\nimplements a decision-making process, which outputs the\ndecision to enter the caf\u00e9. In this case,\nFrank\u2019s decision-making mechanism was\n\u201con-line\u201d\u2014i.e., he used it; he employed it\nfor its primary function. My situation is different. I don\u2019t\nbelieve I am in front of Central Caf\u00e9, nor do I desire\nto drink a beer right now. Still, I can imagine believing and desiring\nso. When I feed these imagined states into my decision-making\nmechanism, I am not employing it for its primary function. Rather, I\nam taking it off-line (I am reusing it). As a result, the\ncognitive process implemented by my mechanism will output a merely\nimagined decision to enter the caf\u00e9. Now, it seems fair to\nsay that my imagined decision resembles Frank\u2019s decision (more\non this in\n section 3).\n If you combine this with how these two mental states have been\ngenerated, the result is that my imagined decision is a mental\nsimulation of Frank\u2019s decision, and thus it is a simulated\nmental state. It is also clear why Frank\u2019s decision is\ngenuine, while my simulated mental state is just a\npretend decision: all else being equal, Frank\u2019s\ndecision to enter Central Caf\u00e9 will cause him to enter\nthe caf\u00e9; on the contrary, no such behaviour will result from\nmy simulated decision. I have not really decided so. Mine was\njust a quasi-decision\u2014an imperfect copy of, a surrogate\nfor, Frank\u2019s genuine decision.\n\nAnd here is\n RES+REU\u2019s\n third virtue. So far, we have said that \u201cmental\nsimulation\u201d can either pick out a dyadic relation between mental\nstates or a monadic property of mental states. In fact, its ambiguity\nruns deeper than this, since philosophers and cognitive scientists\nalso use \u201cmental simulation\u201d to refer to a monadic\nproperty of cognitive processes, namely, the property\nbeing a (mental) simulation process (or: \u201cprocess of\nmental simulation\u201d, \u201csimulational process\u201d,\n\u201csimulative process\u201d, etc.) As a first stab, a (mental)\nsimulation process is a cognitive process generating simulated mental\nstates.\n RES+REU\n has the resources to capture this usage of \u201cmental\nsimulation\u201d too. Indeed,\n RES+REU\nimplicitly contains the following definition of\n\u201csimulation process\u201d:\n\n\n(PROC): Token process P* is a (mental) simulation process if\nand only if:\n\n P* generates token state M*\n M* resembles another token state, M, in some\nsignificant respects\n Both M and M* are mental states\n M is generated by token process P\n Both P and P* are cognitive processes\n P is implemented by the use of a token cognitive\nmechanism of type C\n P* is implemented by the reuse of a token\ncognitive mechanism of type C\n\n\n\nGo back to the case in which Lisa was having a visual experience of a\nyellow banana, while I was having a visual image of a yellow banana.\nOur two mental states resembled one another, but different cognitive\nprocesses generated them: seeing in Lisa\u2019s case, and\nvisualizing in my case. Moreover, Lisa\u2019s\nseeing was implemented by the use of the visual mechanism,\nwhile my visualizing was implemented by its reuse. According\nto PROC, the latter cognitive process, but not the former, was thus a\nsimulation process.\n\nTo sum up,\n RES+REU\n captures many of the crucial features that Simulation Theorists\nascribe to mental simulation. For this reason, we shall adopt it as\nour working definition of \u201cmental simulation\nof\u201d\u2014consequently, we shall adopt PROC as a definition of\n\u201csimulated mental\n state\u201d.[2]\n We can put this into a diagram.\n\n\n\nFigure 1\n\n\nThe hexagon at the bottom depicts a cognitive mechanism C (it\ncould be, say, the visual mechanism). When C is used (arrow on\nthe left), it implements cognitive process P (say, seeing);\nwhen it is re-used (arrow on the right), it implements cognitive\nprocess P* (say, visualizing). P generates mental state\nM (say, a visual experience of a red tomato), while P*\ngenerates mental state M* (say, a visual image of a red\ntomato). These two mental states (M and M*) resemble one\nanother. Given this: M* is a mental simulation of\nM; M* is a simulated mental state; and\nP* is a simulation\n process.[3]\n2.4 Final Worries\n\nIn this section, we shall finally consider three worries raised for\nadopting\n RES+REU\n as a definition of \u201cmental simulation of\u201d. If you have\nalready had enough of\n RES+REU,\n please feel free to move straight to\n section 3.\n\nHeal (1994) pointed out a problem with committing ST to a particular\naccount of the cognitive mechanisms that underlie it. Suppose that the\nhuman mind contains two distinct decision-making mechanisms:\nMec1, which takes beliefs and desires as input, and generates\ndecisions as output; and Mec2, which works by following\nexactly the same logical principles as Mec1, but takes\nimagined beliefs and imagined desires as input and generates imagined\ndecisions as output. Consider again Frank\u2019s decision to enter\nCentral Caf\u00e9 and my imagined decision to do so.\nAccording to the two mechanisms hypothesis, Frank desired to drink a\nbeer and believed that he could buy one at Central\nCaf\u00e9, fed these mental states into Mec1, which\ngenerated the decision to enter the caf\u00e9. As for me, I fed the\nimagined desire to drink a beer and the imagined belief that I could\nbuy one at Central Caf\u00e9 into a distinct (type of)\nmechanism, i.e., Mec2, which generated the imagined decision\nto enter Central Caf\u00e9. Here is the question: does my\nimagined decision to enter Central Caf\u00e9 count as a\nmental simulation of Frank\u2019s decision to do so? If your answer\nis \u201cYes, it does\u201d, then\n RES+REU\n is in trouble, since my imagined decision was not generated by\nreusing the same (type of) cognitive mechanism that Frank used to\ngenerate his decision; his decision was generated by Mec1, my\nimagined decision by Mec2. Thus, Heal concludes, a definition\n\u201cmental simulation of\u201d should not contain any commitment\nabout cognitive mechanisms\u2014it should not make any implementation\nclaim\u2014but should be given at a more abstract level of\ndescription.\n\nIn the face of this difficulty, a defender of\n RES+REU\n can say the following. First, she might reject the intuition that, in\nthe two mechanisms scenario, my imagined decision counts as a mental\nsimulation of Frank\u2019s decision. At a minimum, she might say that\nthis scenario does not elicit any robust intuition in one direction or\nthe other: it is not clear whether these two mental states stand in\nthe relation being a mental simulation of. Second, she might\ndownplay the role of intuitions in the construction of a definition\nfor \u201cmental simulation of\u201d and cognate notions. In\nparticular, if she conceives of ST as an empirical theory in cognitive\nscience, she will be happy to discount the evidential value of\nintuitions if countervailing theoretical considerations are\navailable. This, e.g., is Currie and Ravenscroft\u2019s (2002)\nposition, who write that \n\n\nthere are two reasons \u2026 why the Simulation Theorist should\nprefer [a one mechanism hypothesis]: \u2026 first, the postulation\nof two mechanisms is less economical than the postulation of one;\nsecond, \u2026 we have very good reasons to think that\nimagination-based decision making does not operate in isolation from\nthe subject\u2019s real beliefs and desires. \u2026 If imagination\nand belief operate under a system of inferential apartheid\u2014as\nthe two-mechanisms view has it\u2014how could this happen? (Currie\n& Ravenscroft 2002: 67\u201368)\n\n\nA second worry has to do with the fact that\n RES+REU\n appears to be too liberal. Take this case. Yesterday, Angelina had\nthe visual experience of a red apple. On the night of June 15, 1815,\nNapoleon conjured up the visual image of a red apple. Angelina used\nher visual mechanism to see, while Napoleon reused his to imagine. If\nwe add to this that Napoleon\u2019s mental state resembled\nAngelina\u2019s,\n RES+REU\n predicts that Napoleon\u2019s (token) visual image was a mental\nsimulation of Angelina\u2019s (token) visual experience. This might\nstrike one as utterly bizarre. In fact, not only did Napoleon not\nintend to simulate Angelina\u2019s experience: he could\nnot even have intended to do it. After all, Angelina was born\nroughly 150 years after Napoleon\u2019s death. By the same token, it\nis also impossible that Napoleon\u2019s visual image has been\ncaused by Angelina\u2019s visual experience. As a matter of\nfact, the visual image Napoleon had on the night of June 15, 1815 is\nentirely disconnected from the visual experience that\nAngelina had yesterday. Thus, how could the former be a mental\nsimulation of the latter? If you think about it, the problem is even\nworse than this.\n RES+REU\n has it that Napoleon\u2019s visual image of a red apple is a mental\nsimulation of all the visual experiences of a red apple that\nhave obtained in the past, that are currently obtaining, and that will\nobtain in the future. Isn\u2019t that absurd?\n\nAgain, a defender of\n RES+REU\n can give a two-fold answer. First, she can develop an argument that\nthis is not absurd at all. Intuitively, the following principle seems\nto be true:\n\n\n(TYPE): the mental state type visual image of a red apple is\na mental simulation of the mental state type visual experience of\na red apple.\n\n\nIf TYPE is correct, then the following principle has to be true as\nwell:\n\n\n(TOKEN): Any token mental state of the type visual image of a red\napple is a mental simulation of every token mental state of the\ntype visual experience of a red apple.\n\n\nBut TOKEN entails that Napoleon\u2019s (token) visual image of a red\napple is a mental simulation of Angelina\u2019s (token) visual\nexperience of a red apple, which is exactly what\n RES+REU\n predicts. Thus,\n RES+REU\u2019s\n prediction, rather than being absurd, independently follows from\nquite intuitive assumptions. Moreover, even though TOKEN and\n RES+REU\n make the same prediction about the Napoleon-Angelina case, TOKEN is\nnot entailed by\n RES+REU,\n since the latter contains a restriction on how visual images\nhave to be generated. Thus, if one finds TOKEN intuitively acceptable,\nit is hard to see how one can find\n RES+REU\n to be too liberal.\n\nThe second component of the answer echoes one of the answers given to\nHeal: for a Simulation Theorist who conceives of ST as a theory in\ncognitive science, intuitions have a limited value in assessing a\ndefinition of \u201cmental simulation of\u201d. In fact, the main\naim of this definition is not that of capturing folk intuitions, but\nrather that of offering a clear enough picture of the relation of\nmental simulation on the basis of which an adequate theory of\nmindreading can be built. So, if the proposed definition fails, say,\nto help distinguishing ST from TT, or is of limited use in\ntheory-building, or is contradicted by certain important results from\ncognitive science, then one has a good reason to abandon it. On the\ncontrary, it should not be a cause for concern if\n RES+REU\n does not match the folk concept MENTAL SIMULATION OF. The notion\n\u201cmental simulation of\u201d is a term of art\u2014like, say,\nthe notions of I-Language or of Curved Space. These notions\ndo poorly match the folk concepts of language and space, but\nlinguists and physicists do not take this to be a problem. The same\napplies to the notion of mental simulation.\n\nAnd here is the third and final worry.\n RES+REU\n is supposed to be a definition of \u201cmental simulation of\u201d\non the basis of which a theory of mindreading can be built. However,\nneither\n RES+REU\n nor\n PROC\n make any reference to the idea of representing others\u2019 mental\nstates. Thus, how could these definitions help us to construct a\nSimulation Theory of mindreading? The answer is simple: they\nwill help us exactly as a clear definition of\n\u201ccomputation\u201d, which has nothing to do with how the mind\nworks, helped to develop the Computational Theory of Mind (see entry\non\n computational theory of mind).\n\nHere is another way to make the point. ST is made up of two\ndistinct claims: the first is that mental simulation is\npsychologically real, i.e., that there are mental states and processes\nsatisfying\n RES+REU\n and\n PROC.\n The second claim is that mental simulation plays a central role in\nmindreading. Clearly, the second claim cannot be true if the first is\nfalse. However, the second claim can be false even if the first claim\nis true: mental simulation could be psychologically real, but play no\nrole in mindreading at all. Hence, Simulation Theorists have to do\nthree things. First, they have to establish that mental simulation is\npsychologically real. We consider this issue in\n section 3.\n Second, they have to articulate ST as a theory of\nmindreading. That is, they have to spell out in some detail the\ncrucial role that mental simulation is supposed to play in\nrepresenting others\u2019 mental states, and contrast the resulting\ntheory with other accounts of mindreading. We dwell on this in\nsections\n 4\n and\n 5.\n Finally, Simulation Theorists have to provide evidence in support of\ntheir theory of mindreading\u2014that is, they have to give us good\nreasons to believe that mental simulation does play a crucial role in\nrepresenting others\u2019 mental states. We discuss this issue in\n section 6.\n3. Two Types of Simulation Processes\n\nNow that we have definitions of \u201cmental simulation of\u201d and\ncognate notions, it is time to consider which mental states and\nprocesses satisfy them, if any. Are there really simulated mental\nstates? That is, are there mental states generated by the\nreuse of cognitive mechanisms? And do these mental states\nresemble the mental states generated by the use of such\nmechanisms? For example, is it truly the case that visual images are\nmental simulations of visual experiences? What about\ndecisions, emotions, beliefs, desires, and bodily sensations? Can our\nminds generate simulated counterparts of all these types of mental\nstates? In this section, we consider how Simulation Theorists have\ntackled these problems. We will do so by focusing on the following\nquestion: are there really simulation processes (as defined\nby\n PROC)?\n If the answer to this question is positive, it follows that there are\nmental states standing in the relation of mental simulation (as\ndefined by\n RES+REU),\n and thus simulated mental states.\n\nFollowing Goldman (2006), it has become customary among Simulation\nTheorists to argue for the existence of two types of simulation\nprocesses: high-level simulation processes and\nlow-level simulation processes (see, however, de Vignemont\n2009). By exploring this distinction, we begin to articulate the\ncognitive architecture underlying mental simulation proposed by\nST.\n3.1 High-Level Simulation Processes\n\nHigh-level simulation processes are cognitive processes with the\nfollowing features: (a) they are typically conscious, under voluntary\ncontrol, and stimulus-independent; (b) they satisfy\n PROC,\n that is, they are implemented by the reuse of a certain\ncognitive mechanism, C, and their output states\nresemble the output states generated by the use of\n C.[4]\n Here are some cognitive processes that, according to Simulation\nTheorists, qualify as high-level simulation processes. Visualizing:\nthe cognitive process generating visual images (Currie 1995; Currie\n& Ravenscroft 2002; Goldman 2006); motor imagination: the\ncognitive process generating imagined bodily movements and actions\n(Currie & Ravenscroft 1997, 2002; Goldman 2006); imagining\ndeciding: the cognitive process generating decision-like imaginings\n(Currie & Ravenscroft 2002); imagining believing: the cognitive\nprocess generating belief-like imaginings (Currie & Ravenscroft\n2002); imagining desiring: the cognitive process generating\ndesire-like imaginings (Currie 2002). In what follows, we shall\nconsider a couple of them in some detail.\n\nVisualizing first. It is not particularly hard to see why visualizing\nsatisfies condition (a). Typically: one can decide to visualize (or\nstop visualizing) something; the process is not driven by perceptual\nstimuli; and at least some parts of the visualization process are\nconscious. There might be cases in which visualizing is not under\nvoluntary control, is stimulus-driven and, maybe, even entirely\nunconscious. This, however, is not a problem, since we know that there\nare clear cases satisfying (a).\n\nUnsurprisingly, the difficult task for Simulation Theorists is to\nestablish that visualizing has feature (b), that is: it is implemented\nby the reuse of the visual mechanism; and its outputs (that\nis, visual images) resemble genuine visual experiences.\nSimulation Theorists maintain that they have strong empirical evidence\nsupporting the claim that visualizing satisfies\n PROC.\n Here is a sample (this and further evidence is extensively discussed\nin Currie 1995, Currie & Ravenscroft 2002, and in Goldman\n2006):\n\n visualizing recruits some of the brain areas involved in vision\n(Kosslyn et al. 1999);\n left-neglect patients have the same deficit in both seeing and\nvisualizing\u2014i.e., they do not have perceptual experience of the\nleft half of the visual space and they also fail to imagine the left\nhalf of the imagined space (Bisiach & Luzzatti 1978);\n ocular movements occurring during visualizing approximate those\nhappening during seeing (Spivey et al. 2000);\n some patients systematically mistake visual images for perceptual\nstates (Goldenberg et al. 1995);\n visual perception and visualizing exhibit similar patterns of\ninformation-processing (facilitations, constraints, illusions) (Decety\n& Michel 1989; Kosslyn et al. 1999)\n\n\nOn this basis, Simulation Theorists conclude that visualizing is\nindeed implemented by the reuse of the visual mechanism\n(evidence i and ii) and that its outputs, i.e., visual images, do\nresemble visual experiences (evidence iii, iv, and v). Thus,\nvisualizing is a process that qualifies as high-level simulation, and\nvisual images are simulated mental states.\n\nVisual images are mental simulations of perceptual states. Are there\nhigh-level simulation processes whose outputs instead are mental\nsimulations of propositional attitudes? (If you think that visual\nexperiences are propositional attitudes, you can rephrase the question\nas follows: are there high-level simulation processes whose outputs\nare mental simulations of non-sensory states?) Three candidate\nprocesses have received a fair amount of attention in the\nsimulationist literature: imagining desiring, imagining deciding, and\nimagining believing. The claims made by Simulation Theorists about\nthese cognitive processes and their output states have generated an\nintense debate (Doggett & Egan 2007; Funkhouser & Spaulding\n2009; Kieran & Lopes 2003; Nichols 2006a, 2006b; Nichols &\nStich 2003; Velleman 2000). We do not have space to review it here\n(two good entry points are the introduction to Nichols 2006a and the\nentry on\n imagination).\n Rather, we shall confine ourselves to briefly illustrating the\nsimulationist case in favour of the thesis that imagining believing is\na high-level simulation process.\n\nI don\u2019t believe that Rome is in France, but I can imagine\nbelieving it. Imagining believing typically is a conscious,\nstimulus-independent process, under voluntary control. Thus, imagining\nbelieving satisfies condition (a). In order for it to count as an\ninstance of high-level simulation process, it also needs to\nhave feature (b), that is: (b.i) its outputs (i.e., belief-like\nimaginings) have to resemble genuine beliefs in some\nsignificant respects; (b.ii) it has to be implemented by the\nreuse of the cognitive mechanism (whose use implements the\ncognitive process) that generates genuine beliefs\u2014let us call it\n\u201cthe belief-forming mechanism\u201d. Does imagining believing\nsatisfy (b)? Currie and Ravenscroft (2002) argue in favour of (b.i).\nBeliefs are individuated in terms of their content and functional\nrole. Belief-like imaginings\u2014Currie and Ravenscroft\nsay\u2014have the same content and a similar functional role to their\ngenuine counterparts. For example, the belief that Rome is in France\nand the belief-like imagining that Rome is in France have exactly the\nsame propositional content: that Rome is in France. Moreover,\nbelief-like imaginings mirror the inferential role of genuine beliefs.\nIf one believes both that Rome is in France and that French is the\nlanguage spoken in France, one can infer the belief that French is the\nlanguage spoken in Rome. Analogously, from the belief-like imagining\nthat Rome is in France and the genuine belief that French is the\nlanguage spoken in France, one can infer the belief-like imagining\nthat French is the language spoken in Rome. So far, so good (but see\nNichols 2006b).\n\nWhat about (b.ii)? Direct evidence bearing on it is scarce. However,\nSimulation Theorists can give an argument along the following lines.\nFirst, one owes an explanation of why belief-like imaginings are,\nwell, belief-like\u2014as we have said above, it seems that they have\nthe same type of content as, and a functional role similar to, genuine\nbeliefs. A possible explanation for this is that both types of mental\nstates are generated by (cognitive processes implemented by) the same\ncognitive mechanism. Second, it goes without saying that our mind\ncontains a mechanism for generating beliefs (the belief-forming\nmechanism), and that there must be some mechanism or another in charge\nof generating belief-like imaginings. It is also well known that\ncognitive mechanisms are evolutionary costly to build and maintain.\nThus, evolution might have adopted the parsimonious strategy of\nredeploying a pre-existing mechanism (the belief-forming mechanism)\nfor a non-primary function, i.e., generating belief-like\nimaginings\u2014in general, this hypothesis is also supported by the\nidea that neural reuse is one of the fundamental organizational\nprinciple of the brain (Anderson 2008). If one puts these two strands\nof reasoning together, one gets a prima facie case for the\nclaim that imagining believing is implemented by the reuse of the\nbelief-forming mechanism\u2014that is, a prima facie case\nfor the conclusion that imagining believing satisfies (b.ii). Since\nimagining believing appears also to satisfy (b.i) and (a), lacking\nevidence to the contrary, Simulation Theorists are justified in\nconsidering it to be a high-level simulation process.\n\nLet\u2019s take stock. We have examined a few suggested instances of\nhigh-level simulation processes. If Simulation Theorists are correct,\nthey exhibit the following commonalities: they satisfy\n PROC\n (this is why they are simulation processes); they are\ntypically conscious, under voluntary control, and stimulus-independent\n(this is why they are high-level). Do they have some other\nimportant features in common? Yes, they do\u2014Simulation Theorists\nsay. They all are under the control of a single cognitive\nmechanism: imagination (more precisely, Currie & Ravenscroft\n(2002) talk of Re-Creative Imagination, while Goldman (2006, 2009)\nuses the expression \u201cEnactment Imagination\u201d). The\nfollowing passage will give you the basic gist of the proposal:\n\n\nWhat is distinctive to high-level simulation is the psychological\nmechanism \u2026 that produces it, the mechanism of imagination.\nThis psychological system is capable of producing a wide variety of\nsimulational events: simulated seeings (i.e., visual imagery),\n\u2026 simulated motor actions (motor imagery), simulated beliefs,\n\u2026 and so forth. \u2026 In producing simulational outputs,\nimagination does not operate all by itself. \u2026 For example, it\nrecruits parts of the visual system to produce visual imagery\n\u2026. Nonetheless, imagination \u201c\u2018takes the\nlead\u201d\u2019 in directing or controlling the other systems it\nenlists for its project. (Goldman 2009: 484\u201385)\n\n\nHere is another way to make the point. We already know that, according\nto ST, visualizing is implemented by the reuse of the visual\nmechanism. In the above passage, Goldman adds that the reuse of the\nvisual mechanism is initiated, guided and controlled by imagination.\nThe same applies, mutatis mutandis, to all cases of\nhigh-level simulation processes. For example, in imagining hearing,\nimagination \u201cgets in control\u201d of the auditory mechanism,\ntakes it off-line, and (re)uses it to generate simulated auditory\nexperiences. Goldman (2012b, Goldman & Jordan 2013) supports this\nclaim by making reference to neuroscientific data indicating that the\nsame core brain network, the so-called \u201cdefault network\u201d,\nsubserves all the following self-projections: prospection (projecting\noneself into one\u2019s future); episodic memory (projecting oneself\ninto one\u2019s past); perspective taking (projecting oneself into\nother minds); and navigation (projecting oneself into other places)\n(see Buckner & Carroll 2007 for a review). These different\nself-projections presumably involve different high-level simulation\nprocesses. However, they all have something in common: they all\ninvolve imagination-based perspectival shifts. Therefore, the fact\nthat there is one brain network common to all these self-projections\nlends some support to the claim that there is one common cognitive\nmechanism, i.e., imagination, which initiates, guides, and controls\nall high-level simulation processes. \n\nIf Goldman is right, and all high-level simulation processes are\nguided by imagination, we can then explain why, in our common\nparlance, we tend to describe high-level simulation processes and\noutputs in terms of imaginings, images, imagery, etc. More\nimportantly, we can also explain why high-level simulation processes\nare conscious, under voluntary control, and stimulus-independent.\nThese are, after all, typical properties of imaginative processes.\nHowever, there are simulation processes that typically are neither\nconscious, nor under voluntary control, nor stimulus independent. This\nindicates that they are not imagination-based. It is to this other\ntype of simulation processes that we now turn.\n3.2 Low-Level Simulation Processes\n\nLow-level simulation processes are cognitive processes with these\nfeatures: (a*) they are typically unconscious, automatic, and\nstimulus-driven; (b) they satisfy\n PROC,\n that is, they are implemented by the reuse of a certain\ncognitive mechanism, C, and their output states\nresemble the output states generated by the use of C.\nWhat cognitive processes are, according to ST, instances of low-level\nsimulation? The answer can be given in two words: mirroring processes.\nClarifying what these two words mean, however, will take some\ntime.\n\nThe story begins at the end of the 1980s in Parma, Italy, where the\nneuroscientist Giacomo Rizzolatti and his team were investigating the\nproperties of the neurons in the macaque monkey ventral premotor\ncortex. Through single-cell recording experiments, they discovered\nthat the activity of neurons in the area F5 is correlated with\ngoal-directed motor actions and not with particular movements\n(Rizzolatti et al. 1988). For example, some F5 neurons fire when the\nmonkey grasps an object, regardless of whether the monkey uses the\nleft or the right hand. A plausible interpretation of these results is\nthat neurons in monkey area F5 encode motor intentions (i.e.,\nthose intentions causing and guiding actions like reaching, grasping,\nholding, etc.) and not mere kinematic instructions (i.e.,\nthose representations specifying the fine-grained motor details of an\naction). (In-depth philosophical analyses of the notion of motor\nintention can be found in: Brozzo forthcoming; Butterfill &\nSinigaglia 2014; Pacherie 2000). This was an already interesting\nresult, but it was not what the Parma group became famous for. Rather,\ntheir striking discovery happened a few years later, helped by\nserendipity. Researchers were recording the activity of F5 neurons in\na macaque monkey performing an object-retrieval task. In between\ntrials, the monkey stood still and watched an experimenter setting up\nthe new trial, with microelectrodes still measuring the monkey\u2019s\nbrain activity. Surprisingly, some of the F5 neurons turned out to\nfire when the monkey saw the experimenter grasping and\nplacing objects. This almost immediately led to new experiments, which\nrevealed that a portion of F5 neurons not only fire when the monkey\nperforms a certain goal-directed motor action (say, bringing a piece\nof food to the mouth), but also when it sees another agent performing\nthe same (type of) action (di Pellegrino et al. 1992; Gallese et al.\n1996; Rizzolatti et al. 1996). For this reason, these neurons were\naptly called \u201cmirror neurons\u201d, and it was\nproposed that they encode motor intentions both during action\nexecution and action observation (Rizzolatti & Sinigaglia 2007,\nforthcoming). Later studies found mirror neurons also in the macaque\nmonkey inferior parietal lobule (Gallese et al. 2002), which together\nwith the ventral premotor cortex constitutes the monkey cortical\nmirror neuron circuit (Rizzolatti & Craighero 2004).\n\nSubsequent evidence suggested that an action mirror\nmechanism\u2014that is, a cognitive mechanism that gets\nactivated both when an individual performs a certain goal-directed\nmotor action and when she sees another agent performing the same\naction\u2014also exists in the human brain (for reviews, see\nRizzolatti & Craighero 2004, and Rizzolatti & Sinigaglia\nforthcoming). In fact, it appears that there are mirror\nmechanisms in the human brain outside the action domain as well:\na mirror mechanism for disgust (Wicker et al. 2003), one for pain\n(Singer at al. 2004; Avenanti et al. 2005), and one for touch\n(Blakemore et al. 2005). Given the variety of mirror mechanisms, it is\nnot easy to give a definition that fits them all. Goldman (2008b) has\nquite a good one though, and we will draw from it: a cognitive\nmechanism is a mirror mechanism if and only if it gets activated both\nwhen an individual undergoes a certain mental event\nendogenously and when she perceives a sign that\nanother individual is undergoing the same (type of) mental event. For\nexample, the pain mirror mechanism gets activated both when\nindividuals experience \u201ca painful stimulus and \u2026 when\nthey observe a signal indicating that [someone else] is receiving a\nsimilar pain stimulus\u201d (Singer et al. 2004: 1157).\n\nHaving introduced the notions of mirror neuron and mirror mechanism,\nwe can define the crucial notion of this section: mirroring\nprocess. We have seen that mirror mechanisms can get activated in\ntwo distinct modes: (i) endogenously; (ii) in the perception mode. For\nexample, my action mirror mechanism gets endogenously activated when I\ngrasp a mug, while it gets activated in the perception mode when I see\nyou grasping a mug. Following again Goldman (2008b), let us say that a\ncognitive process is a mirroring process if and only if it is\nconstituted by the activation of a mirror mechanism in the\nperception mode. For example, what goes on in my brain when I see\nyou grasping a mug counts as a mirroring process.\n\nNow that we know what mirroring processes are, we can return to our\ninitial problem\u2014i.e., whether they are low-level simulation\nprocesses (remember that a cognitive process is a low-level simulation\nprocess if and only if: (a*) it is typically unconscious, automatic,\nand stimulus-driven; (b) it satisfies\n PROC).\n For reasons of space, we will focus on disgust mirroring only.\n\nWicker et al. (2003) carried out an fMRI study in which participants\nfirst observed videos of disgusted facial expressions and subsequently\nunderwent a disgust experience via inhaling foul odorants. It turned\nout that the same neural area\u2014the left anterior\ninsula\u2014that was preferentially activated during the experience\nof disgust was also preferentially activated during the observation of\nthe disgusted facial expressions. These results indicate the existence\nof a disgust mirror mechanism. Is disgust mirroring\n(the activation of the disgust mirror mechanism in the perception\nmode) a low-level simulation process? Simulation Theorists answer in\nthe affirmative.\n\nHere is why disgust mirroring satisfies (a*): the process is\nstimulus-driven: it is sensitive to certain perceptual\nstimuli (disgusted facial expressions); it is automatic; and\nit is typically unconscious (even though its output, i.e.,\n\u201cmirrored disgust\u201d, is sometimes conscious). What about\ncondition (b)? Presumably, the primary (evolutionary) function of the\ndisgust mechanism is to produce a disgust response to spoiled food,\ngerms, parasites etc. (Rozin et al. 2008). In the course of evolution,\nthis mechanism could have been subsequently co-opted to also get\nactivated by the perception (of a sign) that someone else is\nexperiencing disgust, in order to facilitate social learning of food\npreferences (Gari\u00e9py et al. 2014). If this is correct, then\ndisgust mirroring is implemented by the reuse of the disgust\nmechanism (by employing this mechanism for a function different than\nits primary one). Moreover, the output of disgust mirroring\nresembles the genuine experience of disgust in at least two\nsignificant respects: first, both mental states have the same neural\nbasis; second, when conscious, they share a similar phenomenology.\nAccordingly, (b) is satisfied. By putting all this together,\nSimulation Theorists conclude that disgust mirroring is a low-level\nsimulation process, and mirrored disgust is a simulated mental state\n(Goldman 2008b; Barlassina 2013)\n4. The Role of Mental Simulation in Mindreading\n\nIn the previous section, we examined the case for the psychological\nreality of mental simulation. We now turn to ST as a theory of\nmindreading. We will tackle two main issues: the extent to which\nmindreading is simulation-based, and how simulation-based mindreading\nworks.\n4.1 The Centrality of Mental Simulation in Mindreading\n\nST proposes that mental simulation plays a central role in\nmindreading, i.e., it plays a central role in the capacity to\nrepresent and reason about others\u2019 mental state. What does\n\u201ccentral\u201d mean here? Does it mean the central\nrole, with other contributors to mindreading being merely peripheral?\nThis is an important question, since in recent years there have been\nproposed hybrid models according to which both mental simulation and\ntheorizing play important roles in mindreading (see\n section 5.2).\n \n\nA possible interpretation of the claim that mental simulation plays a\ncentral role in representing others\u2019 mental states is that\nmindreading events are always simulation-based, even if they\nsometimes also involve theory. Some Simulation Theorists, however,\nreject this interpretation, since they maintain that there are\nmindreading events in which mental simulation plays no role at all\n(Currie & Ravenscroft 2002). For example, if I know that Little\nJimmy is happy every time he finds a dollar, and I also know that he\nhas just found a dollar, I do not need to undergo any simulation\nprocess to conclude that Little Jimmy is happy right now. I just need\nto carry out a simple logical inference.\n\nHowever, generalizations like, \u201cLittle Jimmy is happy every time\nhe finds a dollar,\u201d are ceteris paribus rules. People\nreadily recognize exceptions: for example, we recognize situations in\nwhich Jimmy would probably not be happy even if he found a dollar,\nincluding some in which finding a dollar might actually make him\nunhappy. Rather than applying some additional or more complex rules\nthat cover such situations, it is arguable that putting ourselves in\nJimmy's situation and using \u201cgood common sense\u201d alerts us\nto to these exceptions and overrides the rule. If that is correct,\nthen simulation is acting as an overseer or governor even when people\nappear to be simply applying rules. \n\nGoldman (2006) suggests that we cash out the central role of mental\nsimulation in representing others\u2019 mental states as follows:\nmindreading is often simulation-based. Goldman\u2019s\nsuggestion, however, turns out to be empty, since he explicitly\nrefuses to specify what \u201coften\u201d means in this context.\n\n\n\nHow often is often? Every Tuesday, Thursday, and Saturday? Precisely\nwhat claim does ST mean to make? It is unreasonable to demand a\nprecise answer at this time. (Goldman 2006: 42; see also Goldman 2002;\nJeannerod & Pacherie 2004)\n\n\nPerhaps a better way to go is to characterize the centrality of mental\nsimulation for mindreading not in terms of frequency of use,\nbut in terms of importance. Currie and Ravenscroft make the\nvery plausible suggestion that \u201cone way to see how important a\nfaculty is for performing a certain task is to examine what happens\nwhen the faculty is lacking or damaged\u201d (Currie &\nRavenscroft 2002: 51). On this basis, one could say that mental\nsimulation plays a central role in mindreading if and only\nif: if one\u2019s simulational capacity (i.e., the capacity to\nundergo simulation processes/simulated mental states) were impaired,\nthen one\u2019s mindreading capacity would be significantly\nimpaired. \n\nAn elaboration of this line of thought comes from Gordon (2005)\u2014\nsee also Gordon (1986, 1996) and Peacocke (2005)\u2014who argues that\nsomeone lacking the capacity for mental simulation would not be able\nto represent mental states as such, since she is incapable of\nrepresenting anyone as having a mind in the first place.\nGordon\u2019s argument is essentially as follows:\n\n\nWe represent something as having a mind, as having mental states and\nprocesses, only if we represent it as a subject (\u201csubject of\nexperience,\u201d in formulations of \u201cthe hard problem of\nconsciousness\u201d), where \u201ca subject\u201d is understood as\na generic \u201cI\u201d. This distinguishes it from a \u201cmere\nobject\u201d (and also is a necessary condition for a more benevolent\nsort of empathy).\n\nTo represent something as another \u201cI\u201d is to represent it\nas a possible target of self-projection: as something one might (with\nvarying degrees of success) imaginatively put oneself in the place of.\n(Of course, one can fancifully put oneself in the place of just about\nanything\u2014a suspension bridge, even; but that is not a\nreductio ad absurdum, because one can also fancifully\nrepresent just about anything as having a mind.) \n\n\nIt is not clear, however, what consequences Gordon\u2019s conceptual\nargument would have for mindreading, if any. Even if a capacity to\nself-project were needed for representing mental states as such, would\nlack of this capacity necessarily impair mindreading? That is,\ncouldn't one predict explain, predict, and coordinate behavior using a\ntheory of internal states, without conceptualizing these as states of\nan I or subject? As a more general point, Simulation Theorists have\nnever provided a principled account of what would constitute a\n\u201csignificant impairment\u201d of mindreading capacity.\n\nTo cut a long story short, ST claims that mental simulation plays a\ncentral role in mindreading, but at the present stage its proponents\ndo not agree on what this centrality exactly amounts to. We will come\nback to this issue in\n section 5,\n when we shall discuss the respective contributions of mental\nsimulation and theorizing in mindreading.\n\nWe now turn to a different problem: how does mental simulation\ncontribute to mindreading when it does? That is, how does\nsimulation-based mindreading work? Here again, Simulation Theorists\ndisagree about what the right answer is. In what follows, we explore\nsome dimensions of disagreement.\n4.2 Constitution or Causation?\n\nSome Simulation Theorists defend a strong view of\nsimulation-based mindreading (Gordon 1986, 1995, 1996; Gallese et al.\n2004; Gallese & Sinigaglia 2011). They maintain that many\nsimulation-based mindreading events are (entirely)\nconstituted by mental simulation events (where mental\nsimulation events are simulated mental states or simulation\nprocesses). In other words, some Simulation Theorists claim that,\non many occasions, the fact that a subject S is\nrepresenting someone else\u2019s mental states is nothing over and\nabove the fact that S is undergoing a mental simulation event:\nthe former fact reduces to the latter. For example, Lisa\u2019s\nundergoing a mirrored disgust experience as a result of observing\nJohn\u2019s disgusted face would count as a mindreading event:\nLisa\u2019s simulated mental state would represent John\u2019s\ndisgust (Gallese et al. 2004). Let us call this \u201cthe\nConstitution View\u201d.\n\nWe shall elaborate on the details of the Constitution View in\n section 4.3.\n Before doing that, we consider an argument that has been directed\nagainst it over and over again, and which is supposed to show that the\nConstitution View is a non-starter (Fuller 1995; Heal 1995; Goldman\n2008b; Jacob 2008, 2012). Lacking a better name, we will call it\n\u201cthe Anti-Constitution argument\u201d. Here it is. By\ndefinition, a mindreading event is a mental event in which a subject,\nS, represents another subject, Q, as having a certain\nmental state M. Now\u2014the argument continues\u2014the\nonly way in which S can represent Q as having\nM is this: S has to employ the concept of that\nmental state and form the judgment, or the belief,\nthat Q is in M. Therefore, a mindreading event is\nidentical to an event of judging that someone else has a certain\nmental state (where this entails the application of mentalistic\nconcepts). It follows from this that mental simulation events cannot\nbe constitutive of mindreading events, since the former events are not\nevents of judging that someone else has a certain mental state. An\nexample should clarify the matter. Consider Lisa again, who is\nundergoing a mirrored disgust experience as a result of\nobserving John\u2019s disgusted face. Clearly, undergoing such a\nsimulated disgust experience is a different mental event from\njudging that John is experiencing disgust. Therefore,\nLisa\u2019s mental simulation does not constitute a mindreading\nevent.\n\nIn\n section 4.3,\n we will discuss how the defenders of the Constitution View have\nresponded to this argument. Suppose for the moment that the\nAnti-Constitution argument is sound. What alternative pictures of\nsimulation-based mindreading are available? Those Simulation Theorists\nwho reject the Constitution View tend to endorse the Causation\nView, according to which mental simulation events never\nconstitute mindreading events, but only causally contribute\nto them. The best developed version of this view is Goldman\u2019s\n(2006) Three-Stage Model (again, this is our label, not his),\nwhose basic structure is as follows:\n\n\nSTAGE 1. Mental simulation: Subject S undergoes a\nsimulation process, which outputs a token simulated mental state\nm*.\n\nSTAGE 2. Introspection: S introspects m* and\ncategorizes/conceptualizes it as (a state of type)\nM.\n\nSTAGE 3. Judgment: S attributes (a state of type)\nM to another subject, Q, through the judgment\nQ is in M.\n\n(The causal relations among these stages are such that: STAGE 1 causes\nSTAGE 2, and STAGE 2 in turn causes STAGE 3. See Spaulding 2012 for a\ndiscussion of the notion of causation in this context.)\n\n\nHere is our trite example. On the basis of observing John\u2019s\ndisgusted facial expression, Lisa comes to judge that John is\nhaving a disgust experience. How did she arrive at the formation of\nthis judgment? Goldman\u2019s answer is as follows. The observation\nof John\u2019s disgusted facial expression triggered a disgust\nmirroring process in Lisa, resulting in Lisa\u2019s undergoing a\nmirrored disgust experience (STAGE 1). This caused Lisa to introspect\nher simulated disgust experience and to categorize it as a disgust\nexperience (STAGE 2) (the technical notion of introspection used by\nGoldman will be discussed in\n section 4.4).\n This, in turn, brought about the formation of the judgment John\nis having a disgust experience (STAGE 3). Given that, according\nto Goldman, mindreading events are identical to events of judging that\nsomeone else has a certain mental state, it is only this last stage of\nLisa\u2019s cognitive process that constitutes a mindreading event.\nOn the other hand, the previous two stages were merely causal\ncontributors to it. But mental simulation entirely took place at STAGE\n1. This is why the Three-Stage Model is a version of the Causation\nView: according to the model, mental simulation events causally\ncontribute to, but do not constitute, mindreading events.\n4.3 Mindreading without Judgement \n\nThe main strategy adopted by the advocates of the Constitution View in\nresponding to the Anti-Constitution argument consists in impugning the\nidentification of mindreading events with events of judging\nthat someone else has a certain mental state. A prominent version of\nthis position is Gordon\u2019s (1995, 1996) Radical\nSimulationism, according to which representing someone\nelse\u2019s mental states does not require the formation of\njudgments involving the application of mentalistic\nconcepts. Rather, Gordon proposes that the main bulk of\nmindreading events are non-conceptual representations of\nothers\u2019 mental states, where these non-conceptual\nrepresentations are constituted by mental simulation events. If this\nis true, many mindreading events are constituted by mental\nsimulation events, and thus the Constitution View is correct.\n\nThe following case should help to get Radical Simulationism across.\nSuppose that I want to represent the mental state that an\nindividual\u2014call him \u201cMr Tees\u201d\u2014is in right now.\nAccording to Gordon, there is a false assumption behind the idea that,\nin order to do so, I need to form a judgment with the content Mr\nTees is in M (where \u201cM\u201d is a\nplaceholder for a mentalistic concept). The false assumption is that\nthe only thing that I can do is to simulate myself in Mr\nTees\u2019s situation. As Gordon points out, it is also possible for\nme to simulate Mr Tees in his situation. And if I do so, my\nvery simulation of Mr Tees constitutes a representation of\nhis mental state, without the need of forming any judgment. This is\nhow Gordon makes his point:\n\n\nTo simulate Mr Tees in his situation requires an egocentric shift, a\nrecentering of my egocentric map on Mr Tees. He becomes in my\nimagination the referent of the first person pronoun \u201cI\u201d.\n\u2026 Such recentering is the prelude to transforming myself in\nimagination into Mr Tees as much as actors become the characters they\nplay. \u2026 But once a personal transformation has been\naccomplished, \u2026 I am already representing him as being\nin a certain state of mind. (Gordon 1995: 55\u201356)\n\n\nIt is important to stress the dramatic difference between\nGordon\u2019s Radical Simulationism and Goldman\u2019s Three-Stage\nModel. According to the latter, mental simulation events causally\ncontribute to representing other people\u2019s mental states,\nbut the mindreading event proper is always constituted by a\njudgment (or a belief). Moreover, Goldman maintains that the ability\nto form such judgments requires both the capacity to\nintrospect one\u2019s own mental states (more in this in\n section 4.4)\n and possession of mentalistic concepts. None of this is true\nof Radical Simulationism. Rather, Gordon proposes that, in the large\nmajority of cases, it is the very mental simulation event itself that\nconstitutes a representation of someone else\u2019s mental\nstates. Furthermore, since such mental simulation events neither\nrequire the capacity for introspection nor possession of mentalistic\nconcepts, Radical Simulationism entails the surprising conclusion that\nthese two features play at best a very minor role in mindreading. A\ntestable corollary is that social interaction often relies on an\nunderstanding of others that does not require the explicit application\nof mental state concepts.\n4.4 Mindreading and Introspection\n\nFrom what we have said so far, one could expect that Gordon should\nagree with Goldman on at least one point. Clearly, Gordon has to admit\nthat there are some cases of mindreading in which a subject\nattributes a mental state to someone else through a judgment involving\nthe application of mentalistic concepts. Surely, Gordon cannot deny\nthat there are occasions in which we think things like Mary\nbelieves that John is late or Pat desires to visit\nLisbon. Being a Simulation Theorist, Gordon will also presumably\nbe eager to maintain that many such mindreading events are based on\nmental simulation events. But if Gordon admits that much, should he\nnot also concede that Goldman\u2019s Three-Stage Model is the right\naccount of at least those simulation-based mindreading\nevents? Surprising as it may be, Gordon still disagrees.\n\nGordon (1995) accepts that there are occasions in which a subject\narrives at a judgment about someone else\u2019s mental state\non the basis of some mental simulation event. He might also concede to\nGoldman that such a judgment involves mentalistic concepts (but see\nGordon\u2019s 1995 distinction between comprehending and\nuncomprehending ascriptions). Contra Goldman,\nhowever, Gordon argues that introspection plays no role at\nall in the generation of these judgments. Focusing on a specific\nexample will help us to clarify this further disagreement between\nGoldman and Gordon.\n\nSuppose that I know that Tom believes that (1) and (2):\n\nFido is a dog\nAll dogs enjoy watching TV\n\n\nOn this basis, I attribute to Tom the further belief that (3):\n\nFido enjoys watching TV\n\n\nGoldman\u2019s Three-Stage Model explains this mindreading act in the\nfollowing way. FIRST STAGE: I imagine believing what Tom believes\n(i.e., I imagine believing that (1) and (2)); I then feed those\nbelief-like imaginings into my reasoning mechanism (in the off-line\nmode); as a result, my reasoning mechanism outputs the imagined belief\nthat (3). The SECOND STAGE of the process consists in introspecting\nthis simulated belief and categorizing it as a belief.\nCrucially, in Goldman\u2019s model, \u201cintrospection\u201d does\nnot merely refer to the capacity to self-ascribe mental states.\nRather, it picks out a distinctive cognitive method for\nself-ascription, a method which is typically described as\nnon-inferential and quasi-perceptual (see the\nsection Inner sense accounts in the entry on\n self-knowledge).\n In particular, Goldman (2006) characterizes introspection as a\ntransduction process that takes the neural properties of a mental\nstate token as input and outputs a categorization of the type of\nstate. In the case that we are considering, my introspective mechanism\ntakes the neural properties of my token simulated belief as input and\ncategorizes it as a belief as output. After all this, the\nTHIRD STAGE occurs: I project the categorized belief onto Tom, through\nthe judgment Tom believes that Fido enjoys watching\nTV. (You might wonder where the content of Tom\u2019s\nbelief comes from. Goldman (2006) has a story about that too, but we\nwill leave this aside).\n\nWhat about Gordon? How does he explain, in a simulationist fashion but\nwithout resorting to introspection, the passage from knowing that Tom\nbelieves that (1) and (2) to judging that Tom believes that (3)?\nAccording to Gordon, the first step in the process is, of course,\nimagining to be Tom\u2014thus believing, in the context\nof the simulation, that (1) and (2). This results (again in the\ncontext of the simulation) in the formation of the belief that (3).\nBut how do I now go about discovering that *I*, Tom, believe that (3)?\nHow can one perform such a self-ascription if not via introspection? A\nsuggestion given by Gareth Evans will show us how\u2014Gordon\nthinks.\n\nEvans (1982) famously argued that we answer the question \u201cDo I\nbelieve that p?\u201d by answering another question, namely\n\u201cIs it the case that p?\u201d In other words, according\nto Evans, we ascribe beliefs to ourselves not by introspecting, or by\n\u201clooking inside\u201d, but by looking \u201coutside\u201d and\ntrying to ascertain how the world is. If, e.g., I want to know whether\nI believe that Manchester is bigger than Sheffield, I just ask myself\n\u201cIs Manchester bigger than Sheffield?\u201d If I answer in the\naffirmative, then I believe that Manchester is bigger than Sheffield.\nIf I answer in the negative, then I believe that Manchester is\nnot bigger than Sheffield. If I do not know what to answer,\nthen I do not have any belief with regard to this subject\nmatter.\n\nGordon (1986, 1995) maintains that this self-ascription\nstrategy\u2014which he labels \u201cthe ascent\nroutine\u201d (Gordon 2007)\u2014is also the strategy that we\nemploy, in the context of a simulation, to determine the mental states\nof the simulated agent:\n\n\nIn a simulation of O, I settle the question of whether O\nbelieves that p by simply asking \u2026 whether it is the\ncase that p. That is, I simply concern myself with the\nworld\u2014O\u2019s world, the world from O\u2019s\nperspective. \u2026 Reporting O\u2019s beliefs is\njust reporting what is there. (Gordon 1995: 60)\n\n\nSo, this is how, in Gordon\u2019s story, I come to judge that Tom has\nthe belief that Fido enjoys watching TV. In the context of the\nsimulation, *I* asked *myself* (where both \u201c*I*\u201d and\n\u201c*myself*\u201d in fact refer to Tom) whether *I* believe that\nFido enjoys watching TV. And *I* answered this question by answering\nanother question, namely, whether it is the case that Fido enjoys\nwatching TV. Given that, from *my* perspective, Fido enjoys watching\nTV (after all, from *my* perspective, Fido is a dog and all dogs enjoy\nwatching TV), *I* expressed my belief by saying: \u201cYes,\n*I*, Tom, believe that Fido enjoys watching TV\u201d. As you can see,\nin such a story, introspection does not do anything. (We will come\nback to the role of introspection in mindreading in\n section 6.2).\n4.5 Summary\n\nIn sections 2, 3, and 4 we dwelt upon the \u201cinternal\u201d\ndisagreements among Simulation Theorists. It goes without saying that\nsuch disagreements are both wide and deep. In fact, different\nSimulation Theorists give different answers to such fundamental\nquestions as: \u201cWhat is mental simulation?\u201d, \u201cHow\ndoes mental simulation contribute to mindreading?, \u2018What is the\nrole of introspection in mindreading?\u201d In light of such\ndifferences of opinion in the simulationist camp, one might conclude\nthat, after all, Stich and Nichols (1997) were right when saying that\nthere is no such thing as the Simulation Theory. However, if\none considers what is shared among Simulation Theorists, one will\nrealize that there is unity amidst this diversity. A good way to\nreveal the commonalities among different versions of ST is by\ncontrasting ST with its arch-enemy, i.e., the Theory-Theory of\nmindreading. This is what we do in the next section.\n5. Simulation Theory and Theory-Theory\n\nST is only one of several accounts of mindreading on the market. A\nrough-and-ready list of the alternatives should at least include: the\nIntentional Stance Theory (Dennett 1987; Gergely & Csibra 2003;\nGergely et al. 1995); Interactionism (Gallagher 2001; Gallagher &\nHutto 2008; De Jaegher at al. 2010); and the Theory-Theory (Gopnik\n& Wellman 1992; Gopnik & Meltzoff 1997; Leslie 1994; Scholl\n& Leslie 1999). In this entry, we will discuss the Theory-Theory\n(TT) only, given that the TT-ST controversy has constituted the focal\npoint of the debate on mindreading during the last 30 years or so.\n5.1 The Theory-Theory\n\nAs suggested by its name, the Theory-Theory proposes that mindreading\nis grounded by the possession of a Theory of Mind (\u201ca folk\npsychology\u201d)\u2014i.e., it is based on the tacit knowledge of\nthe following body of information: a number of \u201cfolk\u201d laws\nor principles connecting mental states with sensory stimuli,\nbehavioural responses, and other mental states. Here are a couple of\nputative examples:\n\n\nLaw of sight: If S is in front of object O,\nS directs her eye-gaze to O, S\u2019s visual\nsystem is properly functioning, and the environmental conditions are\noptimal, then ceteris paribus S will see O.\n\nLaw of the practical syllogism: If S desires a certain\noutcome G and S believes that by performing a certain\naction A she will obtain G, then ceteris\nparibus S will decide to perform A.\n\n\nThe main divide among Theory-Theorists concerns how the Theory of Mind\nis acquired\u2014i.e., it concerns where this body of knowledge comes\nfrom. According to the Child-Scientist Theory-Theory (Gopnik &\nWellman 1992; Gopnik & Meltzoff 1997), a child constructs a Theory\nof Mind exactly as a scientist constructs a scientific theory: she\ncollects evidence, formulates explanatory hypotheses, and revises\nthese hypotheses in the light of further evidence. In other words,\n\u201cfolk\u201d laws and principles are obtained through hypothesis\ntesting and revision\u2014a process that, according to proponents of\nthis view, is guided by a general-purpose, Bayesian learning mechanism\n(Gopnik & Wellman 2012). On the contrary, the Nativist\nTheory-Theory (Carruthers 2013; Scholl & Leslie 1999) argues that\na significant part of the Theory of Mind is innate, rather than\nlearned. More precisely, Nativists typically consider the core of the\nTheory of Mind as resulting from the maturation of a cognitive module\nspecifically dedicated to representing mental states\n\nThese disagreements notwithstanding, the main tenet of TT is clear\nenough: attributions of mental states to other people are guided by\nthe possession of a Theory of Mind. For example, if I know that you\ndesire to buy a copy of The New York Times and I know that\nyou believe that if you go to News & Booze you can buy a\ncopy, then I can use the Law of the Practical Syllogism to\ninfer that you will decide to go to News & Booze.\n\nTT has been so popular among philosophers and cognitive scientists\nthat the explanation it proposes has ended up being the name of the\nvery phenomenon to be explained: on many occasions, scholars use the\nexpression \u201cTheory of Mind\u201d as a synonym of\n\u201cmindreading\u201d. Simulation Theorists, however, have never\nbeen particularly impressed by this. According to them, there is\nno need to invoke the tacit knowledge of a Theory of Mind to\naccount for mindreading, since a more parsimonious\nexplanation is available: we reuse our own cognitive\nmechanisms to mentally simulate others\u2019 mental states. For\nexample, why do I need to know the Law of the Practical\nSyllogism, if I can employ my own decision-making mechanism\n(which I have anyway) to simulate your decision? It is\nuneconomical\u2014Simulation Theorists say\u2014to resort\nto an information-rich strategy, if an information-poor strategy will\ndo equally as well.\n\nThe difference between TT and ST can be further illustrated through a\nnice example given by Stich and Nichols (1992). Suppose that you want\nto predict the behavior of an airplane in certain atmospheric\nconditions. You can collect the specifications of the airplane and\ninfer, on the basis of aerodynamic theory, how the airplane\nwill behave. Alternatively, you can build a model of the airplane and\nrun a simulation. The former scenario approximates the way in\nwhich TT describes our capacity to represent others\u2019 mental\nstates, while the latter approximates ST. Two points need to be\nstressed, though. First, while knowledge of aerodynamic theory is\nexplicit, TT says that our knowledge of the Theory of Mind is\ntypically implicit (or tacit). That is, someone who knows\naerodynamic theory is aware of the theory\u2019s laws and\nprinciples and is able to report them correctly, while the laws and\nprinciples constituting one\u2019s Theory of Mind typically lie\noutside awareness and reportability. Second, when we run a simulation\nof someone else\u2019s mental states, we do not need to build a\nmodel: we are the model\u2014that is, we use our own\nmind as a model of others\u2019 minds.\n\nSimulation Theorists maintain that the default state for the\n\u201cmodel\u201d is one in which the simulator simply makes no\nadjustments when simulating another individual. That is, ST has it\nthat we are automatically disposed to attribute to a target mental\nstates no different from our own current states. This would often\nserve adequately in social interaction between people who are\ncooperating or competing in what is for practical purposes the same\nsituation. We tend to depart from this default when we perceive\nrelevant differences between others\u2019 situations and our own. In\nsuch cases, we might find ourselves adjusting for situational\ndifferences by putting ourselves imaginatively in what we consider the\nother\u2019s situation to be.\n\nWe might also make adjustments for individual differences. An\nacquaintance will soon be choosing between candidate a and\ncandidate b in an upcoming election. To us, projecting\nourselves imaginatively into that voting situation, the choice is\nglaringly obvious: candidate a, by any reasonable criteria.\nBut then we may wonder whether this imaginative projection into the\nvoting situation adequately represents our acquaintance in\nthat situation. We might recall things the person has said, or\npeculiarities of dress style, diet, or entertainment, that might seem\nrelevant. Internalizing such behavior ourselves, trying to \u201cget\nbehind\u201d it as an actor might get behind a scripted role, we\nmight then put, as it were, a different person into the voting\nsituation, one who might choose candidate b.\n\nSuch a transformation would require quarantining some of our own\nmental states, preferences, and dispositions, inhibiting them so that\nthey do not contaminate our off-line decision-making in the role of\nthe other. Such inhibition of one's own mental states would be\ncognitively demanding. For that reason, ST predicts that mindreading\nwill be subject to egocentric errors\u2014that is, it\npredicts that we will often attribute to a target the mental state\nthat we would have if we were in the target\u2019s situation, rather\nthan the state the target is actually in (Goldman 2006). In\n section 6.2,\n we shall discuss whether this prediction is borne out by the\ndata.\n5.2 Collapse or Cooperation?\n\nOn the face of it, ST and TT could not be more different from one\nanother. Some philosophers, however, have argued that, on closer\ninspection, ST collapses into TT, thus revealing itself as a form of\nTT in disguise. The collapse argument was originally formulated by\nDaniel Dennett (1987):\n\n\nIf I make believe I am a suspension bridge and wonder what I will do\nwhen the wind blows, what \u201ccomes to my mind\u201d in my\nmake-believe state depends on\u2026 my knowledge of\nphysics\u2026 Why should my making believe I have your beliefs be\nany different? In both cases, knowledge of the imitated object is\nneeded to drive the\u2026 \u201csimulation\u201d, and the\nknowledge must be\u2026 something like a theory. (Dennett\n1987: 100\u2013101, emphasis added)\n\n\nDennett\u2019s point is clear. If I imagine being, say, a bridge,\nwhat I imagine will depend on my theory of bridges. Suppose that I\nhave a folk theory of bridges that contains the following principle:\n\u201cA bridge cannot sustain a weight superior to its own\nweight\u201d. In this case, if I imagine an elephant weighing three\ntons walking over a bridge weighing two tons, I will imagine the\nbridge collapsing. Since my \u201cbridge-simulation\u201d is\nentirely theory-driven, \u201csimulation\u201d is a\nmisnomer. The same carries over to \u201csimulating other\npeople\u201ds mental states\u2019, Dennett says. If I try to imagine\nyour mental states, what I imagine will depend entirely on my Theory\nof Mind. Therefore, the label \u201cmental simulation\u201d is\nmisleading.\n\nHeal (1986) and Goldman (1989) promptly replied to Dennett. Fair\nenough, if a system S tries to simulate the state of a\nradically different system Q (e.g., if a human being tries to\nsimulate the state of a bridge), then S\u2019s simulation must\nbe guided by a theory. However, if a system S tries to simulate\nthe state of a relevantly similar system S*, then\nS\u2019s simulation can be entirely process-driven:\nto simulate the state which S* is in, S simply has to\nrun in itself a process similar to the one S* underwent. Given\nthat, for all intents and purposes, human beings are relevantly\nsimilar to each other, a human being can mentally simulate what\nfollows from having another human being\u2019s mental states without\nresorting to a body of theoretical knowledge about the mind\u2019s\ninner workings. She will just need to reuse her own cognitive\nmechanisms to implement a simulation process.\n\nThis reply invited the following response (Jackson 1999). If the\npossibility of process-driven simulation is grounded in the similarity\nbetween the simulator and the simulated, then I have to assume that\nyou are relevantly similar to me, when I mentally simulate your mental\nstates. This particular assumption, in turn, will be derived from a\ngeneral principle\u2014something like \u201cHuman beings\nare psychologically similar\u201d. Therefore, mental simulation is\ngrounded in the possession of a theory. The threat of collapse is\nback! One reply to Jackson\u2019s arguments is as follows (for other\nreplies see Goldman 2006): the fact that process-driven simulation is\ngrounded in the similarity among human beings does not entail\nthat, in order to run a simulation, a simulator must know (or believe,\nor assume) that such similarity obtains; no more, indeed, than the\nfact that the solubility of salt is grounded in the molecular\nstructure of salt entails that a pinch of salt needs to know chemistry\nto dissolve in water.\n\nGranting that ST and TT are distinct theories, we can now ask a\ndifferent question: are the theories better off individually or should\nthey join forces somehow? Let us be more explicit. Can ST on its own\noffer an adequate account of mindreading (or at least of the great\nmajority of its episodes)? And what about TT? A good number of\ntheorists now believe that neither ST nor TT alone will do. Rather,\nmany would agree that these two theories need to cooperate, if they\nwant to reach a satisfactory explanation of mindreading. Some authors\nhave put forward TT-ST hybrid models, i.e., models in which the tacit\nknowledge of a Theory of Mind is the central aspect of mindreading,\nbut it is in many cases supplemented by simulation processes\n(Botterill & Carruthers 1999; Nichols & Stich 2003). Other\nauthors have instead defended ST-TT hybrid models, namely, accounts of\nmindreading where the pride of place is given to mental simulation,\nbut where the possession of a Theory of Mind plays some non-negligible\nrole nonetheless (Currie & Ravenscroft 2002; Goldman 2006; Heal\n2003). Since this entry is dedicated to ST, we will briefly touch upon\none instance of the latter variety of hybrid account.\n\nHeal (2003) suggested that the domain of ST is restricted to those\nmental processes involving rational transitions among\ncontentful mental states. To wit, Heal maintains that mental\nsimulation is the cognitive routine that we employ to represent other\npeople\u2019s rational processes, i.e., those cognitive\nprocesses which are sensitive to the semantic content of the mental\nstates involved. On the other hand, \n\n\nwhen starting point and/or outcome are [states] without content,\nand/or the connection is not [rationally] intelligible, there is no\nreason \u2026 to suppose that the process \u2026 can be simulated.\n(Heal 2003: 77)\n\n\nAn example will clarify the matter. Suppose that I know that you\ndesire to eat sushi, and that you believe that you can order sushi by\ncalling Yama Sushi. To reach the conclusion that you will\ndecide to call Yama Sushi, I only need to imagine desiring\nand believing what you desire and believe, and to run a simulated\ndecision-making process in myself. No further knowledge is required to\npredict your decision: simulation alone will do the job. Consider, on\nthe other hand, the situation in which I know that you took a certain\ndrug and I want to figure out what your mental states will be. In this\ncase\u2014Heal says\u2014my prediction cannot be based on mental\nsimulation. Rather, I need to resort to a body of information about\nthe likely psychological effects of that drug, i.e., I have to resort\nto a Theory of Mind (fair enough, I can also take the drug myself, but\nthis will not count as mental simulation). This, according to Heal,\ngeneralizes to all cases in which a mental state is the input or the\noutput of a mere causal process. In those cases, mental\nsimulation is ineffective and should be replaced by theorizing. Still,\nthose cases do not constitute the central part of mindreading. In\nfact, many philosophers and cognitive scientists would agree that the\ncrucial component of human mindreading is the ability to reason about\nothers\u2019 propositional attitudes. And this is exactly\nthe ability that, according to Heal, should be explained in term of\nmental simulation. This is why Heal\u2019s proposal counts as an\nST-TT hybrid, rather than the other way around.\n6. Simulation Theory: Pros and Cons\n\nST has sparked a lively debate, which has been going on since the end\nof the 1980s. This debate has dealt with a great number of theoretical\nand empirical issues. On the theoretical side, we have seen\nphilosophical discussions of the relation between ST and functionalism\n(Gordon 1986; Goldman 1989; Heal 2003; Stich & Ravenscroft 1992),\nand of the role of tacit knowledge in cognitive explanations (Davies\n1987; Heal 1994; Davies & Stone 2001), just to name a few.\nExamples of empirical debates are: how to account for mindreading\ndeficits in Autism Spectrum Disorders (Baron-Cohen 2000; Currie &\nRavenscroft 2002), or how to explain the evolution of mindreading\n(Carruthers 2009; Lurz 2011). It goes without saying that discussing\nall these bones of contention would require an entire book (most\nprobably, a series of books). In the last section of this\nentry, we confine ourselves to briefly introducing the reader to a\nsmall sample of the main open issues concerning ST.\n6.1 The Mirror Neurons Controversy\n\nWe wrote that ST proposes that mirroring processes (i.e., activations\nof mirror mechanisms in the perception mode): (A) are\n(low-level) simulation processes, and (B) contribute (either\nconstitutively or causally) to mindreading (Gallese et al. 2004;\nGallese & Goldman 1998; Goldman 2006, 2008b; Hurley 2005). Both\n(A) and (B) have been vehemently contested by ST\u2019s\nopponents.\n\nBeginning with (A), it has been argued that mirroring processes do not\nqualify as simulation processes, because they fail to satisfy the\ndefinition of \u201csimulation process\u201d (Gallagher 2007;\nHerschbach 2012; Jacob 2008; Spaulding 2012) and/or because they are\nbetter characterized in different terms, e.g., as enactive perceptual\nprocesses (Gallagher 2007) or as elements in an information-rich\nprocess (Spaulding 2012). As for (B), the main worry runs as follows.\nGranting that mirroring processes are simulation processes, what\nevidence do we have for the claim that they contribute to mindreading?\nThis, in particular, has been asked with respect to the role of\nmirroring processes in \u201caction understanding\u201d (i.e., the\ninterpretation of an agent\u2019s behavior in terms of the\nagent\u2019s intentions, goals, etc.). After all, the neuroscientific\nevidence just indicates that action mirroring correlates with\nepisodes of action understanding, but correlation is not causation,\nlet alone constitution. In fact, there are no studies examining\nwhether disruption of the monkey mirror neuron circuit results in\naction understanding deficits, and the evidence on human action\nunderstanding following damage to the action mirror mechanism is\ninconclusive at best (Hickok 2009). In this regard, some authors have\nsuggested that the most plausible hypothesis is instead that action\nmirroring follows (rather than causes or constitutes) the\nunderstanding of others\u2019 mental states (Csibra 2007; Jacob\n2008). For example, Jacob (2008) proposes that the job of mirroring\nprocesses in the action domain is just that of computing a\nrepresentation of the observed agent\u2019s next movement,\non the basis of a previous representation of the\nagent\u2019s intention. Similar deflationary accounts of the action\nmirror mechanism have been given by Brass et al. (2007), Hickok\n(2014), and Vannuscorps and Caramazza (2015)\u2014these accounts\ntypically take the STS (superior temporal sulcus, a brain region\nlacking mirror neurons) to be the critical neural area for action\nunderstanding.\n\nThere are various ways to respond to these criticisms. A strong\nresponse argues that they are based on a misunderstanding of the\nrelevant empirical findings, as well as on a mischaracterization of\nthe role that ST attributes to the action mirror mechanism in action\nunderstanding (Rizzolatti & Sinigaglia 2010, 2014). A weaker\nresponse holds that the focus on action understanding is a bit of a\nred herring, given that the most robust evidence in support of the\ncentral role played by mirroring processes in mindreading comes from\nthe emotion domain (Goldman 2008b). We will consider the weaker\nresponse here.\n\nGoldman and Sripada (2005) discuss a series of paired deficits in\nemotion production and face-based emotion mindreading. These\ndeficits\u2014they maintain\u2014are best explained by the\nhypothesis that one attributes emotions to someone else through\nsimulating these emotions in oneself: when the ability to undergo the\nemotion breaks down, the mindreading capacity breaks down as well.\nBarlassina (2013) elaborates on this idea by considering\nHuntington\u2019s Disease (HD), a neurodegenerative disorder\nresulting in, among other things, damage to the disgust mirror\nmechanism. As predicted by ST, the difficulties individuals with HD\nhave in experiencing disgust co-occur with an impairment in\nattributing disgust to someone else on the basis of observing her\nfacial expression\u2014despite perceptual abilities and knowledge\nabout disgust being preserved in this clinical population. Individuals\nsuffering from HD, however, exhibit an intact capacity for disgust\nmindreading on the basis of non-facial visual stimuli. For this\nreason, Barlassina concludes by putting forward an ST-TT hybrid model\nof disgust mindreading on the basis of visual stimuli.\n6.2 Self and Others\n\nST\u2019s central claim is that we reuse our own cognitive\nmechanisms to arrive at a representation of other\npeople\u2019s mental states. This claim raises a number of issues\nconcerning how ST conceptualizes the self-other relation. We will\ndiscuss a couple of them.\n\nGallagher (2007: 355) writes that \n\n\ngiven the large diversity of motives, beliefs, desires, and behaviours\nin the world, it is not clear how a simulation process \u2026 can\ngive me a reliable sense of what is going on in the other\nperson\u2019s mind. \n\n\nThere are two ways of interpreting Gallagher\u2019s worry. First, it\ncan be read as saying that if mindreading is based on mental\nsimulation, then it is hard to see how mental state attributions could\nbe epistemically justified. This criticism, however, misses\nthe mark entirely, since ST is not concerned with whether mental state\nattributions count as knowledge, but only with how, as a matter of\nfact, we go about forming such attributions. A second way to\nunderstand Gallagher\u2019s remarks is this: as a matter of\nfact, we are pretty successful in understanding other minds;\nhowever, given the difference among individual minds, this pattern of\nsuccesses cannot be explained in terms of mental simulation.\n\nST has a two-tier answer to the second reading of Gallagher\u2019s\nchallenge. First, human beings are very similar with regard to\ncognitive processes such as perception, theoretical reasoning,\npractical reasoning, etc. For example, there is a very high\nprobability that if both you and I look at the same scene, we will\nhave the same visual experience. This explains why, in the large\nmajority of cases, I can reuse my visual mechanism to successfully\nsimulate your visual experiences. Second, even though we are quite\ngood at recognizing others\u2019 mental states, we are nonetheless\nprone to egocentric errors, i.e., we tend to attribute to a\ntarget the mental state that we would undergo if we were in\nthe target\u2019s situation, rather than the actual mental state the\ntarget is in (Goldman 2006). A standard example is the curse of\nknowledge bias, where we take for granted that other people know\nwhat we know (Birch & Bloom 2007). ST has a straightforward\nexplanation of such egocentric errors (Gordon 1995; Goldman 2006): if\nwe arrive at attributing mental states via mental simulation, the\nattribution accuracy will depend on our capacity to\n\u201cquarantine\u201d our genuine mental states, when they do not\nmatch the target\u2019s, and to replace them with more appropriate\nsimulated mental states. This \u201cadjustment\u201d process,\nhowever, is a demanding one, because our genuine mental states exert a\npowerful tendency. Thus, Gallagher is right when he says that, on some\noccasions, \u201cif I project the results of my own simulation onto\nthe other, I understand only myself in that other\u2019s situation,\nbut I don\u2019t understand the other\u201d (Gallagher 2007: 355).\nHowever, given how widespread egocentric errors are, this counts as a\npoint in favour of ST, rather than as an argument against it (but see\nde Vignemont & Mercier 2016, and Saxe 2005).\n\nCarruthers (1996, 2009, 2011) raises a different problem for ST: no\nversion of ST can adequately account for self-attributions of mental\nstates. Recall that, according to Goldman (2006), simulation-based\nmindreading is a three-stage process in which we first mentally\nsimulate a target\u2019s mental state, we then introspect\nand categorize the simulated mental state, and we finally attribute\nthe categorized state to the target. Since Goldman\u2019s model has\nit that attributions of mental states to others asymmetrically depend\non the ability to introspect one\u2019s own mental states, it\npredicts that: (A) introspection is (ontogenetically and\nphylogenetically) prior to the ability to represent others\u2019\nmental states; (B) there are cases in which introspection works just\nfine, but where the ability to represent others\u2019 mental states\nis impaired (presumably, because the mechanism responsible for\nprojecting one\u2019s mental states to the target is damaged).\nCarruthers (2009) argues that neither (A) nor (B) are borne out by the\ndata. The former because there are no creatures that have\nintrospective capacities but at the same time lack the ability to\nrepresent others\u2019 mental states; the latter because there are no\ndissociation cases in which an intact capacity for introspection is\npaired with an impairment in the ability to represent others\u2019\nmental states.\n\nHow might a Simulation Theorist respond to this objection? As we said\nin\n section 4,\n Gordon\u2019s (1986, 1995, 1996) Radical Simulationism does\nnot assign any role to introspection in mindreading. Rather, Gordon\nproposes that self-ascriptions are guided by ascent routines through\nwhich we answer the question \u201cDo I believe that p?\u201d\nby answering the lower-order question \u201cIs it the case that\np?\u201d Carruthers (1996, 2011) thinks that this won\u2019t\ndo either. Here is one of the many problems that Carruthers raises for\nthis suggestion\u2014we can call it \u201cThe Scope\nProblem\u201d: \n\n\nthis suggestion appears to have only a limited range of application.\nFor even if it works for the case of belief, it is very hard to see\nhow one might extend it to account for our knowledge of our own goals,\ndecisions, or intentions\u2014let alone our knowledge of our own\nattitudes of wondering, supposing, fearing, and so on. (Carruthers\n2011: 81)\n\n\nCarruthers\u2019 objections are important and deserve to be taken\nseriously. To discuss them, however, we would need to introduce a lot\nof further empirical evidence and many complex philosophical ideas\nabout self-knowledge. This is not a task that we can take up here (the\ninterested reader is encouraged to read, in addition to Gordon (2007)\nand Goldman (2009), the SEP entries on\n self-knowledge\n and on\n introspection).\n The take-home message should be clear enough nonetheless: anybody who\nputs forward an account of mindreading should remember that such an\naccount has to cohere with a plausible story about the cognitive\nmechanisms underlying self-attribution.\n6.3 Developmental Findings\n\nThe development of mindreading capacities in children has been one of\nthe central areas of empirical investigation. In particular,\ndevelopmental psychologists have put a lot of effort into detailing\nhow the ability to attribute false beliefs to others develops. Until\n2005, the central experimental paradigm to test this ability was the\nverbal false belief task (Wimmer & Perner 1983). Here is\na classic version of it. A subject is introduced to two dolls, Sally\nand Anne, and three objects: Sally\u2019s ball, a basket, and a box.\nSally puts her ball in the basket and leaves the scene. While Sally is\naway, Anne takes the ball out of the basket and puts it into the box.\nSally then returns. The subject is asked where she thinks Sally will\nlook for the ball. The correct answer, of course, is that Sally will\nlook inside the basket. To give this answer, the subject has to\nattribute to Sally the false belief that the ball is in the\nbasket. A number of experiments have found that while four-year old\nchildren pass this task, three-year old children fail it (for a\nreview, see Wellman et al. 2001). For a long time, the mainstream\ninterpretation of these findings has been that children acquire the\nability to attribute false beliefs only around their fourth birthday\n(but see Clements & Perner 1994 and Bloom & German 2000).\n\nIn 2005, this developmental timeline was called into question.\nKristine Onishi and Ren\u00e9e Baillargeon (2005) published the\nresult of a non-verbal version of the false belief task,\nwhich they administered to 15-month old infants. The experiment\ninvolves three steps. First, the infants see a toy between two boxes,\none yellow and one green, and then an actor hiding the toy inside the\ngreen box. Next, the infants see the toy sliding out of the green box\nand hiding inside the yellow box. In the true belief condition (TB),\nthe actor notices that the toy changes location, while in the false\nbelief condition (FB) she does not. Finally, half of the infants see\nthe actor reaching into the green box, while the other half sees the\nactor reaching into the yellow box. According to the\nviolation-of-expectation paradigm, infants reliably look for\na longer time at unexpected events. Therefore, if the infants expected\nthe actor to search for the toy on the basis of the\nactor\u2019s belief about its location, then when the actor had a\ntrue belief that the toy was hidden in one box, the infants\nshould look longer when the actor reached into the other box instead.\nConversely, the infants should look longer at one box when the actor\nfalsely believed that the toy was hidden in the other box.\nStrikingly, these predictions were confirmed in both the (TB) and (FB)\nconditions. On this basis, Onishi and Baillargeon (2005) concluded\nthat children of 15 months possess the capacity to represent\nothers\u2019 false beliefs.\n\nThis and subsequent versions of non-verbal false belief tasks\nattracted a huge amount of interest (at the current stage of research,\nthere is evidence that sensitivity to others\u2019 false beliefs is\npresent in infants as young as 7 months\u2014for a review, see\nBaillargeon at al. 2016). Above all, the following two questions have\nbeen widely discussed: why do children pass the non-verbal false\nbelief task at such an early age, but do not pass the verbal version\nbefore the age of 4? Does passing the non-verbal false belief task\nreally indicate the capacity to represent others\u2019 false beliefs?\n(Perner & Ruffman 2005; Apperly & Butterfill 2009; Baillargeon\net al. 2010; Carruthers 2013; Helming et al. 2014).\n\nGoldman and Jordan (2013) maintain that ST has a good answer to both\nquestions. To begin with, they argue that it is implausible to\nattribute to infants such sophisticated meta-representational\nabilities as the ability to represent others\u2019 false beliefs.\nThus, Goldman and Jordan favour a deflationary view, according to\nwhich infants are sensitive to others\u2019 false beliefs,\nbut do not represent them as such. In particular, they\npropose that rather than believing that another subject S\n(falsely) believes that p, infants simply imagine how the\nworld is from S\u2019s perspective\u2014that is, they simply\nimagine that p is the case. This\u2014Goldman and Jordan\nsay\u2014is a more primitive psychological competence than\nmindreading, since it does not involve forming a judgment about\nothers\u2019 mental states. This brings us to Goldman and\nJordan\u2019s answer to the question \u201cwhy do children pass the\nverbal false belief task only at four?\u201d Passing this task\nrequires fully-fledged mindreading abilities and executive functions\nsuch as inhibitory control. It takes quite a lot of time\u2014around\n3 to 4 years\u2014before these functions and abilities come\nonline.\n7. Conclusion\n\nSince the late 1980s, ST has received a great amount of attention from\nphilosophers, psychologists, and neuroscientists. This is not\nsurprising. Mindreading is a central human cognitive capacity, and ST\nchalleges some basic assumptions about the cognitive processes and\nneural mechanisms underlying human social behavior. Moreover, ST\ntouches upon a number of major philosophical problems, such as the\nrelation between self-knowledge and knowledge of other minds, and the\nnature of mental concepts, including the concept of mind itself. In\nthis entry, we have considered some of the fundamental empirical and\nphilosophical issues surrounding ST. Many of them remain open. In\nparticular, while the consensus view is now that both mental\nsimulation and theorizing play important role in mindreading, the\ncurrently available evidence falls short of establishing what their\nrespective roles are. In other words, it is likely that we shall end\nup adopting a hybrid model of mindreading that combines ST and TT,\nbut, at the present stage, it is very difficult to predict what this\nhybrid model will look like. Hopefully, the joint work of philosophers\nand cognitive scientists will help to settle the matter.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Anderson, Michael L., 2008, \u201cNeural Reuse: A Fundamental\nOrganizational Principle of the Brain\u201d, <em>Behavioral and Brain\nScience</em>, 20(4): 239\u2013313. doi:10.1017/S0140525X10000853",
                "\u2013\u2013\u2013, 2015, <em>After Phrenology: Neural Reuse\nand the Interactive Brain</em>, Cambridge, MA: MIT Press.",
                "Apperly, Ian A. and Stephen A. Butterfill, 2009, \u201cDo Humans\nHave Two Systems to Track Beliefs and Belief-Like States?\u201d,\n<em>Psychological Review</em>, 116(4): 953\u201370.\ndoi:10.1037/a0016923",
                "Avenanti, Alessio, Domenica Bueti, Gaspare Galati, &amp; Salvatore\nM. Aglioti, 2005, \u201cTranscranial Magnetic Stimulation Highlights\nthe Sensorimotor Side of Empathy for Pain\u201d, <em>Nature\nNeuroscience</em>, 8(7): 955\u2013960. doi:10.1038/nn1481",
                "Baillargeon, Ren\u00e9e, Rose M. Scott, and Zijing He, 2010,\n\u201cFalse-Belief Understanding in Infants\u201d, <em>Trends in\nCognitive Sciences</em>, 14(3): 110\u2013118.\ndoi:10.1016/j.tics.2009.12.006",
                "Baillargeon, Ren\u00e9e, Rose M. Scott, and Lin Bian, 2016,\n\u201cPsychological Reasoning in Infancy\u201d, <em>Annual Review of\nPsychology</em>, 67: 159\u2013186.\ndoi:10.1146/annurev-psych-010213-115033 ",
                "Barlassina, Luca, 2013, \u201cSimulation is not Enough: A Hybrid\nModel of Disgust Attribution on the Basis of Visual Stimuli\u201d,\n<em>Philosophical Psychology</em>, 26(3): 401\u2013419.\ndoi:10.1080/09515089.2012.659167",
                "Baron-Cohen, Simon, 2000, \u201cTheory of Mind and Autism: A\nFifteen Year Review\u201d, in Simon Baron-Cohen, Helen\nTager-Flusberg, and Donald J. Cohen (eds.); <em>Understanding Other\nMinds: Perspectives from Developmental Cognitive Neuroscience</em>\n(2nd edition), New York: Oxford University Press, pp. 3\u201320.",
                "Bechtel, William, 2008, <em>Mental Mechanisms: Philosophical\nPerspectives on Cognitive Neuroscience</em>, New York: Taylor and\nFrancis.",
                "Birch, Susan A. and Paul Bloom, 2007, \u201cThe Curse of\nKnowledge in Reasoning About False Beliefs\u201d, <em>Psychological\nScience</em>, 18(5): 382\u2013386.\ndoi:10.1111/j.1467-9280.2007.01909.x",
                "Bisiach, Edoardo and Claudio Luzzatti, 1978, \u201cUnilateral\nNeglect of Representational Space\u201d, <em>Cortex</em>, 14(1):\n129\u2013133. doi:10.1016/S0010-9452(78)80016-1",
                "Blakemore, S.-J., D. Bristow, G. Bird, C. Frith, and J. Ward,\n2005, \u201cSomatosensory Activations During the Observation of Touch\nand a Case of Vision-Touch Synaesthesia\u201d, <em>Brain</em>,\n128(7): 1571\u20131583. doi:10.1093/brain/awh500",
                "Bloom, Paul and Tim P. German, 2000, \u201cTwo Reasons to Abandon\nthe False Belief Task as a Test of Theory of Mind\u201d,\n<em>Cognition</em>, 77(1): B25\u201331.\ndoi:10.1016/S0010-0277(00)00096-2",
                "Botterill, George and Peter Carruthers, 1999, <em>The Philosophy\nof Psychology</em>, Cambridge: Cambridge University Press.",
                "Brass, Marcel, Ruth M. Schmitt, Stephanie Spengler, and\nGy\u00f6rgy Gergely, 2007, \u201cInvestigating Action Understanding:\nInferential Processes versus Action Simulation\u201d, <em>Current\nBiology</em>, 17(24): 2117\u20132121.\ndoi:10.1016/j.cub.2007.11.057",
                "Brozzo, Chiara, forthcoming, \u201cMotor Intentions: How\nIntentions and Motor Representations Come Together\u201d, <em>Mind\n&amp; Language</em>.",
                "Buckner, Randy L. and Daniel C. Carroll, 2007,\n\u201cSelf-Projection and the Brain\u201d, <em>Trends in Cognitive\nScience</em>, 11(2): 49\u201357. doi:10.1016/j.tics.2006.11.004",
                "Butterfill, Stephen A. and Corrado Sinigaglia, 2014,\n\u201cIntention and Motor Representation in Purposive Action\u201d,\n<em>Philosophy and Phenomenological Research</em>, 88(1):\n119\u2013145. doi:10.1111/j.1933-1592.2012.00604.x",
                "Carruthers, Peter, 1996, \u201cSimulation and Self-Knowledge: A\nDefense of Theory-Theory\u201d, in Carruthers and Smith 1996:\n22\u201338. doi:10.1017/CBO9780511597985.004",
                "\u2013\u2013\u2013, 2009, \u201cHow we Know Our Own Minds: The\nRelationship between Mindreading and Metacognition\u201d,\n<em>Behavioral and Brain Sciences</em>, 32(2): 121\u2013138.\ndoi:10.1017/S0140525X09000545",
                "\u2013\u2013\u2013, 2011, <em>The Opacity of Mind: An\nIntegrative Theory of Self-Knowledge</em>, Oxford: Oxford University\nPress. doi:10.1093/acprof:oso/9780199596195.001.0001",
                "\u2013\u2013\u2013, 2013, \u201cMindreading in Infancy\u201d,\n<em>Mind and Language</em>, 28(2): 141\u2013172.\ndoi:10.1111/mila.12014",
                "Carruthers, Peter and Peter K. Smith (eds.), 1996, <em>Theories of\nTheories of Mind</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511597985",
                "Clements, Wendy A. and Josef Perner, 1994, \u201cImplicit\nUnderstanding of Belief\u201d, <em>Cognitive Development</em>, 9(4):\n377\u2013395. doi:10.1016/0885-2014(94)90012-4",
                "Craver, Carl F., 2007, <em>Explaining the Brain. Mechanisms and\nthe Mosaic Unity of Neuroscience</em>, Oxford: Oxford University\nPress. doi:10.1093/acprof:oso/9780199299317.001.0001",
                "Csibra, Gergely, 2007, \u201cAction Mirroring and Action\nUnderstanding: An Alternative Account\u201d, in Patrick Haggard, Yves\nRosetti, and Mitsuo Kawato (eds.) <em>Sensorimotor Foundations of\nHigher Cognition. Attention and Performance XII</em>, Oxford\nUniversity Press, Oxford, pp. 453\u2013459.\ndoi:10.1093/acprof:oso/9780199231447.003.0020",
                "Currie, Gregory, 1995, \u201cVisual Imagery as the Simulation of\nVision\u201d, <em>Mind and Language</em>, 10(1\u20132): 25\u201344.\ndoi:10.1111/j.1468-0017.1995.tb00004.x",
                "\u2013\u2013\u2013, 2002, \u201cDesire in Imagination\u201d,\nin Tamar Szabo Gendler and John Hawthorne (eds.), <em>Conceivability\nand Possibility</em>, Oxford: Oxford University Press, pp.\n201\u2013221.",
                "Currie, Gregory and Ian Ravenscroft, 1997, \u201cMental\nSimulation and Motor Imagery\u201d, <em>Philosophy of Science</em>,\n64(1): 161\u201380. doi:10.1086/392541",
                "\u2013\u2013\u2013, 2002, <em>Recreative Minds: Imagination in\nPhilosophy and Psychology</em>, Oxford: Oxford University Press.\ndoi:10.1093/acprof:oso/9780198238089.001.0001",
                "Davies, Martin, 1987, \u201cTacit Knowledge and Semantic Theory:\nCan a Five per Cent Difference Matter?\u201d <em>Mind</em>, 96(384):\n441\u2013462. doi:10.1093/mind/XCVI.384.441",
                "Davies, Martin and Tony Stone (eds.), 1995a, <em>Folk Psychology:\nThe Theory of Mind Debate</em>, Oxford: Blackwell Publishers.",
                "\u2013\u2013\u2013 (eds.), 1995b, <em>Mental Simulation:\nEvaluations and Applications\u2014Reading in Mind and Language</em>,\nOxford: Blackwell Publishers.",
                "\u2013\u2013\u2013, 2001, \u201cMental Simulation, Tacit\nTheory, and the Threat of Collapse\u201d, <em>Philosophical\nTopics</em>, 29(1/2): 127\u2013173.\ndoi:10.5840/philtopics2001291/212",
                "Decety, Jean and Fran\u00e7ois Michel, 1989, \u201cComparative\nAnalysis of Actual and Mental Movement Times in Two Graphic\nTasks\u201d, <em>Brain and Cognition</em>, 11(1): 87\u201397.\ndoi:10.1016/0278-2626(89)90007-9",
                "De Jaegher, Hanne, Ezequiel Di Paolo, and Shaun Gallagher, 2010,\n\u201cCan Social Interaction Constitute Social\nCognition?\u201d<em>Trends in Cognitive Sciences</em>, 14(10):\n441\u2013447. doi:10.1016/j.tics.2010.06.009",
                "Dennett, Daniel C., 1987, <em>The Intentional Stance</em>,\nCambridge, MA: MIT Press.",
                "de Vignemont, Fr\u00e9d\u00e9rique, 2009, \u201cDrawing the\nBoundary Between Low-Level and High-Level Mindreading\u201d,\n<em>Philosophical Studies</em>, 144(3): 457\u2013466.\ndoi:10.1007/s11098-009-9354-1",
                "de Vignemont, Fr\u00e9d\u00e9rique and Hugo Mercier, 2016,\n\u201cUnder Influence: Is Altercentric Bias Compatible with\nSimulation Theory?\u201d in Brian P. McLaughlin and Hilary Kornblith\n(eds.), <em>Goldman and his Critics</em>, Oxford: Blackwell.\ndoi:10.1002/9781118609378.ch13",
                "Dilthey, Wilhelm, [1894] 1977, <em>Descriptive Psychology and\nHistorical Understanding</em>, Richard M. Zaner and Kenneth L. Heiges\n(trans.), with an introduction by Rudolf A. Makkreel, The Hague:\nMartinus Nijhof. doi:10.1007/978-94-009-9658-8",
                "di Pellegrino, G., L. Fadiga, L. Fogassi, V. Gallese, and G.\nRizzolatti, 1992, \u201cUnderstanding Motor Events: A\nNeuropsychological Study\u201d, <em>Experimental Brain Research</em>,\n91(1): 176\u2013180. doi:10.1007/BF00230027",
                "Doggett, Tyler and Andy Egan, 2007, \u201cWanting Things You\nDon\u2019t Want: The Case for an Imaginative Analogue of\nDesire\u201d, <em>Philosophers' Imprint</em>, 7(9).\n [<a href=\"http://hdl.handle.net/2027/spo.3521354.0007.009\" target=\"other\">Doggett and Egan 2007 available online</a>]",
                "Evans, Gareth, 1982, <em>The Varieties of Reference</em>, Oxford:\nOxford University Press.",
                "Fisher, Justin C., 2006, \u201cDoes Simulation Theory Really\nInvolve Simulation?\u201d <em>Philosophical Psychology</em>, 19(4):\n417\u2013432. doi:10.1080/09515080600726377",
                "Fuller, Gary, 1995, \u201cSimulation and Psychological\nConcepts\u201d, in Davies and Stone 1995b: chapter 1, pp.\n19\u201332",
                "Funkhouser, Eric and Shannon Spaulding, 2009, \u201cImagination\nand Other Scripts\u201d, <em>Philosophical Studies</em>, 143(3):\n291\u2013314. doi:10.1007/s11098-009-9348-z",
                "Gallagher, Shaun, 2001, \u201cThe Practice of Mind: Theory,\nSimulation, or Primary Interaction?\u201d <em>Journal of\nConsciousness Studies</em>, 8(5\u20137): 83\u2013108.",
                "\u2013\u2013\u2013, 2007, \u201cSimulation Trouble\u201d,\n<em>Social Neuroscience</em>, 2(3\u20134): 353\u2013365.\ndoi:10.1080/17470910601183549",
                "Gallagher, Shaun and Daniel D. Hutto, 2008, \u201cUnderstanding\nOthers Through Primary Interaction and Narrative Practice\u201d, in\nJordan Zlatev, Timothy P. Racine, Chris Sinha, &amp; Esa Itkonen\n(eds.), <em>The Shared Mind: Perspectives on Intersubjectivity</em>,\nAmsterdam: John Benjamins, pp. 17\u201338.\ndoi:10.1075/celcr.12.04gal",
                "Gallese, Vittorio, 2001, \u201cThe \u2018Shared Manifold\u2019\nHypothesis: From Mirror Neurons to Empathy\u201d, <em>Journal of\nConsciousness Studies</em>, 8(5\u20137): 33\u201350.",
                "\u2013\u2013\u2013, 2007, \u201cBefore and Below \u2018Theory\nof Mind\u2019: Embodied Simulation and the Neural Correlates of\nSocial Cognition\u201d, <em>Philosophical Transactions of the Royal\nSociety B</em>, 362: 659\u2013669. doi:10.1098/rstb.2006.2002",
                "Gallese, Vittorio and Alvin Goldman, 1998, \u201cMirror Neurons\nand the Simulation Theory of Mind-reading\u201d, <em>Trends in\nCognitive Sciences</em>, 2(12): 493\u2013501.\ndoi:10.1016/S1364-6613(98)01262-5",
                "Gallese, Vittorio and Corrado Sinigaglia, 2011, \u201cWhat is so\nSpecial about Embodied Simulation?\u201d <em>Trends in Cognitive\nScience</em>, 15(11): 512\u20139. doi:10.1016/j.tics.2011.09.003",
                "Gallese, Vittorio, Luciano Fadiga, Leonardo Fogassi, and Giacomo\nRizzolatti, 1996, \u201cAction Recognition in the Premotor\nCortex\u201d, <em>Brain</em>, 119(2): 593\u2013609.\ndoi:10.1093/brain/119.2.593",
                "Gallese, Vittorio, Leonardo Fogassi, Luciano Fadiga, and Giacomo\nRizzolatti, 2002, \u201cAction Representation and the Inferior\nParietal Lobule\u201d, in Wolfgang Prinz and Bernhard Hommel (eds.),\n<em>Common Mechanisms in Perception and Action</em> (Attention and\nPerformance XIX), Oxford: Oxford University Press, pp.\n247\u2013266.",
                "Gallese, Vittorio, Christian Keysers, and Giacomo Rizzolatti,\n2004, \u201cA Unifying View of the Basis of Social Cognition\u201d,\n<em>Trends in Cognitive Sciences</em>: 8(9): 396\u2013403.\ndoi:10.1016/j.tics.2004.07.002",
                "Gari\u00e9py, Jean-Fran\u00e7ois, Karli K. Watson, Emily Du,\nDiana L. Xie, Joshua Erb, Dianna Amasino, and Michael L. Platt, 2014,\n\u201cSocial Learning in Humans and Other Animals\u201d,\n<em>Frontiers in Neuroscience</em>, 31 March 2014,\ndoi:10.3389/fnins.2014.00058.",
                "Gergely, Gy\u00f6rgy and Gergely Csibra, 2003, \u201cTeleological\nReasoning in Infancy: The Na\u00efve Theory of Rational Action\u201d,\n<em>Trends in Cognitive Sciences</em>, 7(7): 287\u2013292.\ndoi:10.1016/S1364-6613(03)00128-1",
                "Gergely, Gy\u00f6rgy, Zolt\u00e1n N\u00e1dasdy, Gergely\nCsibra, and Szilvia B\u00edr\u00f3, 1995, \u201cTaking the\nIntentional Stance at 12 Months of Age\u201d, <em>Cognition</em>,\n56(2): 165\u201393. doi:10.1016/0010-0277(95)00661-H",
                "Goldenberg, Georg, Wolf M\u00fcllbacher, and Andreas Nowak, 1995,\n\u201cImagery without Perception: A Case Study of Anosognosia for\nCortical Blindness\u201d, <em>Neuropsychologia</em>, 33(11):\n1373\u20131382. doi:10.1016/0028-3932(95)00070-J",
                "Goldman, Alvin I., 1989, \u201cInterpretation\nPsychologized\u201d, <em>Mind and Language</em>, 4(3): 161\u2013185;\nreprinted in Davies and Stone 1995a, pp. 74\u201399.\ndoi:10.1111/j.1468-0017.1989.tb00249.x",
                "\u2013\u2013\u2013, 2002, \u201cSimulation Theory and Mental\nConcepts\u201d, in J\u00e9r\u00f4me Dokic &amp; Jo\u00eblle Proust\n(eds.), <em>Simulation and Knowledge of Action</em>, Amsterdam ;\nPhiladelphia: John Benjamins, 35\u201371.",
                "\u2013\u2013\u2013, 2006, <em>Simulating Minds: The Philosophy,\nPsychology, and Neuroscience of Mindreading</em>, Oxford: Oxford\nUniversity Press. doi:10.1093/0195138929.001.0001",
                "\u2013\u2013\u2013, 2008a, \u201cHurley on Simulation\u201d,\n<em>Philosophy and Phenomenological Research</em>, 77(3):\n775\u2013788. doi:10.1111/j.1933-1592.2008.00221.x",
                "\u2013\u2013\u2013, 2008b, \u201cMirroring, Mindreading, and\nSimulation\u201d, in Jaime A. Pineda (ed.), <em>Mirror Neuron\nSystems: The Role of Mirroring Processes in Social Cognition</em>, New\nYork: Humana Press, pp. 311\u2013330.\ndoi:10.1007/978-1-59745-479-7_14",
                "\u2013\u2013\u2013, 2009, \u201c<em>Pr\u00e9cis</em> of\n<em>Simulating Minds: : The Philosophy, Psychology, and Neuroscience\nof Mindreading</em>\u201d and \u201cReplies to Perner and Brandl,\nSaxe, Vignemont, and Carruthers\u201d, <em>Philosophical Studies</em>\n144(3): 431\u2013434, 477\u2013491. doi:10.1007/s11098-009-9355-0\nand doi:10.1007/s11098-009-9358-x",
                "\u2013\u2013\u2013, 2012a, \u201cA Moderate Approach to\nEmbodied Cognitive Science\u201d, <em>Review of Philosophy and\nPsychology</em>, 3(1): 71\u201388. doi:10.1007/s13164-012-0089-0",
                "\u2013\u2013\u2013, 2012b, \u201cTheory of Mind\u201d, in\nEric Margolis, Richard Samuels, and Stephen P. Stich (eds.), <em>The\nOxford Handbook of Philosophy of Cognitive Science</em>, Oxford:\nOxford University Press, 402\u2013424.\ndoi:10.1093/oxfordhb/9780195309799.013.0017",
                "Goldman, Alvin I. and Lucy C. Jordan, 2013, \u201cMindreading by\nSimulation: The Roles of Imagination and Mirroring\u201d, in Simon\nBaron-Cohen, Michael Lombardo, and Helen Tager-Flusberg (eds.),\n<em>Understanding Other Minds: Perspectives From Developmental Social\nNeuroscience</em>, Oxford: Oxford University Press, 448\u2013466.\ndoi:10.1093/acprof:oso/9780199692972.003.0025",
                "Goldman, Alvin I. and Chandra Sekhar Sripada, 2005,\n\u201cSimulationist Models of Face-Based Emotion\nRecognition\u201d,<em>Cognition</em>, 94(3): 193\u2013213.\ndoi:10.1016/j.cognition.2004.01.005",
                "Gopnik, Alison and Andrew N. Meltzoff, 1997, <em>Words, Thoughts,\nand Theories</em>, Cambridge, MA: Bradford Books/MIT Press.",
                "Gopnik, Alison and Henry M. Wellman, 1992, \u201cWhy the Child's\nTheory of Mind Really Is a Theory\u201d, <em>Mind and Language</em>,\n7(1\u20132): 145\u201371: reprinted in Davies and Stone 1995a, pp.\n232\u2013258. doi:10.1111/j.1468-0017.1992.tb00202.x",
                "\u2013\u2013\u2013, 2012, \u201cReconstructing Constructivism:\nCausal Models, Bayesian Learning Mechanisms, and the\nTheory-Theory\u201d, <em>Psychological Bulletin</em>\u201d,\n138(6):1085\u2013108. doi:10.1037/a0028044",
                "Gordon, Robert M., 1986, \u201cFolk Psychology as\nSimulation\u201d, <em>Mind and Language</em>, 1(2): 158\u2013171;\nreprinted in Davies and Stone 1995a, pp. 60\u201373.\ndoi:10.1111/j.1468-0017.1986.tb00324.x",
                "\u2013\u2013\u2013, 1995, \u201cSimulation Without\nIntrospection or Inference From Me to You\u201d, in Davies &amp;\nStone 1995b: 53\u201367.",
                "\u2013\u2013\u2013, 1996, \u201c\u2018Radical\u2019\nSimulationism\u201d, in Carruthers &amp; Smith 1996: 11\u201321.\ndoi:10.1017/CBO9780511597985.003",
                "\u2013\u2013\u2013, 2000, \u201cSellars\u2019s Rylean\nRevisited\u201d, <em>Protosoziologie</em>, 14: 102\u2013114.",
                "\u2013\u2013\u2013, 2005, \u201cIntentional Agents Like\nMyself,\u201d, in <em>Perspectives on Imitation: From Mirror Neurons\nto Memes</em>, S. Hurley &amp; N. Chater (eds.), Cambridge, MA: MIT\nPress",
                "\u2013\u2013\u2013, 2007, \u201cAscent Routines for\nPropositional Attitudes\u201d, <em>Synthese</em>, 159 (2):\n151\u2013165. doi:10.1007/s11229-007-9202-9",
                "Harris, Paul L., 1989, <em>Children and Emotion</em>, Oxford:\nBlackwell Publishers.",
                "\u2013\u2013\u2013, 1992, \u201cFrom Simulation to Folk\nPsychology: The Case for Development\u201d, <em>Mind and\nLanguage</em>, 7(1\u20132): 120\u2013144; reprinted in Davies and\nStone 1995a, pp. 207\u2013231.\ndoi:10.1111/j.1468-0017.1992.tb00201.x",
                "Heal, Jane, 1986, \u201cReplication and Functionalism\u201d, in\n<em>Language, Mind, and Logic</em>, J. Butterfield (ed.), Cambridge:\nCambridge University Press; reprinted in Davies and Stone 1995a, pp.\n45\u201359.",
                "\u2013\u2013\u2013, 1994, \u201cSimulation vs Theory-Theory:\nWhat is at Issue?\u201d in Christopher Peacocke (ed.),\n<em>Objectivity, Simulation, and the Unity of Consciousness: Current\nIssues in the Philosophy of Mind</em> (Proceedings of the British\nAcademy, 83), Oxford: Oxford University Press, pp. 129\u2013144.\n [<a href=\"http://www.britac.ac.uk/pubs/proc/volumes/pba83.html\" target=\"other\">Heal 1994 available online</a>]",
                "\u2013\u2013\u2013, 1995, \u201cHow to Think About\nThinking\u201d, in Davies and Stone 1995b: chapter 2, pp.\n33\u201352.",
                "\u2013\u2013\u2013, 1998, \u201cCo-Cognition and Off-Line\nSimulation: Two Ways of Understanding the Simulation Approach\u201d,\n<em>Mind and Language</em>, 13(4): 477\u2013498.\ndoi:10.1111/1468-0017.00088",
                "\u2013\u2013\u2013, 2003, <em>Mind, Reason and\nImagination</em>, Cambridge: Cambridge University Press.",
                "Helming, Katharina A., Brent Strickland, and Pierre Jacob, 2014,\n\u201cMaking Sense of Early False-Belief Understanding\u201d,\n<em>Trends in Cognitive Sciences</em>, 18(4): 167\u2013170.\ndoi:10.1016/j.tics.2014.01.005",
                "Herschbach, Mitchell, 2012, \u201cMirroring Versus Simulation: On\nthe Representational Function of Simulation\u201d, <em>Synthese</em>,\n189(3): 483\u201351. doi:10.1007/s11229-011-9969-6",
                "Hickok, Gregory, 2009, \u201cEight Problems for the Mirror Neuron\nTheory of Action Understanding in Monkeys and Humans\u201d,\n<em>Journal of Cognitive of Neuroscience</em>, 21(7): 1229\u20131243.\ndoi:10.1162/jocn.2009.21189",
                "\u2013\u2013\u2013, 2014, <em>The Myth of Mirror Neurons: The\nReal Neuroscience of Communication and Cognition</em>, New York:\nNorton.",
                "Hume, David, 1739, <em>A Treatise of Human Nature</em>, edited by\nL.A. Selby-Bigge, 2<sup>nd</sup> edition, revised by P.H. Nidditch,\nOxford: Clarendon Press, 1975",
                "Hurley, Susan, 2005, \u201cThe Shared Circuits Hypothesis: A\nUnified Functional Architecture for Control, Imitation, and\nSimulation\u201d, in <em>Perspectives on Imitation: From Neuroscience\nto Social Science, Volume 1: Mechanisms of Imitation and Imitation in\nAnimals</em>, Susan Hurley &amp; Nick Chater (eds.), Cambridge, MA:\nMIT Press, pp. 177\u2013193.",
                "\u2013\u2013\u2013, 2008, \u201cUnderstanding\nSimulation\u201d, <em>Philosophy and Phenomenological Research</em>,\n77(3): 755\u2013774. doi:10.1111/j.1933-1592.2008.00220.x",
                "Jackson, Frank, 1999, \u201cAll That Can Be at Issue in the\nTheory-Theory Simulation Debate\u201d, <em>Philosophical Papers</em>,\n28(2): 77\u201395. doi:10.1080/05568649909506593",
                "Jacob, Pierre, 2008, \u201cWhat do Mirror Neurons Contribute to\nHuman Social Cognition?\u201d, <em>Mind and Language</em>, 23(2):\n190\u2013223. doi:10.1111/j.1468-0017.2007.00337.x",
                "\u2013\u2013\u2013, 2012, \u201cSharing and Ascribing\nGoals\u201d, <em>Mind and Language</em>, 27(2): 200\u2013227.\ndoi:10.1111/j.1468-0017.2012.01441.x",
                "Jeannerod, Marc and Elisabeth Pacherie, 2004, \u201cAgency,\nSimulation and Self-Identification\u201d, <em>Mind and Language</em>\n19(2): 113\u2013146. doi:10.1111/j.1468-0017.2004.00251.x",
                "Kieran, Matthew and Dominic McIver Lopes (eds.), 2003,\n<em>Imagination, Philosophy, and the Arts</em>, London:\nRoutledge.",
                "Kosslyn, S.M., A. Pascual-Leone, O. Felician, S. Camposano, J.P.\nKeenan, W.L. Thompson, G. Ganis, K.E. Sukel, and N.M. Alpert, 1999,\n\u201cThe Role of Area 17 in Visual Imagery: Convergent Evidence from\nPET and rTMS\u201d, <em>Science</em>, 284(5411): 167\u2013170.\ndoi:10.1126/science.284.5411.167 ",
                "Leslie, Alan M., 1994, \u201cPretending and Believing: Issues in\nthe Theory of ToMM\u201d, <em>Cognition</em>, 50(1\u20133):\n211\u2013238 . doi:10.1016/0010-0277(94)90029-9",
                "Lipps, Theodor, 1903, \u201cEinf\u00fchlung, Innere Nachahmung\nund Organempfindung\u201d, <em>Archiv f\u00fcr gesamte\nPsychologie</em>, 1: 465\u2013519. Translated as \u201cEmpathy,\nInner Imitation and Sense-Feelings\u201d, in <em>A Modern Book of\nEsthetics</em>, New York: Holt, Rinehart and Winston, 1979, pp.\n374\u2013382.",
                "Lurz, Robert W., 2011, <em>Mindreading Animals</em>, Cambridge,\nMA: MIT Press. doi:10.7551/mitpress/9780262016056.001.0001",
                "Machamer, Peter, Lindley Darden, and Carl F. Craver, 2000,\n\u201cThinking about Mechanisms\u201d, <em>Philosophy of\nscience</em>, 67(1): 1\u201325. doi:10.1086/392759",
                "Marr, D., 1982. <em>Vision</em>, San Francisco: Freeman\nPress.",
                "Nichols, Shaun (ed.), 2006a, <em>The Architecture of the\nImagination: New Essays on Pretense, Possibility, and Fiction</em>,\nOxford: Oxford University Press.\ndoi:10.1093/acprof:oso/9780199275731.001.0001",
                "\u2013\u2013\u2013, 2006b, \u201cJust the Imagination: Why\nImagining Doesn't Behave Like Believing\u201d, <em>Mind &amp;\nLanguage</em>, 21(4): 459\u2013474.\ndoi:10.1111/j.1468-0017.2006.00286.x",
                "Nichols, Shaun and Stephen P. Stich, 2003, <em>Mindreading: An\nIntegrated Account of Pretence, Self-Awareness, and Understanding of\nOther Minds</em>, Oxford: Oxford University Press.\ndoi:10.1093/0198236107.001.0001",
                "Onishi, Kristine H. and Ren\u00e9e Baillargeon, 2005, \u201cDo\n15-Month-Old Infants Understand False Beliefs?\u201d\n<em>Science</em>, 308(5719): 255\u2013258.\ndoi:10.1126/science.1107621",
                "Pacherie, Elisabeth, 2000, \u201cThe Content of\nIntentions\u201d, <em>Mind and Language</em>, 15(4): 400\u2013432.\ndoi:10.1111/1468-0017.00142",
                "Peackocke, C. 2005, \u201cAnother I: Representing Conscious\nStates, Perception, and Others\u201d, in J. L. Berm\u00fadez (ed.),\n<em>Thought, Reference, and Experience: Themes From the Philosophy of\nGareth Evans</em>, Oxford: Clarendon Press",
                "Perner, Josef and Deborah Howes, 1992, \u201c\u2018He Thinks he\nKnows\u2019 and more Developmental Evidence Against the Simulation\n(Role-Taking) Theory\u201d, <em>Mind and Language</em>, 7(1\u20132):\n72\u201386; reprinted in Davies and Stone 1995a, pp. 159\u2013173.\ndoi:10.1111/j.1468-0017.1992.tb00197.x",
                "Perner Josef and Anton K\u00fchberger, 2005, \u201cMental\nSimulation: Royal Road to Other Minds?\u201d, in Bertram F. Malle and\nSara D. Hodges (eds.), <em>Other Minds: How Humans Bridge the Divide\nBetween Self and Others</em>, New York: Guilford Press, pp.\n174\u2013187.",
                "Perner, Josef and Ted Ruffman, 2005, \u201cInfants\u2019 Insight\nin to the Mind: How Deep?\u201d <em>Science</em>, 308(5719):\n214\u2013216. doi:10.1126/science.1111656 ",
                "Ramsey, William M., 2010, \u201cHow Not to Build a Hybrid:\nSimulation vs. Fact-finding\u201d, <em>Philosophical Psychology</em>,\n23(6): 775\u2013795. doi:10.1080/09515089.2010.529047",
                "Rizzolatti, Giacomo and Laila Craighero, 2004, \u201cThe\nMirror-Neuron System\u201d, <em>Annual Review of Neuroscience</em>,\n27: 169\u201392. doi:10.1146/annurev.neuro.27.070203.144230 ",
                "Rizzolatti, Giacomo &amp; Corrado Sinigaglia, 2007, \u201cMirror\nneurons and motor intentionality\u201d, <em>Functional\nNeurology</em>, 22(4): 205\u2013210",
                "\u2013\u2013\u2013, 2010, \u201cThe Functional Role of the\nParieto-Frontal Mirror Circuit: Interpretations and\nMisinterpretations\u201d, <em>Nature Reviews Neuroscience</em> 11:\n264\u2013274. doi:10.1038/nrn2805",
                "\u2013\u2013\u2013, 2014, \u201cReview: A Curious Book on\nMirror Neurons and Their Myth\u201d, <em>The American Journal of\nPsychology</em>, 128(4): 527\u2013533.\ndoi:10.5406/amerjpsyc.128.4.0527 ",
                "\u2013\u2013\u2013, forthcoming, \u201cThe Mirror Mechanism: a\nBasic Principle of Brain Function\u201d, <em>Nature Reviews\nNeuroscience</em>, 17: 757\u2013765. doi:10.1038/nrn.2016.135",
                "Rizzolatti, G., R. Camarda, L. Fogassi, M. Gentilucci, G. Luppino,\nand M. Matelli, 1988, \u201cFunctional Organization of Inferior Area\n6 in the Macaque Monkey\u201d, <em>Experimental Brain Research</em>,\n71(1): 491\u2013507. doi:10.1007/BF00248742",
                "Rizzolatti, Giacomo, Luciano Fadiga, Vittorio Gallese, and\nLeonardo Fogassi, 1996, \u201cPremotor Cortex and the Recognition of\nMotor Actions\u201d, <em>Cognitive Brain Research</em>, 3(2):\n131\u2013141. doi:10.1016/0926-6410(95)00038-0",
                "Rozin, Paul, Jonathan Haidt, and Clark R. McCauley, 2008,\n\u201cDisgust\u201d, in Michael Lewis, Jeannette M.\nHaviland\u2013Jones &amp; Lisa Feldman Barrett (eds.), <em>Handbook\nof Emotions</em> (3rd edition), New York: Guilford Press, pp.\n757\u2013776.",
                "Saxe, Rebbecca, 2005, \u201cAgainst Simulation: The Argument from\nError\u201d, <em>Trends in Cognitive Sciences</em>, 9(4):\n174\u2013179. doi:10.1016/j.tics.2005.01.012",
                "Scholl, Brian J. and Alan M. Leslie, 1999, \u201cModularity,\nDevelopment and Theory of Mind\u201d, <em>Mind and Language</em>,\n14(1): 131\u2013153. doi:10.1111/1468-0017.00106",
                "Singer, Tania, Ben Seymour, John O\u2019Doherty, Holger Kaube,\nRaymond J. Dolan, and Chris D. Frith, 2004, \u201cEmpathy for Pain\nInvolves the Affective but not Sensory Components of Pain\u201d,\n<em>Science</em>, 303(5661): 1157\u2013 1162.\ndoi:10.1126/science.1093535",
                "Smith, Adam, 1759, <em>The Theory of Moral Sentiments</em>, D.D.\nRaphael and A.L. Macfie (eds.), Oxford: Oxford University Press,\n1976.",
                "Spaulding, Shannon, 2012, \u201cMirror Neurons are not Evidence\nfor the Simulation Theory\u201d, <em>Synthese</em>, 189(3):\n515\u2013534. doi:10.1007/s11229-012-0086-y",
                "Spivey, Michael J., Daniel C. Richardson, Melinda J. Tyler, and\nEzekiel E. Young, 2000, \u201cEye movements During Comprehension of\nSpoken Scene Descriptions\u201d, in <em>Proceedings of the\n22<sup>nd</sup> Annual Conference of the Cognitive Science\nSociety</em>, Mahwah, NJ: Erlbaum, pp. 487\u2013492.",
                "Stich, Stephen and Shaun Nichols, 1992, \u201cFolk Psychology:\nSimulation or Tacit Theory?\u201d, <em>Mind and Language</em>,\n7(1\u20132): 35\u201371; reprinted in Davies and Stone 1995a, pp.\n123\u2013158. doi:10.1111/j.1468-0017.1992.tb00196.x",
                "\u2013\u2013\u2013, 1997, \u201cCognitive Penetrability,\nRationality, and Restricted Simulation\u201d, <em>Mind and\nLanguage</em>, 12(3\u20134): 297\u2013326.\ndoi:10.1111/j.1468-0017.1997.tb00076.x",
                "Stich, Stephen and Ian Ravenscroft, 1992, \u201cWhat <em>is</em>\nFolk Psychology?\u201d <em>Cognition</em>, 50(1\u20133):\n447\u201368. doi:10.1016/0010-0277(94)90040-X",
                "Velleman, J. David, 2000, \u201cThe Aim of Belief\u201d, in\n<em>The Possibility of Practical Reason</em>, Oxford: Oxford\nUniversity Press, pp. 244\u2013282",
                "Vannuscorps, Gilles and Alfonso Caramazza, 2015, \u201cTypical\nAction Perception and Interpretation without Motor Simulation\u201d,\n<em>Proceedings of the National Academy of Sciences</em>, 113(1):\n1\u20136. doi:10.1073/pnas.1516978112",
                "Wellman, Henry M., David Cross, and Julanne Watson, 2001,\n\u201cMeta-Analysis of Theory-of-Mind Development: The Truth about\nFalse Belief\u201d, <em>Child Development</em>, 72(3): 655\u2013684.\ndoi:10.1111/1467-8624.00304",
                "Wicker, Bruno, Christian Keysers, Jane Plailly, Jean-Pierre Royet,\nVittorio Gallese, and Giacomo Rizzolatti, 2003, \u201cBoth of us\nDisgusted in <em>My</em> Insula: The Common Neural Basis of Seeing and\nFeeling Disgust\u201d, <em>Neuron</em>, 40(3): 655\u2013664.\ndoi:10.1016/S0896-6273(03)00679-2",
                "Wimmer, Heinz and Josef Perner, 1983, \u201cBeliefs About\nBeliefs: Representation and Constraint Function of Wrong Beliefs in\nYoung Children\u2019s Understanding of Deception\u201d,\n<em>Cognition</em>, 13(1): 103\u2013128.\ndoi:10.1016/0010-0277(83)90004-5"
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Anderson, Michael L., 2008, \u201cNeural Reuse: A Fundamental\nOrganizational Principle of the Brain\u201d, <em>Behavioral and Brain\nScience</em>, 20(4): 239\u2013313. doi:10.1017/S0140525X10000853</li>\n<li>\u2013\u2013\u2013, 2015, <em>After Phrenology: Neural Reuse\nand the Interactive Brain</em>, Cambridge, MA: MIT Press.</li>\n<li>Apperly, Ian A. and Stephen A. Butterfill, 2009, \u201cDo Humans\nHave Two Systems to Track Beliefs and Belief-Like States?\u201d,\n<em>Psychological Review</em>, 116(4): 953\u201370.\ndoi:10.1037/a0016923</li>\n<li>Avenanti, Alessio, Domenica Bueti, Gaspare Galati, &amp; Salvatore\nM. Aglioti, 2005, \u201cTranscranial Magnetic Stimulation Highlights\nthe Sensorimotor Side of Empathy for Pain\u201d, <em>Nature\nNeuroscience</em>, 8(7): 955\u2013960. doi:10.1038/nn1481</li>\n<li>Baillargeon, Ren\u00e9e, Rose M. Scott, and Zijing He, 2010,\n\u201cFalse-Belief Understanding in Infants\u201d, <em>Trends in\nCognitive Sciences</em>, 14(3): 110\u2013118.\ndoi:10.1016/j.tics.2009.12.006</li>\n<li>Baillargeon, Ren\u00e9e, Rose M. Scott, and Lin Bian, 2016,\n\u201cPsychological Reasoning in Infancy\u201d, <em>Annual Review of\nPsychology</em>, 67: 159\u2013186.\ndoi:10.1146/annurev-psych-010213-115033 </li>\n<li>Barlassina, Luca, 2013, \u201cSimulation is not Enough: A Hybrid\nModel of Disgust Attribution on the Basis of Visual Stimuli\u201d,\n<em>Philosophical Psychology</em>, 26(3): 401\u2013419.\ndoi:10.1080/09515089.2012.659167</li>\n<li>Baron-Cohen, Simon, 2000, \u201cTheory of Mind and Autism: A\nFifteen Year Review\u201d, in Simon Baron-Cohen, Helen\nTager-Flusberg, and Donald J. Cohen (eds.); <em>Understanding Other\nMinds: Perspectives from Developmental Cognitive Neuroscience</em>\n(2nd edition), New York: Oxford University Press, pp. 3\u201320.</li>\n<li>Bechtel, William, 2008, <em>Mental Mechanisms: Philosophical\nPerspectives on Cognitive Neuroscience</em>, New York: Taylor and\nFrancis.</li>\n<li>Birch, Susan A. and Paul Bloom, 2007, \u201cThe Curse of\nKnowledge in Reasoning About False Beliefs\u201d, <em>Psychological\nScience</em>, 18(5): 382\u2013386.\ndoi:10.1111/j.1467-9280.2007.01909.x</li>\n<li>Bisiach, Edoardo and Claudio Luzzatti, 1978, \u201cUnilateral\nNeglect of Representational Space\u201d, <em>Cortex</em>, 14(1):\n129\u2013133. doi:10.1016/S0010-9452(78)80016-1</li>\n<li>Blakemore, S.-J., D. Bristow, G. Bird, C. Frith, and J. Ward,\n2005, \u201cSomatosensory Activations During the Observation of Touch\nand a Case of Vision-Touch Synaesthesia\u201d, <em>Brain</em>,\n128(7): 1571\u20131583. doi:10.1093/brain/awh500</li>\n<li>Bloom, Paul and Tim P. German, 2000, \u201cTwo Reasons to Abandon\nthe False Belief Task as a Test of Theory of Mind\u201d,\n<em>Cognition</em>, 77(1): B25\u201331.\ndoi:10.1016/S0010-0277(00)00096-2</li>\n<li>Botterill, George and Peter Carruthers, 1999, <em>The Philosophy\nof Psychology</em>, Cambridge: Cambridge University Press.</li>\n<li>Brass, Marcel, Ruth M. Schmitt, Stephanie Spengler, and\nGy\u00f6rgy Gergely, 2007, \u201cInvestigating Action Understanding:\nInferential Processes versus Action Simulation\u201d, <em>Current\nBiology</em>, 17(24): 2117\u20132121.\ndoi:10.1016/j.cub.2007.11.057</li>\n<li>Brozzo, Chiara, forthcoming, \u201cMotor Intentions: How\nIntentions and Motor Representations Come Together\u201d, <em>Mind\n&amp; Language</em>.</li>\n<li>Buckner, Randy L. and Daniel C. Carroll, 2007,\n\u201cSelf-Projection and the Brain\u201d, <em>Trends in Cognitive\nScience</em>, 11(2): 49\u201357. doi:10.1016/j.tics.2006.11.004</li>\n<li>Butterfill, Stephen A. and Corrado Sinigaglia, 2014,\n\u201cIntention and Motor Representation in Purposive Action\u201d,\n<em>Philosophy and Phenomenological Research</em>, 88(1):\n119\u2013145. doi:10.1111/j.1933-1592.2012.00604.x</li>\n<li>Carruthers, Peter, 1996, \u201cSimulation and Self-Knowledge: A\nDefense of Theory-Theory\u201d, in Carruthers and Smith 1996:\n22\u201338. doi:10.1017/CBO9780511597985.004</li>\n<li>\u2013\u2013\u2013, 2009, \u201cHow we Know Our Own Minds: The\nRelationship between Mindreading and Metacognition\u201d,\n<em>Behavioral and Brain Sciences</em>, 32(2): 121\u2013138.\ndoi:10.1017/S0140525X09000545</li>\n<li>\u2013\u2013\u2013, 2011, <em>The Opacity of Mind: An\nIntegrative Theory of Self-Knowledge</em>, Oxford: Oxford University\nPress. doi:10.1093/acprof:oso/9780199596195.001.0001</li>\n<li>\u2013\u2013\u2013, 2013, \u201cMindreading in Infancy\u201d,\n<em>Mind and Language</em>, 28(2): 141\u2013172.\ndoi:10.1111/mila.12014</li>\n<li>Carruthers, Peter and Peter K. Smith (eds.), 1996, <em>Theories of\nTheories of Mind</em>, Cambridge: Cambridge University Press.\ndoi:10.1017/CBO9780511597985</li>\n<li>Clements, Wendy A. and Josef Perner, 1994, \u201cImplicit\nUnderstanding of Belief\u201d, <em>Cognitive Development</em>, 9(4):\n377\u2013395. doi:10.1016/0885-2014(94)90012-4</li>\n<li>Craver, Carl F., 2007, <em>Explaining the Brain. Mechanisms and\nthe Mosaic Unity of Neuroscience</em>, Oxford: Oxford University\nPress. doi:10.1093/acprof:oso/9780199299317.001.0001</li>\n<li>Csibra, Gergely, 2007, \u201cAction Mirroring and Action\nUnderstanding: An Alternative Account\u201d, in Patrick Haggard, Yves\nRosetti, and Mitsuo Kawato (eds.) <em>Sensorimotor Foundations of\nHigher Cognition. Attention and Performance XII</em>, Oxford\nUniversity Press, Oxford, pp. 453\u2013459.\ndoi:10.1093/acprof:oso/9780199231447.003.0020</li>\n<li>Currie, Gregory, 1995, \u201cVisual Imagery as the Simulation of\nVision\u201d, <em>Mind and Language</em>, 10(1\u20132): 25\u201344.\ndoi:10.1111/j.1468-0017.1995.tb00004.x</li>\n<li>\u2013\u2013\u2013, 2002, \u201cDesire in Imagination\u201d,\nin Tamar Szabo Gendler and John Hawthorne (eds.), <em>Conceivability\nand Possibility</em>, Oxford: Oxford University Press, pp.\n201\u2013221.</li>\n<li>Currie, Gregory and Ian Ravenscroft, 1997, \u201cMental\nSimulation and Motor Imagery\u201d, <em>Philosophy of Science</em>,\n64(1): 161\u201380. doi:10.1086/392541</li>\n<li>\u2013\u2013\u2013, 2002, <em>Recreative Minds: Imagination in\nPhilosophy and Psychology</em>, Oxford: Oxford University Press.\ndoi:10.1093/acprof:oso/9780198238089.001.0001</li>\n<li>Davies, Martin, 1987, \u201cTacit Knowledge and Semantic Theory:\nCan a Five per Cent Difference Matter?\u201d <em>Mind</em>, 96(384):\n441\u2013462. doi:10.1093/mind/XCVI.384.441</li>\n<li>Davies, Martin and Tony Stone (eds.), 1995a, <em>Folk Psychology:\nThe Theory of Mind Debate</em>, Oxford: Blackwell Publishers.</li>\n<li>\u2013\u2013\u2013 (eds.), 1995b, <em>Mental Simulation:\nEvaluations and Applications\u2014Reading in Mind and Language</em>,\nOxford: Blackwell Publishers.</li>\n<li>\u2013\u2013\u2013, 2001, \u201cMental Simulation, Tacit\nTheory, and the Threat of Collapse\u201d, <em>Philosophical\nTopics</em>, 29(1/2): 127\u2013173.\ndoi:10.5840/philtopics2001291/212</li>\n<li>Decety, Jean and Fran\u00e7ois Michel, 1989, \u201cComparative\nAnalysis of Actual and Mental Movement Times in Two Graphic\nTasks\u201d, <em>Brain and Cognition</em>, 11(1): 87\u201397.\ndoi:10.1016/0278-2626(89)90007-9</li>\n<li>De Jaegher, Hanne, Ezequiel Di Paolo, and Shaun Gallagher, 2010,\n\u201cCan Social Interaction Constitute Social\nCognition?\u201d<em>Trends in Cognitive Sciences</em>, 14(10):\n441\u2013447. doi:10.1016/j.tics.2010.06.009</li>\n<li>Dennett, Daniel C., 1987, <em>The Intentional Stance</em>,\nCambridge, MA: MIT Press.</li>\n<li>de Vignemont, Fr\u00e9d\u00e9rique, 2009, \u201cDrawing the\nBoundary Between Low-Level and High-Level Mindreading\u201d,\n<em>Philosophical Studies</em>, 144(3): 457\u2013466.\ndoi:10.1007/s11098-009-9354-1</li>\n<li>de Vignemont, Fr\u00e9d\u00e9rique and Hugo Mercier, 2016,\n\u201cUnder Influence: Is Altercentric Bias Compatible with\nSimulation Theory?\u201d in Brian P. McLaughlin and Hilary Kornblith\n(eds.), <em>Goldman and his Critics</em>, Oxford: Blackwell.\ndoi:10.1002/9781118609378.ch13</li>\n<li>Dilthey, Wilhelm, [1894] 1977, <em>Descriptive Psychology and\nHistorical Understanding</em>, Richard M. Zaner and Kenneth L. Heiges\n(trans.), with an introduction by Rudolf A. Makkreel, The Hague:\nMartinus Nijhof. doi:10.1007/978-94-009-9658-8</li>\n<li>di Pellegrino, G., L. Fadiga, L. Fogassi, V. Gallese, and G.\nRizzolatti, 1992, \u201cUnderstanding Motor Events: A\nNeuropsychological Study\u201d, <em>Experimental Brain Research</em>,\n91(1): 176\u2013180. doi:10.1007/BF00230027</li>\n<li>Doggett, Tyler and Andy Egan, 2007, \u201cWanting Things You\nDon\u2019t Want: The Case for an Imaginative Analogue of\nDesire\u201d, <em>Philosophers' Imprint</em>, 7(9).\n [<a href=\"http://hdl.handle.net/2027/spo.3521354.0007.009\" target=\"other\">Doggett and Egan 2007 available online</a>]</li>\n<li>Evans, Gareth, 1982, <em>The Varieties of Reference</em>, Oxford:\nOxford University Press.</li>\n<li>Fisher, Justin C., 2006, \u201cDoes Simulation Theory Really\nInvolve Simulation?\u201d <em>Philosophical Psychology</em>, 19(4):\n417\u2013432. doi:10.1080/09515080600726377</li>\n<li>Fuller, Gary, 1995, \u201cSimulation and Psychological\nConcepts\u201d, in Davies and Stone 1995b: chapter 1, pp.\n19\u201332</li>\n<li>Funkhouser, Eric and Shannon Spaulding, 2009, \u201cImagination\nand Other Scripts\u201d, <em>Philosophical Studies</em>, 143(3):\n291\u2013314. doi:10.1007/s11098-009-9348-z</li>\n<li>Gallagher, Shaun, 2001, \u201cThe Practice of Mind: Theory,\nSimulation, or Primary Interaction?\u201d <em>Journal of\nConsciousness Studies</em>, 8(5\u20137): 83\u2013108.</li>\n<li>\u2013\u2013\u2013, 2007, \u201cSimulation Trouble\u201d,\n<em>Social Neuroscience</em>, 2(3\u20134): 353\u2013365.\ndoi:10.1080/17470910601183549</li>\n<li>Gallagher, Shaun and Daniel D. Hutto, 2008, \u201cUnderstanding\nOthers Through Primary Interaction and Narrative Practice\u201d, in\nJordan Zlatev, Timothy P. Racine, Chris Sinha, &amp; Esa Itkonen\n(eds.), <em>The Shared Mind: Perspectives on Intersubjectivity</em>,\nAmsterdam: John Benjamins, pp. 17\u201338.\ndoi:10.1075/celcr.12.04gal</li>\n<li>Gallese, Vittorio, 2001, \u201cThe \u2018Shared Manifold\u2019\nHypothesis: From Mirror Neurons to Empathy\u201d, <em>Journal of\nConsciousness Studies</em>, 8(5\u20137): 33\u201350.</li>\n<li>\u2013\u2013\u2013, 2007, \u201cBefore and Below \u2018Theory\nof Mind\u2019: Embodied Simulation and the Neural Correlates of\nSocial Cognition\u201d, <em>Philosophical Transactions of the Royal\nSociety B</em>, 362: 659\u2013669. doi:10.1098/rstb.2006.2002</li>\n<li>Gallese, Vittorio and Alvin Goldman, 1998, \u201cMirror Neurons\nand the Simulation Theory of Mind-reading\u201d, <em>Trends in\nCognitive Sciences</em>, 2(12): 493\u2013501.\ndoi:10.1016/S1364-6613(98)01262-5</li>\n<li>Gallese, Vittorio and Corrado Sinigaglia, 2011, \u201cWhat is so\nSpecial about Embodied Simulation?\u201d <em>Trends in Cognitive\nScience</em>, 15(11): 512\u20139. doi:10.1016/j.tics.2011.09.003</li>\n<li>Gallese, Vittorio, Luciano Fadiga, Leonardo Fogassi, and Giacomo\nRizzolatti, 1996, \u201cAction Recognition in the Premotor\nCortex\u201d, <em>Brain</em>, 119(2): 593\u2013609.\ndoi:10.1093/brain/119.2.593</li>\n<li>Gallese, Vittorio, Leonardo Fogassi, Luciano Fadiga, and Giacomo\nRizzolatti, 2002, \u201cAction Representation and the Inferior\nParietal Lobule\u201d, in Wolfgang Prinz and Bernhard Hommel (eds.),\n<em>Common Mechanisms in Perception and Action</em> (Attention and\nPerformance XIX), Oxford: Oxford University Press, pp.\n247\u2013266.</li>\n<li>Gallese, Vittorio, Christian Keysers, and Giacomo Rizzolatti,\n2004, \u201cA Unifying View of the Basis of Social Cognition\u201d,\n<em>Trends in Cognitive Sciences</em>: 8(9): 396\u2013403.\ndoi:10.1016/j.tics.2004.07.002</li>\n<li>Gari\u00e9py, Jean-Fran\u00e7ois, Karli K. Watson, Emily Du,\nDiana L. Xie, Joshua Erb, Dianna Amasino, and Michael L. Platt, 2014,\n\u201cSocial Learning in Humans and Other Animals\u201d,\n<em>Frontiers in Neuroscience</em>, 31 March 2014,\ndoi:10.3389/fnins.2014.00058.</li>\n<li>Gergely, Gy\u00f6rgy and Gergely Csibra, 2003, \u201cTeleological\nReasoning in Infancy: The Na\u00efve Theory of Rational Action\u201d,\n<em>Trends in Cognitive Sciences</em>, 7(7): 287\u2013292.\ndoi:10.1016/S1364-6613(03)00128-1</li>\n<li>Gergely, Gy\u00f6rgy, Zolt\u00e1n N\u00e1dasdy, Gergely\nCsibra, and Szilvia B\u00edr\u00f3, 1995, \u201cTaking the\nIntentional Stance at 12 Months of Age\u201d, <em>Cognition</em>,\n56(2): 165\u201393. doi:10.1016/0010-0277(95)00661-H</li>\n<li>Goldenberg, Georg, Wolf M\u00fcllbacher, and Andreas Nowak, 1995,\n\u201cImagery without Perception: A Case Study of Anosognosia for\nCortical Blindness\u201d, <em>Neuropsychologia</em>, 33(11):\n1373\u20131382. doi:10.1016/0028-3932(95)00070-J</li>\n<li>Goldman, Alvin I., 1989, \u201cInterpretation\nPsychologized\u201d, <em>Mind and Language</em>, 4(3): 161\u2013185;\nreprinted in Davies and Stone 1995a, pp. 74\u201399.\ndoi:10.1111/j.1468-0017.1989.tb00249.x</li>\n<li>\u2013\u2013\u2013, 2002, \u201cSimulation Theory and Mental\nConcepts\u201d, in J\u00e9r\u00f4me Dokic &amp; Jo\u00eblle Proust\n(eds.), <em>Simulation and Knowledge of Action</em>, Amsterdam ;\nPhiladelphia: John Benjamins, 35\u201371.</li>\n<li>\u2013\u2013\u2013, 2006, <em>Simulating Minds: The Philosophy,\nPsychology, and Neuroscience of Mindreading</em>, Oxford: Oxford\nUniversity Press. doi:10.1093/0195138929.001.0001</li>\n<li>\u2013\u2013\u2013, 2008a, \u201cHurley on Simulation\u201d,\n<em>Philosophy and Phenomenological Research</em>, 77(3):\n775\u2013788. doi:10.1111/j.1933-1592.2008.00221.x</li>\n<li>\u2013\u2013\u2013, 2008b, \u201cMirroring, Mindreading, and\nSimulation\u201d, in Jaime A. Pineda (ed.), <em>Mirror Neuron\nSystems: The Role of Mirroring Processes in Social Cognition</em>, New\nYork: Humana Press, pp. 311\u2013330.\ndoi:10.1007/978-1-59745-479-7_14</li>\n<li>\u2013\u2013\u2013, 2009, \u201c<em>Pr\u00e9cis</em> of\n<em>Simulating Minds: : The Philosophy, Psychology, and Neuroscience\nof Mindreading</em>\u201d and \u201cReplies to Perner and Brandl,\nSaxe, Vignemont, and Carruthers\u201d, <em>Philosophical Studies</em>\n144(3): 431\u2013434, 477\u2013491. doi:10.1007/s11098-009-9355-0\nand doi:10.1007/s11098-009-9358-x</li>\n<li>\u2013\u2013\u2013, 2012a, \u201cA Moderate Approach to\nEmbodied Cognitive Science\u201d, <em>Review of Philosophy and\nPsychology</em>, 3(1): 71\u201388. doi:10.1007/s13164-012-0089-0</li>\n<li>\u2013\u2013\u2013, 2012b, \u201cTheory of Mind\u201d, in\nEric Margolis, Richard Samuels, and Stephen P. Stich (eds.), <em>The\nOxford Handbook of Philosophy of Cognitive Science</em>, Oxford:\nOxford University Press, 402\u2013424.\ndoi:10.1093/oxfordhb/9780195309799.013.0017</li>\n<li>Goldman, Alvin I. and Lucy C. Jordan, 2013, \u201cMindreading by\nSimulation: The Roles of Imagination and Mirroring\u201d, in Simon\nBaron-Cohen, Michael Lombardo, and Helen Tager-Flusberg (eds.),\n<em>Understanding Other Minds: Perspectives From Developmental Social\nNeuroscience</em>, Oxford: Oxford University Press, 448\u2013466.\ndoi:10.1093/acprof:oso/9780199692972.003.0025</li>\n<li>Goldman, Alvin I. and Chandra Sekhar Sripada, 2005,\n\u201cSimulationist Models of Face-Based Emotion\nRecognition\u201d,<em>Cognition</em>, 94(3): 193\u2013213.\ndoi:10.1016/j.cognition.2004.01.005</li>\n<li>Gopnik, Alison and Andrew N. Meltzoff, 1997, <em>Words, Thoughts,\nand Theories</em>, Cambridge, MA: Bradford Books/MIT Press.</li>\n<li>Gopnik, Alison and Henry M. Wellman, 1992, \u201cWhy the Child's\nTheory of Mind Really Is a Theory\u201d, <em>Mind and Language</em>,\n7(1\u20132): 145\u201371: reprinted in Davies and Stone 1995a, pp.\n232\u2013258. doi:10.1111/j.1468-0017.1992.tb00202.x</li>\n<li>\u2013\u2013\u2013, 2012, \u201cReconstructing Constructivism:\nCausal Models, Bayesian Learning Mechanisms, and the\nTheory-Theory\u201d, <em>Psychological Bulletin</em>\u201d,\n138(6):1085\u2013108. doi:10.1037/a0028044</li>\n<li>Gordon, Robert M., 1986, \u201cFolk Psychology as\nSimulation\u201d, <em>Mind and Language</em>, 1(2): 158\u2013171;\nreprinted in Davies and Stone 1995a, pp. 60\u201373.\ndoi:10.1111/j.1468-0017.1986.tb00324.x</li>\n<li>\u2013\u2013\u2013, 1995, \u201cSimulation Without\nIntrospection or Inference From Me to You\u201d, in Davies &amp;\nStone 1995b: 53\u201367.</li>\n<li>\u2013\u2013\u2013, 1996, \u201c\u2018Radical\u2019\nSimulationism\u201d, in Carruthers &amp; Smith 1996: 11\u201321.\ndoi:10.1017/CBO9780511597985.003</li>\n<li>\u2013\u2013\u2013, 2000, \u201cSellars\u2019s Rylean\nRevisited\u201d, <em>Protosoziologie</em>, 14: 102\u2013114.</li>\n<li>\u2013\u2013\u2013, 2005, \u201cIntentional Agents Like\nMyself,\u201d, in <em>Perspectives on Imitation: From Mirror Neurons\nto Memes</em>, S. Hurley &amp; N. Chater (eds.), Cambridge, MA: MIT\nPress</li>\n<li>\u2013\u2013\u2013, 2007, \u201cAscent Routines for\nPropositional Attitudes\u201d, <em>Synthese</em>, 159 (2):\n151\u2013165. doi:10.1007/s11229-007-9202-9</li>\n<li>Harris, Paul L., 1989, <em>Children and Emotion</em>, Oxford:\nBlackwell Publishers.</li>\n<li>\u2013\u2013\u2013, 1992, \u201cFrom Simulation to Folk\nPsychology: The Case for Development\u201d, <em>Mind and\nLanguage</em>, 7(1\u20132): 120\u2013144; reprinted in Davies and\nStone 1995a, pp. 207\u2013231.\ndoi:10.1111/j.1468-0017.1992.tb00201.x</li>\n<li>Heal, Jane, 1986, \u201cReplication and Functionalism\u201d, in\n<em>Language, Mind, and Logic</em>, J. Butterfield (ed.), Cambridge:\nCambridge University Press; reprinted in Davies and Stone 1995a, pp.\n45\u201359.</li>\n<li>\u2013\u2013\u2013, 1994, \u201cSimulation vs Theory-Theory:\nWhat is at Issue?\u201d in Christopher Peacocke (ed.),\n<em>Objectivity, Simulation, and the Unity of Consciousness: Current\nIssues in the Philosophy of Mind</em> (Proceedings of the British\nAcademy, 83), Oxford: Oxford University Press, pp. 129\u2013144.\n [<a href=\"http://www.britac.ac.uk/pubs/proc/volumes/pba83.html\" target=\"other\">Heal 1994 available online</a>]</li>\n<li>\u2013\u2013\u2013, 1995, \u201cHow to Think About\nThinking\u201d, in Davies and Stone 1995b: chapter 2, pp.\n33\u201352.</li>\n<li>\u2013\u2013\u2013, 1998, \u201cCo-Cognition and Off-Line\nSimulation: Two Ways of Understanding the Simulation Approach\u201d,\n<em>Mind and Language</em>, 13(4): 477\u2013498.\ndoi:10.1111/1468-0017.00088</li>\n<li>\u2013\u2013\u2013, 2003, <em>Mind, Reason and\nImagination</em>, Cambridge: Cambridge University Press.</li>\n<li>Helming, Katharina A., Brent Strickland, and Pierre Jacob, 2014,\n\u201cMaking Sense of Early False-Belief Understanding\u201d,\n<em>Trends in Cognitive Sciences</em>, 18(4): 167\u2013170.\ndoi:10.1016/j.tics.2014.01.005</li>\n<li>Herschbach, Mitchell, 2012, \u201cMirroring Versus Simulation: On\nthe Representational Function of Simulation\u201d, <em>Synthese</em>,\n189(3): 483\u201351. doi:10.1007/s11229-011-9969-6</li>\n<li>Hickok, Gregory, 2009, \u201cEight Problems for the Mirror Neuron\nTheory of Action Understanding in Monkeys and Humans\u201d,\n<em>Journal of Cognitive of Neuroscience</em>, 21(7): 1229\u20131243.\ndoi:10.1162/jocn.2009.21189</li>\n<li>\u2013\u2013\u2013, 2014, <em>The Myth of Mirror Neurons: The\nReal Neuroscience of Communication and Cognition</em>, New York:\nNorton.</li>\n<li>Hume, David, 1739, <em>A Treatise of Human Nature</em>, edited by\nL.A. Selby-Bigge, 2<sup>nd</sup> edition, revised by P.H. Nidditch,\nOxford: Clarendon Press, 1975</li>\n<li>Hurley, Susan, 2005, \u201cThe Shared Circuits Hypothesis: A\nUnified Functional Architecture for Control, Imitation, and\nSimulation\u201d, in <em>Perspectives on Imitation: From Neuroscience\nto Social Science, Volume 1: Mechanisms of Imitation and Imitation in\nAnimals</em>, Susan Hurley &amp; Nick Chater (eds.), Cambridge, MA:\nMIT Press, pp. 177\u2013193.</li>\n<li>\u2013\u2013\u2013, 2008, \u201cUnderstanding\nSimulation\u201d, <em>Philosophy and Phenomenological Research</em>,\n77(3): 755\u2013774. doi:10.1111/j.1933-1592.2008.00220.x</li>\n<li>Jackson, Frank, 1999, \u201cAll That Can Be at Issue in the\nTheory-Theory Simulation Debate\u201d, <em>Philosophical Papers</em>,\n28(2): 77\u201395. doi:10.1080/05568649909506593</li>\n<li>Jacob, Pierre, 2008, \u201cWhat do Mirror Neurons Contribute to\nHuman Social Cognition?\u201d, <em>Mind and Language</em>, 23(2):\n190\u2013223. doi:10.1111/j.1468-0017.2007.00337.x</li>\n<li>\u2013\u2013\u2013, 2012, \u201cSharing and Ascribing\nGoals\u201d, <em>Mind and Language</em>, 27(2): 200\u2013227.\ndoi:10.1111/j.1468-0017.2012.01441.x</li>\n<li>Jeannerod, Marc and Elisabeth Pacherie, 2004, \u201cAgency,\nSimulation and Self-Identification\u201d, <em>Mind and Language</em>\n19(2): 113\u2013146. doi:10.1111/j.1468-0017.2004.00251.x</li>\n<li>Kieran, Matthew and Dominic McIver Lopes (eds.), 2003,\n<em>Imagination, Philosophy, and the Arts</em>, London:\nRoutledge.</li>\n<li>Kosslyn, S.M., A. Pascual-Leone, O. Felician, S. Camposano, J.P.\nKeenan, W.L. Thompson, G. Ganis, K.E. Sukel, and N.M. Alpert, 1999,\n\u201cThe Role of Area 17 in Visual Imagery: Convergent Evidence from\nPET and rTMS\u201d, <em>Science</em>, 284(5411): 167\u2013170.\ndoi:10.1126/science.284.5411.167 </li>\n<li>Leslie, Alan M., 1994, \u201cPretending and Believing: Issues in\nthe Theory of ToMM\u201d, <em>Cognition</em>, 50(1\u20133):\n211\u2013238 . doi:10.1016/0010-0277(94)90029-9</li>\n<li>Lipps, Theodor, 1903, \u201cEinf\u00fchlung, Innere Nachahmung\nund Organempfindung\u201d, <em>Archiv f\u00fcr gesamte\nPsychologie</em>, 1: 465\u2013519. Translated as \u201cEmpathy,\nInner Imitation and Sense-Feelings\u201d, in <em>A Modern Book of\nEsthetics</em>, New York: Holt, Rinehart and Winston, 1979, pp.\n374\u2013382.</li>\n<li>Lurz, Robert W., 2011, <em>Mindreading Animals</em>, Cambridge,\nMA: MIT Press. doi:10.7551/mitpress/9780262016056.001.0001</li>\n<li>Machamer, Peter, Lindley Darden, and Carl F. Craver, 2000,\n\u201cThinking about Mechanisms\u201d, <em>Philosophy of\nscience</em>, 67(1): 1\u201325. doi:10.1086/392759</li>\n<li>Marr, D., 1982. <em>Vision</em>, San Francisco: Freeman\nPress.</li>\n<li>Nichols, Shaun (ed.), 2006a, <em>The Architecture of the\nImagination: New Essays on Pretense, Possibility, and Fiction</em>,\nOxford: Oxford University Press.\ndoi:10.1093/acprof:oso/9780199275731.001.0001</li>\n<li>\u2013\u2013\u2013, 2006b, \u201cJust the Imagination: Why\nImagining Doesn't Behave Like Believing\u201d, <em>Mind &amp;\nLanguage</em>, 21(4): 459\u2013474.\ndoi:10.1111/j.1468-0017.2006.00286.x</li>\n<li>Nichols, Shaun and Stephen P. Stich, 2003, <em>Mindreading: An\nIntegrated Account of Pretence, Self-Awareness, and Understanding of\nOther Minds</em>, Oxford: Oxford University Press.\ndoi:10.1093/0198236107.001.0001</li>\n<li>Onishi, Kristine H. and Ren\u00e9e Baillargeon, 2005, \u201cDo\n15-Month-Old Infants Understand False Beliefs?\u201d\n<em>Science</em>, 308(5719): 255\u2013258.\ndoi:10.1126/science.1107621</li>\n<li>Pacherie, Elisabeth, 2000, \u201cThe Content of\nIntentions\u201d, <em>Mind and Language</em>, 15(4): 400\u2013432.\ndoi:10.1111/1468-0017.00142</li>\n<li>Peackocke, C. 2005, \u201cAnother I: Representing Conscious\nStates, Perception, and Others\u201d, in J. L. Berm\u00fadez (ed.),\n<em>Thought, Reference, and Experience: Themes From the Philosophy of\nGareth Evans</em>, Oxford: Clarendon Press</li>\n<li>Perner, Josef and Deborah Howes, 1992, \u201c\u2018He Thinks he\nKnows\u2019 and more Developmental Evidence Against the Simulation\n(Role-Taking) Theory\u201d, <em>Mind and Language</em>, 7(1\u20132):\n72\u201386; reprinted in Davies and Stone 1995a, pp. 159\u2013173.\ndoi:10.1111/j.1468-0017.1992.tb00197.x</li>\n<li>Perner Josef and Anton K\u00fchberger, 2005, \u201cMental\nSimulation: Royal Road to Other Minds?\u201d, in Bertram F. Malle and\nSara D. Hodges (eds.), <em>Other Minds: How Humans Bridge the Divide\nBetween Self and Others</em>, New York: Guilford Press, pp.\n174\u2013187.</li>\n<li>Perner, Josef and Ted Ruffman, 2005, \u201cInfants\u2019 Insight\nin to the Mind: How Deep?\u201d <em>Science</em>, 308(5719):\n214\u2013216. doi:10.1126/science.1111656 </li>\n<li>Ramsey, William M., 2010, \u201cHow Not to Build a Hybrid:\nSimulation vs. Fact-finding\u201d, <em>Philosophical Psychology</em>,\n23(6): 775\u2013795. doi:10.1080/09515089.2010.529047</li>\n<li>Rizzolatti, Giacomo and Laila Craighero, 2004, \u201cThe\nMirror-Neuron System\u201d, <em>Annual Review of Neuroscience</em>,\n27: 169\u201392. doi:10.1146/annurev.neuro.27.070203.144230 </li>\n<li>Rizzolatti, Giacomo &amp; Corrado Sinigaglia, 2007, \u201cMirror\nneurons and motor intentionality\u201d, <em>Functional\nNeurology</em>, 22(4): 205\u2013210</li>\n<li>\u2013\u2013\u2013, 2010, \u201cThe Functional Role of the\nParieto-Frontal Mirror Circuit: Interpretations and\nMisinterpretations\u201d, <em>Nature Reviews Neuroscience</em> 11:\n264\u2013274. doi:10.1038/nrn2805</li>\n<li>\u2013\u2013\u2013, 2014, \u201cReview: A Curious Book on\nMirror Neurons and Their Myth\u201d, <em>The American Journal of\nPsychology</em>, 128(4): 527\u2013533.\ndoi:10.5406/amerjpsyc.128.4.0527 </li>\n<li>\u2013\u2013\u2013, forthcoming, \u201cThe Mirror Mechanism: a\nBasic Principle of Brain Function\u201d, <em>Nature Reviews\nNeuroscience</em>, 17: 757\u2013765. doi:10.1038/nrn.2016.135</li>\n<li>Rizzolatti, G., R. Camarda, L. Fogassi, M. Gentilucci, G. Luppino,\nand M. Matelli, 1988, \u201cFunctional Organization of Inferior Area\n6 in the Macaque Monkey\u201d, <em>Experimental Brain Research</em>,\n71(1): 491\u2013507. doi:10.1007/BF00248742</li>\n<li>Rizzolatti, Giacomo, Luciano Fadiga, Vittorio Gallese, and\nLeonardo Fogassi, 1996, \u201cPremotor Cortex and the Recognition of\nMotor Actions\u201d, <em>Cognitive Brain Research</em>, 3(2):\n131\u2013141. doi:10.1016/0926-6410(95)00038-0</li>\n<li>Rozin, Paul, Jonathan Haidt, and Clark R. McCauley, 2008,\n\u201cDisgust\u201d, in Michael Lewis, Jeannette M.\nHaviland\u2013Jones &amp; Lisa Feldman Barrett (eds.), <em>Handbook\nof Emotions</em> (3rd edition), New York: Guilford Press, pp.\n757\u2013776.</li>\n<li>Saxe, Rebbecca, 2005, \u201cAgainst Simulation: The Argument from\nError\u201d, <em>Trends in Cognitive Sciences</em>, 9(4):\n174\u2013179. doi:10.1016/j.tics.2005.01.012</li>\n<li>Scholl, Brian J. and Alan M. Leslie, 1999, \u201cModularity,\nDevelopment and Theory of Mind\u201d, <em>Mind and Language</em>,\n14(1): 131\u2013153. doi:10.1111/1468-0017.00106</li>\n<li>Singer, Tania, Ben Seymour, John O\u2019Doherty, Holger Kaube,\nRaymond J. Dolan, and Chris D. Frith, 2004, \u201cEmpathy for Pain\nInvolves the Affective but not Sensory Components of Pain\u201d,\n<em>Science</em>, 303(5661): 1157\u2013 1162.\ndoi:10.1126/science.1093535</li>\n<li>Smith, Adam, 1759, <em>The Theory of Moral Sentiments</em>, D.D.\nRaphael and A.L. Macfie (eds.), Oxford: Oxford University Press,\n1976.</li>\n<li>Spaulding, Shannon, 2012, \u201cMirror Neurons are not Evidence\nfor the Simulation Theory\u201d, <em>Synthese</em>, 189(3):\n515\u2013534. doi:10.1007/s11229-012-0086-y</li>\n<li>Spivey, Michael J., Daniel C. Richardson, Melinda J. Tyler, and\nEzekiel E. Young, 2000, \u201cEye movements During Comprehension of\nSpoken Scene Descriptions\u201d, in <em>Proceedings of the\n22<sup>nd</sup> Annual Conference of the Cognitive Science\nSociety</em>, Mahwah, NJ: Erlbaum, pp. 487\u2013492.</li>\n<li>Stich, Stephen and Shaun Nichols, 1992, \u201cFolk Psychology:\nSimulation or Tacit Theory?\u201d, <em>Mind and Language</em>,\n7(1\u20132): 35\u201371; reprinted in Davies and Stone 1995a, pp.\n123\u2013158. doi:10.1111/j.1468-0017.1992.tb00196.x</li>\n<li>\u2013\u2013\u2013, 1997, \u201cCognitive Penetrability,\nRationality, and Restricted Simulation\u201d, <em>Mind and\nLanguage</em>, 12(3\u20134): 297\u2013326.\ndoi:10.1111/j.1468-0017.1997.tb00076.x</li>\n<li>Stich, Stephen and Ian Ravenscroft, 1992, \u201cWhat <em>is</em>\nFolk Psychology?\u201d <em>Cognition</em>, 50(1\u20133):\n447\u201368. doi:10.1016/0010-0277(94)90040-X</li>\n<li>Velleman, J. David, 2000, \u201cThe Aim of Belief\u201d, in\n<em>The Possibility of Practical Reason</em>, Oxford: Oxford\nUniversity Press, pp. 244\u2013282</li>\n<li>Vannuscorps, Gilles and Alfonso Caramazza, 2015, \u201cTypical\nAction Perception and Interpretation without Motor Simulation\u201d,\n<em>Proceedings of the National Academy of Sciences</em>, 113(1):\n1\u20136. doi:10.1073/pnas.1516978112</li>\n<li>Wellman, Henry M., David Cross, and Julanne Watson, 2001,\n\u201cMeta-Analysis of Theory-of-Mind Development: The Truth about\nFalse Belief\u201d, <em>Child Development</em>, 72(3): 655\u2013684.\ndoi:10.1111/1467-8624.00304</li>\n<li>Wicker, Bruno, Christian Keysers, Jane Plailly, Jean-Pierre Royet,\nVittorio Gallese, and Giacomo Rizzolatti, 2003, \u201cBoth of us\nDisgusted in <em>My</em> Insula: The Common Neural Basis of Seeing and\nFeeling Disgust\u201d, <em>Neuron</em>, 40(3): 655\u2013664.\ndoi:10.1016/S0896-6273(03)00679-2</li>\n<li>Wimmer, Heinz and Josef Perner, 1983, \u201cBeliefs About\nBeliefs: Representation and Constraint Function of Wrong Beliefs in\nYoung Children\u2019s Understanding of Deception\u201d,\n<em>Cognition</em>, 13(1): 103\u2013128.\ndoi:10.1016/0010-0277(83)90004-5</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "folk psychology: as a theory",
            "imagination",
            "introspection",
            "materialism: eliminative",
            "mind: computational theory of",
            "self-knowledge"
        ],
        "entry_link": [
            {
                "../folkpsych-theory/": "folk psychology: as a theory"
            },
            {
                "../imagination/": "imagination"
            },
            {
                "../introspection/": "introspection"
            },
            {
                "../materialism-eliminative/": "materialism: eliminative"
            },
            {
                "../computational-mind/": "mind: computational theory of"
            },
            {
                "../self-knowledge/": "self-knowledge"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "\n<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>\n",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=folkpsych-simulation\" target=\"other\">How to cite this entry</a>.",
            "\n<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>\n",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/folkpsych-simulation/\" target=\"other\">Preview the PDF version of this entry</a>\n at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "\n<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>\n",
            "<a href=\"https://www.inphoproject.org/entity?sep=folkpsych-simulation&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "\n<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>\n",
            "<a href=\"http://philpapers.org/sep/folkpsych-simulation/\" target=\"other\">Enhanced bibliography for this entry</a>\n at\n <a href=\"http://philpapers.org/\" target=\"other\">PhilPapers</a>,\n with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=folkpsych-simulation": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/folkpsych-simulation/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=folkpsych-simulation&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "http://philpapers.org/sep/folkpsych-simulation/": "Enhanced bibliography for this entry"
            },
            {
                "http://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [],
        "listed_links": []
    }
}