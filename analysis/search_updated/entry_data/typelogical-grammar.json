{
    "url": "typelogical-grammar",
    "title": "Typelogical Grammar",
    "authorship": {
        "year": "Copyright \u00a9 2010",
        "author_text": "Michael Moortgat\n<Michael.Moortgat@phil.uu.nl>",
        "author_links": [
            {
                "mailto:Michael%2eMoortgat%40phil%2euu%2enl": "Michael.Moortgat@phil.uu.nl"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2010</a> by\n\n<br/>\nMichael Moortgat\n&lt;<a href=\"mailto:Michael%2eMoortgat%40phil%2euu%2enl\"><em>Michael<abbr title=\" dot \">.</abbr>Moortgat<abbr title=\" at \">@</abbr>phil<abbr title=\" dot \">.</abbr>uu<abbr title=\" dot \">.</abbr>nl</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Tue Sep 7, 2010"
    ],
    "preamble": "\n\n\nTypelogical grammars are substructural logics, designed for reasoning\nabout the composition of form and meaning in natural language. At\nthe core of these grammars are residuated families of type-forming\noperations; a hierarchy of typelogical grammars results from the\nchoices one makes with respect to the structural properties of the\ntype-forming operations, and the means one introduces to control the\ngrammatical resource management.  Computational semantics is obtained\nfrom the Curry-Howard interpretation of categorial derivations.\nParsing and natural language processing is modeled in terms of\nsuitably refined versions of the proof nets of linear logic.\n",
    "toc": [
        {
            "#BitHis": "1. A bit of history"
        },
        {
            "#LamSys": "2.   The Lambek systems"
        },
        {
            "#ModGraCom": "2.1   Modelling grammatical composition"
        },
        {
            "#SynSemInt": "2.2 The syntax-semantics interface"
        },
        {
            "#ExtTypGra": "3.   Extended typelogical grammars"
        },
        {
            "#MulSysStrCon": "3.1   Multimodal systems, structural control"
        },
        {
            "#LogDis": "3.2   The logic of discontinuity"
        },
        {
            "#SymCatGra": "3.3   Symmetric categorial grammar"
        },
        {
            "#FleIntConSem": "3.4   Flexible interpretation, continuation semantics"
        },
        {
            "#ProNetPro": "4.  Proof nets and processing"
        },
        {
            "#RecCapCom": "5.   Recognizing capacity, complexity"
        },
        {
            "#RelApp": "6.   Related approaches"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. A bit of history\nTypelogical grammar has its roots in two seminal papers written by\nJim Lambek half a century ago (Lambek 1958, 1961). In these papers,\nthe author set himself the aim \u201cto obtain an effective rule (or\nalgorithm) for distinguishing sentences from non-sentences, which\nworks not only for the formal languages of interest to the\nmathematical logician, but also for natural languages\n[\u2026]\u201d. To realize this goal, the familiar parts of speech\n(nouns, verbs, \u2026) are turned into formulas of a logic \u2014 a\nlogic designed to reason about grammatical composition.  The judgement\nwhether a phrase is wellformed, under this view, is the outcome of a\nprocess of deduction.  A decision procedure for such judgements is\nobtained by casting the grammar logic in the format of a Gentzen-style\nsequent calculus.  The sequent presentation is extremely simple: the\nlogic of grammar is a logic without structural rules.  Contraction and\nWeakening are dropped; their presence would entail that wellformedness\nis unaffected by arbitrary copying or deletion of grammatical\nmaterial.  To take into account also word order and phrase structure\ninformation, Lambek further removes the structural rules of Exchange\nand (in the 1961 paper) Associativity.\nAt the time of their publication, these ideas did not resonate;\ntheir impact on the field of computational linguistics dates from\nthe 1980s. Two factors have played an important role in this belated\nrecognition.  The first was the addition of a computational semantics\nfor categorial derivations along the lines of the Curry-Howard\nproofs-as-programs interpretation in van Benthem 1983, reprinted in\nBuszkowski et al. 1988. Lambek's typelogical grammars, so\nviewed, could be seen to realize Montague\u2019s compositionality\nprogram in an uncompromising way, with the lambda calculus and type\ntheory providing powerful tools to study derivational and lexical\nsemantics. The second factor was the introduction of linear logic\n(Girard 1987), and with it, the surge of interest in substructural\nlogics. A key insight from linear logic injected into typelogical\ngrammar is the idea that structural rules can be reintroduced in a\ncontrolled form by means of so-called modalities: in moving to more\ndiscriminating type logics, no expressivity is lost. From a\ncomputational point of view, variants of the proof nets of linear\nlogic have provided the basis for typelogical natural language\nprocessing.\nTypelogical grammar, in its current incarnations, keeps the general\narchitecture of Lambek's original calculi, but extends this to a more\narticulate vocabulary of type-forming operations.  Of central\nimportance are the multiplicative operations, used to model\ngrammatical composition; these form the focus of this article. Next to\nthe multiplicatives one can consider additive or Boolean operations\nand first or second order quantification to handle phenomena of\nlexical ambiguity, type polymorphism and the management of feature\ninformation. Morrill 1994 is a good source of examples for such\nextensions.\nOutline of this article.  We start with the standard\nLambek systems. We study their model-theoretic and proof-theoretic\naspects (frame semantics, sequent calculus), and the relation between\nthe two (soundness, completeness). We characterize compositional\ninterpretation as a homomorphism relating a syntactic source calculus\nand a target calculus for meaning assembly. The mapping associates\nsyntactic derivations with semantic readings, expressed as terms of\nthe simply typed linear lambda calculus.  In \u00a73 we turn to the\nexpressive limitations of the standard Lambek systems, in syntax and\nsemantics, and study how they can be addressed by systematically\nextending the categorial architecture in a modular way.\nGeneralizations concern the arity of the type-forming operations\n(binary composition operations versus unary control operators);\nmultimodal extensions where multiple families of type-forming\noperations co-exist and communicate via structural interaction\nprinciples; one-sorted vs multi-sorted logics (discontinuous calculi);\nsingle-conclusion vs multiple-conclusion systems (symmetric calculi);\nand more structured views of the syntax- semantics interface\n(continuation semantics). To close the panoramic tour, we present\nproof nets for the various typelogical systems studied in \u00a73, and\nwe compare these systems with respect to expressivity and\ncomputational tractability.\n2.   The Lambek systems\n2.1   Modelling grammatical composition\nThe type language to be considered in this section consists of a\nsmall set of atomic types, and is closed under the binary operations\nproduct, left and right division. Some notational conventions: in the\nspecification below, lower case p ranges over atomic types,\nupper case A, B over arbitrary types. We pronounce\nA\\B as \u2018A under B\u2019\nand B/A as \u2018B over A\u2019\nthus to make clear which part of the \u2018fraction\u2019 is the\ndenominator (A), and which is the numerator\n(B).  \n\nTypes: A,B ::= p | A \u2297 B\n| A\\B | B/A\n\nIn categorizing linguistic expressions, atomic types stand for\nphrases that one can think of as grammatically \u2018complete\u2019.\nExamples, for English, could be s for declarative sentences\n(\u2018Mary dreams\u2019,\u2026), np for noun phrases\n(\u2018Mary\u2019, \u2018the girl\u2019,\u2026), n for\ncommon nouns (\u2018girl\u2019, \u2018smart girl\u2019,\u2026).\nDivision expresses incompleteness: an expression with\ntype A\\B (B/A) will produce a\nphrase of type B when it is put together with a phrase of\ntype A to its left (right).  Product types A\n\u2297 B explicitly express the formation of a complex\nphrase out of constituent parts of type A and B in\nthat order.  So if \u2018Mary\u2019 is typed as np and the\nverb \u2018dreams\u2019 as np\\s, we\nobtain s for the combination \u2018Mary dreams\u2019 by\nmultiplying out these types: np \u2297\n(np\\s). Similarly for the combination \u2018the\ngirl dreams\u2019, where one would start from a\ntype np/n for the determiner and n for\n\u2018girl\u2019: ((np/n) \u2297 n)\n\u2297 (np\\s).\nTo make this informal description of the interpretation of the type\nlanguage precise, we turn to modal logic. Frames F =\n(W,R), in the categorial setting, consist of a\nset W of linguistic resources (expressions,\n\u2018signs\u2019), structured in terms of a ternary relation\nR. This ternary relation stands for grammatical composition, or\n\u2018Merge\u2019 as it is known in the generative tradition: read\nRxyz as \u201cthe expression x is obtained by\nputting together the subexpressions y\nand z\u201d. For comparison: in the Routley-Meyer semantics\nfor relevance logic, R would be the accessibility relation\ninterpreting the fusion operation.\nA model M is a pair (F,V)\nwhere V is an interpretation (valuation) sending atomic types\nto subsets of W.  For complex types, the valuation respects\nthe clauses below.  We write x \u2208 V(A)\nas M,x \u22a9 A or, if no confusion will\narise, x \u22a9 A.\n\nx \u22a9 A \u2297 B iff\n\u2203yz such that Rxyz and y\n\u22a9 A and z \u22a9 B\ny \u22a9 C/B iff \u2200xz,\nif Rxyz and z \u22a9 B, then x\n\u22a9 C\nz \u22a9 A\\C iff \u2200xy,\nif Rxyz and y \u22a9 A, then x\n\u22a9 C\n\nA syntactic calculus for a categorial type language is a deductive\nsystem producing statements of the form A \u22a2 B\n(\u2018B is derivable from A\u2019).  A\nstatement A \u22a2 B holds in a model\n(\u2018M \u22a8 A \u22a2 B\u2019)\nif V(A) \u2286 V(B); it is valid\n(\u2018\u22a8 A \u22a2\nB\u2019) if it holds in all models. For the minimal grammar\nlogic, the set of derivations in the syntactic calculus is freely\ngenerated from the axiom and rules of inference below. This minimal\nsystem, for historical reasons, is known as NL (for\n\u2018Non-associative Lambek calculus\u2019).  The\nfirst line states that derivability is a reflexive, transitive\nrelation, i.e., a preorder.  The bidirectional (\u2018if and only\nif\u2019) inference rules of the second line characterize the product\nand division operations as a residuated triple as it is known in\nresiduation theory. (Galatos et al. 2007 provides good\nbackground reading.) The syntactic calculus, so defined, precisely\nfits the intended interpretation of the type language, in the sense of\nthe soundness and completeness result below.\n\npreorder laws:\n  \nA \u22a2 A (reflexivity)\nfrom A \u22a2 B and B\n\u22a2 C infer A \u22a2 C (transitivity)\n\n\nresiduation laws: A \u22a2\nC/B iff A \u2297 B\n\u22a2 C iff B \u22a2 A\\C\nsoundness and completeness: A \u22a2 B is\nprovable in the grammatical base logic NL iff\n\u22a8 A \u22a2 B, i.e., iff V(A)\n\u2286 V(B) for every valuation V on every\nframe F (Do\u0161en 1992).\n\nThe completeness result for NL does not impose any restrictions on\nthe interpretation of the Merge\nrelation R. This means that the theorems\nand inference rules of the minimal grammar logic have the status of\ngrammatical invariants: properties of type combination that hold no\nmatter what the structural particularities of individual languages may\nbe.  Here are some examples of such universally valid principles. They\ncome in pairs, because of the left-right symmetry relating slash and\nbackslash.\n\napplication:\n \n(A/B) \u2297 B \u22a2 A\nB \u2297 (B\\A) \u22a2 A\n\n\nco-application: \n \nA \u22a2 (A \u2297 B)/B\nA \u22a2 B\\(B \u2297 A)\n\n\nlifting: \n \nA \u22a2 B/(A\\B)\nA \u22a2 (B/A)\\B\n\n\nmonotonicity: from A \u22a2 B and C\n\u22a2 D infer any of the following:\n \nA \u2297 C \u22a2 B \u2297 D\nA/D \u22a2 B/C\nD\\A \u22a2 C\\B\n\n\n\nGiven the universal freely generated syntactic calculus discussed\nabove, the task of providing a categorial grammar for\na particular language is reduced to specifying its lexicon:\nthe typelogical framework, in this sense, represents the culminating\npoint of \u2018lexicalizing\u2019 grammar formalisms.  A categorial\nlexicon is a relation associating each word with a finite number of\ntypes.  Given a lexicon Lex, a categorial grammar assigns\ntype B to a string of words w1 \u00b7\u00b7\u00b7 \nwn iff for 1 \u2264 i \u2264 n,\n(wi,Ai) \u2208 Lex,\nand X \u22a2 B is provable in the syntactic\ncalculus where X is a product formula with\nyield A1\n\u00b7\u00b7\u00b7 An. The grammar can be\nconsidered adequate if the strings w1\n\u00b7\u00b7\u00b7 wn are indeed judged to be the wellformed\nphrases of type B.\nLexical type assignments don't have to be handcrafted: Buszkowski\nand Penn (1990) model the acquisition of the lexicon as a\nprocess of solving type equations. Their unification-based algorithms\ntake function-argument structures as input (binary trees with a\ndistinguised head daughter); one obtains variations depending on\nwhether the solution should assign a unique type to every vocabulary\nitem (so-called rigid grammars), or whether one accepts multiple\nassignments (k-valued grammars, with k as the\nmaximal lexical ambiguity factor). Kanazawa (1998) studies learnable\nclasses of grammars from this perspective, in the sense of\nGold\u2019s notion of identifiability \u2018in the limit\u2019.\nThis line of research is by now well established, for typelogical\ngrammars proper, and for the related pregroup formalism discussed\nunder \u00a76.\nThe radical lexicalism of typelogical grammar means there is no\nroom for construction specific rule stipulations: central grammatical\nnotions, rather than being postulated, must emerge from the type\nstructure. Here are some examples.\n\nValency. Intransitive verbs (\u2018dreams\u2019,\n\u2018sleeps\u2019) form a complete sentence with just a subject\nnoun phrase to their left; transitive verbs (\u2018sees\u2019,\n\u2018admires\u2019) require both a subject to their left and a\ndirect object to their right. Such selectional requirements are\nexpressed in terms of the directional\nimplications: np\\s for intransitive,\n(np\\s)/np for transitive verbs.  In a\ncontext-free grammar, these distinctions require the postulation of\nnew non-terminals.\nCase. The distinction between phrases that can fulfill\nany noun phrase selectional requirement (say, proper names) versus\ncase-marked pronouns insisting on playing the subject or direct object\nrole is expressed through higher-order type assignment: proper names\ncan be typed simply as np, subject pronouns\n(\u2018he\u2019, \u2018she\u2019)\nas s/(np\\s), direct object pronouns (and\nreflexives) as\n((np\\s)/np)\\(np\\s).\nUnder such typing, one correctly distinguishes between the grammatical\n\u2018he sees her\u2019 versus the ill-formed \u2018him likes\nshe\u2019.\nComplements vs modifiers.  Compare exocentric types\n(A/B or B\\A with A\n\u2260 B) versus endocentric\ntypes A/A, A\\A. The latter express\nmodification; optionality of modifier phrases follows. Compare\n\u2018the girl\u2019, \u2018the smart girl\u2019, \u2018the girl\n(who teases Bill)\u2019, with \u2018girl\u2019 typed as n,\n\u2018smart\u2019 as n/n and the relative clause\n\u2018who teases Bill\u2019 as n\\n.\nFiller-gap dependencies.  Types with nested implications\nA/(C/B), A/(B\\C),\netc., signal the withdrawal of a gap hypothesis of type B in\na domain of type C. The relative pronoun \u2018who\u2019 in\n\u2018the girl who teases Bill\u2019 is typed as\n(n\\n)/(np\\s): it combines with a\nsentence of which the subject must remain unexpressed, as one sees\nfrom the ill-formed \u2018the girl who Mary teases Bill\u2019.\n\nSequent calculus, decidability. How can we decide whether a\nstatement A \u22a2 B is indeed a theorem of the\nsyntactic calculus?  In the presence of expanding rules, such as\nLifting, this is not immediately obvious: the transitivity inference\nfrom A \u22a2 B and B \u22a2 C\nto A \u22a2 C involves a \u2018lemma\u2019\nformula B which disappears from the conclusion, and there is\nan infinite number of candidate lemma formulas to consider.  A key\npoint of Lambek's original papers consists in the reformulation of the\nsyntactic calculus in an equivalent Gentzen-style sequent format,\nwhich enjoys cut-elimination.\nSequents for the grammatical base logic NL are\nstatements X \u21d2 A, where X (the\nantecedent) is a structure, and A (the succedent) a type\nformula. The antecedent structure is required to be non-empty. A\nstructure is either a single formula, or a binary branching tree with\nformulas at the leaves.  In the sequent rules below, the tree\nstructure of the antecedent is indicated by bracketing\n(\u2013,\u2013).  The notation X[Y] refers to a\nstructure X containing a distinguished\nsubstructure Y.  For every connective (type-forming\noperation), there are two inference rules, introducing the connective\nto the left or to the right of the derivability arrow.  In this\nsequent presentation, as in Gentzen's propositional logics, Cut\nis an admissible rule: every proof of a theorem that makes use of Cut\ninferences can be transformed into an equivalent cut-free derivation.\nBackward-chaining proof search in the cut-free system respects the\nsubformula property and immediately yields a decision procedure.\n\n\n\n\n\n\n\n\n\n\n\u00a0\n\n\nA\u21d2A\n\n\n\nAx\n\n\n\n\n\n\nY\u21d2A\u00a0\u00a0X[A]\u21d2B\n\n\nX[Y]\u21d2B\n\n\n\nCut\n\n\n\n\n\n\n\n\nX\u21d2A\u00a0\u00a0Y\u21d2B\n\n\n(X,Y)\u21d2A\u2297B\n\n\n\n(\u2297R)\n\n\n\n\n\n\nX[(A,B)]\u21d2C\n\n\nX[A\u2297B]\u21d2C\n\n\n\n(\u2297L)\n\n\n\n\n\n\n\n\nY\u21d2B\u00a0\u00a0X[A]\u21d2C\n\n\nX[(Y,B\\A)]\u21d2C\n\n\n\n(\\L)\n\n\n\n\n\n\n(B,X)\u21d2A\n\n\nX\u21d2B\\A\n\n\n\n(\\R)\n\n\n\n\n\n\n\n\nY\u21d2B\u00a0\u00a0X[A]\u21d2C\n\n\nX[(A/B,Y)]\u21d2C\n\n\n\n(/L)\n\n\n\n\n\n\n(X,B)\u21d2A\n\n\nX\u21d2A/B\n\n\n\n(/R)\n\n\n\n\nNL: Sequent Calculus \n\nA landscape of calculi. From the pure residuation logic, one obtains\na hierarchy of calculi by attributing associativity and/or\ncommutativity properties to the composition operation \u2297. These\ncalculi reflect different views on how the grammatical material is\nstructured.  The table below summarizes the options. \n\n\n\nlogic\nstructure\nassociative\ncommutative\n\n\nNL\ntree\n\u2013\n\u2013\n\n\nL\nstring\n\u2713\n\u2013\n\n\nNLP\nmobile\n\u2013\n\u2713\n\n\nLP (=MILL)\nmultiset\n\u2713\n\u2713\n\n\n\n\nFor reasons of historical precedence, the system of Lambek 1958, with\nan associative composition operation, is referred to as L; the\npure residuation logic NL, i.e., the non-associative version\nof L, was introduced later in Lambek 1961.  Addition of\ncommutativity turns L and NL into LP\nand NLP, respectively. LP, Lambek calculus with\nPermutation, was introduced in van Benthem 1983; in retrospect, this\nthe implication/fusion fragment of Multiplicative Intuitionistic\nLinear Logic (MILL). The commutative variant of NL has been\nstudied by Kandulski; it has not found significant linguistic\napplications. For the four systems in the hierarchy, one writes\n(N)L(P)* for the (non-conservative) extension\nwhich allows empty antecedents.\n\nIn the presentation of the syntactic calculus, the structural options\ntake the form of non-logical axioms (postulates), which one\nadds to the residuation laws.  In the sequent presentation, one has\ncorresponding structural rules.  The sequent calculus\nfor L(P) also allows for a sugared presentation where\nthe antecedent is treated as a list or a multiset of formulas; the\ninference steps for the structural rules can then be left implicit.\nWith respect to the frame semantics, each of the structural options\nintroduces a constraint on the interpretation of the Merge relation\nR\u2297.  Completeness for the calculi with structural options is\nthen with respect to all frames respecting the relevant constraints\n(Do\u0161en 1992). The associative calculus L in fact allows\nmore specific models where we read Rxyz as x\n= y \u00b7 z, with \u00b7 a\nbinary concatenation operation.  Pentus (1995) presents a\nquite intricate proof that L is indeed complete with respect to\nsuch free semigroup models (or language models, as they are also\ncalled).\n\nstructural postulates: \n  \nA \u2297 B \u22a2 B\n  \u2297 A (commutativity)\nA \u2297 (B \u2297 C) \u2261\n  (A \u2297 B) \u2297 C (associativity)\n\n\ncorresponding structural rules for the sequent presentation:\n\n  \n\n\n\n\n\n\nW[(Y,X)]\u21d2C\n\n\nW[(X,Y)]\u21d2C\n\n\n\n(comm.)\n\n\n\n\n\n\nW[((X,Y),Z)]\u21d2C\n\n\nW[(X,(Y,Z))]\u21d2C\n\n\n\n(assoc.)\n\n\n\n\n\n\nframe constraint for commutativity:\n\u2200xyz(Rxyz implies Rxzy)\nframe constraint for associativity (rebracketing to the left):\n\u2200xyzrs(Rrxs and Rsyz imply\n\u2203t(Rrtz and Rtxy)); similarly for the\nother direction\n\nA characteristic property of LP is the collapse of the\ndistinction between left and right division: A\\B\nand B/A become interderivable.  From\na syntactic point of view, the global availability of\nassociativity and/or commutativity in LP would entail that\narbitrary changes in constituent structure and/or word order cannot\naffect the well-formedness of an expression \u2014 a position that\nfew linguists will subscribe to.  Whether global associativity as we\nfind it in L is a viable option for syntax is open to dispute. Lambek\npoints to cases of overgeneration resulting from free rebracketing in\nhis 1961 paper, but later reverts to the associative view. In the\nfollowing section, we will see that LP is perfectly legitimate\nas a calculus of meaning composition. In \u00a73, we discuss\ncontrolled forms of structural reasoning, anchored in lexical\ntype assignment, as an alternative to the problematic all-or-nothing\noptions.\n2.2 The syntax-semantics interface\nIn order to give equal weight to syntactic and semantic\nconsiderations, we can set up a categorial grammar as a pair of\ncalculi linked by a compositional interpretation: a\nsyntactic source calculus, a semantic target\ncalculus, and a homomorphism mapping types and derivations of the\nsource to the corresponding types and derivations of the target. In\nthis section, we work out this architecture for the standard Lambek\ncalculi. In the following section, we will see how the extended\ncategorial type logics reflect different views on the division of\nlabour between syntax and semantics, and hence on the amount of work\nthat has to be done to achieve a compositional mapping between the\ntwo.\n\n\n\n(N)L{n,np,s}/,\\\n(\u00b7)\u2032\nLP{e,t}\u2192\n\n\nSyntax\nhomomorphism\nSemantics\n\n\n\nThe semantic study of categorial deduction started with van Benthem\n1983.  In line with the Curry-Howard \u2018formulas-as-types,\nproofs-as-programs\u2019 method, derivations in the various\ncategorial calculi are associated with terms of suitable fragments of\nthe lambda calculus. For the sake of simplicity, we restrict attention\nto the implicational vocabulary: the directional slashes for\n(N)L, and the non-directional implication\nof LP.\n\nLet us start with the Curry-Howard correspondence for LP. The\nchoice of LP as the calculus of natural language semantics captures\nthe fact that meaning composition is a resource-sensitive process: in\ninterpreting a derivation, no material can be copied or thrown away.\nLet us refer to the terms of the simply typed linear lambda calculus\nas \u039b(Lin).  In the absence of Contraction and Weakening, this\nis the smallest set such that, given a denumerably infinite set of\nvariables Var,\n\nx \u2208 \u039b(Lin) if x \u2208 Var;\n\u03bbx.M \u2208 \u039b(Lin) if x\n\u2208 Var, M \u2208 \u039b(Lin), and there is exactly one\nfree variable occurrence of x in M;\n(M N) \u2208 \u039b(Lin) if M \u2208\n\u039b(Lin), N \u2208 \u039b(Lin), and the sets of free variables\nof M and N are disjoint.\n\nFrom \u039b(Lin), one obtains \u039b(LP), the terms in\nCurry-Howard correspondence with LP derivations, by adding one\nextra restriction, reflecting the requirement that sequent antecedents\nmust be non-empty: every subterm contains at least one free variable.\nThe derivations of LP are now read as judgements of a type\ninference system for \u039b(LP).  Derivations are given in\nthe natural deduction style, with elimination and introduction rules\nfor the linear implication \u2192. Judgements then are sequents of the\nform \u0393 \u22a2 M : B.  \u0393 is a non-empty\nmultiset of typing declarations x1\n: A1, \u2026,\nxn : An;\nthe Ai and B are linear implicative\ntypes, and M is a \u039b(LP) term of type B\nbuilt out of the xi of\ntype Ai. Axiom sequents are of the\nform x : A \u22a2 x : A. Elimination\nand Introduction rules for the linear implication are given below. In\nthe Introduction rule, x \u2209 dom(\u0393); in the\nElimination rule dom(\u0393) \u2229 dom(\u0394) = \u2205.\n\n\n\n\n\n\n\n\u0393,x : A \u22a2 M : B\n\n\n\u0393 \u22a2\n\u03bbx.M : A \u2192 B\n\n\n\n\u2192I\n\n\n\n\n\n\n\u0393 \u22a2 M : A \u2192 B\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u0394 \u22a2 N : A\n\n\n\u0393,\u0394 \u22a2\n(M N) : B\n\n\n\n\u2192E\n\n\n\n\n\nThe syntactic calculi (N)L, similarly, are in\nCurry-Howard correspondence with directional linear lambda\nterms (Wansing 1992). There is no standard notation. In the\ndirectional typing rules below, we use \u03bbr\nvs \u03bbl for the image of the slash and\nbackslash Introduction rules; in the case of the Elimination rules, we\nhave right and left function application, with the triangle pointing\nto the function. The antecedent is now a (bracketed) string of typing\ndeclarations xi : Ai.\n\n\n\n\n\n\n\n(\u0393,x : A) \u22a2 M : B\n\n\n\u0393 \u22a2 \u03bbrx.M : B/A\n\n\n\nI/\n\n\n\n\n\n\n(x :\nA,\u0393) \u22a2 M : B\n\n\n\u0393 \u22a2 \u03bblx.M : A\\B\n\n\n\nI\\\n\n\n\n\n\n\n\n\n\u0393\n\u22a2 M : B/A\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u0394 \u22a2 N : A\n\n\n(\u0393,\u0394) \u22a2 (M \u22b2 N) : B\n\n\n\nE/\n\n\n\n\n\n\n\u0393 \u22a2 N : A\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u0394 \u22a2 M : A\\B\n\n\n(\u0393,\u0394) \u22a2 (N \u22b3 M) : B\n\n\n\nE\\\n\n\n\n\n\nThe source and target calculi each have their own set of basic\ntypes, motivated by syntactic and semantic considerations\nrespectively.  At the syntactic end, one could discriminate between\nsentences s, noun phrases np, common\nnouns n, for example.  At the semantic end, for a simple\nextensional interpretation, one could introduce two basic types, e and\nt. Set-theoretic interpretation for the semantic types is\nthen given in terms of a non-empty set of\nindividuals/entities E and the truth values {0,1}.\nDenotation domains Dom(A) for semantic types A are\nset up such that Dom(e) = E, Dom(t) = {0,1}\nand Dom(A\\B) = Dom(B/A) is the set\nof functions from Dom(A) to Dom(B).\n\nConsider next the homomorphic mapping from the syntactic source\ncalculus to the semantic target calculus. The mapping is specified at\nthe level of types and at the level of proofs (terms). Setting up the\nmapping at the level of atomic types as below, sentences denote truth\nvalues; (proper) noun phrases individuals; common nouns functions from\nindividuals to truth values. For complex syntactic types, the\ninterpretation function sends the two directional implications to the\nlinear implication of the target calculus. At the level of proofs\n(terms), likewise, the directional constructs of the syntactic source\ncalculus are identified in the interpretation. (We use a primed\nversion for the target variable corresponding to a source variable, as\na reminder of the fact that the type of these expressions is\ndifferent.)\n\ntypes: (np)\u2032 = e, (s)\u2032\n= t, (n)\u2032 = e \u2192 t,\n(A\\B)\u2032 = (B/A)\u2032 =\nA\u2032 \u2192 B\u2032\nterms: (x)\u2032 = x\u2032,\n(\u03bbrx.M)\u2032 =\n(\u03bblx.M)\u2032 =\n\u03bbx\u2032.(M)\u2032, (N\n\u22b3 M)\u2032 = (M \u22b2 N)\u2032 =\n((M)\u2032 (N)\u2032)\n\n\nIn the previous sections, we have seen that the theorems of NL,\nL and LP form a proper inclusion hierarchy.  The\nsemantic counterpart is that in moving to more discriminating\nsyntactic calculi, more and more LP terms are lost in\ntranslation: desirable recipes for meaning assembly are often\nunobtainable as the image of (N)L proofs.  For the three\ncalculi, the table below gives a characteristic type transition.  The\nsecond row has the directional proof terms associated with the\n(N)L type transitions; the third row gives the\ncorresponding LP term, obtained via the translation\nhomomorphism, in the case of (N)L, or directly for\nthe LP case.\n\n\n\n\n\nNL:  argument lowering\nL: composition\nLP:  argument raising\n\n\n(B/(A\\B))\\C \u22a2 A\\C\nA\\B \u22a2 (A\\C)/(B\\C)\nA \u2192 (B \u2192 C) \u22a2 \n((A\u2009\u2192\u2009C)\u2009\u2192\u2009C)\u2009\u2192\u2009(B\u2009\u2192\u2009C)\n\n\nz \u22a2 \u03bblx.((\u03bbry.(x \u22b3 y)) \u22b3 z)\ny \u22a2 \u03bbrz\u03bblx.((x \u22b3 y) \u22b3 z)\n\n\n\nz\u2032 \u22a2 \u03bbx\u2032.(z\u2032 \u03bby\u2032.(y\u2032 x\u2032))\ny\u2032 \u22a2 \u03bbz\u2032\u03bbx\u2032.(z\u2032 (y\u2032 x\u2032))\nx \u22a2 \u03bbw\u03bbz.(w \u03bby.((x y) z))\n\n\nArgument lowering is valid in NL, hence also in\nL, LP. Function composition depends on associativity; it\nis invalid in NL, valid in L(P). Function\ncomposition has been used to build up partial semantic\nrepresentations, running in parallel with the incremental\n(left-to-right) processing of a string. Argument raising, finally, is\nvalid only in LP, i.e., this form of meaning assembly cannot be\nobtained as the image of a derivation in any of the syntactic calculi\n(N)L. But, as we will see below, this transition plays\nan important role in the analysis of natural language scope\nambiguities.\nDerivational versus lexical semantics.  The constraints\nimposed by resource-sensitivity put severe limitations on the\nexpressivity of the derivational semantics. To some extent, these can\nbe overcome at the level of lexical semantics. The\nCurry-Howard term associated with a derivation, seen as a program for\nmeaning assembly, abstracts from the contribution of particular\nlexical items.  The semantic specification for a lexical item of\ntype A takes the form of a lambda term of the corresponding\nsemantic type A\u2032, but this lambda term is no longer\nrequired to be linear.  Below some examples of non-linear lexical\nmeaning recipes.  The specification for the reflexive pronoun\n\u2018himself\u2019 is a pure combinator (a closed term): it\nidentifies the first and second argument of a binary relation.  The\nterms for the relative pronoun \u2018that\u2019 or for the\ndeterminers \u2018a, some\u2019 have an abstraction that binds two\noccurrences of a variable, so as to compute the intersection of their\ntwo (e \u2192 t) arguments (noun and verb phrase),\nand to test the intersection for non-emptiness in the case of\n\u2018some\u2019.\n\n\n\n\n\n\nNL type\nLP type\nLexical recipe\n\n\nhimself\n((np\\s)/np)\\(np\\s)\n(e\u2192e\u2192t)\u2192e\u2192t\n\u03bbR\u03bbx.((R x) x)\n\n\na, some\n(s/(np\\s))/n \n(e\u2192t)\u2192(e\u2192t)\u2192t\n\u03bbP\u03bbQ.(\u2203 \u03bbx.((P x)\u2227(Q x)))\n\n\nthat\n(n\\n)/(np\\s)\n(e\u2192t)\u2192(e\u2192t)\u2192e\u2192t\n\u03bbP\u03bbQ\u03bbx.((P x)\u2227(Q x)))\n\n\nThe interplay between lexical and derivational aspects of meaning\nassembly is illustrated with the example below. Notice that the linear\nproof term reflects the derivational history (modulo directionality);\nafter substitution of the lexical recipes and \u03b2 conversion this\ntransparency is lost. The full encapsulation of lexical semantics is\none of the strong attractions of the categorial approach.\n\nstring: \u2018a boy hurt himself\u2019\nNL derivation: (x :\n(s/np\\s)/n,y\n: n),(z :\n((np\\s)/np,w :\n((np\\s)/np)\\(np\\s))\n\u22a2 M : s\ncorresponding LP proof term: (M)\u2032 =\n((x\u2032 y\u2032)\n(w\u2032 z\u2032))\nlexical insertion: x\u2032 \u21a6\n\u03bbP\u03bbQ.(\u2203\n\u03bbx.((P\nx)\u2227(Q x))),y\u2032\n\u21a6 boy,z\u2032 \u21a6 hurt,w\u2032 \u21a6\n\u03bbR\u03bbx.((R x) x)\nfinal result after \u03b2 conversion: (\u2203\n \u03bbx.((boy x) \u2227 (hurt x x)))\n\n3.   Extended typelogical grammars\nThe strategy of combining resource-sensitivity at the level of\nderivational semantics with non-linear lexical meaning assignments is\nnot a general solution for the expressive limitations of the syntactic\ncalculi originally conceived by Lambek. A type of problem that\nnecessitates extensions of the derivational machinery itself has to do\nwith the inability of (N)L to\nestablish discontinuous dependencies between grammatical\nresources in a satisfactory way.  Such dependencies manifest\nthemselves in two situations.\nExtraction.  These are phenomena which generative grammar\nrefers to as \u2018overt displacement\u2019, as we find it\nin wh \u2018movement\u2019 constructions.  Compare\nthe wh phrases \u2018what \u2014 annoys Mary\u2019 versus\n\u2018what Mary put \u2014 there\u2019, as they would occur in a\ncontext \u2018I know what annoys Mary\u2019 or \u2018I know what\nMary put there\u2019.  The dash marks the spot where a noun phrase\nwould fit in a normal declarative sentence: \u2018this record annoys\nMary\u2019, \u2018Mary put the record there\u2019.  Assigning the\ntype wh/(np\\s) to \u2018what\u2019, we\ncan derive wh for the first example, with a np\nhypothesis in the left-peripheral subject position.  If this\nhypothesis (the \u2018gap\u2019) occurs internally, as in\nthe second example, it is unreachable for (N)L: one\ncannot derive np\\s for \u2018Mary \u2014 put\nthere\u2019 (nor s/np, for that matter, which would\nrequire a right-peripheral gap).\nInfixation. Typical examples would be cases of non-local\nsemantic construal, as in \u2018Alice knows someone is\ncheating\u2019, with a wide-scope reading for \u2018someone\u2019:\n\u2018there is a particular person x such that Alice\nthinks x is cheating\u2019. The quantifier phrase\n\u2018someone\u2019 occupies the structural position where in fact\nthe np-type hypothesis is needed, and realizes its semantic\neffect at some higher sentential level. With a type-assignment\ns/(np\\s) for \u2018someone\u2019, there\nis no derivation producing the non-local reading. In generative\ngrammar, one would call the non-local construal an instance of\n\u2018covert\u2019 movement.\nThe extensions of the basic calculus\nto be discussed in the sections below represent the strategies that\nare being pursued to find principled solutions to these problems of\ndiscontinuous dependencies.\n3.1   Multimodal systems, structural control\nThe key idea of Multimodal Categorial Grammars, introduced in the\n1990s, is simple: instead of a single family of residuated\ntype-forming operations, one considers multiple families, co-existing\nin one logic. To discriminate between these families, type-forming\noperations are decorated with a mode index\n/i,\u2009\u2297i,\u2009\\i;\nlikewise for the interpreting Merge\nrelations Ri. Each family has the\nsame logical rules (the residuation laws). But they can\ndiffer in their structural properties. In particular, they can\ninteract in terms of structural rules that mix different\nmodes.  At the level of the interpretation, such interaction\nprinciples introduce frame constraints, similar to the constraints\nthat went with the move from NL to L and LP.\nFor an example, let us return to the case of non-peripheral\nextraction \u2018(what) Mary put \u2014 there\u2019.  Assume we\nhave two modes of composition: \u2297c and\n\u2297d.  Regular valency requirements are\nexpressed in terms of the slashes for the\n\u2297c product.  Discontinuous dependencies are\nhandled by structural postulates of mixed associativity and\ncommutativity, and an inclusion postulate expressing the relative\n\u2018strength\u2019 of \u2297c and\n\u2297d. The type-assignment to the pronoun\n\u2018what\u2019 provides access to these postulates, so that it can\nestablish a link with a non-subject np hypothesis, also in a\nsentence-internal position.\n\nmixed associativity:\n(A\u2297c B)\u2297d C\n\u22a2 A\u2297c(B\n\u2297d C)\nmixed commutativity:\n(A\u2297c B)\n\u2297d C \u22a2 (A \u2297d\nC) \u2297c B\ninclusion: A \u2297d B \u22a2\n A \u2297c B\ntype for \u2018what\u2019 related to a non-subject np\nhypothesis: wh/c(s/d np)\n\nWe can now succesfully demonstrate that the phrase \u2018Mary put\n\u2014 there\u2019 is of\ntype s/dnp, as shown in the\nsketch of a derivation below. By means of the mixed interaction\npostulates, the np hypothesis finds its way to the\nnon-peripheral position where it is required by the verb\n\u2018put\u2019. Once it has reached its home position, the\ninclusion step switches from the structurally permissive mode d to the\nc mode expressing regular subcategorization.\n\n\n\u22ee\n\n\u00a0\n\u00a0inclusion\n\u00a0mixed comm.\n\u00a0mixed assoc.\n\u00a0\n\n\nnp\n\u2297c\n(((((np\\cs)\u2009/c\u2009pp)\u2009/c np)\n\u2297c\nnp)\n\u2297c\npp) \u22a2 s\n\n\n\nnp\n\u2297c\n(((((np\\cs)\u2009/c\u2009pp)\u2009/c\u2009np)\n\u2297d\nnp)\n\u2297c\npp) \u22a2 s\n\n\n\nnp\n\u2297c\n(((((np\\cs)\u2009/c\u2009pp)\u2009/c\u2009np)\n\u2297c\nnp)\n\u2297d\nnp) \u22a2 s\n\n\n\n(np\n\u2297c\n((((np\u2009\\c\u2009s)\u2009/c\u2009pp)\u2009/c\u2009np)\n\u2297c\npp))\n\u2297d\nnp) \u22a2 s\n\n\nnp\n\u2297c\n(((np\u2009\\c\u2009s)\u2009/c\u2009pp)\u2009/c\u2009np)\n\u2297c\npp)\n\u22a2 s\u2009/d np\n\n\nMary\n\nput\n\nthere\n\n\n\n\nThrough multimodal interaction principles, one avoids the\novergeneration that would result from global Associativity\nand/or Commutativity options for a single composition operation\n\u2297. Undisciplined use of multimodality, however, could easily\nlead to the introduction of construction-specific mode distinctions,\nthus compromising one of the main attractions of the typelogical\napproach.  The theory of structural control operators to be discussed\nbelow offers a more principled solution to the type of problem\nmultimodal approaches address.\nControl operators.  Linear Logic, by dropping the structural\nrules of Contraction and Weakening, splits the conjunction\n\u2018&\u2019 of classical logic in a multiplicative and an\nadditive connective.  This move to a resource-sensitive logic can be\nobtained without sacrificing expressivity: the unary modalities\n\u2018!\u2019,\u2018?\u2019 allow one to reintroduce\nContraction/Weakening in a controlled form and thus to recover\nclassical logic from within the linear setting.\nA similar strategy can be followed within typelogical grammar\n(Moortgat 1996, Kurtonina 1995).  The type language is extended with a\npair of unary operators which we will write \u25ca,\u25a1; formulas\nnow are built out of atomic formulas p with the unary and\nbinary type-forming operations.  As with the binary vocabulary, we\nstart with a minimal logic for \u25ca,\u25a1; facilities for\nstructural control can then be added in the form of extra postulates.\nThe truth conditions below characterize the control operators \u25ca\nand \u25a1 as inverse duals with respect to a binary accessibility\nrelation R\u25ca. This interpretation turns them\ninto a residuated pair, just like composition and the left and right\ndivision operations.\n\nFormulas: A,B ::= p | \u25caA |\n \u25a1A | A\\B | A\n \u2297 B | A/B\nInterpretation:\n  \nx \u22a9\u25caA iff\n  \u2203y(R\u25caxy\n  and y \u22a9 A)\nx \u22a9\u25a1A iff\n \u2200y(R\u25cayx\n implies y \u22a9 A)\n\n\nResiduation laws: \u25caA \u22a2 B\niff A \u22a2 \u25a1B\n\nWe saw that in the minimal logic NL completeness with\nrespect to the frame semantics for composition and its residuals\ndoesn't impose restrictions on the interpretation of the merge\nrelation R\u2297. The same holds\nfor R\u25ca in the pure residuation logic of\n\u25ca,\u25a1. From the residuation laws, one easily derives\nmonotonicity of the control operators (A \u22a2 B\nimplies \u25caA \u22a2 \u25caB and \u25a1A\n\u22a2 \u25a1B); their compositions satisfy\n\u25ca\u25a1A \u22a2 A and A \u22a2\n\u25a1\u25caA. These properties can be put to use in refining\nlexical type assignment so that selectional dependencies are\ntaken into account.  Compare the effect of an\nassignment A/B\nversus A/\u25ca\u25a1B. The former will produce an\nexpression of type A in composition both with expressions of\ntype B and \u25ca\u25a1B, the latter only with the\nmore specific of these two, \u25ca\u25a1B. An expression typed as\n\u25a1\u25caB will resist composition with\neither A/B or A/\u25ca\u25a1B.\nBernardi and Szabolcsi (2008) present accounts of licensing of\npolarity-sensitive expressions and scope construal based on (a\ngeneralization of) this modalisation strategy.\nFor sequent presentation of \u25ca,\u25a1, antecedent tree\nstructures now are built out of formulas by means of unary and binary\ntree-building operations, (\u2013) and (\u2013,\u2013).  The\nresiduation pattern then gives rise to the following left and right\nintroduction rules.  Cut elimination carries over straightforwardly to\nthe extended system, and with it decidability and the subformula\nproperty.\n\n\n\n\n\n\n\u0393[(A)] \u21d2 B \n\n\n\u0393[\u25caA] \u21d2 B\n\n\n\n\u25caL\n\n\n\n\n\n\u0393 \u21d2 A\n\n\n(\u0393) \u21d2 \u25caA\n\n\n\n\u25caR\n\n\n\n\n\n\u0393[A] \u21d2 B\n\n\n\u0393[(\u25a1A)] \u21d2 B\n\n\n\n\u25a1L\n\n\n\n\n\n(\u0393) \u21d2 A\n\n\n\u0393 \u21d2 \u25a1A\n\n\n\n\u25a1R\n\n\n\n\n\nControlling structural resource management.  Let us turn\nthen to the use of \u25ca,\u25a1 as control devices. The control can\ntake two forms: one is to license access to a structural\noption that would be overgenerating if globally available; the second\nis to occasionally block a structural capability of the\ngrammar. For the licensing type of control, compare the multimodal\ntreatment of extraction in terms of a distinction\n\u2297c vs \u2297d, with\nthe \u25ca-controlled version below, which relies on a single binary\ncomposition operation, and narrows down the \u2018movement\u2019\npotential entirely to \u25ca-marked resources.\n\n\u25ca-controlled mixed associativity: (A\n\u2297 B) \u2297 \u25caC \u22a2 A\n\u2297 (B \u2297 \u25caC)\n\u25ca-controlled mixed commutativity: (A\n\u2297 B) \u2297 \u25caC \u22a2\n(A \u2297 \u25caC) \u2297 B\ntype for \u2018what\u2019 related to a non-subject np\nhypothesis: wh/(s/\u25ca\u25a1np)\n\nThe derivation sketch below illustrates the interplay between\nlogical and structural reasoning. As long as the gap subformula\n\u25ca\u25a1np carries the licensing \u25ca, the structural\nrules are applicable; as soon as it has found the appropriate\nstructural position where it is selected by the transitive verb, it\ncan be used as a regular np, given the type transition\n\u25ca\u25a1np \u22a2 np which obviates the need\nfor the inclusion postulate of the earlier account.  Related analyses\nof extraction based on the \u2018!\u2019 modality of Linear Logic\ncan be found in (Barry et al. 1991), with the dereliction\nrule !A \u22a2 A taking the place of\n\u25ca\u25a1A \u22a2 A for gap introduction.\n\n\n\u22ee\n\n\u00a0\n\u00a0since \u25ca\u25a1A \u22a2 A\n\u00a0\u25ca mixed comm.\n\u00a0\u25ca mixed assoc.\n\u00a0\n\n\nnp \u2297 (((((np\\s)/pp)/np)\n  \u2297 np) \u2297 pp) \u22a2 s\n\n\n\nnp \u2297 (((((np\\s)/pp)/np) \n \u2297 \u25ca\u25a1np) \u2297 pp) \u22a2 s\n\n\n\nnp \u2297 (((((np\\s)/pp)/np)\n \u2297 pp) \u2297 \u25ca\u25a1np) \u22a2 s\n\n\n\n(np \u2297 ((((np\\s)/pp)/np)\n \u2297pp)) \u2297 \u25ca\u25a1np \u22a2 s\n\n\nnp\n\u2297 \n((((np\u2009\\\u2009s)\u2009/\u2009pp)\u2009/\u2009np)\n\u2297\npp)\n\u22a2 s\u2009/\u2009\u25ca\u25a1np\n\n\nMary\n\nput\n\nthere\n\n\n\n\nFor the type of control where a structural transformation has to be\nblocked, we can turn to extraction islands: phrases that do\nnot allow a gap, such as adjuncts. Compare \u2018Mary fell asleep\nduring the concert\u2019, with the adjunct phrase \u2018during the\nconcert\u2019 of type s\\s, with the ill-formed\n\u2018I know what Mary fell asleep during \u2014\u2019. To make the\nadjunct inaccessible, one can assign \u2018during\u2019 the type\n(\u25a1(s\\s))/np: for the \u25a1 to be\neliminated, the whole adjunct phrase has to be enclosed by a\nstructural \u25ca, which then acts as a barrier for extraction. Without\nsuch a barrier, the extraction postulates as formulated above would\nallow the ill-formed sentence to be derived.  This strategy of\nprojecting island barriers from lexical type assignments was\nintroduced by Morrill; see the discussion of \u2018structural\ninhibition\u2019 in Morrill 1994.\nThe two uses of the control operators illustrated here give rise to\na general theory of substructural communication relating the different\ntype logics in the categorial landscape. Let Source and Target be\nneighbouring logics differing in some structural option, for\nexample NL versus L, or L\nversus LP. Kurtonina and Moortgat (1997) establish a set of\nembedding theorems of the following form:\n\ntranslation: \u03bc : Source(/,\u2297,\\) \u2192\nTarget(\u25ca,\u25a1,/,\u2297,\\), such that\nA \u22a2 B is derivable in the Source logic iff\n\u03bc(A) \u22a2 \u03bc(B) is derivable in the Target\nlogic\n\nIn the case where the Target logic is more discriminating than the\nSource, the translation implements control of the licensing\ntype. The other direction of communication obtains when the Target\nsystem is less discriminating than the Source.  The modal decoration\neffected by the translation in this case blocks the applicability of\nstructural rules.\nFrame constraints, term assignment.  The frame semantics for\nthe pure residuation logic does not impose restrictions on the\ninterpretation of the R\u25ca\nand R\u2297 relations.  In the case of extended\nversions with modally controlled structural postulates, there is a\nframe constraint for each structural postulate, and completeness holds\nwith respect to appropriately restricted frames.\n\n\n\n\n\n\nxyz\n\n\n\\/|\n\n\nst\n\n\n\\/\n\n\nr\n\n\n\n\u00a0\u00a0\u00a0\n\n\nz\n|\nyt\u2032\n\\/\nxs\u2032\n\\/\nr\n\n\n\u00a0\u00a0\u00a0\n\n\nz\n|\nxt\u2032\n\\/\ns\u2032y\n\\/\nr\n\n\n\n\ninput\n\u00a0\u00a0\u00a0\noutput \u25ca mixed ass.\n\u00a0\u00a0\u00a0\noutput \u25ca mixed comm.\n\n\n\nDepicting R\u2297 with a branching\nand R\u25ca with a non-branching node, in the case\nof the modally controlled extraction postulates discussed here, we\nhave the constraint that for\nall x,y,z,r,s,t\ncomposed as in the input configuration below, there are alternative\ninternal points s\u2032,\u2009t\u2032 connecting\nthe root r to the leaves x,y,z.\nFor the mapping between the modally extended syntactic source\ncalculus and the semantic target calculus LP, we have two\noptions.  The first is to treat \u25ca,\u25a1 purely as syntactic\ncontrol devices.  One then sets (\u25caA)\u2032 =\n(\u25a1A)\u2032 = A\u2032, and the inference\nrules affecting the modalities leave no trace in the LP term\nassociated with a derivation. The second is to actually provide\ndenotation domains for the new types, and to extend the term language\naccordingly.  For the minimal logic of \u25ca,\u25a1, one can turn to\nWansing (2002), who develops a set-theoretic interpretation of minimal\ntemporal intuitionistic logic.  The temporal modalities of future\npossibility and past necessity are indistinguishable from the control\noperators \u25ca,\u25a1, prooftheoretically and as far as their\nrelational interpretation is concerned.  Morrill (1990) gives an\ninterpretation in intensional lambda calculus for a stronger S5\nmodality, which assumes a universal accessibility relation at the\nlevel of the frame semantics.  Denotations for modalized\nformulas A, in this setting, are functions from indices\n(situations, reference points) to A denotations.\nDiscussion. The control operators discussed here bear a\nstrong resemblance to the syntactic control features used in Stabler's\nalgebraic formulation of Minimalist Grammars (Stabler 1997, 1999).\nThese features, like \u25ca,\u25a1, come in matching pairs of a\nlicensor \u2018+f\u2019 and a licensee\n\u2018\u2212f\u2019 that have to cancel for a derivation\nto be successful; movement is triggered by the presence of an\nappropriate licensor feature.  For an explicit comparison of the\nmimimalist and the typelogical view on structural control, see Vermaat\n(2004).\nWhether one wants the full expressivity of modally controlled\nstructural rules is a matter of debate.  Vermaat (2006) takes the\nstrong position that the cross-linguistic possibilities for\ndisplacement can be fully captured in terms of the right branch\nextraction postulates discussed above, together with their mirror\nimages for extraction from left branches.  Under this view, which is\nconsistent with the radical lexicalism of the original categorial\nsystems, this postulate set is fixed at the level of Universal\nGrammar, and variation is reduced to the language-specific lexica that\ndetermine which of the available extraction patterns are\nactivated.\n3.2   The logic of discontinuity\nThe discontinuous Lambek calculi that have been developed by\nMorrill and co-workers (see Morrill et al. 2007, 2009) and\nChapter 6 of the forthcoming monograph (Morrill 2010) extend the\nassociative Lambek calculus L. We saw that L is the\nlogic of strings composed by concatenation.  The discontinuous calculi\nenrich the ontology with a notion of split strings:\nexpressions consisting of detached parts, as in the idiom \u2018take\n\u2014 to task\u2019. To build the phrase \u2018take someone to\ntask\u2019, one wraps the discontinuous expression around\nits object. In this particular example, there is a single point of\ndiscontinuity, but one can also think of cases with more than one\nsplit point. This naturally leads to two notions of discontinuous\ncomposition: a deterministic view, where wrapping targets a particular\nsplit point, and a non-deterministic view where the targeted split\npoint is arbitrary. In the case of expressions with a single split\npoint, these two notions coincide.\nThe vocabulary of DL (Discontinuous Lambek Calculus)\nconsists of residuated families of unary and binary type-forming\noperations.  A representative sample is given below.  For the binary\ncase, in addition to the concatenation product of L and the\nresidual slash operations, we have a discontinuous (wrapping) product\n\u2299, with residual infixation \u2193 and extraction \u2191\noperations.  For the deterministic interpretation, the discontinuous\ntype-forming operations have an indexed form\n\u2191k, \u2299k,\n\u2193k explicitly referring to the k-th\nsplit point of their interpretants.  The function of the unary\noperations is to control the creation and removal of split points.  As\nin the binary case, we have non-deterministic operations\n(bridge \u2227, split \u2228) and indexed forms\n(\u2227k,\u2228k)\nwith a deterministic interpretation.\n\nA,B ::= \u2026 | A \u2299 B\n| A \u2193 B | B \u2191 A |\n\u2227A | \u2228A\n\nOn the model-theoretic side, an innovative feature of DL is\nthe move to a multi-sorted interpretation.  The key notion is\nthat of a graded algebra: a freely generated algebra\n(W,\u00b7,1, \u23b5) where the monoid\n(W,\u00b7,1) of the interpretation of L* is\naugmented with a distinguished generator \u23b5 called the separator.\nThe sort of an expression s, \u03c3(s), is\ngiven by the number of occurrences of the separator in it. Expressions\nof the nullary sort are the familiar strings for the language models\nof L. Expressions of sort n > 0 are split\nstrings, with n marked positions where other expressions can\nbe substituted.\nInterpretation of types is now relativized to sorted\ndomains Wi = {s | \u03c3(s)\n= i} for i \u2265 0. Frames, accordingly, are sorted\nstructures\n({Wi}i\u2208N,Rbridge,Rwrap,\u00b7,{bridgek}k\u2208N*,{wrapk}k\u2208N*)\nwith n + 1-ary relations for the n-ary type-forming\noperations with a non-deterministic interpretation and n-ary\noperations (functions) for the n-place deterministic\nvocabulary items.  The operation \u00b7 : Wi\n\u00d7 Wj\n\u2192 Wi+j here is the sorted\nversion of the concatenation operation of L.\n\n\n\nrelation/operation\ninterpretation\n\n\nRwrap \u2286 Wi+1\n \u00d7 Wj \u00d7 Wi+j\nthe smallest relation\ns.t. Rwrap(u\u23b5w,v,uvw)\n\n\nRbridge\n\u2286 Wi+1 \u00d7 Wi\nthe smallest relation s.t. Rbridge(u\u23b5v,uv)\n\n\nwrapk : Wi+1\n \u00d7 Wj \u2192 Wi+j\nwrapk(s,t) is the result of\nreplacing the k-th separator in s by t\n\n\nbridgek : Wi+1\n \u2192 Wi\nbridgek(s) is the result of replacing\nthe k-th separator in s by 1\n\n\n\n An interpretation for DL associates atomic types of\nsort i to subsets of Wi. Interpretation\nclauses for the new complex types are standard. In the light of the\nillustrations below, we give the clauses for non-deterministic\nbridge/split, and the wrapping family. The sort of the types can be\nreadily computed from the sort information for the interpreting\noperations/relations.\n\ns \u22a9 \u2227A iff\n\u2203t(Rbridge(t,s)\nand t \u22a9 A)\nt \u22a9 \u2228B iff\n\u2200s(Rbridge(t,s)\nimplies s \u22a9 B)\ns \u22a9 A \u2299 B iff\n\u2203s\u2032s\u2033(Rwrap(s\u2032,s\u2033,s)\nand s\u2032 \u22a9 A and s\u2033 \u22a9 B)\ns\u2033 \u22a9 A \u2193 C iff \u2200s\u2032s(if Rwrap(s\u2032,s\u2033,s) and s\u2032 \u22a9 A, then s \u22a9 C)\ns\u2032 \u22a9 C \u2191 B iff\n \u2200s\u2033s(if Rwrap(s\u2032,s\u2033,s) and s\u2033 \u22a9 B, then s \u22a9 C)\n\nOn the proof-theoretic side, a cut-elimination theorem for a\nsequent presentation of DL establishes decidability.\nThe DL sequent rules are shown to be sound with respect to the\nintended interpretation; a completeness result so far has not been\nobtained.  For the mapping from the syntactic source\ncalculus DL to the semantic target calculus LP, the\nunary type-forming operations are considered inert: the inference\nrules for these connectives, consequently, leave no trace in\nthe LP proof term associated with a derivation in the syntactic\nsource calculus. The continuous and discontinuous families, for the\nrest, are treated exactly alike.  Specifically, the infixation and\nextraction operations are mapped to LP function types, like the\nslashes.\nIllustration.  DL has been successfully applied to a great\nnumber of discontinuous dependencies, both of the overt and of the\ncovert type. The non-deterministic operations have been used to model\nparticle shift and complement alternation constructions.  The\ndeterministic operations of sort 1 (single split point) are used in\nthe analysis of non-peripheral extraction, discontinuous idioms,\ngapping and ellipsis, quantifier scope construal, reflexivisation,\npied-piping and the Dutch cross- serial dependencies, among\nothers.\nWe illustrate the non-deterministic use of DL with English\nparticle shift, using labeled natural deduction format to display\nderivations, with items Form-Meaning:Type. A verb-particle\ncombination \u2018call \u2014 up\u2019 can be lexically typed as\n\u2228(np\\s) \u2191 np of sort 2, with an\ninternal split point, and a right-peripheral one. Elimination of the\nnon-deterministic extraction operation \u2191 offers a choice as to\nwhether wrapping will affect the first or the second split point. The\nfirst option is displayed below. The remaining separator is removed in\nthe elimination step for \u2228, with the continuous verb phrases\n\u2018call Mary up\u2019 or \u2018call up Mary\u2019 as\nresult.\n\n\n\ncalled \u22c5 \u23b5 \u22c5 up \u22c5 \u23b5\n\u2212phone : \u2228(np\\s)\n\u2191 np\u00a0\u00a0\u00a0\u00a0Mary \u2212 m : np\n\u00a0E\u2191\u00a0\n\n\n\n\n\ncalled \u22c5 Mary \u22c5 up \u22c5 \u23b5\n\u2212 (phone m) : \u2228(np\\s)\n\u00a0E\u2228\n\n\ncalled \u22c5 Mary \u22c5 up \u2212\n (phone m) : np\\s\n\n\n\n\n\n\nFor an example involving covert discontinuity, consider quantifier\nscope construal.  DL provides a uniform type assignment to\ngeneralized quantifier expressions such as \u2018everyone\u2019,\n\u2018someone\u2019: (s \u2191 np)\n\u2193 s.  In the syntactic source calculus, this type\nassignment allows a quantifier phrase QP to occupy any position that\ncould be occupied by a regular non-quantificational noun phrase.\nSemantically, the image of the \u2191 Introduction rule at the level\nof the semantic target calculus LP binds an np type\nhypothesis at the position that was occupied by the QP (the a\n\u2212 x : np premise, with a\nand x structural and semantic variables for the np\nhypothesis).  The image of the \u2193 Elimination rule applies the\nterm representing the QP meaning to this abstract.  Scope ambiguities\narise from derivational ambiguity in the source\ncalculus DL. The derivation below results in a non-local\nreading \u2018there is a particular x such that Mary\nthinks x left\u2019.  Looking upward from the conclusion,\nthe last rule applied is \u2193 Elimination, which means the QP takes\nscope at the main clause level.  An alternative derivation, producing\nthe local scope reading, would have the / Elimination rule for\n\u2018thinks\u2019: (np\\s)/s as the last\nstep.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u2026\u00a0\u00a0a \u2212 x : np\u00a0\u00a0\u2026\n\n\u22ee\n\n\n\nMary \u22c5 thinks \u22c5 a \u22c5 left \u2212 ((thinks (left x)) m) : s\n\n\n\n\u00a0\n\u00a0\n\u00a0\u2191I\n\u00a0\u2193E\n\n\nsomeone \u2212 \u2203 : (s \u2191 np)\n\u2193 s\u00a0\nMary \u22c5 thinks \u22c5 \u23b5\n\u22c5 left \u2212 \u03bbx.((thinks\n(left x)) m) : s \u2191 np\n\n\nMary \u22c5 thinks \u22c5 someone \u22c5 left \u2212\n(\u2203 \u03bbx.((thinks\n(left x)) m)) : s\n\n\n\n\n\n\nDiscussion.  The basis for the DL extensions is the\nassociative calculus L. As we saw above, a global insensitivity\nto phrase structure is a source of overgeneration, unless blocked by\nexplicit island modalities.  In the development of DL nothing\nseems to hinge on the associativity of the base system: it would seem\nentirely feasible, in other words, to develop DL as an\nextension of a non-associative basis, allowing for the representation\nof constituent-structure information. In the interpreting frames, one\nwould then start from a graded groupoid rather than a\nmonoid. The fact that the DL framework can readily accommodate\na string or tree-based point of view testifies to the versatility of\nthe approach.\n3.3   Symmetric categorial grammar\nThe extensions of the Syntactic Calculus that we studied in the\nprevious sections all obey an \u201cintuitionistic\u201d\nrestriction: in statements\nA1,\u2026,An\n\u22a2 B the antecedent can consist of multiple formulas\n(configured as a \u2297 tree in the non-associative case, a list or\na multiset in the case of L, LP), the succedent is a\nsingle formula.\nIn a remarkable paper antedating Linear Logic by five years,\nGrishin (1983) presents a number of extensions of the Lambek calculus\nwith the common characteristic that derivability holds between\nhypotheses A1,\u2026,An,\ntaken together by means of a multiplicative conjunction,\nand multiple\nconclusions B1,\u2026,Bm,\ncombined by means of a multiplicative disjunction. Linguistic\nexploration of Grishin's ideas has started in recent years.  In this\nsection, we introduce a multiple-conclusion categorial system that is\nalready well-studied: LG (for Lambek-Grishin calculus).  We\npresent syntax and relational semantics of the system; in the next\nsection, we turn to its computational interpretation.\n\n\n\npreorder laws\nA \u22a2 A\n\n\n\nA\n \u22a2 B\u00a0\u00a0\u00a0\u00a0  B \u22a2 C\n\n\nA \u22a2 C\n\n\n\n\n\n(dual) residuation laws)\n\n\n\nA\n \u22a2 C/B\n\n\nA\n \u2297 B \u22a2 C\n\n\nB \u22a2 A\\C\n\n\n\n\n\n\nB\n \u29b8 C \u22a2 A\n\n\nC\n \u22a2 B \u2295 A\n\n\nC\n \u2298 A \u22a2 B\n\n\n\n\n\ninteraction principles\n\n\n\nA\n \u2297 B \u22a2 C \u2295 D\n\n\nC\n \u29b8 A \u22a2 D\u2009/\u2009B\n\n\n\n\n\n\nA\n \u2297 B \u22a2 C \u2295 D\n\n\nB\n \u2298 D \u22a2 A\u2009\\\u2009C\n\n\n\n\n\n\n\n\n\nA\n \u2297 B \u22a2 C \u2295 D\n\n\nC \u29b8 B\n \u22a2 A\u2009\\\u2009D\n\n\n\n\n\n\nA \u2297 B\n \u22a2 C \u2295 D\n\n\nA \u2298 D \u22a2 C\u2009/\u2009B\n\n\n\n\n\nThe Lambek-Grishin calculus LG\n\nLG consists of a symmetric version of the pure residuation\nlogic NL together with structure-preserving interaction\nprinciples relating the conjunctive and disjunctive operations.  We\ndiscuss these components in turn. For symmetry, the inventory of\ntype-forming operations is doubled: in addition to the NL\noperations \u2297,\\,/ (product, left and right division), there is a\nsecond family \u2295,\u2298,\u29b8: coproduct, right and left\ndifference.  The two families are related by an arrow reversal\nsymmetry \u03b4, which translates type formulas according to the\ntable below.\n\n\n\n\u03b4\n\u00a0\n\n\n\nC/B\n\u00a0\u00a0\u00a0   A \u2297 B \u00a0\u00a0\u00a0\u00a0  A\\C\n\n\nB\n \u29b8 C\u00a0\u00a0  B \u2295 A\n\u00a0 C \u2298 A\n\n\n\n\n\n\nAt the level of derivability, we then have A \u22a2 B iff\n\u03b4(B) \u22a2 \u03b4(A): for every theorem or rule of NL,\nwe also find its image under \u03b4 in LG. A note about the\nnotation: we read B \u29b8 A as \u2018B\nfrom A\u2019 and A \u2298 B as\n\u2018A less B\u2019, i.e., the quantity that is\nsubtracted is put under the circled (back)slash, just as we have the\ndenominator under the (back)slash in the case of left and right\ndivision types. In a formulas-as-types spirit, we will feel free to\nrefer to the division operations also as implications, and to the\ndifference operations as coimplications.\nCommunication between the product and coproduct families requires\nthe addition of interaction principles to the (dual) residuation laws.\nThe principles above take the form of inference rules obtained from\nthe following recipe: from A \u2297 B\n\u22a2 C \u2295 D in the premise, one selects a\nproduct and a coproduct term; in the conclusion,\none simultaneously introduces the residual operations for the\nremaining two terms. Using the (dual) residuation laws, one derives\nthe following patterns from the interaction principles.\nAlternatively, one can take (P1)\u2013(P4) as primitive postulates,\nand obtain the interaction principles as derived inference rules,\nusing transitivity and the (dual) residuation laws.\n\n\n\n(P1)\n(A \u29b8 B) \u2297 C\n\u22a2 A \u29b8 (B \u2297 C)\n\n\n(P2)\nC \u2297 (A \u29b8 B)\n\u22a2 A \u29b8 (C \u2297 B)\n\n\n(P3)\nC \u2297 (B \u2298 A) \u22a2\n(C \u2297 B) \u2298 A\n\n\n(P4)\n(B \u2298 A) \u2297 C \u22a2\n(B \u2297 C) \u2298 A\n\n\n\nDerivability patterns of the form (P1)\u2013(P4) have been called\nlinear distributivity principles \u2014 linear, because they do not\nduplicate any of the terms involved. In LG, in addition to\nbeing linear, they respect the word order and phrase structure\ninformation encoded in the non-commutative, non-associative\ntype-forming operations.\nIllustration. The interaction principles of LG\nprovide a particularly direct way of capturing phenomena that depend\non infixation rather than concatenation.  The derivations\nbelow (using monotonicity, and (dual) residuation steps) show how the\nsame pieces of information (the same premises) can be used either to\nintroduce an implication B\\C on the left of the\nturnstile, or a coimplication B \u2298 C on the\nright.  The first option leads to a rule of Application \u2014 the\ncentral composition operation of standard Lambek calculus. The second\noption leads to a Co-Application variant.  Although these two rules\nare derived from the same premises, there is an important difference\nbetween them.  When the implication B\\C composes\nwith its argument, it must stay external to X.  In the case\nof the coimplication, when X is some product of\nfactors A1,\u2026,An, the\nconditions for the interaction principles are met.  This means that\nthe coimplication B \u2298 C will be able to\ndescend into the phrase X and associate with any of the\nconstituent parts Ai into a formula (B\n\u2298 C) \u29b8 Ai.\n\n\n\n\n\n\nX\n \u22a2 B\u00a0\u00a0 C \u22a2 Y\n\n\nB\\C\n \u22a2 X\\Y\n\n\nX\n \u2297 (B\\C) \u22a2 Y\n\n\n\n\u00a0\u00a0\u00a0\n\n\n\nX \u22a2 B\n     \u00a0\u00a0 C \u22a2 Y\n\n\nX\n \u2298 Y \u22a2 B \u2298 C\n\n\nX\n \u22a2 (B \u2298 C) \u2295 Y\n\n\n\n\n\n\nIn general, an expression of type (B \u2298 C)\n\u29b8 A behaves locally as an A within a context\nof type B; it then acts as a function transforming B\ninto C. We illustrate with the example of non-local scope\nconstrual for which we have seen the DL analysis in the previous\nsection. The key point is the lexical type assignment to the\ngeneralized quantifier expression, instantiating (B\n\u2298 C) \u29b8 A as (s\n\u2298 s) \u29b8 np. The semantic interpretation\nof this derivation will be discussed below.\n\n\n\nnp \u2297 (((np\\s)/s) \u2297 (np \u2297 (np\\s)))\n   \u22a2 s\u00a0\u00a0\u00a0\u00a0 s \u22a2 s\n\n\nnp \u2297 (((np\\s)/s) \u2297 (\n\u00a0np\u00a0 \u2297 (np\\s)))\n \u22a2 \n\u00a0(s \u2298 s)\u00a0  \u2295 s\n\n\n\u22ee\n\n\nnp\n\u00a0\u2297\u00a0\n(((np\\s)/s)\n\u00a0\u2297\u00a0\n ((\n\u00a0(s \u2298 s)\u00a0 \u29b8 \n\u00a0np\u00a0)\n\u00a0\u2297\u00a0\n(np\\s))\n) \u22a2 s\n\n\nAlice\n\nthinks\n\nsomeone\n\nleft\n\n\n\n\nCompleteness, decidability. Relational models for LG\nare given in terms of two interpreting\nrelations: R\u2297 for multiplicative\nconjunction (merge, fusion), and R\u2295 for\nmultiplicative disjunction (fission). The truth conditions for\nco-product and the difference operations are given below.\n\nx \u22a9 A \u2295 B iff\n \u2200yz(if R\u2295xyz, then\n either y \u22a9 A or z \u22a9 B)\ny \u22a9 C \u2298 B iff\n \u2203xz(R\u2295xyz and\n not-(z \u22a9 B) and x \u22a9 C)\nz \u22a9 A \u29b8 C iff\n \u2203xy(R\u2295xyz\n and not-(y \u22a9 A) and x \u22a9 C)\n\nCompleteness of LG with respect to this interpretation is proved in\nKurtonina and Moortgat 2010.  The minimal symmetric system (without\ninteraction principles) has fission R\u2295 and\nmerge R\u2297 as distinct relations, without\nimposing restrictions on their interpretation.  In the presense of the\ninteraction principles, their interpretation is related in terms of\nframe constraints. The distributivity principle (A\n\u29b8 B) \u2297 C \u22a2 A \u29b8\n(B \u2297 C), for example, corresponds to the\nconstraint that for\nevery x,y,z,w,v, if we\nhave a configuration R\u2297xyz\nand R\u2295vwy, then there exists an\nalternative internal point t such\nthat R\u2295twx\nand R\u2297tvz.  For decidability,\nMoortgat (2009) gives a sequent presentation of LG in the\nformat of a Display Calculus allowing cut-free proof search.\nDiscussion. LG is a weaker logic than CNL, the\nClassical Non-Associative Lambek Calculus of de Groote and Lamarche\n2002. In the latter system, like in classical linear logic, we have an\ninvolutive negation and De Morgan dualities turning multiplicative\nconjunction (times) and disjunction (par) into interexpressible\noperations. With respect to the linguistic applications, one can\ncompare\nLG with the Discontinuous Calculus of \u00a73.2.  Whereas the\nlatter provides uniform analyses of both the extraction and the\ninfixation type of discontinuities, the distributivity principles\nof LG are primarily addressing the infixation variety.  It may\nbe interesting in this respect to note that Grishin 1983 proposes a\nsecond group of distributivity principles \u2014 converses of the\nones discussed above.  Whether these could play a role in the analysis\nof overt displacement remains to be seen.  From a formal point of\nview, each of the groups of distributivities is a conservative\nextension of the basic symmetric calculus.  But the combination of the\ntwo (i.e., the distributivity principles as invertible rules)\ninduces partial associativity/commutativity of the (co)product\noperations, i.e., structure-preservation is lost.\n3.4   Flexible interpretation, continuation semantics\nIn the previous sections, the emphasis was on extending the\ncapabilities of the syntactic source calculi. In this section, we look\nat developments that put more structure in the mapping between the\nsource and target calculi.\nThe syntax-semantics mapping, as discussed in \u00a72.2,\nis rigid: once we have determined its action on the atomic\ntypes of the syntactic source calculus, everything is fixed. This\nrigidity is problematic as soon as we have a class of syntactic\nexpressions with a non-uniform contribution to meaning assembly.  Noun\nphrases are a case in point.  Mapping np to semantic\ntype e is appropriate for proper nouns and definite\ndescriptions whose denotations can be taken to be individuals.  But\nfor quantifying expressions like \u2018someone\u2019, \u2018no\nstudent\u2019, an interpretation of type e is inadequate.\nThe rigid syntax-semantics mapping thus forces one to assign these\nexpressions a higher-order type in the syntax, for\nexample s/(np\\s), so as to obtain a\nsemantic type with the right kind of denotation as the translation\nimage, (e \u2192 t) \u2192 t. If one wants\nto avoid this semantically motivated complication of the syntax, one\ncould set np\u2032 = (e \u2192 t)\n\u2192 t. But now the effect will be that simple transitive\nverbs (np\\s)/np, which one would like to\ntreat as binary relations e \u2192 e\n\u2192 t by default, are associated with third-order\ninterpretations instead.\nFlexible interpretation. An attractive alternative to this rigid\nview of the syntax-semantics interface, is the flexible interpretation\nof Hendriks 1993.  In this approach, a type of the syntactic source\ncalculus is associated with an infinite set of LP types: one of\nthese is the default semantic type associated with the syntactic\nsource type, the others are derived from this default by means\nof type shifting laws. Similarly, a source calculus term is\ntranslated into an infinite set of target semantic terms; one of these\nis the basic translation (not necessarily of the default\nsemantic type for the relevant syntactic category), the others are\nderived by the Curry-Howard term image of the typing shifting laws.\nThe type shifting principles used are (i) argument lowering, (ii)\nvalue raising, and (iii) argument raising. The first two correspond to\nvalid type transitions of NL; argument raising is the crucial\nprinciple that goes beyond the expressivity of the syntactic source\ncalculi, as we saw in \u00a72.2.\nAs an example of flexible interpretation, compare \u2018John loves\nMary\u2019 and \u2018Everyone loves someone\u2019.  Syntactically,\nall noun phrases are typed as np, and the verb as\n(np\\s)/np. \u2018John\u2019 and\n\u2018Mary\u2019 are interpreted with constants of type e,\n\u2018loves\u2019 with a constant of type e\n\u2192 e \u2192 t, the default semantic types for\nthe syntactic source types.  But \u2018everyone\u2019 and\n\u2018someone\u2019 are mapped to constants of type (e\n\u2192 t) \u2192 t. Interpreting the syntactic\nderivation for \u2018Everyone loves someone\u2019, the semantic\ntypes no longer match for simple function application: the verb\nexpects two e type arguments, but instead finds two arguments\nof type (e \u2192 t) \u2192 t. There are\ntwo ways of accommodating these higher-order arguments by means of\nargument raising: depending on whether one raises first the object\nargument and then the subject, or vice versa, one obtains two readings\nfor one and the same syntactic derivation: a reading corresponding to\nthe surface order, with \u2200 taking scope over \u2203, and a\nreading with the inverted scope order. The correspondence between\nsyntax and semantics, under this flexible view, has become\na relation, rather than being functionally\ndetermined by the translation homomorphism of \u00a72.2.\nContinuations.  It has become clear in recent years, that\nthe core ideas of Hendriks' type-shifting account of derivational\nambiguity can be insightfully recast in terms of a\ncontinuation-passing-style interpretation (CPS), as developed within\ncomputer science, and the different evaluation strategies\navailable for such interpretation. The use of continuations in natural\nlanguage semantics has been pioneered by de Groote (2001b) and Barker\n(2002). In the theory of programming languages, a continuation is a\nrepresentation of the control state, i.e., the future of the\ncomputation to be performed. By adding the control state as an\nexplicit parameter in the interpretation, it becomes possible for a\nprogram to manipulate its continuation, and thus to express control\nconstructs that would otherwise be unavailable.  Technically,\ncontinuation semantics makes use of a designated response type for the\nultimate result of a computation; a continuation for an expression of\ntype A is a function that takes an A value to the\nresponse type. In the application to natural language semantics, the\nresponse type is generally identified with the type of truth\nvalues t, i.e., the type assigned to complete sentences.\nBarker 2004 shows how to obtain the type-shifting scope ambiguity\nfor \u2018Everyone loves someone\u2019 in terms of a\ncontinuation-passing-style translation.  The key idea is that in\nmapping the source calculus to the semantic target calculus, all types\nare parameterized with an extra continuation argument.  We use a new\ntranslation function (\u00b7)* for this, which composes the mapping\nfrom syntactic to semantic types with the continuization.  A source\nlanguage type A is now associated with a so-called\ncomputation in the target language, i.e., a function acting\non its own continuation: A* = (A\u2032\n\u2192 t) \u2192 t.\nAt the level of proofs, given the above interpretation of\ntypes, the task is to find an LP proof for the sequent below,\nthe image of the \\ and / elimination rules\nfor A,\u2009A\\B \u22a2 B\nand B/A,\u2009A \u22a2 B.\nWhereas in the source calculus there is only one way of putting\ntogether an A\\B (or B/A) function\nwith its\nA argument, in the target calculus there is a choice as to\nthe evaluation order: do we want to first evaluate the\ntranslation image of the argument, then that of the function, or the\nother way around.  We write \u00b7v for the\nfirst option (call-by-value) and \u00b7n for the\nsecond (call-by-name).  In the target language, m\nand n are variables of type A\u2032\n\u2192 B\u2032 and A\u2032\nrespectively; k is the resulting B\u2032 \u2192\nt continuation.\n\nLP translation of Application:(A\u2032\n\u2192 t) \u2192 t,\u2009((A\u2032\n\u2192 B\u2032) \u2192 t) \u2192 t \u22a2\n(B\u2032 \u2192 t) \u2192 t\ncall-by-value solution:(M\n\u22b2 N)v = (N\n\u22b3 M)v =\n\u03bbk.(Nv\n\u03bbn.(Mv \u03bbm.(k (m\nn))))\ncall-by-name solution:(N\n\u22b3 M)n = (M\n\u22b2 N)n =\n\u03bbk.(Mn\n\u03bbm.(Nn\n \u03bbn.(k (m n))))\n\nThe continuation-passing-style interpretation, like the\ntype-shifting approach, makes it possible to assign syntactic\ntype np both to proper names and to quantificational noun\nphrases: in the target calculus, the translation of np has\nthe appropriate semantic type (e \u2192 t)\n\u2192 t.  But the lifting strategy is now generalized to all\nsource types: a transitive verb (np\\s)/np)\nis mapped to ((e \u2192 e \u2192 t)\n\u2192 t) \u2192 t, etc.  For the translation of\nlexical constants of type A, the default recipe is\n\u03bbk.(k c), c a non-logical\nconstant of type A\u2032.  The default translation simply\npasses the semantic value for these lexical items to the continuation\nparameter k. But quantificational noun phrases effectively\nexploit the continuation parameter: they take scope over\ntheir continuation, leading to lexical recipes\n\u03bbk.(\u2200\n\u03bbx.(k x)),\n\u03bbk.(\u2203\n\u03bbx.(k x)) for \u2018everyone\u2019\nand \u2018someone\u2019. The choice between the evaluation\nstrategies, in combination with these lexical recipes, then results in\ndifferent interpretations for a single derivation in the\nsource calculus M = (everyone\u22b3(loves\u22b2someone)),\nwith \u00b7v producing the surface scope\nconstrual, and \u00b7n the inverted scope\nreading.\n\n\n\nMv\n\u00a0=\u00a0\n\u03bbk.(\u2200 \u03bbx.(\u2203\n \u03bby.(k ((loves y) x)))\n\n\nMn\n\u00a0=\u00a0\n\u03bbk.(\u2203 \u03bby.(\u2200\n \u03bbx.(k ((loves y) x)))\n\n\n\nThe above example only uses the slash Elimination of NL in\nthe syntactic source calculus.  An important motivation for the\nintroduction of continuations is that they make it possible to give a\nconstructive interpretation to classical (as opposed to\nintuitionistic) logic; see S\u00f8rensen and Urzyczyn 2006 for\ndiscussion. It will be no surprise, then, that also the\nmultiple-conclusion symmetric categorial grammar LG has a\nnatural interpretation in the continuation-passing-style (Bernardi and\nMoortgat 2010, Moortgat 2009).  In the example we gave above, source\ntypes A are provided with a single continuation parameter. In\nthe CPS translation for LG types, the continuization of\nsyntactic source types is performed recursively.  Let us\nwrite V(A) for target language values of\ntype A, K(A) for continuations, i.e.,\nfunctions V(A) \u2192 R,\nand C(A) for computations, i.e.,\nfunctions K(A) \u2192 R, where R\nis the response type.  For an LG syntactic source\ntype A, the call-by-value CPS translation yields an LP\nvalue V(A) as follows.  V(p)\n= p for atomic types,\n\nimplications: V(A\\B)\n= V(B/A) = K(B)\n\u2192 K(A)\ncoimplications (dual to implications): V(A\n\u2298 B) = V(B \u29b8 A)\n= K(A\\B)\n\nAt the level of proofs (and the terms in Curry-Howard\ncorrespondence with them), the CPS translation turns the\nmultiple-conclusion source derivations into\nsingle-conclusion LP derivations. The translation respects the\ninvariant below. An active output formula A (marked off by\nthe vertical bar in the box below) maps to a computation\nC(A), an active input formula to a\ncontinuation K(A). A cut then is interpreted as the\napplication of C(A) to K(A).\n\n\n\nsource: LG/,\\,\u2298,\u29b8\n\u00a0\u2192CPS\u00a0\ntarget: LP\u2192\n\n\nX \u22a2 A | Y\n\nV(X),K(Y)\n \u22a2 C(A)\n\n\nX | A \u22a2 Y\n\nV(X),K(Y) \u22a2 K(A) \n\n\nX \u22a2 Y\n\nV(X),K(Y) \u22a2 R\n\n\n\nDiscussion.  Continuation-based approaches are now available\nfor a number of recalcitrant phenomena that would seem to defy a\ncompositional treatment.  Examples, at the sentential level, include\nthe treatment of in situ scope construal and wh questions of\nShan and Barker 2006, where crossover and superiority violations are\nexplained in terms of a preference of the human processor for a\nleft-to-right evaluation strategy; donkey anaphora (Barker and Shan\n2008)); quantifier scope ambiguities for the call-by-value and\ncall-by-name interpretation of LG are investigated in Bernardi and\nMoortgat 2010. At the discourse level, de Groote (2006) gives a\ntype-theoretic analysis of dynamic phenomena, modeling propositions as\nfunctions over a sentence's left and right context (continuation).\n4.  Proof nets and processing\nIn the previous sections, we have seen how the different categorial\ncalculi can be presented as proof systems with a sequent-based\ndecision procedure.  Naive proof search in these systems, however, is\ninefficient from a computational point of view: in general, there will\nbe multiple ways to construct alternative proofs that differ only in\nthe order of the application of the inference rules, but produce the\nsame interpretation (the LP term associated with a derivation\nunder the interpretation homomorphism). This issue of\n\u2018spurious\u2019 ambiguity can be tackled by the introduction of\nnormal form derivations (as in Hepple 1990, Hendriks 1993), compare\nfocused proof search regimes in linear logic), combined with the use\nof chart-based parsing methods, as in Hepple 1999, Capelletti 2007. An\nalternative for categorial \u2018parsing-as-deduction\u2019 is to\nleave the sequent calculus for what it is, and to switch to\na proof net approach.  Proof nets, originally developed in\nthe context of linear logic, use a representation of derivations that\nis inherently free of \u2018spurious ambiguity\u2019, i.e., the issue\nof irrelevant rule orderings simply doesn't arise. For a general\ntreatment of proof nets, we refer to the entry on \n linear Logic.\n Below we comment on aspects that are specifically addressing issues in\ncategorial grammar.\nProof nets for the Lambek calculi. Proof nets for the\nassociative calculus L and the commutative variant LP\nhave been studied initially by Roorda (1991, 1992). To capture the\n\u2018intuitionistic\u2019 nature of these systems, one works with\nformulas with polarities: input (\u2018given\u2019)\npolarity for antecedent occurrences of a formula, versus output\n(\u2018to prove\u2019) polarity for succedent\noccurrences. Correctness criteria identify proof nets among a wider\nclass of graphs: to the criteria of acyclicity and connectedness,\napplicable for linear logic in general, one adds planarity to\ncapture word order sensitivity: in the proof nets for L, axioms\nlinks cannot cross.  With respect to the syntax-semantics interface,\nde Groote and Retor\u00e9 (1996) show that the lambda terms in\nCurry-Howard correspondence with LP derivations in the semantic\ntarget calculus can be read off from a proof net by specifying a set\nof \u2018travel instructions\u2019 for traversing a net; these\ninstructions then correspond step-by-step with the construction of the\nassociated lambda term.\nIncremental processing. Proof nets, considered statically as\ngraphs satisfying certain correctness criteria, remove spurious\nchoices relating to the order of rule applications in sequent calculi:\nin this respect, they represent a purely \u2018declarative\u2019\nview on categorial deductions. Johnson (1998) and Morrill (2000) have\npointed out that an alternative, \u2018procedural\u2019 view on the\nactual process of constructing a net makes perfect sense as well, and\noffers an attractive perspective on performance phenomena. Under this\ninterpretation, a net is built in a left-to-right incremental fashion\nby establishing possible linkings between the input/output literals of\nthe partial proof nets associated with lexical items as they occur in\nreal time. This suggests a simple complexity measure on an incremental\ntraversal, given by the number of unresolved dependencies between\nliterals.  This complexity measure correlates nicely with a number of\nwell-attested processing issues, such as the difficulty of center\nembedding, garden path effects, attachment preferences, and\npreferred scope construals in ambiguous constructions.\nFirst-order quantifiers.  The planarity condition singles\nout the non-commutative proof nets for L among the LP\nnets. To deal with the more structured categorial calculi discussed\nhere, the correctness criteria have to be refined. One strategy of\ndoing this is via a translation into MILL1 (first-order multiplicative\nintuitionistic linear logic) where one has proof nets with extra links\nfor existential and universal quantification over first order\nvariables. One can then use these variables in a way very similar to\nthe use of position arguments in Definite Clause Grammars as used in\nlogic programming. Moot and Piazza (2001) work out such translations\nfor L and NL. For the concatenation operations\nof L, one replaces the proposition letters (atomic formulas) by\ntwo-place terms, marking beginning and end of a continuous string. For\nnon-associative NL, one adds an extra variable to keep track of\nthe nesting depth of subformulas. For wrapping operations in the\nsimple discontinuous calculus DL (allowing a single split\npoint), Morrill and Fadda (2008) use four-place predicates.  In\ngeneral, we find a correlation here between the syntactic expressivity\nof the calculi and the number of variables needed to encode their\nstructural resource management.\nNets and rewriting.  The multimodal and symmetric calculi of\n\u00a73.1 and \u00a73.3 pose a challenge to the proof net methods as\noriginally developed for linear logic.  In these systems we typically\nfind one-way structural rules, such as the extraction postulates for\novert displacement, or the Grishin distributivity laws in the case of\nLG: these one-way rules naturally suggest a notion of graph\nrewriting. A completely general proof net framework for the\nextended Lambek calculi, with a correctness criterion based on\nrewriting, has been developed in Moot and Puite 2002 and Moot\n2007.\nThe basic building block for the Moot-Puite nets is a generalized\nnotion of a link, accommodating connectives of any arity.  A link is\ndetermined by its type (tensor or cotensor), its premises (a sequence\nP1,\u2026,Pn, 0\n\u2264 n), its conclusions (a\nsequence C1,\u2026,Cm, 0\n\u2264 m), and its main formula (which can be empty, in the\ncase of a neutral link, or one of the Pi\nor Ci). A proof structure is a set of\nlinks over a finite set of formulas such that every formula is at most\nonce the premise of a link and at most once the conclusion.  Formulas\nwhich are not the conclusion of any link are the hypotheses\nof the proof structures, whereas the formulas which are not the\npremise of any link are the conclusions.  An axiom formula is\na formula which is not the main formula of any\nlink.  Abstract proof structures are obtained by erasing all\nformulas on the internal nodes. A proof net is a proof\nstructure for which the abstract proof structure converts to a tensor\ntree \u2014 a rooted tree in the case of the intuitionistic systems,\npossibly an unrooted tree in the case of symmetric LG.  Proofs\nnets, so defined, can then be show to be the graphs that correspond to\nvalid derivations.\nThe rewriting steps transforming a candidate abstract proof\nstructure into a proof net are of two kinds.  The logical\ncontractions correspond to identities A\n\u22a2 A, for complex formulas A; they reduce a\nconfiguration of a matching tensor and cotensor link to a point.\nThe structural conversions perform an internal rewiring of a\nproof structure with\nhypotheses H1,\u2026,Hn and\nconclusions C1,\u2026,Cm to\na structure with some permutation of the Hi as\nhypotheses and some permutation of the Ci as\nconclusions. Copying and deletion, in other words, are ruled out. As\nan example, the rewriting corresponding to one of the Grishin\ninteraction principles discussed in \u00a73.3, allowing us to\ninfer C \u29b8 A \u22a2 D/B\nfrom A \u2297 B \u22a2 C\n\u2295 D. Hypotheses A, B are on the left,\nconclusions C, D on the right.  The net\nrepresentation brings out in a particularly clear way that these\nprinciples are structure-preserving: they leave the order of\nhypotheses and conclusions untouched.\n\n\n\n5.   Recognizing capacity, complexity\nReflecting on the above, one can say that the extensions of the\nsyntactic calculus reviewed here are motivated by the desire to find a\nproper balance between expressivity and computational\ntractability: on the side of expressivity, an adequate\ntypelogical framework should be able to recognize patterns beyond the\nstrictly context-free; ideally, one would like to keep such\nexpressivity compatible with a polynomial derivability problem.  Among\ncontemporary \u2018lexicalized\u2019 grammar formalisms, there is a\nremarkable convergence on systems that meet these requirements: the\nso-called \u2018mildly context-sensitive\u2019 systems (Joshi,\nVijay-Shanker, and Weir 1991).  Where can we situate the typelogical\nsystems discussed here with respect to recognizing capacity and\ncomplexity?\nThe minimal system in the typelogical hierarchy NL has a\npolynomial recognition problem (see de Groote 1999, and Capelletti\n2007 for actual parsing algorithms), but it is strictly context-free\n(Kandulski 1988).  Extensions with global structural rules are\nunsatisfactory, both on the expressivity and on the complexity front.\nAs for L, Pentus (1993b, 2006) shows that it remains strictly\ncontext-free, whereas the addition of global associativity makes the\nderivability problem NP complete.  NP completeness already holds for\nthe product-free fragment of L (Savateev 2009).  Also\nfor LP, i.e., multiplicative intuitionistic linear logic, we\nhave NP completeness (Kanovich 1994).  With regard to recognizing\ncapacity, van Benthem (1995) shows that LP recognizes all\npermutation closures of context-free languages: a class which is too\nwide from the syntactic point of view.  As the logic of\nmeaning assembly, LP is a core component of the\ntypelogical inventory.  But as we saw in the discussion of the\nsyntax-semantics interface, we can restrict attention to the\nsublanguage of LP that forms the image of derivations in\nsyntactic calculi making interesting claims about word order and\nphrase structure.\nThe situation of the multimodal and symmetric extensions is more\nintricate. Expressivity here is directly related to the kind of\nrestrictions one imposes on structural resource management. At one end\nof the spectrum, multimodality without structural rules does not lead\nus beyond context-free recognition: J\u00e4ger (2003) shows that the\npure residuation logic for n-ary families of type-forming\noperations stays strictly context-free. If one requires structural\nrules to be resource-sensitive (no copying or deletion) and,\nfor the unary modalities, non-expanding, one obtains the full\nexpressivity of context-sensitive grammars, and the PSPACE complexity\nthat goes with it (Moot 2002). (PSPACE consists of those problems \nsolvable using some polynomial amount of memory space.  See the entry on \n computability and complexity.\n If one imposes no restrictions on structural rules (specifically, if\none allows copying and deletion operations), unsurprisingly, one\nobtains the expressivity of unrestricted rewriting systems (Carpenter\n1999). A controlled use of copying is used in the analysis of\nanaphora resolution in J\u00e4ger 2005.\nThe symmetric calculus LG without interaction\nprinciples is context-free, as shown in Bastenhof 2010.  For the\nsystem with the interaction principles of \u00a73.3, Melissen\n(2009) shows that all languages which are the intersection of a\ncontext- free language and the permutation closure of a context-free\nlanguage are recognizable in LG. In this class, we find\ngeneralized forms of MIX (the language consisting of an equal number\nof symbols a, b, c, in any order), with\nequal multiplicity of k alphabet symbols in any order, and\ncounting dependencies\n an1\u2026ank\nfor any number k of alphabet symbols.  Patterns of this type\nare recognized by Range Concatenation Grammars and Global Index\nGrammars; a comparison with these formalisms then might be useful to\nfix the upper bound of the recognizing capacity of LG, which is as yet\nunknown.\nWith respect to computational complexity, Moot (2008) establishes a\ncorrespondence between Lexicalized Tree Adjoining Grammars on the one\nhand, and categorial grammars with the multimodal extraction\npostulates of \u00a73.1 and a restricted set of LG grammars on\nthe other. For these grammars he obtains a polynomial parsability\nresult via a translation into Hyperedge Replacement Grammars.  In the\ncase of LG, the restriction requires the coimplications\n\u2298,\u29b8 to occur in matching pairs in lexical type\nassignments.  The lexicon of the generalized MIX construction of\nMelissen 2009, and the type assignment used for quantifier phrases in\nthe analysis of scope construal in Bernardi and Moortgat 2010, do not\nrespect this restriction. For the general case of LG with the\ninteraction principles of \u00a73.3, Bransen (2010) establishes\nNP-completeness.  The position of the discontinuous calculi of\n\u00a73.2 in this hierarchy has to be determined: they\nrecognize more than the context-free languages, but it is not clear\nwhether they stay within the mildly context-sensitive family.\n6.   Related approaches\nTypelogical grammars as discussed here share a number of\ncharacteristics with a number of related formal grammar frameworks\nwhere types also play a key role.  We briefly discuss some of these\nrelatives, and provide pointers to the literature for readers who want\nto explore the connections further.\nCombinatory Categorial Grammar (CCG).  The CCG framework\n(see Steedman 2000 for a comprehensive presentation) takes its name\nfrom the Combinatory Logic of Curry and Feys.  Whereas the design of\ntypelogical grammars follows a logical agenda (sequent calculus,\nsoundness, completeness, etc), grammars in the CCG tradition are\npresented as finite sets of rules for type change and type\ncombination.  This rule inventory will typically include function\napplication schemata, type lifting, and functional composition, both\nof the kind valid within associative L (composing implicational\ntypes with the same directionality), and of the mixed kind (composing\nfunctors with different directionality).\nThe development of CCG and Lambek style typelogical grammars in the\n1980s initially followed separate courses. More recently, there are\nsigns of convergence. An important factor has been the introduction of\nthe typelogical technique of multimodal control to fine-tune the\napplicability of the CCG combinatory schemata (Baldridge 2002, Kruijff\nand Baldridge 2003).  Multimodal typelogical grammar, from this\nperspective, plays the role of the underlying general logic which one\nuses to establish the validity of the CCG combinatory schemata,\nwhereas the particular choice of primitive combinators is motivated by\ncomputational efficiency considerations (Hoyt and Baldridge 2008). In\nterms of generative capacity, CCG is a member of the mildly context\nsensitive family of grammar formalisms. Polynomial parsability is\nobtained by imposing a bound on the functional composition\nschemata.\nPregroup grammars.  Pregroups are an algebraic version of\ncompact bilinear logic (Lambek 1993) obtained by collapsing\nthe tensor and cotensor operations.  Pregroup grammars were introduced\nin Lambek 1999 as a simplification of the original Syntactic\nCalculus L. They have since been used to build computational\nfragments for a great variety of languages by Lambek and co-workers.\nA pregroup is a partially ordered monoid in which each\nelement a has a left and a right adjoint, al,\nar, satisfying ala \u2192 1\n\u2192 aal and aar \u2192 1\n\u2192 ara, respectively.  Type assignment takes\nthe form of associating a word with one or more elements from the free\npregroup generated by a partially ordered set of basic types.  For the\nconnection with categorial type formulas, one can use the translations\na/b = abl\nand b\\a = bra. Parsing, in the\npregroup setting, is extremely straightforward. Lambek (1999) proves\nthat one only has to perform the contractions\nreplacing ala and ala by the\nmultiplicative unit 1.  This is essentially a check for\nwell-bracketing \u2014 an operation that can be entrusted to a\npushdown automaton. The expansions 1 \u2192 aal\nand 1 \u2192 ara are needed to prove equations\nlike (ab)l\n= blal.  We have used the latter to\nobtain the pregroup version of the higher-order relative pronoun type\n(n\\n)/(s/np) in the example\nbelow.\n\n\n\nbook\nthat\nCarroll\nwrote\n\n\n\ntype assignment in L\u00a0:\nn\n(n\\n)/(s/np)\nnp\n(np\\s)/np\n\n\n\npregroup type assignment\u00a0:\nn\nnr\u2009n\u2009npll\u2009sl\nnp\nnpr\u2009s\u2009npl\n\u2192 n\n\n\nCompact bilinear logic is not a conservative extension of the\noriginal Syntactic Calculus.  Every sequent derivable in L has\na translation derivable in the corresponding pregroup, but the\nconverse is not true: the pregroup image of the types (a\n\u2297 b)/c and a \u2297\n(b/c), for example,\nis a\u2009b\u2009cl, but these two types are\nnot interderivable in L.\nWith respect to generative capacity, Buszkowski (2001) shows that\nthe pregroup grammars are equivalent to context-free grammars. They\nshare, in other words, the expressive limitations of the original\ncategorial grammars. To overcome these limitations different\nstrategies have been pursued, including lexical rules (metarules),\nderivational constraints, controlled forms of commutativity, and\nproducts of pregroups. The Studia Logica special issue\n(Buszkowski and Preller 2007) and the monograph Lambek 2008 give a\ngood picture of current research.\nAbstract Categorial Grammar.  The ACG framework (de Groote\n2001a) is a meta-theory of compositional grammar architectures. ACGs\nare built on higher-order linear signatures \u03a3 =\n(A,C,\u03c4), where A and C are\nfinite sets of atomic types and constants respectively, and \u03c4 a\nfunction assigning each constant a linear implicative type over\nA. Given a source signature \u03a3 and a target signature\n\u03a3\u2032, an interpretation is a mapping form \u03a3 to\n\u03a3\u2032 given by a pair of functions: \u03b7 mapping the type\natoms of \u03a3 to linear implicative types of \u03a3\u2032 and\n\u03b8 mapping the constants of \u03a3 to well-typed linear lambda\nterms of \u03a3\u2032 in a way that is compatible with the mapping\non types. Using the terminology of compiler theory, one refers to the\nsource and target signatures as the abstract vocabulary and the\nconcrete vocabulary, respectively, and to the interpretive\nmapping as the lexicon. An ACG is then obtained by specifying\nan atomic type of \u03a3 as the distinguished type of the\ngrammar.\nIn the ACG setting, one can model the syntax-semantics interface in\nterms of the abstract versus object vocabulary distinction. But one\ncan also obtain surface form as the result of an interpretive\nmapping, using the canonical \u03bb term encodings of strings and\ntrees and operations on them. ACG has given rise to an interesting\ncomplexity hierarchy for rewriting grammar formalisms encoded as ACGs:\ncontext-free grammars, tree-adjoining grammars, etc.; see for example\nde Groote and Pogodalla 2004.  Expressive power of these formalisms is\nmeasured in terms of the maximal order of the constants in the\nabstract vocabulary and of the object types interpreting the atomic\nabstract types. The study of ACG encodings of typelogical systems\nproper has started with Retor\u00e9 and Salvati 2010; these authors\npresent an ACG construction for (product-free) NL.\nIt will be clear from this description that the ACG architecture is\nclosely related to the compositional interpretation for categorial\ntype logics as discussed in this artile. A key difference is the\nnature of the \u2018abstract syntax\u2019, i.e. the source calculus\nfrom which interpretations are homomorphically derived. In the case of\nthe standard Lambek systems and the extended systems discussed in\n\u00a73 above, the abstract syntax is a directional type\nlogic; in the case of ACG, one finds LP and the linear lambda\ncalculus both at the source and at the target end.  The debate as to\nwhether structural properties of language have to be accounted for at\nthe level of the abstract syntax has a long history, starting with\nCurry 1961; see Muskens 2007 for discussion.  The typelogical view\naccounts for word order universals at the level of its logical\nconstants, i.e., the type-forming operations, and the laws that\ngovern them.  The ACG view is more liberal in this respect: the\nderivation of surface form can be specified on a word-by-word\nbasis. Whether this more relaxed connection between abstract syntax\nand surface realisation is desirable, is a matter of debate. An\nattractive feature of ACG that has not been investigated\nsystematically within the typelogical setting is the connection\nbetween expressivity and order restrictions on the source constants\nand on the interpretive mapping.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "For general logical and mathematical background, see Galatos\net\u00a0al.\u00a02007, Restall\u00a02000, S\u00f8rensen and\nUrzyczyn\u00a02006.",
                "For monographs, collections and survey articles on typelogical\ngrammar, see Buszkowski\u00a01997, Buszkowski et\u00a0al.\u00a01988,\nCarpenter\u00a01998, J\u00e4ger\u00a02005, Moortgat\u00a01988, 1997,\nMorrill\u00a01994, 2010, Oehrle et\u00a0al.\u00a01988, van\nBenthem\u00a01995.",
                "Baldridge, J. (2002).\n<em>Lexically Specified Derivational Control in Combinatory Categorial\nGrammar</em>.  Ph. D. thesis, University of Edinburgh.",
                "Barker, C. (2004).  Continuations in natural language.  In\nH. Thielecke (Ed.), <em>CW'04: Proceedings of the 4th ACM SIGPLAN\ncontinuations workshop</em>, Tech. Rep. CSR-04-1, School of Computer\nScience, University of Birmingham, pp. 1\u201311.",
                "\u2013\u2013\u2013. (2002).  Continuations and the nature of\nquantification. <em>Natural language semantics</em>, 10: 211\u2013242.",
                "Barker, C. and C. Shan (2006).  Types as graphs: Continuations in\ntype logical grammar. <em>Journal of Logic, Language and Information</em>, 15(4):\n331\u2013370.",
                "\u2013\u2013\u2013. (2008).  Donkey anaphora is in-scope\nbinding. <em>Semantics and Pragmatics</em>, 1(1): 1\u201346.",
                "Barry, G., M. Hepple, N. Leslie, and G. Morrill (1991).  Proof\nfigures and structural operators for categorial grammar.\nIn <em>Proceedings of the 5th conference on European chapter of the\nAssociation for Computational Linguistics</em>, \nAssociation for Computational Linguistics, pp. 198\u2013203.",
                "Bastenhof, A. (2010). Tableaux for the Lambek-Grishin calculus. CoRR abs/1009.3238.\nTo appear in <em>Proceedings ESSLLI 2010 Student\nSession</em>. Copenhagen.",
                "Bernardi, R. and M. Moortgat (2010).  Continuation semantics for\nthe Lambek-Grishin calculus.\n<em>Information and Computation</em>, 208(5): 394\u2013416.",
                "Bernardi, R. and A. Szabolcsi (2008).  Optionality, Scope, and\nLicensing: An Application of Partially Ordered Categories.\n<em>Journal of Logic, Language and Information</em>, 17(3):\n237\u2013283.",
                "Bransen, J. (2010). The Lambek-Grishin calculus is NP-complete. To\nappear in <em>Proceedings 15th Conference on Formal Grammar</em>,\nCopenhagen. CoRR abs/1005.4697.",
                "Buszkowski, W. (2001).  Lambek grammars based on pregroups.  In\nP. de Groote, G. Morrill, and C. Retor\u00e9 (Eds.), <em>Logical\nAspects of Computational Linguistics</em>, <em>Lecture Notes in\nArtificial Intelligence</em> (Volume 2099), Berlin: Springer, pp.\n95\u2013109.",
                "\u2013\u2013\u2013. (1997).  Mathematical linguistics and proof\ntheory.  In J. van Benthem and A. ter Meulen (Eds.), <em>Handbook of\nLogic and Language</em> (Chapter 12), Amsterdam: Elsevier, and\nCambridge, MA: MIT Press, pp. 683\u2013736.",
                "Buszkowski, W. and G. Penn (1990).  Categorial grammars determined\nfrom linguistic data by unification.\n<em>Studia Logica</em>, 49(4): 431\u2013454.",
                "Buszkowski, W. and A. Preller (2007).  Editorial introduction\nspecial issue on pregroup grammars.\n<em>Studia Logica</em>, 87(2): 139\u2013144.",
                "Buszkowski, W., W. Marciszewski, and J. van Benthem (Eds.) (1988).\n<em>Categorial Grammar</em>.  Amsterdam: John Benjamins.",
                "Capelletti, M. (2007).\n<em>Parsing with structure-preserving categorial grammars</em>.\nPh. D. thesis, Utrecht Institute of Linguistics OTS, Utrecht\nUniversity.",
                "Carpenter, B. (1999).  The Turing-completeness of multimodal\ncategorial grammars.  In J. Gerbrandy, M. Marx, M. de Rijke, and\nY. Venema (Eds.), <em>JFAK. Essays Dedicated to Johan van Benthem on\nthe Occasion of his 50th Birthday</em>. Amsterdam: Amsterdam\nUniversity Press.",
                "\u2013\u2013\u2013. (1998).\n<em>Type-logical Semantics</em>.  Cambridge, MA: MIT Press.",
                "Curry, H. B. (1961).  Some logical aspects of grammatical\nstructure.  In R. Jacobson (Ed.), <em>Structure of Language and its\nMathematical Aspects</em>,  <em>Proceedings of the\nSymposia in Applied Mathematics</em> (Volume XII),  American\nMathematical Society, pp.  56\u201368.",
                "de Groote, P. (2006).  Towards a Montagovian account of dynamics.\nIn <em>Proceedings SALT 16</em>. CLC Publications.",
                "\u2013\u2013\u2013. (2001a).  Towards abstract categorial\ngrammars.  In <em>Proceedings of 39th Annual Meeting of the\nAssociation for Computational Linguistics</em>, Association\nfor Computational Linguistics, pp.  252\u2013259.",
                "\u2013\u2013\u2013. (2001b).  Type raising, continuations, and classical\nlogic.  In M. S. R. van Rooy (Ed.), <em>Proceedings of the Thirteenth\nAmsterdam Colloquium</em>, Amsterdam: ILLC (Universiteit van\nAmsterdam), pp.  97\u2013101.",
                "\u2013\u2013\u2013. (1999).  The non-associative Lambek\ncalculus with product in polynomial time.  In N. V. Murray\n(Ed.), <em>Automated Reasoning With Analytic Tableaux and Related\nMethods</em>, <em>Lecture Notes in Artificial Intelligence</em>\n(Volume 1617), Berlin: Springer, pp.  128\u2013139.",
                "de Groote, P. and F. Lamarche (2002).  Classical non-associative\nLambek calculus.\n<em>Studia Logica</em>, 71(3): 355\u2013388.",
                "de Groote, P. and S. Pogodalla (2004).  On the Expressive Power of\nAbstract Categorial Grammars: Representing Context-Free Formalisms.\n<em>Journal of Logic, Language and Information</em>, 13(4):\n421\u2013438.",
                "de Groote, P. and C. Retor\u00e9 (1996).  On the semantic\nreadings of proof nets.  In G.-J. Kruijff, G. Morrill, and D. Oehrle\n(Eds.), <em>Proceedings 2nd Formal Grammar Conference</em>, Prague,\npp.  57\u201370.",
                "Do\u0161en, K. (1992).  A brief survey of frames for the Lambek\ncalculus. <em>Mathematical Logic Quarterly</em>, 38(1): 179\u2013187.",
                "Galatos, N., P. Jipsen, T. Kowalski, and H. Ono (2007).\n<em>Residuated Lattices: An Algebraic Glimpse at Substructural Logics,\nStudies in Logic and the Foundations of Mathematics (Volume 151)</em>,\nAmsterdam: Elsevier.",
                "Girard, J.-Y. (1987).  Linear logic.\n<em>Theoretical Computer Science</em>, 50: 1\u2013102.",
                "Grishin, V. (1983).  On a generalization of the Ajdukiewicz-Lambek\nsystem.  In A. Mikhailov (Ed.), <em>Studies in Nonclassical Logics and\nFormal Systems</em>, Moscow: Nauka, pp.  315\u2013334.  [English\ntranslation in Abrusci and Casadio (eds.) New Perspectives in Logic\nand Formal Linguistics. Bulzoni, Rome, 2002].",
                "Hendriks, H. (1993).\n<em>Studied Flexibility. Categories and Types in Syntax and\nSemantics</em>.  Ph. D. thesis, ILLC, University of Amsterdam.",
                "Hepple, M. (1999).  An Earley-style predictive chart parsing\nmethod for Lambek grammars.  In <em>Proceedings of the 37th Annual\nMeeting of the Association for Computational Linguistics</em>,\nAssociation for Computational Linguistics, pp.  465\u2013472.",
                "\u2013\u2013\u2013. (1990).  Normal form theorem proving for the Lambek\ncalculus.  In <em>Papers presented to the 13th International\nConference on Computational Linguistics</em>, Helsinki, pp.\n173\u2013178.",
                "Hoyt, F. and J. Baldridge (2008).  A logical basis for the D\ncombinator and normal form in CCG.  In <em>Proceedings of ACL-08:\nHLT</em>, Association for Computational Linguistics, pp.\n326\u2013334.",
                "J\u00e4ger, G. (2005).\n<em>Anaphora And Type Logical Grammar</em>.  Berlin: Springer.",
                "\u2013\u2013\u2013. (2004). Residuation, Structural Rules and Context Freeness.\n<em>Journal of Logic, Language and Information</em>, 13: 47\u201359.",
                "Johnson, M. (1998).  Proof nets and the complexity of processing\ncenter-embedded constructions.\n<em>Journal of Logic, Language and Information</em>, 7(4):\n433\u2013447.",
                "Joshi, A. K., K. Vijay-Shanker, and D. Weir (1991).  The\nconvergence of mildly context-sensitive grammar formalisms.  In\nP. Sells, S. M. Shieber, and T. Wasow (Eds.), <em>Foundational Issues\nin Natural Language Processing</em>, Cambridge, MA:\nMIT Press,  pp.  31\u201381.",
                "Kanazawa, M. (1998).\n<em>Learnable classes of categorial grammars</em>.  Stanford: CSLI\nPublications.",
                "Kandulski, M. (1988).  The equivalence of nonassociative Lambek\ncategorial grammars and context-free grammars.\n<em>Zeitschrift f\u00fcr mathematische Logik und Grundlagen der\nMathematik</em>, 34: 41\u201352.",
                "Kanovich, M. (1994).  The Complexity of Horn Fragments of Linear\nLogic. <em>Annals of Pure and Applied Logic</em>, 69(2-3): 195\u2013241.",
                "Kruijff, G.-J. and J. Baldridge (2003).  Multi-modal combinatory\ncategorial grammar.  In <em>Proceedings of the 10th Conference of the\nEuropean Chapter of the Association for Computational\nLinguistics</em>, Association for Computational Linguistics, pp.\n211\u2013218.",
                "Kurtonina, N. (1995).\n<em>Frames and Labels. A Modal Analysis of Categorial Inference</em>.\nPh. D. thesis, OTS Utrecht, ILLC Amsterdam.",
                "Kurtonina, N. and M. Moortgat (2010).  Relational semantics for\nthe Lambek-Grishin calculus.  In C. Ebert, G. J\u00e4ger, and\nJ. Michaelis (Eds.), <em>The Mathematics of Language. Proceedings of\nthe 10th and 11th Biennial Conference</em>, Lecture Notes in Computer\nScience (Volume 6149). Berlin: Springer, pp. 210\u2013222.",
                "\u2013\u2013\u2013 (1997).  Structural control.  In\nP. Blackburn and M. de Rijke (Eds.), <em>Specifying Syntactic\nStructures</em>,  Stanford: CSLI Publications, pp.  75\u2013113.",
                "Lambek, J. (2008).\n<em>From word to sentence. A computational algebraic approach to\ngrammar</em>.  Polimetrica.",
                "\u2013\u2013\u2013. (1999).  Type grammar revisited.  In\nA. Lecomte, F. Lamarche, and G. Perrier (Eds.), <em>Logical Aspects of\nComputational Linguistics</em>, <em>Lecture Notes in Artificial\nIntelligence</em> (Volume 1582), Berlin: Springer, pp.\n1\u201327.",
                "\u2013\u2013\u2013. (1993).  From categorial to bilinear logic.  In\nK. Do\u0161en and P. Schr\u00f6der-Heister (Ed.), <em>Substructural Logics</em>.\nOxford University Press.",
                "\u2013\u2013\u2013. (1961).  On the calculus of syntactic\ntypes.  In R. Jacobson (Ed.), <em>Structure of Language and its\nMathematical Aspects</em>, <em>Proceedings of the Symposia in Applied\nMathematics</em> (Volume XII), American Mathematical Society, pp.\n166\u2013178.",
                "\u2013\u2013\u2013. (1958).  The mathematics of sentence structure.\n<em>American Mathematical Monthly</em>, 65: 154\u2013170.",
                "Melissen, M. (2009).  The generative capacity of the\nLambek-Grishin calculus: A new lower bound.  In P. de Groote\n(Ed.), <em>Proceedings 14th Conference on Formal Grammar</em>, \nLecture Notes in Computer Science (Volume 5591), Berlin: Springer.",
                "Moortgat, M. (2009).  Symmetric categorial grammar.\n<em>Journal of Philosophical Logic</em>, 8(6),\n681\u2013710.",
                "\u2013\u2013\u2013. (1997).  Categorial type logics.  In J. van Benthem\nand A. ter Meulen (Eds.), <em>Handbook of Logic and Language</em>\n(Chapter 2),  Amsterdam: Elsevier, pp. 93\u2013177.  (Second edition, revised and\nupdated: Elsevier Insights Series, 2010).",
                "\u2013\u2013\u2013. (1996).  Multimodal linguistic inference.\n<em>Journal of Logic, Language and Information</em>, 5(3\u20134):\n349\u2013385.",
                "\u2013\u2013\u2013. (1988).\n<em>Categorial Investigations. Logical and Linguistic Aspects of the\nLambek calculus</em>.  Berlin: De Gruyter.",
                "Moot, R. (2008).  Lambek grammars, tree adjoining grammars and\nhyperedge replacement grammars.  In <em>Proceedings of TAG+9, The 9th\nInternational Workshop on Tree Adjoining Grammars and Related\nFormalisms</em>, T\u00fcbingen, pp.  65\u201372.",
                "\u2013\u2013\u2013. (2007).  Proof nets for display logic.\n<em>CoRR</em>, abs/0711.2444.",
                "\u2013\u2013\u2013. (2002).\n<em>Proof Nets for Linguistic Analysis</em>.  Ph. D. thesis, Utrecht\nInstitute of Linguistics OTS, Utrecht University.",
                "Moot, R. and M. Piazza (2001).  Linguistic Applications of First\nOrder Intuitionistic Linear Logic. <em>Journal of Logic, Language and\nInformation</em>, 10(2): 211\u2013232.",
                "Moot, R. and Q. Puite (2002).  Proof Nets for the Multimodal\nLambek Calculus.\n<em>Studia Logica</em>, 71(3): 415\u2013442.",
                "Morrill, G. (2010).\n<em>Categorial Grammar: Logical Syntax, Semantics, and\nProcessing</em>.  Oxford: Oxford University Press.",
                "\u2013\u2013\u2013. (2000).  Incremental processing and acceptability.\n<em>Computational linguistics</em>, 26(3): 319\u2013338.",
                "\u2013\u2013\u2013. (1994).\n<em>Type Logical Grammar: Categorial Logic of Signs</em>.  Dordrecht:\nKluwer Academic Publishers.",
                "\u2013\u2013\u2013. (1990).  Intensionality and boundedness.\n<em>Linguistics and Philosophy</em>, 13(6): 699\u2013726.",
                "Morrill, G. and M. Fadda (2008).  Proof nets for basic\ndiscontinuous Lambek calculus.\n<em>Journal of Logic and Computation</em>, 18(2): 239\u2013256.",
                "Morrill, G., M. Fadda, and O. Valentin (2007).  Nondeterministic\ndiscontinuous Lambek calculus.  In <em>Proceedings of the Seventh\nInternational Workshop on Computational Semantics (IWCS7)</em>,\nTilburg.",
                "Morrill, G., O. Valentin, and M. Fadda (2009).  Dutch grammar and\nprocessing: A case study in TLG.  In P. Bosch, D. Gabelaia, and\nJ. Lang (eds.), <em>Logic, Language, and Computation: 7th\nInternational Tbilisi Symposium on Logic, Language, and\nComputation</em>, Tbilisi, Georgia, October 1-5, 2007 (Revised\nSelected Papers), Lecture Notes in Artificial Intelligence (Volume\n5422), Berlin: Springer, pp.  272\u2013286.",
                "Muskens, R. (2007).  Separating syntax and combinatorics in\ncategorial grammar. <em>Research on Language &amp;\nComputation</em>, 5(3): 267\u2013285.",
                "Oehrle, R. T., E. Bach, and D. Wheeler (Eds.) (1988).\n<em>Categorial Grammars and Natural Language Structures</em>, Studies\nin Linguistics and Philosophy (Number 32). Dordrecht: Reidel.",
                "Pentus, M. (1993b).  Lambek grammars are context free.\nIn <em>Proceedings of the 8th Annual IEEE</em> Symposium on Logic in\nComputer Science},  IEEE Computer Society Press, pp.  429\u2013433.",
                "\u2013\u2013\u2013. (2006).  Lambek calculus is NP-complete.\n<em>Theoretical Computer Science</em>, 357: 186\u2013201.",
                "\u2013\u2013\u2013. (1995).  Models for the Lambek calculus.\n<em>Annals of Pure and Applied Logic</em>, 75(1\u20132),\n179\u2013213.",
                "Restall, G. (2000). <em>An Introduction to Substructural\nLogics</em>.  London: Routledge.",
                "Retor\u00e9, C. and S. Salvati (2010).  A faithful\nrepresentation of non-associative Lambek grammars in Abstract\nCategorial Grammars.\n<em>Journal of Logic, Language and Information</em>, 19(2).  Special\nissue on New Directions in Type Theoretic Grammars.",
                "Roorda, D. (1992).  Proof Nets for Lambek calculus.\n<em>Journal of Logic and Computation</em>, 2(2): 211\u2013231.",
                "Savateev, Y. (2009).  Product-free Lambek Calculus is NP-complete.\nIn S. Artemov and A. Nerode (Eds.), <em>Proceedings of the 2009\nInternational Symposium on Logical Foundations of Computer\nScience</em>, Lecture Notes in Computer Science (Volume 5407), Berlin: Springer, pp.\n380\u2013394.",
                "Shan, C. and C. Barker (2006).  Explaining Crossover and\nSuperiority as Left-to-right Evaluation.\n<em>Linguistics and Philosophy</em>, 29(1): 91\u2013134.",
                "S\u00f8rensen, M. H. and P. Urzyczyn (2006).\n<em>Lectures on the Curry-Howard Isomorphism</em>,\n<em>Studies in Logic and the Foundations of Mathematics</em> (Volume\n149),  Amsterdam: Elsevier.",
                "Stabler, E. (1999).  Remnant movement and complexity.  In\nG. Bouma, E. Hinrichs, G.-J. Kruijff, and R. T. Oehrle (Eds.),\n<em>Constraints and Resources in Natural Language Syntax and\nSemantics</em>, Stanford: CSLI, pp.  299\u2013326.",
                "\u2013\u2013\u2013. (1997).  Derivational minimalism.  In\nC. Retor\u00e9 (Ed.), <em>Logical Aspects of Computational\nLinguistics</em>, <em>Lecture Notes in Artificial Intelligence</em>\n(Volume 1328), Berlin: Springer, pp.  68\u201395.",
                "Steedman, M. (2000).\n<em>The Syntactic Process</em>.  Cambridge, MA: MIT Press.",
                "van Benthem, J. (1995).\n<em>Language in Action: Categories, Lambdas and Dynamic Logic</em>.\nCambridge, MA: MIT Press.",
                "\u2013\u2013\u2013. (1983).  The semantics of variety in categorial\ngrammar.  Technical Report 83-29, Simon Fraser University.  Revised\nversion in W. Buszkowski <em>et al</em>. (1988).",
                "Vermaat, W. (2006).\n<em>The logic of variation. A cross-linguistic account of wh-question\nformation</em>.  Ph. D. thesis, Utrecht Institute of Linguistics OTS,\nUtrecht University.",
                "\u2013\u2013\u2013. (2004).  The minimalist move operation in a deductive\nperspective.\n<em>Research on Language &amp; Computation</em>, 2(1), 69\u201385.",
                "Wansing, H. (2002).  Sequent systems for modal logics.  In\nD. Gabbay and F. Guenthner (Eds.), <em>Handbook of Philosophical\nLogic</em> (Volume 8), Dordrecht: Kluwer Academic Publishers, pp.\n61\u2013145.",
                "\u2013\u2013\u2013. (1992).  Formulas-as-types for a hierarchy\nof sublogics of intuitionistic propositional logic.  In D. Pearce and\nH. Wansing (Eds.), <em>Nonclassical Logics and Information\nProcessing</em>, Lecture Notes in Computer Science (Volume 619),\nBerlin: Springer, pp.  125\u2013145."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2><a name=\"Bib\">Bibliography</a></h2>\n<p>\nNote: In addition to the regular text references, the bibliography\ncontains some items that can place the entry in a broader\ncontext.</p>\n<ul>\n<li>For general logical and mathematical background, see Galatos\net\u00a0al.\u00a02007, Restall\u00a02000, S\u00f8rensen and\nUrzyczyn\u00a02006.</li>\n<li>For monographs, collections and survey articles on typelogical\ngrammar, see Buszkowski\u00a01997, Buszkowski et\u00a0al.\u00a01988,\nCarpenter\u00a01998, J\u00e4ger\u00a02005, Moortgat\u00a01988, 1997,\nMorrill\u00a01994, 2010, Oehrle et\u00a0al.\u00a01988, van\nBenthem\u00a01995.</li>\n</ul>\n<ul class=\"hanging\">\n<li>Baldridge, J. (2002).\n<em>Lexically Specified Derivational Control in Combinatory Categorial\nGrammar</em>.  Ph. D. thesis, University of Edinburgh.</li>\n<li>Barker, C. (2004).  Continuations in natural language.  In\nH. Thielecke (Ed.), <em>CW'04: Proceedings of the 4th ACM SIGPLAN\ncontinuations workshop</em>, Tech. Rep. CSR-04-1, School of Computer\nScience, University of Birmingham, pp. 1\u201311.</li>\n<li>\u2013\u2013\u2013. (2002).  Continuations and the nature of\nquantification. <em>Natural language semantics</em>, 10: 211\u2013242.</li>\n<li>Barker, C. and C. Shan (2006).  Types as graphs: Continuations in\ntype logical grammar. <em>Journal of Logic, Language and Information</em>, 15(4):\n331\u2013370.</li>\n<li>\u2013\u2013\u2013. (2008).  Donkey anaphora is in-scope\nbinding. <em>Semantics and Pragmatics</em>, 1(1): 1\u201346.</li>\n<li>Barry, G., M. Hepple, N. Leslie, and G. Morrill (1991).  Proof\nfigures and structural operators for categorial grammar.\nIn <em>Proceedings of the 5th conference on European chapter of the\nAssociation for Computational Linguistics</em>, \nAssociation for Computational Linguistics, pp. 198\u2013203.</li>\n<li>Bastenhof, A. (2010). Tableaux for the Lambek-Grishin calculus. CoRR abs/1009.3238.\nTo appear in <em>Proceedings ESSLLI 2010 Student\nSession</em>. Copenhagen.</li>\n<li>Bernardi, R. and M. Moortgat (2010).  Continuation semantics for\nthe Lambek-Grishin calculus.\n<em>Information and Computation</em>, 208(5): 394\u2013416.</li>\n<li>Bernardi, R. and A. Szabolcsi (2008).  Optionality, Scope, and\nLicensing: An Application of Partially Ordered Categories.\n<em>Journal of Logic, Language and Information</em>, 17(3):\n237\u2013283.</li>\n<li>Bransen, J. (2010). The Lambek-Grishin calculus is NP-complete. To\nappear in <em>Proceedings 15th Conference on Formal Grammar</em>,\nCopenhagen. CoRR abs/1005.4697.</li>\n<li>Buszkowski, W. (2001).  Lambek grammars based on pregroups.  In\nP. de Groote, G. Morrill, and C. Retor\u00e9 (Eds.), <em>Logical\nAspects of Computational Linguistics</em>, <em>Lecture Notes in\nArtificial Intelligence</em> (Volume 2099), Berlin: Springer, pp.\n95\u2013109.</li>\n<li>\u2013\u2013\u2013. (1997).  Mathematical linguistics and proof\ntheory.  In J. van Benthem and A. ter Meulen (Eds.), <em>Handbook of\nLogic and Language</em> (Chapter 12), Amsterdam: Elsevier, and\nCambridge, MA: MIT Press, pp. 683\u2013736.</li>\n<li>Buszkowski, W. and G. Penn (1990).  Categorial grammars determined\nfrom linguistic data by unification.\n<em>Studia Logica</em>, 49(4): 431\u2013454.</li>\n<li>Buszkowski, W. and A. Preller (2007).  Editorial introduction\nspecial issue on pregroup grammars.\n<em>Studia Logica</em>, 87(2): 139\u2013144.</li>\n<li>Buszkowski, W., W. Marciszewski, and J. van Benthem (Eds.) (1988).\n<em>Categorial Grammar</em>.  Amsterdam: John Benjamins.</li>\n<li>Capelletti, M. (2007).\n<em>Parsing with structure-preserving categorial grammars</em>.\nPh. D. thesis, Utrecht Institute of Linguistics OTS, Utrecht\nUniversity.</li>\n<li>Carpenter, B. (1999).  The Turing-completeness of multimodal\ncategorial grammars.  In J. Gerbrandy, M. Marx, M. de Rijke, and\nY. Venema (Eds.), <em>JFAK. Essays Dedicated to Johan van Benthem on\nthe Occasion of his 50th Birthday</em>. Amsterdam: Amsterdam\nUniversity Press.</li>\n<li>\u2013\u2013\u2013. (1998).\n<em>Type-logical Semantics</em>.  Cambridge, MA: MIT Press.</li>\n<li>Curry, H. B. (1961).  Some logical aspects of grammatical\nstructure.  In R. Jacobson (Ed.), <em>Structure of Language and its\nMathematical Aspects</em>,  <em>Proceedings of the\nSymposia in Applied Mathematics</em> (Volume XII),  American\nMathematical Society, pp.  56\u201368.</li>\n<li>de Groote, P. (2006).  Towards a Montagovian account of dynamics.\nIn <em>Proceedings SALT 16</em>. CLC Publications.</li>\n<li>\u2013\u2013\u2013. (2001a).  Towards abstract categorial\ngrammars.  In <em>Proceedings of 39th Annual Meeting of the\nAssociation for Computational Linguistics</em>, Association\nfor Computational Linguistics, pp.  252\u2013259.</li>\n<li>\u2013\u2013\u2013. (2001b).  Type raising, continuations, and classical\nlogic.  In M. S. R. van Rooy (Ed.), <em>Proceedings of the Thirteenth\nAmsterdam Colloquium</em>, Amsterdam: ILLC (Universiteit van\nAmsterdam), pp.  97\u2013101.</li>\n<li>\u2013\u2013\u2013. (1999).  The non-associative Lambek\ncalculus with product in polynomial time.  In N. V. Murray\n(Ed.), <em>Automated Reasoning With Analytic Tableaux and Related\nMethods</em>, <em>Lecture Notes in Artificial Intelligence</em>\n(Volume 1617), Berlin: Springer, pp.  128\u2013139.</li>\n<li>de Groote, P. and F. Lamarche (2002).  Classical non-associative\nLambek calculus.\n<em>Studia Logica</em>, 71(3): 355\u2013388.</li>\n<li>de Groote, P. and S. Pogodalla (2004).  On the Expressive Power of\nAbstract Categorial Grammars: Representing Context-Free Formalisms.\n<em>Journal of Logic, Language and Information</em>, 13(4):\n421\u2013438.</li>\n<li>de Groote, P. and C. Retor\u00e9 (1996).  On the semantic\nreadings of proof nets.  In G.-J. Kruijff, G. Morrill, and D. Oehrle\n(Eds.), <em>Proceedings 2nd Formal Grammar Conference</em>, Prague,\npp.  57\u201370.</li>\n<li>Do\u0161en, K. (1992).  A brief survey of frames for the Lambek\ncalculus. <em>Mathematical Logic Quarterly</em>, 38(1): 179\u2013187.</li>\n<li>Galatos, N., P. Jipsen, T. Kowalski, and H. Ono (2007).\n<em>Residuated Lattices: An Algebraic Glimpse at Substructural Logics,\nStudies in Logic and the Foundations of Mathematics (Volume 151)</em>,\nAmsterdam: Elsevier.</li>\n<li>Girard, J.-Y. (1987).  Linear logic.\n<em>Theoretical Computer Science</em>, 50: 1\u2013102.</li>\n<li>Grishin, V. (1983).  On a generalization of the Ajdukiewicz-Lambek\nsystem.  In A. Mikhailov (Ed.), <em>Studies in Nonclassical Logics and\nFormal Systems</em>, Moscow: Nauka, pp.  315\u2013334.  [English\ntranslation in Abrusci and Casadio (eds.) New Perspectives in Logic\nand Formal Linguistics. Bulzoni, Rome, 2002].</li>\n<li>Hendriks, H. (1993).\n<em>Studied Flexibility. Categories and Types in Syntax and\nSemantics</em>.  Ph. D. thesis, ILLC, University of Amsterdam.</li>\n<li>Hepple, M. (1999).  An Earley-style predictive chart parsing\nmethod for Lambek grammars.  In <em>Proceedings of the 37th Annual\nMeeting of the Association for Computational Linguistics</em>,\nAssociation for Computational Linguistics, pp.  465\u2013472.</li>\n<li>\u2013\u2013\u2013. (1990).  Normal form theorem proving for the Lambek\ncalculus.  In <em>Papers presented to the 13th International\nConference on Computational Linguistics</em>, Helsinki, pp.\n173\u2013178.</li>\n<li>Hoyt, F. and J. Baldridge (2008).  A logical basis for the D\ncombinator and normal form in CCG.  In <em>Proceedings of ACL-08:\nHLT</em>, Association for Computational Linguistics, pp.\n326\u2013334.</li>\n<li>J\u00e4ger, G. (2005).\n<em>Anaphora And Type Logical Grammar</em>.  Berlin: Springer.</li>\n<li>\u2013\u2013\u2013. (2004). Residuation, Structural Rules and Context Freeness.\n<em>Journal of Logic, Language and Information</em>, 13: 47\u201359.</li>\n<li>Johnson, M. (1998).  Proof nets and the complexity of processing\ncenter-embedded constructions.\n<em>Journal of Logic, Language and Information</em>, 7(4):\n433\u2013447.</li>\n<li>Joshi, A. K., K. Vijay-Shanker, and D. Weir (1991).  The\nconvergence of mildly context-sensitive grammar formalisms.  In\nP. Sells, S. M. Shieber, and T. Wasow (Eds.), <em>Foundational Issues\nin Natural Language Processing</em>, Cambridge, MA:\nMIT Press,  pp.  31\u201381.</li>\n<li>Kanazawa, M. (1998).\n<em>Learnable classes of categorial grammars</em>.  Stanford: CSLI\nPublications.</li>\n<li>Kandulski, M. (1988).  The equivalence of nonassociative Lambek\ncategorial grammars and context-free grammars.\n<em>Zeitschrift f\u00fcr mathematische Logik und Grundlagen der\nMathematik</em>, 34: 41\u201352.</li>\n<li>Kanovich, M. (1994).  The Complexity of Horn Fragments of Linear\nLogic. <em>Annals of Pure and Applied Logic</em>, 69(2-3): 195\u2013241.</li>\n<li>Kruijff, G.-J. and J. Baldridge (2003).  Multi-modal combinatory\ncategorial grammar.  In <em>Proceedings of the 10th Conference of the\nEuropean Chapter of the Association for Computational\nLinguistics</em>, Association for Computational Linguistics, pp.\n211\u2013218.</li>\n<li>Kurtonina, N. (1995).\n<em>Frames and Labels. A Modal Analysis of Categorial Inference</em>.\nPh. D. thesis, OTS Utrecht, ILLC Amsterdam.</li>\n<li>Kurtonina, N. and M. Moortgat (2010).  Relational semantics for\nthe Lambek-Grishin calculus.  In C. Ebert, G. J\u00e4ger, and\nJ. Michaelis (Eds.), <em>The Mathematics of Language. Proceedings of\nthe 10th and 11th Biennial Conference</em>, Lecture Notes in Computer\nScience (Volume 6149). Berlin: Springer, pp. 210\u2013222.</li>\n<li>\u2013\u2013\u2013 (1997).  Structural control.  In\nP. Blackburn and M. de Rijke (Eds.), <em>Specifying Syntactic\nStructures</em>,  Stanford: CSLI Publications, pp.  75\u2013113.</li>\n<li>Lambek, J. (2008).\n<em>From word to sentence. A computational algebraic approach to\ngrammar</em>.  Polimetrica.</li>\n<li>\u2013\u2013\u2013. (1999).  Type grammar revisited.  In\nA. Lecomte, F. Lamarche, and G. Perrier (Eds.), <em>Logical Aspects of\nComputational Linguistics</em>, <em>Lecture Notes in Artificial\nIntelligence</em> (Volume 1582), Berlin: Springer, pp.\n1\u201327.</li>\n<li>\u2013\u2013\u2013. (1993).  From categorial to bilinear logic.  In\nK. Do\u0161en and P. Schr\u00f6der-Heister (Ed.), <em>Substructural Logics</em>.\nOxford University Press.</li>\n<li>\u2013\u2013\u2013. (1961).  On the calculus of syntactic\ntypes.  In R. Jacobson (Ed.), <em>Structure of Language and its\nMathematical Aspects</em>, <em>Proceedings of the Symposia in Applied\nMathematics</em> (Volume XII), American Mathematical Society, pp.\n166\u2013178.</li>\n<li>\u2013\u2013\u2013. (1958).  The mathematics of sentence structure.\n<em>American Mathematical Monthly</em>, 65: 154\u2013170.</li>\n<li>Melissen, M. (2009).  The generative capacity of the\nLambek-Grishin calculus: A new lower bound.  In P. de Groote\n(Ed.), <em>Proceedings 14th Conference on Formal Grammar</em>, \nLecture Notes in Computer Science (Volume 5591), Berlin: Springer.</li>\n<li>Moortgat, M. (2009).  Symmetric categorial grammar.\n<em>Journal of Philosophical Logic</em>, 8(6),\n681\u2013710.</li>\n<li>\u2013\u2013\u2013. (1997).  Categorial type logics.  In J. van Benthem\nand A. ter Meulen (Eds.), <em>Handbook of Logic and Language</em>\n(Chapter 2),  Amsterdam: Elsevier, pp. 93\u2013177.  (Second edition, revised and\nupdated: Elsevier Insights Series, 2010).</li>\n<li>\u2013\u2013\u2013. (1996).  Multimodal linguistic inference.\n<em>Journal of Logic, Language and Information</em>, 5(3\u20134):\n349\u2013385.</li>\n<li>\u2013\u2013\u2013. (1988).\n<em>Categorial Investigations. Logical and Linguistic Aspects of the\nLambek calculus</em>.  Berlin: De Gruyter.</li>\n<li>Moot, R. (2008).  Lambek grammars, tree adjoining grammars and\nhyperedge replacement grammars.  In <em>Proceedings of TAG+9, The 9th\nInternational Workshop on Tree Adjoining Grammars and Related\nFormalisms</em>, T\u00fcbingen, pp.  65\u201372.</li>\n<li>\u2013\u2013\u2013. (2007).  Proof nets for display logic.\n<em>CoRR</em>, abs/0711.2444.</li>\n<li>\u2013\u2013\u2013. (2002).\n<em>Proof Nets for Linguistic Analysis</em>.  Ph. D. thesis, Utrecht\nInstitute of Linguistics OTS, Utrecht University.</li>\n<li>Moot, R. and M. Piazza (2001).  Linguistic Applications of First\nOrder Intuitionistic Linear Logic. <em>Journal of Logic, Language and\nInformation</em>, 10(2): 211\u2013232.</li>\n<li>Moot, R. and Q. Puite (2002).  Proof Nets for the Multimodal\nLambek Calculus.\n<em>Studia Logica</em>, 71(3): 415\u2013442.</li>\n<li>Morrill, G. (2010).\n<em>Categorial Grammar: Logical Syntax, Semantics, and\nProcessing</em>.  Oxford: Oxford University Press.</li>\n<li>\u2013\u2013\u2013. (2000).  Incremental processing and acceptability.\n<em>Computational linguistics</em>, 26(3): 319\u2013338.</li>\n<li>\u2013\u2013\u2013. (1994).\n<em>Type Logical Grammar: Categorial Logic of Signs</em>.  Dordrecht:\nKluwer Academic Publishers.</li>\n<li>\u2013\u2013\u2013. (1990).  Intensionality and boundedness.\n<em>Linguistics and Philosophy</em>, 13(6): 699\u2013726.</li>\n<li>Morrill, G. and M. Fadda (2008).  Proof nets for basic\ndiscontinuous Lambek calculus.\n<em>Journal of Logic and Computation</em>, 18(2): 239\u2013256.</li>\n<li>Morrill, G., M. Fadda, and O. Valentin (2007).  Nondeterministic\ndiscontinuous Lambek calculus.  In <em>Proceedings of the Seventh\nInternational Workshop on Computational Semantics (IWCS7)</em>,\nTilburg.</li>\n<li>Morrill, G., O. Valentin, and M. Fadda (2009).  Dutch grammar and\nprocessing: A case study in TLG.  In P. Bosch, D. Gabelaia, and\nJ. Lang (eds.), <em>Logic, Language, and Computation: 7th\nInternational Tbilisi Symposium on Logic, Language, and\nComputation</em>, Tbilisi, Georgia, October 1-5, 2007 (Revised\nSelected Papers), Lecture Notes in Artificial Intelligence (Volume\n5422), Berlin: Springer, pp.  272\u2013286.</li>\n<li>Muskens, R. (2007).  Separating syntax and combinatorics in\ncategorial grammar. <em>Research on Language &amp;\nComputation</em>, 5(3): 267\u2013285.</li>\n<li>Oehrle, R. T., E. Bach, and D. Wheeler (Eds.) (1988).\n<em>Categorial Grammars and Natural Language Structures</em>, Studies\nin Linguistics and Philosophy (Number 32). Dordrecht: Reidel.</li>\n<li>Pentus, M. (1993b).  Lambek grammars are context free.\nIn <em>Proceedings of the 8th Annual IEEE</em> Symposium on Logic in\nComputer Science},  IEEE Computer Society Press, pp.  429\u2013433.</li>\n<li>\u2013\u2013\u2013. (2006).  Lambek calculus is NP-complete.\n<em>Theoretical Computer Science</em>, 357: 186\u2013201.</li>\n<li>\u2013\u2013\u2013. (1995).  Models for the Lambek calculus.\n<em>Annals of Pure and Applied Logic</em>, 75(1\u20132),\n179\u2013213.</li>\n<li>Restall, G. (2000). <em>An Introduction to Substructural\nLogics</em>.  London: Routledge.</li>\n<li>Retor\u00e9, C. and S. Salvati (2010).  A faithful\nrepresentation of non-associative Lambek grammars in Abstract\nCategorial Grammars.\n<em>Journal of Logic, Language and Information</em>, 19(2).  Special\nissue on New Directions in Type Theoretic Grammars.</li>\n<li>Roorda, D. (1992).  Proof Nets for Lambek calculus.\n<em>Journal of Logic and Computation</em>, 2(2): 211\u2013231.</li>\n<li>Savateev, Y. (2009).  Product-free Lambek Calculus is NP-complete.\nIn S. Artemov and A. Nerode (Eds.), <em>Proceedings of the 2009\nInternational Symposium on Logical Foundations of Computer\nScience</em>, Lecture Notes in Computer Science (Volume 5407), Berlin: Springer, pp.\n380\u2013394.</li>\n<li>Shan, C. and C. Barker (2006).  Explaining Crossover and\nSuperiority as Left-to-right Evaluation.\n<em>Linguistics and Philosophy</em>, 29(1): 91\u2013134.</li>\n<li>S\u00f8rensen, M. H. and P. Urzyczyn (2006).\n<em>Lectures on the Curry-Howard Isomorphism</em>,\n<em>Studies in Logic and the Foundations of Mathematics</em> (Volume\n149),  Amsterdam: Elsevier.</li>\n<li>Stabler, E. (1999).  Remnant movement and complexity.  In\nG. Bouma, E. Hinrichs, G.-J. Kruijff, and R. T. Oehrle (Eds.),\n<em>Constraints and Resources in Natural Language Syntax and\nSemantics</em>, Stanford: CSLI, pp.  299\u2013326.</li>\n<li>\u2013\u2013\u2013. (1997).  Derivational minimalism.  In\nC. Retor\u00e9 (Ed.), <em>Logical Aspects of Computational\nLinguistics</em>, <em>Lecture Notes in Artificial Intelligence</em>\n(Volume 1328), Berlin: Springer, pp.  68\u201395.</li>\n<li>Steedman, M. (2000).\n<em>The Syntactic Process</em>.  Cambridge, MA: MIT Press.</li>\n<li>van Benthem, J. (1995).\n<em>Language in Action: Categories, Lambdas and Dynamic Logic</em>.\nCambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013. (1983).  The semantics of variety in categorial\ngrammar.  Technical Report 83-29, Simon Fraser University.  Revised\nversion in W. Buszkowski <em>et al</em>. (1988).</li>\n<li>Vermaat, W. (2006).\n<em>The logic of variation. A cross-linguistic account of wh-question\nformation</em>.  Ph. D. thesis, Utrecht Institute of Linguistics OTS,\nUtrecht University.</li>\n<li>\u2013\u2013\u2013. (2004).  The minimalist move operation in a deductive\nperspective.\n<em>Research on Language &amp; Computation</em>, 2(1), 69\u201385.</li>\n<li>Wansing, H. (2002).  Sequent systems for modal logics.  In\nD. Gabbay and F. Guenthner (Eds.), <em>Handbook of Philosophical\nLogic</em> (Volume 8), Dordrecht: Kluwer Academic Publishers, pp.\n61\u2013145.</li>\n<li>\u2013\u2013\u2013. (1992).  Formulas-as-types for a hierarchy\nof sublogics of intuitionistic propositional logic.  In D. Pearce and\nH. Wansing (Eds.), <em>Nonclassical Logics and Information\nProcessing</em>, Lecture Notes in Computer Science (Volume 619),\nBerlin: Springer, pp.  125\u2013145.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "compositionality",
            "logic: linear",
            "logic: modal",
            "logic: relevance",
            "logic: substructural",
            "type theory"
        ],
        "entry_link": [
            {
                "../compositionality/": "compositionality"
            },
            {
                "../logic-linear/": "logic: linear"
            },
            {
                "../logic-modal/": "logic: modal"
            },
            {
                "../logic-relevance/": "logic: relevance"
            },
            {
                "../logic-substructural/": "logic: substructural"
            },
            {
                "../type-theory/": "type theory"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<td valign=\"top\"><img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=typelogical-grammar\" target=\"other\">How to cite this entry</a>.",
            "<td valign=\"top\"><img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/typelogical-grammar/\" target=\"other\">Preview the PDF version of this entry</a> at the <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<td valign=\"top\"><img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=typelogical-grammar&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<td valign=\"top\"><img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"http://philpapers.org/sep/typelogical-grammar/\" target=\"other\">Enhanced bibliography for this entry</a> at <a href=\"http://philpapers.org\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=typelogical-grammar": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/typelogical-grammar/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=typelogical-grammar&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "http://philpapers.org/sep/typelogical-grammar/": "Enhanced bibliography for this entry"
            },
            {
                "http://philpapers.org": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "<a href=\"http://www.labri.fr/perso/moot/grail3.html\" target=\"other\">Moot's typelogical theorem prover</a>",
            "<a href=\"http://symcg.pbworks.com\" target=\"other\">Symmetric Categorial Grammar</a>",
            "<a href=\"http://groups.inf.ed.ac.uk/ccg/\" target=\"other\">Combinatory Categorial Grammar</a>"
        ],
        "listed_links": [
            {
                "http://www.labri.fr/perso/moot/grail3.html": "Moot's typelogical theorem prover"
            },
            {
                "http://symcg.pbworks.com": "Symmetric Categorial Grammar"
            },
            {
                "http://groups.inf.ed.ac.uk/ccg/": "Combinatory Categorial Grammar"
            }
        ]
    }
}