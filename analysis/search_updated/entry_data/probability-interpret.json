{
    "url": "probability-interpret",
    "title": "Interpretations of Probability",
    "authorship": {
        "year": "Copyright \u00a9 2023",
        "author_text": "Alan H\u00e1jek\n<alan.hajek@anu.edu.au>",
        "author_links": [
            {
                "http://philosophy.anu.edu.au/profile/alan-hajek/": "Alan H\u00e1jek"
            },
            {
                "mailto:alan%2ehajek%40anu%2eedu%2eau": "alan.hajek@anu.edu.au"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2023</a> by\n\n<br/>\n<a href=\"http://philosophy.anu.edu.au/profile/alan-hajek/\" target=\"other\">Alan H\u00e1jek</a>\n&lt;<a href=\"mailto:alan%2ehajek%40anu%2eedu%2eau\"><em>alan<abbr title=\" dot \">.</abbr>hajek<abbr title=\" at \">@</abbr>anu<abbr title=\" dot \">.</abbr>edu<abbr title=\" dot \">.</abbr>au</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Mon Oct 21, 2002",
        "substantive revision Thu Nov 16, 2023"
    ],
    "preamble": "\n\nProbability is the most important concept in modern science,\nespecially as nobody has the slightest notion what it means.\n\u2014Bertrand Russell, 1929 Lecture\n\n(cited in Bell 1945, 587)\n\n\nOne regularly reads and hears probabilistic claims like the following:\n\nThe Democrats will probably win the next election.\nThe coin is just as likely to land heads as tails.\nThere\u2019s a 30% chance of rain tomorrow.\nThe probability that a radium atom decays in one year is roughly\n0.0004.\n\n\nBut what do these statements mean? This may be understood as a\nmetaphysical question about what kinds of things are probabilities, or\nmore generally as a question about what makes probability statements\ntrue or false. At a first pass, various interpretations of\nprobability answer this question, one way or another.\n\nHowever, there is also a stricter usage: an\n\u2018interpretation\u2019 of a formal theory provides\nmeanings for its primitive symbols or terms, with an eye to turning\nits axioms and theorems into true statements about some subject. In\nthe case of probability, Kolmogorov\u2019s axiomatization (which we\nwill see shortly) is the usual formal theory, and the so-called\n\u2018interpretations of probability\u2019 usually interpret\nit. That axiomatization introduces a function\n\u2018\\(P\\)\u2019 that has certain formal properties. We may then\nask \u2018What is \\(P\\)?\u2019. Several of the views that we will\ndiscuss also answer this question, one way or another.\n\nOur topic is complicated by the fact that there are various\nalternative formalizations of probability. Moreover, as we will see,\nsome of the leading \u2018interpretations of probability\u2019 do\nnot obey all of Kolmogorov\u2019s axioms, yet they have not\nlost their title for that. And various other quantities that have\nnothing to do with probability do satisfy Kolmogorov\u2019s\naxioms, and thus are \u2018interpretations\u2019 of it in the strict\nsense: normalized mass, length, area, volume, and other quantities\nthat fall under the scope of measure theory, the abstract mathematical\ntheory that generalizes such quantities. Nobody seriously considers\nthese to be \u2018interpretations of probability\u2019, however,\nbecause they do not play the right role in our conceptual\napparatus.\n\nPerhaps we would do better, then, to think of the interpretations as\nanalyses of various concepts of probability. Or perhaps\nbetter still, we might regard them as explications of such\nconcepts, refining them to be fruitful for philosophical and\nscientific theorizing (\u00e0 la Carnap 1950, 1962).\n\nHowever we think of it, the project of finding such interpretations is\nan important one. Probability is virtually ubiquitous. It plays a role\nin almost all the sciences. It underpins much of the social sciences\n\u2014 witness the prevalent use of statistical testing, confidence\nintervals, regression methods, and so on. It finds its way, moreover,\ninto much of philosophy. In epistemology, the philosophy of mind, and\ncognitive science, we see states of opinion being modeled by\nsubjective probability functions, and learning being modeled by the\nupdating of such functions. Since probability theory is central to\ndecision theory and game theory, it has ramifications for ethics and\npolitical philosophy. It figures prominently in such staples of\nmetaphysics as causation and laws of nature. It appears again in the\nphilosophy of science in the analysis of confirmation of theories,\nscientific explanation, and in the philosophy of specific scientific\ntheories, such as quantum mechanics, statistical mechanics,\nevolutionary biology, and genetics. It can even take center stage in\nthe philosophy of logic, the philosophy of language, and the\nphilosophy of religion. Thus, problems in the foundations of\nprobability bear at least indirectly, and sometimes directly, upon\ncentral scientific, social scientific, and philosophical concerns. The\ninterpretation of probability is one of the most important such\nfoundational problems.\n",
    "toc": [
        {
            "#KolProCal": "1. Kolmogorov\u2019s Probability Calculus"
        },
        {
            "#CriAdeForIntPro": "2. Criteria of adequacy for the interpretations of probability"
        },
        {
            "#MaiInt": "3. The Main Interpretations"
        },
        {
            "#ClaPro": "3.1 Classical Probability"
        },
        {
            "#LogPro": "3.2 Logical/Evidential Probability"
        },
        {
            "#SubPro": "3.3 Subjective Probability"
        },
        {
            "#FreInt": "3.4 Frequency Interpretations"
        },
        {
            "#ProInt": "3.5 Propensity Interpretations"
        },
        {
            "#BesSysInt": "3.6 Best-System Interpretations"
        },
        {
            "#ConFutPro": "4. Conclusion: Future Prospects?"
        },
        {
            "#SugFurRea": "Suggested Further Reading"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. Kolmogorov\u2019s Probability Calculus\n\nProbability theory was a relative latecomer in intellectual history.\nTo be sure, proto-probabilistic ideas concerning evidence and\ninference date back to antiquity (see Franklin 2001). However,\nprobability\u2019s mathematical treatment had to wait until the\nFermat-Pascal correspondence, and their analysis of games of chance in\n17th century France. Its axiomatization had to wait still\nlonger, in Kolmogorov\u2019s classic Foundations of the Theory of\nProbability (1933). Roughly, probabilities lie between 0 and 1\ninclusive, and they are additive. More formally, let \\(\\Omega\\) be a\nnon-empty set (\u2018the universal set\u2019). A field (or\nalgebra) on \\(\\Omega\\) is a set \\(\\mathbf{F}\\) of subsets of\n\\(\\Omega\\) that has \\(\\Omega\\) as a member, and that is closed under\ncomplementation (with respect to \\(\\Omega)\\) and union. Let \\(P\\) be a\nfunction from \\(\\mathbf{F}\\) to the real numbers obeying:\n\n(Non-negativity) \\(P(A) \\ge 0\\), for all \\(A \\in\n\\mathbf{F}\\).\n(Normalization) \\(P(\\Omega) = 1\\).\n(Finite additivity) \\(P(A \\cup B) = P(A) + P(B)\\) for all \\(A, B\n\\in \\mathbf{F}\\) such that \\(A \\cap B = \\varnothing\\).\n\n\nCall \\(P\\) a probability function, and \\((\\Omega ,\n\\mathbf{F}, P)\\) a probability space. This is\nKolmogorov\u2019s \u201celementary theory of probability\u201d.\n\nThe non-negativity and normalization axioms are largely matters of\nconvention, although it is non-trivial that probability functions take\nat least the two values 0 and 1, and that they have a maximal value\n(unlike various other measures, such as length, volume, and so on,\nwhich are unbounded). We will return to finite additivity at a number\nof points below.\n\nWe may now apply the theory to various familiar cases. For example, we\nmay represent the results of tossing a single die once by the set\n\\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\), and we could let \\(\\mathbf{F}\\) be\nthe set of all subsets of \\(\\Omega\\). Under the natural assignment of\nprobabilities to members of \\(\\mathbf{F}\\), we obtain such welcome\nresults as the following: \n\\[\\begin{align}\nP(\\{1\\}) &= \\frac{1}{6}, \\\\\n P(\\text{even}) &= P(\\{2\\} \\cup \\{4\\} \\cup \\{6\\}) \\\\\n &= \\frac{3}{6}, \\\\\n P(\\text{odd or less than 4}) &= P(\\text{odd}) + P(\\text{less than 4}) - P(\\text{odd} \\cap \\text{less than 4}) \\\\\n &= \\frac{1}{2} + \\frac{1}{2} - \\frac{2}{6} \\\\\n &= \\frac{4}{6}, \n\\end{align}\\]\n\n\nand so on.\n\nWe could instead attach probabilities to members of a collection\n\\(\\mathbf{S}\\) of sentences of a formal language, closed\nunder (countable) truth-functional combinations, with the following\ncounterpart axiomatization:\n\n\\(P(A) \\ge 0\\) for all \\(A \\in \\mathbf{S}\\).\nIf \\(T\\) is a logical truth (in classical logic), then \\(P(T) =\n1\\).\n\\(P(A \\vee B) = P(A) + P(B)\\) for all \\(A \\in \\mathbf{S}\\) and \\(B\n\\in \\mathbf{S}\\) such that \\(A\\) and \\(B\\) are logically\nincompatible.\n\n\nThe bearers of probabilities are sometimes also called\n\u201cevents\u201d, \u201coutcomes\u201d, or\n\u201cpropositions\u201d, but the underlying formalism remains the\nsame. More attention has been given to interpreting\n\u2018\\(P\\)\u2019 than to interpreting its bearers; we will be\nconcerned with the former.\n\nThe elementary theory of probability suffices for most everyday\napplications of probability, and it will suffice for most of our\ndiscussion below. But more advanced treatments in mathematics,\nstatistics, and science require more mathematical sophistication\ninvolving countable infinite extensions. (Readers less\ninterested in the mathematical details may want to skip to \"The\nconditional probability ...\" three paragaphs below.) Now let us\nstrengthen our closure assumptions regarding \\(\\mathbf{F}\\), requiring\nit to be closed under complementation and countable union; it\nis then called a sigma field (or sigma algebra) on\n\\(\\Omega\\). It is controversial whether we should strengthen finite\nadditivity, as Kolmogorov does:\n\n\\(3'\\). (Countable additivity) If \\(A_1, A_2, A_3\\ldots\\) is a\ncountably infinite sequence of (pairwise) disjoint sets, each of which\nis an element of \\(\\mathbf{F}\\), then \n\\[ P(\\bigcup_{n=1}^{\\infty} A_n) = \\sum_{n=1}^{\\infty} P(A_n) \\]\n\n\n\nKolmogorov comments that infinite probability spaces are idealized\nmodels of real random processes, and that he limits himself\narbitrarily to only those models that satisfy countable additivity.\nThis axiom is the cornerstone of the assimilation of probability\ntheory to measure theory.\n\nThe conditional probability of A given B is then given by the\nratio of unconditional probabilities: \n\\[ P(A\\mid B) = \\frac{P(A\\cap B)}{P(B)},\\text{ provided } P(B) \\gt 0. \\]\n\n\nThis is often taken to be the definition of conditional\nprobability, although it should be emphasized that this is a technical\nusage of the term that may not align perfectly with a pretheoretical\nconcept that we might have (see H\u00e1jek, 2003). We recognize it\nin locutions such as \u201cthe probability that the die lands 1,\ngiven that it lands odd, is 1/3\u201d, or \u201cthe probability that\nit will rain tomorrow, given that there are dark clouds in the sky\ntomorrow morning, is high\u201d. It is the concept of the probability\nof something given or in the light of some piece of\nevidence or information. Indeed, some authors take conditional\nprobability to be the primitive notion, and axiomatize it directly\n(e.g. Popper 1959b, R\u00e9nyi 1970, van Fraassen 1976, Spohn 1986,\nand Roeper and Leblanc 1999).\n\nThere are other formalizations that give up normalization; that give\nup countable additivity, and even additivity; that allow probabilities\nto take infinitesimal values (positive, but smaller than every\npositive real number); that allow probabilities to be imprecise\n\u2014 interval-valued, or more generally represented with sets of\nprecise probability functions; and that treat probabilities\ncomparatively rather than quantitatively. (See Fine 1974, Halpern\n2003, Cozman 2016, Fine 2016, Hawthorne 2016, Lyon 2016.) For now,\nhowever, when we speak of \u2018the probability calculus\u2019, we\nwill mean Kolmogorov\u2019s approach, as is standard. See\nH\u00e1jek and Hitchcock (2016b) for a relatively non-technical\nintroduction to it, intended for philosophers.\n\nGiven certain probabilities as inputs, the axioms and theorems allow\nus to compute various further probabilities. However, apart from the\nassignment of 1 to the universal set and 0 to the empty set, they are\nsilent regarding the initial assignment of\n probabilities.[1]\n For guidance with that, we need to turn to the interpretations of\nprobability. First, however, let us list some criteria of adequacy for\nsuch interpretations.\n2. Criteria of Adequacy for the Interpretations of Probability\n\nWhat criteria are appropriate for assessing the cogency of a proposed\ninterpretation of probability? Of course, an interpretation should be\nprecise, unambiguous, non-circular, and use well-understood\nprimitives. But those are really prescriptions for good philosophizing\ngenerally; what do we want from our interpretations of\nprobability, specifically? We begin by following Salmon (1966,\n64), although we will raise some questions about his criteria, and\npropose some others. He writes:\n\n\nAdmissibility. We say that an interpretation of a formal\nsystem is admissible if the meanings assigned to the primitive terms\nin the interpretation transform the formal axioms, and consequently\nall the theorems, into true statements. A fundamental requirement for\nprobability concepts is to satisfy the mathematical relations\nspecified by the calculus of probability\u2026\n\nAscertainability. This criterion requires that there be some\nmethod by which, in principle at least, we can ascertain values of\nprobabilities. It merely expresses the fact that a concept of\nprobability will be useless if it is impossible in principle to find\nout what the probabilities are\u2026\n\nApplicability. The force of this criterion is best expressed\nin Bishop Butler\u2019s famous aphorism, \u201cProbability is the\nvery guide of life.\u201d\u2026\n\n\nIt might seem that the criterion of admissibility goes without saying.\nThe word \u2018interpretation\u2019 is often used in such a way that\n\u2018admissible interpretation\u2019 is a pleonasm. Yet it turns\nout that the criterion is non-trivial, and indeed if taken seriously\nwould rule out several of the leading interpretations of probability!\nAs we will see, some of them fail to satisfy countable additivity; for\nothers (certain propensity interpretations) the status of at least\nsome of the axioms is unclear. Nevertheless, we regard them as genuine\ncandidates. It should be remembered, moreover, that Kolmogorov\u2019s\nis just one of many possible axiomatizations, and there is not\nuniversal agreement on which is \u2018best\u2019 (whatever that\nmight mean). Indeed, Salmon\u2019s preferred axiomatization differs\nfrom\n Kolmogorov\u2019s.[2]\n Thus, there is no such thing as admissibility tout court,\nbut rather admissibility with respect to this or that axiomatization.\nIn any case, if we found an inadmissible interpretation (with respect\nto Kolmogorov\u2019s axiomatization) that did a wonderful job of\nmeeting the criteria of ascertainability and applicability, then we\nshould surely embrace it.\n\nSo let us turn to those criteria. It is a little unclear in the\nascertainability criterion just what \u201cin principle\u201d\namounts to \u2013 it outruns what is practical or feasible \u2013\nthough perhaps some latitude here is all to the good. Most of the work\nwill be done by the applicability criterion. We must say more (as\nSalmon indeed does) about what sort of a guide to life\nprobability is supposed to be. Mass, length, area and volume are all\nuseful concepts, and they are \u2018guides to life\u2019 in various\nways (think how critical distance judgments can be to survival);\nmoreover, they are admissible and ascertainable, so presumably it is\nthe applicability criterion that will rule them out. Perhaps it is\nbest to think of applicability as a cluster of criteria, each of which\nis supposed to capture something of probability\u2019s distinctive\nconceptual roles; moreover, we should not require that all of them be\nmet by a given interpretation. They include:\n\n\nNon-triviality: an interpretation should make non-extreme\nprobabilities at least a conceptual possibility. For example, suppose\nthat we interpret \u2018\\(P\\)\u2019 as the truth function:\nit assigns the value 1 to all true sentences, and 0 to all false\nsentences. Then trivially, all the axioms come out true, so this\ninterpretation is admissible. We would hardly count it as an adequate\ninterpretation of probability, however, and so we\nneed to exclude it. It is essential to probability that, at least in\nprinciple, it can take intermediate values. All of the\ninterpretations that we will present meet this criterion, so we will\ndiscuss it no more.\n\nApplicability to frequencies: an interpretation should render\nperspicuous the relationship between probabilities and (long-run)\nfrequencies. Among other things, it should make clear why, by and\nlarge, more probable events occur more frequently than less probable\nevents.\n\nApplicability to rational beliefs: an interpretation should\nclarify the role that probabilities play in constraining the degrees\nof belief, or credences, of rational agents. Among other\nthings, knowing that one event is more probable than another, a\nrational agent will be more confident about the occurrence of the\nformer event.\n\nApplicability to rational decisions: an interpretation should\nmake clear how probabilities figure in rational decision-making. This\nseems especially apposite for a \u2018guide to life\u2019.\n\nApplicability to ampliative inferences: an interpretation\nwill score bonus points if it illuminates the distinction between\n\u2018good\u2019 and \u2018bad\u2019 ampliative inferences, while\nexplicating why both fall short of deductive inferences.\n\nApplicability to science: an interpretation should illuminate\nparadigmatic uses of probability in science (for example, in quantum\nmechanics and statistical mechanics).\n\n\nPerhaps there are further metaphysical desiderata that we\nmight impose on the interpretations. For example, there appear to be\nconnections between probability and modality. Events with\npositive probability can happen, even if they don\u2019t.\nSome authors also insist on the converse condition that only\nevents with positive probability can happen, although this is more\ncontroversial \u2014 see our discussion of \u2018regularity\u2019\nin Section 3.3.4. (Indeed, in uncountable probability spaces this\ncondition will require the employment of infinitesimals, and will thus\ntake us beyond the standard Kolmogorov theory \u2014\n\u2018standard\u2019 both in the sense of being the orthodoxy, and\nin its employment of standard, as opposed to\n\u2018non-standard\u2019 real numbers. See Skyrms 1980.) In any\ncase, our list is already long enough to help in our assessment of the\nleading interpretations on the market.\n3. The Main Interpretations\n\nBroadly speaking, there are arguably three main concepts of\nprobability:\n\nAn epistemological concept, which is meant to measure objective\nevidential support relations. For example, \u201cin light of the\nrelevant seismological and geological data, California will\nprobably experience a major earthquake this\ndecade\u201d.\nThe concept of an agent\u2019s degree of confidence, a graded\nbelief. For example, \u201cI am not sure that it will rain in\nCanberra this week, but it probably will.\u201d\nA physical concept that applies to various systems in the world,\nindependently of what anyone thinks. For example, \u201ca particular\nradium atom will probably decay within 10,000\nyears\u201d.\n\n\nSome philosophers will insist that not all of these concepts are\nintelligible; some will insist that one of them is basic, and that the\nothers are reducible to it. Moreover, the boundaries between these\nconcepts are somewhat permeable. After all, \u2018degree of\nconfidence\u2019 is itself an epistemological concept, and as we will\nsee, it is thought to be rationally constrained both by evidential\nsupport relations and by attitudes to physical probabilities in the\nworld. And there are intramural disputes within the camps supporting\neach of these concepts, as we will also see. Be that as it may, it\nwill be useful to keep these concepts in mind. Sections 3.1 and 3.2\ndiscuss analyses of concept (1), classical and\nlogical/evidential probability; 3.3 discusses analyses of\nconcept (2), subjective probability; 3.4, 3.5, and 3.6\ndiscuss three analyses of concept (3), frequentist,\npropensity, and best-system interpretations.\n3.1 Classical Probability\n\nThe classical interpretation owes its name to its early and august\npedigree. It was championed by de Moivre and Laplace, and inchoate\nversions of it may be found in the works of Pascal, Bernoulli,\nHuygens, and Leibniz. It assigns probabilities in the absence of any\nevidence, or in the presence of symmetrically balanced evidence. The\nguiding idea is that in such circumstances, probability is shared\nequally among all the possible outcomes, so that the classical\nprobability of an event is simply the fraction of the total number of\npossibilities in which the event occurs. It seems especially well\nsuited to those games of chance that by their very design create such\ncircumstances \u2014 for example, the classical probability of a fair\ndie landing with an even number showing up is 3/6. It is often\npresupposed (usually tacitly) in textbook probability puzzles.\n\nHere is a classic statement by de Moivre:\n\n[I]f we constitute a fraction whereof the numerator be the number of\nchances whereby an event may happen, and the denominator the number of\nall the chances whereby it may either happen or fail, that fraction\nwill be a proper designation of the probability of happening. (1718;\n1967, 1\u20132)\n Laplace gives the best-known but slightly different\nformulation:\n\n\nThe theory of chances consists in reducing all events of the same kind\nto a certain number of equally possible cases, that is to say, to\ncases whose existence we are equally uncertain of, and in determining\nthe number of cases favourable to the event whose probability is\nsought. The ratio of this number to that of all possible cases is the\nmeasure of this probability, which is thus only a fraction whose\nnumerator is the number of favourable cases, and whose denominator is\nthe number of all possible cases. (1814; 1999, 4)\n\n\nWe may ask a number of questions about this formulation. When are\nevents of the same kind? Intuitively, \u2018heads\u2019 and\n\u2018tails\u2019 are equally likely outcomes of tossing a fair\ncoin; but if their kind is \u2018ways the coin could land\u2019,\nthen \u2018edge\u2019 should presumably be counted alongside them.\nThe \u201ccertain number of equally possible cases\u201d and\n\u201cthe number of all possible cases\u201d are presumably finite\nnumbers. What, then, of probabilities in infinite spaces? Apparently,\nirrational-valued probabilities such as \\(1/\\sqrt{2}\\) are\nautomatically eliminated, and thus theories such as quantum mechanics\nthat posit them cannot be accommodated. (We will shortly see, however,\nthat Laplace\u2019s theory has been refined to handle infinite\nspaces.)\n\nWho are \u201cwe\u201d, who \u201care equally uncertain\u201d?\nDifferent people may be equally undecided about different things,\nwhich suggests that Laplace is offering a subjectivist interpretation\nin which probabilities vary from person to person depending on\ncontingent differences in their evidence. Yet he means to characterize\nthe objective probability assignment of a rational agent in an\nepistemically neutral position with respect to a set of \u201cequally\npossible\u201d cases. But then the proposal risks sounding empty: for\nwhat is it for an agent to be \u201cequally uncertain\u201d\nabout a set of cases, other than assigning them equal probability?\n\nThis brings us to one of the key objections to Laplace\u2019s\naccount. The notion of \u201cequally possible\u201d cases faces the\ncharge of either being a category mistake (for\n\u2018possibility\u2019 does not come in degrees), or circular (for\nwhat is meant is really \u2018equally probable\u2019). The notion is\nfinessed by the so-called \u2018principle of indifference\u2019, a\ncoinage due to Keynes (although he was no friend of the principle):\n\u201cif there is no known reason for predicating of our subject one\nrather than another of several alternatives, then relatively to such\nknowledge the assertions of each of these alternatives have an equal\nprobability\u201d (1921, 52\u201353). (The \u2018principle of equal\nprobability\u2019 would be a better name.) Thus, it might be claimed,\nthere is no circularity in the classical interpretation after all.\nHowever, this move may only postpone the problem, for there is still a\nthreat of circularity, albeit at a lower level. We have two cases\nhere: outcomes for which we have no evidence\n(\u201creason\u201d) at all, and outcomes for which we have\nsymmetrically balanced evidence. There is no circularity in\nthe first case unless the notion of \u2018evidence\u2019 is itself\nprobabilistic; but artificial examples aside, it is doubtful that the\ncase ever arises. For example, we have a considerable fund of evidence\non coin tossing from the results of our own experiments, the testimony\nof others, our knowledge of some of the relevant physics, and so on.\nIn the second case, the threat of circularity is more apparent, for it\nseems that some sort of weighing of the evidence in favor of\neach outcome is required, and this seems to require a reference to\nprobability. Indeed, the most obvious characterization of\nsymmetrically balanced evidence is in terms of equality of conditional\nprobabilities: given evidence \\(E\\) and possible outcomes \\(O_1, O_2 ,\n\\ldots ,O_n\\), the evidence is symmetrically balanced iff \\(P(O_1\\mid\nE) = P(O_2\\mid E) = \\ldots = P(O_n\\mid E)\\). Then it seems that\nprobabilities reside at the base of the interpretation after all.\nStill, it would be an achievement if all probabilities could be\nreduced to cases of equal probability. See Zabell (2016) for further\ndiscussion of the classical interpretation and the principle of\nindifference.\n\nWhen the spaces are countably infinite, the spirit of the classical\ntheory may be upheld by appealing to the information-theoretic\nprinciple of maximum entropy, a generalization of the\nprinciple of indifference championed by Jaynes (1968). Entropy is a\nmeasure of the lack of \u2018informativeness\u2019 of a probability\nfunction. The more concentrated is the function, the less is its\nentropy; the more diffuse it is, the greater is its entropy. For a\ndiscrete assignment of probabilities \\(P = (p_1, p_2,\\ldots)\\), the\nentropy of \\(P\\) is defined as: \n\\[ -\\sum_i p_i\\log p_i \\]\n\n\n(For more explanation of this formula see the entry on\n Information.)\n\nThe principle of maximum entropy enjoins us to select from the family\nof all probability functions consistent with our background knowledge\nthe function that maximizes this quantity. In the special case of\nchoosing the most uninformative probability function over a finite set\nof possible outcomes, this is just the familiar \u2018flat\u2019\nclassical assignment discussed previously. Things get more complicated\nin the infinite case, since there cannot be a flat assignment over\ndenumerably many outcomes, on pain of violating the standard\nprobability calculus (with countable additivity). Rather, the best we\ncan have are sequences of progressively flatter assignments, none of\nwhich is truly flat. We must then impose some further\nconstraint that narrows the field to a smaller family in which there\nis an assignment of maximum\n entropy.[3]\n This constraint has to be imposed from outside as background\nknowledge, but there is no general theory of which external constraint\nshould be applied when. See Seidenfeld (1986) for mathematical results\nregarding maximum entropy and a critique of it.\n\nLet us turn now to uncountably infinite spaces. It is easy \u2014 all\ntoo easy \u2014 to assign equal probabilities to the points in such a\nspace: each gets probability 0. Non-trivial probabilities arise when\nuncountably many of the points are clumped together in larger sets. If\nthere are finitely many clumps, Laplace\u2019s classical theory may\nbe appealed to again: if the evidence bears symmetrically on these\nclumps, each gets the same share of probability.\n\nEnter Bertrand\u2019s paradoxes (1889). They all arise in uncountable\nspaces and turn on alternative parametrizations of a given problem\nthat are non-linearly related to each other. Some presentations are\nneedlessly arcane; length and area suffice to make the point. The\nfollowing example (adapted from van Fraassen 1989) nicely illustrates\nhow Bertrand-style paradoxes work. A factory produces cubes with\nside-length between 0 and 1 foot; what is the probability that a\nrandomly chosen cube has side-length between 0 and 1/2 a foot? The\nclassical intepretation\u2019s answer is apparently 1/2, as we\nimagine a process of production that is uniformly distributed over\nside-length. But the question could have been given an equivalent\nrestatement: A factory produces cubes with face-area between 0 and 1\nsquare-feet; what is the probability that a randomly chosen cube has\nface-area between 0 and 1/4 square-feet? Now the answer is apparently\n1/4, as we imagine a process of production that is uniformly\ndistributed over face-area. This is already disastrous, as we cannot\nallow the same event to have two different probabilities (especially\nif this interpretation is to be admissible!). But there is worse to\ncome, for the problem could have been restated equivalently again: A\nfactory produces cubes with volume between 0 and 1 cubic feet; what is\nthe probability that a randomly chosen cube has volume between 0 and\n1/8 cubic-feet? Now the answer is apparently 1/8, as we imagine a\nprocess of production that is uniformly distributed over volume. And\nso on for all of the infinitely many equivalent reformulations of the\nproblem (in terms of the fourth, fifth, \u2026 power of the length,\nand indeed in terms of every non-zero real-valued exponent of the\nlength). What, then, is the probability of the event in\nquestion?\n\nThe paradox arises because the principle of indifference can be used\nin incompatible ways. We have no evidence that favors the side-length\nlying in the interval [0, 1/2] over its lying in [1/2, 1], or vice\nversa, so the principle requires us to give probability 1/2 to each.\nUnfortunately, we also have no evidence that favors the face-area\nlying in any of the four intervals [0, 1/4], [1/4, 1/2], [1/2, 3/4],\nand [3/4, 1] over any of the others, so we must give probability 1/4\nto each. The event \u2018the side-length lies in [0, 1/2]\u2019,\nreceives a different probability when merely redescribed. And so it\ngoes, for all the other reformulations of the problem. We cannot meet\nany pair of these constraints simultaneously, let alone all of\nthem.\n\nJaynes attempts to save the principle of indifference and to extend\nthe principle of maximum entropy to the continuous case, with his\ninvariance condition: in two problems where we have the same\nknowledge, we should assign the same probabilities. He regards this as\na consistency requirement. For any problem, we have a group of\nadmissible transformations, those that change the problem into an\nequivalent form. Various details are left unspecified in the problem;\nequivalent formulations of it fill in the details in different ways.\nJaynes\u2019 invariance condition bids us to assign equal\nprobabilities to equivalent propositions, reformulations of one\nanother that are arrived at by such admissible transformations of our\nproblem. Any probability assignment that meets this condition is\ncalled an invariant assignment. Ideally, our problem will\nhave a unique invariant assignment. To be sure, things will not always\nbe ideal; but sometimes they are, in which case this is surely\nprogress on Bertrand-style problems.\n\nAnd in any case, for many garden-variety problems such technical\nmachinery will not be needed. Suppose I tell you that a prize is\nbehind one of three doors, and you get to choose a door. This seems to\nbe a paradigm case in which the principle of indifference works well:\nthe probability that you choose the right door is 1/3. It seems\nimplausible that we should worry about some reparametrization of the\nproblem that would yield a different answer. To be sure,\nBertrand-style problems caution us that there are limits to the\nprinciple of indifference. But arguably we must just be careful not to\noverstate its applicability.\n\nHow does the classical theory of probability fare with respect to our\ncriteria of adequacy? Let us begin with admissibility. (Laplacean)\nclassical probabilities obey non-negativity and normalization, but\nthey are only finitely additive (de Finetti 1974). So they do not obey\nthe full Kolmogorov probability calculus, but they provide an\ninterpretation of the elementary theory.\n\nClassical probabilities are ascertainable, assuming that the space of\npossibilities can be determined in principle. They bear a relationship\nto the credences of rational agents; the circularity concern, as we\nsaw above, is that the relationship is vacuous, and that rather than\nconstraining the credences of a rational agent in an\nepistemically neutral position, they merely record them.\n\nWithout supplementation, the classical theory makes no contact with\nfrequency information. However the coin happens to land in a sequence\nof trials, the possible outcomes remain the same. Indeed, even if we\nhave strong empirical evidence that the coin is biased towards heads\nwith probability, say, 0.6, it is hard to see how the unadorned\nclassical theory can accommodate this fact \u2014 for what now are\nthe ten possibilities, six of which are favorable to heads? Laplace\ndoes supplement the theory with his Rule of Succession: \u201cThus we\nfind that an event having occurred successively any number of times,\nthe probability that it will happen again the next time is equal to\nthis number increased by unity divided by the same number, increased\nby two units.\u201d (1951, 19) That is: \n\\[ Pr(\\text{success on } N+1^{\\text{st}}\\text{ trial}\\mid N\\text{ consec. succeses}) = \\frac{N+1}{N+2} \\]\n\n\nThus, inductive learning is possible \u2014 though not by classical\nprobabilities per se, but rather thanks to this further rule.\nAnd we must ask whether such learning can be captured once and for all\nby such a simple formula, the same for all domains and events. We will\nreturn to this question when we discuss the logical interpretation\nbelow.\n\nScience apparently invokes at various points probabilities that look\nclassical. Bose-Einstein statistics, Fermi-Dirac statistics, and\nMaxwell-Boltzmann statistics each arise by considering the ways in\nwhich particles can be assigned to states, and then applying the\nprinciple of indifference to different subdivisions of the set of\nalternatives, Bertrand-style. The trouble is that Bose-Einstein\nstatistics apply to some particles (e.g. photons) and not to others,\nFermi-Dirac statistics apply to different particles (e.g. electrons),\nand Maxwell-Boltzmann statistics do not apply to any known particles.\nNone of this can be determined a priori, as the classical\ninterpretation would have it. Moreover, the classical theory purports\nto yield probability assignments in the face of ignorance. But as Fine\n(1973) writes:\n\nIf we are truly ignorant about a set of alternatives, then we are also\nignorant about combinations of alternatives and about subdivisions of\nalternatives. However, the principle of indifference when applied to\nalternatives, or their combinations, or their subdivisions, yields\ndifferent probability assignments (170).\n\n\nThis brings us to one of the chief points of controversy regarding the\nclassical interpretation. Critics accuse the principle of indifference\nof extracting information from ignorance. Proponents reply that it\nrather codifies the way in which such ignorance should be\nepistemically managed \u2014 for anything other than an equal\nassignment of probabilities would represent the possession of some\nknowledge. Critics counter-reply that in a state of complete\nignorance, it is better to assign imprecise probabilities (perhaps\nranging over the entire [0, 1] interval), or to eschew the assignment\nof probabilities altogether.\n3.2 The Logical/Evidential Interpretation\n3.2.1 The logical interpretation\n\nLogical theories of probability retain the classical\ninterpretation\u2019s idea that probabilities can be determined a\npriori by an examination of the space of possibilities. However, they\ngeneralize it in two important ways: the possibilities may be assigned\nunequal weights, and probabilities can be computed whatever\nthe evidence may be, symmetrically balanced or not. Indeed, the\nlogical interpretation, in its various guises, seeks to encapsulate in\nfull generality the degree of support or confirmation that a piece of\nevidence \\(e\\) confers upon a given hypothesis \\(h\\), which we may\nwrite as \\(c(h, e)\\). In doing so, it can be regarded also as\ngeneralizing deductive logic and its notion of implication, to a\ncomplete theory of inference equipped with the notion of \u2018degree\nof implication\u2019 that relates \\(e\\) to \\(h\\). It is often called\nthe theory of \u2018inductive logic\u2019, although this is a\nmisnomer: there is no requirement that \\(e\\) be in any sense\n\u2018inductive\u2019 evidence for \\(h\\). \u2018Non-deductive\nlogic\u2019 would be a better name, but this overlooks the fact that\ndeductive logic\u2019s relations of implication and incompatibility\nare also accommodated as extreme cases in which the confirmation\nfunction takes the values 1 and 0 respectively. In any case, it is\nsignificant that the logical interpretation provides a framework for\ninduction.\n\nEarly proponents of logical probability include Johnson (1921), Keynes\n(1921), and Jeffreys (1939/1998). However, by far the most systematic\nstudy of logical probability was by Carnap. His formulation of logical\nprobability begins with the construction of a formal language. In\n(1950/1962) he considers a class of very simple languages consisting\nof a finite number of logically independent monadic predicates (naming\nproperties) applied to countably many individual constants (naming\nindividuals) or variables, and the usual logical connectives. The\nstrongest (consistent) statements that can be made in a given language\ndescribe all of the individuals in as much detail as the expressive\npower of the language allows. They are conjunctions of complete\ndescriptions of each individual, each description itself a conjunction\ncontaining exactly one occurrence (negated or unnegated) of each\npredicate of the language. Call these strongest statements state\ndescriptions.\n\nAny probability measure \\(m(-)\\) over the state descriptions\nautomatically extends to a measure over all sentences, since each\nsentence is equivalent to a disjunction of state descriptions; m in\nturn induces a confirmation function \\(c(-, -)\\): \n\\[ c(h,e) = \\frac{m(h \\amp e)}{m(e)} \\]\n\n\nThere are infinitely many candidates for \\(m\\), and hence \\(c\\), even\nfor very simple languages. Carnap argues for his favored measure\n\u201c\\(m^*\\)\u201d by insisting that the only thing that\nsignificantly distinguishes individuals from one another is some\nqualitative difference, not just a difference in labeling. Call a\nstructure description a maximal set of state descriptions,\neach of which can be obtained from another by some permutation of the\nindividual names. \\(m^*\\) assigns each structure description equal\nmeasure, which in turn is divided equally among their constituent\nstate descriptions. It gives greater weight to homogenous state\ndescriptions than to heterogeneous ones, thus \u2018rewarding\u2019\nuniformity among the individuals in accordance with putatively\nreasonable inductive practice. The induced \\(c^*\\) allows inductive\nlearning from experience.\n\nConsider, for example, a language that has three names, \\(a\\), \\(b\\)\nand \\(c\\), for individuals, and one predicate \\(F\\). For this\nlanguage, the state descriptions are: \n\\[\\begin{array}{crcrcr}\n1. & Fa &\\amp& Fb &\\amp& Fc \\\\\n 2. & \\neg Fa &\\amp& Fb &\\amp& Fc \\\\\n 3. & Fa &\\amp& \\neg Fb &\\amp& Fc \\\\\n 4. & Fa &\\amp& Fb &\\amp& \\neg Fc \\\\\n 5. & \\neg Fa &\\amp& \\neg Fb &\\amp& Fc \\\\\n 6. & \\neg Fa &\\amp& Fb &\\amp& \\neg Fc \\\\\n 7. & Fa &\\amp& \\neg Fb &\\amp& \\neg Fc \\\\\n 8. & \\neg Fa &\\amp& \\neg Fb &\\amp& \\neg Fc \\\\\n \n\\end{array}\\]\n\n\nThere are four structure descriptions: \n\\[\\begin{align}\n\\{1\\}, &\\text{ \u201cEverything is }F\\text{\u201d;} \\\\\n \\{2, 3, 4\\}, &\\text{ \u201cTwo } F\\text{s, one }\\neg F\\text{\u201d;} \\\\\n \\{5, 6, 7\\}, &\\text{ \u201cOne } F\\text{, two }\\neg F\\text{s\u201d; and} \\\\\n \\{8\\}, &\\text{ \u201cEverything is }\\neg F\\text{\u201d;} \\\\\n \n\\end{align}\\]\n\n\nThe measure \\(m^*\\) assigns numbers to the state descriptions as\nfollows: first, every structure description is assigned an equal\nweight, 1/4; then, each state description belonging to a given\nstructure description is assigned an equal part of the weight assigned\nto the structure description: \n\\[\\begin{array}{llll}\n\\textit{State description} & \\textit{Structure Description} & \\textit{Weight} & \\quad m^* \\\\\n \\left.\\begin{array}{l}\n1.\\ Fa.Fb.Fc \n\\end{array}\\right. & \\text{I. Everything is } F & 1/4 & \\quad 1/4 \\\\\n \\left.\\begin{array}{l}\n2.\\ \\neg Fa.Fb.Fc\\phantom{\\neg} \\\\\n 3.\\ Fa.\\neg Fb.Fc \\\\\n 4.\\ Fa.Fb.\\neg Fc \n\\end{array} \\right\\} & \\text{II. Two } F\\text{s, one }\\neg F & 1/4 & \\left\\{\\begin{array}{l}\n1/12 \\\\\n 1/12 \\\\\n 1/12 \n\\end{array}\\right. \\\\\n \\left.\\begin{array}{l}\n5.\\ \\neg Fa.\\neg Fb.Fc \\\\\n 6.\\ \\neg Fa.Fb.\\neg Fc \\\\\n 7.\\ Fa.\\neg Fb.\\neg Fc \n\\end{array} \\right\\} & \\text{III. One } F\\text{, two }\\neg F\\text{s} & 1/4 & \\left\\{\\begin{array}{l}\n1/12 \\\\\n 1/12 \\\\\n 1/12 \n\\end{array}\\right. \\\\\n \\left.\\begin{array}{l}\n8.\\ \\neg Fa.\\neg Fb.\\neg Fc \n\\end{array}\\right. & \\text{IV. Everything is } \\neg F & 1/4 & \\quad 1/4 \n\\end{array}\\]\n\n\nNotice that \\(m^*\\) gives greater weight to the homogenous state\ndescriptions 1 and 8 than to the heterogeneous ones. This will\nmanifest itself in the inductive support that hypotheses can gain from\nappropriate evidence statements. Consider the hypothesis statement \\(h\n= Fc\\), true in 4 of the 8 state descriptions, with a priori\nprobability \\(m^*(h) = 1/2\\). Suppose we examine individual\n\u201c\\(a\\)\u201d and find it has property \\(F\\) \u2014 call this\nevidence \\(e\\). Intuitively, \\(e\\) is favorable (albeit weak)\ninductive evidence for \\(h\\). We have: \\(m^*(h \\amp e) = 1/3,\\)\n\\(m^*(e) = 1/2\\), and hence \n\\[ c^*(h,e) = \\frac{m^*(h \\amp e)}{m^*(e)} = \\frac{2}{3}. \\]\n\n\nThis is greater than the a priori probability \\(m^*(h) =\n1/2\\), so the hypothesis has been confirmed. It can be shown that in\ngeneral \\(m^*\\) yields a degree of confirmation \\(c^*\\) that allows\nlearning from experience.\n\nNote, however, that infinitely many confirmation functions, defined by\nsuitable choices of the initial measure, allow learning from\nexperience. We do not have yet a reason to think that \\(c^*\\) is the\nright choice. Carnap claims nevertheless that \\(c^*\\) stands out for\nbeing simple and natural.\n\nHe later generalizes his confirmation function to a continuum of\nfunctions \\(c_{\\lambda}\\). Define a family of predicates to\nbe a set of predicates such that, for each individual, exactly one\nmember of the set applies, and consider first-order languages\ncontaining a finite number of families. Carnap (1963) focuses on the\nspecial case of a language containing only one-place predicates. He\nlays down a host of axioms concerning the confirmation function \\(c\\),\nincluding those induced by the probability calculus itself, various\naxioms of symmetry (for example, that \\(c(h, e)\\) remains unchanged\nunder permutations of individuals, and of predicates of any family),\nand axioms that guarantee undogmatic inductive learning, and long-run\nconvergence to relative frequencies. They imply that, for a family\n\\(\\{P_n\\},\\) \\(n = 1, \\ldots,k\\) \\((k \\gt 2){:}\\) \\[\nc_{\\lambda}(\\text{individual } s+1 \\text{ is } P_j,\\ s_j \\text{ of the\nfirst } s \\text{ individuals are }P_j) = \\frac{(s_j + \\lambda/k)}{s+\n\\lambda}, \\]\n\n\nwhere \\(\\lambda\\) is a positive real number. The higher the value of\n\\(\\lambda\\), the less impact evidence has: induction from what is\nobserved becomes progressively more swamped by a classical-style equal\nassignment to each of the \\(k\\) possibilities regarding individual \\(s\n+ 1\\).\n\nI turn to various objections to Carnap\u2019s program that have been\noffered in the literature, noting that this remains an area of lively\ndebate. (See Maher (2010) for rebuttals of some of these objections\nand for defenses of the program; see Fitelson (2006) for an overall\nassessment of the program.) Firstly, is there a correct setting of\n\\(\\lambda\\), or said another way, how \u2018inductive\u2019 should\nthe confirmation function be? The concern here is that any particular\nsetting of \\(\\lambda\\) is arbitrary in a way that compromises\nCarnap\u2019s claim to be offering a logical notion of\nprobability. Also, it turns out that for any such setting, a universal\nstatement in an infinite universe always receives zero confirmation,\nno matter what the (finite) evidence. Many find this counterintuitive,\nsince laws of nature with infinitely many instances can apparently be\nconfirmed. Earman (1992) discusses the prospects for avoiding the\nunwelcome result.\n\nSignificantly, Carnap\u2019s various axioms of symmetry are hardly\nlogical truths. Moreover, Fine (1973, 202) argues that we cannot\nimpose further symmetry constraints that are seemingly just as\nplausible as Carnap\u2019s, on pain of inconsistency. Goodman (1955)\ntaught us: that the future will resemble the past in some respect is\ntrivial; that it will resemble the past in all respects is\ncontradictory. And we may continue: that a probability assignment can\nbe made to respect some symmetry is trivial; that one can be made to\nrespect all symmetries is contradictory. This threatens the whole\nprogram of logical probability.\n\nAnother Goodmanian lesson is that inductive logic must be sensitive to\nthe meanings of predicates, strongly suggesting that a purely\nsyntactic approach such as Carnap\u2019s is doomed. Scott and Krauss\n(1966) use model theory in their formulation of logical probability\nfor richer and more realistic languages than Carnap\u2019s. Still,\nfinding a canonical language seems to many to be a pipe dream, at\nleast if we want to analyze the \u201clogical probability\u201d of\nany argument of real interest \u2014 either in science, or in\neveryday life.\n\nLogical probabilities are admissible. It is easily shown that they\nsatisfy finite additivity, and given that they are defined on finite\nsets of sentences, the extension to countable additivity is trivial.\nGiven a choice of language, the values of a given confirmation\nfunction are ascertainable; thus, if this language is rich enough for\na given application, the relevant probabilities are ascertainable. The\nwhole point of the theory of logical probability is to explicate\nampliative inference, although given the apparent arbitrariness in the\nchoice of language and in the setting of \\(\\lambda\\) \u2014 thus, in\nthe choice of confirmation function \u2014 one may wonder how well it\nachieves this. The problem of arbitrariness of the confirmation\nfunction also hampers the extent to which the logical interpretation\ncan truly illuminate the connection between probabilities and\nfrequencies.\n\nThe arbitrariness problem, moreover, stymies any compelling connection\nbetween logical probabilities and rational credences. And a further\nproblem remains even after the confirmation function has been chosen:\nif one\u2019s credences are to be based on logical probabilities,\nthey must be relativized to an evidence statement, \\(e\\). Carnap\nrequires that \\(e\\) be one\u2019s total evidence\u2014the\nmaximally specific information at one\u2019s disposal, the strongest\nproposition of which one is certain. But perhaps learning does not\ncome in the form of such \u2018bedrock\u2019 propositions, as\nJeffrey (1992) has argued \u2014 maybe it rather involves a shift in\none\u2019s subjective probabilities across a partition, without any\ncell of the partition becoming certain. Then it may be that the\nstrongest proposition of which one is certain is expressed by a\ntautology \\(T\\) \u2014 hardly an interesting notion of \u2018total\n evidence\u2019.[4]\n\nIn connection with the \u2018applicability to science\u2019\ncriterion, a point due to Lakatos is telling. By Carnap\u2019s\nlights, the degree of confirmation of a hypothesis depends on the\nlanguage in which the hypothesis is stated and over which the\nconfirmation function is defined. But scientific progress often brings\nwith it a change in scientific language (for example, the addition of\nnew predicates and the deletion of old ones), and such a change will\nbring with it a change in the corresponding \\(c\\)-values. Thus, the\ngrowth of science may overthrow any particular confirmation theory.\nThere is something of the snake eating its own tail here, since\nlogical probability was supposed to explicate the confirmation of\nscientific theories.\n\nWe have seen that the later Carnap relaxed his earlier aspiration to\nfind a unique confirmation function, allowing a continuum of\nsuch functions displaying a wide range of inductive cautiousness.\nVarious critics of logical probabilities believe that he did not go\nfar enough \u2014 that even his later systems constrain inductive\nlearning beyond what is rationally required. This recalls the classic\ndebate earlier in the 20th century between Keynes, a famous\nproponent of logical probabilities, and Ramsey, an equally famous\nopponent. Ramsey (1926; 1990) was skeptical of there being any\nnon-trivial relations of logical probability: he said that he could\nnot discern them himself, and that others disagree about them. This\nskepticism led him to formulate his enormously influential version of\nthe subjective interpretation of probability, to be discussed\nshortly.\n3.2.2 The evidential interpretation\n\nOne might insist, however, that there are non-trivial probabilistic\nevidential relations, even if they are not logical. It may\nnot be a matter of logic that the sun will probably rise\ntomorrow, given our evidence, yet there still seems to be an objective\nsense in which it probably will, given our evidence. In a crime\ninvestigation, there may be a fact of the matter of how strongly the\navailable evidence supports the guilt of various suspects. This does\nnot seem to be a matter of logic\u2014nor of physics, nor of what\nanyone happens to think, nor of how the facts in the actual world turn\nout. It seems to be a matter, rather, of evidential\nprobabilities.\n\nMore generally, Timothy Williamson (2000, 209) writes:\n\nGiven a scientific hypothesis \\(h\\), we can intelligibly ask: how\nprobable is \\(h\\) on present evidence? We are asking how much the\nevidence tells for or against the hypothesis. We are not asking what\nobjective physical chance or frequency of truth \\(h\\) has. A proposed\nlaw of nature may be quite improbable on present evidence even though\nits objective chance of truth is 1. That is quite consistent with the\nobvious point that the evidence bearing on \\(h\\) may include evidence\nabout objective chances or frequencies. Equally, in asking how\nprobable \\(h\\) is on present evidence, we are not asking about\nanyone\u2019s actual degree of belief in \\(h\\). Present evidence may\ntell strongly against \\(h\\), even though everyone is irrationally\ncertain of \\(h\\).\n\n\nWilliamson identifies one\u2019s evidence with what one knows.\nHowever, one might adopt other conceptions of evidence, and one might\neven take evidential probabilities to link any two propositions\nwhatsoever. Williamson maintains that evidential probabilities are not\nlogical\u2014in particular, they are not syntactically definable. He\nassumes an initial probability distribution \\(P\\), which\n\u201cmeasures something like the intrinsic plausibility of\nhypotheses prior to investigation\u201d (211). The evidential\nprobability of \\(h\\) on total evidence \\(e\\) is then given by\n\\(P(h\\mid e)\\).\n\nAre evidential probabilities admissible? Williamson says that \u201cP\nwill be assumed to satisfy a standard set of axioms for the\nprobability calculus\u201d (211). So admissibility is built into the\nvery specification of P. Are they ascertainable? He writes:\n\nWhat, then, are probabilities on evidence? We should resist demands\nfor an operational definition; such demands are as damaging in the\nphilosophy of science as they are in science itself. Sometimes the\nbest policy is to go ahead and theorize with a vague but powerful\nnotion. One\u2019s original intuitive understanding becomes refined\nas a result, although rarely to the point of a definition in precise\npretheoretic terms. That policy will be pursued here. (211)\n\n\nThis might be understood as rejecting ascertainability as a criterion\nof adequacy.\n\nHowever, some authors are skeptical that there are such things as\nevidential probabilities\u2014e.g. Joyce (2004). He also argues that\nthere is more than one sense in which evidence tells for or against a\nhypothesis. Bacon (2014) allows that there are such things as\nevidential probabilities, but he argues that various puzzling results\nfollow from Williamson\u2019s account of them, in virtue of its\nidentifying evidence with knowledge. Moreover, one may resist demands\nfor an operational definition of evidential probabilities,\nwhile seeking some further understanding of them in terms of other\ntheoretical concepts. For example, perhaps \\(P(h\\mid e)\\) is the\nsubjective probability that a perfectly rational agent with evidence\n\\(e\\) would assign to \\(h\\)? Williamson argues against this proposal;\nEder (2023) defends it, and she offers several ways of interpreting\nevidential probabilities in terms of ideal subjective probabilities.\nIf some such way is tenable, evidential probabilities would presumably\nenjoy whatever applicability that such subjective probabilities have.\nThis brings us to our next interpretation of probability.\n3.3 The Subjective Interpretation\n3.3.1 Probability as degree of belief\n\nNearly a century before Ramsey, De Morgan wrote: \u201cBy degree of\nprobability, we really mean, or ought to mean, degree of belief\u201d\n(1847, 172). According to the subjective (or\npersonalist or Bayesian) interpretation,\nprobabilities are degrees of confidence, or credences, or partial\nbeliefs of suitable agents. Thus, we really have many\ninterpretations of probability here\u2014 as many as there are\nsuitable agents. What makes an agent suitable? What we might call\nunconstrained subjectivism places no constraints on the\nagents \u2014 anyone goes, and hence anything goes. Various studies\nby psychologists are taken to show that people commonly violate the\nusual probability calculus in spectacular ways. (See, e.g., several\narticles in Kahneman et al. 1982.) We clearly do not have here an\nadmissible interpretation (with respect to any probability calculus),\nsince there is no limit to what degrees of confidence agents might\nhave.\n\nMore promising, however, is the thought that the suitable agents must\nbe, in a strong sense, rational. Following Ramsey, various\nsubjectivists have wanted to assimilate probability to logic by\nportraying probability as \u201cthe logic of partial belief\u201d\n(1926; 1990, 53 and 55). A rational agent is required to be logically\nconsistent, now taken in a broad sense. These subjectivists argue that\nthis implies that the agent obeys the axioms of probability (although\nperhaps with only finite additivity), and that subjectivism is thus\n(to this extent) admissible. Before we can present this argument, we\nmust say more about what degrees of belief are.\n3.3.2 The betting analysis and the Dutch Book argument\n\nSubjective probabilities have long been analyzed in terms of betting\nbehavior. Here is a classic statement by de Finetti (1980):\n\nLet us suppose that an individual is obliged to evaluate the rate\n\\(p\\) at which he would be ready to exchange the possession of an\narbitrary sum \\(S\\) (positive or negative) dependent on the occurrence\nof a given event \\(E\\), for the possession of the sum \\(pS\\); we will\nsay by definition that this number \\(p\\) is the measure of the degree\nof probability attributed by the individual considered to the event\n\\(E\\), or, more simply, that \\(p\\) is the probability of \\(E\\)\n(according to the individual considered; this specification can be\nimplicit if there is no ambiguity). (62)\n\n\nThis boils down to the following analysis:\n\nYour degree of belief in \\(E\\) is \\(p\\) iff \\(p\\) units of utility is\nthe price at which you would buy or sell a bet that pays 1 unit of\nutility if \\(E\\), 0 if not \\(E\\).\n\n\nThe analysis presupposes that, for any \\(E\\), there is exactly one\nsuch price \u2014 let\u2019s call this your fair price for\nthe bet on \\(E\\). This presupposition may fail. There may be no such\nprice \u2014 you may refuse to bet on \\(E\\) at all (perhaps unless\ncoerced, in which case your genuine opinion about \\(E\\) may not be\nrevealed), or your selling price may differ from your buying price, as\nmay occur if your probability for \\(E\\) is imprecise. There may be\nmore than one fair price \u2014 you may find a range of such prices\nacceptable, as may also occur if your probability for \\(E\\) is\nimprecise. For now, however, let us waive these concerns, and turn to\nan important argument that uses the betting analysis purportedly to\nshow that rational degrees of belief must conform to the probability\ncalculus (with at least finite additivity).\n\nA Dutch book is a series of bets bought and sold at prices\nthat collectively guarantee loss, however the world turns out. Suppose\nwe identify your credences with your betting prices. Ramsey notes, and\nit can be easily proven (e.g., Skyrms 1984), that if your credences\nviolate the probability calculus, then you are susceptible to a Dutch\nbook\u2014this is the Dutch Book Theorem. For example,\nsuppose that you violate the additivity axiom by assigning \\(P(A \\cup\nB) \\lt P(A) + P(B)\\), where \\(A\\) and \\(B\\) are mutually exclusive.\nThen a cunning bettor could buy from you a bet on \\(A \\cup B\\) for\n\\(P(A \\cup B)\\) units, and sell you bets on \\(A\\) and \\(B\\)\nindividually for \\(P(A)\\) and \\(P(B)\\) units respectively. He pockets\nan initial profit of \\(P(A) + P(B) - P(A \\cup B)\\), and retains it\nwhatever happens. Ramsey offers the following influential gloss:\n\u201cIf anyone\u2019s mental condition violated these laws [of the\nprobability calculus], his choice would depend on the precise form in\nwhich the options were offered him, which would be absurd.\u201d\n(1990, 78) The Dutch Book argument concludes: rationality requires\nyour credences to obey the probability calculus.\n\nThe argument is incomplete as it stands. As H\u00e1jek (2008, 2009b)\nobserves, the Dutch Book Theorem leaves open the possibility that you\nare susceptible to a Dutch Book whether or not your credences violate\nthe probability calculus\u2014perhaps we are all susceptible? Equally\nimportant, and often neglected, is the converse theorem that\nestablishes how you can avoid such a predicament. If your subjective\nprobabilities conform to the probability calculus, then no Dutch book\ncan be made against you (Kemeny 1955); your probability assignments\nare then said to be coherent. Williamson (1999) extends the\nDutch Book argument to countable additivity: if your credences violate\ncountable additivity, then you are susceptible to a Dutch book (with\ninfinitely many bets). Conformity to the full probability calculus\nthus seems to be necessary and sufficient for\n coherence.[5]\n We thus have an argument that rational credences provide an\ninterpretation of the full probability calculus, and thus an\nadmissible interpretation. Note, however, that de Finetti\u2014the\narch subjectivist and proponent of the Dutch Book argument\u2014was\nan opponent of countable additivity (e.g. in his 1974). See\nH\u00e1jek (2009b), Pettigrew (2020) and the entry on\n Dutch Book arguments\n for various objections to Dutch Book arguments for conformity to the\nprobability calculus and for other putative norms on credences.\n\nBut let us return to the betting analysis of credences. It is an\nattempt to make good on Ramsey\u2019s idea that probability \u201cis\na measurement of belief qua basis of action\u201d (67).\nWhile he regards the method of measuring an agent\u2019s credences by\nher betting behavior as \u201cfundamentally sound\u201d (68), he\nrecognizes that it has its limitations.\n\nThe betting analysis gives an operational definition of subjective\nprobability, and indeed it inherits some of the difficulties of\noperationalism in general, and of behaviorism in particular. For\nexample, you may have reason to misrepresent your true opinion, or to\nfeign having opinions that in fact you lack, by making the relevant\nbets (perhaps to exploit an incoherence in someone else\u2019s\nbetting prices). Moreover, as Ramsey points out, placing the very bet\nmay alter your state of opinion. Trivially, it does so regarding\nmatters involving the bet itself (e.g., you suddenly increase your\nprobability that you have just placed a bet). Less trivially, placing\nthe bet may change the world, and hence your opinions, in other ways.\nFor example, betting at high stakes on the proposition \u2018I will\nsleep well tonight\u2019 may suddenly turn you into an insomniac! And\nthen the bet may concern an event such that, were it to occur, you\nwould no longer value the pay-off the same way. (During the August 11,\n1999 solar eclipse in the UK, a man placed a bet that would have paid\na million pounds if the world came to an end.)\n\nThese problems stem largely from taking literally the notion of\nentering into a bet on \\(E\\), with its corresponding payoffs. The\nproblems may be avoided by identifying your degree of belief in a\nproposition with the betting price you regard as fair, whether or not\nyou enter into such a bet; it corresponds to the betting odds that you\nbelieve confer no advantage or disadvantage to either side of the bet\n(Howson and Urbach 1993). At your fair price, you should be\nindifferent between taking either\n side.[6]\n\nDe Finetti speaks of \u201can arbitrary sum\u201d as the prize of\nthe bet on \\(E\\). The sum had better be potentially infinitely\ndivisible, or else probability measurements will be precise only up to\nthe level of \u2018grain\u2019 of the potential prizes. For example,\na sum that can be divided into only 100 parts will leave probability\nmeasurements imprecise beyond the second decimal place, conflating\nprobabilities that should be distinguished (e.g., those of a logical\ncontradiction and of \u2018a fair coin lands heads 8 times in a\nrow\u2019). More significantly, if utility is not a linear function\nof such sums, then the size of the prize will make a difference to the\nputative probability: winning a dollar means more to a pauper more\nthan it does to Bill Gates, and this may be reflected in their betting\nbehaviors in ways that have nothing to do with their genuine\nprobability assignments. De Finetti responds to this problem by\nsuggesting that the prizes be kept small; that, however, only creates\nthe opposite problem that agents may be reluctant to bother about\ntrifles, as Ramsey points out.\n\nBetter, then, to let the prizes be measured in utilities: after all,\nutility is infinitely divisible, and utility is a linear function of\nutility. While we\u2019re at it, we should adopt a more liberal\nnotion of betting. After all, there is a sense in which every decision\nis a bet, as Ramsey observed.\n3.3.3 Probabilities and utilities\n\nUtilities (desirabilities) of outcomes, their probabilities, and\nrational preferences are all intimately linked. The Port Royal\nLogic (Arnauld, 1662) showed how utilities and probabilities\ntogether determine rational preferences; de Finetti\u2019s betting\nanalysis derives probabilities from utilities and rational\npreferences; von Neumann and Morgenstern (1944) derive utilities from\nprobabilities and rational preferences. And most remarkably, Ramsey\n(1926) (and later, Savage 1954 and Jeffrey 1966) derives both\nprobabilities and utilities from rational preferences\nalone.\n\nFirst, he defines a proposition to be ethically neutral\n\u2014 relative to an agent \u2014 if the agent is indifferent\nbetween the proposition\u2019s truth and falsehood. The agent\ndoesn\u2019t care about the ethically neutral proposition as such\n\u2014 it may be a means to an end that he might care about, but it\nhas no intrinsic value. (The result of a coin toss is typically like\nthis for most of us.) Now, there is a simple test for determining\nwhether, for a given agent, an ethically neutral proposition \\(N\\) has\nprobability 1/2. Suppose that the agent prefers \\(A\\) to \\(B\\). Then\n\\(N\\) has probability 1/2 iff the agent is indifferent between the\ngambles: \n\\[\\begin{align}\n& A \\text{ if } N, B \\text{ if not } \\\\\n & B \\text{ if } N, A \\text{ if not}. \\\\\n \n\\end{align}\\]\n\n\nRamsey assumes that it does not matter what the candidates for \\(A\\)\nand \\(B\\) are. We may assign arbitrarily to \\(A\\) and \\(B\\) any two\nreal numbers \\(u(A)\\) and \\(u(B)\\) such that \\(u(A) \\gt u(B)\\),\nthought of as the desirabilities of \\(A\\) and \\(B\\) respectively.\nHaving done this for the one arbitrarily chosen pair \\(A\\) and \\(B\\),\nthe utilities of all other propositions are determined.\n\nGiven various assumptions about the richness of the preference space,\nand certain \u2018consistency assumptions\u2019, he can define a\nreal-valued utility function of the outcomes \\(A, B\\), etc \u2014 in\nfact, various such functions will represent the agent\u2019s\npreferences. He is then able to define equality of differences in\nutility for any outcomes over which the agent has preferences. It\nturns out that ratios of utility-differences are invariant \u2014 the\nsame whichever representative utility function we choose. This fact\nallows Ramsey to define degrees of belief as ratios of such\ndifferences. For example, suppose the agent is indifferent between\n\\(A\\), and the gamble \u201c\\(B\\) if \\(X, C\\) otherwise\u201d. Then\nit follows from considerations of expected utility that her degree of\nbelief in \\(X, P(X)\\), is given by: \n\\[ P(X) = \\frac{u(A) - u(C)}{u(B) - u(C)} \\]\n\n\nRamsey shows that degrees of belief so derived obey the probability\ncalculus (with finite additivity).\n\nSavage (1954) likewise derives probabilities and utilities from\npreferences among options that are constrained by certain putative\n\u2018consistency\u2019 axioms. For a given set of such preferences,\nhe generates a class of utility functions, each a positive linear\ntransformation of the other (i.e. of the form \\(U_1 = aU_2 + b\\),\nwhere \\(a \\gt 0)\\), and a unique probability function. Together these\nare said to \u2018represent\u2019 the agent\u2019s preferences, and\nthe result that they do so is called a \u2018representation\ntheorem\u2019. Jeffrey (1966) refines Savage\u2019s approach. The\nresult is a theory of decision according to which rational choice\nmaximizes \u2018expected utility\u2019, a certain\nprobability-weighted average of utilities. (See Buchak 2016 for more\ndiscussion.) Some of the difficulties with the behavioristic betting\nanalysis of degrees of belief can now be resolved by moving to an\nanalysis of degrees of belief that is functionalist in spirit. For\nexample, according to Lewis (1986a, 1994a), an agent\u2019s credences\nare represented by the probability function belonging to a utility\nfunction/probability function pair that best rationalizes her\nbehavioral dispositions, rationality being given a decision-theoretic\nanalysis. Representation theorems (in one form or another) underpin\nrepresentation theorem arguments that rational agents\u2019\ncredences obey the probability calculus: their preferences obey the\nrequisite axioms, and thus their credences are representable that way.\nHowever, as well as being representable probabilistically, such\nagents\u2019 credences are representable\nnon-probabilistically; why should the probabilistic\nrepresentation be privileged? See Zynda (2000), H\u00e1jek (2008),\nand Meacham and Weisberg (2011) for this and other objections to\nrepresentation theorem arguments.\n\nThere is a deep issue that underlies all of these accounts of\nsubjective probability. They all presuppose the existence of necessary\nconnections between desire-like states and belief-like states,\nrendered explicit in the connections between preferences and\nprobabilities. In response, one might insist that such connections are\nat best contingent, and indeed can be imagined to be absent. Think of\nan idealized Zen Buddhist monk, devoid of any preferences, who\ndispassionately surveys the world before him, forming beliefs but no\ndesires. It could be replied that such an agent is not so easily\nimagined after all \u2014 even if the monk does not value worldly\ngoods, he will still prefer some things to others (e.g., truth to\nfalsehood).\n\nOnce desires enter the picture, they may also have unwanted\nconsequences. Again, how does one separate an agent\u2019s enjoyment\nor disdain for gambling from the value she places on the gamble\nitself? Ironically, a remark that Ramsey makes in his critique of the\nbetting analysis seems apposite here: \u201cThe difficulty is like\nthat of separating two different co-operating forces\u201d (1990,\n68). See Eriksson and H\u00e1jek (2007) for further criticism of\npreference-based accounts of credence.\n\nThe betting analysis makes subjective probabilities ascertainable to\nthe extent that an agent\u2019s betting dispositions are\nascertainable. The derivation of them from preferences makes them\nascertainable to the extent that his or her preferences are known.\nHowever, it is unclear that an agent\u2019s full set of preferences\nis ascertainable even to himself or herself. Here a lot of weight may\nneed to be placed on the \u2018in principle\u2019 qualification in\nthe ascertainability criterion. The expected utility representation\nmakes it virtually analytic that an agent should be guided by\nprobabilities \u2014 after all, the probabilities are her own, and\nthey are fed into the formula for expected utility in order to\ndetermine what it is rational for her to do. So the applicability to\nrational decision criterion is clearly met.\n3.3.4 Orthodox Bayesianism, and further constraints on rational credences\n\nBut do they function as a good guide? Here it is useful to\ndistinguish different versions of subjectivism. Orthodox\nBayesians in the style of de Finetti recognize no rational\nconstraints on subjective probabilities beyond:\n\nconformity to the probability calculus, and\na rule for updating probabilities in the face of new evidence,\nknown as conditioning or conditionalizing. An agent\nwith probability function \\(P_1\\), who becomes certain of a piece of\nevidence \\(E\\) (and nothing stronger), should shift to a new\nprobability function \\(P_2\\) related to \\(P_1\\) by:\n \n\\[\\tag{Conditioning} P_2(X) = P_1(X \\mid E),\\text{ provided }P_1(E) \\gt 0. \\]\n\n\nThis is a permissive epistemology, licensing doxastic states that we\nwould normally call crazy. Thus, you could assign probability 1 to\nthis sentence ruling the universe, while upholding such extreme\nsubjectivism.\n\nSome subjectivists impose the further rationality requirement of\nregularity: anything that is possible (in an appropriate\nsense) gets assigned positive probability. It is advocated by authors\nsuch as Jeffreys (1939/1998), Kemeny (1955), Edwards et al. (1963),\nShimony (1970), and Stalnaker (1970). It is meant to capture a form of\nopen-mindedness and responsiveness to evidence. But then, perhaps\nunintuitively, someone who assigns probability 0.999 to this sentence\nruling the universe can be judged rational, while someone who assigns\nit probability 0 is judged irrational. See, e.g., Levi (1978) for\nfurther opposition to regularity.\n\nProbabilistic coherence plays much the same role for degrees of belief\nthat consistency plays for ordinary, all-or-nothing beliefs.\nWhat an extreme subjectivist, even one who demands regularity, lacks\nis an analogue of truth, some yardstick for distinguishing\nthe \u2018veridical\u2019 probability assignments from the rest\n(such as the 0.999 one above), some way in which probability\nassignments are answerable to the world. It seems, then, that the\nsubjectivist needs something more.\n\nAnd various subjectivists offer more. Having isolated the\n\u201clogic\u201d of partial belief as conformity to the probability\ncalculus, Ramsey goes on to discuss what makes a degree of belief in a\nproposition reasonable. After canvassing several possible\nanswers, he settles upon one that focuses on habits of\nopinion formation \u2014 \u201ce.g. the habit of proceeding from the\nopinion that a toadstool is yellow to the opinion that it is\nunwholesome\u201d (50). He then asks, for a person with this habit,\nwhat probability it would be best for him to have that a given yellow\ntoadstool is unwholesome, and he answers that \u201cit will in\ngeneral be equal to the proportion of yellow toadstools which are in\nfact unwholesome\u201d (1990, 91). This resonates with more recent\nproposals (e.g., van Fraassen 1984, Shimony 1988) for evaluating\ndegrees of belief according to how closely they match the\ncorresponding relative frequencies \u2014 in the jargon, how well\ncalibrated they are. Since relative frequencies obey the\naxioms of probability (up to finite additivity), it is thought that\nrational credences, which strive to track them, should do so\n also.[7]\n\nHowever, rational credences may strive to track various things. For\nexample, we are often guided by the opinions of experts. We consult\nour doctors on medical matters, our weather forecasters on\nmeteorological matters, and so on. Gaifman (1988) coins the terms\n\u201cexpert assignment\u201d and \u201cexpert probability\u201d\nfor a probability assignment that a given agent strives to track:\n\u201cThe mere knowledge of the [expert] assignment will make the\nagent adopt it as his subjective probability\u201d (193). This idea\nmay be codified as follows: \n\\[\\begin{align}\n\\tag{Expert} &P(A\\mid pr(A)=x) = x, \\\\\n &\\text{for all } x \\text{ where this is defined}. \n\\end{align}\\]\n\n\nwhere \u2018\\(P\\)\u2019 is the agent\u2019s subjective probability\nfunction, and \u2018\\(pr(A)\\)\u2019 is the assignment that the agent\nregards as expert. For example, if you regard the local weather\nforecaster as an expert on your local weather, and she assigns\nprobability 0.1 to it raining tomorrow, then you may well follow\nsuit: \n\\[ P(\\textit{rain}\\mid pr(\\textit{rain}) = 0.1) = 0.1 \\]\n\n\nMore generally, we might speak of an entire probability function as\nbeing such a guide for an agent over a specified set of propositions.\nVan Fraassen (1989, 198) gives us this definition: \u201cIf \\(P\\) is\nmy personal probability function, then \\(q\\) is an expert function\nfor me concerning family \\(F\\) of propositions exactly if \\(P(A\n\\mid q(A) = x) = x\\) for all propositions \\(A\\) in family\n\\(F\\).\u201d\n\nLet us define a universal expert function for a\ngiven rational agent as one that would guide all of that\nagent\u2019s probability assignments in this way: an expert function\nfor the agent concerning all propositions. van Fraassen (1984, 1995a),\nfollowing Goldstein (1983), argues that an agent\u2019s future\nprobability functions are universal expert functions for that\nagent. He enshrines this idea in his Reflection Principle,\nwhere P is the agent\u2019s probability and \\(P_{t}\\) is her\nfunction at a later time \\(t\\): \n\\[\\begin{align}\n&P (A \\mid P_t(A) = x) = x, \\\\\n &\\text{for all } t, A \\text{ and } x \\text{ for which this is defined.} \n\\end{align}\\]\n\n\nThe principle encapsulates a certain demand for \u2018diachronic\ncoherence\u2019 imposed by rationality. Van Fraassen defends it with\na \u2018diachronic\u2019 Dutch Book argument (one that considers\nbets placed at different times), and by analogizing violations of it\nto the sort of pragmatic inconsistency that one finds in Moore\u2019s\nparadox.\n\nWe may go still further. There may be universal expert functions for\nlarge classes of rational agents, and perhaps all of them. The\nPrinciple of Direct Probability regards the relative\nfrequency function as a universal expert function for all\nrational agents; we have already seen the importance that proponents\nof calibration place on it. Let \\(A\\) be an event-type, and let\nrelfreq\\((A)\\) be the relative frequency of \\(A\\) (in some\nsuitable reference class). Then for any rational agent with\nprobability function \\(P\\), we have (cf. Hacking 1965):\n\n\\[\\begin{align}\n&P(A\\mid \\textit{relfreq}(A) = x) = x, \\\\\n &\\text{for all } A \\text{ and for all } x \\text{ where this is defined.} \n\\end{align}\\]\n\n\nLewis (1980) posits a similar expert role for the objective chance\nfunction, ch, for all rational initial credences in his\nPrincipal Principle (here\n simplified[8]):\n \n\\[\\begin{align}\n&C(A\\mid \\textit{ch}(A) = x) = x, \\\\\n &\\text{for all } A \\text{ and for all } x \\text{ where this is defined.} \n\\end{align}\\]\n\n\n\u2018\\(C\\)\u2019 denotes the \u2018ur\u2019 credence function of\nan agent at the beginning of enquiry. This is an idealization that\nensures that the agent does not have any \u201cinadmissible\u201d\nevidence that bears on \\(A\\) without bearing on the chance of \\(A\\).\nFor example, a rational agent who somehow knows that a particular coin\ntoss lands heads is surely not required to assign\n\n\\[ C(\\text{heads} \\mid \\textit{ch}(\\text{heads}) = \\frac{1}{2}) = \\frac{1}{2}. \\]\n\n\nRather, this conditional probability should be 1, since she has\ninformation relevant to the outcome \u2018heads\u2019 that trumps\nits chance. The other expert principles surely need to be suitably\nqualified \u2013 otherwise they face analogous counterexamples. Yet\nstrangely, the Principal Principle is the only expert principle about\nwhich concerns about inadmissible evidence have been raised in the\nliterature.\n\nI will say more about relative frequencies and chance shortly.\n\nThe ultimate expert, presumably, is the truth function\n\u2014 the function that assigns 1 to all the true propositions and 0\nto all the false ones. Knowledge of its values should surely trump\nknowledge of the values assigned by human experts (including\none\u2019s future selves), frequencies, or chances. Note that for any\nputative expert \\(q\\), \n\\[\\begin{align}\n&P(A\\mid q(A) = x \\,\\cap\\, A) = 1, \\\\\n &\\text{for all } A \\text{ and for all } x \\text{ where this is defined.} \n\\end{align}\\]\n\n\n\u2014 the truth of \\(A\\) overrides anything the expert might say. So\nall of the proposed expert probabilities above should really be\nregarded as defeasible. Joyce (1998) portrays the rational agent as\nestimating truth values, seeking to minimize a measure of distance\nbetween them and her probability assignments\u2014that is, to\nmaximize the accuracy of those assignments. Generalizing a\ntheorem of de Finetti\u2019s (1974), he shows that for any measure of\ndistance that satisfies certain intuitive properties, any agent who\nviolates the probability axioms could serve this epistemic goal better\nby obeying them instead, however the world turns out. In short,\nnon-probabilistic credences are accuracy-dominated by\nprobabilistic credences. This provides a \u201cnon-pragmatic\u201d\nargument for probabilism (in contrast to the Dutch Book and\nrepresentation theorem arguments) for finite domains. Nielsen (2023)\nextends a related accuracy argument by Predd et al. (2009), with\ndifferent conditions on accuracy measures, to arbitrarily large\ndomains.\n\nThere are some unifying themes in these putative constraints on\nsubjective probability. An agent\u2019s degrees of belief determine\nher estimates of certain quantities: the values of bets, or the\ndesirabilities of gambles more generally, or the probability\nassignments of various \u2018experts\u2019 \u2014 humans, relative\nfrequencies, objective chances, or truth values. The laws of\nprobability then are claimed to be constraints on these estimates:\nputative necessary conditions for minimizing her \u2018losses\u2019\nin a broad sense, be they monetary, or measured by distances from the\nassignments of these experts.\n3.3.5 Objective Bayesianism\n\nWe have been gradually adding more and more constraints on rational\ncredences, putatively demanded by rationality. Recall that Carnap\nfirst assumed that there was a unique confirmation function, and then\nrelaxed this assumption to allow a plurality of such functions. We now\nseem to be heading in the opposite direction: starting with the\nextremely permissive orthodox Bayesianism, we are steadily reducing\nthe class of rationally permissible credence functions. So far the\nconstraints that we have admitted have not been especially\nevidence-driven. Objective Bayesians maintain that a\nrational agent\u2019s credences are largely determined by her\nevidence.\n\nHow large is \u201clargely\u201d? The lines of demarcation are not\nsharp, and subjective Bayesianism may be regarded as a somewhat\nindeterminate region on a spectrum of views that morph into objective\nBayesianism. At one end lies an extreme form of subjective\nBayesianism, according to which rational credences are constrained\nonly by the probability calculus (and updating by conditionalization).\nAt the other of the spectrum lies an extreme form of objective\nBayesianism, according to which rational probabilities are constrained\nto the point of uniqueness by one\u2019s evidence\u2014we may call\nthis the Uniqueness Thesis. But both objective Bayesians and\nsubjective Bayesians may adopt less extreme positions, and typically\ndo. For example, Jon Williamson (2010) is an objective Bayesian, but\nnot an extreme one. He adds to the probability calculus the\nconstraints of being calibrated with evidence, and otherwise\nequivocating between basic outcomes, especially appealing to versions\nof maximum entropy. As such, his view is a descendant of the classical\ninterpretation and its generalization due to Jaynes.\n3.4 Frequency Interpretations\n\nGamblers, actuaries and scientists have long understood that relative\nfrequencies bear an intimate relationship to probabilities. Frequency\ninterpretations posit the most intimate relationship of all: identity.\nThus, we might identify the probability of \u2018heads\u2019 on a\ncertain coin with the number of heads in a suitable sequence of tosses\nof the coin, divided by the total number of tosses. A simple version\nof frequentism, which we will call finite frequentism,\nattaches probabilities to events or attributes in a finite reference\nclass in such a straightforward manner:\n\nthe probability of an attribute A in a finite reference class B is\nthe relative frequency of actual occurrences of A within B.\n\n\nThus, finite frequentism bears certain structural similarities to the\nclassical interpretation, insofar as it gives equal weight to each\nmember of a set of events, simply counting how many of them are\n\u2018favorable\u2019 as a proportion of the total. The crucial\ndifference, however, is that where the classical interpretation\ncounted all the possible outcomes of a given experiment,\nfinite frequentism counts actual outcomes. It is thus\ncongenial to those with empiricist scruples. It was developed by Venn\n(1876), who in his discussion of the proportion of births of males and\nfemales, concludes: \u201cprobability is nothing but that\nproportion\u201d (p. 84, his\n emphasis).[9])\n Finite frequentism is often assumed, tacitly or explicitly, in\nstatistics and in the sciences more generally.\n\nFinite frequentism gives an operational definition of probability, and\nits problems begin there. For example, just as we want to allow that\nour thermometers could be ill-calibrated, and could thus give\nmisleading measurements of temperature, so we want to allow that our\n\u2018measurements\u2019 of probabilities via frequencies could be\nmisleading, as when a fair coin lands heads 9 out of 10 times. More\nthan that, it seems to be built into the very notion of probability\nthat such misleading results can arise. Indeed, in many cases,\nmisleading results are guaranteed. Starting with a degenerate case:\naccording to the finite frequentist, a coin that is never tossed, and\nthat thus yields no actual outcomes whatsoever, lacks a probability\nfor heads altogether; yet a coin that is never measured does not\nthereby lack a diameter. Perhaps even more troubling, a coin that is\ntossed exactly once yields a relative frequency of heads of either 0\nor 1, whatever its bias. Or we can imagine a unique radiocative atom\nwhose probabilities of decaying at various times obey a continuous law\n(e.g. exponential); yet according to finite frequentism, with\nprobability 1 it decays at the exact time that it actually\ndoes, for its relative frequency of doing so is 1/1. Famous enough to\nmerit a name of its own, these are instances of the so-called\n\u2018problem of the single case\u2019. In fact, many events are\nmost naturally regarded as not merely unrepeated, but in a strong\nsense unrepeatable \u2014 the 2020 presidential election,\nthe final game of the 2019 NBA play-offs, the Civil War,\nKennedy\u2019s assassination, certain events in the very early\nhistory of the universe, and so on. Nonetheless, it seems natural to\nthink of non-extreme probabilities attaching to some, and perhaps all,\nof them. Worse still, some cosmologists regard it as a genuinely\nchancy matter whether our universe is open or closed (apparently\ncertain quantum fluctuations could, in principle, tip it one way or\nthe other), yet whatever it is, it is \u2018single-case\u2019 in the\nstrongest possible sense.\n\nThe problem of the single case is particularly striking, but we really\nhave a sequence of related problems: \u2018the problem of the double\ncase\u2019, \u2018the problem of the triple case\u2019 \u2026\nEvery coin that is tossed exactly twice can yield only the relative\nfrequencies 0, 1/2 and 1, whatever its bias\u2026 According to\nactual frequentism, it is an analytic truth that every coin that is\ntossed an odd number of times is biased. A finite reference class of\nsize \\(n\\), however large \\(n\\) is, can only produce relative\nfrequencies at a certain level of \u2018grain\u2019, namely \\(1/n\\).\nAmong other things, this rules out irrational-valued probabilities;\nyet our best physical theories say otherwise. Furthermore, there is a\nsense in which any of these problems can be transformed into the\nproblem of the single case. Suppose that we toss a coin a thousand\ntimes. We can regard this as a single trial of a\nthousand-tosses-of-the-coin experiment. Yet we do not want to be\ncommitted to saying that that experiment yields its actual\nresult with probability 1.\n\nThe problem of the single case is that the finite frequentist fails to\nsee intermediate probabilities in various places where others do.\nThere is also the converse problem: the frequentist sees intermediate\nprobabilities in various places where others do not. Our world has\nmyriad different entities, with myriad different attributes. We can\ngroup them into still more sets of objects, and then ask with which\nrelative frequencies various attributes occur in these sets. Many such\nrelative frequencies will be intermediate; the finite frequentist\nautomatically identifies them with intermediate probabilities. But it\nwould seem that whether or not they are genuine\nprobabilities, as opposed to mere tallies, depends on the\ncase at hand. Bare ratios of attributes among sets of disparate\nobjects may lack the sort of modal force that one might expect from\nprobabilities. I belong to the reference class consisting of myself,\nthe Eiffel Tower, the southernmost sandcastle on Santa Monica Beach,\nand Mt Everest. Two of these four objects are less than 7 feet tall, a\nrelative frequency of 1/2; moreover, we could easily extend this\nclass, preserving this relative frequency (or, equally easily, not).\nYet it would be odd to say that my probability of being less\nthan 7 feet tall, relative to this reference class, is 1/2, although\nit is perfectly acceptable (if uninteresting) to say that 1/2 of the\nobjects in the reference class are less than 7 feet tall.\n\nSome frequentists (notably Venn 1876, Reichenbach 1949, and von Mises\n1957 among others), partly in response to some of the problems above,\nhave gone on to consider infinite reference classes,\nidentifying probabilities with limiting relative frequencies\nof events or attributes therein. Thus, we require an infinite sequence\nof trials in order to define such probabilities. But what if the\nactual world does not provide an infinite sequence of trials of a\ngiven experiment? Indeed, that appears to be the norm, and perhaps\neven the rule. In that case, we are to identify probability with a\nhypothetical or counterfactual limiting relative\nfrequency. We are to imagine hypothetical infinite extensions of an\nactual sequence of trials; probabilities are then what the limiting\nrelative frequencies would be if the sequence were so\nextended. We might thus call this interpretation hypothetical\nfrequentism:\n\nthe probability of an attribute A in a reference class B is the\nvalue the limiting relative frequency of occurrences of A within B\nwould be if B were infinite.\n\n\nNote that at this point we have left empiricism behind. A modal\nelement has been injected into frequentism with this invocation of a\ncounterfactual; moreover, the counterfactual may involve a radical\ndeparture from the way things actually are, one that may even require\nthe breaking of laws of nature. (Think what it would take for the coin\nin my pocket, which has only been tossed once, to be tossed infinitely\nmany times \u2014 never wearing out, and never running short of\npeople willing to toss it!) One may wonder, moreover, whether there is\nalways \u2014 or ever \u2014 a fact of the matter of what such\ncounterfactual relative frequencies are.\n\nLimiting relative frequencies, we have seen, must be relativized to a\nsequence of trials. Herein lies another difficulty. Consider an\ninfinite sequence of the results of tossing a coin, as it might be H,\nT, H, H, H, T, H, T, T, \u2026 Suppose for definiteness that the\ncorresponding relative frequency sequence for heads, which begins 1/1,\n1/2, 2/3, 3/4, 4/5, 4/6, 5/7, 5/8, 5/9, \u2026, converges to 1/2. By\nsuitably reordering these results, we can make the sequence converge\nto any value in [0, 1] that we like. (If this is not obvious, consider\nhow the relative frequency of even numbers among positive integers,\nwhich intuitively \u2018should\u2019 converge to 1/2, can instead be\nmade to converge to 1/4 by reordering the integers with the even\nnumbers in every fourth place, as follows: 1, 3, 5, 2, 7, 9, 11, 4,\n13, 15, 17, 6, \u2026) To be sure, there may be something natural\nabout the ordering of the tosses as given \u2014 for example, it may\nbe their temporal ordering. But there may be more than one\nnatural ordering. Imagine the tosses taking place on a train that\nshunts backwards and forwards on tracks that are oriented west-east.\nThen the spatial ordering of the results from west to east\ncould look very different. Why should one ordering be privileged over\nothers?\n\nA well-known objection to any version of frequentism is that\nrelative frequencies must be relativised to a\nreference class. Consider a probability concerning myself that I care\nabout \u2014 say, my probability of living to age 80. I belong to the\nclass of males, the class of non-smokers, the class of philosophy\nprofessors who have two vowels in their surname, \u2026 Presumably\nthe relative frequency of those who live to age 80 varies across (most\nof) these reference classes. What, then, is my probability of living\nto age 80? It seems that there is no single frequentist answer.\nInstead, there is my probability-qua-male, my\nprobability-qua-non-smoker, my probability-qua-male-non-smoker, and so\non. This is an example of the so-called reference class\nproblem for frequentism (although it can be argued that analogues\nof the problem arise for the other interpretations as\n well[10]).\n And as we have seen in the previous paragraph, the problem is only\ncompounded for limiting relative frequencies: probabilities must be\nrelativized not merely to a reference class, but to a sequence within\nthe reference class. We might call this the reference sequence\nproblem.\n\nThe beginnings of a solution to this problem would be to restrict our\nattention to sequences of a certain kind, those with certain desirable\nproperties. For example, there are sequences for which the limiting\nrelative frequency of a given attribute does not exist; Reichenbach\nthus excludes such sequences. Von Mises (1957) gives us a more\nthoroughgoing restriction to what he calls collectives\n\u2014 hypothetical infinite sequences of attributes (possible\noutcomes) of specified experiments that meet certain requirements.\nCall a place-selection an effectively specifiable method of\nselecting indices of members of the sequence, such that the selection\nor not of the index \\(i\\) depends at most on the first \\(i - 1\\)\nattributes. Von Mises imposes these axioms:\n\nAxiom of Convergence: the limiting relative frequency of any\nattribute exists.\n\n\nAxiom of Randomness: the limiting relative frequency of each\nattribute in a collective \\(\\omega\\) is the same in any infinite\nsubsequence of \\(\\omega\\) which is determined by a place\nselection.\n\n\nThe probability of an attribute \\(A\\), relative to a collective\n\\(\\omega\\), is then defined as the limiting relative frequency of\n\\(A\\) in \\(\\omega\\). Note that a constant sequence such as H, H, H,\n\u2026, in which the limiting relative frequency is the same in\nany infinite subsequence, trivially satisfies the axiom of\nrandomness. This puts some strain on the terminology \u2014 offhand,\nsuch sequences appear to be as non-random as they come\n\u2014 although to be sure it is desirable that probabilities be\nassigned even in such sequences. Be that as it may, there is a\nparallel between the role of the axiom of randomness in von\nMises\u2019 theory and the principle of maximum entropy in the\nclassical theory: both attempt to capture a certain notion of\ndisorder.\n\nCollectives are abstract mathematical objects that are not empirically\ninstantiated, but that are nonetheless posited by von Mises to explain\nthe stabilities of relative frequencies in the behavior of actual\nsequences of outcomes of a repeatable random experiment. Church (1940)\nrenders precise the notion of a place selection as a recursive\nfunction. Nevertheless, the reference sequence problem remains:\nprobabilities must always be relativized to a collective, and for a\ngiven attribute such as \u2018heads\u2019 there are infinitely many.\nVon Mises embraces this consequence, insisting that the notion of\nprobability only makes sense relative to a collective. In particular,\nhe regards single case probabilities as nonsense: \u201cWe can say\nnothing about the probability of death of an individual even if we\nknow his condition of life and health in detail. The phrase\n\u2018probability of death\u2019, when it refers to a single person,\nhas no meaning at all for us\u201d (11). Some critics believe that\nrather than solving the problem of the single case, this merely\nignores it. And note that von Mises drastically understates the\ncommitments of his theory: by his lights, the phrase\n\u2018probability of death\u2019 also has no meaning at all when it\nrefers to a million people, or a billion, or any finite number \u2014\nafter all, collectives are infinite. More generally, it seems\nthat von Mises\u2019 theory has the unwelcome consequence that\nprobability statements never have meaning in the real world, for\napparently all sequences of attributes are finite.\n\nLet us see how the frequentist interpretations fare according to our\ncriteria of adequacy. Finite relative frequencies of course satisfy\nfinite additivity. In a finite reference class, only finitely many\nevents can occur, so only finitely many events can have positive\nrelative frequency. In that case, countable additivity is satisfied\nsomewhat trivially: all but finitely many terms in the infinite sum\nwill be 0. Limiting relative frequencies violate countable additivity\n(de Finetti 1972, \u00a75.22). Indeed, the domain of definition of\nlimiting relative frequency is not even a field, let alone a sigma\nfield (de Finetti 1972, \u00a75.8). So such relative frequencies do\nnot provide an admissible interpretation of Kolmogorov\u2019s axioms.\nFinite frequentism has no trouble meeting the ascertainability\ncriterion, as finite relative frequencies are in principle easily\ndetermined. The same cannot be said of limiting relative frequencies.\nOn the contrary, any finite sequence of trials (which, after all, is\nall we ever see) puts literally no constraint on the limit of an\ninfinite sequence; still less does an actual finite sequence\nput any constraint on the limit of an infinite hypothetical\nsequence, however fast and loose we play with the notion of \u2018in\nprinciple\u2019 in the ascertainability criterion.\n\nIt might seem that the frequentist interpretations resoundingly meet\nthe applicability to frequencies criterion. Finite frequentism meets\nit all too well, while hypothetical frequentism meets it in the wrong\nway. If anything, finite frequentism makes the connection between\nprobabilities and frequencies too tight, as we have already\nobserved. A fair coin that is tossed a million times is very\nunlikely to land heads exactly half the time; one\nthat is tossed a million and one times is even less likely to do so!\nFacts about finite relative frequencies should serve as evidence, but\nnot conclusive evidence, for the relevant probability\nassignments. Hypothetical frequentism fails to connect probabilities\nwith finite frequencies. It connects them with limiting relative\nfrequencies, of course, but again too tightly: for even in infinite\nsequences, the two can come apart. (A fair coin could land heads\nforever, even if it is highly unlikely to do so.) To be sure, science\nhas much interest in finite frequencies, and indeed working with them\nis much of the business of statistics. Whether it has any interest in\nhighly idealized, hypothetical extensions of actual sequences, and\nrelative frequencies therein, is another matter. The applicability to\nrational beliefs and to rational decisions go much the same way. Such\nbeliefs and decisions are guided by finite frequency information, but\nthey are not guided by information about limits of\nhypothetical frequencies, since one never has such information. For\nmuch more extensive critiques of finite frequentism and hypothetical\nfrequentism, see H\u00e1jek (1997) and H\u00e1jek (2009)\nrespectively, and La Caze (2016).\n3.5 Propensity Interpretations\n\nLike the frequency interpretations, propensity\ninterpretations regard probabilities as objective properties of\nentities in the real world. Probability is thought of as a physical\npropensity, or disposition, or tendency of a given type of physical\nsituation to yield an outcome of a certain kind, or to yield a long\nrun relative frequency of such an outcome.\n\nWhile Popper (1957) is often credited as being the pioneer of\npropensity interpretations, we already find the key idea in the\nwritings of Peirce (1910, 79\u201380): \u201cI am, then, to define\nthe meaning of the statement that the probability, that if a\ndie be thrown from a dice box it will turn up a number divisible by\nthree, is one-third. The statement means that the die has a certain\n\u2018would-be\u2019; and to say that the die has a\n\u2018would-be\u2019 is to say that it has a property, quite\nanalogous to any habit that a man might have.\u201d A\nman\u2019s habit is a paradigmatic example of a disposition;\naccording to Peirce the die\u2019s probability of landing 3 or 6 is\nan analogous disposition. We might think of various habits coming in\ndifferent degrees, measuring their various strengths. Analogously, the\ndie\u2019s propensities to land various ways measure the strength of\nits dispositions to do so.\n\nPeirce continues: \u201cNow in order that the full effect of the\ndie\u2019s \u2018would-be\u2019 may find expression, it is\nnecessary that the die should undergo an endless series of throws from\nthe dice box\u201d, and he imagines the relative frequency of the\nevent-type in question oscilating from one side of 1/3 to another.\nThis again anticipates Popper\u2019s view. But an important\ndifference is that Peirce regards the propensity as a property of the\ndie itself, whereas Popper attributes the propensity to the entire\nchance set-up of throwing the die.\n\nPopper (1957) is motivated by the desire to make sense of single-case\nprobability attributions that one finds in quantum mechanics\u2014for\nexample \u2018the probability that this radium atom decays in 1600\nyears is 1/2\u2019. He develops the theory further in (1959a). For\nhim, a probability \\(p\\) of an outcome of a certain type is a\npropensity of a repeatable experiment to produce outcomes of that type\nwith limiting relative frequency \\(p\\). For instance, when we say that\na coin has probability 1/2 of landing heads when tossed, we mean that\nwe have a repeatable experimental set-up \u2014 the tossing set-up\n\u2014 that has a propensity to produce a sequence of outcomes in\nwhich the limiting relative frequency of heads is 1/2. With its heavy\nreliance on limiting relative frequency, this position risks\ncollapsing into von Mises-style frequentism according to some critics.\nGiere (1973), on the other hand, explicitly allows single-case\npropensities, with no mention of frequencies: probability is just a\npropensity of a repeatable experimental set-up to produce sequences of\noutcomes. This, however, creates the opposite problem to\nPopper\u2019s: how, then, do we get the desired connection between\nprobabilities and frequencies?\n\nIt is thus useful to follow Gillies (2000a, 2016) in distinguishing\nlong-run propensity theories and single-case\npropensity theories:\n\nA long-run propensity theory is one in which propensities are\nassociated with repeatable conditions, and are regarded as\npropensities to produce in a long series of repetitions of these\nconditions frequencies which are approximately equal to the\nprobabilities. A single-case propensity theory is one in which\npropensities are regarded as propensities to produce a particular\nresult on a specific occasion (2000a, 822).\n\n\nHacking (1965) and Gillies offer long-run (though not infinitely\nlong-run) propensity theories. Fetzer (1982, 1983) and Miller (1994)\noffer single-case propensity theories. So does Popper in a later work\n(1990), in which he regards propensities as \u201cproperties of\nthe whole physical situation and sometimes of the particular\nway in which a situation changes\u201d (17). Note that\n\u2018propensities\u2019 are categorically different things\ndepending on which sort of theory we are considering. According to the\nlong-run theories, propensities are tendencies to produce relative\nfrequencies with particular values, but the propensities are not\nmeasured by the probability values themselves; according to the\nsingle-case theories, the propensities are measured by the\nprobability values. According to Popper\u2019s earlier view, for\nexample, a fair die has a propensity \u2014 an extremely\nstrong tendency \u2014 to land \u20183\u2019 with long-run\nrelative frequency 1/6. The small value of 1/6 does not\nmeasure this tendency. According to Giere, on the other hand, the die\nhas a weak tendency to land \u20183\u2019. The value of 1/6\ndoes measure this tendency.\n\nIt seems that those theories that tie propensities to frequencies do\nnot provide an admissible interpretation of the (full) probability\ncalculus, for the same reasons that relative frequencies do not. It is\nprima facie unclear whether single-case propensity theories\nobey the probability calculus or not. To be sure, one can\nstipulate that they do so, perhaps using that stipulation as\npart of the implicit definition of propensities. Still, it remains to\nbe shown that there really are such things \u2014 stipulating what a\nwitch is does not suffice to show that witches exist. Indeed, to\nclaim, as Popper does, that an experimental arrangement has a tendency\nto produce a given limiting relative frequency of a particular\noutcome, presupposes a kind of stability or uniformity in the workings\nof that arrangement (for the limit would not exist in a suitably\nunstable arrangement). But this is the sort of\n\u2018uniformity of nature\u2019 presupposition that Hume argued\ncould not be known either a priori, or empirically. Now,\nappeals can be made to limit theorems \u2014 so called \u2018laws of\nlarge numbers\u2019 \u2014 whose content is roughly that under\nsuitable conditions, such limiting relative frequencies almost\ncertainly exist, and equal the single case propensities. Still, these\ntheorems make assumptions (e.g., that the trials are independent and\nidentically distributed) whose truth again cannot be known, and must\nmerely be postulated.\n\nPart of the problem here, say critics, is that we do not know enough\nabout what propensities are to adjudicate these issues. There is\nsome property of this coin tossing arrangement such that this\ncoin would land heads with a certain long-run frequency, say. But as\nHitchcock (2002) points out, \u201ccalling this property a\n\u2018propensity\u2019 of a certain strength does little to indicate\njust what this property is.\u201d Said another way, propensity\naccounts are accused of giving empty accounts of probability, \u00e0\nla Moli\u00e8re\u2019s \u2018dormative virtue\u2019 (Sober 2000,\n64). Similarly, Gillies objects to single-case propensities on the\ngrounds that statements about them are untestable, and that they are\n\u201cmetaphysical rather than scientific\u201d (825). Some might\nlevel the same charge even against long-run propensities, which are\nsupposedly distinct from the testable relative\nfrequencies.\n\nThis suggests that the propensity account has difficulty meeting the\napplicability to science criterion. Some propensity theorists (e.g.,\nGiere) liken propensities to physical magnitudes such as electrical\ncharge that are the province of science. But Hitchcock observes that\nthe analogy is misleading. We can only determine the general\nproperties of charge \u2014 that it comes in two varieties, that like\ncharges repel, and so on \u2014 by empirical investigation. What\ninvestigation, however, could tell us whether or not propensities are\nnon-negative, normalized and additive? (See also Eagle 2004.)\n\nMore promising, perhaps, is the idea that propensities are to play\ncertain theoretical roles, and that these place constraints on the way\nthey must behave, and hence what they could be (in the style of the\nRamsey/Lewis/\u2018Canberra plan\u2019 approach to theoretical terms\n\u2014 see Lewis 1970 or Jackson 2000). The trouble here is that\nthese roles may pull in opposite directions, overconstraining\nthe problem. The first role, according to some, constrains them to\nobey the probability calculus (with finite additivity); the second\nrole, according to others, constrains them to violate it.\n\nOn the one hand, propensities are said to constrain the degrees of\nbelief, or credences, of a rational agent. Recall the\n\u2018applicability to rational beliefs\u2019 criterion: an\ninterpretation should clarify the role that probabilities play in\nconstraining the credences of rational agents. One such putative role\nfor propensities is codified by Lewis\u2019s \u2018Principal\nPrinciple\u2019. (See section 3.3.) The Principal Principle underpins\nan argument (Lewis 1980) that whatever they are, propensities must\nobey the usual probability calculus (with finite additivity). After\nall, it is argued, rational credences, which are guided by them,\ndo.\n\nOn the other hand, Humphreys (1985) gives an influential argument that\npropensities do not obey Kolmogorov\u2019s probability\ncalculus. The idea is that the probability calculus implies\nBayes\u2019 theorem, which allows us to reverse a\nconditional probability: \n\\[ P(A\\mid B) = \\frac{P(B\\mid A) \\cdot P(A)}{P(B)} \\]\n\n\nYet propensities seem to be measures of \u2018causal\ntendencies\u2019, and much as the causal relation is asymmetric, so\nthese propensities supposedly do not reverse. Suppose that we have a\ntest for an illness that occasionally gives false positives and false\nnegatives. A given sick patient may have a (non-trivial) propensity to\ngive a positive test result, but it apparently makes no sense to say\nthat a given positive test result has a (non-trivial) propensity to\nhave come from a sick patient. Thus, we have an argument that whatever\nthey are, propensities must not obey the usual probability\ncalculus. \u2018Humphreys\u2019 paradox\u2019, as it is known, is\nreally an argument against any formal account of propensities that has\nas a theorem:\n\n(\u2217) if the probability of \\(B\\), given \\(A\\) exists, then the\nprobability of \\(A\\), given \\(B\\) exists,\n\n\nhowever one understands these conditional probabilities. The argument\nhas prompted Fetzer and Nute (in Fetzer 1981) to offer a\n\u201cprobabilistic causal calculus\u201d that looks quite different\nfrom Kolmogorov\u2019s\n calculus.[11]\n But one could respond more conservatively, as Lyon (2014) points out.\nFor example, R\u00e9nyi\u2019s axiomatization of primitive\nconditional probabilities does not have (\u2217) as a theorem, and\nthus propensities may conform to it despite Humphreys\u2019 argument.\nNonetheless, Lyon offers \u201ca more general problem for the\npropensity interpretation. There are all sorts of pairs of events that\nhave no propensity relations between them, and all three axiom\nsystems\u2014Kolmogorov\u2019s, Popper\u2019s, and\nR\u00e9nyi\u2019s\u2014will sometimes force there to be\nconditional probabilities between them. This is not an argument that\nthere is no alternative axiom system that propensity theorists can\nadopt, but it is an argument that the three main contenders are not\nviable\u201d (124).\n\nOr perhaps all this shows that the notion of \u2018propensity\u2019\nbifurcates: on the one hand, there are propensities that bear an\nintimate connection to relative frequencies and rational credences,\nand that obey the usual probability calculus (with finite additivity);\non the other hand, there are causal propensities that behave rather\ndifferently. In that case, there would be still more interpretations\nof probability than have previously been recognized.\n3.6 Best-System Interpretations\n\nTraditionally, philosophers of probability have recognized five\nleading interpretations of probability\u2014classical, logical,\nsubjectivist, frequentist, and propensity. But recently, so-called\nbest-system interpretations of chance have become\nincreasingly popular and important. While they bear some similarities\nto frequentist accounts, they avoid some of frequentism\u2019s major\nfailings; and while they are sometimes assimilated to propensity\naccounts, they are really quite distinct. So they deserve separate\ntreatment.\n\nThe best-system approach was pioneered by Lewis (1994b). His analysis\nof chance is based on his account of laws of nature (1973),\nwhich in turn refines an account due to Ramsey (1928/1990). According\nto Lewis, the laws of nature are the theorems of the best\nsystematization of the universe\u2014the true theory\nthat best combines the theoretical virtues of simplicity and\nstrength. These virtues trade off. It is easy for a theory to be\nsimple but not strong, by saying very little; it is easy for a theory\nto be strong but not simple, by conjoining lots of disparate facts.\nThe best theory balances simplicity and strength optimally\u2014in\nshort, it is the most economical true theory.\n\nSo far, there is no mention of chances. Now, we allow probabilistic\ntheories to enter the competition. We are not yet in a position to\nspeak of such theories as being true. Instead, let us introduce\nanother theoretical virtue: fit. The more probable the actual\nhistory of the universe is by the lights of the theory, the better it\nfits that history. Now the theories compete according to how well they\ncombine simplicity, strength, and fit. The theorems of the winning\ntheory are the laws of nature. Some of these laws may be\nprobabilistic. The chances are the probabilities that are determined\nby these probabilistic laws.\n\nAccording to Lewis (1986b), intermediate chances are incompatible with\ndeterminism. Loewer (2004) agrees that intermediate\npropensities are incompatible with determinism, understanding\nthose to be essentially dynamical: \u201cthey specify the\ndegree to which one state has a tendency to cause another\u201d (15).\nBut he argues that chances are best understood along Lewisian\nbest-system lines, and that there is no reason to limit them to\ndynamical chances. In particular, best-system chances may also attach\nto initial conditions: adding to the dynamical laws a\nprobability assignment, or distribution, over initial\nconditions may provide a substantial gain in strength with relatively\nlittle cost in simplicity. Science furnishes important examples of\ndeterministic theories with such initial-condition probabilities.\nAdding the so-called micro-canonical distribution to Newton\u2019s\nlaws (and the assumption that the distant past had low entropy) yields\nall of statistical mechanics; adding the so-called quantum equilibrium\ndistribution to Bohm\u2019s dynamical laws yields standard quantum\nmechanics. Indeed, this contact with actual science is one of the\nselling points of best-system analyses. See Schwarz (2016) for further\nselling points.\n\nAt first blush, best-systems analyses seem to score well on our\ncriteria of adequacy. They are admissible by definition: chances are\ndetermined by probabilistic laws (rather than by those expressed by\nsome other formalism). One could in principle ascertain values of\nprobabilities, since they supervene on what actually happens in the\nuniverse (though \u2018in principle\u2019 bears a heavy burden).\nApplicability to frequencies is secured through the role that\n\u2018fit\u2019 plays. Schwarz (2014) offers a proof of the\nPrincipal Principle, which could be taken to undergird the\nbest-systems analyses\u2019 applicability to rational beliefs and\nrational decisions. And we have just mentioned the\ninterpretation\u2019s applicability to science.\n\nThis approach solves, or at least eases, some of frequentism\u2019s\nproblems. Progress can be made on the problem of the single case. The\nchances of a rare atom decaying in various time intervals may be\ndetermined by a more pervasive functional law, in which decay chances\nare given for a far wider range of atoms by plugging in a range of\nsettings of some other magnitude (e.g., atomic number). And simplicity\nmay militate in favour of this functional law being continuous, so\neven irrational-valued probabilities may be assigned. Moreover, bare\nratios of attributes among sets of disparate objects will not qualify\nas chances if they are not pervasive enough, for then a theory that\nassigns them probabilities will lose too much simplicity without\nsufficient gain in strength.\n\nHowever, some other problems for frequentism remain, and some new ones\nemerge, beginning with more basic problems for the Lewisian account of\nlawhood itself. Some of them are partly a matter of Lewis\u2019s\nspecific formulation. Critics (e.g. van Fraassen 1989) question the\nrather nebulous notion of \u201cbalancing\u201d simplicity and\nstrength, which are themselves somewhat sketchy. But arguably some\ntechnical story (e.g. information-theoretic) could be offered to\nprecisify them. Lewis himself worries that the exchange rate for such\nbalancing may depend partly on our psychology, in which case there is\nthe threat the laws themselves depend on our psychology, an\nunpalatable idealism about them. But he maintains that this threat is\nnot serious as long as \u201cnature is kind\u201d, and one theory is\nso robustly the front-runner that it remains so under any reasonable\nstandards for balancing. And again, perhaps technical tools can offer\nsome objectivity here. (See section 4 for a gesture at such\ntools.)\n\nMore telling is the concern that simplicity is language-relative, and\nindeed that any theory can be given the simplest specification\npossible: simply abbreviate it as \\(T\\)! Lewis replies that a\ntheory\u2019s simplicity must be judged according to its\nspecification in a canonical language, in which all of the predicates\ncorrespond to natural properties. Thus, \u2018green\u2019\nmay well be eligible, but \u2018grue\u2019 surely is not. (See\nGoodman 1955.) Our abbreviation, then, has to be unpacked in terms of\nsuch a language, in which its true complexity will be revealed. But\nthis now involves a substantial metaphysical commitment to a\ndistinction between natural and unnatural properties, one that various\nempiricists (e.g. van Fraassen 1989) find objectionable.\n\nFurther problems arise with the refinement to handle probabilistic\nlaws. Again, some of them may be due to Lewis\u2019s particular\nformulation. Elga (2004) observes that Lewis\u2019s notion of fit is\nproblematic in various infinite universes\u2014think of an infinite\nsequence of tosses of a coin. Offhand, it seems that the particular\ninfinite sequence that is actualized will be assigned probability\nzero by any plausible candidate theory that regards the\nprobability of heads as intermediate and the trials as independent.\nElga argues, moreover, that there are technical difficulties with\naddressing this problem with infinitesimal probabilities. However,\nperhaps we merely need a different understanding of\n\u2018fit\u2019\u2014perhaps understood as \u2018typicality\u2019\n(Elga), or perhaps one closer to that employed by statisticians with\n\u2018chi-squared\u2019 tests of goodness of fit (Schwarz 2014).\n\nHoefer (2007) modifies Lewis\u2019s best-system account in light of\nsome of these problems. Hoefer understands \u201cbest\u201d as\n\u201cbest for us\u201d, covering regularities that are of interest\nto us, using the language both of science and of daily life, without\nany special privilege bestowed upon natural properties. Moreover, the\n\u201cbest system\u201d is now one of chances directly, rather than\nof laws. Thus, there may be chances associated with the punctuality of\ntrains, for example, without any presumption that there are any\nassociated laws. Hoefer follows Elga in understanding\n\u2018fit\u2019 as \u2018typicality\u2019. Strength is a matter of\nthe size of the overall domain of the best system\u2019s probability\nfunctions. Simplicity is to be understood in terms of elegant\nunification, and user-friendliness to beings like us. As a result,\nHoefer embraces the agent-centric nature of chances in his sense,\nregarding as essential the credence-guiding role for them that is\ncaptured by the Principal Principle. This is how his account meets the\n\u2018applicability to rational beliefs\u2019 criterion.\n\nHowever, some other problems for Lewis\u2019s account may run deeper,\nthreatening best-system analyses more generally, and symptomatic of\nthe ghost of frequentism that still hovers behind such analyses. One\nproblem for frequentism that we saw strikes at the heart of any\nattempt to reduce chances to properties of patterns of outcomes. Such\noutcomes may be highly misleading regarding the true chances,\nbecause of their probabilistic nature. This is most vivid for\nevents that are single-case by any reasonable typing. Whether or our\nuniverse turns out to be open or closed, plausibly that outcome is\ncompatible with any underlying intermediate chance. The point\ngeneralizes, however pervasive the probabilistic pattern might be.\nPlausibly, a coin\u2019s landing 9 heads out of 10 tosses is\ncompatible with any underlying intermediate chance for heads; and so\non. The pattern of outcomes that is instantiated may be a poor guide\nto the true chance. (See H\u00e1jek 2009 for further arguments\nagainst frequentism that carry over to best-system accounts.)\n\nAnother way of putting the concern is that best-system accounts\nmistake an idealized epistemology of chance for its metaphysics\n(though see Lewis\u2019 insistence that this is not the case, in his\n1994). Such accounts single out three theoretical virtues\u2014and\none may wonder why just those three\u2014and reifies the\nprobabilities of a theory that displays the virtues to the highest\ndegree. But a probabilistic world may be recalcitrant to even the best\ntheorizing: nature may be unkind.\n4. Conclusion: Recent Trends, Future Prospects\n\nIt should be clear from the foregoing that there is still much work to\nbe done regarding the interpretations of probability. Each\ninterpretation that we have canvassed seems to capture some crucial\ninsight into a concept of it, yet falls short of doing complete\njustice to this concept. Perhaps the full story about probability is\nsomething of a patchwork, with partially overlapping pieces and\nprinciples about how they ought to relate. In that sense, the above\ninterpretations might be regarded as complementary, although to be\nsure each may need some further refinement. My bet, for what it is\nworth, is that we will retain the distinct notions of physical,\nlogical/evidential, and subjective probability, with a rich tapestry\nof connections between them.\n\nThere are further signs of the rehabilitation of classical and logical\nprobability, and in particular the principle of indifference and the\nprinciple of maximum entropy, by authors such as Paris and\nVencovsk\u00e1 (1997), Maher (2000, 2001), Bartha and Johns (2001),\nNovack (2010), White (2010), and Pettigrew (2016). However, Rinard\n(2014) argues that the principle of indifference leads to incoherence\neven when imprecise probabilities are allowed. Eva (2019) resurrects\nthe principle as a constraint on comparative probabilities of\nthe form \u2018I am more confident in p than in\nq\u2019 or \u2018I am equally confident in p and\nq\u2019. This, in turn, showcases another recent trend: an\nincreased interest in comparative probabilities.\n\nRelevant here may also be advances in information theory and\ncomplexity theory. Information theory uses probabilities to define the\ninformation in a particular event, the degree of uncertainty in a\nrandom variable, and the mutual information between random variables\n(Shannon 1948, Shannon & Weaver 1949). This theory has been\ndeveloped extensively to give accounts of complexity, optimal data\ncompression and encoding (Kolmogorov 1965, Li and Vitanyi 1997, Cover\nand Thomas 2006; see the entry on\n information\n for more details). It is applied across the sciences, from its\nnatural home in computer science and communication theory, to physics\nand biology. Interpreting information in these areas goes hand-in-hand\nwith interpreting the underlying probabilities: each concept of\nprobability has a corresponding concept of information. For example,\nScarantino (2015) offers an account of \u2018natural\ninformation\u2019 in biology that is compatible with either a logical\ninterpretation of probability or objective Bayesian interpretation,\nwhile Kraemer (2015) offers one that rests on a finite frequency\ninterpretation.\n\nInformation theory has also proved to be fruitful in the study of\nrandomness (Kolmogorov 1965, Martin-L\u00f6f 1966), which obviously is\nintimately related to the notion of probability \u2013 see Eagle\n(2016), and the entry on\n chance versus randomness.\n Refinements of our understanding of randomness, in turn, should have\na bearing on the frequency interpretations (recall von Mises\u2019\nappeal to randomness in his definition of a \u2018collective\u2019),\nand on propensity accounts (especially those that make explicit ties\nto frequencies). Given the apparent connection between propensities\nand causation adumbrated in Section 3.5, powerful causal modelling\nmethods should also prove fruitful here. More generally, the theory of\ngraphical causal models (also known as Bayesian networks) uses\ndirected acyclic graphs to represent causal relationships in a system.\n(See Spirtes, Glymour and Scheines 1993, Pearl 2000, Woodward 2003.)\nThe graphs and the probabilities of the system\u2019s variables\nharmonize in accordance with the causal Markov condition, a\nsophisticated version of Reichenbach\u2019s slogan \u201cno\ncorrelation without causation\u201d. (See the entry on\n causal models\n for more details.) Thus again, each understanding of probability has\na counterpart understanding of causal networks.\n\nRegarding best-system interpretations of chance, I noted that it is\nsomewhat unclear exactly what \u2018simplicity\u2019 and\n\u2018strength\u2019 consist in, and exactly how they are to be\nbalanced. Perhaps insights from statistics and computer science may be\nhelpful here: approaches to statistical model selection, and in\nparticular the \u2018curve-fitting\u2019 problem, that attempt to\ncharacterize simplicity, and its trade-off with strength \u2014 e.g.,\nthe Akaike Information Criterion (see Forster and Sober 1994), the\nBayesian Information Criterion (see Kiesepp\u00e4 2001), Minimum\nDescription Length theory (see Rissanen 1999) and Minimum Message\nLength theory (see Wallace and Dowe 1999).\n\nPhysical probabilities are becoming even more crucial to scientific\ninquiry. Probabilities are not just used to characterize the support\ngiven to scientific theories by evidence; they appear essentially in\nthe content of the theories themselves. This has led to fertile\nphilosophical ground interpreting the probabilities in such theories.\nFor example, quantum mechanics has physical probabilities at the\nfundamental level. The interpretation of these probabilities is\nrelated to the interpretation of the theory itself (see the entry on\n philosophical issues in quantum theory).\n Statistical mechanics and evolutionary theory have non-fundamental\nobjective probabilities. Are they genuine chances? How can we account\nfor them? See Strevens (2003) and Lyon (2011) for discussion. However,\nSchwarz (2018) argues that these probabilities can and should be left\nuninterpreted. Loewer (2012, 2020) proposes that the Lewisian best\nsystem of our world is given by \u201cthe\nMentaculus\u201d\u2014a complete probability map of the\nuniverse. This is Albert\u2019s (2000) package of:\n\nthe fundamental dynamical laws of statistical mechanics;\nthe claim that initially the universe was in a microstate \\(M(0)\\)\nwhose entropy was tiny (\u201cthe Past Hypothesis\u201d);\nand a law specifying a uniform probability distribution over the\nmicro-states that realize \\(M(0).\\)\n\n\nAnother ongoing debate regarding physical probabilities concerns\nwhether chance is compatible with determinism\u2014see, e.g.,\nSchaffer (2007), who is an incompatibilist, and Ismael (2009) and\nLoewer (2020), who are compatibilists. Handfield and Wilson (2014)\nargue that chance ascriptions are context-sensitive, varying according\nto the relevant \u201cevidence base\u201d. This captures the thought\nthat in a deterministic universe, there is some sense in\nwhich all chances are extreme, while doing justice to other\ncompatibilist usages of chance. See Frigg (2016) for an overview of\nthis debate. Relatedly, an important approach to objective probability\nthat has gained popularity involves the so-called method of\narbitrary functions. Originating with Poincar\u00e9 (1896), it\nis a mathematical technique for determining probability functions for\ncertain systems with chaotic dynamical laws mapping input conditions\nto outcomes. Roughly speaking, the probabilities for the outcomes are\nrelatively insensitive to the probabilities over the various initial\nconditions \u2014 think of how the probabilities of outcomes of spins\nof a roulette wheel apparently do not depend on how the wheel is spun,\nsometimes vigorously, sometimes feebly. See Strevens (2003, 2013) for\ndetailed treatments of this approach.\n\nThe subjectivist theory of probability is also thriving\u2014indeed,\nit has been the biggest growth area among all the interpretations,\nthanks to the burgeoning of formal epistemology in the last couple of\ndecades. For each of the topics that I will briefly mention, I can\nonly cite a few representative works.\n\nEspecially since Joyce (1998), accuracy arguments for various\nBayesian norms have been influential. They include arguments for\nconditionalization (Greaves and Wallace 2006, Briggs and Pettigrew\n2020), the Reflection Principle (Easwaran 2013), and the Principal\nPrinciple (Pettigrew 2016). However, Mahtani (2021) argues that the\nmathematical theorems that are invoked to support the accuracy\napproach do not justify probabilism. These lines of research continue\nto develop. And these norms themselves have received further\nattention\u2014e.g. Schoenfield (2017) on conditionalization, and\nHall (1994, 2004), Ismael (2008), and Briggs (2009) on the Principal\nPrinciple.\n\nYet for some problems, Bayesian modelling seems not to be sufficiently\nnuanced. A recently flourishing area has concerned modelling an\nagent\u2019s self-locating credences, concerning who she is,\nor what time it is. The contents of such credences are usually taken\nto be richer than just propositions (thought of as sets of possible\nworlds); rather, they are finer-grained propositions (sets of centered\nworlds \u2014 see Lewis 1979). This in turn has ramifications for\nupdating rules, in particular calling conditionalization into\nquestion\u2014see Meacham (2008). The so-called Sleeping Beauty\nproblem (Elga 2000) has generated much discussion in this regard. See\nTitelbaum (2012) for a comprehensive study and approach to such\nproblems, Titelbaum (2016), and the entry on self-locating beliefs for\na survey of the literature. These continue to be fertile areas of\nresearch.\n\nOn the other hand, there is another sense in which Bayesian modelling\nhas been regarded as too nuanced. It seems to be\npsychologically unrealistic to portray humans (rather than\nideally rational agents) as having degrees of belief that are\ninfinitely precise real numbers. Thus, there have been various\nattempts to \u2018humanize\u2019 Bayesianism, and this line of\nresearch is gaining momentum. For example, there has been a\nflourishing study of imprecise probability and imprecise decision\ntheory, in which credences need not be precise numbers\u2014for\nexample, they could be sets of numbers, or intervals. See\nhttp://www.sipta.org/ for up-to-date research in this area. This\nresonates with recent work on whether imprecise probabilities are\nrationally required\u2014H\u00e1jek and Smithson (2012) and Isaacs,\nH\u00e1jek, and Hawthorne (2022) on the pro side, Schoenfield (2017)\non the con side. The debate continues.\n\nNor is it plausible that humans obey all the theorems of the\nprobability calculus\u2014we are incoherent in all sorts of ways. The\nlast couple of decades have also seen research on degrees of\nincoherence\u2014measuring the extent of departures from obedience to\nthe probability calculus\u2014including Zynda (1996), Schervish,\nSeidenfeld and Kadane (2003), De Bona and Staffel (2017, 2018), and\nStaffel (2019). Lin (2013) sees traditional epistemology\u2019s\nnotion of belief as appropriate for humans who fall short of\nthe Bayesian ideal, but who nevertheless may obey various doxastic\nnorms that can be given Bayesian endorsement. He models everyday\npractical reasoning, with qualitative beliefs and desires, providing a\nqualitative decision theory and representation theorem. Easwaran\n(2016) takes humans to genuinely have all-or-nothing beliefs, but\noffers an instrumentalist justification for representing\nthose beliefs with probabilities.\n\nIt also a fact of life that humans disagree with each other.\nHow should an agent modify her credences (if at all) when she\ndisagrees on some claim with an epistemic peer\u2014someone\nwho has the same evidence as her, and whom she regards as equally good\nat evaluating that evidence? The literature on this topic is huge (see\nKopec and Titelbaum (2016) for a survey, and the entry on\n disagreement),\n and it connects in important ways with the interpretations of\nprobability. Intuitively, we feel that disagreement with an epistemic\npeer rationally calls for moving one\u2019s opinion in the direction\nof theirs, since disagreement with a peer seems to be evidence that\none has made a mistake in evaluating one\u2019s initial evidence. As\nKelly (2010) argues, this \u2018conciliationist\u2019 intuition\nappears to commit us to the evidential interpretation of probability,\nwith the common evidence bestowing a unique probability on the\ndisputed claim. (See Schoenfield 2014 and Titelbaum 2016 for dissent;\nfor a defense of the Uniqueness Thesis more generally, see Horowitz\nand Dogramaci 2016.) The intuition also appears to commit us to\nprobabilistic enkrasia: the view that our credences are\nbeholden to our attitudes about evidential probabilities, in\nmuch the same way as the Principal Principle portrays our credences as\nbeholden to our attitudes about chances. (See Christensen 2013 and\nElga 2010 for versions of probabilistic enkrasia principles.)\nLet\u2019s grant that disagreement with a peer about some claim is\nevidence that one has made a mistake regarding it. This should affect\none\u2019s opinion in it only if one\u2019s attitude about the\ncorrect way to evaluate the evidence constrains one\u2019s\nattitude about the claim. However, probabilistic enkrasia has been\ncriticised (see Williamson 2014; Lasonen-Aarnio 2015).\n\nWe thus come back full circle to where we started. The classical and\nlogical/evidential interpretations sought to capture an objective\nnotion of probability that measures evidential support relations.\nEarly proponents of the subjective interpretation gave us a highly\npermissive notion of rational credences, constrained only by the\nprobability calculus. Less liberal subjectivists added further\nrationality constraints, with credences beholden to attitudes about\nphysical probabilities, and to evidential probabilities\u2014at an\nextreme, to the point of uniqueness. The three kinds of concepts of\nprobability that we identified at the outset converge:\nepistemological, degrees of confidence, and physical. Future research\nwill doubtless explore further the relationships between\nthem\u2014and how they provide guides to life.\nSuggested Further Reading\n\nKyburg (1970) contains a vast bibliography of the literature on\nprobability and induction pre-1970. Also useful for references before\n1967 is the bibliography for \u201cProbability\u201d in the\nMacmillan Encyclopedia of Philosophy. Earman (1992) and\nHowson and Urbach (1993) have large bibliographies, and give detailed\npresentations of the Bayesian program. H\u00e1jek and Hitchcock\n(2021 [Other Internet Resources]) has a more recent and extensive\nannotated bibliography for all the interpretations of probability\ndiscussed in this entry. Skyrms (2000) is an excellent introduction to\nthe philosophy of probability.  Von Plato (1994) is more technically\ndemanding and more historically oriented, with another extensive\nbibliography that has references to many landmarks in the development\nof probability theory in the last century. Fine (1973) is still a\nhighly sophisticated survey of and contribution to various\nfoundational issues in probability, with an emphasis on\ninterpretations. More recent philosophical studies of the leading\ninterpretations include Childers (2013), Gillies (2000b), Galavotti\n(2005), Huber (2019), and Mellor (2005). H\u00e1jek and Hitchcock\n(2016) is a collection of original survey articles on philosophical\nissues related to probability. Section IV includes chapters on most of\nthe major interpretations of probability. It also includes coverage of\nthe history of probability, Kolmogorov\u2019s formalism and\nalternatives, and applications of probability in science and\nphilosophy. Joyce (2011) is a thorough survey of subjective\nBayesianism; Titelbaum (2022) is a wide-ranging and accessible\nintroduction to Bayesian epistemology. H\u00e1jek and Lin (2017)\ncanvass various respects of similarity and dissimilarity between\nBayesian epistemology and traditional epistemology. Knauff and Spohn\n(2021) is a comprehensive open access handbook on many topics\nconcerning rationality; the chapter by H\u00e1jek and Staffel (2021)\nelaborates on a number of issues raised in this entry\u2019s\ndiscussion of subjective probability. Eagle (2010) is a valuable\nanthology of many significant papers in the philosophy of probability,\nwith detailed and incisive critical discussions. Billingsley (1995)\nand Feller (1968) are classic, rather advanced textbooks on the\nmathematical theory of probability. Ross (2013) is less advanced and\nhas lots of examples.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Albert, D., 2000, <em>Time and Chance</em>, Cambridge, MA: Harvard\nUniversity Press.",
                "Arnauld, A., 1662, <em>Logic, or, The Art of Thinking</em>\n(\u201cThe Port Royal Logic\u201d), tr. J. Dickoff and P. James,\nIndianapolis: Bobbs-Merrill, 1964.",
                "Bacon, A., 2014, \u201cGiving Your Knowledge Half A\nChance\u201d, <em>Philosophical Studies</em>, 171 (2):\n373\u2013397.",
                "Bartha, P. and R. Johns, 2001, \u201cProbability and\nSymmetry\u201d, <em>Philosophy of Science</em>, 68 (Proceedings):\nS109\u2013S122.",
                "Bell, E. T., 1945, <em>The Development of Mathematics</em>, 2nd\nedition, New York, McGraw-Hill Book Company.",
                "Bertrand, J., 1889, <em>Calcul des Probabilit\u00e9s</em>\n[<em>Calculus of Probabilities</em>], Paris, France:\nGauthier-Villars.",
                "Billingsley, P., 1995, <em>Probability and Measure</em>, 3rd\nedition, New York: John Wiley &amp; Sons.",
                "Briggs, R., 2009, \u201cThe Anatomy of the Big Bad Bug\u201d,\n<em>No\u00fbs</em>, 43 (3): 428\u2013449.\ndoi:10.1111/nous.12258",
                "Briggs, R. A., and R. Pettigrew, 2020, \u201cAn\nAccuracy-Dominance Argument for Conditionalization\u201d,\n<em>No\u00fbs</em> 54 (1): 162\u2013181, doi:10.1111/nous.12258",
                "Buchak, L., 2016, \u201cDecision Theory\u201d, in H\u00e1jek\nand Hitchcock (eds.) 2016, 789\u2013815.",
                "Carnap, R., 1950, <em>Logical Foundations of Probability</em>,\nChicago: University of Chicago Press; 2nd edition, 1962.",
                "\u2013\u2013\u2013, 1952, <em>The Continuum of Inductive\nMethods</em>, Chicago: University of Chicago Press.",
                "\u2013\u2013\u2013, 1963, \u201cReplies and Systematic\nExpositions\u201d, in <em>The Philosophy of Rudolf Carnap</em>, P. A.\nSchilpp, (ed.), La Salle, IL: Open Court, 859\u20131013.",
                "Childers, T., 2013, <em>Philosophy and Probability</em>, Oxford\nUniversity Press.",
                "Christensen, D., 2010, \u201cRational Reflection\u201d,\n<em>Philosophical Perspectives</em>, 24 (1): 121\u2013140.",
                "Church, A., 1940, \u201cOn the Concept of a Random\nSequence\u201d, <em>Bulletin of the American Mathematical\nSociety</em>, 46: 130\u2013135.",
                "Cover, T. M., and J. A. Thomas, 1991, <em>Elements of Information\nTheory</em>, New York: John Wiley &amp; Sons, Inc.",
                "Cozman, F. G., 2016, \u201cImprecise and Indeterminate\nProbabilities\u201d, in H\u00e1jek and Hitchcock (eds.) 2016,\n296\u2013311.",
                "De Bona, G., and J. Staffel, 2017, \u201cGraded Incoherence for\nAccuracy Firsters\u201d, <em>Philosophy of Science</em>, 284 (2):\n189\u2013213.",
                "\u2013\u2013\u2013, 2018, \u201cWhy Be (Approximately)\nCoherent?\u201d, <em>Analysis</em>, 78 (3): 405\u2013415.",
                "de Finetti, B., 1937, \u201cLa Pr\u00e9vision: Ses Lois\nLogiques, Ses Sources Subjectives\u201d, <em>Annales de\nl\u2019Institut Henri Poincar\u00e9</em>, 7: 1\u201368; translated\nas \u201cForesight. Its Logical Laws, Its Subjective Sources\u201d,\nin <em>Studies in Subjective Probability</em>, H. E. Kyburg, Jr. and\nH. E. Smokler (eds.), Robert E. Krieger Publishing Company, 1980,\n55\u2013118.",
                "\u2013\u2013\u2013, 1972, <em>Probability, Induction and\nStatistics</em>, New York: Wiley.",
                "\u2013\u2013\u2013, 1990 [1974], <em>Theory of Probability</em>\n(Volume 1), New York: John Wiley &amp; Sons.",
                "de Moivre, A., 1718/1967, <em>The Doctrine of Chances: or, A\nMethod of Calculating the Probability of Events in Play</em>, London:\nW. Pearson, 1718; 2nd edition, 1738; 3rd edition 1756; reprinted 1967,\nNew York, NY: Chelsea.",
                "De Morgan, A., 1847, <em>Formal Logic, or, The Calculus of\nInference, Necessary and Probable</em>, London: Taylor and\nWalton.",
                "Dogramaci, S., and S. Horowitz, 2016, \u201cAn Argument for\nUniqueness about Evidential Support\u201d, <em>Philosophical\nIssues</em> 26 (1): 130\u2013147.",
                "Eagle, A., 2010, <em>Philosophy of Probability: Contemporary\nReadings</em>, London: Routledge.",
                "\u2013\u2013\u2013, 2004, \u201cTwenty-One Arguments Against\nPropensity Analyses of Probability\u201d, <em>Erkenntnis</em>, 60:\n371\u2013416.",
                "\u2013\u2013\u2013, 2016, \u201cProbability and\nRandomness\u201d, in H\u00e1jek and Hitchcock (eds.) 2016,\n440\u2013459.",
                "\u2013\u2013\u2013, 2018, \u201cChance, Determinism, and\nUnsettledness\u201d, <em>Philosophical Studies</em>, 1\u201322.",
                "Earman, J., 1992, <em>Bayes or Bust?</em>, Cambridge, MA: MIT\nPress.",
                "Easwaran, K., 2013, \u201cExpected Accuracy Supports\nConditionalization\u2014and Conglomerability and Reflection\u201d,\n<em>Philosophy of Science</em> 80 (1): 119\u2013142.",
                "\u2013\u2013\u2013, 2016, \u201cDr. Truthlove or: How I\nLearned to Stop Worrying and Love Bayesian Probabilities\u201d,\n<em>No\u00fbs</em> 50 (4): 816\u2013853.",
                "Eder A. A.., 2023, \u201cEvidential Probabilities and\nCredences\u201d, <em>The British Journal for the Philosophy of\nScience</em> 74 (1).",
                "Edwards, W., H. Lindman, and L. J. Savage, 1963, \u201cBayesian\nStatistical Inference for Psychological Research\u201d,\n<em>Psychological Review</em>, 70: 193\u2013242.",
                "Elga, A., 2000, \u201cSelf-Locating Belief and the Sleeping\nBeauty Problem\u201d, <em>Analysis</em>, 60 (2): 143\u2013147. Also\nin Eagle 2010.",
                "\u2013\u2013\u2013, 2004, \u201cInfinitesimal Chances and the\nLaws of Nature\u201d, <em>Australasian Journal of Philosophy</em>, 82\n(1): 67\u201376.",
                "\u2013\u2013\u2013, 2013, \u201cThe Puzzle of the Unmarked\nClock and the New Rational Reflection Principle\u201d,\n<em>Philosophical Studies</em> 164 (1): 127\u2013139.",
                "Eriksson, L. and A. H\u00e1jek, 2007, \u201cWhat Are Degrees of\nBelief?\u201d, <em>Studia Logica</em> (Special Issue, Formal\nEpistemology, Branden Fitelson, ed.), 86 (2): 185\u2013215.",
                "Eva, B., 2019, \u201cPrinciples of Indifference\u201d,\n<em>Journal of Philosophy</em>, 116 (7): 390\u2013411.",
                "Feller, W., 1968, <em>An Introduction to Probability Theory and\nIts Applications</em>, New York: John Wiley &amp; Sons.",
                "Festa, R., 1993, <em>Optimum Inductive Methods: A Study in\nInductive Probability, Bayesian Statistics, and Verisimilitude</em>,\nDordrecht: Kluwer (Synthese Library 232).",
                "Fetzer, J. H., 1981, <em>Scientific Knowledge: Causation,\nExplanation, and Corroboration</em> (Boston Studies in the Philosophy\nof Science, Volume 69), Dordrecht: D. Reidel.",
                "\u2013\u2013\u2013, 1982, \u201cProbabilistic\nExplanations\u201d, <em>PSA: Proceedings of the Biennial Meeting of\nPhilosophy of Science Association</em>, 2: 194\u2013207.",
                "\u2013\u2013\u2013, 1983, \u201cProbability and Objectivity in\nDeterministic and Indeterministic Situations\u201d,\n<em>Synthese</em>, 57: 367\u2013386.",
                "Fine, T., 1973, <em>Theories of Probability</em>, Waltham, MA:\nAcademic Press.",
                "\u2013\u2013\u2013, 2016, \u201cMathematical Alternatives to Standard\nProbability that Provide Selectable Degrees of Precision\u201d, in\nH\u00e1jek and Hitchcock (eds.) 2016, 203\u2013247.",
                "Fitelson, B., 2006, \u201cInductive Logic\u201d, in <em>The\nPhilosophy of Science: An Encyclopedia</em> (Volume 1: A\u2013M), S.\nSarkar and J. Pfeiffer (eds.), New York: Routledge,\n384\u2013394.",
                "Forster, M. and E. Sober, 1994, \u201cHow to Tell when Simpler,\nMore Unified, or Less Ad Hoc Theories will Provide More Accurate\nPredictions\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 45: 1\u201335.",
                "Franklin, J., 2001, <em>The Science of Conjecture: Evidence and\nProbability Before Pascal</em>, Baltimore: Johns Hopkins University\nPress.",
                "Frigg, R., 2016, \u201cChance and Determinism\u201d, in\nH\u00e1jek and Hitchcock (eds.) 2016, 460\u2013474.",
                "Gaifman, H., 1988, \u201cA Theory of Higher Order\nProbabilities\u201d, in <em>Causation, Chance, and Credence</em>, B.\nSkyrms and W. L. Harper (eds.), Dordrecht: Kluwer Academic Publishers,\n191\u2013219.",
                "Galavotti, M. C., 2005, <em>Philosophical Introduction to\nProbability</em>, Stanford: CSLI Publications.",
                "Giere, R. N., 1973, \u201cObjective Single-Case Probabilities and\nthe Foundations of Statistics\u201d, in <em>Logic, Methodology and\nPhilosophy of Science</em> (Volume IV), P. Suppes <em>et al</em>.,\n(eds.), New York: North-Holland, 467\u2013483. Also in Eagle\n2010.",
                "Gillies, D., 2000a, \u201cVarieties of Propensity\u201d,\n<em>British Journal for the Philosophy of Science</em>, 51:\n807\u2013835.",
                "\u2013\u2013\u2013, 2000b, <em>Philosophical Theories of\nProbability</em>, London: Routledge.",
                "\u2013\u2013\u2013, 2016, <em>The Propensity\nInterpretation</em>, in H\u00e1jek and Hitchcock (eds.) 2016,\n406\u2013422.",
                "Goldstein, M., 1983, \u201cThe Prevision of a Prevision\u201d,\n<em>Journal of the American Statistical Association</em>, 78:\n817\u2013819.",
                "Goodman, N., 1955, <em>Fact, Fiction, and Forecast</em>,\nCambridge, MA: Harvard University Press; 2nd edition, Indianapolis:\nBobbs-Merrill, 1965; 3rd edition Indianapolis: Bobbs-Merrill, 1973;\n4th edition, Cambridge, MA: Harvard University Press, 1983.",
                "Greaves, H., and D. Wallace, 2006, \u201cJustifying\nConditionalization: Conditionalization Maximizes Expected Epistemic\nUtility\u201d, <em>Mind</em>, 115 (459): 607\u2013632.",
                "Hacking, I., 1965, <em>The Logic of Statistical Inference</em>,\nCambridge: Cambridge University Press.",
                "H\u00e1jek, A., 1997, \u201c\u2018<em>Mises Redux\u2019\n\u2014 Redux</em>. Fifteen Arguments Against Finite\nFrequentism\u201d, <em>Erkenntnis</em>, 45: 209\u2013227. Also in\nEagle 2010.",
                "\u2013\u2013\u2013, 2003 \u201cWhat Conditional Probability\nCould Not Be\u201d, <em>Synthese</em>, 137 (3): 273\u2013323.",
                "\u2013\u2013\u2013, 2008, \u201cArguments for\u2014or\nAgainst\u2014Probabilism?\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, 59: 793\u2013819; reprinted in\n<em>Degrees of Belief</em>, F. Huber and C. Schmidt-Petri (eds.),\nDordrecht: Springer, 2009, 229\u2013251.",
                "\u2013\u2013\u2013, 2009a, \u201cFifteen Arguments Against\nHypothetical Frequentism\u201d, <em>Erkenntnis</em>, 70:\n211\u2013235. Also in Eagle 2010.",
                "\u2013\u2013\u2013, 2009b, \u201cDutch Book Arguments\u201d,\nin <em>The Oxford Handbook of Rational and Social Choice</em>, P.\nAnand, P. Pattanaik, and C. Puppe (eds.), Oxford: Oxford University\nPress, 173\u2013195.",
                "H\u00e1jek, A., and C. Hitchcock, (eds.), 2016, <em>The Oxford\nHandbook of Probability and Philosophy</em>, Oxford: Oxford University\nPress.",
                "H\u00e1jek, A. and C. Hitchcock, 2016b, \u201cProbability for\nEveryone\u2014Even Philosophers\u201d, in\nH\u00e1jek, A., and C. Hitchcock (eds.) 2016, pp. 5\u201330.",
                "H\u00e1jek, A. and H. Lin, 2017, \u201cA Tale of Two\nEpistemologies\u201d, <em>Res Philosophica</em>, 94 (2):\n207\u2013232.",
                "H\u00e1jek, A., and M. Smithson, 2012, \u201cRationality and\nIndeterminate Probabilities\u201d, <em>Synthese</em>, 187 (1):\n33\u201348.",
                "H\u00e1jek, A. and J. Staffel, 2021, \u201cSubjective\nProbability and Its Dynamics\u201d, in Knauff and Spohn (eds.)\n2021.",
                "Hall, N., 1994, \u201cCorrecting the Guide to Objective\nChance\u201d <em>Mind</em>, 103 (412): 505\u2013518.",
                "\u2013\u2013\u2013, 2003, \u201cTwo Concepts of\nCausation\u201d, in J.  Collins, N. Hall, and L. Paul (eds.),\n<em>Counterfactuals and Causation</em>, Cambridge, MA: MIT Press,\n225\u2013276.",
                "\u2013\u2013\u2013, 2004, \u201cTwo Mistakes About Credence\nand Chance\u201d, <em>Australasian Journal of Philosophy</em>, 82\n(1): 93\u2013111.",
                "Halpern, J., 2003, <em>Reasoning About Uncertainty</em>,\nCambridge, MA: The MIT Press.",
                "Handfield, T. and A. Wilson, 2014, \u201cChance and\nContext\u201d, in <em>Chance and Temporal Asymmetry</em>, A. Wilson\n(ed.), Oxford: Oxford University Press.",
                "Hawthorne, J., 2016, \u201cA Logic of Comparative Support:\nQualitative Conditional Probability Relations Representable by Popper\nFunctions\u201d, in H\u00e1jek and Hitchcock (eds.) 2016,\n277\u2013295.",
                "Hintikka, J., 1965, \u201cA Two-Dimensional Continuum of\nInductive Methods\u201d, in <em>Aspects of Inductive Logic</em>, J.\nHintikka and P. Suppes (eds.), Amsterdam: North-Holland,\n113\u2013132.",
                "Hitchcock, C., 2002, \u201cProbability and Chance\u201d, in the\n<em>International Encyclopedia of the Social and Behavioral\nSciences</em> (Volume 18), London: Elsevier, 12,089\u201312,095.",
                "Hoefer, C., 2007, \u201cThe Third Way on Objective Probability: A\nSkeptic\u2019s Guide to Objective Chance\u201d, <em>Mind</em>, 116\n(2): 549\u2013596.",
                "Howson, C. and P. Urbach, 1993, <em>Scientific Reasoning: The\nBayesian Approach</em>, La Salle, IL: Open Court, 2<sup>nd</sup>\nedition.",
                "Huber, F., 2018, <em>A Logical Introduction to Probability and\nInduction</em>, Oxford University Press.",
                "Humphreys, P., 1985, \u201cWhy Propensities Cannot Be\nProbabilities\u201d, <em>Philosophical Review</em>, 94: 557\u201370.\nAlso in Eagle 2010.",
                "Isaacs, Y., A. H\u00e1jek, and J. Hawthorne, 2022,\n\u201cNon-Measurability, Imprecise Credences, and Imprecise\nChances\u201d, <em>Mind</em>, 131 (523): 894\u2013918.",
                "Ismael, J., 2008, \u201cRaid! Dissolving the Big, Bad Bug\u201d,\n<em>No\u00fbs</em>, 42 (2): 292\u2013307.",
                "\u2013\u2013\u2013, 2009, \u201cProbability in Deterministic\nPhysics\u201d, <em>The Journal of Philosophy</em>, 106 (2):\n89\u2013108.",
                "Jackson, F., 1997, <em>From Metaphysics to Ethics: A Defence of\nConceptual Analysis</em>, Oxford: Oxford University Press.",
                "Jaynes, E. T., 1968, \u201cPrior Probabilities\u201d\n<em>Institute of Electrical and Electronic Engineers Transactions on\nSystems Science and Cybernetics</em>, SSC-4: 227\u2013241.",
                "Jeffrey, R., 1965, <em>The Logic of Decision</em>, Chicago:\nUniversity of Chicago Press; 2<sup>nd</sup> edition, 1983.",
                "\u2013\u2013\u2013, 1992, <em>Probability and the Art of\nJudgment</em>, Cambridge: Cambridge University Press.",
                "Jeffreys, H., 1939, <em>Theory of Probability</em>; reprinted in\nOxford Classics in the Physical Sciences series, Oxford: Oxford\nUniversity Press, 1998.",
                "Johnson, W. E., 1921, <em>Logic</em>, Cambridge: Cambridge\nUniversity Press.",
                "Joyce, J., 1998, \u201cA Nonpragmatic Vindication of\nProbabilism\u201d, <em>Philosophy of Science</em>, 65 (4):\n575\u2013603; reprinted in Eagle 2010.",
                "\u2013\u2013\u2013, 2004, \u201cWilliamson on Evidence and\nKnowledge\u201d, <em>Philosophical Books</em>, 45 (4):\n296\u2013305.",
                "\u2013\u2013\u2013,  2011, \u201cThe Development of Subjective\nBayesianism\u201d, in Gabbay, D. M., S. Hartmann, and J. Woods (eds),\n<em>Handbook of the History of Logic</em> (Volume 10: <em>Inductive\nLogic</em>), Boston: Elsevier, 415\u2013475.",
                "Kahneman, D., P. Slovic, and A. Tversky, (eds.), 1982,\n<em>Judgment Under Uncertainty. Heuristics and Biases</em>, Cambridge:\nCambridge University Press.",
                "Kelly, T., 2010, \u201cPeer Disagreement and Higher Order\nEvidence\u201d, in In Alvin I. Goldman &amp; Dennis Whitcomb (eds.),\n<em>Social Epistemology: Essential Readings</em>, Oxford: Oxford\nUniversity Press, pp. 183\u2013217.",
                "Kemeny, J., 1955, \u201cFair Bets and Inductive\nProbabilities\u201d, <em>Journal of Symbolic Logic</em>, 20:\n263\u2013273.",
                "Keynes, J. M., 1921, <em>A Treatise on Probability</em>, London:\nMacmillan and Co.",
                "Kiesepp\u00e4, I. A., 2001, \u201cStatistical Model Selection\nCriteria and Bayesianism\u201d, <em>Philosophy of Science</em>, 68\n(Proceedings): S141-S152.",
                "Knauff, Markus and Wolfgang Spohn, 2021, \n(eds.),  <em>Handbook of Rationality</em>, Cambridge, MA: MIT Press.\n[<a href=\"https://direct.mit.edu/books/oa-edited-volume/5525/The-Handbook-of-Rationality\" target=\"other\">Knauff and Spohn 2021 available online</a>].",
                "Kolmogorov, A. N., 1933, <em>Grundbegriffe der\nWahrscheinlichkeitrechnung</em>, Ergebnisse Der Mathematik; translated\nas <em>Foundations of Probability</em>, New York: Chelsea Publishing\nCompany, 1950.",
                "\u2013\u2013\u2013, 1965, \u201cThree Approaches to the\nQuantitative Definition of Information\u201d, <em>Problemy Perdaci\nInformacii</em>, 1: 4\u20137.",
                "Kopec, M., and M. G. Titelbaum, 2016, \u201cThe Uniqueness\nThesis\u201d, <em>Philosophy Compass</em>, 11 (4):\n189\u2013200.",
                "Kraemer, D. M, 2015, \u201cNatural Probabilistic\nInformation\u201d, <em>Synthese</em>, 192 (9): 2901\u20132919.",
                "Kyburg, H. E., 1970, <em>Probability and Inductive Logic</em>, New\nYork: Macmillan.",
                "Kyburg, H. E. and Smokler, H. E., (eds.), 1980, <em>Studies in\nSubjective Probability</em>, 2nd edition, Huntington, New York: Robert\nE. Krieger Publishing Co.",
                "La Caze, A., 2016, \u201cFrequentism\u201d, in H\u00e1jek and\nHitchcock (eds.) 2016, 341\u2013359.",
                "Laplace, P. S., 1814/1999. <em>Philosophical Essay of\nProbabilities</em>, translated by Andrew Dale, New York:\nSpringer.",
                "Lasonen-Aarnio, M., 2015, \u201cNew Rational Reflection and\nInternalism about Rationality\u201d, <em>Oxford Studies in\nEpistemology</em>, 5: 145\u2013171.",
                "Levi, I., 1978, \u201cCoherence, Regularity and Conditional\nProbability\u201d, <em>Theory and Decision</em>, 9: 1\u201315.",
                "Lewis, D., 1970, \u201cHow to Define Theoretical Terms\u201d,\n<em>Journal of Philosophy</em>, 67: 427\u2013446.",
                "\u2013\u2013\u2013, 1973, <em>Counterfactuals</em>, Oxford:\nBlackwell.",
                "\u2013\u2013\u2013, 1979,\u201cAttitudes De Dicto and De\nSe\u201d, <em>Philosophical Review</em>, 88: 513\u2013543.",
                "\u2013\u2013\u2013, 1980, \u201cA Subjectivist\u2019s Guide\nto Objective Chance\u201d, in Richard C. Jeffrey (ed.) <em>Studies in\nInductive Logic and Probability</em>, Vol II., Berkeley and Los\nAngeles: University of California Press; reprinted in Lewis 1986b,\n263\u2013294. Also in Eagle 2010.",
                "\u2013\u2013\u2013, 1986a, \u201cProbabilities of Conditionals\nand Conditional Probabilities II\u201d, <em>Philosophical\nReview</em>, 95: 581\u2013589.",
                "\u2013\u2013\u2013, 1986b, <em>Philosophical Papers: Volume\nII</em>, Oxford: Oxford University Press.",
                "\u2013\u2013\u2013, 1994a, \u201cReduction of Mind\u201d, in\n<em>A Companion to the Philosophy of Mind</em>, S. Guttenplan (ed.),\nOxford: Blackwell, 412\u2013431.",
                "\u2013\u2013\u2013, 1994b, \u201cHumean Supervenience\nDebugged\u201d, <em>Mind</em>, 103: 473\u2013490.",
                "Li, M. and P. Vit\u00e1nyi, 1997, <em>An Introduction to\nKolmogorov Complexity</em> <em>and Its Applications</em>,\n2<sup>nd</sup> ed., New York: Springer.",
                "Lin, Hanti, 2013, \u201cFoundations of Everyday Practical\nReasoning\u201d, <em>Journal of Philosophical Logic</em>, 42 (6):\n831\u2013862.",
                "Loewer, B., 2004, \u201cDavid Lewis\u2019s Humean Theory of\nObjective Chance\u201d, <em>Philosophy of Science</em>, 71 (5):\n1115\u20131125. Also in Eagle 2010.",
                "\u2013\u2013\u2013, 2012, \u201cTwo Accounts of Laws and Time\u201d,\n<em>Philosophical Studies</em>, 160 (1): 115\u2013137.",
                "\u2013\u2013\u2013, 2020, \u201cThe Mentaculus Vision\u201d,\nin V.  Allori (ed.) <em>Statistical Mechanics and Scientific\nExplanation: Determinism, Indeterminism, and Laws of Nature</em>,\nSingapore: World Scientific, 3\u201329.",
                "Lyon, A., 2011, \u201cDeterministic Probability: Neither Chance\nnor Credence\u201d, <em>Synthese</em>, 182 (3): 413\u201332.",
                "\u2013\u2013\u2013, 2014, \u201cFrom Kolmogorov, to Popper, to\nRenyi: There\u2019s No Escaping Humphreys\u2019 Paradox (When\nGeneralized)\u201d, in <em>Chance and Temporal Asymmetry</em>,\nOxford: Oxford University Press.",
                "\u2013\u2013\u2013, 2016, \u201cKolmogorov\u2019s\nAxiomatization and Its Discontents\u201d, in H\u00e1jek and\nHitchcock (eds.) 2016, 155\u2013166.",
                "Maher, P., 2000, \u201cProbabilities for Two Properties\u201d,\n<em>Erkenntnis</em>, 52: 63\u201391.",
                "\u2013\u2013\u2013, 2001, \u201cProbabilities for Multiple\nProperties: The Models of Hesse and Carnap and Kemeny\u201d,\n<em>Erkenntnis</em>, 55: 183\u2013216.",
                "\u2013\u2013\u2013, 2010, \u201cExplication of Inductive\nProbability\u201d, <em>Journal of Philosophical Logic</em>, 39:\n593\u2013616.",
                "Mahtani, A., 2022, \u201cDutch Book and Accuracy Theorems\u201d,\n<em>Proceedings of the Aristotelian Society</em>, 120 (3):\n309\u2013327.",
                "Martin-L\u00f6f, P., 1966, \u201cThe Definition of Random\nSequences\u201d, <em>Information and Control</em>, 9:\n602\u2013619.",
                "Meacham, C. J. G., 2008, \u201cSleeping Beauty and the Dynamics\nof De Se Beliefs\u201d, <em>Philosophical Studies</em>, 138 (2):\n245\u2013269.",
                "Meacham, C. J. G., and J. Weisberg, 2011, \u201cRepresentation\nTheorems and the Foundations of Decision Theory\u201d,\n<em>Australasian Journal of Philosophy</em>, 89 (4):\n641\u2013663.",
                "Mellor, D. H., 2005, <em>Probability: A Philosophical\nIntroduction</em>, London: Routledge.",
                "Miller, D. W., 1994, <em>Critical Rationalism: A Restatement and\nDefence</em>, Lasalle, Il: Open Court.",
                "Nielsen, M., 2023, \u201cAccuracy and Probabilism in Infinite\nDomains\u201d, <em>Mind</em>, 132 (526): 402\u2013427.",
                "Norton, J. D., 2008, \u201cIgnorance and Indifference\u201d,\n<em>Philosophy of Science</em>, 75 (1): 45\u201368.",
                "Paris J. and A. Vencovsk\u00e1, 1997, \u201cIn Defence of the\nMaximum Entropy Inference Process\u201d, <em>International Journal of\nApproximate Reasoning</em>, 17: 77\u2013103.",
                "Pearl, J., 2000, <em>Causality</em>, Cambridge: Cambridge\nUniversity Press.",
                "Peirce, C. S., 1957, \u201cNotes on the Doctrine of\nChances\u201d, in <em>Essays in the Philosophy of Science</em> (The\nAmerican Heritage Series), Indianapolis and New York: Bobbs-Merrill,\n74\u201384.",
                "Pettigrew, R., 2014, \u201cAccuracy, Risk, and the Principle of\nIndifference\u201d <em>Philosophy and Phenomenological Research</em>,\n92 (1): 35\u201359.",
                "\u2013\u2013\u2013, 2016, <em>Accuracy and the Laws of\nCredence</em>, Oxford: Oxford University Press.",
                "\u2013\u2013\u2013, 2020, <em>Dutch Book Arguments</em>\n(Elements in Decision Theory and Philosophy), Cambridge: Cambridge\nUniversity Press.",
                "Poincar\u00e9, H. 1896, <em>Calcul des Probabilit\u00e9s</em>,\nParis: Gauthier-Villars.",
                "Popper, K. R., 1957, \u201cThe Propensity Interpretation of the\nCalculus of Probability and the Quantum Theory\u201d, in S.\nK\u00f6rner (ed.), <em>The Colston Papers</em>, 9: 65\u201370.",
                "\u2013\u2013\u2013, 1959a, \u201cThe Propensity Interpretation\nof Probability\u201d, <em>British Journal of the Philosophy of\nScience</em>, 10: 25\u201342. Also in Eagle 2010.",
                "\u2013\u2013\u2013, 1959b, <em>The Logic of Scientific\nDiscovery</em>, New York: Basic Books; reprinted, London: Routledge,\n1992.",
                "\u2013\u2013\u2013, 1990, <em>A World of Propensities \u2013\nTwo New Views on Causality</em>, Bristol: Thoemmes.",
                "Predd, J. B., R. Seiringer, E. H. Lieb, D. N. Osherson, H. V.\nPoor, and S. R. Kulkarni, 2009, \u201cProbabilistic Coherence and\nProper Scoring Rules\u201d, <em>IEEE Transactions on Information\nTheory</em>, 55 (10): 4786\u20134792.",
                "Ramsey, F. P., 1926, \u201cTruth and Probability\u201d, in\n<em>Foundations of Mathematics and other Essays</em>, R. B.\nBraithwaite (ed.), London: Kegan, Paul, Trench, Trubner, &amp; Co.,\n1931, 156\u2013198; reprinted in <em>Studies in Subjective\nProbability</em>, H. E. Kyburg, Jr. and H. E. Smokler (eds.),\n2<sup>nd</sup> edition, New York: R. E. Krieger Publishing Company,\n1980, 23\u201352; reprinted in <em>Philosophical Papers</em>, D. H.\nMellor (ed.), Cambridge: Cambridge University Press, 1990,\n52\u201394. Also in Eagle 2010.",
                "\u2013\u2013\u2013, 1928/1990, \u201cGeneral Propositions and\nCausality\u201d, <em>Philosophical Papers</em>, edited by D. H.\nMellor, Cambridge: Cambridge University Press, 145\u2013163.",
                "Reichenbach, H., 1949, <em>The Theory of Probability</em>,\nBerkeley: University of California Press.",
                "R\u00e9nyi, A., 1970, <em>Foundations of Probability</em>, San\nFrancisco: Holden-Day, Inc.",
                "Rinard, S., 2014, \u201cThe Principle of Indifference and\nImprecise Probability\u201d, <em>Thought</em>, 3: 110\u2013114.",
                "Rissanen, J. 1999, \u201cHypothesis Selection and Testing by the\nMDL Principle\u201d, <em>Computer Journal</em>, 42 (4):\n260\u2013269.",
                "Roeper, P. and H. Leblanc, 1999, <em>Probability Theory and\nProbability Logic</em>, Toronto: University of Toronto Press.",
                "Ross, S., 2013,<em>A First Course in Probability</em>, 9th\nedition, Upper Saddle River, NJ: Pearson.",
                "Salmon, W., 1966, <em>The Foundations of Scientific\nInference</em>, Pittsburgh: University of Pittsburgh Press.",
                "Savage, L. J., 1954, <em>The Foundations of Statistics</em>, New\nYork: John Wiley.",
                "Scarantino, A., 2015, \u201cInformation as a Probabilistic\nDifference Maker\u201d, <em>Australasian Journal of Philosophy</em>,\n93 (3): 419\u2013443.",
                "Schaffer, J., 2007, \u201cDeterministic Chance?\u201d, <em>The\nBritish Journal for the Philosophy of Science</em>, 58 (2):\n113\u2013140.",
                "Schervish, M. J., T. Seidenfeld, and J. B. Kadane, 2003,\n\u201cMeasures of Incoherence\u201d, in <em>Bayesian Statistics</em>\n(Volume 7), J.M. Bernardo, et al. (eds.), Oxford: Oxford University\nPress, 385\u2013402.",
                "Schoenfield, M., 2017a, \u201cConditionalization Does Not (in\nGeneral) Maximize Expected Accuracy\u201d, <em>Mind</em>, 126 (504):\n1155\u20131187.",
                "\u2013\u2013\u2013, 2017b, \u201cThe Accuracy and Rationality\nof Imprecise Credences\u201d, <em>No\u00fbs</em>, 51 (4):\n667\u2013685.",
                "\u2013\u2013\u2013, 2019, \u201cPermission to Believe: Why\nPermissivism Is True and What It Tells Us about Irrelevant Influences\non Belief\u201d, in J. Fantl, M. McGrath, and E. Sosa (eds.),\n<em>Contemporary Epistemology: An Anthology</em>, Hoboken:\nWiley-Blackwell, 277\u2013295.",
                "Schwarz, W., 2014, \u201cProving the Principal Principle\u201d,\nin <em>Chance and Temporal Asymmetry</em>, A. Wilson (ed.), Oxford:\nOxford University Press, 81\u201399.",
                "\u2013\u2013\u2013, 2016, \u201cBest System Approaches to\nChance\u201d, in H\u00e1jek and Hitchock (eds.), 2016,\n423\u2013439.",
                "\u2013\u2013\u2013, 2018, \u201cNo Interpretation of\nProbability\u201d, <em>Erkenntnis</em>, 83 (6): 1195\u20131212.",
                "Scott D., and P. Krauss, 1966, \u201cAssigning Probabilities to\nLogical Formulas\u201d, in <em>Aspects of Inductive Logic</em>, J.\nHintikka and P. Suppes (eds.), Amsterdam: North-Holland,\n219\u2013264.",
                "Seidenfeld, T., 1986, \u201cEntropy and Uncertainty\u201d,\n<em>Philosophy of Science</em>, 53: 467\u2013491.",
                "Shannon, C. E., 1948, \u201cA Mathematical Theory of\nCommunication\u201d, <em>Bell System Technical Journal</em>, 27 (3):\n379\u2013423.",
                "Shannon, C. E, and W. Weaver, 1949, <em>The Mathematical Theory of\nCommunication</em>, University of Illinois Press.",
                "Shimony, A., 1970, \u201cScientific Inference\u201d, in <em>The\nNature and Function of Scientific Theories</em>, R. Colodny (ed.),\nPittsburgh: University of Pittsburgh Press.",
                "\u2013\u2013\u2013, 1988, \u201cAn Adamite Derivation of the\nCalculus of Probability\u201d, in J.H. Fetzer (ed.), <em>Probability\nand Causality</em>, Dordrecht: D. Reidel.",
                "Skyrms, B., 1980, <em>Causal Necessity</em>, New Haven: Yale\nUniversity Press.",
                "\u2013\u2013\u2013, 1984, <em>Pragmatics and Empiricism</em>,\nNew Haven: Yale University Press.",
                "\u2013\u2013\u2013, 2000, <em>Choice and Chance</em>,\n4<sup>th</sup> edition, Belmont, CA: Wadsworth, Inc.",
                "Sober, E., 2000, <em>Philosophy of Biology</em>, 2<sup>nd</sup>\nedition, Boulder, CO: Westview Press.",
                "Spirtes, P., C. Glymour, and R. Scheines, 1993, <em>Causation,\nPrediction, and Search</em>, New York: Springer-Verlag.",
                "Spohn, W., 1986, \u201cThe Representation of Popper\nMeasures\u201d, <em>Topoi</em>, 5: 69\u201374.",
                "Staffel, J., 2019, <em>Unsettled Thoughts: A Theory of Degrees of\nRationality</em>, Oxford: Oxford University Press.",
                "Stalnaker, R., 1970, \u201cProbabilities and Conditionals\u201d,\n<em>Philosophy of Science</em>, 37: 64\u201380.",
                "Stove, D. C., 1986, <em>The Rationality of Induction</em>, Oxford:\nOxford University Press.",
                "Strevens, M., 2003, <em>Bigger Than Chaos: Understanding\nComplexity through Probability</em>, Cambridge, MA: Harvard University\nPress.",
                "\u2013\u2013\u2013, 2013, <em>Tychomancy</em>, Cambridge, MA:\nHarvard University Press.",
                "Titelbaum, M. G., 2013, <em>Quitting Certainties: A Bayesian\nFramework Modeling Degrees of Belief</em>, Oxford University\nPress.",
                "\u2013\u2013\u2013, 2016, \u201cSelf-Locating\nCredences\u201d, in H\u00e1jek and Hitchcock (eds.) 2016,\n666\u2013680.",
                "\u2013\u2013\u2013, 2017, \u201cOne\u2019s Own\nReasoning\u201d, <em>Inquiry</em>, 60 (3): 208\u2013232.",
                "\u2013\u2013\u2013, 2017, <em>Fundamentals of Bayesian\nEpistemology</em> (Volumes 1 and 2), Oxford: Oxford University\nPress.",
                "van Fraassen, B., 1984, \u201cBelief and the Will\u201d,\n<em>Journal of Philosophy</em>, 81: 235\u2013256. Also in Eagle\n2010.",
                "\u2013\u2013\u2013, 1989, <em>Laws and Symmetry</em>, Oxford:\nClarendon Press.",
                "\u2013\u2013\u2013, 1995a, \u201cBelief and the Problem of\nUlysses and the Sirens\u201d, <em>Philosophical Studies</em>, 77:\n7\u201337.",
                "\u2013\u2013\u2013, 1995b, \u201cFine-grained Opinion,\nConditional Probability, and the Logic of Belief\u201d, <em>Journal\nof Philosophical Logic</em>, 24: 349\u2013377.",
                "Venn, J., 1876, <em>The Logic of Chance</em>, 2<sup>nd</sup>\nedition, London: Macmillan; reprinted, New York: Chelsea Publishing\nCo., 1962.",
                "von Mises R., 1957, <em>Probability, Statistics and Truth</em>,\nrevised English edition, New York: Macmillan.",
                "von Neumann, J. and O. Morgenstern, 1944, <em>Theory of Games and\nEconomic Behavior</em>, Princeton: Princeton University Press; New\nYork: John Wiley and Sons, 1964.",
                "von Plato J., 1994, <em>Creating Modern Probability</em>,\nCambridge: Cambridge University Press.",
                "Wallace, C. S. and D. L. Dowe, 1999, \u201cMinimum Message Length\nand Kolmogorov Complexity\u201d, <em>Computer Journal</em> (Special\nIssue: Kolmogorov Complexity), 42 (4): 270\u2013283.",
                "White, R., 2010, \u201cEvidential Symmetry and Mushy\nCredence\u201d, <em>Oxford Studies in Epistemology</em>, 3 (161):\n20.",
                "Williamson, J., 1999, \u201cCountable Additivity and Subjective\nProbability\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 50 (3): 401\u2013416.",
                "Williamson, T., 2000, <em>Knowledge and Its Limits</em>, Oxford:\nOxford University Press.",
                "\u2013\u2013\u2013, 2014, \u201cVery Improbable\nKnowing\u201d, <em>Erkenntnis</em>, 79 (5): 971\u2013999.",
                "Woodward, J., 2003, <em>A Theory of Explanation: Causation,\nInvariance and Intervention</em>, Oxford: Oxford University\nPress.",
                "Zabell, S. 2016, \u201cSymmetry Arguments in Probability\u201d,\nin H\u00e1jek and Hitchcock (eds.) 2016, 315\u2013340.",
                "Zynda, L., 1996, \u201cCoherence as an Ideal of\nRationality\u201d, <em>Synthese</em> 109(2): 175\u2013216.",
                "\u2013\u2013\u2013, 2000, \u201cRepresentation Theorems and\nRealism about Degrees of Belief\u201d, <em>Philosophy of Science</em>\n67(1): 45\u201369."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2><a id=\"Bib\">Bibliography</a></h2>\n<ul class=\"hanging\">\n<li>Albert, D., 2000, <em>Time and Chance</em>, Cambridge, MA: Harvard\nUniversity Press.</li>\n<li>Arnauld, A., 1662, <em>Logic, or, The Art of Thinking</em>\n(\u201cThe Port Royal Logic\u201d), tr. J. Dickoff and P. James,\nIndianapolis: Bobbs-Merrill, 1964.</li>\n<li>Bacon, A., 2014, \u201cGiving Your Knowledge Half A\nChance\u201d, <em>Philosophical Studies</em>, 171 (2):\n373\u2013397.</li>\n<li>Bartha, P. and R. Johns, 2001, \u201cProbability and\nSymmetry\u201d, <em>Philosophy of Science</em>, 68 (Proceedings):\nS109\u2013S122.</li>\n<li>Bell, E. T., 1945, <em>The Development of Mathematics</em>, 2nd\nedition, New York, McGraw-Hill Book Company.</li>\n<li>Bertrand, J., 1889, <em>Calcul des Probabilit\u00e9s</em>\n[<em>Calculus of Probabilities</em>], Paris, France:\nGauthier-Villars.</li>\n<li>Billingsley, P., 1995, <em>Probability and Measure</em>, 3rd\nedition, New York: John Wiley &amp; Sons.</li>\n<li>Briggs, R., 2009, \u201cThe Anatomy of the Big Bad Bug\u201d,\n<em>No\u00fbs</em>, 43 (3): 428\u2013449.\ndoi:10.1111/nous.12258</li>\n<li>Briggs, R. A., and R. Pettigrew, 2020, \u201cAn\nAccuracy-Dominance Argument for Conditionalization\u201d,\n<em>No\u00fbs</em> 54 (1): 162\u2013181, doi:10.1111/nous.12258</li>\n<li>Buchak, L., 2016, \u201cDecision Theory\u201d, in H\u00e1jek\nand Hitchcock (eds.) 2016, 789\u2013815.</li>\n<li>Carnap, R., 1950, <em>Logical Foundations of Probability</em>,\nChicago: University of Chicago Press; 2nd edition, 1962.</li>\n<li>\u2013\u2013\u2013, 1952, <em>The Continuum of Inductive\nMethods</em>, Chicago: University of Chicago Press.</li>\n<li>\u2013\u2013\u2013, 1963, \u201cReplies and Systematic\nExpositions\u201d, in <em>The Philosophy of Rudolf Carnap</em>, P. A.\nSchilpp, (ed.), La Salle, IL: Open Court, 859\u20131013.</li>\n<li>Childers, T., 2013, <em>Philosophy and Probability</em>, Oxford\nUniversity Press.</li>\n<li>Christensen, D., 2010, \u201cRational Reflection\u201d,\n<em>Philosophical Perspectives</em>, 24 (1): 121\u2013140.</li>\n<li>Church, A., 1940, \u201cOn the Concept of a Random\nSequence\u201d, <em>Bulletin of the American Mathematical\nSociety</em>, 46: 130\u2013135.</li>\n<li>Cover, T. M., and J. A. Thomas, 1991, <em>Elements of Information\nTheory</em>, New York: John Wiley &amp; Sons, Inc.</li>\n<li>Cozman, F. G., 2016, \u201cImprecise and Indeterminate\nProbabilities\u201d, in H\u00e1jek and Hitchcock (eds.) 2016,\n296\u2013311.</li>\n<li>De Bona, G., and J. Staffel, 2017, \u201cGraded Incoherence for\nAccuracy Firsters\u201d, <em>Philosophy of Science</em>, 284 (2):\n189\u2013213.</li>\n<li>\u2013\u2013\u2013, 2018, \u201cWhy Be (Approximately)\nCoherent?\u201d, <em>Analysis</em>, 78 (3): 405\u2013415.</li>\n<li>de Finetti, B., 1937, \u201cLa Pr\u00e9vision: Ses Lois\nLogiques, Ses Sources Subjectives\u201d, <em>Annales de\nl\u2019Institut Henri Poincar\u00e9</em>, 7: 1\u201368; translated\nas \u201cForesight. Its Logical Laws, Its Subjective Sources\u201d,\nin <em>Studies in Subjective Probability</em>, H. E. Kyburg, Jr. and\nH. E. Smokler (eds.), Robert E. Krieger Publishing Company, 1980,\n55\u2013118.</li>\n<li>\u2013\u2013\u2013, 1972, <em>Probability, Induction and\nStatistics</em>, New York: Wiley.</li>\n<li>\u2013\u2013\u2013, 1990 [1974], <em>Theory of Probability</em>\n(Volume 1), New York: John Wiley &amp; Sons.</li>\n<li>de Moivre, A., 1718/1967, <em>The Doctrine of Chances: or, A\nMethod of Calculating the Probability of Events in Play</em>, London:\nW. Pearson, 1718; 2nd edition, 1738; 3rd edition 1756; reprinted 1967,\nNew York, NY: Chelsea.</li>\n<li>De Morgan, A., 1847, <em>Formal Logic, or, The Calculus of\nInference, Necessary and Probable</em>, London: Taylor and\nWalton.</li>\n<li>Dogramaci, S., and S. Horowitz, 2016, \u201cAn Argument for\nUniqueness about Evidential Support\u201d, <em>Philosophical\nIssues</em> 26 (1): 130\u2013147.</li>\n<li>Eagle, A., 2010, <em>Philosophy of Probability: Contemporary\nReadings</em>, London: Routledge.</li>\n<li>\u2013\u2013\u2013, 2004, \u201cTwenty-One Arguments Against\nPropensity Analyses of Probability\u201d, <em>Erkenntnis</em>, 60:\n371\u2013416.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cProbability and\nRandomness\u201d, in H\u00e1jek and Hitchcock (eds.) 2016,\n440\u2013459.</li>\n<li>\u2013\u2013\u2013, 2018, \u201cChance, Determinism, and\nUnsettledness\u201d, <em>Philosophical Studies</em>, 1\u201322.</li>\n<li>Earman, J., 1992, <em>Bayes or Bust?</em>, Cambridge, MA: MIT\nPress.</li>\n<li>Easwaran, K., 2013, \u201cExpected Accuracy Supports\nConditionalization\u2014and Conglomerability and Reflection\u201d,\n<em>Philosophy of Science</em> 80 (1): 119\u2013142.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cDr. Truthlove or: How I\nLearned to Stop Worrying and Love Bayesian Probabilities\u201d,\n<em>No\u00fbs</em> 50 (4): 816\u2013853.</li>\n<li>Eder A. A.., 2023, \u201cEvidential Probabilities and\nCredences\u201d, <em>The British Journal for the Philosophy of\nScience</em> 74 (1).</li>\n<li>Edwards, W., H. Lindman, and L. J. Savage, 1963, \u201cBayesian\nStatistical Inference for Psychological Research\u201d,\n<em>Psychological Review</em>, 70: 193\u2013242.</li>\n<li>Elga, A., 2000, \u201cSelf-Locating Belief and the Sleeping\nBeauty Problem\u201d, <em>Analysis</em>, 60 (2): 143\u2013147. Also\nin Eagle 2010.</li>\n<li>\u2013\u2013\u2013, 2004, \u201cInfinitesimal Chances and the\nLaws of Nature\u201d, <em>Australasian Journal of Philosophy</em>, 82\n(1): 67\u201376.</li>\n<li>\u2013\u2013\u2013, 2013, \u201cThe Puzzle of the Unmarked\nClock and the New Rational Reflection Principle\u201d,\n<em>Philosophical Studies</em> 164 (1): 127\u2013139.</li>\n<li>Eriksson, L. and A. H\u00e1jek, 2007, \u201cWhat Are Degrees of\nBelief?\u201d, <em>Studia Logica</em> (Special Issue, Formal\nEpistemology, Branden Fitelson, ed.), 86 (2): 185\u2013215.</li>\n<li>Eva, B., 2019, \u201cPrinciples of Indifference\u201d,\n<em>Journal of Philosophy</em>, 116 (7): 390\u2013411.</li>\n<li>Feller, W., 1968, <em>An Introduction to Probability Theory and\nIts Applications</em>, New York: John Wiley &amp; Sons.</li>\n<li>Festa, R., 1993, <em>Optimum Inductive Methods: A Study in\nInductive Probability, Bayesian Statistics, and Verisimilitude</em>,\nDordrecht: Kluwer (Synthese Library 232).</li>\n<li>Fetzer, J. H., 1981, <em>Scientific Knowledge: Causation,\nExplanation, and Corroboration</em> (Boston Studies in the Philosophy\nof Science, Volume 69), Dordrecht: D. Reidel.</li>\n<li>\u2013\u2013\u2013, 1982, \u201cProbabilistic\nExplanations\u201d, <em>PSA: Proceedings of the Biennial Meeting of\nPhilosophy of Science Association</em>, 2: 194\u2013207.</li>\n<li>\u2013\u2013\u2013, 1983, \u201cProbability and Objectivity in\nDeterministic and Indeterministic Situations\u201d,\n<em>Synthese</em>, 57: 367\u2013386.</li>\n<li>Fine, T., 1973, <em>Theories of Probability</em>, Waltham, MA:\nAcademic Press.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cMathematical Alternatives to Standard\nProbability that Provide Selectable Degrees of Precision\u201d, in\nH\u00e1jek and Hitchcock (eds.) 2016, 203\u2013247.</li>\n<li>Fitelson, B., 2006, \u201cInductive Logic\u201d, in <em>The\nPhilosophy of Science: An Encyclopedia</em> (Volume 1: A\u2013M), S.\nSarkar and J. Pfeiffer (eds.), New York: Routledge,\n384\u2013394.</li>\n<li>Forster, M. and E. Sober, 1994, \u201cHow to Tell when Simpler,\nMore Unified, or Less Ad Hoc Theories will Provide More Accurate\nPredictions\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 45: 1\u201335.</li>\n<li>Franklin, J., 2001, <em>The Science of Conjecture: Evidence and\nProbability Before Pascal</em>, Baltimore: Johns Hopkins University\nPress.</li>\n<li>Frigg, R., 2016, \u201cChance and Determinism\u201d, in\nH\u00e1jek and Hitchcock (eds.) 2016, 460\u2013474.</li>\n<li>Gaifman, H., 1988, \u201cA Theory of Higher Order\nProbabilities\u201d, in <em>Causation, Chance, and Credence</em>, B.\nSkyrms and W. L. Harper (eds.), Dordrecht: Kluwer Academic Publishers,\n191\u2013219.</li>\n<li>Galavotti, M. C., 2005, <em>Philosophical Introduction to\nProbability</em>, Stanford: CSLI Publications.</li>\n<li>Giere, R. N., 1973, \u201cObjective Single-Case Probabilities and\nthe Foundations of Statistics\u201d, in <em>Logic, Methodology and\nPhilosophy of Science</em> (Volume IV), P. Suppes <em>et al</em>.,\n(eds.), New York: North-Holland, 467\u2013483. Also in Eagle\n2010.</li>\n<li>Gillies, D., 2000a, \u201cVarieties of Propensity\u201d,\n<em>British Journal for the Philosophy of Science</em>, 51:\n807\u2013835.</li>\n<li>\u2013\u2013\u2013, 2000b, <em>Philosophical Theories of\nProbability</em>, London: Routledge.</li>\n<li>\u2013\u2013\u2013, 2016, <em>The Propensity\nInterpretation</em>, in H\u00e1jek and Hitchcock (eds.) 2016,\n406\u2013422.</li>\n<li>Goldstein, M., 1983, \u201cThe Prevision of a Prevision\u201d,\n<em>Journal of the American Statistical Association</em>, 78:\n817\u2013819.</li>\n<li>Goodman, N., 1955, <em>Fact, Fiction, and Forecast</em>,\nCambridge, MA: Harvard University Press; 2nd edition, Indianapolis:\nBobbs-Merrill, 1965; 3rd edition Indianapolis: Bobbs-Merrill, 1973;\n4th edition, Cambridge, MA: Harvard University Press, 1983.</li>\n<li>Greaves, H., and D. Wallace, 2006, \u201cJustifying\nConditionalization: Conditionalization Maximizes Expected Epistemic\nUtility\u201d, <em>Mind</em>, 115 (459): 607\u2013632.</li>\n<li>Hacking, I., 1965, <em>The Logic of Statistical Inference</em>,\nCambridge: Cambridge University Press.</li>\n<li>H\u00e1jek, A., 1997, \u201c\u2018<em>Mises Redux\u2019\n\u2014 Redux</em>. Fifteen Arguments Against Finite\nFrequentism\u201d, <em>Erkenntnis</em>, 45: 209\u2013227. Also in\nEagle 2010.</li>\n<li>\u2013\u2013\u2013, 2003 \u201cWhat Conditional Probability\nCould Not Be\u201d, <em>Synthese</em>, 137 (3): 273\u2013323.</li>\n<li>\u2013\u2013\u2013, 2008, \u201cArguments for\u2014or\nAgainst\u2014Probabilism?\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, 59: 793\u2013819; reprinted in\n<em>Degrees of Belief</em>, F. Huber and C. Schmidt-Petri (eds.),\nDordrecht: Springer, 2009, 229\u2013251.</li>\n<li>\u2013\u2013\u2013, 2009a, \u201cFifteen Arguments Against\nHypothetical Frequentism\u201d, <em>Erkenntnis</em>, 70:\n211\u2013235. Also in Eagle 2010.</li>\n<li>\u2013\u2013\u2013, 2009b, \u201cDutch Book Arguments\u201d,\nin <em>The Oxford Handbook of Rational and Social Choice</em>, P.\nAnand, P. Pattanaik, and C. Puppe (eds.), Oxford: Oxford University\nPress, 173\u2013195.</li>\n<li>H\u00e1jek, A., and C. Hitchcock, (eds.), 2016, <em>The Oxford\nHandbook of Probability and Philosophy</em>, Oxford: Oxford University\nPress.</li>\n<li>H\u00e1jek, A. and C. Hitchcock, 2016b, \u201cProbability for\nEveryone\u2014Even Philosophers\u201d, in\nH\u00e1jek, A., and C. Hitchcock (eds.) 2016, pp. 5\u201330.</li>\n<li>H\u00e1jek, A. and H. Lin, 2017, \u201cA Tale of Two\nEpistemologies\u201d, <em>Res Philosophica</em>, 94 (2):\n207\u2013232.</li>\n<li>H\u00e1jek, A., and M. Smithson, 2012, \u201cRationality and\nIndeterminate Probabilities\u201d, <em>Synthese</em>, 187 (1):\n33\u201348.</li>\n<li>H\u00e1jek, A. and J. Staffel, 2021, \u201cSubjective\nProbability and Its Dynamics\u201d, in Knauff and Spohn (eds.)\n2021.</li>\n<li>Hall, N., 1994, \u201cCorrecting the Guide to Objective\nChance\u201d <em>Mind</em>, 103 (412): 505\u2013518.</li>\n<li>\u2013\u2013\u2013, 2003, \u201cTwo Concepts of\nCausation\u201d, in J.  Collins, N. Hall, and L. Paul (eds.),\n<em>Counterfactuals and Causation</em>, Cambridge, MA: MIT Press,\n225\u2013276.</li>\n<li>\u2013\u2013\u2013, 2004, \u201cTwo Mistakes About Credence\nand Chance\u201d, <em>Australasian Journal of Philosophy</em>, 82\n(1): 93\u2013111.</li>\n<li>Halpern, J., 2003, <em>Reasoning About Uncertainty</em>,\nCambridge, MA: The MIT Press.</li>\n<li>Handfield, T. and A. Wilson, 2014, \u201cChance and\nContext\u201d, in <em>Chance and Temporal Asymmetry</em>, A. Wilson\n(ed.), Oxford: Oxford University Press.</li>\n<li>Hawthorne, J., 2016, \u201cA Logic of Comparative Support:\nQualitative Conditional Probability Relations Representable by Popper\nFunctions\u201d, in H\u00e1jek and Hitchcock (eds.) 2016,\n277\u2013295.</li>\n<li>Hintikka, J., 1965, \u201cA Two-Dimensional Continuum of\nInductive Methods\u201d, in <em>Aspects of Inductive Logic</em>, J.\nHintikka and P. Suppes (eds.), Amsterdam: North-Holland,\n113\u2013132.</li>\n<li>Hitchcock, C., 2002, \u201cProbability and Chance\u201d, in the\n<em>International Encyclopedia of the Social and Behavioral\nSciences</em> (Volume 18), London: Elsevier, 12,089\u201312,095.</li>\n<li>Hoefer, C., 2007, \u201cThe Third Way on Objective Probability: A\nSkeptic\u2019s Guide to Objective Chance\u201d, <em>Mind</em>, 116\n(2): 549\u2013596.</li>\n<li>Howson, C. and P. Urbach, 1993, <em>Scientific Reasoning: The\nBayesian Approach</em>, La Salle, IL: Open Court, 2<sup>nd</sup>\nedition.</li>\n<li>Huber, F., 2018, <em>A Logical Introduction to Probability and\nInduction</em>, Oxford University Press.</li>\n<li>Humphreys, P., 1985, \u201cWhy Propensities Cannot Be\nProbabilities\u201d, <em>Philosophical Review</em>, 94: 557\u201370.\nAlso in Eagle 2010.</li>\n<li>Isaacs, Y., A. H\u00e1jek, and J. Hawthorne, 2022,\n\u201cNon-Measurability, Imprecise Credences, and Imprecise\nChances\u201d, <em>Mind</em>, 131 (523): 894\u2013918.</li>\n<li>Ismael, J., 2008, \u201cRaid! Dissolving the Big, Bad Bug\u201d,\n<em>No\u00fbs</em>, 42 (2): 292\u2013307.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cProbability in Deterministic\nPhysics\u201d, <em>The Journal of Philosophy</em>, 106 (2):\n89\u2013108.</li>\n<li>Jackson, F., 1997, <em>From Metaphysics to Ethics: A Defence of\nConceptual Analysis</em>, Oxford: Oxford University Press.</li>\n<li>Jaynes, E. T., 1968, \u201cPrior Probabilities\u201d\n<em>Institute of Electrical and Electronic Engineers Transactions on\nSystems Science and Cybernetics</em>, SSC-4: 227\u2013241.</li>\n<li>Jeffrey, R., 1965, <em>The Logic of Decision</em>, Chicago:\nUniversity of Chicago Press; 2<sup>nd</sup> edition, 1983.</li>\n<li>\u2013\u2013\u2013, 1992, <em>Probability and the Art of\nJudgment</em>, Cambridge: Cambridge University Press.</li>\n<li>Jeffreys, H., 1939, <em>Theory of Probability</em>; reprinted in\nOxford Classics in the Physical Sciences series, Oxford: Oxford\nUniversity Press, 1998.</li>\n<li>Johnson, W. E., 1921, <em>Logic</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li>Joyce, J., 1998, \u201cA Nonpragmatic Vindication of\nProbabilism\u201d, <em>Philosophy of Science</em>, 65 (4):\n575\u2013603; reprinted in Eagle 2010.</li>\n<li>\u2013\u2013\u2013, 2004, \u201cWilliamson on Evidence and\nKnowledge\u201d, <em>Philosophical Books</em>, 45 (4):\n296\u2013305.</li>\n<li>\u2013\u2013\u2013,  2011, \u201cThe Development of Subjective\nBayesianism\u201d, in Gabbay, D. M., S. Hartmann, and J. Woods (eds),\n<em>Handbook of the History of Logic</em> (Volume 10: <em>Inductive\nLogic</em>), Boston: Elsevier, 415\u2013475.</li>\n<li>Kahneman, D., P. Slovic, and A. Tversky, (eds.), 1982,\n<em>Judgment Under Uncertainty. Heuristics and Biases</em>, Cambridge:\nCambridge University Press.</li>\n<li>Kelly, T., 2010, \u201cPeer Disagreement and Higher Order\nEvidence\u201d, in In Alvin I. Goldman &amp; Dennis Whitcomb (eds.),\n<em>Social Epistemology: Essential Readings</em>, Oxford: Oxford\nUniversity Press, pp. 183\u2013217.</li>\n<li>Kemeny, J., 1955, \u201cFair Bets and Inductive\nProbabilities\u201d, <em>Journal of Symbolic Logic</em>, 20:\n263\u2013273.</li>\n<li>Keynes, J. M., 1921, <em>A Treatise on Probability</em>, London:\nMacmillan and Co.</li>\n<li>Kiesepp\u00e4, I. A., 2001, \u201cStatistical Model Selection\nCriteria and Bayesianism\u201d, <em>Philosophy of Science</em>, 68\n(Proceedings): S141-S152.</li>\n<li>Knauff, Markus and Wolfgang Spohn, 2021, \n(eds.),  <em>Handbook of Rationality</em>, Cambridge, MA: MIT Press.\n[<a href=\"https://direct.mit.edu/books/oa-edited-volume/5525/The-Handbook-of-Rationality\" target=\"other\">Knauff and Spohn 2021 available online</a>].</li>\n<li>Kolmogorov, A. N., 1933, <em>Grundbegriffe der\nWahrscheinlichkeitrechnung</em>, Ergebnisse Der Mathematik; translated\nas <em>Foundations of Probability</em>, New York: Chelsea Publishing\nCompany, 1950.</li>\n<li>\u2013\u2013\u2013, 1965, \u201cThree Approaches to the\nQuantitative Definition of Information\u201d, <em>Problemy Perdaci\nInformacii</em>, 1: 4\u20137.</li>\n<li>Kopec, M., and M. G. Titelbaum, 2016, \u201cThe Uniqueness\nThesis\u201d, <em>Philosophy Compass</em>, 11 (4):\n189\u2013200.</li>\n<li>Kraemer, D. M, 2015, \u201cNatural Probabilistic\nInformation\u201d, <em>Synthese</em>, 192 (9): 2901\u20132919.</li>\n<li>Kyburg, H. E., 1970, <em>Probability and Inductive Logic</em>, New\nYork: Macmillan.</li>\n<li>Kyburg, H. E. and Smokler, H. E., (eds.), 1980, <em>Studies in\nSubjective Probability</em>, 2nd edition, Huntington, New York: Robert\nE. Krieger Publishing Co.</li>\n<li>La Caze, A., 2016, \u201cFrequentism\u201d, in H\u00e1jek and\nHitchcock (eds.) 2016, 341\u2013359.</li>\n<li>Laplace, P. S., 1814/1999. <em>Philosophical Essay of\nProbabilities</em>, translated by Andrew Dale, New York:\nSpringer.</li>\n<li>Lasonen-Aarnio, M., 2015, \u201cNew Rational Reflection and\nInternalism about Rationality\u201d, <em>Oxford Studies in\nEpistemology</em>, 5: 145\u2013171.</li>\n<li>Levi, I., 1978, \u201cCoherence, Regularity and Conditional\nProbability\u201d, <em>Theory and Decision</em>, 9: 1\u201315.</li>\n<li>Lewis, D., 1970, \u201cHow to Define Theoretical Terms\u201d,\n<em>Journal of Philosophy</em>, 67: 427\u2013446.</li>\n<li>\u2013\u2013\u2013, 1973, <em>Counterfactuals</em>, Oxford:\nBlackwell.</li>\n<li>\u2013\u2013\u2013, 1979,\u201cAttitudes De Dicto and De\nSe\u201d, <em>Philosophical Review</em>, 88: 513\u2013543.</li>\n<li>\u2013\u2013\u2013, 1980, \u201cA Subjectivist\u2019s Guide\nto Objective Chance\u201d, in Richard C. Jeffrey (ed.) <em>Studies in\nInductive Logic and Probability</em>, Vol II., Berkeley and Los\nAngeles: University of California Press; reprinted in Lewis 1986b,\n263\u2013294. Also in Eagle 2010.</li>\n<li>\u2013\u2013\u2013, 1986a, \u201cProbabilities of Conditionals\nand Conditional Probabilities II\u201d, <em>Philosophical\nReview</em>, 95: 581\u2013589.</li>\n<li>\u2013\u2013\u2013, 1986b, <em>Philosophical Papers: Volume\nII</em>, Oxford: Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 1994a, \u201cReduction of Mind\u201d, in\n<em>A Companion to the Philosophy of Mind</em>, S. Guttenplan (ed.),\nOxford: Blackwell, 412\u2013431.</li>\n<li>\u2013\u2013\u2013, 1994b, \u201cHumean Supervenience\nDebugged\u201d, <em>Mind</em>, 103: 473\u2013490.</li>\n<li>Li, M. and P. Vit\u00e1nyi, 1997, <em>An Introduction to\nKolmogorov Complexity</em> <em>and Its Applications</em>,\n2<sup>nd</sup> ed., New York: Springer.</li>\n<li>Lin, Hanti, 2013, \u201cFoundations of Everyday Practical\nReasoning\u201d, <em>Journal of Philosophical Logic</em>, 42 (6):\n831\u2013862.</li>\n<li>Loewer, B., 2004, \u201cDavid Lewis\u2019s Humean Theory of\nObjective Chance\u201d, <em>Philosophy of Science</em>, 71 (5):\n1115\u20131125. Also in Eagle 2010.</li>\n<li>\u2013\u2013\u2013, 2012, \u201cTwo Accounts of Laws and Time\u201d,\n<em>Philosophical Studies</em>, 160 (1): 115\u2013137.</li>\n<li>\u2013\u2013\u2013, 2020, \u201cThe Mentaculus Vision\u201d,\nin V.  Allori (ed.) <em>Statistical Mechanics and Scientific\nExplanation: Determinism, Indeterminism, and Laws of Nature</em>,\nSingapore: World Scientific, 3\u201329.</li>\n<li>Lyon, A., 2011, \u201cDeterministic Probability: Neither Chance\nnor Credence\u201d, <em>Synthese</em>, 182 (3): 413\u201332.</li>\n<li>\u2013\u2013\u2013, 2014, \u201cFrom Kolmogorov, to Popper, to\nRenyi: There\u2019s No Escaping Humphreys\u2019 Paradox (When\nGeneralized)\u201d, in <em>Chance and Temporal Asymmetry</em>,\nOxford: Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cKolmogorov\u2019s\nAxiomatization and Its Discontents\u201d, in H\u00e1jek and\nHitchcock (eds.) 2016, 155\u2013166.</li>\n<li>Maher, P., 2000, \u201cProbabilities for Two Properties\u201d,\n<em>Erkenntnis</em>, 52: 63\u201391.</li>\n<li>\u2013\u2013\u2013, 2001, \u201cProbabilities for Multiple\nProperties: The Models of Hesse and Carnap and Kemeny\u201d,\n<em>Erkenntnis</em>, 55: 183\u2013216.</li>\n<li>\u2013\u2013\u2013, 2010, \u201cExplication of Inductive\nProbability\u201d, <em>Journal of Philosophical Logic</em>, 39:\n593\u2013616.</li>\n<li>Mahtani, A., 2022, \u201cDutch Book and Accuracy Theorems\u201d,\n<em>Proceedings of the Aristotelian Society</em>, 120 (3):\n309\u2013327.</li>\n<li>Martin-L\u00f6f, P., 1966, \u201cThe Definition of Random\nSequences\u201d, <em>Information and Control</em>, 9:\n602\u2013619.</li>\n<li>Meacham, C. J. G., 2008, \u201cSleeping Beauty and the Dynamics\nof De Se Beliefs\u201d, <em>Philosophical Studies</em>, 138 (2):\n245\u2013269.</li>\n<li>Meacham, C. J. G., and J. Weisberg, 2011, \u201cRepresentation\nTheorems and the Foundations of Decision Theory\u201d,\n<em>Australasian Journal of Philosophy</em>, 89 (4):\n641\u2013663.</li>\n<li>Mellor, D. H., 2005, <em>Probability: A Philosophical\nIntroduction</em>, London: Routledge.</li>\n<li>Miller, D. W., 1994, <em>Critical Rationalism: A Restatement and\nDefence</em>, Lasalle, Il: Open Court.</li>\n<li>Nielsen, M., 2023, \u201cAccuracy and Probabilism in Infinite\nDomains\u201d, <em>Mind</em>, 132 (526): 402\u2013427.</li>\n<li>Norton, J. D., 2008, \u201cIgnorance and Indifference\u201d,\n<em>Philosophy of Science</em>, 75 (1): 45\u201368.</li>\n<li>Paris J. and A. Vencovsk\u00e1, 1997, \u201cIn Defence of the\nMaximum Entropy Inference Process\u201d, <em>International Journal of\nApproximate Reasoning</em>, 17: 77\u2013103.</li>\n<li>Pearl, J., 2000, <em>Causality</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li>Peirce, C. S., 1957, \u201cNotes on the Doctrine of\nChances\u201d, in <em>Essays in the Philosophy of Science</em> (The\nAmerican Heritage Series), Indianapolis and New York: Bobbs-Merrill,\n74\u201384.</li>\n<li>Pettigrew, R., 2014, \u201cAccuracy, Risk, and the Principle of\nIndifference\u201d <em>Philosophy and Phenomenological Research</em>,\n92 (1): 35\u201359.</li>\n<li>\u2013\u2013\u2013, 2016, <em>Accuracy and the Laws of\nCredence</em>, Oxford: Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 2020, <em>Dutch Book Arguments</em>\n(Elements in Decision Theory and Philosophy), Cambridge: Cambridge\nUniversity Press.</li>\n<li>Poincar\u00e9, H. 1896, <em>Calcul des Probabilit\u00e9s</em>,\nParis: Gauthier-Villars.</li>\n<li>Popper, K. R., 1957, \u201cThe Propensity Interpretation of the\nCalculus of Probability and the Quantum Theory\u201d, in S.\nK\u00f6rner (ed.), <em>The Colston Papers</em>, 9: 65\u201370.</li>\n<li>\u2013\u2013\u2013, 1959a, \u201cThe Propensity Interpretation\nof Probability\u201d, <em>British Journal of the Philosophy of\nScience</em>, 10: 25\u201342. Also in Eagle 2010.</li>\n<li>\u2013\u2013\u2013, 1959b, <em>The Logic of Scientific\nDiscovery</em>, New York: Basic Books; reprinted, London: Routledge,\n1992.</li>\n<li>\u2013\u2013\u2013, 1990, <em>A World of Propensities \u2013\nTwo New Views on Causality</em>, Bristol: Thoemmes.</li>\n<li>Predd, J. B., R. Seiringer, E. H. Lieb, D. N. Osherson, H. V.\nPoor, and S. R. Kulkarni, 2009, \u201cProbabilistic Coherence and\nProper Scoring Rules\u201d, <em>IEEE Transactions on Information\nTheory</em>, 55 (10): 4786\u20134792.</li>\n<li>Ramsey, F. P., 1926, \u201cTruth and Probability\u201d, in\n<em>Foundations of Mathematics and other Essays</em>, R. B.\nBraithwaite (ed.), London: Kegan, Paul, Trench, Trubner, &amp; Co.,\n1931, 156\u2013198; reprinted in <em>Studies in Subjective\nProbability</em>, H. E. Kyburg, Jr. and H. E. Smokler (eds.),\n2<sup>nd</sup> edition, New York: R. E. Krieger Publishing Company,\n1980, 23\u201352; reprinted in <em>Philosophical Papers</em>, D. H.\nMellor (ed.), Cambridge: Cambridge University Press, 1990,\n52\u201394. Also in Eagle 2010.</li>\n<li>\u2013\u2013\u2013, 1928/1990, \u201cGeneral Propositions and\nCausality\u201d, <em>Philosophical Papers</em>, edited by D. H.\nMellor, Cambridge: Cambridge University Press, 145\u2013163.</li>\n<li>Reichenbach, H., 1949, <em>The Theory of Probability</em>,\nBerkeley: University of California Press.</li>\n<li>R\u00e9nyi, A., 1970, <em>Foundations of Probability</em>, San\nFrancisco: Holden-Day, Inc.</li>\n<li>Rinard, S., 2014, \u201cThe Principle of Indifference and\nImprecise Probability\u201d, <em>Thought</em>, 3: 110\u2013114.</li>\n<li>Rissanen, J. 1999, \u201cHypothesis Selection and Testing by the\nMDL Principle\u201d, <em>Computer Journal</em>, 42 (4):\n260\u2013269.</li>\n<li>Roeper, P. and H. Leblanc, 1999, <em>Probability Theory and\nProbability Logic</em>, Toronto: University of Toronto Press.</li>\n<li>Ross, S., 2013,<em>A First Course in Probability</em>, 9th\nedition, Upper Saddle River, NJ: Pearson.</li>\n<li>Salmon, W., 1966, <em>The Foundations of Scientific\nInference</em>, Pittsburgh: University of Pittsburgh Press.</li>\n<li>Savage, L. J., 1954, <em>The Foundations of Statistics</em>, New\nYork: John Wiley.</li>\n<li>Scarantino, A., 2015, \u201cInformation as a Probabilistic\nDifference Maker\u201d, <em>Australasian Journal of Philosophy</em>,\n93 (3): 419\u2013443.</li>\n<li>Schaffer, J., 2007, \u201cDeterministic Chance?\u201d, <em>The\nBritish Journal for the Philosophy of Science</em>, 58 (2):\n113\u2013140.</li>\n<li>Schervish, M. J., T. Seidenfeld, and J. B. Kadane, 2003,\n\u201cMeasures of Incoherence\u201d, in <em>Bayesian Statistics</em>\n(Volume 7), J.M. Bernardo, et al. (eds.), Oxford: Oxford University\nPress, 385\u2013402.</li>\n<li>Schoenfield, M., 2017a, \u201cConditionalization Does Not (in\nGeneral) Maximize Expected Accuracy\u201d, <em>Mind</em>, 126 (504):\n1155\u20131187.</li>\n<li>\u2013\u2013\u2013, 2017b, \u201cThe Accuracy and Rationality\nof Imprecise Credences\u201d, <em>No\u00fbs</em>, 51 (4):\n667\u2013685.</li>\n<li>\u2013\u2013\u2013, 2019, \u201cPermission to Believe: Why\nPermissivism Is True and What It Tells Us about Irrelevant Influences\non Belief\u201d, in J. Fantl, M. McGrath, and E. Sosa (eds.),\n<em>Contemporary Epistemology: An Anthology</em>, Hoboken:\nWiley-Blackwell, 277\u2013295.</li>\n<li>Schwarz, W., 2014, \u201cProving the Principal Principle\u201d,\nin <em>Chance and Temporal Asymmetry</em>, A. Wilson (ed.), Oxford:\nOxford University Press, 81\u201399.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cBest System Approaches to\nChance\u201d, in H\u00e1jek and Hitchock (eds.), 2016,\n423\u2013439.</li>\n<li>\u2013\u2013\u2013, 2018, \u201cNo Interpretation of\nProbability\u201d, <em>Erkenntnis</em>, 83 (6): 1195\u20131212.</li>\n<li>Scott D., and P. Krauss, 1966, \u201cAssigning Probabilities to\nLogical Formulas\u201d, in <em>Aspects of Inductive Logic</em>, J.\nHintikka and P. Suppes (eds.), Amsterdam: North-Holland,\n219\u2013264.</li>\n<li>Seidenfeld, T., 1986, \u201cEntropy and Uncertainty\u201d,\n<em>Philosophy of Science</em>, 53: 467\u2013491.</li>\n<li>Shannon, C. E., 1948, \u201cA Mathematical Theory of\nCommunication\u201d, <em>Bell System Technical Journal</em>, 27 (3):\n379\u2013423.</li>\n<li>Shannon, C. E, and W. Weaver, 1949, <em>The Mathematical Theory of\nCommunication</em>, University of Illinois Press.</li>\n<li>Shimony, A., 1970, \u201cScientific Inference\u201d, in <em>The\nNature and Function of Scientific Theories</em>, R. Colodny (ed.),\nPittsburgh: University of Pittsburgh Press.</li>\n<li>\u2013\u2013\u2013, 1988, \u201cAn Adamite Derivation of the\nCalculus of Probability\u201d, in J.H. Fetzer (ed.), <em>Probability\nand Causality</em>, Dordrecht: D. Reidel.</li>\n<li>Skyrms, B., 1980, <em>Causal Necessity</em>, New Haven: Yale\nUniversity Press.</li>\n<li>\u2013\u2013\u2013, 1984, <em>Pragmatics and Empiricism</em>,\nNew Haven: Yale University Press.</li>\n<li>\u2013\u2013\u2013, 2000, <em>Choice and Chance</em>,\n4<sup>th</sup> edition, Belmont, CA: Wadsworth, Inc.</li>\n<li>Sober, E., 2000, <em>Philosophy of Biology</em>, 2<sup>nd</sup>\nedition, Boulder, CO: Westview Press.</li>\n<li>Spirtes, P., C. Glymour, and R. Scheines, 1993, <em>Causation,\nPrediction, and Search</em>, New York: Springer-Verlag.</li>\n<li>Spohn, W., 1986, \u201cThe Representation of Popper\nMeasures\u201d, <em>Topoi</em>, 5: 69\u201374.</li>\n<li>Staffel, J., 2019, <em>Unsettled Thoughts: A Theory of Degrees of\nRationality</em>, Oxford: Oxford University Press.</li>\n<li>Stalnaker, R., 1970, \u201cProbabilities and Conditionals\u201d,\n<em>Philosophy of Science</em>, 37: 64\u201380.</li>\n<li>Stove, D. C., 1986, <em>The Rationality of Induction</em>, Oxford:\nOxford University Press.</li>\n<li>Strevens, M., 2003, <em>Bigger Than Chaos: Understanding\nComplexity through Probability</em>, Cambridge, MA: Harvard University\nPress.</li>\n<li>\u2013\u2013\u2013, 2013, <em>Tychomancy</em>, Cambridge, MA:\nHarvard University Press.</li>\n<li>Titelbaum, M. G., 2013, <em>Quitting Certainties: A Bayesian\nFramework Modeling Degrees of Belief</em>, Oxford University\nPress.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cSelf-Locating\nCredences\u201d, in H\u00e1jek and Hitchcock (eds.) 2016,\n666\u2013680.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cOne\u2019s Own\nReasoning\u201d, <em>Inquiry</em>, 60 (3): 208\u2013232.</li>\n<li>\u2013\u2013\u2013, 2017, <em>Fundamentals of Bayesian\nEpistemology</em> (Volumes 1 and 2), Oxford: Oxford University\nPress.</li>\n<li>van Fraassen, B., 1984, \u201cBelief and the Will\u201d,\n<em>Journal of Philosophy</em>, 81: 235\u2013256. Also in Eagle\n2010.</li>\n<li>\u2013\u2013\u2013, 1989, <em>Laws and Symmetry</em>, Oxford:\nClarendon Press.</li>\n<li>\u2013\u2013\u2013, 1995a, \u201cBelief and the Problem of\nUlysses and the Sirens\u201d, <em>Philosophical Studies</em>, 77:\n7\u201337.</li>\n<li>\u2013\u2013\u2013, 1995b, \u201cFine-grained Opinion,\nConditional Probability, and the Logic of Belief\u201d, <em>Journal\nof Philosophical Logic</em>, 24: 349\u2013377.</li>\n<li>Venn, J., 1876, <em>The Logic of Chance</em>, 2<sup>nd</sup>\nedition, London: Macmillan; reprinted, New York: Chelsea Publishing\nCo., 1962.</li>\n<li>von Mises R., 1957, <em>Probability, Statistics and Truth</em>,\nrevised English edition, New York: Macmillan.</li>\n<li>von Neumann, J. and O. Morgenstern, 1944, <em>Theory of Games and\nEconomic Behavior</em>, Princeton: Princeton University Press; New\nYork: John Wiley and Sons, 1964.</li>\n<li>von Plato J., 1994, <em>Creating Modern Probability</em>,\nCambridge: Cambridge University Press.</li>\n<li>Wallace, C. S. and D. L. Dowe, 1999, \u201cMinimum Message Length\nand Kolmogorov Complexity\u201d, <em>Computer Journal</em> (Special\nIssue: Kolmogorov Complexity), 42 (4): 270\u2013283.</li>\n<li>White, R., 2010, \u201cEvidential Symmetry and Mushy\nCredence\u201d, <em>Oxford Studies in Epistemology</em>, 3 (161):\n20.</li>\n<li>Williamson, J., 1999, \u201cCountable Additivity and Subjective\nProbability\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 50 (3): 401\u2013416.</li>\n<li>Williamson, T., 2000, <em>Knowledge and Its Limits</em>, Oxford:\nOxford University Press.</li>\n<li>\u2013\u2013\u2013, 2014, \u201cVery Improbable\nKnowing\u201d, <em>Erkenntnis</em>, 79 (5): 971\u2013999.</li>\n<li>Woodward, J., 2003, <em>A Theory of Explanation: Causation,\nInvariance and Intervention</em>, Oxford: Oxford University\nPress.</li>\n<li>Zabell, S. 2016, \u201cSymmetry Arguments in Probability\u201d,\nin H\u00e1jek and Hitchcock (eds.) 2016, 315\u2013340.</li>\n<li>Zynda, L., 1996, \u201cCoherence as an Ideal of\nRationality\u201d, <em>Synthese</em> 109(2): 175\u2013216.</li>\n<li>\u2013\u2013\u2013, 2000, \u201cRepresentation Theorems and\nRealism about Degrees of Belief\u201d, <em>Philosophy of Science</em>\n67(1): 45\u201369.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "Carnap, Rudolf",
            "causal models",
            "causation: probabilistic",
            "chance: versus randomness",
            "decision theory",
            "disagreement",
            "Dutch book arguments",
            "epistemology: Bayesian",
            "information",
            "Laplace, Pierre Simon",
            "logic: inductive",
            "Popper, Karl",
            "probability, in medieval and Renaissance philosophy",
            "quantum theory: philosophical issues in",
            "Ramsey, Frank",
            "Reichenbach, Hans",
            "self-locating beliefs",
            "statistics, philosophy of"
        ],
        "entry_link": [
            {
                "../carnap/": "Carnap, Rudolf"
            },
            {
                "../causal-models/": "causal models"
            },
            {
                "../causation-probabilistic/": "causation: probabilistic"
            },
            {
                "../chance-randomness/": "chance: versus randomness"
            },
            {
                "../decision-theory/": "decision theory"
            },
            {
                "../disagreement/": "disagreement"
            },
            {
                "../dutch-book/": "Dutch book arguments"
            },
            {
                "../epistemology-bayesian/": "epistemology: Bayesian"
            },
            {
                "../information/": "information"
            },
            {
                "../logic-inductive/": "logic: inductive"
            },
            {
                "../popper/": "Popper, Karl"
            },
            {
                "../probability-medieval-renaissance/": "probability, in medieval and Renaissance philosophy"
            },
            {
                "../qt-issues/": "quantum theory: philosophical issues in"
            },
            {
                "../ramsey/": "Ramsey, Frank"
            },
            {
                "../reichenbach/": "Reichenbach, Hans"
            },
            {
                "../self-locating-beliefs/": "self-locating beliefs"
            },
            {
                "../statistics/": "statistics, philosophy of"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=probability-interpret\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/probability-interpret/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=probability-interpret&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/probability-interpret/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=probability-interpret": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/probability-interpret/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=probability-interpret&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/probability-interpret/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "Bartha, Paul, <a href=\"https://philosophy.ubc.ca/wp-content/uploads/sites/19/2019/09/p550wk5.pdf\" target=\"other\">Probability</a> (in PDF),\nlectures notes, University of British Columbia.",
            "Fitelson, Branden, 2008, \u201c<a href=\"http://fitelson.org/probability/notes.html\" target=\"other\">Lecture notes on Probability and Induction</a>\u201d,\nUniversity of California, Berkeley.",
            "H\u00e1jek, A., and C. Hitchcock, 2021,\n  \u201c<a href=\"https://www.oxfordbibliographies.com/display/document/obo-9780195396577/obo-9780195396577-0416.xml\" target=\"other\">Interpretations of Probability</a>\u201d, <em>Oxford Bibliographies Online</em>..",
            "Pettigrew, Richard and Jonathan Weisberg (eds.), 2019, \n<a href=\"https://jonathanweisberg.org/pdf/open-handbook-of-formal-epistemology.pdf\" target=\"other\"><em>The Open Handbook of Formal Epistemology</em></a>,\nopen access, published by PhilPapers.",
            "Weisberg, Jonathan,\n <a href=\"https://jonathanweisberg.org/vip/\" target=\"other\"><em>Odds and Ends</em></a>,\n an open access, open source textbook."
        ],
        "listed_links": [
            {
                "https://philosophy.ubc.ca/wp-content/uploads/sites/19/2019/09/p550wk5.pdf": "Probability"
            },
            {
                "http://fitelson.org/probability/notes.html": "Lecture notes on Probability and Induction"
            },
            {
                "https://www.oxfordbibliographies.com/display/document/obo-9780195396577/obo-9780195396577-0416.xml": "Interpretations of Probability"
            },
            {
                "https://jonathanweisberg.org/pdf/open-handbook-of-formal-epistemology.pdf": "The Open Handbook of Formal Epistemology"
            },
            {
                "https://jonathanweisberg.org/vip/": "Odds and Ends"
            }
        ]
    }
}