{
    "main_text": "Moral AI\n6. Moral AI\n\nComputer Ethics has been around for a long time. In this\nsub-field, typically one would consider how one ought to act in a\ncertain class of situations involving computer technology, where the\n\u201cone\u201d here refers to a human being (Moor 1985). So-called\n\u201crobot ethics\u201d is different. In this sub-field (which goes\nby names such as \u201cmoral AI,\u201d \u201cethical AI,\u201d\n\u201cmachine ethics,\u201d \u201cmoral robots,\u201d etc.) one is\nconfronted with such prospects as robots being able to make autonomous\nand weighty decisions \u2013 decisions that might or might not be\nmorally permissible (Wallach & Allen 2010). If one were to attempt\nto engineer a robot with a capacity for sophisticated ethical\nreasoning and decision-making, one would also be doing Philosophical\nAI, as that concept is characterized\n elsewhere\n in the present entry. There can be many different flavors of\napproaches toward Moral AI. Wallach and Allen (2010) provide a\nhigh-level overview of the different approaches. Moral reasoning is\nobviously needed in robots that have the capability for lethal action.\nArkin (2009) provides an introduction to how we can control and\nregulate machines that have the capacity for lethal behavior. Moral AI\ngoes beyond obviously lethal situations, and we can have a spectrum of\nmoral machines. Moor (2006) provides one such spectrum of possible\nmoral agents. An example of a non-lethal but ethically-charged machine\nwould be a lying machine. Clark (2010) uses a computational theory\nof the mind, the ability to represent and reason about other\nagents, to build a lying machine that successfully persuades people\ninto believing falsehoods. Bello & Bringsjord (2013) give a\ngeneral overview of what might be required to build a moral machine,\none of the ingredients being a theory of mind. \n\nThe most general framework for building machines that can reason\nethically consists in endowing the machines with a moral code.\nThis requires that the formal framework used for reasoning by the\nmachine be expressive enough to receive such codes. The field of Moral\nAI, for now, is not concerned with the source or provenance of such\ncodes. The source could be humans, and the machine could receive the\ncode directly (via explicit encoding) or indirectly (reading). Another\npossibility is that the code is inferred by the machine from a more\nbasic set of laws. We assume that the robot has access to some such\ncode, and we then try to engineer the robot to follow that code under\nall circumstances while making sure that the moral code and its\nrepresentation do not lead to unintended consequences. Deontic\nlogics are a class of formal logics that have been studied the\nmost for this purpose. Abstractly, such logics are concerned mainly\nwith what follows from a given moral code. Engineering then studies\nthe match of a given deontic logic to a moral code (i.e., is the logic\nexpressive enough) which has to be balanced with the ease of\nautomation. Bringsjord et al. (2006) provide a blueprint for using\ndeontic logics to build systems that can perform actions in accordance\nwith a moral code. The role deontic logics play in the framework\noffered by Bringsjord et al (which can be considered to be\nrepresentative of the field of deontic logic for moral AI) can be best\nunderstood as striving towards Leibniz\u2019s dream of a universal\nmoral calculus: \n\nWhen controversies arise, there will be no more need for a disputation\nbetween two philosophers than there would be between two accountants\n[computistas]. It would be enough for them to pick up their pens and\nsit at their abacuses, and say to each other (perhaps having summoned\na mutual friend): \u2018Let us calculate.\u2019\n\n\nDeontic logic-based frameworks can also be used in a fashion that is\nanalogous to moral self-reflection. In this mode, logic-based\nverification of the robot\u2019s internal modules can done before the\nrobot ventures out into the real world. Govindarajulu and Bringsjord\n(2015) present an approach, drawing from formal-program\nverification, in which a deontic-logic based system could be used\nto verify that a robot acts in a certain ethically-sanctioned manner\nunder certain conditions. Since formal-verification approaches can be\nused to assert statements about an infinite number of situations and\nconditions, such approaches might be preferred to having the robot\nroam around in an ethically-charged test environment and make a finite\nset of decisions that are then judged for their ethical correctness.\nMore recently, Govindarajulu and Bringsjord (2017) use a deontic logic\nto present a computational model of the\n Doctrine of Double Effect,\n an ethical principle for moral dilemmas that has been studied\nempirically and analyzed extensively by\n philosophers.[35]\n The principle is usually presented and motivated via dilemmas using\ntrolleys and was first presented in this fashion by Foot (1967). \n\nWhile there has been substantial theoretical and philosophical work,\nthe field of machine ethics is still in its infancy. There has been\nsome embryonic work in building ethical machines. One recent such\nexample would be Pereira and Saptawijaya (2016) who use logic\nprogramming and base their work in machine ethics on the ethical\ntheory known as contractualism, set out by Scanlon (1982). And\nwhat about the future? Since artificial agents are bound to get\nsmarter and smarter, and to have more and more autonomy and\nresponsibility, robot ethics is almost certainly going to grow in\nimportance. This endeavor might not be a straightforward application\nof classical ethics. For example, experimental results suggest that\nhumans hold robots to different ethical standards than they expect\nfrom humans under similar conditions (Malle et al.\n 2015).[36]\n\n",
    "section_title": "6. Moral AI",
    "entry_title": "Artificial Intelligence",
    "hierarchy_title": "Artificial Intelligence || Moral AI",
    "tokenized_text": [
        "moral",
        "ai",
        "moral",
        "ai",
        "computer",
        "ethic",
        "around",
        "long",
        "time",
        "subfield",
        "typically",
        "one",
        "would",
        "consider",
        "one",
        "ought",
        "act",
        "certain",
        "class",
        "situation",
        "involving",
        "computer",
        "technology",
        "one",
        "refers",
        "human",
        "moor",
        "socalled",
        "robot",
        "ethic",
        "different",
        "subfield",
        "go",
        "name",
        "moral",
        "ai",
        "ethical",
        "ai",
        "machine",
        "ethic",
        "moral",
        "robot",
        "etc",
        "one",
        "confronted",
        "prospect",
        "robot",
        "able",
        "make",
        "autonomous",
        "weighty",
        "decision",
        "decision",
        "might",
        "might",
        "morally",
        "permissible",
        "wallach",
        "allen",
        "one",
        "attempt",
        "engineer",
        "robot",
        "capacity",
        "sophisticated",
        "ethical",
        "reasoning",
        "decisionmaking",
        "one",
        "would",
        "also",
        "philosophical",
        "ai",
        "concept",
        "characterized",
        "elsewhere",
        "present",
        "entry",
        "many",
        "different",
        "flavor",
        "approach",
        "toward",
        "moral",
        "ai",
        "wallach",
        "allen",
        "provide",
        "highlevel",
        "overview",
        "different",
        "approach",
        "moral",
        "reasoning",
        "obviously",
        "needed",
        "robot",
        "capability",
        "lethal",
        "action",
        "arkin",
        "provides",
        "introduction",
        "control",
        "regulate",
        "machine",
        "capacity",
        "lethal",
        "behavior",
        "moral",
        "ai",
        "go",
        "beyond",
        "obviously",
        "lethal",
        "situation",
        "spectrum",
        "moral",
        "machine",
        "moor",
        "provides",
        "one",
        "spectrum",
        "possible",
        "moral",
        "agent",
        "example",
        "nonlethal",
        "ethicallycharged",
        "machine",
        "would",
        "lying",
        "machine",
        "clark",
        "us",
        "computational",
        "theory",
        "mind",
        "ability",
        "represent",
        "reason",
        "agent",
        "build",
        "lying",
        "machine",
        "successfully",
        "persuades",
        "people",
        "believing",
        "falsehood",
        "bello",
        "bringsjord",
        "give",
        "general",
        "overview",
        "might",
        "required",
        "build",
        "moral",
        "machine",
        "one",
        "ingredient",
        "theory",
        "mind",
        "general",
        "framework",
        "building",
        "machine",
        "reason",
        "ethically",
        "consists",
        "endowing",
        "machine",
        "moral",
        "code",
        "requires",
        "formal",
        "framework",
        "used",
        "reasoning",
        "machine",
        "expressive",
        "enough",
        "receive",
        "code",
        "field",
        "moral",
        "ai",
        "concerned",
        "source",
        "provenance",
        "code",
        "source",
        "could",
        "human",
        "machine",
        "could",
        "receive",
        "code",
        "directly",
        "via",
        "explicit",
        "encoding",
        "indirectly",
        "reading",
        "another",
        "possibility",
        "code",
        "inferred",
        "machine",
        "basic",
        "set",
        "law",
        "assume",
        "robot",
        "access",
        "code",
        "try",
        "engineer",
        "robot",
        "follow",
        "code",
        "circumstance",
        "making",
        "sure",
        "moral",
        "code",
        "representation",
        "lead",
        "unintended",
        "consequence",
        "deontic",
        "logic",
        "class",
        "formal",
        "logic",
        "studied",
        "purpose",
        "abstractly",
        "logic",
        "concerned",
        "mainly",
        "follows",
        "given",
        "moral",
        "code",
        "engineering",
        "study",
        "match",
        "given",
        "deontic",
        "logic",
        "moral",
        "code",
        "ie",
        "logic",
        "expressive",
        "enough",
        "balanced",
        "ease",
        "automation",
        "bringsjord",
        "et",
        "al",
        "provide",
        "blueprint",
        "using",
        "deontic",
        "logic",
        "build",
        "system",
        "perform",
        "action",
        "accordance",
        "moral",
        "code",
        "role",
        "deontic",
        "logic",
        "play",
        "framework",
        "offered",
        "bringsjord",
        "et",
        "al",
        "considered",
        "representative",
        "field",
        "deontic",
        "logic",
        "moral",
        "ai",
        "best",
        "understood",
        "striving",
        "towards",
        "leibniz",
        "dream",
        "universal",
        "moral",
        "calculus",
        "controversy",
        "arise",
        "need",
        "disputation",
        "two",
        "philosopher",
        "would",
        "two",
        "accountant",
        "computistas",
        "would",
        "enough",
        "pick",
        "pen",
        "sit",
        "abacus",
        "say",
        "perhaps",
        "summoned",
        "mutual",
        "friend",
        "let",
        "u",
        "calculate",
        "deontic",
        "logicbased",
        "framework",
        "also",
        "used",
        "fashion",
        "analogous",
        "moral",
        "selfreflection",
        "mode",
        "logicbased",
        "verification",
        "robot",
        "internal",
        "module",
        "done",
        "robot",
        "venture",
        "real",
        "world",
        "govindarajulu",
        "bringsjord",
        "present",
        "approach",
        "drawing",
        "formalprogram",
        "verification",
        "deonticlogic",
        "based",
        "system",
        "could",
        "used",
        "verify",
        "robot",
        "act",
        "certain",
        "ethicallysanctioned",
        "manner",
        "certain",
        "condition",
        "since",
        "formalverification",
        "approach",
        "used",
        "assert",
        "statement",
        "infinite",
        "number",
        "situation",
        "condition",
        "approach",
        "might",
        "preferred",
        "robot",
        "roam",
        "around",
        "ethicallycharged",
        "test",
        "environment",
        "make",
        "finite",
        "set",
        "decision",
        "judged",
        "ethical",
        "correctness",
        "recently",
        "govindarajulu",
        "bringsjord",
        "use",
        "deontic",
        "logic",
        "present",
        "computational",
        "model",
        "doctrine",
        "double",
        "effect",
        "ethical",
        "principle",
        "moral",
        "dilemma",
        "studied",
        "empirically",
        "analyzed",
        "extensively",
        "philosopher",
        "principle",
        "usually",
        "presented",
        "motivated",
        "via",
        "dilemma",
        "using",
        "trolley",
        "first",
        "presented",
        "fashion",
        "foot",
        "substantial",
        "theoretical",
        "philosophical",
        "work",
        "field",
        "machine",
        "ethic",
        "still",
        "infancy",
        "embryonic",
        "work",
        "building",
        "ethical",
        "machine",
        "one",
        "recent",
        "example",
        "would",
        "pereira",
        "saptawijaya",
        "use",
        "logic",
        "programming",
        "base",
        "work",
        "machine",
        "ethic",
        "ethical",
        "theory",
        "known",
        "contractualism",
        "set",
        "scanlon",
        "future",
        "since",
        "artificial",
        "agent",
        "bound",
        "get",
        "smarter",
        "smarter",
        "autonomy",
        "responsibility",
        "robot",
        "ethic",
        "almost",
        "certainly",
        "going",
        "grow",
        "importance",
        "endeavor",
        "might",
        "straightforward",
        "application",
        "classical",
        "ethic",
        "example",
        "experimental",
        "result",
        "suggest",
        "human",
        "hold",
        "robot",
        "different",
        "ethical",
        "standard",
        "expect",
        "human",
        "similar",
        "condition",
        "malle",
        "et",
        "al"
    ]
}