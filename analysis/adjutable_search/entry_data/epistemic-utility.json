{
    "url": "epistemic-utility",
    "title": "Epistemic Utility Arguments for Epistemic Norms",
    "authorship": {
        "year": "Copyright \u00a9 2023",
        "author_text": "Richard Pettigrew\n<richard.pettigrew@bris.ac.uk>",
        "author_links": [
            {
                "http://eis.bris.ac.uk/~rp3959/": "Richard Pettigrew"
            },
            {
                "mailto:richard%2epettigrew%40bris%2eac%2euk": "richard.pettigrew@bris.ac.uk"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2023</a> by\n\n<br/>\n<a href=\"http://eis.bris.ac.uk/~rp3959/\" target=\"other\">Richard Pettigrew</a>\n&lt;<a href=\"mailto:richard%2epettigrew%40bris%2eac%2euk\"><em>richard<abbr title=\" dot \">.</abbr>pettigrew<abbr title=\" at \">@</abbr>bris<abbr title=\" dot \">.</abbr>ac<abbr title=\" dot \">.</abbr>uk</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Fri Sep 23, 2011",
        "substantive revision Wed Oct 11, 2023"
    ],
    "preamble": "\n\nIf I believe George Eliot wrote more than six novels and also believe\nshe wrote fewer than four, you will no doubt judge my beliefs\nirrational. After all, if she did write more than six, she\ndidn\u2019t write fewer than four. And similarly, if my degree of\nbelief that Eliot wrote more than six novels is greater than my degree\nof belief that she wrote more than five, then again you will think me\nirrational. After all, if she did write more than six, she also wrote\nmore than five. In both cases, there is a general norm I fail to\nsatisfy. In the first, it might be this:\n\n\nConsistency\\(_2\\) If two propositions cannot both be\ntrue together, you should not believe both.\n\n\nIn the second case, it might be this:\n\n\nNo Drop If one proposition entails another, then your\ndegree of belief in the first should not exceed your degree of belief\nin the second.\n\n\nThis entry is concerned with norms like these. More specifically, it\nis concerned with how we might establish these norms. More\nspecifically still, it is concerned with what epistemologists have\ncome to call epistemic utility arguments in their favor. The\nnorms we seek to establish primarily govern epistemic states;\nthat is, they say what rationality requires of your beliefs, degrees\nof belief, and any other attitudes whose role it is to represent the\nway the world is. But, as we will see, they also govern the activities\nby which we acquire those states, such as gathering and responding to\nevidence.\n\nEpistemic utility arguments are inspired by traditional utility-based\narguments in decision theory, so let\u2019s begin with a quick\nsummary of those. Traditional decision theory explores a particular\nstrategy for establishing the norms that govern which choices it is\nrational for an individual to make in a particular situation (see\nentry on\n normative theories of rational choice: expected utility).\n Given such a situation, the framework for the theory includes:\nstates of the world described in as much detail as required;\nactions that are available to the individual in the\nsituation, and the individual\u2019s utility function, which\ntakes a state of the world and an action and returns a measure of the\nextent to which she values the outcome of performing that action at\nthat world. We call this measure the utility of the outcome\nat the world. For example, there might be just two relevant states of\nthe world: one in which it rains and one in which it doesn\u2019t.\nAnd there might be just two relevant actions from which to choose:\ntake an umbrella when you leave the house or don\u2019t. Then your\nutility function will measure how much you value the outcomes of each\naction at each state of the world: that is, it will give the value of\nbeing in the rain without an umbrella, being in the rain with an\numbrella, being with an umbrella when there is no rain, and being\nwithout an umbrella when there is no rain. With this framework in\nhand, we can state certain very general norms of action in terms of\nit. For instance, if one action has strictly greater utility than\nanother in every possible state of the world, we say the first\nstrongly dominates the second, and the norm of Dominance says\nthat you should not choose a strongly dominated action.\n\nIn epistemic utility theory, the states of the world remain the same,\nbut the possible actions an individual might perform are replaced by\nthe possible epistemic states she might be in, and the\nutility function is replaced by an epistemic utility\nfunction, which takes a state of the world and an epistemic state\nand returns a measure of the purely epistemic value of that epistemic\nstate at that state of the world. So, in epistemic utility theory, we\nappeal to epistemic utility to ask which of a range of possible\nepistemic states it is rational to be in, just as in traditional\nutility theory we appeal to non-epistemic, pragmatic utility to ask\nwhich of a range of possible actions it is rational to perform. (In\nfact, we will often talk of epistemic disutility rather than\nepistemic utility in this entry. But it is easy to translate between\nthem: the negative of an epistemic utility function is an epistemic\ndisutility function, and vice versa.)\n\nAgain, certain very general norms may be stated, such as the obvious\nanalogue of Dominance from above: if one epistemic state has greater\nepistemic utility than another in every possible state of the world,\nthen it is irrational to be in the latter. And we might use them to\nestablish norms for epistemic states. For instance, consider\nConsistency\\(_2\\) from the introduction. Let\u2019s say the epistemic\nutility of believing a truth is some positive number \\(R\\), while the\nepistemic utility of believing a falsehood is some negative number\n\\(-W\\) (\\(R\\) for Right, \\(W\\) for Wrong). And\nlet\u2019s say the epistemic utility of a set of beliefs is just the\nsum of the epistemic utilities of the individual beliefs that belong\nto it, so that if you believe two truths and a falsehood, for\ninstance, your epistemic utility is \\(2R - W\\). Now suppose that \\(W\\)\nis greater than \\(R\\); that is, the badness of believing falsely is\ngreater than the goodness of believing truly; that is, we more\nstrongly wish to avoid false belief than we want to achieve true\nbelief; that is, our epistemic utilities encode a sort of epistemic\nconservatism. Then, if I believe each of two propositions that cannot\nboth be true together, my total epistemic utility is either \\(R-W\\),\nif one is true and the other false, or \\(-2W\\) if neither is true. And\neach of these is less than zero. So suspending judgment on both is\nguaranteed to be better than believing both. And so, by Dominance,\nbelieving both is irrational and we have an epistemic utility argument\nfor Consistency\\(_2\\). This is the style of argument we will consider\nin this entry. As we\u2019ll see in\n Section 5.2,\n there is an argument from Dominance to No Drop as well.\n\nBecause we appeal to the purely epistemic utility of the\nepistemic states we consider, rather than the pragmatic or\npractical utility of the outcomes of the choices they lead us\nto make, the arguments of epistemic utility theory are different from\nbetting arguments or dutch book arguments for epistemic norms (Ramsey\n1926 [1931]; de Finetti 1937 [1980]; see entry on\n dutch book arguments).\n They are also different from the sort of axiomatic justification\nexemplified by Cox's theorem (Cox 1946, 1961; Paris 1994) as well as\nthe sort of structural justification given by R. I. G. Hughes and Bas\nvan Fraassen (1984) and Hannes Leitgeb (2021).\n",
    "toc": [
        {
            "#ModEpiSta": "1. Modelling Epistemic States"
        },
        {
            "#ForArgEpiUtiThe": "2. The Form of Arguments in Epistemic Utility Theory"
        },
        {
            "#AgeStaWor": "3. Agendas and States of the World"
        },
        {
            "#EpiUtiArgFulBel": "4. Epistemic Utility Arguments concerning Outright Beliefs"
        },
        {
            "#DomCon": "4.1 Dominance and Consistency"
        },
        {
            "#ExpEpiUtiLocThe": "4.2 Expected Epistemic Utility and the Lockean Thesis"
        },
        {
            "#StrDomLocThe": "4.3 Dominance and Almost Lockean Completeness"
        },
        {
            "#UpBel": "4.4 Updating your beliefs when you receive evidence"
        },
        {
            "#EpiUtiArgPreCre": "5. Epistemic Utility Arguments for Precise Credences"
        },
        {
            "#EpiUtiFunPreCre": "5.1 Epistemic utility function for precise credences"
        },
        {
            "#EpiUtiArgPro": "5.2 Epistemic utility arguments for Probabilism"
        },
        {
            "#EpiUtiArgChCr": "5.3 Epistemic utility arguments for chance-credence norms"
        },
        {
            "#EpiUtiArgCon": "5.4 Epistemic utility arguments for Conditionalization"
        },
        {
            "#EpiArgUniThe": "5.5 Epistemic utility arguments for and against the Uniqueness Thesis"
        },
        {
            "#EpiUtiArgSocEpi": "5.6 Epistemic utility arguments in social epistemology"
        },
        {
            "#ComCon": "6. Comparative confidence"
        },
        {
            "#ImpCre": "7. Imprecise credences"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. Modelling Epistemic States\n\nLet\u2019s begin by listing the different ways in which we might\nrepresent an individual\u2019s epistemic state at a given time (see\nentry on\n formal representations of belief).\n We might represent them using any of the following:\n\nthe set of propositions she believes at the time (we might call\nthis the outright belief model; it is the object of study in\nmuch traditional epistemology and in doxastic and epistemic logic;\noutright beliefs are those we report when we say \u2018I think I\nswitched off the gas\u2019 or \u2018I believe it will rain\ntomorrow\u2019; we\u2019ll consider them in\n Section 4);\na credence function, which takes each proposition about which she\nhas an opinion and returns her credence in that proposition at the\ntime, where her credence in a proposition measures how confident she\nis in it as a number at least 0 and at most 1 (this is the precise\ncredence or standard Bayesian model; it is the object of\nstudy in much formal and Bayesian epistemology; credences are the\nstates we report when we say \u2018I\u2019m 70% sure I\nswitched off the gas\u2019 or \u2018I\u2019m 50-50 whether it will\nrain tomorrow\u2019; we\u2019ll consider them in\n Section 5);\na comparative confidence ordering, which takes each pair of\npropositions about which she has an opinion and says whether she is\nmore confident in one than the other, equally confident in both, or\nneither more confident in one nor equally confident in both (this is\nthe comparative confidence model; we report comparative\nconfidences when we say \u2018I\u2019m more confident I switched off\nthe gas than the electricity\u2019 or \u2018I\u2019m more confident\nthan not that it will rain tomorrow\u2019; we\u2019ll consider them\nin\n Section 6);\na set of credence functions, each of which is a precisification of\nher otherwise vague or imprecise or indeterminate credences at the\ntime (this is the imprecise credence model; we report\nimprecise credences when we say \u2018I\u2019m\n50%\u201370% sure I switched off the gas\u2019 or\n\u2018I\u2019m less than 60% sure it will rain\ntomorrow\u2019; we\u2019ll consider them in\n Section 7);\n\n\nEpistemic utility theory may be applied to any one of these ways of\nrepresenting an individual\u2019s epistemic state. Whichever we\nchoose, we define an epistemic (dis)utility function to be a function\nthat takes a set of epistemic states modelled in this way, together\nwith a state of the world, to a real number, or (positive or) negative\ninfinity, and we take this number to measure the epistemic\n(dis)utility of those epistemic attitudes at that world.\n2. The Form of Arguments in Epistemic Utility Theory\n\nWe begin by highlighting the form that epistemic utility arguments\ntake, regardless of which sorts of epistemic states concern us. Recall\nthe argument for\n Consistency\\(_2\\)\n from the introduction. It had two premises: first, we placed\nconditions on the measure of epistemic utility; second, we stated a\nnorm from standard utility theory. From those, we deduced the norm on\nbelief. This is the structure of nearly all epistemic utility\narguments. In general, in epistemic utility theory, we argue for an\nepistemic norm N using the following two ingredients:\n\nE A set of conditions that a legitimate measure\nof epistemic utility must satisfy.\nQ A norm of standard utility theory (or decision\ntheory), which is to be applied, using an epistemic utility function,\nto discover what rationality requires of an agent in a given\nsituation.\n\n\nTypically, the inference from E and Q to N appeals to a mathematical\ntheorem, which shows that, applied to any epistemic utility function\nthat satisfies the conditions E, the norm Q entails the norm N.\n3. Agendas and States of the World\n\nOne final piece of general stage-setting will be useful before we can\nembark on our journey through the arguments. On each of the models of\nbelief listed in\n Section 1,\n there is a set of propositions with which our individual\u2019s\nepistemic states are concerned: the ones to which they assign\ncredences in the precise credence model, for instance. We call this\nset their agenda and often denote it \\(\\mathcal{F}\\).\n\nFor the most part, we\u2019ll assume this agenda is a finite algebra\nof propositions. That is, (i) it contains finitely many propositions;\n(ii) it contains a necessarily true proposition and a necessarily\nfalse proposition; (iii) and it is closed under taking negations,\nconjunctions, and disjunctions\u2014that is, if it contains a\nproposition, it also contains its negation, and if it contains two\npropositions, it also contains their conjunction and their\ndisjunction. (But see\n Section 5.2.5,\n where we lift assumption (i).)\n\nThe epistemic utility of an individual\u2019s set of epistemic\nattitudes depends on the way the world is. For instance, a belief is\nepistemically valuable if it\u2019s true, but disvaluable if\nit\u2019s false. So we\u2019d better say how we represent these\nstates of the world formally. For the most part, we\u2019ll assume\nthe logic that governs the propositions in our individual\u2019s\nagenda is classical (but see\n Section 5.2.6,\n where we drop that assumption). In that case, a state of the world\nrelative to an agenda is just a classically consistent assignment of\nthe classical truth values, True and False, to the propositions in\nthat agenda. We often write \\(\\mathcal{W}_\\mathcal{F}\\) for the set of\nstates of the world relative to the agenda \\(\\mathcal{F}\\).\n\nSince \\(\\mathcal{F}\\) is a finite algebra, for each state of the world\n\\(w\\) relative to \\(\\mathcal{F}\\), there is a proposition in\n\\(\\mathcal{F}\\) that is true at that state of the world and only at\nthat state of the world. We will abuse notation and also write \\(w\\)\nfor this proposition.\n4. Epistemic Utility Arguments concerning Outright Beliefs\n\nIn the outright belief model, our individual\u2019s epistemic state\nis represented by their belief set, which contains each\nproposition in their agenda that they believe; on the rest, we say\nthat they suspend judgment.\n\nFollowing Kenny Easwaran (2016) and Kevin Dorst (2017), who in turn\ngeneralize Carl Hempel\u2019s (1962) approach, we define the\nepistemic utility of a belief set at a state of the world as follows:\nthe epistemic utility of a belief in a true proposition is \\(R\\),\nwhile the epistemic utility of a belief in a false proposition is\n\\(-W\\), where \\(0 \\lt R, W\\); and the epistemic utility of a belief\nset is the sum of the epistemic utilities of the beliefs it contains.\nI\u2019ll call this the Jamesian Epistemic Utility assumption, since\nit allows for different ways of scoring the goodness of believing a\ntruth and the badness of believing a falsehood, which goes some way to\nexplicating the view in William James\u2019 \u2018The Will to\nBelieve\u2019 (1897).\n\nEaswaran and Dorst impose no constraints on \\(R\\) and \\(W\\) except\n\\(-W \\lt 0 \\lt R\\). Hempel assumes \\(R, W = 1\\).\n4.1 Dominance and Consistency\n\nSo, with all this in hand, the argument for Consistency\\(_2\\) runs as\nfollows:\n\n\nEpistemic Conservatism \\(W \\gt R \\gt 0\\).\n\nDominance If one option strongly dominates another,\nrationality requires you not to choose the second.\n\nTherefore,\n\nConsistency\\(_2\\) If two propositions cannot both be\ntrue together, rationality requires that you should not believe\nboth.\n\n4.2 Expected Epistemic Utility and the Lockean Thesis\n\nDominance is a very weak norm of rational choice, but there are\nstronger ones. Among them is one of the most popular norms of decision\ntheory, which says you should maximize expected utility from the point\nof view of your credences.\n\n\nMaximize Subjective Expected Utility If one option\nhas greater expected utility than another from the point of view of\nyour credences, then rationality requires that you should not choose\nthe second.\n\n\nThe expected utility of an option relative to your credences is\nobtained by taking its utility at each state, weighting that by your\ncredence in that state, and summing up these credence-weighted\nutilities. For instance, suppose \\(p\\) is your credence in a\nproposition and \\(1-p\\) is your credence in its negation. Then the\nexpected epistemic utility of believing that proposition from the\npoint of view of your credences is\n\n\\(p \\times \\text{epistemic utility of believing a truth} + (1-p)\\\n\\times\\)\n\n\\( \\text{epistemic utility of believing a falsehood} = pR +\n(1-p)(-W)\\)\n\n\nNow we can ask when believing a proposition maximizes expected utility\nfrom the point of view of your credences.\n\n\nExpectation Theorem for the Lockean Thesis (Hempel 1962;\nEaswaran 2016; Dorst 2017) Suppose your credence in \\(X\\) is\n\\(p\\). Then:\n\nIf \\(p \\gt \\frac{W}{R+W}\\), then believing \\(X\\) uniquely\nmaximizes expected epistemic utility. (That is, believing has strictly\ngreater expected utility than suspending.)\nIf \\(p = \\frac{W}{R+W}\\), then believing \\(X\\) and suspending\njudgment on \\(X\\) both maximize expected epistemic utility. (That is,\nbelieving has the same expected utility as suspending.)\nIf \\(p \\lt \\frac{W}{R + W}\\), then suspending judgment on \\(X\\)\nuniquely maximizes expected epistemic utility. (That is, believing has\nstrictly less expected utility than suspending.)\n\n\n\nEaswaran and Dorst both appeal to this result to argue for the Lockean\nThesis, which is the most well-known norm that connects credences and\noutright beliefs. It takes its name from passages in John\nLocke\u2019s (1689 [1975]) An Essay on Human Understanding\nin which he suggests that belief is nothing more than sufficiently\nhigh credence, but it was formulated explicitly by Richard Foley\n(1992). In fact, the Lockean Thesis is a family of putative norms:\neach member of the family is distinguished by the threshold above\nwhich it demands belief, below which it demands suspension, and at\nwhich it permits either.\n\n\nThe Lockean Thesis with threshold \\(t\\) Suppose\nyour credence in \\(X\\) is \\(p\\). Then\n\n\nIf \\(p \\gt t\\), you are rationally required to believe \\(X\\);\nIf \\(p = t\\), you are rationally permitted to believe \\(X\\) and\nrationally permitted to suspend on \\(X\\);\nIf \\(p \\lt t\\), you are rationally required to suspend on\n\\(X\\).\n\n\n\nThen we have the following argument:\n\n\nJamesian Epistemic Utility\n \\(0 \\lt R, W\\).\n\nMaximize Subjective Expected Utility\n\nTherefore,\n\nThe Lockean Thesis with threshold \\(\\frac{W}{R+W}\\)\n\n4.2.1 Expected Epistemic Utility, the Uniqueness Thesis, and Epistemic Permissivism\n\nThomas Kelly (2014) has pointed out that this argument has an\ninteresting consequence for the debate in epistemology between those\nwho argue for the Uniqueness Thesis and those who side with Epistemic\nPermissivism. Given a sort of epistemic state, the Uniqueness Thesis\nfor that sort of state runs as follows:\n\n\nThe Uniqueness Thesis Given an agenda, the following\nholds: for any body of evidence, there is a unique epistemic state of\nthe given sort concerning the propositions in that agenda that\nrationality requires you to have if that body of evidence is your\ntotal evidence.\n\n\nEpistemic Permissivism is simply the negation of the Uniqueness\nThesis. So, for instance, the Uniqueness Thesis for credences says\nthat, for any agenda and any body of evidence, there is a unique\ncredence function over that agenda that rationality requires you to\nhave in response to that evidence, while Epistemic Permissivism says\nthat there is at least one body of evidence for which there is more\nthan one credence function it is rational to have in response to that\nevidence.\n\nNow, suppose you subscribe to the Uniqueness Thesis about credences.\nBut you also think that rationality permits different ways in which\nyou might set the utility \\(R\\) of believing a truth and the utility\n\\(-W\\) of believing a falsehood. For instance, you might think \\(R =\n1, W = 2\\) is permitted, but so is \\(R = 2, W = 3\\). And suppose the\nunique rational credence in proposition \\(X\\) is 0.65. Maximizing\nexpected epistemic utility with \\(R = 2, W = 3\\) entails the Lockean\nThesis with threshold \\(\\frac{3}{2+3}\\), and this requires that you\nbelieve \\(X\\), since \\(0.65 \\gt \\frac{3}{2+3}\\); but maximizing\nexpected epistemic utility with \\(R = 1, W = 2\\) entails the Lockean\nThesis with threshold \\(\\frac{2}{1+2}\\), and this requires that you\nsuspend on \\(X\\), since \\(0.65 \\lt \\frac{2}{1+2}\\). And so we have\nEpistemic Permissivism about outright beliefs, even though we have the\nUniqueness Thesis for credences. Which beliefs rationality requires\nyou to have depends not only on your evidence, but also on your\nepistemic utilities. In general, the smaller the ratio of \\(R\\) to\n\\(W\\), the higher your credence in a proposition must be for you to\nbelieve it.\n4.2.2 Expected Epistemic Utility and Consistency\n\nAnother interesting consequence of the\n Expectation Theorem for the Lockean Thesis\n is that it shows that we can\u2019t give an argument from\n Dominance\n to the natural generalization of\n Consistency\\(_2\\)\n to arbitrarily many propositions; and we can only give the\ngeneralizations to \\(n\\) propositions, for some given \\(n\\), by\nbecoming increasingly conservative in our epistemic utilities\n(Fitelson & Easwaran 2015; Easwaran 2016).\n\nSay that a set of propositions is inconsistent if the propositions in\nit cannot all be true together. Then we have the following two\nnorms:\n\n\nConsistency\\(_n\\) If A is an\ninconsistent set of \\(n\\) or fewer propositions, then rationality\nrequires that you should not believe each proposition in\nA.\n\n\n\nConsistency If A is an inconsistent\nset of finitely many propositions, then rationality requires that you\nshould not believe each proposition in A.\n\n\nTake any \\(n\\) and suppose there is a lottery with \\(n\\) tickets in\nwhich each ticket is equally likely to be the winner. Let \\(L_i\\) be\nthe proposition that says the \\(i^\\mathrm{th}\\) ticket will lose. Then\nthe set of propositions \\(\\{L_1, \\ldots, L_n\\}\\) is inconsistent.\nNonetheless, if my credence in each \\(L_i\\) is \\(1 - \\frac{1}{n}\\), as\nit should be, and the Lockean threshold \\(t\\) is below \\(1 -\n\\frac{1}{n}\\), then the\n Lockean Thesis\n with threshold \\(t\\) says I must believe each member of this\nincoherent set. What\u2019s more, we know that believing each\nmaximizes expected epistemic utility from the point of view of those\ncredences, providing \\(\\frac{W}{R + W}\\) is less than \\(1 -\n\\frac{1}{n}\\). And we also know that no strongly dominated option can\never maximize expected utility. So, if \\(W \\lt (n-1)R\\), and therefore\n\\(\\frac{W}{R + W} \\lt 1 - \\frac{1}{n}\\), then it\u2019s possible to\nhave an inconsistent set of beliefs in \\(n\\) propositions that is not\ndominated. And this shows in turn that there can be no argument from\n Dominance\n to\n Consistency.\n For any \\(W \\gt R \\gt 0\\), there is some \\(n\\) such that\n\\(\\frac{W}{R+W} \\lt 1 - \\frac{1}{n}\\). On the other hand, if \\(n \\lt\n\\frac{R+W}{R}\\), then we can at least argue from\n Dominance\n to\n Consistency\\(_n\\),\n since the maximum epistemic utility of believing each of \\(n\\)\ninconsistent propositions is \\((n-1)R - W\\), which is always less than\nzero if \\(n \\lt \\frac{R+W}{R}\\).\n4.3 Dominance and Almost Lockean Completeness\n\nDaniel Rothschild (2021) gives an argument from\n Dominance\n to a norm he calls Almost Lockean Completeness for Belief Sets at a\nthreshold, which says:\n\n\nAlmost Lockean Completeness for Belief Sets with threshold\n\\(t\\) Rationality requires that there there is some\nprobabilistic credence function such that your beliefs satisfy the\nLockean Thesis with threshold \\(t\\) with respect to that credence\nfunction.\n\n\nIt\u2019s worth noting that the Lockean Thesis and Almost Lockean\nCompleteness for Belief Sets are quite different norms. The first\ngoverns a relationship between your credences and your beliefs; the\nsecond does not even assume you have any credences, and instead\ngoverns only your beliefs\u2014it says that your beliefs should be\nas they would be if you were to have credences and they were\nto be related to your beliefs as the Lockean Thesis says they should\nbe.\n\nHere is Rothschild\u2019s argument. Above, we assumed that the\nepistemic utilities of true beliefs in different propositions are the\nsame, and similarly for false beliefs. But we might score attitudes to\ndifferent propositions differently: \\(R_X\\) for a true belief in\n\\(X\\), \\(-W_X\\) for a false belief in \\(X\\); \\(R_Y\\) for a true belief\nin \\(Y\\), \\(-W_Y\\) for a false belief in \\(Y\\); and so on. For\ninstance, if \\(X\\) concerns the correct fundamental theory of physics,\nI might set \\(R_X = 10, W_X = 20\\), while if \\(Y\\) concerns the number\nof blades of grass in Hyde Park, I might set \\(R_Y = 1, W_Y = 2\\).\nThis might reflect the greater importance of \\(X\\) than \\(Y\\). Now, if\n\\(\\frac{W_X}{R_X} = \\frac{W_Y}{R_Y}\\), for any two propositions \\(X,\nY\\), we say that the epistemic utilities have uniform ratio.\nAnd in that case the Lockean threshold is the same for each\nproposition if we maximize expected utility. But what about\n Dominance?\n Rothschild proves the following result:\n\n\nDominance Theorem for Almost Lockean Completeness for Belief\nSets (Rothschild 2021) A belief set satisfies Almost Lockean\nCompleteness iff there is no set of epistemic utilities with uniform\nratio under which the pair is strongly dominated.\n\n\nI sketch the proof in the\n supplementary materials.\n\nOne issue with this argument: To extract\n Almost Lockean Completeness\n from the\n Dominance Theorem for Almost Lockean Completeness,\n a decision-theoretic norm is needed. It would say that it\u2019s\nirrational to be dominated relative to any set of epistemic\nutilities that have uniform ratio. But this norm is not compelling.\nWhy care about being dominated relative to epistemic utilities that\nare not your own?\n4.4 Updating your beliefs when you receive evidence\n\nAll the norms we have considered so far in this entry have been\nsynchronic: that is, they say what rationality requires of your\nbeliefs at a given time. In this section, we turn to diachronic norms:\nthese say what rationality requires of the relationship between your\nbeliefs at one time and your beliefs at another, typically when you\nlearn some evidence between those times. We\u2019ll look at two sets\nof norms for belief updating: AGM belief revision\n (Section 4.4.1)\n and Plan Lockean Revision\n (Section 4.4.2).\n4.4.1 AGM belief revision\n\nAGM belief revision is a set of putative norms that govern full\nbeliefs introduced by Carlos Alchourr\u00f3n, Peter G\u00e4rdenfors,\nand David Makinson (1985); it includes both synchronic and diachronic\nnorms (see entry on\n the logic of belief revision).\n The synchronic norms are these, and they apply both before and after\nyou acquire new evidence:\n\n\nConsistency If \\(\\mathbf{A}\\) is an inconsistent set\nof finitely many propositions, then you should not believe each\nproposition in \\(\\mathbf{A}\\).\n\nClosure If \\(X\\) is a logical consequence of the\npropositions in \\(\\mathbf{A}\\), then you should not believe each\nproposition in \\(\\mathbf{A}\\) while not believing \\(X\\).\n\n\nWe\u2019ve already seen that we cannot give an argument for either of\nthese from the point of view of epistemic utility. But perhaps we can\ndo better with the diachronic norms. These norms govern a belief\nupdating operator \\(\\star\\), which takes your belief set\n\\(\\mathbf{B}\\), together with a proposition \\(E\\) that gives the\nevidence you learn, and returns \\(\\mathbf{B} \\star E\\), which is your\nnew belief set after you learn \\(E\\). The AGM postulates state that\nthe following are required by rationality:\n\n\nSuccess \\(E\\) is in \\(\\mathbf{B} \\star E\\). That is,\nafter learning a proposition, you should believe it.\n\nInclusion \\(\\mathbf{B} \\star E \\subseteq\n\\mathsf{Cn}(\\mathbf{B} \\cup \\{E\\})\\), where \\(\\mathsf{Cn}\\) takes a\nset of propositions and returns its logical closure. That is, you\nshould believe a proposition after learning only if it is a logical\nconsequence of what previously believed and the proposition you\nlearn.\n\nPreservation If \\(\\mathbf{B}\\) and \\(E\\) are\nconsistent, then \\(\\mathbf{B} \\subseteq \\mathbf{B} \\star E\\). That is,\nif what you learn is consistent with what you previously believed, you\nshouldn\u2019t drop your belief in anything you previously believed\nwhen you learn.\n\nExtensionality If \\(E\\) and \\(F\\) are logically\nequivalent, then \\(\\mathbf{B} \\star E = \\mathbf{B} \\star F\\). That is,\nlearning either of two logically equivalent propositions should change\nyour beliefs in the same way.\n\n\nAs Shear and Fitelson (2019) show, we can justify\n Success,\n Inclusion, and\n Extensionality\n by appealing to\n Maximize Expected Epistemic Utility.\n To do this, we note that, as we\u2019ll justify in\n Section 5.3,\n there is a standard norm that is taken to govern how we should update\nour credences in response to new evidence. It\u2019s called\nConditionalization and it says that, if you assign positive credence\nto a proposition \\(E\\) and then learn \\(E\\) for sure as evidence, then\nyour new credence in a proposition \\(X\\) should be your old\nconditional credence in \\(X\\) given \\(E\\), where that is defined to be\nthe ratio of your credence in the conjunction of \\(X\\) and \\(E\\) to\nyour credence in \\(E\\) alone; or, in other words, it\u2019s the\nproportion of your old credence in \\(E\\) that you also assigned to\n\\(X\\). So you might think that (i) you should set your original\ncredences by maximising expected utility with respect to your original\ncredences, and (ii) set your new credences after learning evidence by\nmaximising expected utility with respect to your new credences, which\nare obtained from your old ones by updating on your evidence in line\nwith Conditionalization. Doing this secures\n Success,\n Inclusion, and\n Extensionality.\n It doesn\u2019t secure\n Preservation\n because learning a new proposition that is consistent with all the\npropositions to which you assigned credence higher than some threshold\ncan lead you to drop your credence in one of those propositions below\nthat threshold.\n4.4.2 Almost Lockean Completeness for Updating Plans\n\nPatrick Rooyakkers (ms) has extended Rothschild\u2019s argument for\nthe Lockean Thesis so that it establishes a version of Almost Lockean\nCompleteness but for combinations of belief sets and updating plans.\nThe idea is this: Suppose you\u2019re about to learn some new\nevidence. You don\u2019t know what it is, but you know it will be one\nof the propositions \\(E_1, \\ldots, E_k\\), which together form a\npartition\u2014that is, the propositions are exhaustive and mutually\nexclusive. Then, as well as your prior belief set, which we\u2019ll\ncall \\(\\mathbf{B}\\), you should have an updating plan in place for how\nyou\u2019ll respond to each of the possible pieces of evidence you\nmight receive; for each \\(E_i\\), this should give the belief set\n\\(\\beta_{E_i}\\) you plan to have if \\(E_i\\) is the proposition you\nlearn. Then the following norm governs this plan:\n\n\nAlmost Lockean Completeness for Plans with threshold\n\\(t\\) Rationality requires that there is a probabilistic\ncredence function such that:\n\nIf the unconditional credence it assigns to \\(X\\) is greater than\n\\(t\\), then \\(X\\) is in \\(\\mathbf{B}\\); if it is less than \\(t\\), then\n\\(X\\) is not in \\(\\mathbf{B}\\); \nFor each \\(E_i\\), if the conditional credence it assigns to \\(X\\)\ngiven \\(E_i\\) is greater than \\(t\\), then \\(X\\) is in \\(\\beta_{E_i}\\);\nif it is less than \\(t\\), then \\(X\\) is not in \\(\\beta_{E_i}\\).\n\n\n\nThat is, you are required to obey the Lockean Thesis with a particular\nthreshold and some probabilistic credence function before you acquire\nthe new evidence, and obey it with respect to some unconditional\ncredences; and you are required to plan to obey it with the same\nthreshold after you\u2019ve received the evidence, and obey it then\nwith respect to the conditional credences given the evidence you\nlearn.\n\nRooyakkers\u2019 argument has the same form as Rothschild\u2019s. He\nproves the following on the assumption that the epistemic utility at a\nworld of a pair consisting of a prior belief set and a belief plan\nshould be the sum of the epistemic utility of the prior belief set at\nthat world and the epistemic utility of the posterior belief set that\nthe plan endorses if you learn the proposition in the partition that\nis true at that world:\n\n\nDominance Theorem for Almost Lockean Completeness for Plans\n(Rooyakkers ms) A prior belief set and a belief plan together\nsatisfy Almost Lockean Completeness for Plans iff there is no set of\nepistemic utilities with uniform ratio under which the pair is\nstrongly dominated.\n\n5. Epistemic Utility Arguments for Precise Credences\n\nIn the precise credence model, we represent an individual\u2019s\nepistemic state by their credence function, which takes each\nproposition in their agenda and returns a real number at least 0 and\nat most 1, which measures the strength of their belief, or their\ndegree of confidence, in that proposition. In mathematical notation,\n\\(C : \\mathcal{F} \\rightarrow [0, 1]\\).\n\nWe\u2019ll meet the norm of Probabilism below, but it will be helpful\nto say here what it means for a credence function to be probabilistic,\nso that we can use that notion in the coming section. Suppose \\(C\\) is\na credence function defined on the agenda \\(\\mathcal{F}\\). Then, if\n\\(\\mathcal{F}\\) is an algebra, \\(C\\) is probabilistic if\n\nNormality: \\(C(\\top) = 1\\), if \\(\\top\\) is a tautology; and\n\\(C(\\bot) = 0\\), if \\(\\bot\\) is a contradiction.\nFinite Additivity: \\(C(X \\vee Y) = C(X) + C(Y)\\), for all mutually\nexclusive \\(X\\) and \\(Y\\) in \\(\\mathcal{F}\\).\n\n\nAnother piece of terminology that will be useful below. A\nmixture of a sequence of credence functions is a weighted sum\nof them. That is, given a sequence of credence functions, \\(C_1,\n\\ldots, C_n\\) and a sequence of weights \\(0 \\leq \\lambda_1, \\ldots,\n\\lambda_n \\leq 1\\) that sum to 1, we define the mixture of these\ncredence functions with these weights to be \\(\\lambda_1C_1 + \\ldots +\n\\lambda_nC_n\\), where, for each \\(X\\), \n\\[(\\lambda_1C_1 + \\ldots + \\lambda_nC_n)(X) = \\lambda_1C_1(X) + \\ldots + \\lambda_nC_n(X)\\]\n The straight\nmixture of \\(C_1, \\ldots, C_n\\) is the mixture in which each\nreceives the same weight. If each of a sequence of credence functions\nis probabilistic, so is any mixture of them.\n5.1 Epistemic utility functions for precise credences\n\nAn epistemic utility function for the states considered in the precise\ncredence model takes a credence function on an agenda and a state of\nthe world relative to that same agenda, and returns a real number or\n\\(-\\infty\\) or \\(\\infty\\) that measures the epistemic utility of that\ncredence function at that state of the world. One of the most popular\nepistemic utility functions is the Brier score. To define it,\nwe first define a measure of the epistemic utility of a single\ncredence in a single proposition, and then use that to generate a\nmeasure of the epistemic utility of an entire credence function on an\nagenda. Measures of the epistemic utility of a single credence are\nknown as scoring rules. Suppose \\(s\\) is a scoring rule.\nThen, given a credence \\(p\\):\n\n\\(s(1, p)\\) gives the epistemic utility of having credence \\(p\\)\nin a true proposition;\n\\(s(0, p)\\) gives the epistemic utility of having credence \\(p\\)\nin a false proposition.\n\n\nHere\u2019s the quadratic scoring rule:\n\n\\(q(1, p) = -(1-p)^2\\)\n\\(q(0, p) = -p^2\\)\n\n\nOne way to understand this: If a proposition is true, then credence 1\nis the ideal credence in it; if it\u2019s false, then credence 0 is\nthe ideal. The quadratic scoring rule says that the epistemic\ndisutility of a credence is the square of the difference\nbetween it and the ideal, and the epistemic utility is the negative of\nthat. So the epistemic utility of a credence is its proximity to the\nideal credence for a particular way of measuring distance.\n\nThe Brier score of an entire credence function is then\ndefined to be the sum of the quadratic scores of the credences it\nassigns. So: \n\\[\nB(C, w) = \\sum_{X \\in \\mathcal{F}} q(V_w(X), C(X)) = -\\sum_{X \\in \\mathcal{F}} (V_w(X) - C(X))^2\n\\]\n where \\(V_w(X) = 1\\) if \\(X\\) is true at\n\\(w\\), and \\(V_w(X) = 0\\) if \\(X\\) is false at \\(w\\). We might think\nof \\(V_w\\) as the ideal or omniscient credence function at world\n\\(w\\).\n\nThe quadratic score and the Brier score have certain properties that\nare important in epistemic utility arguments concerning precise\ncredences:\n\nFirst, properties of scoring rules:\n\n\nContinuity (for scoring rules) We say that a scoring\nrule \\(s\\) is continuous if \\(s(1, p)\\) and \\(s(0, p)\\) are\nboth continuous functions of \\(p\\) on \\([0, 1]\\).\n\nStrict Propriety (for scoring rules) We say that a\nscoring rule \\(s\\) is strictly proper if, for any \\(0 \\leq p\n\\leq 1\\), \n\\[\nps(1, x) + (1-p)s(0, p)\n\\]\n is maximized uniquely at \\(x = p\\). (That is,\neach probability expects itself to be best, epistemically\nspeaking.)\n\n\nSecond, properties of epistemic utility functions:\n\n\nContinuity (for epistemic utility functions) We say\nthat an epistemic utility measure \\(EU\\) is continuous if\n\\(EU(C, w)\\) is a continuous function of \\(C\\) on the set of credence\nfunctions defined on the same agenda.\n\nStrict Propriety (for epistemic utility functions) We\nsay that an epistemic utility measure \\(EU\\) is strictly\nproper if, for any probabilistic credence function \\(P\\) defined\non \\(\\mathcal{F}\\), \n\\[\n\\sum_{w \\in \\mathcal{W}_\\mathcal{F}} P(w)EU(C, w)\n\\]\n is maximized uniquely, among credence\nfunctions defined on \\(\\mathcal{F}\\), at \\(C = P\\). (That is, each\nprobabilistic credence function expects itself to be best,\nepistemically speaking.)\n\nExtensionality (for epistemic utility functions) We\nsay that an epistemic utility measure \\(EU\\) is extensional\nif, whenever \\(C\\) is a probability function on \\(\\mathcal{F}\\), and\n\\(\\pi\\) is a permutation of the worlds in \\(\\mathcal{W}_\\mathcal{F}\\),\nthen \\(EU(C, w) = EU(\\pi(C), \\pi(w))\\), where \\(\\pi(C)(w) =\nC(\\pi(w))\\).\n\nAdditivity (for epistemic utility functions) We say\nthat an epistemic utility measure \\(EU\\) is additive if, for\neach \\(X\\) in \\(\\mathcal{F}\\), there is a scoring rule \\(s_X\\) such\nthat \n\\[\nEU(C, w) = \\sum_{X \\in \\mathcal{F}} s_X(V_w(X), C(X))\n\\]\n\n\n(That is, the epistemic utility of an entire credence function is the\nsum of the epistemic utilities of the individual credences, where\nthese can be given by different scoring rules for each proposition in\nthe agenda.)\n\n\nSuppose \\(EU\\) is additive. Then (i) \\(EU\\) is continuous iff each\n\\(s_X\\) is continuous; and (ii) \\(EU\\) is strictly proper iff each\n\\(s_X\\) is strictly proper.\n\nA detailed discussion of the various arguments for using scoring rules\nand epistemic utility functions that have these properties claims can\nbe found in the\n supplementary materials.\n They roughly divide into two sorts:\n\nThe first sort of argument is based on a veritist account of epistemic\nvalue, which says that the sole fundamental source of epistemic value\nis what Joyce (1998) calls gradational accuracy. The idea is\nthat a credence in a true proposition is more accurate, and therefore\nmore valuable, epistemically speaking, the higher it is, while a\ncredence in a false proposition is more accurate, and thus\nepistemically more valuable, the lower it is. Put another way, the\nideal credence function to have at a world is the omniscient credence\nfunction at that world, which assigns maximal credence to all the\ntruths and minimal credence to all the falsehoods; and your credence\nfunction is more accurate, and therefore epistemically more valuable,\nthe closer it lies to this ideal. So, for veritists, epistemic utility\nfunctions measure the accuracy of a credence function, and\ncharacterizing the legitimate epistemic utility functions is\ncharacterizing the legitimate ways of measuring accuracy.\n\nJoyce (1998) offers one such characterization, based on a series of\naxioms he justifies individually. Leitgeb and Pettigrew (2010) offer\nan argument for the Brier score based on the requirement to avoid a\ncertain sort of rational dilemma. D\u2019Agostino and Sinigaglia\n(2010) offer another argument for that epistemic utility function\nbased on the idea that accuracy is proximity to the ideal credence\nfunction. Pettigrew (2016) also thinks of accuracy that way, but\noffers an argument for additive and continuous strictly proper\nepistemic utility functions, based on a suggestion by Frank P. Ramsey\n(1926 [1931]) that connects accuracy and calibration, and Williams and\nPettigrew (2023) improve on that characterization. Based on a\npragmatic understanding of accuracy, where the utility of a credence\nis the pragmatic utility it obtains for you through the practical\ndecisions it leads you to make, Levinstein (2017) builds on technical\nresults by Mark J. Schervish (1989) to characterize the additive and\ncontinuous strictly proper scoring rules. And building on a suggestion\nby Sophie Horowitz (2017) that the epistemic value of a credence\nfunction is the quality of the educated guesses that it would license\nyou to make were you faced with a forced choice between guessing\nvarious propositions, Gabrielle Kerbel (ms.) takes the accuracy of a\ncredence to be the average quality of the guesses your credence\nlicenses across a large range of forced choices it might be used to\nmake, and shows that this generates an additive and continuous\nstrictly proper epistemic utility function.\n\nThe second sort of argument does not commit to a particular account of\nepistemic value. Rather, it argues directly that, whatever is the\nsource of epistemic value, measures of it should have certain\nproperties. For instance, Joyce (2009) argues that measures of\nepistemic value should be strictly proper as follows: If a measure of\nepistemic utility is not strictly proper, then there is a\nprobabilistic credence function that doesn\u2019t expect itself to be\nbest, epistemically speaking. Because of this, that credence function\ncannot be the unique rational response to any evidence, because it\nthinks of an alternative as equally good, and so someone with that\ncredence function could rationally move to the alternative. But, for\nany probabilistic credence function, there is a body of evidence to\nwhich it is the unique rational response. So we have a contradiction.\nTherefore, every legitimate measure of epistemic utility is strictly\nproper. H\u00e1jek (2008) criticizes this argument and Pettigrew\n(2016) defends Joyce.\n\nWe now move to some general objections to these characterizations of\nepistemic utility functions.\n5.1.1 The Varying Importance Objection \n\nAccording to Additivity, which is assumed by many of the accounts of\nepistemic utility, the epistemic utility of a whole credence function\nis the sum of the epistemic utilities of the individual credences it\ncomprises; and which scoring rule measures the epistemic utility of a\ncredence in a proposition at a world can depend on the proposition,\nbut not on the world. This allows the veritist, for instance, to\naccommodate the fact that the accuracy of some propositions is more\nimportant to us than the accuracy of others: I might take the accuracy\nof a proposition about how many blades of grass there are on my lawn\nto be less important than a proposition about the fundamental\nconstants of the universe. In such a case, I can simply take the\naccuracy of a credence function to be a weighted sum of the epistemic\nutilities of the individual credences, with greater weight given to\nthe propositions whose accuracy is more important to me. But Ben\nLevinstein (2018) argues that the importance of a proposition does\nsometimes depend on which world we inhabit: in worlds where I meet a\nparticular person and fall in love with them, propositions that\nconcern their well-being have great importance to me, and the\nepistemic utility of my credences in those propositions should\ncontribute greatly to the epistemic utility of my whole credence\nfunction; in worlds where I never meet that person, on the other hand,\nthe importance of these propositions is much diminished, as is the\ncontribution of the epistemic utility of my credences in them to my\ntotal epistemic utility. And so the weights we assign to the scores of\nthe individual credences must also depend on the worlds; something\nthat Additivity rules out. And Levinstein shows further that, if we do\nallow the weights to vary with the worlds, the resulting measure of\nepistemic utility is no longer strictly proper, and indeed the\nargument from\n Dominance\n to\n Probabilism\n that we\u2019ll discuss in\n Section 5.2\n fails if we use it.\n5.1.2 The Verisimilitude Objection \n\nGraham Oddie (2019) has argued that there is a source of epistemic\nvalue that cannot be captured by any of the epistemic utility\nfunctions that satisfy the conditions described above; this is the\nvirtue of verisimilitude (see entry on\n truthlikeness).\n His point is most easily introduced by an example. Suppose I am\ninterested in how many stars there are on the flag of Suriname. I have\ncredences in three propositions: One, Two, and\nThree. In fact, there is exactly one star on the flag, so\nOne is true at the actual world, while Two and\nThree are false. Now consider two different credence\nfunctions on these three propositions: \n\\[\n\\begin{array}{r|ccc}\n& \\textit{One} & \\textit{Two} & \\textit{Three} \\\\\n\\hline\nC & 0 & 0.5 & 0.5 \\\\\nC' & 0 & 1 & 0 \n\\end{array}\n\\]\n\n\nSo, \\(C\\) and \\(C'\\) both assign credence 0 to the true proposition,\nOne; they are certain that there are either two or three\nstars on the flag, but while \\(C\\) spreads its credence equally over\nthese two false options, \\(C'\\) is certain of the first. According to\nOddie, \\(C'\\) has greater truthlikeness than \\(C\\) at the actual world\nbecause it assigns a higher credence to a proposition that, while\nfalse, is more truthlike, namely, Two, and it assigns a lower\ncredence to a proposition that is, while also false, less truthlike,\nnamely, Three. On this basis, he argues that any measure of\nepistemic disutility must judge \\(C\\) to be worse than \\(C'\\).\nHowever, he notes, nearly all measures of gradational accuracy\nendorsed in epistemic utility theory will not judge in that way: they\nwill judge \\(C'\\) worse than \\(C\\). And indeed those that do so judge\nwill fail to respect truthlikeness in other ways. Jeffrey Dunn (2018)\nand Miriam Schoenfield (2019) respond to Oddie\u2019s arguments.\n5.1.3 The Numerical Representability Objection \n\nWe have considered a number of different characterizations of the\nlegitimate ways of measuring epistemic utility. Each has assumed that\nthe measures of these quantities are numerically representable; that\nis, each assumes it makes sense to use real numbers to measure these\nquantities. Conor Mayo-Wilson and Greg Wheeler call this assumption\ninto question (Mayo-Wilson & Wheeler, ms.). They argue that, in\norder to represent a quantity numerically, you need to prove a\nrepresentation theorem for it in measurement theory. And, if you wish\nto use that quantity as a measure of utility, or as a component of a\nmeasure of utility, you need to prove a representation theorem not\nonly for the quantity itself, but for its use in expected utility\ncalculations. They note that this was the purpose of the\nrepresentation theorems of von Neumann & Morgenstern as well as\nSavage and Jeffrey (see entry on\n normative theories of rational choice: expected utility).\n And they argue that the methods that these authors use are not\navailable to the proponent of epistemic utility arguments. \n5.2 Epistemic utility arguments for Probabilism\n\nFollowing the structure of epistemic utility arguments described in\n Section 2,\n the arguments for Probabilism have three components: an account of\nepistemic utility, which specifies a range of legitimate measures of\nthat quantity; a decision-theoretic norm; and a mathematical theorem\nthat derives the epistemic norm from the decision-theoretic norm when\nthe options are credence functions and utility is epistemic\nutility.\n\n\nProbabilism Rationality requires that your credence\nfunction at any given time is probabilistic.\n\n\nProbabilism is one of a handful of norms that characterize the\nBayesian view in credal epistemology. The epistemic utility arguments\nin its favor appeal to a slight weakening of the Dominance norm to\nwhich we appealed above. We say that one option strongly\ndominates another if it is better at all possible states of the\nworld, and we say it weakly dominates if it is at least as\ngood at all states of the world and better at some.\n\n\nUndominated Dominance If one option is strongly\ndominated by another that isn\u2019t itself even weakly dominated,\nthen rationality requires that you should not adopt the first.\n\n\nAs before, we also appeal to a mathematical theorem to derive\nProbabilism from the account of epistemic utility and the\ndecision-theoretic norm. The strongest theorem in the area is\nthis:\n\n\nDominance Theorem for Probabilism (de Finetti 1974; Savage\n1971; Predd, et al. 2009; Pettigrew 2022; Nielsen 2022)\nSuppose our epistemic utility function is continuous and strictly\nproper. Then\n\n Every non-probabilistic credence function defined on a particular\nagenda is strongly dominated by a probabilistic credence function\ndefined on that agenda.\n No probabilistic credence function defined on a particular agenda\nis even weakly dominated by any credence function defined on that\nagenda.\n\n\n\nSee the\n supplementary materials\nfor a sketch of how the proof of (i) follows from the Dominance\nTheorem for Convex Hulls.\n\nSo, we have the following argument for Probabilism:\n\n\nContinuity\n +\n Strict Propriety (for epistemic utility functions)\n\nUndominated Dominance\n\nTherefore,\n\nProbabilism\n\n\nWe now turn to objections to this argument.\n5.2.1 The Different Dominators Objection\n\nMany of the existing characterizations of the legitimate epistemic\nutility functions characterize a family of such measures; they do not\nnarrow the field to a single epistemic utility function. But, for all\nthat the\n Dominance Theorem for Probabilism\n tells us, it may well be that, for a given non-probabilistic credence\nfunction, different epistemic utility functions in such a family give\ndifferent sets of credence functions that dominate it. Thus, an agent\nwith a non-probabilistic credence function might be faced with a range\nof alternative credence functions, each of which dominates theirs\nrelative to a different legitimate epistemic utility function.\nMoreover, it may be that any credence function that dominates their\ncredence function relative to one epistemic utility function does not\ndominate it relative to another; indeed, it may be that any credence\nfunction that dominates theirs relative to the first risks very high\nepistemic disutility at some world relative to the second, and\nvice versa. In this situation, it is plausible that the agent\nis rationally permitted to stick with her non-probabilistic credence\nfunction. This objection was originally raised by Aaron Bronfman in\nunpublished work, and it has been discussed by H\u00e1jek (2008) and\nPettigrew (2010, 2013b)\n5.2.2 Evidence and Accuracy\n\nAccording to\n Undominated Dominance,\n a dominated option is only ruled irrational in virtue of being\ndominated if at least one of the options that dominate it is not\nitself dominated. But there may be other features that a credence\nfunction might have besides itself being dominated such that being\ndominated by that credence function does not entail irrationality.\nKenny Easwaran and Branden Fitelson (2012) suggest such a feature.\nSuppose that your credence function is non-probabilistic, but it\nmatches the evidence that you have: that is, the credence it assigns\nto a proposition matches the extent to which your evidence supports\nthat proposition. And suppose that none of the credence functions that\ndominate your credence function have that feature. Then, we might say,\nthe fact that your credence function is dominated does not rule it\nirrational. For instance, suppose that a trick coin is about to be\ntossed. Your evidence tells you that the chance of it landing heads is\n0.7. Your credence that it will lands heads is 0.7 and your credence\nthat it will land tails is 0.6. Then you might think that your\ncredences match your evidence, because you have evidence only about it\nlanding heads and your credence that it will land heads equals the\nknown chance that it will land heads. However, it turns out that all\nof the credence functions that dominate your credence function fail to\nmatch this evidence, when epistemic utility is measured by the\n Brier score:\n that is, they assign credence other than 0.7 to the coin landing\nheads. Pettigrew (2014a) and Joyce (2018) respond to this objection on\nbehalf of the dominance argument for Probabilism.\n5.2.3 Dominance and Act-State Dependence\n\nThe final objection to the argument begins with the following sort of\ncase (Greaves 2013; Caie 2013; Campbell-Moore 2015):\n\n\nThwarted Accuracy Suppose I can read your mind. You\nhave opinions only about two propositions, \\(X\\) and \\(\\neg X\\). And\nsuppose that I have control over the truth of \\(X\\) and \\(\\neg X\\). I\ndecide to do the following. First, define the non-probabilistic\ncredence function \\(C^\\dag(X) = 0.8\\) and \\(C^\\dag(\\neg X) = 0.1\\).\nThen:\n\nIf your credence function is \\(C^\\dag\\), I will make \\(X\\) true\n(and thereby make your credence function very accurate);\nIf your credence function is not \\(C^\\dag\\) and your credence in\n\\(X\\) is greater than 0.5, I will make \\(X\\) false (and thereby make\nyour credence function rather inaccurate);\nIf your credence function is not \\(C^\\dag\\) and your credence in\n\\(X\\) is at most 0.5, I will make \\(X\\) true (and thereby make your\ncredence function rather inaccurate).\n\n\n\nNow \\(C^\\dag\\) is not probabilistic, so there are credence functions\nthat are more accurate than \\(C^\\dag\\) whether \\(X\\) is true or false.\nHowever, because of the way I will manipulate the world in response to\nyour credences about it, if you adopt anything other than \\(C^\\dag\\),\nyou\u2019ll end up less accurate. In such a case, it seems\nrationality doesn\u2019t require us to have probabilistic credences.\nThe culprit here is\n Undominated Dominance.\n It is only plausible in cases in which the options between which the\nagent is choosing will not influence the way the world is if they are\nadopted. Such situations are sometimes called situations of\nact-state independence.\n\nThere are three responses available here: the first is to bite the\nbullet, accept the restriction to\n Undominated Dominance,\n and therefore accept a restriction on the cases in which Probabilism\nholds; the second is to argue that the practical case and the\nepistemic case are different, with different decision-theoretic\nprinciples applying to each; the third, of course, is to abandon the\naccuracy argument for Probabilism. Joyce (2018) and Pettigrew (2018a)\nargue for the first response. They advocate different\ndecision-theoretic principles to replace\n Undominated Dominance\n in the epistemic case: Joyce advocates standard causal decision\ntheory together with a Ratifiability condition (Jeffrey 1983);\nPettigrew omits the ratifiability condition. But they both agree that\nthese principles will agree with\n Undominated Dominance\n in cases of act-state independence; and they agree with the verdict\nthat \\(C^\\dag\\) is the only credence function that isn\u2019t ruled\nout as irrational in Thwarted Accuracy. Konek and Levinstein (2019)\nargue for the second response, claiming that, since doxastic states\nand actions have different directions of fit, different\ndecision-theoretic principles will govern them; and Kurt Sylvan (2020)\ncan be read as arguing for the same conclusion on the basis of his\nclaim that, while accuracy is the fundamental source of value for\nepistemic states like credences, it is a value to which the\nappropriate response is respect, not promotion. They\nhold that\n Undominated Dominance\n is the correct principle when the options are credence functions,\neven though it is not the correct principle when the options are\nactions. Caie (2013) and Berker (2013a,b), on the other hand, argue\nfor the third option.\n5.2.4 Epistemic expansions\n\nThe\n Dominance Theorem for Probabilism\n states: for epistemic utility functions of a particular sort, every\nnon-probabilistic credence function defined on a particular agenda is\ndominated by an alternative probabilistic credence function,\ndefined on that same agenda, that is itself not dominated by\na further alternative defined again on the same agenda. But\nyou might think that this is still not sufficient to establish\n Probabilism.\n After all, while the dominating credence function is not itself\ndominated by an alternative credence function defined on the same\nagenda, it might be dominated by an alternative credence function\ndefined on a different agenda. For instance, take the\nnon-probabilistic credence function \\(C^*\\) defined on \\(\\mathcal{F} =\n\\{X, \\neg X\\}\\), where \\(C^*(X) = 0.6 = C^*(\\neg X)\\). Relative to the\nBrier score, it is dominated by \\(C'(X) = 0.5 = C'(\\neg X)\\). But\n\\(C'\\) is Brier dominated by \\(C^\\dag\\) defined on \\(\\mathcal{F}^\\dag\n= \\{X\\}\\), where \\(C^\\dag(X) = 0.5\\).\n\nA natural reaction to this is to define the epistemic utility of a\ncredence function to be the average epistemic utility of the credences\nit assigns, rather than the total epistemic utility. For instance,\njust as the Brier score is the total quadratic score of the credences\nit assigns, we can define the average Brier score of a\ncredence function to be the average quadratic score of the credences\nit assigns. Now, relative to the average Brier score, \\(C^*\\) is\nindeed dominated by \\(C'\\) and \\(C'\\) is not dominated by \\(C^\\dag\\).\nBut \\(C'\\) is dominated by \\(C^+\\) defined on \\(\\mathcal{F}^+ =\n\\{\\top\\}\\), where \\(C^+(\\top) = 1\\). Jennifer Carr (2015) initiated\nthe investigation into how epistemic utility arguments for Probabilism\nmight work when we start to compare credence functions defined on\ndifferent agendas. She notes the analogy with population axiology in\nethics (see entry on\n the repugnant conclusion).\n Pettigrew (2018b) takes this analogy further, proving an\nimpossibility result analogous to those prevalent in that part of\nethics, and Brian Talbot (2022) presses the objection based on this\nproblem further.\n5.2.5 Infinite probability spaces\n\nIn the final two parts of this section, we ask what happens to the\nargument for\n Probabilism\n when (i) we allow for infinite agendas and (ii) we allow the logic of\nthe propositions in those agendas to be non-classical.\n\nWe have assumed throughout that the set of propositions on which an\nagent\u2019s credence function is defined is finite. What happens\nwhen we lift this restriction? The first problem is that we need to\nsay how to measure the epistemic utility of a credence function\ndefined over an infinite set of propositions. Then, having done that,\nwe need to say which such credence functions are dominated relative to\nthese measures, and which aren\u2019t.\n\nSean Walsh has described an extension of the Brier score to the case\nin which the set of propositions to which we assign credences is\ncountably infinite; and he has shown that non-probabilistic credence\nfunctions on such sets are dominated relative to that measure, while\nprobabilistic ones are not. (For a description of Walsh\u2019s\nunpublished work, see Kelley 2019). Mikayla Kelley (2019) has then\ngone considerably further and generalized Walsh\u2019s results\nsignificantly by describing a wide range of possible epistemic utility\nfunctions and characterizing the undominated credence functions\ndefined on sets of propositions of different varieties; and Michael\nNielsen (2023) has generalized them in a different direction.\n5.2.6 Non-classical logic\n\nIn all of the arguments we\u2019ve surveyed above, we have assumed\nthat classical logic governs the propositions to which our agent\nassigns credences. This secures\n Probabilism,\n which demands, among other things, that an agent assign maximal\ncredence to every classical tautology. But what happens if we drop\nthis assumption? What if, instead, the propositions are governed by a\nthree-valued logic, such as strong Kleene logic or the Logic of\nParadox (see entry on\n many-valued logic)?\n In a series of papers, Robbie Williams (2012a,b, 2018) has built on\nmathematical results by Jeff Paris (2001) and Jean-Yves Jaffray (1989)\nto understand what norms of credence the epistemic utility arguments\nestablish in this case. I\u2019ll give a single example here to\nillustrate.\n\nStrong Kleene logic has three truth values: True, False, and Neither.\nOur first question is this: what is the ideal credence in a\nproposition that is neither true nor false? Williams argues that it\nshould be zero. And then he shows that, if the epistemic utility of a\ncredence at a world is its proximity to the ideal credence at that\nworld, and we measure the distance of one credence to another as the\nsquare of the difference between them, as we do to generate the\nquadratic scoring rule in the classical case, then the credence\nfunctions that are not dominated are precisely those that satisfy the\nnorm of Generalized Probabilism:\n\n\nGeneralized Probabilism Suppose \\(\\models\\) is the\nlogical consequence relation of the correct logic. Rationality\nrequires that your credence function \\(C\\) at a given time should be a\ngeneralized probability function for that logic. That is:\n\n If \\(\\bot \\models\\), then \\(C(\\bot) = 0\\).\n If \\(\\models \\top\\), then \\(C(\\top) = 1\\).\n If \\(X \\models Y\\), then \\(C(X)\\leq C(Y)\\).\n\\(C(X \\vee Y) = C(X) + C(Y) - C(X \\wedge Y)\\).\n\n\n\nNote that, if \\(\\models\\) is classical, then Generalized Probabilism\nis equivalent to Probabilism.\n\nWilliams (2018) also considers the case in which you are uncertain\nwhich logic governs the propositions you consider, and Pettigrew\n(2021) draws on a suggestion by Ian Hacking (1967) in a different\ncontext to explore the case in which you know that the logic is\nclassical, but you don\u2019t know all the logical facts.\n5.3 Epistemic utility arguments for chance-credence norms\n\nIn this section, we consider epistemic utility arguments for norms\nthat govern the relationship between the credences you assign to\npropositions concerning objective chances and credences you assign to\npropositions to which the objective chances assign probabilities: so,\nfor instance, the relationship between your credence in the\nproposition that the chance of rain tomorrow is 76% and the\nproposition that it will rain tomorrow (see entry on\n chance and randomness).\n The most well-known principle of this kind is the one that David\nLewis calls the Principal Principle (1980). To state it, we use the\nfollowing notation: if \\(ch\\) is a probability function, we write\n\\(\\rho_{ch}\\) for the proposition that says that \\(ch\\) gives the\nobjective chances. Then:\n\n\nThe Principal Principle Rationality requires that, if\n\\(C(\\rho_{ch}) \\gt 0\\), and \\(E\\) is your total evidence, then \\(C(X\n\\mid \\rho_{ch}) = ch(X \\mid E)\\), for all \\(X\\) in your agenda. \n\n\nSo, for instance, your credence that it should rain tomorrow\nconditional on the chance of rain tomorrow given all your evidence\nbeing 76% should be 0.76.\n\nNow, as Lewis pointed out, this norm has implausible consequences if\nthe objective chance function might be modest in the presence of\nthe body of evidence \\(E\\): that is, if the true chances might be\nuncertain, given \\(E\\), that they give the true chances; that is, if\nthere is a probability function \\(ch\\) that might give the chances for\nwhich \\(ch(\\rho_{ch} \\mid E) \\lt 1\\). After all, by the Principal\nPrinciple, if \\(C(\\rho_{ch}) \\gt 0\\), then \\(C(\\rho_{ch} \\mid\n\\rho_{ch}) = ch(\\rho_{ch} \\mid E) \\lt 1\\), but by the definition of\nconditional probability, \\(C(\\rho_{ch} \\mid \\rho_{ch}) = 1\\).\nContradiction. So \\(C(\\rho_{ch}) = 0\\). That is, if some of the\npossible chance functions are modest in the presence of our evidence,\nwe must give them zero credence. And, as Lewis argued, the chances\nposited by his account, which is known as Humeanism, will indeed be\nmodest in this sense, because they will give some positive probability\nto the world being so different that its chances are also different\n(Lewis 1980; see Section 3.6 of the entry on\n Interpretations of Probability).\n\nNonetheless, if we assume that the chances are not modest, which is a\nnatural consequence of many non-Humean theories of chance, then we can\ngive an epistemic utility argument for the Principal Principle\n(Pettigrew 2013, 2022). In the first premise, we assume Continuity and\nStrict Propriety (for epistemic utility functions)\u2014either\nbecause credal veritism is true and the legitimate measures of\naccuracy are continuous and strictly proper, or for other reasons. For\nthe second premise, we assume the following decision-theoretic norm,\nwhere we say that one option strongly chance dominates another in\nthe presence of \\(E\\) if every possible chance function,\nconditional on \\(E\\), gives higher expected utility to the first than\nto the second, and we say that one option weakly chance dominates\nanother in the presence of \\(E\\) if every possible chance\nfunction, conditional on \\(E\\), gives at least as high expected\nutility to the first than to the second, and at least one possible\nchance function, conditional on \\(E\\) gives strictly higher expected\nutility to the first than to the second:\n\n\nUndominated Chance Dominance If one option is\nstrongly chance dominated by an alternative in the presence of your\ntotal evidence, and that alternative is not weakly chance dominated by\nanything in the presence of your total evidence, then rationality\nrequires you not to choose the first. \n\n\nAnd then we appeal to the following corollary of the\n Chance Dominance Theorem for the General Chance-Credence Norm,\n which we state below, to derive the\n Principal Principle:\n\n\nChance Dominance Corollary for the Principal\nPrinciple Suppose your epistemic utility function is\ncontinuous and strictly proper. And suppose no possible chance\nfunction is modest in the presence of your evidence. Then:\n\nIf a credence function does not satisfy Probabilism + Principal\nPrinciple, there is an alternative credence function that does satisfy\nProbabilism + Principal Principle such that the latter strongly chance\ndominates the former in the presence of your total evidence;\nIf a credence function does satisfy Probabilism + Principal\nPrinciple, there is no alternative credence function that even weakly\nchance dominates it in the presence of your total evidence.\n\n\n\nSo, we have:\n\n\nContinuity\n +\n Strict Propriety\n (for epistemic utility functions)\n\nUndominated Chance Dominance\n\nTherefore,\n\nProbabilism\n +\n Principal Principle\n\n\nNow, this argument does not fully justify the Principal Principle. A\nfull justification would also justify Undominated Chance Dominance by\nexplaining why chances are so special that rationality requires us to\nreject an option when the possible chance functions unanimously reject\nit. But what the justification does tell us is how we should respond\nrationally to this deference we owe to the chances. After all, there\nare alternative ways we might respond: we might say, for instance,\nthat your credence in \\(X\\) conditional on the chance of \\(X\\) being\ngreater than the chance of \\(Y\\) should be greater than your credence\nin \\(Y\\) conditional on that same chance fact. So the argument does\ngive us something.\n\nSo far, we\u2019ve assumed that chances are not modest. But in fact\nwe can still say something if they are. To state the next result, we\nneed to introduce a little terminology:\n\n a set of credence functions is convex if, whenever two\ncredences functions are in it, so is any\n mixture\n of them;\n a set of credence functions is closed if, whenever there\nis an infinite sequence of credence functions in it and they approach\narbitrarily close to another credence function in the limit, then the\ncredence function they approach is also in the set;\n the closed convex hull of a set of credence functions is\nthe smallest closed and convex set that contains it; that is, for any\nother set of credence functions that is closed and convex and contains\nthat set, the closed convex hull is a subset of it.\n\n\n\nChance Dominance Theorem for Chance-Credence Norms (Pettigrew\n2022, Nielsen 2022) Suppose your epistemic utility function\nis continuous and strictly proper. Then:\n\nIf your credence function does not lie in the closed convex hull\nof the set of possible chance functions conditional on your evidence,\nthen there is an alternative credence function that does lie in that\nclosed convex hull such that the latter strongly chance dominates the\nformer;\nIf your credence function does lie in the closed convex hull of\nthe set of possible chance functions conditional on your evidence,\nthen there is no alternative credence function that weakly chance\ndominates it.\n\n\n\nSee the\n supplementary materials\nfor a sketch of how the proof of (i) follows from the Dominance\nTheorem for Convex Hulls.\n\nTogether with Continuity + Strict Propriety (for epistemic utility\nfunctions) and Undominated Chance Dominance, this tells us that\nrationality requires us to have a credence function that lies in the\nclosed convex hull of the possible chance functions. Now of course\nthat isn\u2019t a terribly intuitive condition. However, for various\nproperties weaker than immodesty that chance functions might all have,\nthis does entail that your credence function should also have that\nproperty as well: all that is required is that, whenever two credence\nfunctions have the property, any\n mixture\n of them does as well. Here are two such properties:\n\n \\(C\\) is chance expectational in the presence of \\(E\\)\nif, for all \\(X\\) in \\(\\mathcal{F}\\), \n\\[\nC(X) = \\sum_{ch} C(\\rho_{ch})ch(X \\mid E)\n\\]\n \n \\(C\\) trusts the chances in the presence of \\(E\\) if,\nfor all \\(X\\) in \\(\\mathcal{F}\\), \n\\[\nC(X \\mid ch(X \\mid E) \\geq x) \\geq x\n\\]\n \n\n\nBoth are preserved under taking\n mixtures\n and so the Chance Dominance Theorem for Chance-Credence Norms gives\narguments for the following two chance-credence principles, if the\nchances have the appropriate properties:\n\n General Recipe (Ismael 2008) Rationality\nrequires you to have a credence function that is chance expectational\nin the presence of your total evidence.\n Chance Trust Principle (Levinstein 2023)\nRationality requires you to trust the chances in the presence of your\ntotal evidence.\n\n\nHowever, Levinstein and Spencer (ms.) argue that the sort of Humean\naccount of chance that posits modest chance functions will also posit\nchance functions that are neither chance-expectational nor trusting of\nthemselves as chances. So, for such accounts, these arguments for the\nweaker chance-credence principles will not work.\n\nLevinstein (2023) offers a different epistemic utility argument for\nthe Chance Trust Principle. Undominated Chance Dominance is intended\nto capture the claim that rationality requires us to defer to the\nchances, and proposes a precise formulation of that demand. Levinstein\noffers a different formulation. To defer to the chances epistemically\nis to expect them to have greater expected epistemic utility than you\nexpect yourself to have (unless you are certain your credences match\nthe chances, in which case you expect them to have exactly as much\nepistemic utility as you expect yourself to have). And, what\u2019s\nmore, you expect this regardless of the epistemic utility function you\nuse: provided it satisfies\n Additivity,\n Continuity, and\n Strict Propriety,\n if you\u2019re uncertain what the chances are, you should expect\nthem to do better than you expect your own credences to do. And,\nLevinstein shows, if you do defer in this way, then you satisfy the\nChance Trust Principle.\n5.4 Epistemic utility arguments for Conditionalization\n\nSo far, we have been concerned with the so-called synchronic norms of\ncredence, that is, those that govern your credences at a particular\ntime. In this section, we turn to what are at least apparently\ndiachronic norms, that is, those that govern the relationship between\nyour credences at different times. The most well-known such norm is\nConditionalization, or Bayes\u2019 Rule, which roughly tells you how\nyou should update your credences upon receiving some new evidence,\nwhen that new evidence comes in the form of a proposition learned with\ncertainty.\n\n\nDiachronic Conditionalization Suppose \\(C\\) is your\ncredence function at an earlier time \\(t\\) and \\(C'\\) is your credence\nfunction at a later time \\(t'\\) and suppose that, between \\(t\\) and\n\\(t'\\) the strongest proposition you learn is \\(E\\), then rationality\nrequires that, if \\(C(E) \\gt 0\\), then for all \\(X\\) in\n\\(\\mathcal{F}\\), \n\\[\nC'(X) = C(X \\mid E) = \\frac{C(X\\ \\& \\ E)}{C(E)}\n\\]\n That is, at the later time, your\nunconditional credence in a proposition should be equal to your\nearlier credence in it conditional on the strongest proposition you\nlearned in the interim. If it is, we say that your posterior is\nobtained from your prior by conditioning on your new evidence. \n\n\nIn fact, however, the original epistemic utility arguments in this\narea did not attempt to establish Diachronic Conditionalization\ndirectly. Rather, they attempted to establish that, when you know at\nthe earlier time that the evidence you\u2019ll receive will come from\na particular partition, then you should plan to update as Diachronic\nConditionalization demands. There are in fact two versions of the\nresulting norm, depending on the scope of the rationality operator\n(Greaves & Wallace 2006; Briggs & Pettigrew 2020).\n\n\nPartitional Plan Conditionalization (narrow scope)\nIf\n\n\\(C\\) is your credence function at an earlier time \\(t\\),\nthe propositions \\(E_1, \\ldots, E_n\\) form a partition,\nbetween \\(t\\) and \\(t'\\), you\u2019ll learn which \\(E_i\\) is\ntrue, and nothing more,\nyou plan to update as follows: if you learn \\(E_i\\), then\nyou\u2019ll adopt \\(R_{E_i}\\) as your credence function at\n\\(t'\\),\n\n\nthen rationality requires that, if \\(C(E_i) \\gt 0\\), then for all\n\\(X\\) in \\(\\mathcal{F}\\), \n\\[\n R_{E_i}(X) = C(X \\mid E_i) = \\frac{C(X\\ \\& \\ E_i)}{C(E_i)}\n\\]\n\n\n\nThis says that, if \\(C\\) is your prior, rationality requires you to\nplan to update upon receipt of new evidence by conditioning \\(C\\) on\nthat evidence.\n\n\nPartitional Plan Conditionalization (wide scope)\nRationality requires that: if\n\n\\(C\\) is your credence function at an earlier time \\(t\\),\nthe propositions \\(E_1, \\ldots, E_n\\) form a partition,\nbetween \\(t\\) and \\(t'\\), you\u2019ll learn which \\(E_i\\) is\ntrue, and nothing more,\n you plan to update as follows: if you learn \\(E_i\\), then\nyou\u2019ll adopt \\(R_{E_i}\\) as your credence function at\n\\(t'\\),\n\n\nthen, if \\(C(E_i) \\gt 0\\), then for all \\(X\\) in \\(\\mathcal{F}\\),\n\n\\[\n R_{E_i}(X) = C(X \\mid E_i) = \\frac{C(X\\ \\& \\ E_i)}{C(E_i)}\n\\]\n\n\n\nThis says that rationality requires you not to have prior \\(C\\) and\nyet plan to update upon receipt of new evidence in some way other than\nby conditioning \\(C\\) on that new evidence.\n5.4.1 Epistemic utility arguments for Partitional Plan Conditionalization\n\nWe begin with arguments for Partitional Plan Conditionalization.\n\nThe first is due to Hilary Greaves and David Wallace (2008), building\non techniques from Peter M. Brown (1976) and Graham Oddie (1997). Some\nterminology:\n\n An updating plan is a function from states of the world\nto credence functions.\n An updating plan is available if it takes the same\nvalues at any two worlds at which your evidence will be the same.\n An updating plan is a conditionalizing plan for a prior\ncredence function if, whenever you give positive credence to the\nevidence you\u2019ll learn at a world, the plan tells you to update\nat that world by conditioning the prior on that evidence.\n\n\n\nExpectation Theorem for Partitional Plan Conditionalization\n(narrow scope) (Greaves & Wallace 2008) Suppose your\nepistemic utility function is strictly proper, and suppose your\nevidence will tell you which member of a particular partition is true.\nThen the updating plans that maximize expected epistemic utility from\nthe point of view of your prior credence function among those\navailable are exactly the conditionalizing plans for that prior.\n\n\nI sketch the proof in the\n supplementary materials.\n\nSo, we have:\n\n\nStrict Propriety\n\n\nMaximize Expected Utility\n\nTherefore,\n\nPartitional Plan Conditionalization (narrow scope)\n\n\n\nBy asking about local updating plans, which say not which credence\nfunction you plan to adopt upon receiving new evidence, but just what\ncredence you plan to assign to a particular proposition, Kenny\nEaswaran (2013) extends this argument to establish a version of van\nFraassen\u2019s (1999) Reflection Principle and a norm known as\nConglomerability, which says that your unconditional credence in a\nproposition should lie in the range spanned by your conditional\ncredences in it given different elements of a partition.\n\nMaximize Expected Utility is a well-known norm of decision theory, but\nit is not universally accepted. Some decision theorists think that it\nis rationally permissible to take risk into account in ways that\nexpected utility theory rules out. Building on a proposal by John\nQuiggin (1982), Lara Buchak (2013) has provided a popular alternative\nnorm, Maximize Risk-Weighted Expected Utility, which allows you to\ntake risk into account. Catrin Campbell-Moore and Bernhard Salow\n(2022) have explored an analogue of Greaves and Wallace\u2019s\nargument that replaces Strict Propriety with its appropriately\nrisk-sensitive analogue and replaces Maximize Expected Utility with\nBuchak\u2019s risk-sensitive version. They show that these do not\nentail Partitional Plan Conditionalization, but rather an alternative\nupdating norm.\n\nThe second argument for Partitional Plan Conditionalization is due to\nRay Briggs and Richard Pettigrew (2020), with an improvement by\nMichael Nielsen (2021). They show that, assuming Additivity +\nContinuity + Strict Propriety, if you look not only at the epistemic\nutility of your updating plan, but at the sum of the epistemic utility\nof your prior and the epistemic utility of your updating plan, then if\nyou violate Partitional Plan Conditionalization (wide scope), there is\nan alternative prior and updating plan you might have had instead that\ndominates yours.\n\n\nDominance Theorem for Partitional Plan Conditionalization\n(wide scope) (Briggs & Pettigrew 2020; Nielsen 2021)\nSuppose your epistemic utility function is additive, continuous, and\nstrictly proper measure. Then:\n\n If your updating plan is available but it is not a\nconditionalizing plan for your prior, then there is an alternative\nprior and alternative available updating plan such that, at every\nstate of the world, the sum of the epistemic utility of your prior and\nthe epistemic utility of your updating plan is less than the sum of\nthe epistemic utility of the alternative prior and the epistemic\nutility of the alternative updating plan.\n If your updating plan is a conditionalizing plan for your prior,\nthen there is no alternative prior and alternative updating plan such\nthat, at every state of the world, the sum of the epistemic utility of\nyour prior and the epistemic utility of your updating plan is less\nthan the sum of the epistemic utility of the alternative prior and the\nepistemic utility of the alternative updating plan.\n\n\n\nI sketch the proof in the\n supplementary materials.\n\nSo, we have:\n\n\nAdditivity\n +\n Continuity\n +\n Strict Propriety\n (for epistemic utility functions)\n\nUndominated Dominance\n\n\nTherefore,\n\nPartitional Plan Conditionalization (wide scope)\n\n5.4.2 Epistemic utility arguments for Diachronic Conditionalization\n\nWe turn now to two arguments for\n Diachronic Conditionalization.\n Both take the same approach. You begin with your prior credence\nfunction at the earlier time. Between the earlier and later time you\nlearn a proposition with certainty. Then, at the later time, you use\nyour prior credence function to decide what your new posterior\ncredence function should be. They differ in how they think that\ndecision should be made.\n\nAccording to Hannes Leitgeb and Richard Pettigrew (2010), you should\npick the posterior credence function that maximizes expected epistemic\nutility from the point of view of your prior credence function, but\nwhere the expectation is taken over only those worlds at which the\nevidence is true. If your epistemic utility function is strictly\nproper, and if your prior assigns positive credence to the proposition\nyou learn, then the unique posterior credence function that maximizes\nthis is the one demanded by\n Diachronic Conditionalization.\n\nCampbell-Moore and Salow (2022) also consider an analogue of this\nargument in the case of Buchak\u2019s risk-sensitive decision theory\nand they show that, in this case, it does establish\n Diachronic Conditionalization.\n\nAccording to Dmitri Gallow (2019), on the other hand, you should\nmaximize epistemic utility in the usual way, where the expectation is\ntaken over all worlds, but you should change the epistemic utility\nfunction you use, so that it assigns the same neutral value to every\ncredence function at every world at which the evidence you\u2019ve\nlearned is false. Again it turns out that, if the epistemic utility\nfunction you begin with is strictly proper, and if your prior assigns\npositive credence to the proposition you learn, the credence function\nthat maximizes this is the one demanded by\n Diachronic Conditionalization.\n5.4.3 Other updating situations\n\nThe updating norms we have considered so far and the arguments in\ntheir favor make a number of assumptions. First, they assume that your\nevidence will come in the form of a proposition learned with\ncertainty\u2014we might call this assumption Certainty.\nSecond, they assume that proposition will be true\u2014we might call\nthis assumption Factivity. Third, they assume that\nproposition will come from a partition that can be specified in\nadvance\u2014we might call this Partitionality. We'll treat\nthese three in turn.\n\nFirst, Certainty. Richard Jeffrey (1965) points out that our evidence\noften doesn\u2019t come in the form of a proposition learned with\ncertainty, because there is often no proposition in our agenda that\nperfectly captures what we learn. In such cases, he suggests, the\nevidence places specific constraints on our posterior credences. He\nconsiders the case in which it specifies which posterior credences you\nmust have in the propositions in a particular partition, and he\nformulated a rule, known as Probability Kinematics or Jeffrey\nConditionalization, which tells you how to set your posterior\ncredences in other propositions that lie outside that partition.\nInspired by a suggestion by Diaconis and Zabell (1982), Leitgeb and\nPettigrew (2010) argue that, when your evidence places constraints on\nyour posterior credence function, you should update by adopting\nwhichever credence function maximizes expected epistemic utility from\nthe point of view of your prior credence function among those\ncredence functions that satisfy the constraint. Leitgeb and\nPettigrew show that the\n Brier score\n gives a different updating rule from the one that Jeffrey proposed.\nLevinstein (2012) argues that this is a reason to reject the Brier\nscore, and Pettigrew (Theorem 12, Section 8.5, 2021) shows that no\nadditive strictly proper scoring rule gives Jeffrey\u2019s rule via\nthis approach.\n\nJason Konek (2022) offers an alternative approach to the situations\nthat Jeffrey identified. He notes that, while there might be no\nproposition in the agenda of your prior credence function that you\ncome to learn with certainty, there is a proposition that expresses\nyour experience, and you become able to entertain it when you have the\nlearning experience, because you can simply point to the learning\nexperience and say \u2018I learned that\u2019. So, after the\nlearning experience, you can add this proposition to your agenda and\nretrospectively set your conditional credences in having that learning\nexperience, given different ways the world might be; and that is\nsufficient to allow you to set your new credences given that you did\nhave that learning experience. He provides an epistemic utility\nargument for a particular way of doing this.\n\nSecond, Factivity. There are two ways to approach this, but the second\nis also the way to approach Partitionality, so we\u2019ll leave that\nfor the moment. The first approach is suggested by Michael Rescorla\n(2022), who asks not what you should plan to do when you learn which\nproposition from a particular partition is true, but what you should\nplan to do when you become certain of a proposition in a partition,\nleaving open whether the proposition of which you\u2019ll become\ncertain will be true. Pettigrew (2023) shows that you should plan to\nupdate by conditioning on what you learned with certainty by giving a\ndominance argument for the following norm, due to Bas van Fraassen\n(1999) (see also (Staffel & de Bona forthcoming)):\n\n\nWeak General Reflection Principle Rationality\nrequires that your prior credence function should be a\n mixture\n of your possible future credence functions. \n Pettigrew proves the following theorem:\n\n\n\nDominance Theorem for Weak General Reflection (Pettigrew\n2023) Suppose your epistemic utility function is additive,\ncontinuous, and strictly proper measure. Then:\n\n If your prior credence function is not a\n mixture\n of your possible posterior credence functions, then there is an\nalternative prior and, for each possible posterior credence function,\nan alternative posterior such that, at every state of the world and\nfor every possible posterior, the sum of the epistemic utility of your\nprior and the epistemic utility of that posterior is less than the sum\nof the epistemic utility of the alternative prior and the epistemic\nutility of the alternative posterior.\n If your prior credence function is a\n mixture\n of your possible posterior credence functions, then there is no\nalternative prior and, for each possible posterior credence function,\nan alternative posterior such that, at every state of the world and\nfor every possible posterior, the sum of the epistemic utility of your\nprior and the epistemic utility of that posterior is less than the sum\nof the epistemic utility of the alternative prior and the epistemic\nutility of the alternative posterior.\n\n\n\nAs van Fraassen (1999) shows, if we assume that (i) for each element\nof a given partition, there is a unique possible posterior that is\ncertain of it, and (ii) for each possible posterior, there is a unique\nelement of the partition of which it is certain, then the Weak General\nReflection Principle entails that each possible posterior is obtained\nfrom your prior by conditioning on the relevant element of the\npartition.\n\nThird, Partitionality. To represent situations in which your evidence\ndoes come in the form of a proposition learned with certainty, but in\nwhich we assume neither that the proposition is true nor that it comes\nfrom a partition that can be specified in advance, we follow Nilanjan\nDas (2023) in defining an evidence function to be a function\nthat takes a state of the world and returns the proposition\nyou\u2019ll learn with certainty at that state of the world. As\nbefore, an updating plan takes a state of the world to the posterior\nyou plan to adopt when you learn the evidence you\u2019ll receive at\nthat state of the world; and, as before, an updating plan is available\nif it gives the same recommendation for any two states of the world at\nwhich you receive the same evidence. Then Miriam Schoenfield (2016)\nshows that you maximize expected epistemic utility not by planning to\nconditionalize on your evidence, but by planning to conditionalize on\nthe fact that you received that evidence. Gallow (2021) worries that\nthe plans Schoenfield considers available are not genuinely available\nto individuals in situations in which their evidence fails to rule out\nthat their evidence is different from how it actually is, and he\nsuggests a framework in which to represent genuinely available plans\nand describes the updating plan that maximizes expected epistemic\nutility in that framework.\n5.4.4 Updating in social situations\n\nSo far, we have only considered an individual\u2019s credences and\ntheir relationship to one another. But we also learn from others who\ninvestigate the world and share the credences they come to have on\nthat basis. So our epistemic situation affects and is affected by the\nepistemic situation of others. Igor Douven and Sylvia Wenmackers\n(2017) have explored a situation like this. They ask whether epistemic\nutility considerations make different demands for updating from those\nthey make in the individual case. They suppose that the members of a\ngroup all begin with the same prior credence function. Each holds a\ncoin and all the coins have the same bias towards landing heads, but\nthey are uncertain what that bias is to begin with. Each individual\ntosses their coin some number of times and updates their own credences\non the basis of what they observe; then they share their evidence with\nsome of the other members of the group; then they repeat this process\na number of times. After each iteration, we measure their epistemic\nutility, and then we look at the expected average epistemic utility\nacross all members and all times in the process. Douven and Wenmackers\ntreat updating on the private evidence from your own coin tosses and\nupdating on public evidence from the credences of others differently.\nThey assume each member updates on the public evidence of\nothers\u2019 credences by taking the average (arithmetic mean) of\ntheir credences and those of the other members. And then they ask\nwhich updating rule for the private evidence will lead to the greatest\nexpected average epistemic utility, and they use computer simulation\nto show that it is not Bayesian conditionalization. Indeed, they show\nthat an updating rule introduced by van Fraassen (Chapter 6, 1989) to\ngive a crude model of inference to the best explanation outperforms\nBayesian conditionalization (though we don\u2019t know whether some\nother rule outperforms that). However as Pettigrew (2021b) points out,\nthis only shows that, when you update on the evidence of your peers by\ntaking averages, rather than by conditionalizing on it, you should\ncompensate for the suboptimality of that choice by doing something\nother than conditionalizing on your private evidence. But of course\nthe results we\u2019ve considered in this section say you\nshouldn\u2019t do that. You should update on the evidence of your\npeers and the evidence of your private coin tosses as you should\nupdate on everything, namely, by conditionalizing. \n5.4.4 The epistemology of inquiry\n\nAs we saw above, when Greaves and Wallace argue for Partitional Plan\nConditionalization (narrow scope), they hold fixed the partition from\nwhich our evidence will come and ask which updating plan maximizes\nexpected epistemic utility. However, we don\u2019t simply receive\nevidence passively. We also go out and seek it, and in those cases we\nhave to pick from which partition we want our evidence to come: Should\nthe scientist perform this experiment or another? Should the detective\ninterview this suspect or that? Adapting an insight due to I. J. Good\n(1967) to the epistemic setting, Wayne Myrvold (2012) and Alejandro\nP\u00e9rez Carballo (2018) show that we can use epistemic utilities\nto tell which evidence we should collect from the epistemic point of\nview.\n\nGiven a partition, we know that an updating plan that maximizes\nexpected epistemic utility is a conditionalizing plan. So let\u2019s\nhold fixed that, for any given partition, we plan to condition on\nwhichever proposition in it we learn with certainty. And now suppose\nthere are two partitions, and we must choose which one to investigate;\nthat is, we must choose from which one our evidence will come, always\nassuming that, whichever we choose, we\u2019ll respond to the\nevidence we receive by conditioning on it. Then we can simply compare\nthe expected epistemic utility of conditioning on whichever element of\nthe first partition we learn and the expected epistemic utility of\nconditioning on whichever element of the second partition we learn,\nand then do whichever is greater. One result is that, if one partition\nis a fine-graining of the other, so that each proposition in the\nlatter is a disjunction of propositions in the former, we should\nalways choose the finer-grained one.\n\nAs well as providing epistemic norms for choosing between the\npartitions we might investigate, epistemic utilities can also give\nnorms for when to investigate at all and when to consider an issue\nsettled for the time being. To obtain these norms, we simply treat the\noption of conducting no further investigations as the case in which we\ninvestigate the trivial partition that consists only of a tautology.\nIf our epistemic utility function is strictly proper, and if you\nassign any probability to investigating a given partition changing\nyour credences, then investigating must have greater expected\nepistemic utility than not investigating, giving a epistemic analogue\nto Good\u2019s value of information theorem (Good 1967; Myrvold\n2012). But of course such investigations are not cost-free, and so the\nquestion will always arise whether the cost is worth it for the\nexpected epistemic gain.\n\nCampbell-Moore and Salow (2020) show that, for risk-sensitive\nindividuals, investigating isn\u2019t always demanded, even when\nit\u2019s free. It has long been known that such individuals are\nsometimes pragmatically required not to investigate; Campbell-Moore\nand Salow show that they are also sometimes epistemically required not\nto.\n\nSo epistemic utilities give epistemic norms that govern our choices\nbetween different inquiries and our choice whether to investigate at\nall, at least when other aspects are equal. But of course, things are\nrarely equal. There are also pragmatic reasons for investigating one\npartition rather than other, and so some reasons for inquiry are\npragmatic: for instance, investigating one partition might have\ngreater expected epistemic utility than investigating another, but it\nmight be more costly, or it might not help as much to inform a\npressing decision we must soon make. But Myrvold\u2019s and\nP\u00e9rez Carballo\u2019s approach does at least tell us the\nepistemic value of an investigation at a state of the world, which can\nthen be weighted against its pragmatic value and perhaps also moral\nvalue to give the all-things-considered verdict on what to do.\nFurthermore, this approach shows that there can be purely epistemic\nreasons for gathering evidence for a particular investigation,\nanswering a question that has been raised in the literature on the\nepistemology of inquiry (e.g. Woodard & Flores forthcoming). And\nFilippo Vindrola and Vincenzo Crupi (forthcoming) have recently\napplied the approach to the Wason Selection Task to vindicate\nWason\u2019s original contention that people tend to choose how to\ninvestigate irrationally in that case.\n5.5 Epistemic utility arguments for and against the Uniqueness Thesis\n\nIn this section, we consider epistemic utility arguments for and\nagainst the\n Uniqueness Thesis\n about credences. Recall that this says that, for any body of evidence\nand any agenda, there is a unique credence function on that agenda\nthat it is rational for an individual with that total evidence to\nhave. And recall that epistemic permissivism about credences is the\nnegation of this claim. There are three sorts of argument. The first\nappeals to norms of decision theory that encode attitudes to risk to\nanswer questions about which prior credence functions are rationally\npermissible. The second appeals to the notions of probabilistic\nknowledge and epistemic luck. The third appeals to the value of\nrationality.\n5.5.1 Epistemic risk and the Uniqueness Thesis\n\nMinimax (sometimes called Maximin) is the most well-known norm of\ndecision theory that encodes an attitude to risk (Wald 1945). This\nsays that you should pick an option that minimizes your\nworst-case or maximal disutility (equivalently, you should\npick an option that maximizes your worst-case or\nminimal utility). If we say that someone is more risk-averse\nthe more weight they give to worst-case scenarios in their\ndecision-making and the less they give to best-case scenarios, Minimax\nis maximally risk-averse.\n\nPettigrew (2016) proves that, if we assume your agenda is an algebra\nand our epistemic utility function is extensional and strictly proper,\nthen Minimax entails the Principle of Indifference:\n\n\nPrinciple of Indifference Rationality requires that\nyou assign the same credence to every possible state of the world.\n\n\nGiven an agenda, Probabilism and the Principle of Indifference pick\nout a unique prior credence function, namely, the uniform credence\nfunction, \\(c^\\dag\\), where \\(c^\\dag(w) = \\frac{1}{n}\\), for all \\(w\\)\nin \\(\\mathcal{W}\\), and \\(n\\) is the number of worlds in\n\\(\\mathcal{W}\\).\n\nHowever, Minimax is often thought too extreme. It might be rationally\npermissible to be risk-averse, but it is not rationally permissible to\nplace all of your weight on the worst-case scenario and pay\nno attention to anything else: you would surely prefer an\noption that pays \u00a31 if the number of stars is even and\n\u00a31,000,000 if it\u2019s odd to an option that pays \u00a32\neither way, and yet Minimax rules out the first.\n\nAlternative risk-sensitive norms of decision theory have been\nproposed. Pettigrew considers the Hurwicz Criterion (Hurwicz 1952;\nPettigrew 2016) and formulates the Generalized Hurwicz Criterion\n(Pettigrew 2022). In the former, you consider not only the worst-case\nscenario but also the best, and you assign a weight to each to give\nthe Hurwicz score. He shows that, if we are permissive enough about\nthe weightings, we obtain permissivism about rational priors. In the\nlatter, we give weights to all scenarios, best, second-best, and so on\ndown to second-worst, worst; and that gives us the generalized Hurwicz\nscore. Again, if we are permissive enough about weightings, we obtain\nan even broader permissivism about priors. \n5.5.2 Epistemic luck, probabilistic knowledge, and the Uniqueness Thesis\n\nJason Konek (2017) argues for a norm that\u2019s slightly weaker than\nthe Uniqueness Thesis. He appeals not to best and worst cases but to\nbest and worst expectations by the lights of different possible chance\nfunctions. He is not so interested in what they think of the prior you\npick, but what they think of the possible posteriors you might obtain\nfrom the prior when you learn new information. He thinks you should\npick a prior so that the difference between the maximum expected\nepistemic utility of your posterior and the minimum is minimized: he\ncalls this principle MaxSen.\n\nWhy do this? Because, Konek argues, this gives you the best chance of\nforming credences that constitute probabilistic knowledge of the sort\nSarah Moss (2018) has described. One putative necessary condition on\nknowledge is that the success you have forming an accurate belief or\ncredence is due to your own ability, rather than to luck. Konek argues\nthat, if you pick the prior he recommends, whatever accuracy you\nobtain after you learn the new evidence and update accordingly is due\nto your own cognitive ability as much as possible and to luck as\nlittle as possible. The relationship of Konek\u2019s MaxSen to the\n Uniqueness Thesis\n is a bit subtle. For someone with no evidence, a fixed agenda, and a\npartition from which their future evidence will come, there is a\nunique credence function it demands; but which it demands does depend\non the partition from which the future evidence will come, and the\n Uniqueness Thesis\n does not strictly permit that.\n5.5.3 Propriety, epistemic permissivism, and the Uniqueness Thesis\n\nSophie Horowitz (2019) appeals to epistemic utility theory to raise\ntwo problems for epistemic permissivism.\n\nFirst, take a\n strictly proper\n epistemic utility function. Then, Horowitz points out, whichever set\nof prior credence functions the epistemic permissivist takes to be\nrationally permissible, for many of those permissible credence\nfunctions, there will be impermissible ones they expect to have\ngreater epistemic utility than many of the other permissible ones. For\ninstance, perhaps rationality doesn\u2019t require that your prior\ncredence in a proposition is a particular number, but it does require\nthat it lies within a certain range\u2014say, between 0.3 and 0.6.\nThen, if your credence is near one end of this range but still within\nit (say, 0.31), then it is rationally permitted, but it will expect\nsomething a little beyond that end of the range (say, 0.29), which is\nthereby not rationally permitted, to have greater epistemic utility\nthan something within the range, and therefore rationally permitted,\nbut at the other end (say, 0.59).\n\nSecond, Horowitz notes that, if our epistemic utility function is\nstrictly proper, then each permissible credence function expects\nitself to be best. And this causes problems for what Horowitz calls\n\u201cacknowledged permissive cases\u201d. These are cases in which\nrationality is permissive, and moreover the individual knows this is\nso. In such cases, they adopt their particular prior, and they know\nthat this prior is merely one among many rationally permissible\npriors; but, because our epistemic utility function is strictly\nproper, they expect it to have greater epistemic utility than any\nalternative, including the alternatives they take to be rationally\npermissible. So, Horowitz asks, in what sense do they really consider\nthose alternatives permissible? Horowitz considers a response by\nMiriam Schoenfield (2014) and finds it wanting.\n5.6 Epistemic utility arguments in social epistemology\n\nSo far, we have considered only norms that govern an\nindividual\u2019s credences. But many epistemological questions arise\nwhen we consider groups of individuals and their interactions. Here\nare two such questions for which we have epistemic utility arguments:\nDoes the group itself have a credence function, just as its individual\nmembers do, and if so how does relate to the credence functions of the\nmembers?\n (Section 5.6.1)\n How do we maximize the total epistemic utility across the group, and\ndoes this place constraints on the individuals?\n (Section 5.6.2).\n5.6.1 The epistemic utility of group credences\n\nIn everyday talk, we often ascribe beliefs and credences to groups of\nindividuals as well as to their members: the Intergovernmental Panel\non Climate Change is 70% confident in such-and-such; the\nparliamentary subcommittee believes so-and-so. And we often think that\nthe credences of the individuals at least partly determine the\ncredences of the group. So suppose I must come up with precise\ncredences to ascribe to a group of individuals. The literature on\nprobabilistic judgment aggregation or opinion pooling offers a range\nof possibilities. For instance:\n\n\nLinear Pooling A group\u2019s credence function\nshould be a\n mixture\n of the members\u2019 credence functions.\n\n\nSarah Moss (2011) offers an epistemic utility argument for Linear\nPooling. She says that the group\u2019s credence function should be\nthe one that maximizes the group\u2019s expected epistemic utility,\nand she defines the group\u2019s expected epistemic utility to be a\nweighted arithmetic mean of the members\u2019 individual expected\nepistemic utilities. And then she proves that, providing our epistemic\nutility function is strictly proper, it is the mixture of the\nmembers\u2019 credence functions with these same weights that\nmaximizes this quantity.\n\nOne concern about this argument is that it assumes something too close\nto what it attempts to establish. It assumes that the members\u2019\nindividual expectations should be combined by weighted\narithmetic averaging and attempts to show that members\u2019\nindividual credence functions should be so combined.\nPettigrew (2017) offers a related argument that improves on\nMoss\u2019s in some ways, though makes very slightly stronger\nassumptions. The idea is that, whatever the group\u2019s credence\nfunction is, there had better not be an alternative that every member\nof the group expects to be better, epistemically speaking. He then\nshows that, if your epistemic utility function is continuous and\nstrictly proper, and if the group\u2019s credence function is not a\nmixture of the individuals\u2019 credence functions, then there is\nsuch an alternative. \n5.6.2 Maximizing total epistemic utility across the group's members\n\nAs well as asking about the epistemic utility of the group\u2019s\ncredences, we can also ask about the total accuracy of the\nmembers\u2019 credences. And this gives an argument for a\nsurprisingly strong norm (Kopec 2012):\n\n\nConsensus Rationality requires that all members of a\ngroup have the same credence function.\n\n\nThe argument is based on the fact that, if a group violates Consensus,\nso that at least two members disagree about some of their credences,\nthen there is a single credence function such that, if all members of\nthe group were to have it, their total epistemic utility would be\ngreater for sure.\n\nWe should take this argument with a pinch of salt. After all, one\nthing that people do is to investigate the world and collect evidence\nand then share their findings. They decide which evidence to collect\nby consulting their credences and asking which will maximize expected\nepistemic or pragmatic utility, as we saw in\n Section 5.3.4.\n And so the individuals in a group that satisfies Consensus will\nconduct the same sorts of investigations and acquire similar evidence,\nwhile a group with more diverse credences will conduct more diverse\ninvestigations and end up with more diverse evidence. And it might\nwell be that the benefits a group gets in the long run from collecting\ndiverse evidence might outweigh the disadvantage they get from lacking\nconsensus at the start (Zollman 2010).\n6. Comparative confidence\n\nIn the comparative confidence model, we represent an\nindividual\u2019s epistemic state by their comparative confidence\nordering, which is an ordering or binary relation \\(\\prec, \\sim\\)\non their agenda. For any two propositions, \\(X\\) and \\(Y\\) in their\nagenda, we say \\(X \\prec Y\\) if they are less confident in \\(X\\) than\nin \\(Y\\) and we say \\(X \\sim Y\\) if they are exactly as confident in\n\\(X\\) as in \\(Y\\).\n\nOur first job is to say how to measure the epistemic utility of such\nan ordering. Fitelson and McCarthy (2014) suggest the following. A\ncomparative confidence ordering is a set of pairwise comparisons.\nFitelson and McCarthy assume that it is complete, so that, for any\n\\(X\\), \\(Y\\) in the individual\u2019s agenda, \\(X \\prec Y\\) or \\(X\n\\sim Y\\) or \\(Y \\prec X\\). So we first say how to score these\nindividual comparisons:  \n\\[\n\\begin{array}{c|c||c|c}\nX & Y & X \\prec Y & X \\sim Y \\\\\n\\hline\nT & T & \\alpha & 1 \\\\\nT & F & \\beta & \\gamma \\\\\nF & T & 1 & \\gamma \\\\\nF & F & \\alpha & 1\n\\end{array}\n\\]\n\n\nThe idea is that, if \\(X \\prec Y\\) and \\(X\\) is false and \\(Y\\) is\ntrue, then you\u2019ve ordered the propositions as the omniscient\nagent would, so you get maximal epistemic utility, which we\u2019ll\ntake to be 1; and similarly if \\(X \\sim Y\\) and \\(X\\) and \\(Y\\) have\nthe same truth value. Then there are three potential mistakes whose\nscore we need to determine, and we've marked those scores as \\(\\alpha,\n\\beta, \\gamma\\).\n\nNow, we could simply permit any different values for these, but\nFitelson and McCarthy give an argument that we should set: \\(\\alpha =\n1\\), \\(\\beta = 0\\), \\(\\gamma = 1/2\\) (or any positive linear\ntransformation of these). Only for these scores does Fitelson and\nMcCarthy\u2019s account deliver a strictly proper way of measuring\nepistemic utility, in the following sense:\n\n If \\(C\\) is a probabilistic credence function and \\(C(X) \\lt\nC(Y)\\), then \\(C\\) expects \\(X \\prec Y\\) to be better than \\(X \\sim\nY\\) and to be better than \\(Y \\prec X\\).\n If \\(C\\) is a probabilistic credence function and \\(C(X) =\nC(Y)\\), then \\(C\\) expects \\(X \\sim Y\\) to be better than \\(X \\prec\nY\\) and to be better than \\(Y \\prec X\\).\n\n\nSo the only strictly proper measure of inaccuracy for comparative\nconfidence orderings is this (up to positive linear transformation):\n\n\\[\n\\begin{array}{c|c||c|c}\nX & Y & X \\prec Y & X \\sim Y \\\\\n\\hline\nT & T & 1 & 1 \\\\\nT & F & 0 & 1/2 \\\\\nF & T & 1 & 1/2 \\\\\nF & F & 1 & 1\n\\end{array}\n\\]\n \n\nWe can now ask: for which norms can we provide epistemic utility\narguments using this measure of epistemic utility? Here is one, where\nwe say that one proposition is strictly stronger than another if the\nfirst entails the second, but the second does not entail the first:\n\n\n\nStrict Quasi-Additivity\n\n If \\(X\\) is strictly stronger than \\(Y\\), \\(X\\) and \\(Z\\) are\nmutually exclusive, and \\(Y\\) and \\(Z\\) are mutually exclusive, then\n\\(X \\vee Z \\prec Y \\vee Z\\). \n If \\(X\\) is equivalent to \\(Y\\), \\(X\\) and \\(Z\\) are mutually\nexclusive, and \\(Y\\) and \\(Z\\) are mutually exclusive, then \\(X \\vee Z\n\\sim Y \\vee Z\\). \n\n\n\nFrom this, we can derive a number of further norms:\n\n\nNon-Triviality \\(\\bot \\prec \\top\\), if \\(\\bot\\) is a\ncontradiction and \\(\\top\\) is a tautology.\n\nRegularity \\(\\bot \\prec X \\prec \\top\\), if \\(\\bot\\)\nis a contradiction, \\(\\top\\) is a tautology, and \\(X\\) is\ncontingent.\n\nStrict Monotonicity\n\n If \\(X\\) is strictly stronger than \\(Y\\), then rationality\nrequires that \\(X \\prec Y\\).\n If \\(X\\) is equivalent to \\(Y\\), then rationality requires that\n\\(X \\sim Y\\).\n\n\n\nNow, we have already assumed that the ordering is complete. If we add\nTransitivity to Completeness and Strict Quasi-Additivity, then it is\nguaranteed that there is a particular way to represent this ordering:\nthere is a Dempster-Shafer belief function \\(b\\) on \\(\\mathcal{F}\\)\nsuch that \\(b(X) \\lt b(Y)\\) iff \\(X \\prec Y\\) and \\(b(X) = b(Y)\\) iff\n\\(X \\sim Y\\) (Wong, et al. 1991).\n\nEric Raidl and Wolfgang Spohn (2020) offer a slightly different way of\nmeasuring the accuracy of a comparative confidence ordering and offer\nan argument for the norms of Spohn\u2019s ranking theory (Spohn\n2012).\n7. Imprecise credences\n\nIn the imprecise credence model, we typically represent an\nindividual\u2019s epistemic state not as a single credence function,\nbut as a set of credence functions, and we assume those credence\nfunctions are probabilistic. There are various related\nrepresentations, some of which are more powerful, some less, such as\nupper and lower previsions, sets of desirable gambles, and probability\nfilters. I\u2019ll focus here on sets of probability functions.\n\nThe central result in this area is that there are no measures of\nepistemic utility for imprecise credences that have the property\nanalogous to the property of strict propriety in the precise case.\nThere are three versions of these results, starting with a theorem due\nto Seidenfeld, Schervish, and Kadane (2012), and including adaptations\nby Miriam Schoenfield (2017) and Conor Mayo-Wilson and Gregory Wheeler\n(2016). I'll present Schoenfield\u2019s, since it\u2019s the most\nstraightforward.\n\nSchoenfield considers the simplest sort of case, where our individual\nonly has opinions about a proposition and its negation. And she\nassumes that any measure of epistemic utility for imprecise credences\nhas the following properties:\n\n\nExtension When restricted to precise probabilities\nover those two propositions, the measure of epistemic utility is\nmaximized at the omniscient credence function and it is\ncontinuous.\n\nBoundedness Epistemic utilities are measured by real\nnumbers. \n\nProbabilistic Admissibility For any precise credal\nstate, there is no imprecise credal state that is at least as good as\nthat precise state at all worlds. \n\n\nThen Schoenfield shows that, if Extension, Boundedness, and\nProbabilistic Admissibility hold, then for any imprecise set, there is\na precise probabilistic credence function that has equal epistemic\nutility at every world. This seems problematic, because it suggests\nthat it can never be rationally required to have imprecise credences,\nand their proponents typically think it can be.\n\nJason Konek (2019) has proposed a way to avoid this concern. He argues\nthat, in fact, we should not expect a single measure of epistemic\nutility to work for every situation. The idea is that our measure of\nepistemic utility for imprecise credences encodes not only our\nattitude to accuracy, but also our attitude to epistemic risk, and for\neach legitimate way of measuring epistemic utility, there is a family\nof imprecise credences that are endorsed by it. So all that is really\nrequired is that, for any coherent imprecise credences, there is a\nlegitimate way of measuring epistemic utility that endorses them: that\nis, where they consider themselves best from that point of view.\n8. Future directions\n\nWe have seen that epistemic utility arguments provide a fruitful\napproach to epistemic norms. We conclude in this section by\nhighlighting some possible avenues for future research, though this\nlist is by no means exhaustive:\n\nOne attraction of the epistemic utility approach is that it does\nnot only provide us with a means by which to establish norms that we\nhave already formulated; it also allows provides a process by which to\nformulate new norms governing different situations that we can then\nuse it justify. The recipe is straightforward: specify the situation;\nspecify your measure of epistemic utility; ask what properties an\nepistemic state must have if it is to optimize that measure of\nepistemic utility in that situation. For instance, it is this approach\nthat lead from Joyce\u2019s argument for Probabilism, to Greaves\n& Wallace\u2019s argument for Conditionalization, to\nMyrvold\u2019s approach to the value of learning new evidence.\nIncreasingly, epistemologists are considering less and less idealized\nepistemic situations: situations in which you have evidence, but you\ndon\u2019t know what that evidence is (Williamson 2000); situations\nin which you have higher-order evidence that casts doubt on your\nfirst-order reasoning (Feldman 2005); and so on. The epistemic utility\napproach is ideally situated to help formulate norms to govern these\nnon-ideal situations.\nWhile there is some work on how to choose between different ways\nof measuring epistemic utility, more could be done (Pettigrew 2016,\nLevinstein 2017). What reason do we have for using one strictly proper\nscoring rule rather than another?\nWhile much work on epistemic utility assumes, along with the\nveritist, that the sole fundamental source of epistemic value is truth\nor gradational accuracy, other parts of epistemology talk of further\nor alternative sources, such as explanatory power or being formed by\nan epistemically virtuous process. How would we measure epistemic\nutility if these are among its sources?\nA final, rather obvious suggestion is that there are substantial\nobjections to the approach that must still be addressed. We have met\nmany of them over the course of this survey, from Levinstein\u2019s\nVarying Importance Objection in\n Section 5.1.1\n to the Act-State Dependence worry in\n Section 5.2.3\n to Jennifer Carr\u2019s epistemic expansions concern in\n Section 5.2.4.\n These three, as well as others detailed above, still lack truly\ncompelling responses.\n\n\nThere is still much to be done.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Alchourr\u00f3n, C.E., P. G\u00e4rdenfors, &amp; D. Makinson,\n1985, \u201cOn the Logic of Theory Change: Partial Meet Contraction\nand Revision Functions\u201d, <em>Journal of Symbolic Logic</em>, 50:\n510\u2013530.",
                "Berker, S., 2013a, \u201cEpistemic Teleology and the Separateness\nof Propositions\u201d, <em>Philosophical Review</em>, 122(3):\n337\u2013393.",
                "\u2013\u2013\u2013, 2013b, \u201cThe Rejection of Epistemic\nConsequentialism\u201d, <em>Philosophical Issues (Supp.\nNo\u00fbs)</em>, 23(1): 363\u2013387.",
                "BonJour, L., 1985, <em>The Structure of Empirical Knowledge</em>,\nCambridge, MA: Harvard University Press.",
                "Briggs, R. A. &amp; R. Pettigrew, 2020, \u201cAn\nAccuracy-Dominance Argument for Conditionalization\u201d,\n<em>No\u00fbs</em>, 54(1): 162\u2013181.",
                "Brown, P. M., 1976, \u201cConditionalization and expected\nutility\u201d <em>Philosophy of Science</em>, 43(3):\n415\u2013419.",
                "Buchak, L., 2013, <em>Risk and Rationality</em>, Oxford: Oxford\nUniversity Press.",
                "Caie, M., 2013, \u201cRational Probabilistic Incoherence\u201d,\n<em>Philosophical Review</em>, 122(4): 527\u2013575.",
                "Campbell-Moore, C., 2015, \u201cRational Probabilistic\nIncoherence? A Reply to Michael Caie\u201d, <em>Philosophical\nReview</em> 124(3): 393\u2013406.",
                "\u2013\u2013\u2013, &amp; B. Salow 2020, \u201cAvoiding Risk\nand Avoiding Evidence\u201d, <em>Australasian Journal of\nPhilosophy</em>, 98(3): 495\u2013515.",
                "\u2013\u2013\u2013, &amp; B. Salow 2022, \u201cAccurate\nUpdating for the Risk\u2013Sensitive\u201d, <em>The British Journal\nfor the Philosophy of Science</em>, 73(3): 751\u2013776.",
                "Carr, J., 2015, \u201cEpistemic Expansions\u201d, <em>Res\nPhilosophica</em>, 92(2): 217\u2013236.",
                "\u2013\u2013\u2013, 2017, \u201cEpistemic Utility Theory and\nthe Aim of Belief\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 95(3): 511\u2013534.",
                "\u2013\u2013\u2013, 2019, \u201cA Modesty Proposal\u201d,\n<em>Synthese</em>. doi:10.1007/s11229-019-02301-x",
                "Cox, R. T., 1946, \u201cProbability, Frequency and Reasonable\nExpectation\u201d, <em>American Journal of Physics</em>, 14:\n1\u201313.",
                "\u2013\u2013\u2013, 1961, <em>The Algebra of Probable\nInference</em>, Baltimore: Johns Hopkins University Press.",
                "D\u2019Agostino, M. &amp; C. Sinigaglia, 2010, \u201cEpistemic\nAccuracy and Subjective Probability\u201d, in M. Dorato &amp; M.\nSu\u00e0rez (eds.), <em>EPSA Epistemology and Methodology of\nScience</em>, Springer.",
                "Das, N., \u201cThe Value of Biased Information\u201d, <em>The\nBritish Journal for the Philosophy of Science</em>, 74(1):\n25\u201355.",
                "de Finetti, B., 1937 [1980], \u201cForesight: Its Logical Laws,\nIts Subjective Sources\u201d, in H. E. Kyburg &amp; H. E. K. Smokler\n(eds.), <em>Studies in Subjective Probability</em>, Huntington, NY:\nRobert E. Kreiger Publishing Co., 1980",
                "\u2013\u2013\u2013, 1974, <em>Theory of Probability</em> Vol.\n1, New York: Wiley.",
                "Diaconis, P. &amp; S. Zabell, 1982, \u201cUpdating Subjective\nProbability\u201d <em>Journal of the American Statistical\nAssociation</em>, 77(380): 822\u2013830.",
                "Dorst, K., 2017, \u201cLockeans Maximize Expected\nAccuracy\u201d, <em>Mind</em>, 128(509): 175\u2013211.",
                "Douven, I. &amp; S. Wenmackers, 2017, \u201cInference to the Best\nExplanation versus Bayes???s Rule in a Social Setting\u201d,\n<em>British Journal for the Philosophy of Science</em>, 68(2):\n535\u2013570.",
                "Dunn, J., 2018, \u201cAccuracy, Verisimilitude, and Scoring\nRules\u201d, <em>Australasian Journal of Philosophy</em>, 97(1):\n151\u2013166.",
                "Easwaran, K., 2013, \u201cExpected Accuracy Supports\nConditionalization\u2014and Conglomerability and Reflection\u201d,\n<em>Philosophy of Science</em>, 80(1): 119\u2013142.",
                "\u2013\u2013\u2013, 2015, \u201cAccuracy, Coherence, and\nEvidence\u201d, <em>Oxford Studies in Epistemology</em>, 5,\n61\u201396.",
                "\u2013\u2013\u2013, 2016, \u201cDr Truthlove, Or: How I\nLearned to Stop Worrying and Love Bayesian Probabilities\u201d,\n<em>No\u00fbs</em>, 50(4): 816\u2013853",
                "\u2013\u2013\u2013 &amp; B. Fitelson, 2012, \u201cAn\n\u2018evidentialist\u2019 worry about Joyce\u2019s argument for\nProbabilism\u201d, <em>Dialectica</em>, 66(3): 425\u2013433.",
                "Feldman, R., 2005, \u201cRespecting the Evidence\u201d,\n<em>Philosophical Perspectives</em>, 19(1): 95\u2013119.",
                "Fitelson, B. &amp; K. Easwaran, 2015, \u201cAccuracy, Coherence\nand Evidence\u201d, <em>Oxford Studies in Epistemology</em>, 5:\n61\u201396.",
                "Fitelson B. &amp; D. McCarthy, 2014, \u201cToward an epistemic\nfoundation for comparative confidence\u201d, Presentation, University\nof Wisconsin-Madison.\n <a href=\"http://fitelson.org/cc_handout.pdf\" target=\"other\">[Online version available here]</a>.",
                "Flores, C. &amp; E. Woodard, forthcoming, \u201cEpistemic Norms\non Evidence\u2013Gathering\u201d, <em>Philosophical\nStudies</em>.",
                "Foley, R., 1992, \u201cThe Epistemology of Belief and the\nEpistemology of Degrees of Belief\u201d, <em>American Philosophical\nQuarterly</em>, 29(2): 111\u2013121.",
                "Fraassen, B.C. van, 1983, \u201cCalibration: Frequency\nJustification for Personal Probability\u201d, in R.S. Cohen &amp; L.\nLaudan (eds.), <em>Physics, Philosophy, and Psychoanalysis</em>,\nDordrecht: Springer.",
                "Gallow, J. D., 2019, \u201cLearning and Value Change\u201d,\n<em>Philosophers\u2019 Imprint</em>, 19: 1\u201322.",
                "\u2013\u2013\u2013, 2021, \u201cUpdating for\nExternalists\u201d, <em>No\u00fbs</em>, 55(3): 487\u2013516.",
                "Goldman, A.I., 1999, <em>Knowledge in a Social World</em>, New\nYork: Oxford University Press.",
                "Good, I. J., 1967, \u201cOn the Principle of Total\nEvidence\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 17(4):319\u2013321.",
                "Greaves, H., 2013, \u201cEpistemic Decision Theory\u201d,\n<em>Mind</em>, 122(488): 915\u2013952.",
                "Greaves, H. &amp; D. Wallace, 2006, \u201cJustifying\nConditionalization: Conditionalization Maximizes Expected Epistemic\nUtility\u201d, <em>Mind</em>, 115(459): 607\u2013632.",
                "Hacking, I., 1967, \u201cSlightly More Realistic Personal\nProbability\u201d, <em>Philosophy of Science</em>, 34(4):\n311\u2013325.",
                "Harman, G., 1973, <em>Thought</em>, Princeton, NJ: Princeton\nUniversity Press.",
                "H\u00e1jek, A., 2008, \u201cArguments For\u2014Or\nAgainst\u2014Probabilism?\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, 59(4): 793\u2013819.",
                "\u2013\u2013\u2013, 2009, \u201cFifteen Arguments against\nHypothetical Frequentism\u201d, <em>Erkenntnis</em>, 70:\n211\u2013235.",
                "Hempel, C., 1962, \u201cDeductive\u2013Nomological vs.\nStatistical Explanation\u201d, in H. Feigl and &amp; G. Maxwell\n(eds.) <em>Minnesota Studies in the Philosophy of Science (vol.\nIII)</em>, Minneapolis:University of Minnesota Press.",
                "Horowitz, S., 2014, \u201cImmoderately rational\u201d,\n<em>Philosophical Studies</em>, 167: 41\u201356.",
                "\u2013\u2013\u2013, 2017, \u201cAccuracy and Educated\nGuesses\u201d in T. Szab\u00f3 Gendler &amp; J. Hawthorne (eds.)\n<em>Oxford Studies in Epistemology, volume 6</em> Oxford: Oxford\nUniversity Press.",
                "\u2013\u2013\u2013, 2019, \u201cThe Truth Problem for\nPermissivism\u201d, <em>Journal of Philosophy</em> 116(5):\n237\u2013262.",
                "Hughes, R. I. G. &amp; B. C. van Fraassen, 1984, \u201cSymmetry\narguments in probability kinematics\u201d, in <em>PSA: Proceedings of\nthe Biennial Meeting of the Philosophy of Science Association</em>\n(Issue 2/Volume Two: Symposia and Invited Papers), pp. 851\u2013869\ndoi:10.1086/psaprocbienmeetp.1984.2.192543",
                "Hurwicz, L., 1952, \u201cA criterion for decision making under\nuncertainty\u201d, Cowles Commission Technical Report 355.",
                "Huttegger, S.M., 2013, \u201cIn Defense of Reflection\u201d,\n<em>Philosophy of Science</em>, 80(3): 413\u2013433.",
                "Ismael, J., 2008, \u201cRaid! Dissolving the Big, Bad Bug\u201d,\n<em>No\u00fbs</em>, 42(2): 292\u2013307.",
                "Jaffray, J-Y., 1989, \u201cCoherent bets under partially\nresolving uncertainty and belief functions\u201d, <em>Theory and\nDecision</em>, 26: 90\u2013105.",
                "James, W., 1897, \u201cThe Will to Believe\u2019, in <em>The\nWill to Believe, and Other Essays in Popular Philosophy</em>, New\nYork: Longmans Green.",
                "Jeffrey, R., 1965, <em>The Logic of Decision</em>, New York:\nMcGraw-Hill.",
                "Jeffrey, R., 1983, <em>The Logic of Decision</em>\n(2<sup>nd</sup>). Chicago; London: University of Chicago Press.",
                "Jenkins, C.S., 2007, \u201cEntitlement and Rationality\u201d,\n<em>Synthese</em>, 157: 25\u201345.",
                "Joyce, J.M., 1998, \u201cA Nonpragmatic Vindication of\nProbabilism\u201d, <em>Philosophy of Science</em>, 65(4):\n575\u2013603.",
                "\u2013\u2013\u2013, 2009, \u201cAccuracy and Coherence:\nProspects for an Alethic Epistemology of Partial Belief\u201d, in F.\nHuber &amp; C. Schmidt-Petri (eds.), <em>Degrees of Belief</em>,\nSpringer.",
                "\u2013\u2013\u2013, 2018, \u201cThe True Consequences of\nEpistemic Consequentialism\u201d, in Ahlstrom-Vij &amp; Dunn\n2018.",
                "Kelley, M., 2019, <em>Accuracy Dominance on Infinite Opinion\nSets</em>, MA Thesis, UC Berkeley.\n <a href=\"https://mikaylalynnkelley.weebly.com/uploads/1/1/7/0/117045875/ma_thesis_final_draft.pdf\" target=\"other\">[Online version available here]</a>.",
                "Kelly, T., 2014, \u201cEvidence Can Be Permissive\u201d, in M.\nSteup, J. Turri, &amp; E. Sosa (eds.) <em>Contemporary Debates in\nEpistemology</em>, Oxford: Wiley-Blackwell.",
                "Kerbel, G., ms, \u201cA New Approach to Scoring on the Educated\nGuessing Framework\u201d, Unpublished manuscript.",
                "Konek, J., 2016, \u201cProbabilistic Knowledge and Cognitive\nAbility\u201d, <em>Philosophical Review</em>, 125(4):\n509\u2013587.",
                "\u2013\u2013\u2013, 2019, \u201cIP Scoring Rules: Foundations\nand Applications\u201d, <em>Proceedings of Machine Learning\nResearch</em>, 103: 256\u2013264.",
                "\u2013\u2013\u2013, 2022, \u201cThe Art of Learning\u201d in\nT. Szab\u00f3 Gendler &amp; J. Hawthorne (eds.) <em>Oxford Studies\nin Epistemology, volume 7</em> Oxford: Oxford University Press.",
                "Konek, J. &amp; B.A. Levinstein, 2019, \u201cThe Foundations of\nEpistemic Decision Theory\u201d, <em>Mind</em>, 128(509):\n69\u2013107.",
                "Kopec, M., 2012, \u201cWe Ought to Agree: A Consequence of\nRepairing Goldman\u2019s Group Scoring Rule\u201d,\n<em>Episteme</em>, 9: 101\u201314.",
                "Leitgeb, H., 2021, \u201cA Structural Justification of\nProbabilism: From Partition Invariance to Subjective\nProbability\u201d, <em>Philosophy of Science</em>, 88(2):\n341\u2013365.",
                "Leitgeb, H. &amp; R. Pettigrew, 2010a, \u201cAn Objective\nJustification of Bayesianism I: Measuring Inaccuracy\u201d,\n<em>Philosophy of Science</em>, 77: 201\u2013235.",
                "\u2013\u2013\u2013, 2010b, \u201cAn Objective Justification of\nBayesianism II: The Consequences of Minimizing Inaccuracy\u201d,\n<em>Philosophy of Science</em>, 77: 236\u2013272.",
                "Levinstein, B. A., 2012, \u201cLeitgeb and Pettigrew on Accuracy\nand Updating\u201d, <em>Philosophy of Science</em>, 79(3):\n413\u2013424.",
                "\u2013\u2013\u2013, 2015, \u201cWith All Due Respect: The\nMacro-Epistemology of Disagreement\u201d, <em>Philosophers\u2019\nImprint</em>, 15(3): 1\u201320.",
                "\u2013\u2013\u2013, 2017, \u201cA Pragmatist\u2019s Guide to\nEpistemic Utility\u201d, <em>Philosophy of Science</em> 84(4):\n613\u2013638.",
                "\u2013\u2013\u2013, 2018, \u201cAn Objection of Varying\nImportance to Epistemic Utility Theory\u201d, <em>Philosophical\nStudies</em>. doi:10.1007/s11098-018-1157-9",
                "\u2013\u2013\u2013, 2023, \u201cAccuracy, Deference, and\nChance\u201d <em>Philosophical Review</em> 132(1): 43\u201387.",
                "Lewis, D., 1980, \u201cA Subjectivist\u2019s Guide to Objective\nChance\u201d, in R.C. Jeffrey (ed.), <em>Studies in Inductive Logic\nand Probability</em> (Vol. II). Berkeley: University of California\nPress.",
                "Locke, J., 1689 [1975] <em>An Essay Concerning Human\nUnderstanding</em>, P.H. Nidditch (ed.) Oxford: Clarendon Press.",
                "Maher, P., 1993, <em>Betting on Theories</em>, Cambridge:\nCambridge University Press.",
                "\u2013\u2013\u2013, 2002, \u201cJoyce\u2019s Argument for\nProbabilism\u201d, <em>Philosophy of Science</em>, 69(1):\n73\u201381.",
                "Mayo-Wilson, C. &amp; G. Wheeler, 2016, \u201cScoring Imprecise\nCredences: A Mildly Immodest Proposal\u201d, <em>Philosophy and\nPhenomenological Research</em>, 92(1): 55\u201378.",
                "\u2013\u2013\u2013, ms., \u201cEpistemic Decision\nTheory\u2019s Reckoning\u201d. Unpublished manuscript.\n <a href=\"http://philsci-archive.pitt.edu/16374/\" target=\"other\">[Online version available here]</a>.\n ",
                "Meacham, C. J. G., 2018, \u201cCan All-Accuracy Accounts Justify\nEvidential Norms\u201d, in Ahlstrom-Vij &amp; Dunn 2018.",
                "Moss, S., 2011, \u201cScoring Rules and Epistemic\nCompromise\u201d, <em>Mind</em>, 120(480): 1053\u20131069.",
                "\u2013\u2013\u2013, 2018, \u201cProbabilistic\nKnowledge\u201d, Oxford: Oxford University Press.",
                "Myrvold, W., 2012, \u201cEpistemic values and the value of\nlearning\u201d, <em>Synthese</em>, 187: 547\u2013568.",
                "Nielsen, M., 2021, \u201cAccuracy-dominance and\nconditionalization\u201d, <em>Philosophical Studies</em>, 178(10):\n3217\u20133236.",
                "\u2013\u2013\u2013, 2022, \u201cOn the Best Accuracy Arguments\nfor Probabilism\u201d, <em>Philosophy of Science</em>, 89(3):\n621\u2013630.",
                "\u2013\u2013\u2013, 2023, \u201cAccuracy and Probabilism in\nInfinite Domains\u201d <em>Mind</em>, 132(526): 402\u2013427.",
                "Oddie, G., 1997, \u201cConditionalization, cogency, and cognitive\nvalue\u201d, <em>British Journal for the Philosophy of Science</em>,\n48(4): 533\u2013541.",
                "\u2013\u2013\u2013, 2019, \u201cWhat Accuracy Could Not\nBe\u201d, <em>The British Journal for the Philosophy of Science</em>,\n70(2): 551\u2013580.",
                "Paris, J. B., 1994, <em>The Uncertain Reasoner\u2019s Companion:\nA Mathematical Perspective</em>, Cambridge: Cambridge University\nPress.",
                "\u2013\u2013\u2013, 2001, \u201cA Note on the Dutch Book\nMethod\u201d, <em>Proceedings of the Second International Symposium\non Imprecise Probabilities and their Applications</em> Ithaca, NY:\nShaker.",
                "P\u00e9rez Carballo, A., 2018, \u201cGood Questions\u201d, in\nJ. Dunn &amp; K. Ahlstrom-Vij (eds.), <em>Epistemic\nConsequentialism</em>, Oxford: Oxford University Press.",
                "Pettigrew, R., 2010, \u201cModelling uncertainty\u201d,\n<em>Grazer Philosophische Studien</em>, 80.",
                "\u2013\u2013\u2013, 2013a, \u201cA New Epistemic Utility\nArgument for the Principal Principle\u201d, <em>Episteme</em>, 10(1):\n19\u201335.",
                "\u2013\u2013\u2013, 2013b, \u201cEpistemic Utility and Norms\nfor Credence\u201d, <em>Philosophy Compass</em>, 8(10):\n897\u2013908.",
                "\u2013\u2013\u2013, 2014a, \u201cAccuracy and Evidence\u201d,\n<em>Dialectica</em>.",
                "\u2013\u2013\u2013, 2014b, \u201cAccuracy, Risk, and the\nPrinciple of Indifference\u201d, <em>Philosophy and Phenomenological\nResearch</em>.",
                "\u2013\u2013\u2013, 2016a, <em>Accuracy and the Laws of\nCredence</em>, Oxford: Oxford University Press.",
                "\u2013\u2013\u2013, 2016b, \u201cJamesian epistemology\nformalised: An explication of \u2018The Will to Believe\u2019\u201d\n<em>Episteme</em> 13(3): 253\u2013268.",
                "\u2013\u2013\u2013, 2017, \u201cOn the Accuracy of Group\nCredences\u201d in T. Szab\u00f3 Gendler &amp; J. Hawthorne (eds.)\n<em>Oxford Studies in Epistemology, volume 6</em> Oxford: Oxford\nUniversity Press.",
                "\u2013\u2013\u2013, 2018a, \u201cMaking Things Right: the true\nconsequences of decision theory in epistemology\u201d, in\nAhlstrom-Vij &amp; Dunn 2018.",
                "\u2013\u2013\u2013, 2018b, \u201cThe Population Ethics of\nBelief: In Search of an Epistemic Theory X\u201d,\n<em>No\u00fbs</em>, 52(2): 336\u2013372.",
                "\u2013\u2013\u2013, 2018c, \u201cAccuracy-First Epistemology\nWithout Additivity\u201d, <em>Philosophy of Science</em>, 89(1):\n128\u2013151.",
                "\u2013\u2013\u2013, 2021a, \u201cLogical ignorance and logical\nlearning\u201d, <em>Synthese</em>, 198(10): 9991\u201310020.",
                "\u2013\u2013\u2013, 2021b, \u201cOn the pragmatic and\nepistemic virtues of inference to the best explanation\u201d,\n<em>Synthese</em> 199(5\u20136): 12407\u201312438.",
                "\u2013\u2013\u2013, 2022, <em>Epistemic Risk and the Demands of\nRationality</em>, Oxford: Oxford University Press.",
                "\u2013\u2013\u2013, 2023, \u201cBayesian updating when what\nyou learn might be false\u201d, <em>Erkenntnis</em> 88(1):\n309\u2013324.",
                "Predd, J., et al., 2009, \u201cProbabilistic Coherence and Proper\nScoring Rules\u201d, <em>IEEE Transactions on Information Theory</em>\n55(10): 4786\u20134792.",
                "Quiggin, J., 1982, \u201cA theory of anticipated utility\u201d,\n<em>Journal of Economic Behavior and Organization</em> 3(4):\n323\u201343.",
                "Raidl, E. &amp; W. Spohn, 2020, \u201cAn Accuracy Argument in\nFavor of Ranking Theory\u201d, <em>Journal of Philosophical\nLogic</em> 49(2): 283\u2013313.",
                "Ramsey, F. P., 1926 [1931], \u201cTruth and Probability\u201d,\nin R. B. Braithwaite (ed.) <em>The Foundations of Mathematics and\nother Logical Essays</em>, London: Routledge &amp; Kegan Paul\nLtd.",
                "Rescorla, M., 2022, \u201cAn Improved Dutch Book Theorem for\nConditionalization\u201d, <em>Erkenntnis</em>, 87(3):\n1013\u20131041.",
                "Rosenkrantz, R.D., 1981, <em>Foundations and Applications of\nInductive Probability</em>, Atascadero, CA: Ridgeview Press.",
                "Rothschild, D., 2021, \u2018Lockean Beliefs, Dutch Books, and\nScoring Systems\u2019, <em>Erkenntnis</em>, 88(5):\n1979\u20131995.",
                "Schervish, M. J., 1989, \u201cA General Method for Comparing\nProbability Assessors\u201c <em>The Annals of Statistics</em>, 17(4):\n1856\u20131879.",
                "Schoenfield, M., 2014, \u201cPermission to Believe: Why\nPermissivism Is True and What It Tells Us About Irrelevant Influences\non Belief\u201d, <em>No\u00fbs</em>, 48(2): 193\u2013218.",
                "\u2013\u2013\u2013, 2016, \u201cConditionalization does not\n(in general) Maximize Expected Accuracy\u201d, <em>Mind</em>,\n126(504): 1155\u20131187",
                "\u2013\u2013\u2013, 2017, \u201cThe Accuracy and Rationality\nof Imprecise Credences\u201d, <em>No\u00fbs</em>, 51(4):\n667\u2013685.",
                "\u2013\u2013\u2013, 2019, \u201cAccuracy and Verisimilitude:\nThe Good, The Bad, and The Ugly\u201d, <em>The British Journal for\nthe Philosophy of Science</em>. doi:10.1093/bjps/axz032",
                "Seidenfeld, T., 1985, \u201cCalibration, Coherence, and Scoring\nRules\u201d, <em>Philosophy of Science</em>, 52(2):\n274\u2013294.",
                "Seidenfeld, T., M.J. Schervish, &amp; J.B. Kadane, 2012,\n\u201cForecasting with imprecise probabilities\u201d,\n<em>International Journal of Approximate Reasoning</em>, 53:\n1248\u20131261.",
                "Shear, T. &amp; B. Fitelson, 2019, \u201cTwo Approaches to Belief\nRevision\u201d <em>Erkenntnis</em> 84(3): 487\u2013518.",
                "Spohn, W., 2012, <em>The Laws of Belief: Ranking Theory &amp; its\nPhilosophical Applications</em>, New York: Oxford University\nPress.",
                "Staffel, J. &amp; G. de Bona, Forthcoming, \u201cAn Improved\nArgument for Superconditionalization\u201d, <em>Erkenntnis</em>.",
                "Sylvan, K., 2020, \u201cAn Epistemic Non-Consequentialism\u201d,\n<em>The Philosophical Review</em>, 129(1): 1\u201351.",
                "Talbot, B., 2022, I \u201cHeadaches for Epistemologists\u201d,\n<em>Philosophy and Phenomenological Research</em>, 104(2):\n408\u2013433.",
                "van Fraassen, B. C., 1999, \u201cConditionalization, A New\nArgument For\u201d, <em>Topoi</em>, 18(2): 93\u201396.",
                "Vindrola, F. &amp; V. Crupi, forthcoming, \u201cBayesians Too\nShould Follow Wason: A Comprehensive Accuracy\u2013Based Analysis of\nthe Selection Task\u201d, <em>The British Journal for the Philosophy\nof Science</em>.",
                "Wald, A., 1945, \u201cStatistical decision functions which\nminimize the maximum risk\u201d, <em>The Annals of Mathematics</em>,\n46(2): 265\u2013280.",
                "Walsh, S., ms., \u201cProbabilism in Infinite Dimensions\u201d.\nUnpublished manuscript. ",
                "White, R., 2009, \u201cEvidential Symmetry and Mushy\nCredence\u201d, <em>Oxford Studies in Epistemology</em>, 3:\n161\u2013186.",
                "Williams, J. R. G., 2012a, \u201cGradational accuracy and\nnonclassical semantics\u201d, <em>Review of Symbolic Logic</em>,\n5(4):513\u2013537.",
                "\u2013\u2013\u2013, 2012b, \u201cGeneralized Probabilism:\nDutch Books and accuracy domination\u201d, <em>Journal of\nPhilosophical Logic</em>, 41(5):811\u2013840.",
                "\u2013\u2013\u2013, 2018, \u201cRational Illogicality\u201d,\n<em>Australasian Journal of Philosophy</em>, 96(1):\n127\u2013141.",
                "Williams, J. R. G. &amp; R. Pettigrew, 2023, \u2018Consequences\nof Calibration\u2019, <em>The British Journal for the Philosophy of\nScience</em>.",
                "Williamson, T., 2000, <em>Knowledge and its Limits</em>, Oxford:\nOxford University Press.",
                "Wong, S.K.M., Yao, Y.Y., Bollmann, P., &amp; B\u00fcrger, H.C.,\n1991, \u201cAxiomatization of qualitative belief structure\u201d,\n<em>IEEE Transactions on System, Man, and Cybernetics</em>, 21:\n726\u2013734.",
                "Zollman, K. J. S., 2010, \u201cThe Epistemic Benefit of Transient\nDiversity\u201d, <em>Erkenntnis</em> 72(1): 17\u201335."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2><a id=\"Bib\">Bibliography</a></h2>\n<ul class=\"hanging\">\n<li>Alchourr\u00f3n, C.E., P. G\u00e4rdenfors, &amp; D. Makinson,\n1985, \u201cOn the Logic of Theory Change: Partial Meet Contraction\nand Revision Functions\u201d, <em>Journal of Symbolic Logic</em>, 50:\n510\u2013530.</li>\n<li>Berker, S., 2013a, \u201cEpistemic Teleology and the Separateness\nof Propositions\u201d, <em>Philosophical Review</em>, 122(3):\n337\u2013393.</li>\n<li>\u2013\u2013\u2013, 2013b, \u201cThe Rejection of Epistemic\nConsequentialism\u201d, <em>Philosophical Issues (Supp.\nNo\u00fbs)</em>, 23(1): 363\u2013387.</li>\n<li>BonJour, L., 1985, <em>The Structure of Empirical Knowledge</em>,\nCambridge, MA: Harvard University Press.</li>\n<li>Briggs, R. A. &amp; R. Pettigrew, 2020, \u201cAn\nAccuracy-Dominance Argument for Conditionalization\u201d,\n<em>No\u00fbs</em>, 54(1): 162\u2013181.</li>\n<li>Brown, P. M., 1976, \u201cConditionalization and expected\nutility\u201d <em>Philosophy of Science</em>, 43(3):\n415\u2013419.</li>\n<li>Buchak, L., 2013, <em>Risk and Rationality</em>, Oxford: Oxford\nUniversity Press.</li>\n<li>Caie, M., 2013, \u201cRational Probabilistic Incoherence\u201d,\n<em>Philosophical Review</em>, 122(4): 527\u2013575.</li>\n<li>Campbell-Moore, C., 2015, \u201cRational Probabilistic\nIncoherence? A Reply to Michael Caie\u201d, <em>Philosophical\nReview</em> 124(3): 393\u2013406.</li>\n<li>\u2013\u2013\u2013, &amp; B. Salow 2020, \u201cAvoiding Risk\nand Avoiding Evidence\u201d, <em>Australasian Journal of\nPhilosophy</em>, 98(3): 495\u2013515.</li>\n<li>\u2013\u2013\u2013, &amp; B. Salow 2022, \u201cAccurate\nUpdating for the Risk\u2013Sensitive\u201d, <em>The British Journal\nfor the Philosophy of Science</em>, 73(3): 751\u2013776.</li>\n<li>Carr, J., 2015, \u201cEpistemic Expansions\u201d, <em>Res\nPhilosophica</em>, 92(2): 217\u2013236.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cEpistemic Utility Theory and\nthe Aim of Belief\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 95(3): 511\u2013534.</li>\n<li>\u2013\u2013\u2013, 2019, \u201cA Modesty Proposal\u201d,\n<em>Synthese</em>. doi:10.1007/s11229-019-02301-x</li>\n<li>Cox, R. T., 1946, \u201cProbability, Frequency and Reasonable\nExpectation\u201d, <em>American Journal of Physics</em>, 14:\n1\u201313.</li>\n<li>\u2013\u2013\u2013, 1961, <em>The Algebra of Probable\nInference</em>, Baltimore: Johns Hopkins University Press.</li>\n<li>D\u2019Agostino, M. &amp; C. Sinigaglia, 2010, \u201cEpistemic\nAccuracy and Subjective Probability\u201d, in M. Dorato &amp; M.\nSu\u00e0rez (eds.), <em>EPSA Epistemology and Methodology of\nScience</em>, Springer.</li>\n<li>Das, N., \u201cThe Value of Biased Information\u201d, <em>The\nBritish Journal for the Philosophy of Science</em>, 74(1):\n25\u201355.</li>\n<li>de Finetti, B., 1937 [1980], \u201cForesight: Its Logical Laws,\nIts Subjective Sources\u201d, in H. E. Kyburg &amp; H. E. K. Smokler\n(eds.), <em>Studies in Subjective Probability</em>, Huntington, NY:\nRobert E. Kreiger Publishing Co., 1980</li>\n<li>\u2013\u2013\u2013, 1974, <em>Theory of Probability</em> Vol.\n1, New York: Wiley.</li>\n<li>Diaconis, P. &amp; S. Zabell, 1982, \u201cUpdating Subjective\nProbability\u201d <em>Journal of the American Statistical\nAssociation</em>, 77(380): 822\u2013830.</li>\n<li>Dorst, K., 2017, \u201cLockeans Maximize Expected\nAccuracy\u201d, <em>Mind</em>, 128(509): 175\u2013211.</li>\n<li>Douven, I. &amp; S. Wenmackers, 2017, \u201cInference to the Best\nExplanation versus Bayes???s Rule in a Social Setting\u201d,\n<em>British Journal for the Philosophy of Science</em>, 68(2):\n535\u2013570.</li>\n<li>Dunn, J., 2018, \u201cAccuracy, Verisimilitude, and Scoring\nRules\u201d, <em>Australasian Journal of Philosophy</em>, 97(1):\n151\u2013166.</li>\n<li>Easwaran, K., 2013, \u201cExpected Accuracy Supports\nConditionalization\u2014and Conglomerability and Reflection\u201d,\n<em>Philosophy of Science</em>, 80(1): 119\u2013142.</li>\n<li>\u2013\u2013\u2013, 2015, \u201cAccuracy, Coherence, and\nEvidence\u201d, <em>Oxford Studies in Epistemology</em>, 5,\n61\u201396.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cDr Truthlove, Or: How I\nLearned to Stop Worrying and Love Bayesian Probabilities\u201d,\n<em>No\u00fbs</em>, 50(4): 816\u2013853</li>\n<li>\u2013\u2013\u2013 &amp; B. Fitelson, 2012, \u201cAn\n\u2018evidentialist\u2019 worry about Joyce\u2019s argument for\nProbabilism\u201d, <em>Dialectica</em>, 66(3): 425\u2013433.</li>\n<li>Feldman, R., 2005, \u201cRespecting the Evidence\u201d,\n<em>Philosophical Perspectives</em>, 19(1): 95\u2013119.</li>\n<li>Fitelson, B. &amp; K. Easwaran, 2015, \u201cAccuracy, Coherence\nand Evidence\u201d, <em>Oxford Studies in Epistemology</em>, 5:\n61\u201396.</li>\n<li>Fitelson B. &amp; D. McCarthy, 2014, \u201cToward an epistemic\nfoundation for comparative confidence\u201d, Presentation, University\nof Wisconsin-Madison.\n <a href=\"http://fitelson.org/cc_handout.pdf\" target=\"other\">[Online version available here]</a>.</li>\n<li>Flores, C. &amp; E. Woodard, forthcoming, \u201cEpistemic Norms\non Evidence\u2013Gathering\u201d, <em>Philosophical\nStudies</em>.</li>\n<li>Foley, R., 1992, \u201cThe Epistemology of Belief and the\nEpistemology of Degrees of Belief\u201d, <em>American Philosophical\nQuarterly</em>, 29(2): 111\u2013121.</li>\n<li>Fraassen, B.C. van, 1983, \u201cCalibration: Frequency\nJustification for Personal Probability\u201d, in R.S. Cohen &amp; L.\nLaudan (eds.), <em>Physics, Philosophy, and Psychoanalysis</em>,\nDordrecht: Springer.</li>\n<li>Gallow, J. D., 2019, \u201cLearning and Value Change\u201d,\n<em>Philosophers\u2019 Imprint</em>, 19: 1\u201322.</li>\n<li>\u2013\u2013\u2013, 2021, \u201cUpdating for\nExternalists\u201d, <em>No\u00fbs</em>, 55(3): 487\u2013516.</li>\n<li>Goldman, A.I., 1999, <em>Knowledge in a Social World</em>, New\nYork: Oxford University Press.</li>\n<li>Good, I. J., 1967, \u201cOn the Principle of Total\nEvidence\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 17(4):319\u2013321.</li>\n<li>Greaves, H., 2013, \u201cEpistemic Decision Theory\u201d,\n<em>Mind</em>, 122(488): 915\u2013952.</li>\n<li>Greaves, H. &amp; D. Wallace, 2006, \u201cJustifying\nConditionalization: Conditionalization Maximizes Expected Epistemic\nUtility\u201d, <em>Mind</em>, 115(459): 607\u2013632.</li>\n<li>Hacking, I., 1967, \u201cSlightly More Realistic Personal\nProbability\u201d, <em>Philosophy of Science</em>, 34(4):\n311\u2013325.</li>\n<li>Harman, G., 1973, <em>Thought</em>, Princeton, NJ: Princeton\nUniversity Press.</li>\n<li>H\u00e1jek, A., 2008, \u201cArguments For\u2014Or\nAgainst\u2014Probabilism?\u201d, <em>The British Journal for the\nPhilosophy of Science</em>, 59(4): 793\u2013819.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cFifteen Arguments against\nHypothetical Frequentism\u201d, <em>Erkenntnis</em>, 70:\n211\u2013235.</li>\n<li>Hempel, C., 1962, \u201cDeductive\u2013Nomological vs.\nStatistical Explanation\u201d, in H. Feigl and &amp; G. Maxwell\n(eds.) <em>Minnesota Studies in the Philosophy of Science (vol.\nIII)</em>, Minneapolis:University of Minnesota Press.</li>\n<li>Horowitz, S., 2014, \u201cImmoderately rational\u201d,\n<em>Philosophical Studies</em>, 167: 41\u201356.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cAccuracy and Educated\nGuesses\u201d in T. Szab\u00f3 Gendler &amp; J. Hawthorne (eds.)\n<em>Oxford Studies in Epistemology, volume 6</em> Oxford: Oxford\nUniversity Press.</li>\n<li>\u2013\u2013\u2013, 2019, \u201cThe Truth Problem for\nPermissivism\u201d, <em>Journal of Philosophy</em> 116(5):\n237\u2013262.</li>\n<li>Hughes, R. I. G. &amp; B. C. van Fraassen, 1984, \u201cSymmetry\narguments in probability kinematics\u201d, in <em>PSA: Proceedings of\nthe Biennial Meeting of the Philosophy of Science Association</em>\n(Issue 2/Volume Two: Symposia and Invited Papers), pp. 851\u2013869\ndoi:10.1086/psaprocbienmeetp.1984.2.192543</li>\n<li>Hurwicz, L., 1952, \u201cA criterion for decision making under\nuncertainty\u201d, Cowles Commission Technical Report 355.</li>\n<li>Huttegger, S.M., 2013, \u201cIn Defense of Reflection\u201d,\n<em>Philosophy of Science</em>, 80(3): 413\u2013433.</li>\n<li>Ismael, J., 2008, \u201cRaid! Dissolving the Big, Bad Bug\u201d,\n<em>No\u00fbs</em>, 42(2): 292\u2013307.</li>\n<li>Jaffray, J-Y., 1989, \u201cCoherent bets under partially\nresolving uncertainty and belief functions\u201d, <em>Theory and\nDecision</em>, 26: 90\u2013105.</li>\n<li>James, W., 1897, \u201cThe Will to Believe\u2019, in <em>The\nWill to Believe, and Other Essays in Popular Philosophy</em>, New\nYork: Longmans Green.</li>\n<li>Jeffrey, R., 1965, <em>The Logic of Decision</em>, New York:\nMcGraw-Hill.</li>\n<li>Jeffrey, R., 1983, <em>The Logic of Decision</em>\n(2<sup>nd</sup>). Chicago; London: University of Chicago Press.</li>\n<li>Jenkins, C.S., 2007, \u201cEntitlement and Rationality\u201d,\n<em>Synthese</em>, 157: 25\u201345.</li>\n<li>Joyce, J.M., 1998, \u201cA Nonpragmatic Vindication of\nProbabilism\u201d, <em>Philosophy of Science</em>, 65(4):\n575\u2013603.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cAccuracy and Coherence:\nProspects for an Alethic Epistemology of Partial Belief\u201d, in F.\nHuber &amp; C. Schmidt-Petri (eds.), <em>Degrees of Belief</em>,\nSpringer.</li>\n<li>\u2013\u2013\u2013, 2018, \u201cThe True Consequences of\nEpistemic Consequentialism\u201d, in Ahlstrom-Vij &amp; Dunn\n2018.</li>\n<li>Kelley, M., 2019, <em>Accuracy Dominance on Infinite Opinion\nSets</em>, MA Thesis, UC Berkeley.\n <a href=\"https://mikaylalynnkelley.weebly.com/uploads/1/1/7/0/117045875/ma_thesis_final_draft.pdf\" target=\"other\">[Online version available here]</a>.</li>\n<li>Kelly, T., 2014, \u201cEvidence Can Be Permissive\u201d, in M.\nSteup, J. Turri, &amp; E. Sosa (eds.) <em>Contemporary Debates in\nEpistemology</em>, Oxford: Wiley-Blackwell.</li>\n<li>Kerbel, G., ms, \u201cA New Approach to Scoring on the Educated\nGuessing Framework\u201d, Unpublished manuscript.</li>\n<li>Konek, J., 2016, \u201cProbabilistic Knowledge and Cognitive\nAbility\u201d, <em>Philosophical Review</em>, 125(4):\n509\u2013587.</li>\n<li>\u2013\u2013\u2013, 2019, \u201cIP Scoring Rules: Foundations\nand Applications\u201d, <em>Proceedings of Machine Learning\nResearch</em>, 103: 256\u2013264.</li>\n<li>\u2013\u2013\u2013, 2022, \u201cThe Art of Learning\u201d in\nT. Szab\u00f3 Gendler &amp; J. Hawthorne (eds.) <em>Oxford Studies\nin Epistemology, volume 7</em> Oxford: Oxford University Press.</li>\n<li>Konek, J. &amp; B.A. Levinstein, 2019, \u201cThe Foundations of\nEpistemic Decision Theory\u201d, <em>Mind</em>, 128(509):\n69\u2013107.</li>\n<li>Kopec, M., 2012, \u201cWe Ought to Agree: A Consequence of\nRepairing Goldman\u2019s Group Scoring Rule\u201d,\n<em>Episteme</em>, 9: 101\u201314.</li>\n<li>Leitgeb, H., 2021, \u201cA Structural Justification of\nProbabilism: From Partition Invariance to Subjective\nProbability\u201d, <em>Philosophy of Science</em>, 88(2):\n341\u2013365.</li>\n<li>Leitgeb, H. &amp; R. Pettigrew, 2010a, \u201cAn Objective\nJustification of Bayesianism I: Measuring Inaccuracy\u201d,\n<em>Philosophy of Science</em>, 77: 201\u2013235.</li>\n<li>\u2013\u2013\u2013, 2010b, \u201cAn Objective Justification of\nBayesianism II: The Consequences of Minimizing Inaccuracy\u201d,\n<em>Philosophy of Science</em>, 77: 236\u2013272.</li>\n<li>Levinstein, B. A., 2012, \u201cLeitgeb and Pettigrew on Accuracy\nand Updating\u201d, <em>Philosophy of Science</em>, 79(3):\n413\u2013424.</li>\n<li>\u2013\u2013\u2013, 2015, \u201cWith All Due Respect: The\nMacro-Epistemology of Disagreement\u201d, <em>Philosophers\u2019\nImprint</em>, 15(3): 1\u201320.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cA Pragmatist\u2019s Guide to\nEpistemic Utility\u201d, <em>Philosophy of Science</em> 84(4):\n613\u2013638.</li>\n<li>\u2013\u2013\u2013, 2018, \u201cAn Objection of Varying\nImportance to Epistemic Utility Theory\u201d, <em>Philosophical\nStudies</em>. doi:10.1007/s11098-018-1157-9</li>\n<li>\u2013\u2013\u2013, 2023, \u201cAccuracy, Deference, and\nChance\u201d <em>Philosophical Review</em> 132(1): 43\u201387.</li>\n<li>Lewis, D., 1980, \u201cA Subjectivist\u2019s Guide to Objective\nChance\u201d, in R.C. Jeffrey (ed.), <em>Studies in Inductive Logic\nand Probability</em> (Vol. II). Berkeley: University of California\nPress.</li>\n<li>Locke, J., 1689 [1975] <em>An Essay Concerning Human\nUnderstanding</em>, P.H. Nidditch (ed.) Oxford: Clarendon Press.</li>\n<li>Maher, P., 1993, <em>Betting on Theories</em>, Cambridge:\nCambridge University Press.</li>\n<li>\u2013\u2013\u2013, 2002, \u201cJoyce\u2019s Argument for\nProbabilism\u201d, <em>Philosophy of Science</em>, 69(1):\n73\u201381.</li>\n<li>Mayo-Wilson, C. &amp; G. Wheeler, 2016, \u201cScoring Imprecise\nCredences: A Mildly Immodest Proposal\u201d, <em>Philosophy and\nPhenomenological Research</em>, 92(1): 55\u201378.</li>\n<li>\u2013\u2013\u2013, ms., \u201cEpistemic Decision\nTheory\u2019s Reckoning\u201d. Unpublished manuscript.\n <a href=\"http://philsci-archive.pitt.edu/16374/\" target=\"other\">[Online version available here]</a>.\n </li>\n<li>Meacham, C. J. G., 2018, \u201cCan All-Accuracy Accounts Justify\nEvidential Norms\u201d, in Ahlstrom-Vij &amp; Dunn 2018.</li>\n<li>Moss, S., 2011, \u201cScoring Rules and Epistemic\nCompromise\u201d, <em>Mind</em>, 120(480): 1053\u20131069.</li>\n<li>\u2013\u2013\u2013, 2018, \u201cProbabilistic\nKnowledge\u201d, Oxford: Oxford University Press.</li>\n<li>Myrvold, W., 2012, \u201cEpistemic values and the value of\nlearning\u201d, <em>Synthese</em>, 187: 547\u2013568.</li>\n<li>Nielsen, M., 2021, \u201cAccuracy-dominance and\nconditionalization\u201d, <em>Philosophical Studies</em>, 178(10):\n3217\u20133236.</li>\n<li>\u2013\u2013\u2013, 2022, \u201cOn the Best Accuracy Arguments\nfor Probabilism\u201d, <em>Philosophy of Science</em>, 89(3):\n621\u2013630.</li>\n<li>\u2013\u2013\u2013, 2023, \u201cAccuracy and Probabilism in\nInfinite Domains\u201d <em>Mind</em>, 132(526): 402\u2013427.</li>\n<li>Oddie, G., 1997, \u201cConditionalization, cogency, and cognitive\nvalue\u201d, <em>British Journal for the Philosophy of Science</em>,\n48(4): 533\u2013541.</li>\n<li>\u2013\u2013\u2013, 2019, \u201cWhat Accuracy Could Not\nBe\u201d, <em>The British Journal for the Philosophy of Science</em>,\n70(2): 551\u2013580.</li>\n<li>Paris, J. B., 1994, <em>The Uncertain Reasoner\u2019s Companion:\nA Mathematical Perspective</em>, Cambridge: Cambridge University\nPress.</li>\n<li>\u2013\u2013\u2013, 2001, \u201cA Note on the Dutch Book\nMethod\u201d, <em>Proceedings of the Second International Symposium\non Imprecise Probabilities and their Applications</em> Ithaca, NY:\nShaker.</li>\n<li>P\u00e9rez Carballo, A., 2018, \u201cGood Questions\u201d, in\nJ. Dunn &amp; K. Ahlstrom-Vij (eds.), <em>Epistemic\nConsequentialism</em>, Oxford: Oxford University Press.</li>\n<li>Pettigrew, R., 2010, \u201cModelling uncertainty\u201d,\n<em>Grazer Philosophische Studien</em>, 80.</li>\n<li>\u2013\u2013\u2013, 2013a, \u201cA New Epistemic Utility\nArgument for the Principal Principle\u201d, <em>Episteme</em>, 10(1):\n19\u201335.</li>\n<li>\u2013\u2013\u2013, 2013b, \u201cEpistemic Utility and Norms\nfor Credence\u201d, <em>Philosophy Compass</em>, 8(10):\n897\u2013908.</li>\n<li>\u2013\u2013\u2013, 2014a, \u201cAccuracy and Evidence\u201d,\n<em>Dialectica</em>.</li>\n<li>\u2013\u2013\u2013, 2014b, \u201cAccuracy, Risk, and the\nPrinciple of Indifference\u201d, <em>Philosophy and Phenomenological\nResearch</em>.</li>\n<li>\u2013\u2013\u2013, 2016a, <em>Accuracy and the Laws of\nCredence</em>, Oxford: Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 2016b, \u201cJamesian epistemology\nformalised: An explication of \u2018The Will to Believe\u2019\u201d\n<em>Episteme</em> 13(3): 253\u2013268.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cOn the Accuracy of Group\nCredences\u201d in T. Szab\u00f3 Gendler &amp; J. Hawthorne (eds.)\n<em>Oxford Studies in Epistemology, volume 6</em> Oxford: Oxford\nUniversity Press.</li>\n<li>\u2013\u2013\u2013, 2018a, \u201cMaking Things Right: the true\nconsequences of decision theory in epistemology\u201d, in\nAhlstrom-Vij &amp; Dunn 2018.</li>\n<li>\u2013\u2013\u2013, 2018b, \u201cThe Population Ethics of\nBelief: In Search of an Epistemic Theory X\u201d,\n<em>No\u00fbs</em>, 52(2): 336\u2013372.</li>\n<li>\u2013\u2013\u2013, 2018c, \u201cAccuracy-First Epistemology\nWithout Additivity\u201d, <em>Philosophy of Science</em>, 89(1):\n128\u2013151.</li>\n<li>\u2013\u2013\u2013, 2021a, \u201cLogical ignorance and logical\nlearning\u201d, <em>Synthese</em>, 198(10): 9991\u201310020.</li>\n<li>\u2013\u2013\u2013, 2021b, \u201cOn the pragmatic and\nepistemic virtues of inference to the best explanation\u201d,\n<em>Synthese</em> 199(5\u20136): 12407\u201312438.</li>\n<li>\u2013\u2013\u2013, 2022, <em>Epistemic Risk and the Demands of\nRationality</em>, Oxford: Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 2023, \u201cBayesian updating when what\nyou learn might be false\u201d, <em>Erkenntnis</em> 88(1):\n309\u2013324.</li>\n<li>Predd, J., et al., 2009, \u201cProbabilistic Coherence and Proper\nScoring Rules\u201d, <em>IEEE Transactions on Information Theory</em>\n55(10): 4786\u20134792.</li>\n<li>Quiggin, J., 1982, \u201cA theory of anticipated utility\u201d,\n<em>Journal of Economic Behavior and Organization</em> 3(4):\n323\u201343.</li>\n<li>Raidl, E. &amp; W. Spohn, 2020, \u201cAn Accuracy Argument in\nFavor of Ranking Theory\u201d, <em>Journal of Philosophical\nLogic</em> 49(2): 283\u2013313.</li>\n<li>Ramsey, F. P., 1926 [1931], \u201cTruth and Probability\u201d,\nin R. B. Braithwaite (ed.) <em>The Foundations of Mathematics and\nother Logical Essays</em>, London: Routledge &amp; Kegan Paul\nLtd.</li>\n<li>Rescorla, M., 2022, \u201cAn Improved Dutch Book Theorem for\nConditionalization\u201d, <em>Erkenntnis</em>, 87(3):\n1013\u20131041.</li>\n<li>Rosenkrantz, R.D., 1981, <em>Foundations and Applications of\nInductive Probability</em>, Atascadero, CA: Ridgeview Press.</li>\n<li>Rothschild, D., 2021, \u2018Lockean Beliefs, Dutch Books, and\nScoring Systems\u2019, <em>Erkenntnis</em>, 88(5):\n1979\u20131995.</li>\n<li>Schervish, M. J., 1989, \u201cA General Method for Comparing\nProbability Assessors\u201c <em>The Annals of Statistics</em>, 17(4):\n1856\u20131879.</li>\n<li>Schoenfield, M., 2014, \u201cPermission to Believe: Why\nPermissivism Is True and What It Tells Us About Irrelevant Influences\non Belief\u201d, <em>No\u00fbs</em>, 48(2): 193\u2013218.</li>\n<li>\u2013\u2013\u2013, 2016, \u201cConditionalization does not\n(in general) Maximize Expected Accuracy\u201d, <em>Mind</em>,\n126(504): 1155\u20131187</li>\n<li>\u2013\u2013\u2013, 2017, \u201cThe Accuracy and Rationality\nof Imprecise Credences\u201d, <em>No\u00fbs</em>, 51(4):\n667\u2013685.</li>\n<li>\u2013\u2013\u2013, 2019, \u201cAccuracy and Verisimilitude:\nThe Good, The Bad, and The Ugly\u201d, <em>The British Journal for\nthe Philosophy of Science</em>. doi:10.1093/bjps/axz032</li>\n<li>Seidenfeld, T., 1985, \u201cCalibration, Coherence, and Scoring\nRules\u201d, <em>Philosophy of Science</em>, 52(2):\n274\u2013294.</li>\n<li>Seidenfeld, T., M.J. Schervish, &amp; J.B. Kadane, 2012,\n\u201cForecasting with imprecise probabilities\u201d,\n<em>International Journal of Approximate Reasoning</em>, 53:\n1248\u20131261.</li>\n<li>Shear, T. &amp; B. Fitelson, 2019, \u201cTwo Approaches to Belief\nRevision\u201d <em>Erkenntnis</em> 84(3): 487\u2013518.</li>\n<li>Spohn, W., 2012, <em>The Laws of Belief: Ranking Theory &amp; its\nPhilosophical Applications</em>, New York: Oxford University\nPress.</li>\n<li>Staffel, J. &amp; G. de Bona, Forthcoming, \u201cAn Improved\nArgument for Superconditionalization\u201d, <em>Erkenntnis</em>.</li>\n<li>Sylvan, K., 2020, \u201cAn Epistemic Non-Consequentialism\u201d,\n<em>The Philosophical Review</em>, 129(1): 1\u201351.</li>\n<li>Talbot, B., 2022, I \u201cHeadaches for Epistemologists\u201d,\n<em>Philosophy and Phenomenological Research</em>, 104(2):\n408\u2013433.</li>\n<li>van Fraassen, B. C., 1999, \u201cConditionalization, A New\nArgument For\u201d, <em>Topoi</em>, 18(2): 93\u201396.</li>\n<li>Vindrola, F. &amp; V. Crupi, forthcoming, \u201cBayesians Too\nShould Follow Wason: A Comprehensive Accuracy\u2013Based Analysis of\nthe Selection Task\u201d, <em>The British Journal for the Philosophy\nof Science</em>.</li>\n<li>Wald, A., 1945, \u201cStatistical decision functions which\nminimize the maximum risk\u201d, <em>The Annals of Mathematics</em>,\n46(2): 265\u2013280.</li>\n<li>Walsh, S., ms., \u201cProbabilism in Infinite Dimensions\u201d.\nUnpublished manuscript. </li>\n<li>White, R., 2009, \u201cEvidential Symmetry and Mushy\nCredence\u201d, <em>Oxford Studies in Epistemology</em>, 3:\n161\u2013186.</li>\n<li>Williams, J. R. G., 2012a, \u201cGradational accuracy and\nnonclassical semantics\u201d, <em>Review of Symbolic Logic</em>,\n5(4):513\u2013537.</li>\n<li>\u2013\u2013\u2013, 2012b, \u201cGeneralized Probabilism:\nDutch Books and accuracy domination\u201d, <em>Journal of\nPhilosophical Logic</em>, 41(5):811\u2013840.</li>\n<li>\u2013\u2013\u2013, 2018, \u201cRational Illogicality\u201d,\n<em>Australasian Journal of Philosophy</em>, 96(1):\n127\u2013141.</li>\n<li>Williams, J. R. G. &amp; R. Pettigrew, 2023, \u2018Consequences\nof Calibration\u2019, <em>The British Journal for the Philosophy of\nScience</em>.</li>\n<li>Williamson, T., 2000, <em>Knowledge and its Limits</em>, Oxford:\nOxford University Press.</li>\n<li>Wong, S.K.M., Yao, Y.Y., Bollmann, P., &amp; B\u00fcrger, H.C.,\n1991, \u201cAxiomatization of qualitative belief structure\u201d,\n<em>IEEE Transactions on System, Man, and Cybernetics</em>, 21:\n726\u2013734.</li>\n<li>Zollman, K. J. S., 2010, \u201cThe Epistemic Benefit of Transient\nDiversity\u201d, <em>Erkenntnis</em> 72(1): 17\u201335.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "belief, formal representations of",
            "epistemology",
            "epistemology: Bayesian",
            "probability, interpretations of"
        ],
        "entry_link": [
            {
                "../formal-belief/": "belief, formal representations of"
            },
            {
                "../epistemology/": "epistemology"
            },
            {
                "../epistemology-bayesian/": "epistemology: Bayesian"
            },
            {
                "../probability-interpret/": "probability, interpretations of"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemic-utility\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/epistemic-utility/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=epistemic-utility&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/epistemic-utility/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemic-utility": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/epistemic-utility/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=epistemic-utility&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/epistemic-utility/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "Pettigrew, Richard,\n <a href=\"https://richardpettigrew.com/books/accuracy/\" target=\"other\">The webpage for Pettigrew\u2019s <em>Accuracy and the Laws of Credence</em></a>.\n This includes video tutorials that work through some of the central\nresults in accuracy-first epistemology.",
            "Weisberg, Jonathan,\n <a href=\"https://jonathanweisberg.org/tags/accuracy-for-dummies/\" target=\"other\">A series of blogposts</a>\n that walk slowly through the technical side of accuracy-first\nepistemology."
        ],
        "listed_links": [
            {
                "https://richardpettigrew.com/books/accuracy/": "The webpage for Pettigrew\u2019s Accuracy and the Laws of Credence"
            },
            {
                "https://jonathanweisberg.org/tags/accuracy-for-dummies/": "A series of blogposts"
            }
        ]
    }
}