{
    "main_text": "Can computers be moral agents? || Expanding the concept of moral agency\n2.3 Expanding the concept of moral agency\n\nThe prospect of increasingly autonomous and intelligent computer\ntechnologies and the growing difficulty of finding responsible human\nagents lead Floridi and Sanders to take a different approach (2004).\nThey propose to extend the class of moral agents to include artificial\nagents, while disconnecting moral agency and moral accountability from\nthe notion of moral responsibility. They contend that \u201cthe\ninsurmountable difficulties for the traditional and now rather\noutdated view that a human can be found accountable for certain kinds\nof software and even hardware\u201d demands a different approach (p.\n372). Instead, they suggest that artificial agents should be\nacknowledged as moral agents that can be held accountable, but not\nresponsible. To illustrate they draw a comparison between artificial\nagents and dogs as sources of moral actions. Dogs can be the cause of\na morally charged action, like damaging property or helping to save a\nperson\u2019s life, as in the case of search-and-rescue dogs. We can\nidentify them as moral agents even though we generally do not hold\nthem morally responsible, according to Floridi and Sanders: they are\nthe source of a moral action and can be held morally accountable by\ncorrecting or punishing them.\n\nJust like animals, Floridi and Sanders argue, artificial agents can be\nseen as sources of moral actions and thus can be held morally\naccountable when they can be conceived of as behaving like a moral\nagent from an appropriate level of abstraction. The notion of\nlevels of abstraction refers to the stance one adopts towards and\nentity to predict and explain its behavior. At a low level of\nabstraction we would explain the behavior of a system in terms of its\nmechanical or biological processes. At a higher level of abstraction\nit can help to describe the behavior of a system in terms of beliefs,\ndesires and thoughts. If at a high enough level a computational system\ncan effectively be described as being interactive, autonomous and\nadaptive, then it can be held accountable according to Floridi and\nSanders (p. 352). It, thus, does not require personhood or free will\nfor an agent to be morally accountable; rather the agent has to act as\nif it had intentions and was able to make choices.\n\nThe advantage of disconnecting accountability from responsibility,\naccording to Floridi and Sanders, is that it places the focus on moral\nagenthood, accountability and censure, instead of on figuring out\nwhich human agents are responsible. \u201cWe are less likely to\nassign responsibility at any cost, forced by the necessity to identify\na human moral agent. We can liberate technological development of AAs\n[Artificial Agents] from being bound by the standard limiting\nview\u201d (p. 376). When artificial agents \u2018behave\nbadly\u2019 they can be dealt with directly, when their autonomous\nbehavior and complexity makes it too difficult to distribute\nresponsibility among human agents. Immoral agents can be modified or\ndeleted. It is then possible to attribute moral accountability even\nwhen moral responsibility cannot be determined.\n\nCritics of Floridi\u2019s and Sanders\u2019 view on accountability\nand moral agency argue that placing the focus of analysis on\ncomputational artifacts by treating them as moral agents will draw\nattention away from the humans that deploy and develop them. Johnson,\nfor instance, makes the case that computer technologies remain\nconnected to the intentionality of their creators and users (2006).\nShe argues that although computational artifacts are a part of the\nmoral world and should be recognized as entities that have moral\nrelevance, they are not moral agents, for they are not intentional.\nThey are not intentional, because they do not have mental states or a\npurpose that comes from the freedom to act. She emphasizes that\nalthough these artifacts are not intentional, they do have\nintentionality, but their intentionality is related to their\nfunctionality. They are human-made artifacts and their design and use\nreflect the intentions of designers and users. Human users, in turn,\nuse their intentionality to interact with and through the software. In\ninteracting with the artifacts they activate the inscribed intentions\nof the designers and developers. It is through human activity that\ncomputer technology is designed, developed, tested, installed,\ninitiated and provided with input and instructions to perform\nspecified tasks. Without this human activity, computers would do\nnothing. Attributing independent moral agency to computers, Johnson\nclaims, disconnects them from the human behavior that creates, deploys\nand uses them. It turns the attention away from the forces that shape\ntechnological development and limits the possibility for intervention.\nFor instance, it leaves the issue of sorting out who is responsible\nfor dealing with malfunctioning or immoral artificial agents or who\nshould make amends for the harmful events they may cause. It postpones\nthe question of who has to account for the conditions under which\nartificial agents are allowed to operate (Noorman 2009).\n\nYet, technologies can still be part of moral action, without being a\nmoral agent. Several philosophers have stressed that moral\nresponsibility cannot be properly understood without recognizing the\nactive role of technology in shaping human action (Jonas 1984; Verbeek\n2006; Johnson and Powers 2005; Nyholm 2018). Johnson, for\ninstance, claims that although computers are not moral agents, the\nartifact designer, the artifact, and the artifact user should all be\nthe focus of moral evaluation as they are all at work in an action\n(Johnson 2006). Humans create these artifacts and inscribe in them\ntheir particular values and intentions to achieve particular effects\nin the world and in turn these technological artifacts influence what\nhuman beings can and cannot do and affect how they perceive and\ninterpret the world.\n\nSimilarly, Verbeek maintains that technological artifacts alone do not\nhave moral agency, but moral agency is hardly ever\n\u2018purely\u2019 human. Moral agency generally involves a\nmediating artifact that shapes human behavior, often in way not\nanticipated by the designer (2008). Moral decisions and actions are\nco-shaped by technological artifacts. He suggests that in all forms of\nhuman action there are three forms of agency at work: 1) the agency of\nthe human performing the action; 2) the agency of the designer who\nhelped shaped the mediating role of the artifacts and 3) the artifact\nmediating human action. The agency of artifacts is inextricably linked\nto the agency of its designers and users, but it cannot be reduced to\neither of them. For him, then, a subject that acts or makes moral\ndecisions is a composite of human and technological components. Moral\nagency is not merely located in a human being, but in a complex blend\nof humans and technologies.\n\nIn later papers, Floridi explores the concept of distributed moral\nactions (2013, 2016). He argues that some moral significant outcomes\ncannot be reduced to the moral significant actions of some\nindividuals. Morally neutral actions of several individuals can still\nresult in morally significant events. Individuals might not have\nintended to cause harm, but nevertheless their combined actions may\nstill result in moral harm to someone or something. In order to deal\nwith the problem of subsequently assigning moral responsibility for\nsuch distributed moral actions, he argues that the focus of analysis\nshould shift from the agents to the patients of moral actions. A moral\naction can then be evaluated in terms of the harm to the patient,\nregardless of the intentions of the agents involved. Assigning\nresponsibility then focuses on whether or not an agent is causally\naccountable for the outcome and on adjusting their behavior to prevent\nharm. If the agents causally accountable - be they artificial or\nbiological - are autonomous, can interact with each other and their\nenvironments and can learn from their interactions they can be held\nresponsible for distributed moral actions, according to Floridi\n(2016).\n",
    "section_title": "2.3 Expanding the concept of moral agency",
    "entry_title": "Computing and Moral Responsibility",
    "hierarchy_title": "Computing and Moral Responsibility || Can computers be moral agents? || Expanding the concept of moral agency",
    "tokenized_text": [
        "computer",
        "moral",
        "agent",
        "expanding",
        "concept",
        "moral",
        "agency",
        "expanding",
        "concept",
        "moral",
        "agency",
        "prospect",
        "increasingly",
        "autonomous",
        "intelligent",
        "computer",
        "technology",
        "growing",
        "difficulty",
        "finding",
        "responsible",
        "human",
        "agent",
        "lead",
        "floridi",
        "sander",
        "take",
        "different",
        "approach",
        "propose",
        "extend",
        "class",
        "moral",
        "agent",
        "include",
        "artificial",
        "agent",
        "disconnecting",
        "moral",
        "agency",
        "moral",
        "accountability",
        "notion",
        "moral",
        "responsibility",
        "contend",
        "insurmountable",
        "difficulty",
        "traditional",
        "rather",
        "outdated",
        "view",
        "human",
        "found",
        "accountable",
        "certain",
        "kind",
        "software",
        "even",
        "hardware",
        "demand",
        "different",
        "approach",
        "p",
        "instead",
        "suggest",
        "artificial",
        "agent",
        "acknowledged",
        "moral",
        "agent",
        "held",
        "accountable",
        "responsible",
        "illustrate",
        "draw",
        "comparison",
        "artificial",
        "agent",
        "dog",
        "source",
        "moral",
        "action",
        "dog",
        "cause",
        "morally",
        "charged",
        "action",
        "like",
        "damaging",
        "property",
        "helping",
        "save",
        "person",
        "life",
        "case",
        "searchandrescue",
        "dog",
        "identify",
        "moral",
        "agent",
        "even",
        "though",
        "generally",
        "hold",
        "morally",
        "responsible",
        "according",
        "floridi",
        "sander",
        "source",
        "moral",
        "action",
        "held",
        "morally",
        "accountable",
        "correcting",
        "punishing",
        "like",
        "animal",
        "floridi",
        "sander",
        "argue",
        "artificial",
        "agent",
        "seen",
        "source",
        "moral",
        "action",
        "thus",
        "held",
        "morally",
        "accountable",
        "conceived",
        "behaving",
        "like",
        "moral",
        "agent",
        "appropriate",
        "level",
        "abstraction",
        "notion",
        "level",
        "abstraction",
        "refers",
        "stance",
        "one",
        "adopts",
        "towards",
        "entity",
        "predict",
        "explain",
        "behavior",
        "low",
        "level",
        "abstraction",
        "would",
        "explain",
        "behavior",
        "system",
        "term",
        "mechanical",
        "biological",
        "process",
        "higher",
        "level",
        "abstraction",
        "help",
        "describe",
        "behavior",
        "system",
        "term",
        "belief",
        "desire",
        "thought",
        "high",
        "enough",
        "level",
        "computational",
        "system",
        "effectively",
        "described",
        "interactive",
        "autonomous",
        "adaptive",
        "held",
        "accountable",
        "according",
        "floridi",
        "sander",
        "p",
        "thus",
        "require",
        "personhood",
        "free",
        "agent",
        "morally",
        "accountable",
        "rather",
        "agent",
        "act",
        "intention",
        "able",
        "make",
        "choice",
        "advantage",
        "disconnecting",
        "accountability",
        "responsibility",
        "according",
        "floridi",
        "sander",
        "place",
        "focus",
        "moral",
        "agenthood",
        "accountability",
        "censure",
        "instead",
        "figuring",
        "human",
        "agent",
        "responsible",
        "le",
        "likely",
        "assign",
        "responsibility",
        "cost",
        "forced",
        "necessity",
        "identify",
        "human",
        "moral",
        "agent",
        "liberate",
        "technological",
        "development",
        "aa",
        "artificial",
        "agent",
        "bound",
        "standard",
        "limiting",
        "view",
        "p",
        "artificial",
        "agent",
        "behave",
        "badly",
        "dealt",
        "directly",
        "autonomous",
        "behavior",
        "complexity",
        "make",
        "difficult",
        "distribute",
        "responsibility",
        "among",
        "human",
        "agent",
        "immoral",
        "agent",
        "modified",
        "deleted",
        "possible",
        "attribute",
        "moral",
        "accountability",
        "even",
        "moral",
        "responsibility",
        "determined",
        "critic",
        "floridi",
        "sander",
        "view",
        "accountability",
        "moral",
        "agency",
        "argue",
        "placing",
        "focus",
        "analysis",
        "computational",
        "artifact",
        "treating",
        "moral",
        "agent",
        "draw",
        "attention",
        "away",
        "human",
        "deploy",
        "develop",
        "johnson",
        "instance",
        "make",
        "case",
        "computer",
        "technology",
        "remain",
        "connected",
        "intentionality",
        "creator",
        "user",
        "argues",
        "although",
        "computational",
        "artifact",
        "part",
        "moral",
        "world",
        "recognized",
        "entity",
        "moral",
        "relevance",
        "moral",
        "agent",
        "intentional",
        "intentional",
        "mental",
        "state",
        "purpose",
        "come",
        "freedom",
        "act",
        "emphasizes",
        "although",
        "artifact",
        "intentional",
        "intentionality",
        "intentionality",
        "related",
        "functionality",
        "humanmade",
        "artifact",
        "design",
        "use",
        "reflect",
        "intention",
        "designer",
        "user",
        "human",
        "user",
        "turn",
        "use",
        "intentionality",
        "interact",
        "software",
        "interacting",
        "artifact",
        "activate",
        "inscribed",
        "intention",
        "designer",
        "developer",
        "human",
        "activity",
        "computer",
        "technology",
        "designed",
        "developed",
        "tested",
        "installed",
        "initiated",
        "provided",
        "input",
        "instruction",
        "perform",
        "specified",
        "task",
        "without",
        "human",
        "activity",
        "computer",
        "would",
        "nothing",
        "attributing",
        "independent",
        "moral",
        "agency",
        "computer",
        "johnson",
        "claim",
        "disconnect",
        "human",
        "behavior",
        "creates",
        "deploys",
        "us",
        "turn",
        "attention",
        "away",
        "force",
        "shape",
        "technological",
        "development",
        "limit",
        "possibility",
        "intervention",
        "instance",
        "leaf",
        "issue",
        "sorting",
        "responsible",
        "dealing",
        "malfunctioning",
        "immoral",
        "artificial",
        "agent",
        "make",
        "amends",
        "harmful",
        "event",
        "may",
        "cause",
        "postpones",
        "question",
        "account",
        "condition",
        "artificial",
        "agent",
        "allowed",
        "operate",
        "noorman",
        "yet",
        "technology",
        "still",
        "part",
        "moral",
        "action",
        "without",
        "moral",
        "agent",
        "several",
        "philosopher",
        "stressed",
        "moral",
        "responsibility",
        "properly",
        "understood",
        "without",
        "recognizing",
        "active",
        "role",
        "technology",
        "shaping",
        "human",
        "action",
        "jonas",
        "verbeek",
        "johnson",
        "power",
        "nyholm",
        "johnson",
        "instance",
        "claim",
        "although",
        "computer",
        "moral",
        "agent",
        "artifact",
        "designer",
        "artifact",
        "artifact",
        "user",
        "focus",
        "moral",
        "evaluation",
        "work",
        "action",
        "johnson",
        "human",
        "create",
        "artifact",
        "inscribe",
        "particular",
        "value",
        "intention",
        "achieve",
        "particular",
        "effect",
        "world",
        "turn",
        "technological",
        "artifact",
        "influence",
        "human",
        "being",
        "affect",
        "perceive",
        "interpret",
        "world",
        "similarly",
        "verbeek",
        "maintains",
        "technological",
        "artifact",
        "alone",
        "moral",
        "agency",
        "moral",
        "agency",
        "hardly",
        "ever",
        "purely",
        "human",
        "moral",
        "agency",
        "generally",
        "involves",
        "mediating",
        "artifact",
        "shape",
        "human",
        "behavior",
        "often",
        "way",
        "anticipated",
        "designer",
        "moral",
        "decision",
        "action",
        "coshaped",
        "technological",
        "artifact",
        "suggests",
        "form",
        "human",
        "action",
        "three",
        "form",
        "agency",
        "work",
        "agency",
        "human",
        "performing",
        "action",
        "agency",
        "designer",
        "helped",
        "shaped",
        "mediating",
        "role",
        "artifact",
        "artifact",
        "mediating",
        "human",
        "action",
        "agency",
        "artifact",
        "inextricably",
        "linked",
        "agency",
        "designer",
        "user",
        "reduced",
        "either",
        "subject",
        "act",
        "make",
        "moral",
        "decision",
        "composite",
        "human",
        "technological",
        "component",
        "moral",
        "agency",
        "merely",
        "located",
        "human",
        "complex",
        "blend",
        "human",
        "technology",
        "later",
        "paper",
        "floridi",
        "explores",
        "concept",
        "distributed",
        "moral",
        "action",
        "argues",
        "moral",
        "significant",
        "outcome",
        "reduced",
        "moral",
        "significant",
        "action",
        "individual",
        "morally",
        "neutral",
        "action",
        "several",
        "individual",
        "still",
        "result",
        "morally",
        "significant",
        "event",
        "individual",
        "might",
        "intended",
        "cause",
        "harm",
        "nevertheless",
        "combined",
        "action",
        "may",
        "still",
        "result",
        "moral",
        "harm",
        "someone",
        "something",
        "order",
        "deal",
        "problem",
        "subsequently",
        "assigning",
        "moral",
        "responsibility",
        "distributed",
        "moral",
        "action",
        "argues",
        "focus",
        "analysis",
        "shift",
        "agent",
        "patient",
        "moral",
        "action",
        "moral",
        "action",
        "evaluated",
        "term",
        "harm",
        "patient",
        "regardless",
        "intention",
        "agent",
        "involved",
        "assigning",
        "responsibility",
        "focus",
        "whether",
        "agent",
        "causally",
        "accountable",
        "outcome",
        "adjusting",
        "behavior",
        "prevent",
        "harm",
        "agent",
        "causally",
        "accountable",
        "artificial",
        "biological",
        "autonomous",
        "interact",
        "environment",
        "learn",
        "interaction",
        "held",
        "responsible",
        "distributed",
        "moral",
        "action",
        "according",
        "floridi"
    ]
}