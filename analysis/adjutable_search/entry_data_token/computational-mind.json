{"url": "computational-mind", "title": "The Computational Theory of Mind", "authorship": {"year": "Copyright \u00a9 2020", "author_text": "Michael Rescorla\n<rescorla@ucla.edu>", "author_links": [{"mailto:rescorla%40ucla%2eedu": "rescorla@ucla.edu"}], "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2020</a> by\n\n<br/>\nMichael Rescorla\n&lt;<a href=\"mailto:rescorla%40ucla%2eedu\"><em>rescorla<abbr title=\" at \">@</abbr>ucla<abbr title=\" dot \">.</abbr>edu</em></a>&gt;\n    </p>\n</div>"}, "pubinfo": ["First published Fri Oct 16, 2015", "substantive revision Fri Feb 21, 2020"], "preamble": "\nCould a machine think? Could the mind itself be a thinking machine?\nThe computer revolution transformed discussion of these questions,\noffering our best prospects yet for machines that emulate reasoning,\ndecision-making, problem solving, perception, linguistic\ncomprehension, and other mental processes. Advances in\ncomputing raise the prospect that the mind itself is a computational\nsystem\u2014a position known as the computational theory of\nmind (CTM). Computationalists are researchers who\nendorse CTM, at least as applied to certain important mental\nprocesses. CTM played a central role within cognitive science during\nthe 1960s and 1970s. For many years, it enjoyed orthodox status. More\nrecently, it has come under pressure from various rival paradigms. A\nkey task facing computationalists is to explain what one means when\none says that the mind \u201ccomputes\u201d. A second task is to\nargue that the mind \u201ccomputes\u201d in the relevant sense. A\nthird task is to elucidate how computational description relates to\nother common types of description, especially neurophysiological\ndescription (which cites neurophysiological properties of the\norganism\u2019s brain or body) and intentional description\n(which cites representational properties of mental states).\n", "toc": [{"#TurMac": "1. Turing machines"}, {"#ArtInt": "2. Artificial intelligence"}, {"#ClaComTheMin": "3. The classical computational theory of mind"}, {"#MacFun": "3.1 Machine functionalism"}, {"#RepTheMin": "3.2 The representational theory of mind"}, {"#NeuNet": "4. Neural networks"}, {"#RelBetNeuNetClaCom": "4.1 Relation between neural networks and classical computation"}, {"#ArgForCon": "4.2 Arguments for connectionism"}, {"#SysPro": "4.3 Systematicity and productivity"}, {"#ComNeu": "4.4 Computational neuroscience"}, {"#ComRep": "5. Computation and representation"}, {"#ComFor": "5.1 Computation as formal"}, {"#ExtAboMenCon": "5.2 Externalism about mental content"}, {"#ConInvCom": "5.3 Content-involving computation"}, {"#AltConCom": "6. Alternative conceptions of computation"}, {"#InfPro": "6.1 Information-processing"}, {"#FunEva": "6.2 Function evaluation"}, {"#Str": "6.3 Structuralism"}, {"#MecThe": "6.4 Mechanistic theories"}, {"#Plu": "6.5 Pluralism"}, {"#ArgAgaCom": "7. Arguments against computationalism"}, {"#TriArg": "7.1 Triviality arguments"}, {"#GodIncThe": "7.2 G\u00f6del\u2019s incompleteness theorem"}, {"#LimComMod": "7.3 Limits of computational modeling"}, {"#TemArg": "7.4 Temporal arguments"}, {"#EmbCog": "7.5 Embodied cognition"}, {"#Bib": "Bibliography"}, {"#Aca": "Academic Tools"}, {"#Oth": "Other Internet Resources"}, {"#Rel": "Related Entries"}], "main_text": "\n1. Turing machines\nThe intuitive notions of computation\nand algorithm are central to mathematics. Roughly speaking,\nan algorithm is an explicit, step-by-step procedure for answering some\nquestion or solving some problem. An algorithm provides routine\nmechanical instructions dictating how to proceed at each\nstep. Obeying the instructions requires no special ingenuity or\ncreativity. For example, the familiar grade-school algorithms describe\nhow to compute addition, multiplication, and division. Until the early\ntwentieth century, mathematicians relied upon informal notions of\ncomputation and algorithm without attempting anything like a formal\nanalysis. Developments in the foundations of mathematics eventually\nimpelled logicians to pursue a more systematic treatment. Alan\nTuring\u2019s landmark paper \u201cOn Computable Numbers, With\nan Application to the Entscheidungsproblem\u201d (Turing 1936)\noffered the analysis that has proved most influential.\nA Turing machine is an abstract model of an idealized\ncomputing device with unlimited time and storage space at its\ndisposal. The device manipulates symbols, much as a human\ncomputing agent manipulates pencil marks on paper during arithmetical\ncomputation. Turing says very little about the nature of symbols. He\nassumes that primitive symbols are drawn from a finite alphabet. He\nalso assumes that symbols can be inscribed or erased at \u201cmemory\nlocations\u201d. Turing\u2019s model works as follows:\n\nThere are infinitely many memory locations, arrayed in a linear\nstructure. Metaphorically, these memory locations are\n\u201ccells\u201d on an infinitely long \u201cpaper\ntape\u201d. More literally, the memory locations might be physically\nrealized in various media (e.g., silicon chips).\nThere is a central processor, which can access one memory location\nat a time. Metaphorically, the central processor is a\n\u201cscanner\u201d that moves along the paper tape one\n\u201ccell\u201d at a time.\nThe central processor can enter into finitely many machine\nstates.\nThe central processor can perform four elementary operations:\nwrite a symbol at a memory location; erase a symbol from a memory\nlocation; access the next memory location in the linear array\n(\u201cmove to the right on the tape\u201d); access the previous\nmemory location in the linear array (\u201cmove to the left on the\ntape\u201d).\nWhich elementary operation the central processor performs depends\nentirely upon two facts: which symbol is currently inscribed at the\npresent memory location; and the scanner\u2019s own current machine\nstate.\nA machine table dictates which elementary operation the\ncentral processor performs, given its current machine state and the\nsymbol it is currently accessing. The machine table also dictates how\nthe central processor\u2019s machine state changes given those same\nfactors. Thus, the machine table enshrines a finite set of routine\nmechanical instructions governing computation.\n\nTuring translates this informal description into a rigorous\nmathematical model. For more details, see the entry\non Turing machines.\nTuring motivates his approach by reflecting on idealized human\ncomputing agents. Citing finitary limits on our perceptual and\ncognitive apparatus, he argues that any symbolic algorithm executed by\na human can be replicated by a suitable Turing machine. He concludes\nthat the Turing machine formalism, despite its extreme simplicity, is\npowerful enough to capture all humanly executable mechanical\nprocedures over symbolic configurations. Subsequent discussants have\nalmost universally agreed.\nTuring computation is often described as digital rather\nthan analog. What this means is not always so clear, but the\nbasic idea is usually that computation operates over discrete\nconfigurations.  By comparison, many historically important algorithms\noperate over continuously variable configurations. For example,\nEuclidean geometry assigns a large role to ruler-and-compass\nconstructions, which manipulate geometric shapes. For any shape,\none can find another that differs to an arbitrarily small\nextent. Symbolic configurations manipulated by a Turing machine do not\ndiffer to arbitrarily small extent. Turing machines operate over\ndiscrete strings of elements (digits) drawn from a finite\nalphabet. One recurring controversy concerns whether the digital\nparadigm is well-suited to model mental activity or whether an analog\nparadigm would instead be more fitting (MacLennan 2012; Piccinini and\nBahar 2013).\nBesides introducing Turing machines, Turing (1936) proved\nseveral seminal mathematical results involving them. In particular, he\nproved the existence of a universal Turing machine (UTM).\nRoughly speaking, a UTM is a Turing machine that can mimic any other\nTuring machine. One provides the UTM with a symbolic input that codes\nthe machine table for Turing machine M. The UTM\nreplicates M\u2019s behavior, executing instructions\nenshrined by M\u2019s machine table. In that sense, the UTM\nis a programmable general purpose computer. To a first\napproximation, all personal computers are also general purpose: they\ncan mimic any Turing machine, when suitably programmed. The main\ncaveat is that physical computers have finite memory, whereas a Turing\nmachine has unlimited memory. More accurately, then, a personal\ncomputer can mimic any Turing machine until it exhausts its\nlimited memory supply.\nTuring\u2019s discussion helped lay the foundations\nfor computer science, which seeks to design, build, and\nunderstand computing systems. As we know, computer scientists can now\nbuild extremely sophisticated computing machines. All these machines\nimplement something resembling Turing computation, although the\ndetails differ from Turing\u2019s simplified model.\n2. Artificial intelligence\nRapid progress in computer science prompted many, including Turing,\nto contemplate whether we could build a computer capable of\nthought.  Artificial Intelligence (AI) aims to construct\n\u201cthinking machinery\u201d. More precisely, it aims to construct\ncomputing machines that execute core mental tasks such as reasoning,\ndecision-making, problem solving, and so on. During the 1950s and\n1960s, this goal came to seem increasingly realistic (Haugeland\n1985).\nEarly AI research emphasized logic. Researchers sought to\n\u201cmechanize\u201d deductive reasoning. A famous example was\nthe Logic Theorist computer program (Newell and Simon 1956),\nwhich proved 38 of the first 52 theorems from Principia\nMathematica (Whitehead and Russell 1925). In one case, it\ndiscovered a simpler proof than Principia\u2019s.\nEarly success of this kind stimulated enormous interest inside and\noutside the academy. Many researchers predicted that intelligent\nmachines were only a few years away. Obviously, these predictions have\nnot been fulfilled. Intelligent robots do not yet walk among us. Even\nrelatively low-level mental processes such as perception vastly exceed\nthe capacities of current computer programs. When confident\npredictions of thinking machines proved too optimistic, many observers\nlost interest or concluded that AI was a fool\u2019s\nerrand. Nevertheless, the decades have witnessed gradual progress. One\nstriking success was IBM\u2019s Deep Blue, which defeated chess\nchampion Gary Kasparov in 1997. Another major success was the\ndriverless car Stanley (Thrun, Montemerlo, Dahlkamp, et al. 2006),\nwhich completed a 132-mile course in the Mojave Desert, winning the\n2005 Defense Advanced Research Projects Agency (DARPA) Grand\nChallenge. A less flashy success story is the vast improvement in\nspeech recognition algorithms.\nOne problem that dogged early work in AI is uncertainty.\nNearly all reasoning and decision-making operates under conditions of\nuncertainty. For example, you may need to decide whether to go on a\npicnic while being uncertain whether it will rain. Bayesian\ndecision theory is the standard mathematical model of\ninference and decision-making under uncertainty. Uncertainty is codified\nthrough probability. Precise rules dictate how to update\nprobabilities in light of new evidence and how to select actions in\nlight of probabilities and utilities. (See the\nentries Bayes\u2019s theorem\nand normative theories of rational choice: expected utility\n for details.)  In the 1980s and\n1990s, technological and conceptual developments enabled efficient\ncomputer programs that implement or approximate Bayesian inference in\nrealistic scenarios. An explosion of Bayesian AI ensued (Thrun,\nBurgard, and Fox 2006), including the aforementioned advances in\nspeech recognition and driverless vehicles. Tractable algorithms that\nhandle uncertainty are a major achievement of contemporary AI (Murphy 2012), and\npossibly a harbinger of more impressive future progress.\nSome philosophers insist that computers, no matter how\nsophisticated they become, will at best mimic rather\nthan replicate thought. A computer simulation of the weather\ndoes not really rain. A computer simulation of flight does not really\nfly. Even if a computing system could simulate mental activity, why\nsuspect that it would constitute the genuine article?\nTuring (1950) anticipated these worries and tried to defuse\nthem. He proposed a scenario, now called the Turing Test,\nwhere one evaluates whether an unseen interlocutor is a computer or a\nhuman. A computer passes the Turing test if one cannot\ndetermine that it is a computer. Turing proposed that we abandon the\nquestion \u201cCould a computer think?\u201d as hopelessly vague,\nreplacing it with the question \u201cCould a computer pass the Turing\ntest?\u201d.  Turing\u2019s discussion has received considerable\nattention, proving especially influential within AI. Ned Block (1981)\noffers an influential critique. He argues that certain possible\nmachines pass the Turing test even though these machines do not come\nclose to genuine thought or intelligence. See the\nentry the Turing test for discussion of\nBlock\u2019s objection and other issues surrounding the Turing\nTest.\nFor more on AI, see the entry\n logic and artificial intelligence.\n For much more detail, see Russell and\nNorvig (2010).\n3. The classical computational theory of mind\nWarren McCulloch and Walter Pitts (1943) first suggested that\nsomething resembling the Turing machine might provide a good model for\nthe mind.  In the 1960s, Turing computation became central to the\nemerging interdisciplinary initiative cognitive science,\nwhich studies the mind by drawing upon psychology, computer science\n(especially AI), linguistics, philosophy, economics (especially game\ntheory and behavioral economics), anthropology, and neuroscience. The\nlabel classical computational theory of mind (which we will\nabbreviate as CCTM) is now fairly standard. According to CCTM, the\nmind is a computational system similar in important respects to a\nTuring machine, and core mental processes (e.g., reasoning,\ndecision-making, and problem solving) are computations similar in\nimportant respects to computations executed by a Turing machine. These\nformulations are imprecise. CCTM is best seen as a family of views,\nrather than a single well-defined\nview.[1]\nIt is common to describe CCTM as embodying \u201cthe computer\nmetaphor\u201d. This description is doubly misleading.\nFirst, CCTM is better formulated by describing the mind as a\n\u201ccomputing system\u201d or a \u201ccomputational system\u201d\nrather than a \u201ccomputer\u201d. As David Chalmers (2011) notes,\ndescribing a system as a \u201ccomputer\u201d strongly suggests that\nthe system is programmable. As Chalmers also notes, one need\nnot claim that the mind is programmable simply because one regards it\nas a Turing-style computational system. (Most Turing machines are not\nprogrammable.) Thus, the phrase \u201ccomputer metaphor\u201d\nstrongly suggests theoretical commitments that are inessential to\nCCTM.  The point here is not just terminological. Critics of CCTM\noften object that the mind is not a programmable general purpose\ncomputer (Churchland, Koch, and Sejnowski 1990). Since classical\ncomputationalists need not claim (and usually do not claim) that the\nmind is a programmable general purpose computer, the objection is\nmisdirected.\nSecond, CCTM is not intended metaphorically. CCTM does not simply\nhold that the mind is like a computing system. CCTM holds\nthat the mind literally is a computing system. Of course, the\nmost familiar artificial computing systems are made from silicon chips\nor similar materials, whereas the human body is made from flesh and\nblood. But CCTM holds that this difference disguises a more\nfundamental similarity, which we can capture through a Turing-style\ncomputational model. In offering such a model, we prescind from\nphysical details. We attain an abstract computational description that\ncould be physically implemented in diverse ways (e.g., through silicon\nchips, or neurons, or pulleys and levers). CCTM holds that a suitable\nabstract computational model offers a literally true description of\ncore mental processes.\nIt is common to summarize CCTM through the slogan \u201cthe mind\nis a Turing machine\u201d. This slogan is also somewhat misleading,\nbecause no one regards Turing\u2019s precise formalism as a plausible\nmodel of mental activity. The formalism seems too restrictive in\nseveral ways:\n\n Turing machines execute pure symbolic computation. The inputs and\noutputs are symbols inscribed in memory locations. In contrast, the\nmind receives sensory input (e.g., retinal stimulations) and\nproduces motor output (e.g., muscle activations). A complete\ntheory must describe how mental computation interfaces with sensory\ninputs and motor outputs.\n A Turing machine has infinite discrete memory capacity. Ordinary\nbiological systems have finite memory capacity. A plausible\npsychological model must replace the infinite memory store with a\nlarge but finite memory store\n Modern computers have random access memory: addressable\nmemory locations that the central processor can directly\naccess. Turing machine memory is not addressable. The central\nprocessor can access a location only by sequentially accessing\nintermediate locations. Computation without addressable memory is\nhopelessly inefficient. For that reason, C.R.  Gallistel and Adam King\n(2009) argue that addressable memory gives a better model of the mind\nthan non-addressable memory.\n A Turing machine has a central processor that\noperates serially, executing one instruction at a time. Other\ncomputational formalisms relax this assumption, allowing multiple\nprocessing units that operate in parallel. Classical\ncomputationalists can allow parallel computations (Fodor and Pylyshyn\n1988; Gallistel and King 2009: 174). See Gandy (1980) and Sieg (2009)\nfor general mathematical treatments that encompass both serial and\nparallel computation.\n Turing computation is deterministic: total computational\nstate determines subsequent computational state. One might instead\nallow stochastic computations. In a stochastic model, current\nstate does not dictate a unique next state. Rather, there is a certain\nprobability that the machine will transition from one state to\nanother.\n\nCCTM claims that mental activity is \u201cTuring-style\ncomputation\u201d, allowing these and other departures from\nTuring\u2019s own formalism.\n3.1 Machine functionalism\n Hilary Putnam (1967) introduced CCTM into philosophy. He\ncontrasted his position with logical behaviorism\nand type-identity theory. Each position purports to\nreveal the nature of mental states, including propositional attitudes\n(e.g., beliefs), sensations (e.g., pains), and emotions (e.g.,\nfear). According to logical behaviorism, mental states are behavioral\ndispositions.  According to type-identity theory, mental states are\nbrain states.  Putnam advances an opposing functionalist\nview, on which mental states are functional states. According to\nfunctionalism, a system has a mind when the system has a \nsuitable functional organization. Mental states are states\nthat play appropriate roles in the system\u2019s functional\norganization. Each mental state is individuated by its interactions\nwith sensory input, motor output, and other mental states.\nFunctionalism offers notable advantages over logical behaviorism\nand type-identity theory:\n\n Behaviorists want to associate each mental state with a\ncharacteristic pattern of behavior\u2014a hopeless task, because\nindividual mental states do not usually have characteristic behavioral\neffects. Behavior almost always results from distinct mental states\noperating together (e.g., a belief and a desire).  Functionalism\navoids this difficulty by individuating mental states through\ncharacteristic relations not only to sensory input and behavior but\nalso to one another.\n Type-identity theorists want to associate each mental state with\na characteristic physical or neurophysiological state. Putnam casts\nthis project into doubt by arguing that mental states are multiply\nrealizable: the same mental state can be realized by diverse\nphysical systems, including not only terrestrial creatures but also\nhypothetical creatures (e.g., a silicon-based Martian). Functionalism\nis tailor-made to accommodate multiple realizability.  According to\nfunctionalism, what matters for mentality is a pattern of\norganization, which could be physically realized in many different\nways. See the entry \nmultiple realizability\n for further discussion of this argument.\n\nPutnam defends a brand of functionalism now called machine\nfunctionalism. He emphasizes probabilistic automata,\nwhich are similar to Turing machines except that transitions between\ncomputational states are stochastic. He proposes that mental activity\nimplements a probabilistic automaton and that particular mental states\nare machine states of the automaton\u2019s central processor. The\nmachine table specifies an appropriate functional organization, and it\nalso specifies the role that individual mental states play within that\nfunctional organization. In this way, Putnam combines functionalism\nwith CCTM.\nMachine functionalism faces several problems. One problem,\nhighlighted by Ned Block and Jerry Fodor (1972), concerns\nthe productivity of thought. A normal human can entertain a\npotential infinity of propositions. Machine functionalism identifies\nmental states with machine states of a probabilistic automaton. Since\nthere are only finitely many machine states, there are not enough\nmachine states to pair one-one with possible mental states of a normal\nhuman. Of course, an actual human will only ever entertain finitely\nmany propositions. However, Block and Fodor contend that this\nlimitation reflects limits on lifespan and memory, rather than (say)\nsome psychological law that restricts the class of humanly\nentertainable propositions. A probabilistic automaton is endowed with\nunlimited time and memory capacity yet even still has only finitely\nmany machine states. Apparently, then, machine functionalism\nmislocates the finitary limits upon human cognition.\nAnother problem for machine functionalism, also highlighted by\nBlock and Fodor (1972), concerns the systematicity of\nthought. An ability to entertain one proposition is correlated\nwith an ability to think other propositions. For example, someone who\ncan entertain the thought that John loves Mary can also\nentertain the thought that Mary loves John. Thus, there seem\nto be systematic relations between mental states. A good theory should\nreflect those systematic relations. Yet machine functionalism\nidentifies mental states with unstructured machines states, which lack\nthe requisite systematic relations to another. For that reason,\nmachine functionalism does not explain systematicity. In response to\nthis objection, machine functionalists might deny that they are\nobligated to explain systematicity. Nevertheless, the objection\nsuggests that machine functionalism neglects essential features of\nhuman mentality. A better theory would explain those features in a\nprincipled way.\nWhile the productivity and systematicity objections to machine\nfunctionalism are perhaps not decisive, they provide strong impetus to\npursue an improved version of CCTM. See Block (1978) for additional\nproblems facing machine functionalism and functionalism more\ngenerally.\n3.2 The representational theory of mind\nFodor (1975, 1981, 1987, 1990, 1994, 2008) advocates a version of\nCCTM that accommodates systematicity and productivity much more\nsatisfactorily. He shifts attention to the symbols\nmanipulated during Turing-style computation.\nAn old view, stretching back at least to William of\nOckham\u2019s Summa Logicae, holds that thinking occurs in\na language of thought (sometimes\ncalled Mentalese). Fodor revives this view. He postulates a\nsystem of mental representations, including both primitive\nrepresentations and complex representations formed from primitive\nrepresentations. For example, the primitive Mentalese words JOHN,\nMARY, and LOVES can combine to form the Mentalese sentence JOHN LOVES\nMARY. Mentalese is compositional: the meaning of a complex\nMentalese expression is a function of the meanings of its parts and\nthe way those parts are combined. Propositional attitudes are\nrelations to Mentalese symbols. Fodor calls this view the\nrepresentational theory of mind (RTM). Combining RTM\nwith CCTM, he argues that mental activity involves Turing-style\ncomputation over the language of thought. Mental computation stores\nMentalese symbols in memory locations, manipulating those symbols in\naccord with mechanical rules.\nA prime virtue of RTM is how readily it accommodates productivity\nand systematicity:\nProductivity: RTM postulates a finite set of primitive\nMentalese expressions, combinable into a potential infinity of complex\nMentalese expressions. A thinker with access to primitive Mentalese\nvocabulary and Mentalese compounding devices has the potential to\nentertain an infinity of Mentalese expressions. She therefore has the\npotential to instantiate infinitely many propositional attitudes\n(neglecting limits on time and memory).\nSystematicity: According to RTM, there are systematic\nrelations between which propositional attitudes a thinker can\nentertain. For example, suppose I can think that John loves Mary.\nAccording to RTM, my doing so involves my standing in some\nrelation R to a Mentalese sentence JOHN LOVES MARY, composed\nof Mentalese words JOHN, LOVES, and MARY combined in the right way. If\nI have this capacity, then I also have the capacity to stand in\nrelation R to the distinct Mentalese sentence MARY LOVES\nJOHN, thereby thinking that Mary loves John. So the capacity to think\nthat John loves Mary is systematically related to the capacity to\nthink that Mary loves John.\nBy treating propositional attitudes as relations to complex mental\nsymbols, RTM explains both productivity and systematicity.\nCCTM+RTM differs from machine functionalism in several other\nrespects.  First, machine functionalism is a theory of mental\nstates in general, while RTM is only a theory of\npropositional attitudes.  Second, proponents of CCTM+RTM need not say\nthat propositional attitudes are individuated functionally. As Fodor\n(2000: 105, fn. 4) notes, we must\ndistinguish computationalism (mental processes are\ncomputational) from functionalism (mental states are\nfunctional states). Machine functionalism endorses both doctrines.\nCCTM+RTM endorses only the first. Unfortunately, many philosophers\nstill mistakenly assume that computationalism entails a functionalist\napproach to propositional attitudes (see Piccinini 2004 for\ndiscussion).\nPhilosophical discussion of RTM tends to focus mainly\non high-level human thought, especially belief and\ndesire. However, CCTM+RTM is applicable to a much wider range of\nmental states and processes. Many cognitive scientists apply it to\nnon-human animals. For example, Gallistel and King (2009) apply it to\ncertain invertebrate phenomena (e.g., honeybee navigation). Even\nconfining attention to humans, one can apply CCTM+RTM\nto subpersonal processing. Fodor (1983) argues that\nperception involves a subpersonal \u201cmodule\u201d that converts\nretinal input into Mentalese symbols and then performs computations\nover those symbols. Thus, talk about a language of thought is\npotentially misleading, since it suggests a non-existent restriction\nto higher-level mental activity.\nAlso potentially misleading is the description of Mentalese as\na language, which suggests that all Mentalese symbols\nresemble expressions in a natural language. Many philosophers,\nincluding Fodor, sometimes seem to endorse that position. However,\nthere are possible non-propositional formats for Mentalese\nsymbols. Proponents of CCTM+RTM can adopt a pluralistic line, allowing\nmental computation to operate over items akin to images, maps,\ndiagrams, or other non-propositional representations (Johnson-Laird\n2004: 187; McDermott 2001: 69; Pinker 2005: 7; Sloman 1978:\n144\u2013176). The pluralistic line seems especially plausible as\napplied to subpersonal processes (such as perception) and non-human\nanimals. Michael Rescorla (2009a,b) surveys research on cognitive\nmaps (Tolman 1948; O\u2019Keefe and Nadel 1978; Gallistel 1990),\nsuggesting that some animals may navigate by computing over mental\nrepresentations more similar to maps than sentences. Elisabeth Camp\n(2009), citing research\non baboon social interaction (Cheney and Seyfarth\n2007), argues that\nbaboons may encode social dominance relations through non-sentential\ntree-structured representations.\nCCTM+RTM is schematic. To fill in the schema, one must provide\ndetailed computational models of specific mental processes. A complete\nmodel will:\n\n describe the Mentalese symbols manipulated by the process;\n isolate elementary operations that manipulate the symbols\n(e.g., inscribing a symbol in a memory location); and\n delineate mechanical rules governing application of elementary\noperations.\n\nBy providing a detailed computational model, we decompose a complex\nmental process into a series of elementary operations governed by\nprecise, routine instructions.\nCCTM+RTM remains neutral in the traditional debate between\nphysicalism and substance dualism. A Turing-style model proceeds at a\nvery abstract level, not saying whether mental computations are\nimplemented by physical stuff or Cartesian soul-stuff (Block 1983:\n522). In practice, all\nproponents of CCTM+RTM embrace a broadly physicalist outlook. They\nhold that mental computations are implemented not by soul-stuff but\nrather by the brain. On this view, Mentalese symbols are realized by\nneural states, and computational operations over Mentalese symbols are\nrealized by neural processes. Ultimately, physicalist proponents of\nCCTM+RTM must produce empirically well-confirmed theories that explain\nhow exactly neural activity implements Turing-style computation. As\nGallistel and King (2009) emphasize, we do not currently have such\ntheories\u2014though see Zylberberg, Dehaene, Roelfsema, and Sigman\n(2011) for some speculations.\nFodor (1975) advances CCTM+RTM as a foundation for cognitive\nscience.  He discusses mental phenomena such as decision-making,\nperception, and linguistic processing. In each case, he maintains, our\nbest scientific theories postulate Turing-style computation over\nmental representations. In fact, he argues that our only\nviable theories have this form. He concludes that CCTM+RTM is\n\u201cthe only game in town\u201d. Many cognitive scientists argue\nalong similar lines. C.R. Gallistel and Adam King (2009), Philip\nJohnson-Laird (1988), Allen Newell and Herbert Simon (1976), and Zenon\nPylyshyn (1984) all recommend Turing-style computation over mental\nsymbols as the best foundation for scientific theorizing about the\nmind.\n4. Neural networks\n In the 1980s, connectionism emerged as a prominent rival to\nclassical computationalism. Connectionists draw inspiration from\nneurophysiology rather than logic and computer science. They employ\ncomputational models, neural networks, that differ\nsignificantly from Turing-style models. A neural network is a\ncollection of interconnected nodes. Nodes fall into three\ncategories: input nodes, output nodes,\nand hidden nodes (which mediate between input and output\nnodes). Nodes have activation values, given by real numbers. One node\ncan bear a weighted connection to another node, also given by\na real number. Activations of input nodes are determined exogenously:\nthese are the inputs to computation.  Total input activation\nof a hidden or output node is a weighted sum of the activations of\nnodes feeding into it. Activation of a hidden or output node is a\nfunction of its total input activation; the particular function varies\nwith the network. During neural network computation, waves of\nactivation propagate from input nodes to output nodes, as determined\nby weighted connections between nodes.\nIn a feedforward network, weighted connections flow only\nin one direction. Recurrent networks have feedback loops, in\nwhich connections emanating from hidden units circle back to hidden\nunits. Recurrent networks are less mathematically tractable than\nfeedforward networks. However, they figure crucially in psychological\nmodeling of various phenomena, such as phenomena that involve some\nkind of memory (Elman 1990).\nWeights in a neural network are typically mutable, evolving in\naccord with a learning algorithm. The literature offers\nvarious learning algorithms, but the basic idea is usually to adjust\nweights so that actual outputs gradually move closer to\nthe target outputs one would expect for the relevant\ninputs. The backpropagation algorithm is a widely used\nalgorithm of this kind (Rumelhart, Hinton, and Williams 1986).\nConnectionism traces back to McCulloch and Pitts (1943), who\nstudied networks of interconnected logic gates (e.g.,\nAND-gates and OR-gates). One can view a network of logic gates as a\nneural network, with activations confined to two values (0 and 1) and\nactivation functions given by the usual truth-functions. McCulloch and\nPitts advanced logic gates as idealized models of individual\nneurons. Their discussion exerted a profound influence on computer\nscience (von Neumann 1945). Modern digital computers are simply\nnetworks of logic gates. Within cognitive science, however,\nresearchers usually focus upon networks whose elements are more\n\u201cneuron-like\u201d than logic gates. In particular, modern-day\nconnectionists typically emphasize analog neural networks whose nodes\ntake continuous rather than discrete activation values. Some authors\neven use the phrase \u201cneural network\u201d so that it\nexclusively denotes such networks.\nNeural networks received relatively scant attention from cognitive\nscientists during the 1960s and 1970s, when Turing-style models\ndominated. The 1980s witnessed a huge resurgence of interest in neural\nnetworks, especially analog neural networks, with the\ntwo-volume Parallel Distributed Processing (Rumelhart, McClelland, and the PDP research group, 1986; McClelland, Rumelhart, and the PDP research group, 1987) serving as a\nmanifesto.  Researchers constructed connectionist models of diverse\nphenomena: object recognition, speech perception, sentence\ncomprehension, cognitive development, and so on. Impressed by\nconnectionism, many researchers concluded that CCTM+RTM was no longer\n\u201cthe only game in town\u201d.\n\nIn the 2010s, a class of computational models known as deep neural\nnetworks became quite popular (Krizhevsky, Sutskever, and Hinton\n2012; LeCun, Bengio, and Hinton 2015). These models are neural\nnetworks with multiple layers of hidden nodes (sometimes hundreds of\nsuch layers). Deep neural networks\u2014trained on large data sets\nthrough one or another learning algorithm (usually\nbackpropagation)\u2014have achieved great success in many areas of\nAI, including object recognition and strategic game-playing. Deep\nneural networks are now widely deployed in commercial applications,\nand they are the focus of extensive ongoing investigation within both\nacademia and industry. Researchers have also begun using them to model\nthe mind (e.g. Marblestone, Wayne, and Kording 2016; Kriegeskorte\n2015).\n\nFor a detailed overview of neural networks, see Haykin (2008). For a\nuser-friendly introduction, with an emphasis on psychological\napplications, see Marcus (2001). For a philosophically oriented\nintroduction to deep neural networks, see Buckner (2019).\n4.1 Relation between neural networks and classical computation\nNeural networks have a very different \u201cfeel\u201d than\nclassical (i.e., Turing-style) models. Yet classical computation and\nneural network computation are not mutually exclusive:\n\n One can implement a neural network in a classical\nmodel. Indeed, every neural network ever physically constructed\nhas been implemented on a digital computer.\n One can implement a classical model in a neural\nnetwork. Modern digital computers implement Turing-style\ncomputation in networks of logic gates.  Alternatively, one can\nimplement Turing-style computation using an analog recurrent neural\nnetwork whose nodes take continuous activation values (Graves, Wayne,\nand Danihelka 2014, Other Internet Resources; Siegelmann and Sontag\n1991; Siegelmann and Sontag 1995).\n\nAlthough some researchers suggest a fundamental opposition between\nclassical computation and neural network computation, it seems more\naccurate to identify two modeling traditions that overlap in certain\ncases but not others (cf. Boden 1991; Piccinini 2008b). In this\nconnection, it is also worth noting that classical computationalism\nand connectionist computationalism have their common origin in the\nwork of McCulloch and Pitts.\nPhilosophers often say that classical computation involves\n\u201crule-governed symbol manipulation\u201d while neural network\ncomputation is non-symbolic. The intuitive picture is that\n\u201cinformation\u201d in neural networks is globally distributed\nacross the weights and activations, rather than concentrated in\nlocalized symbols. However, the notion of \u201csymbol\u201d itself\nrequires explication, so it is often unclear what theorists mean by\ndescribing computation as symbolic versus non-symbolic. As mentioned\nin \u00a71, the Turing formalism places very few\nconditions on \u201csymbols\u201d. Regarding primitive symbols,\nTuring assumes just that there are finitely many of them and that they\ncan be inscribed in read/write memory locations. Neural networks can\nalso manipulate symbols satisfying these two conditions: as just\nnoted, one can implement a Turing-style model in a neural network.\nMany discussions of the symbolic/non-symbolic dichotomy employ a\nmore robust notion of \u201csymbol\u201d. On the more robust\napproach, a symbol is the sort of thing that represents a subject\nmatter. Thus, something is a symbol only if it has semantic or\nrepresentational properties. If we employ this more robust notion of\nsymbol, then the symbolic/non-symbolic distinction cross-cuts the\ndistinction between Turing-style computation and neural network\ncomputation. A Turing machine need not employ symbols in the more\nrobust sense. As far as the Turing formalism goes, symbols manipulated\nduring Turing computation need not have representational properties\n(Chalmers 2011). Conversely, a neural network can manipulate symbols\nwith representational properties. Indeed, an analog neural network can\nmanipulate symbols that have a combinatorial syntax and semantics\n(Horgan and Tienson 1996; Marcus 2001).\nFollowing Steven Pinker and Alan Prince (1988), we may distinguish\nbetween eliminative connectionism and implementationist\nconnectionism.\nEliminative connectionists advance connectionism as a rival to\nclassical computationalism. They argue that the Turing formalism is\nirrelevant to psychological explanation. Often, though not always,\nthey seek to revive the associationist tradition in\npsychology, a tradition that CCTM had forcefully challenged. Often,\nthough not always, they attack the mentalist, nativist linguistics\npioneered by Noam Chomsky (1965). Often, though not always, they\nmanifest overt hostility to the very notion of mental\nrepresentation. But the defining feature of eliminative connectionism\nis that it uses neural networks as replacements for\nTuring-style models. Eliminative connectionists view the mind as a\ncomputing system of a radically different kind than the Turing\nmachine. A few authors explicitly espouse eliminative connectionism\n(Churchland 1989; Rumelhart and McClelland\n1986; Horgan and Tienson\n1996), and many others incline towards it.\nImplementationist connectionism is a more ecumenical position. It\nallows a potentially valuable role for both Turing-style\nmodels and neural networks, operating harmoniously at\ndifferent levels of description (Marcus 2001; Smolensky 1988). A\nTuring-style model is higher-level, whereas a neural network model is\nlower-level.  The neural network illuminates how the brain implements\nthe Turing-style model, just as a description in terms of logic gates\nilluminates how a personal computer executes a program in a high-level\nprogramming language.\n4.2 Arguments for connectionism\nConnectionism excites many researchers because of the analogy\nbetween neural networks and the brain. Nodes resemble neurons, while\nconnections between nodes resemble synapses. Connectionist modeling\ntherefore seems more \u201cbiologically plausible\u201d than\nclassical modeling. A connectionist model of a psychological\nphenomenon apparently captures (in an idealized way) how\ninterconnected neurons might generate the phenomenon.\n\nWhen evaluating the argument from biological plausibility, one should\nrecognize that neural networks vary widely in how closely they match\nactual brain activity. Many networks that figure prominently in\nconnectionist writings are not so biologically plausible (Bechtel and\nAbrahamsen 2002: 341\u2013343; Berm\u00fadez 2010: 237\u2013239;\nClark 2014: 87\u201389; Harnish 2002: 359\u2013362). A few\nexamples:\n\n Real neurons are much more heterogeneous\nthan the interchangeable nodes that figure in typical connectionist\nnetworks.\n Real neurons emit discrete spikes (action potentials) as\noutputs. But the nodes that figure in many prominent neural networks,\nincluding the best known deep neural networks, instead have continuous\noutputs.\n The backpropagation algorithm requires that weights between nodes\ncan vary between excitatory and inhibitory, yet actual synapses cannot\nso vary (Crick and Asanuma 1986). Moreover, the algorithm assumes\ntarget outputs supplied exogenously by modelers who know the\ndesired answer. In that sense, learning\nis supervised. Very little learning in actual biological\nsystems involves anything resembling supervised training.\n\n\nOn the other hand, some neural networks are more biologically\nrealistic (Buckner and Garson 2019; Illing, Gerstner, and Brea\n2019). For instance, there are neural networks that replace\nbackpropagation with more realistic learning algorithms, such as a\nreinforcement learning algorithm (Pozzi, Boht\u00e9, and Roelfsema\n2019, Other Internet Resources) or an unsupervised learning algorithm\n(Krotov and Hopfield 2019). There are also neural networks whose nodes\noutput discrete spikes roughly akin to those emitted by real neurons\nin the brain (Maass 1996; Buesing, Bill, Nessler, and Maass 2011).\nEven when a neural network is not biologically plausible, it may\nstill be more biologically plausible than classical\nmodels. Neural networks certainly seem closer than Turing-style\nmodels, in both details and spirit, to neurophysiological\ndescription. Many cognitive scientists worry that CCTM reflects a\nmisguided attempt at imposing the architecture of digital computers\nonto the brain. Some doubt that the brain implements anything\nresembling digital computation, i.e., computation over discrete\nconfigurations of digits (Piccinini and Bahar 2013). Others doubt that\nbrains display clean Turing-style separation between central processor\nand read/write memory (Dayan 2009). Neural networks fare better on\nboth scores: they do not require computation over discrete\nconfigurations of digits, and they do not postulate a clean separation\nbetween central processor and read/write memory.\nClassical computationalists typically reply that it is premature to\ndraw firm conclusions based upon biological plausibility, given how\nlittle we understand about the relation between neural, computational,\nand cognitive levels of description (Gallistel and King 2009; Marcus\n2001). Using measurement techniques such as cell recordings and\nfunctional magnetic resonance imaging (fMRI), and drawing upon\ndisciplines as diverse as physics, biology, AI, information theory,\nstatistics, graph theory, and dynamical systems theory,\nneuroscientists have accumulated substantial knowledge about the brain\nat varying levels of granularity (Zednik 2019). We now know quite a\nlot about individual neurons, about how neurons interact within neural\npopulations, about the localization of mental activity in cortical\nregions (e.g. the visual cortex), and about interactions among\ncortical regions. Yet we still have a tremendous amount to learn about\nhow neural tissue accomplishes the tasks that it surely accomplishes:\nperception, reasoning, decision-making, language acquisition, and so\non. Given our present state of relative ignorance, it would be rash to\ninsist that the brain does not implement anything resembling Turing\ncomputation.\nConnectionists offer numerous further arguments that we should\nemploy connectionist models instead of, or in addition to, classical\nmodels.  See the entry connectionism\nfor an overview. For purposes of this entry, we mention two additional\narguments.\nThe first argument emphasizes learning (Bechtel and\nAbrahamsen 2002: 51). A vast range of cognitive phenomena involve\nlearning from experience. Many connectionist models are explicitly\ndesigned to model learning, through backpropagation or some other\nalgorithm that modifies the weights between nodes. By contrast,\nconnectionists often complain that there are no good classical models\nof learning. Classical computationalists can respond by citing\nperceived defects of connectionist learning algorithms (e.g., the\nheavy reliance of backpropagation upon supervised training). Classical\ncomputationalists can also cite Bayesian decision theory, which models\nlearning as probabilistic updating. More specifically, classical\ncomputationalists can cite the achievements of Bayesian cognitive\nscience, which uses Bayesian decision theory to construct\nmathematical models of mental activity (Ma 2019). Over the past few\ndecades, Bayesian cognitive science has accrued many explanatory\nsuccesses. This impressive track record suggests that some mental\nprocesses are Bayesian or approximately Bayesian (Rescorla\n2020). Moreover, the advances mentioned\nin \u00a72 show how classical computing systems\ncan execute or at least approximately execute Bayesian updating in\nvarious realistic scenarios. These developments provide hope that\nclassical computation can model many important cases of learning.\nThe second argument emphasizes speed of\ncomputation. Neurons are much slower than silicon-based\ncomponents of digital computers. For this reason, neurons could not\nexecute serial computation quickly enough to match rapid human\nperformance in perception, linguistic comprehension, decision-making,\netc. Connectionists maintain that the only viable solution is to\nreplace serial computation with a \u201cmassively parallel\u201d\ncomputational architecture\u2014precisely what neural networks\nprovide (Feldman and Ballard 1982; Rumelhart 1989). However, this\nargument is only effective against classical computationalists who\ninsist upon serial processing. As noted\nin \u00a73, some Turing-style models\ninvolve parallel processing. Many classical computationalists are\nhappy to allow \u201cmassively parallel\u201d mental computation,\nand the argument gains no traction against these researchers. That\nbeing said, the argument highlights an important question that any\ncomputationalist\u2014whether classical, connectionist, or\notherwise\u2014must address: How does a brain built from relatively\nslow neurons execute sophisticated computations so quickly? Neither\nclassical nor connectionist computationalists have answered this\nquestion satisfactorily (Gallistel and King 2009: 174 and 265).\n4.3 Systematicity and productivity\nFodor and Pylyshyn (1988) offer a widely discussed critique of\neliminativist connectionism. They argue that systematicity and\nproductivity fail in connectionist models, except when the\nconnectionist model implements a classical model. Hence, connectionism\ndoes not furnish a viable alternative to CCTM. At best, it supplies a\nlow-level description that helps bridge the gap between Turing-style\ncomputation and neuroscientific description.\nThis argument has elicited numerous replies and\ncounter-replies. Some argue that neural networks can exhibit\nsystematicity without implementing anything like classical\ncomputational architecture (Horgan and Tienson 1996; Chalmers 1990;\nSmolensky 1991; van Gelder 1990). Some argue that Fodor and Pylyshyn\nvastly exaggerate systematicity (Johnson 2004) or productivity\n(Rumelhart and McClelland 1986), especially for non-human animals\n(Dennett 1991).  These issues, and many others raised by Fodor and\nPylyshyn\u2019s argument, have been thoroughly investigated in the\nliterature.  For further discussion, see Bechtel and Abrahamsen (2002:\n156\u2013199), Berm\u00fadez (2005: 244\u2013278), Chalmers\n(1993), Clark (2014: 84\u201386), and the encyclopedia entries on\n the language of thought hypothesis\n and on \n connectionism.\nGallistel and King (2009) advance a related but distinct\nproductivity argument. They emphasize productivity of mental\ncomputation, as opposed to productivity of mental\nstates. Through detailed empirical case studies, they argue that\nmany non-human animals can extract, store, and retrieve detailed\nrecords of the surrounding environment. For example, the Western scrub\njay records where it cached food, what kind of food it cached in each\nlocation, when it cached the food, and whether it has depleted a given\ncache (Clayton, Emery, and Dickinson 2006). The jay can access these\nrecords and exploit them in diverse computations: computing whether a\nfood item stored in some cache is likely to have decayed; computing a\nroute from one location to another; and so on. The number of possible\ncomputations a jay can execute is, for all practical purposes,\ninfinite.\nCCTM explains the productivity of mental computation by positing a\ncentral processor that stores and retrieves symbols in addressable\nread/write memory. When needed, the central processor can retrieve\narbitrary, unpredicted combinations of symbols from memory. In\ncontrast, Gallistel and King argue, connectionism has difficulty\naccommodating the productivity of mental computation. Although\nGallistel and King do not carefully distinguish between eliminativist\nand implementationist connectionism, we may summarize their argument\nas follows:\n\n Eliminativist connectionism cannot explain how organisms combine\nstored memories (e.g., cache locations) for computational purposes\n(e.g., computing a route from one cache to another). There are a\nvirtual infinity of possible combinations that might be useful, with\nno predicting in advance which pieces of information must be combined\nin future computations. The only computationally tractable solution is\nsymbol storage in readily accessible read/write memory\nlocations\u2014a solution that eliminativist connectionists\nreject.\n Implementationist connectionists can postulate symbol storage in\nread/write memory, as implemented by a neural\nnetwork. However, the mechanisms that connectionists usually\npropose for implementing memory are not plausible. Existing proposals\nare mainly variants upon a single idea: a recurrent neural network\nthat allows reverberating activity to travel around a loop (Elman\n1990). There are many reasons why the reverberatory loop model is\nhopeless as a theory of long-term memory.  For example, noise in the\nnervous system ensures that signals would rapidly degrade in a few\nminutes. Implementationist connectionists have thus far offered no\nplausible model of read/write \nmemory.[2]\n\nGallistel and King conclude that CCTM is much better suited than\neither eliminativist or implementationist connectionism to explain a\nvast range of cognitive phenomena.\nCritics attack this new productivity argument from various angles,\nfocusing mainly on the empirical case studies adduced by Gallistel and\nKing. Peter Dayan (2009), John Donahoe (2010), and Christopher Mole\n(2014) argue that biologically plausible neural network models can\naccommodate at least some of the case studies. Dayan and Donahoe argue\nthat empirically adequate neural network models can dispense with\nanything resembling read/write memory. Mole argues that, in certain\ncases, empirically adequate neural network models\ncan implement the read/write memory mechanisms posited by\nGallistel and King. Debate on these fundamental issues seems poised to\ncontinue well into the future.\n4.4 Computational neuroscience\n Computational neuroscience describes the nervous system\nthrough computational models. Although this research program is\ngrounded in mathematical modeling of individual neurons, the\ndistinctive focus of computational neuroscience is systems of\ninterconnected neurons. Computational neuroscience usually models\nthese systems as neural networks. In that sense, it is a variant,\noff-shoot, or descendant of connectionism. However, most computational\nneuroscientists do not self-identify as connectionists. There are\nseveral differences between connectionism and computational\nneuroscience:\n\n Neural networks employed by computational neuroscientists are\nmuch more biologically realistic than those employed by\nconnectionists. The computational neuroscience literature is filled\nwith talk about firing rates, action potentials, tuning curves,\netc. These notions play at best a limited role in connectionist\nresearch, such as most of the research canvassed in (Rogers and\nMcClelland 2014).\n Computational neuroscience is driven in large measure by\nknowledge about the brain, and it assigns huge importance to\nneurophysiological data (e.g., cell recordings).  Connectionists place\nmuch less emphasis upon such data. Their research is primarily driven\nby behavioral data (although more recent connectionist writings cite\nneurophysiological data with somewhat greater frequency).\n Computational neuroscientists usually regard individual nodes in\nneural networks as idealized descriptions of actual\nneurons. Connectionists usually instead regard nodes\nas neuron-like processing units (Rogers and McClelland 2014)\nwhile remaining neutral about how exactly these units map onto actual\nneurophysiological entities.\n\nOne might say that computational neuroscience is concerned mainly\nwith neural computation (computation by systems of neurons),\nwhereas connectionism is concerned mainly with abstract computational\nmodels inspired by neural computation. But the boundaries\nbetween connectionism and computational neuroscience are admittedly\nsomewhat porous. For an overview of computational neuroscience, see\nTrappenberg (2010) or Miller (2018).\nSerious philosophical engagement with neuroscience dates back at\nleast to Patricia Churchland\u2019s Neurophilosophy\n(1986). As computational neuroscience matured, Churchland became one\nof its main philosophical champions (Churchland, Koch, and Sejnowski\n1990; Churchland and Sejnowski 1992). She was joined by Paul\nChurchland (1995, 2007) and others (Eliasmith 2013; Eliasmith and\nAnderson 2003; Piccinini and Bahar 2013; Piccinini and Shagrir\n2014). All these authors hold that theorizing about mental computation\nshould begin with the brain, not with Turing machines or other\ninappropriate tools drawn from logic and computer science. They also\nhold that neural network modeling should strive for greater biological\nrealism than connectionist models typically attain. Chris Eliasmith\n(2013) develops this neurocomputational viewpoint through\nthe Neural Engineering Framework, which supplements\ncomputational neuroscience with tools drawn from control theory\n(Brogan 1990). He aims to \u201creverse engineer\u201d the brain,\nbuilding large-scale, biologically plausible neural network models of\ncognitive phenomena.\nComputational neuroscience differs in a crucial respect from CCTM\nand connectionism: it abandons multiply realizability. Computational\nneuroscientists cite specific neurophysiological properties and\nprocesses, so their models do not apply equally well to (say) a\nsufficiently different silicon-based creature. Thus, computational\nneuroscience sacrifices a key feature that originally attracted\nphilosophers to CTM. Computational neuroscientists will respond that\nthis sacrifice is worth the resultant insight into neurophysiological\nunderpinnings. But many computationalists worry that, by focusing too\nmuch on neural underpinnings, we risk losing sight of the cognitive\nforest for the neuronal trees. Neurophysiological details are\nimportant, but don\u2019t we also need an additional abstract level\nof computational description that prescinds from such details?\nGallistel and King (2009) argue that a myopic fixation upon what we\ncurrently know about the brain has led computational neuroscience to\nshortchange core cognitive phenomena such as navigation, spatial and\ntemporal learning, and so on. Similarly, Edelman (2014) complains that\nthe Neural Engineering Framework substitutes a blizzard of\nneurophysiological details for satisfying psychological\nexplanations.\n\nPartly in response to such worries, some researchers propose an\nintegrated cognitive computational neuroscience that connects\npsychological theories with neural implementation mechanisms\n(Naselaris et al. 2018; Kriegeskorte and Douglas 2018). The basic idea\nis to use neural network models to illuminate how mental processes are\ninstantiated in the brain, thereby grounding multiply realizable\ncognitive description in the neurophysiological. A good example is\nrecent work on neural implementation of Bayesian inference (e.g.,\nPouget et al. 2013; Orhan and Ma 2017; Aitchison and Lengyel\n2016). Researchers articulate (multiply realizable) Bayesian models of\nvarious mental processes; they construct biologically plausible neural\nnetworks that execute or approximately execute the posited Bayesian\ncomputations; and they evaluate how well these neural network models\nfit with neurophysiological data.\nDespite the differences between connectionism and computational\nneuroscience, these two movements raise many similar issues. In\nparticular, the dialectic from \u00a74.4\nregarding systematicity and productivity arises in similar form.\n5. Computation and representation\nPhilosophers and cognitive scientists use the term\n\u201crepresentation\u201d in diverse ways. Within philosophy, the\nmost dominant usage ties representation to intentionality, i.e., the\n\u201caboutness\u201d of mental states. Contemporary philosophers\nusually elucidate intentionality by invoking representational\ncontent. A representational mental state has a content that\nrepresents the world as being a certain way, so we can ask whether the\nworld is indeed that way. Thus, representationally contentful mental\nstates are semantically evaluable with respect to properties\nsuch as truth, accuracy, fulfillment, and so on. To illustrate:\n\n Beliefs are the sorts of things that can be true or false. My\nbelief that Emmanuel Macron is French is true if Emmanuel\nMacron is French, false if he is not.\n Perceptual states are the sorts of things that can be accurate or\ninaccurate. My perceptual experience as of a red sphere is\naccurate only if a red sphere is before me.\n Desires are the sorts of things that can fulfilled or\nthwarted. My desire to eat chocolate is fulfilled if I eat\nchocolate, thwarted if I do not eat chocolate.\n\nBeliefs have truth-conditions (conditions under which they are\ntrue), perceptual states have accuracy-conditions (conditions under\nwhich they are accurate), and desires have fulfillment-conditions\n(conditions under which they are fulfilled).\nIn ordinary life, we frequently predict and explain behavior by\ninvoking beliefs, desires, and other representationally contentful\nmental states. We identify these states through their representational\nproperties. When we say \u201cFrank believes that Emmanuel Macron is\nFrench\u201d, we specify the condition under which Frank\u2019s\nbelief is true (namely, that Emmanuel Macron is French). When we say\n\u201cFrank wants to eat chocolate\u201d, we specify the condition\nunder which Frank\u2019s desire is fulfilled (namely, that Frank eats\nchocolate). So folk psychology assigns a central role\nto intentional descriptions, i.e., descriptions that identify\nmental states through their representational properties. Whether\nscientific psychology should likewise employ intentional descriptions\nis a contested issue within contemporary philosophy of mind.\nIntentional realism is realism regarding\nrepresentation. At a minimum, this position holds that\nrepresentational properties are genuine aspects of mentality. Usually,\nit is also taken to hold that scientific psychology should freely\nemploy intentional descriptions when appropriate. Intentional realism\nis a popular position, advocated by Tyler Burge (2010a), Jerry Fodor\n(1987), Christopher Peacocke (1992, 1994), and many others. One\nprominent argument for intentional realism cites cognitive science\npractice. The argument maintains that intentional description\nfigures centrally in many core areas of cognitive science, such as\nperceptual psychology and linguistics. For example,\nperceptual psychology describes how perceptual activity transforms\nsensory inputs (e.g., retinal stimulations) into representations of\nthe distal environment (e.g., perceptual representations of distal\nshapes, sizes, and colors). The science identifies perceptual states\nby citing representational properties (e.g., representational\nrelations to specific distal shapes, sizes, colors). Assuming a\nbroadly scientific realist perspective, the explanatory achievements\nof perceptual psychology support a realist posture towards\nintentionality.\nEliminativism is a strong form of anti-realism about\nintentionality. Eliminativists dismiss intentional description as\nvague, context-sensitive, interest-relative, explanatorily\nsuperficial, or otherwise problematic. They recommend that scientific\npsychology jettison representational content. An early example is W.V.\nQuine\u2019s Word and Object (1960), which seeks to replace\nintentional psychology with behaviorist stimulus-response psychology.\nPaul Churchland (1981), another prominent eliminativist, wants to\nreplace intentional psychology with neuroscience.\nBetween intentional realism and eliminativism lie various\nintermediate positions. Daniel Dennett (1971, 1987) acknowledges that\nintentional discourse is predictively useful, but he questions whether\nmental states really have representational properties.\nAccording to Dennett, theorists who employ intentional descriptions\nare not literally asserting that mental states have\nrepresentational properties. They are merely adopting the\n\u201cintentional stance\u201d. Donald Davidson (1980) espouses a\nneighboring interpretivist position. He emphasizes the\ncentral role that intentional ascription plays within ordinary\ninterpretive practice, i.e., our practice of interpreting one\nanother\u2019s mental states and speech acts. At the same time, he\nquestions whether intentional psychology will find a place within\nmature scientific theorizing. Davidson and Dennett both profess\nrealism about intentional mental states. Nevertheless, both\nphilosophers are customarily read as intentional anti-realists. (In\nparticular, Dennett is frequently read as a kind\nof instrumentalist about intentionality.) One source of this\ncustomary reading involves indeterminacy of\ninterpretation. Suppose that behavioral evidence allows two\nconflicting interpretations of a thinker\u2019s mental states.\nFollowing Quine, Davidson and Dennett both say there is then \u201cno\nfact of the matter\u201d regarding which interpretation is correct.\nThis diagnosis indicates a less than fully realist attitude towards\nintentionality.\nDebates over intentionality figure prominently in philosophical\ndiscussion of CTM. Let us survey some highlights.\n5.1 Computation as formal\nClassical computationalists typically assume what one might\ncall the formal-syntactic conception of computation\n(FSC). The intuitive idea is that computation manipulates symbols in\nvirtue of their formal syntactic properties rather than their semantic\nproperties.\nFSC stems from innovations in mathematical logic during the late\n19th and early 20th centuries, especially\nseminal contributions by George Boole and Gottlob Frege. In\nhis Begriffsschrift (1879/1967), Frege effected a\nthoroughgoing formalization of deductive reasoning. To\nformalize, we specify a formal language whose component\nlinguistic expressions are individuated non-semantically (e.g., by\ntheir geometric shapes). We may have some intended interpretation in\nmind, but elements of the formal language are purely syntactic\nentities that we can discuss without invoking semantic properties such\nas reference or truth-conditions. In particular, we can\nspecify inference rules in formal syntactic terms. If we\nchoose our inference rules wisely, then they will cohere with our\nintended interpretation: they will carry true premises to true\nconclusions. Through formalization, Frege invested logic with\nunprecedented rigor. He thereby laid the groundwork for numerous\nsubsequent mathematical and philosophical developments.\nFormalization plays a significant foundational role within computer\nscience. We can program a Turing-style computer that manipulates\nlinguistic expressions drawn from a formal language. If we program the\ncomputer wisely, then its syntactic machinations will cohere with our\nintended semantic interpretation. For example, we can program the\ncomputer so that it carries true premises only to true conclusions, or\nso that it updates probabilities as dictated by Bayesian decision\ntheory.\nFSC holds that all computation manipulates formal\nsyntactic items, without regard to any semantic properties those items\nmay have.  Precise formulations of FSC vary. Computation is said to be\n\u201csensitive\u201d to syntax but not semantics, or to have\n\u201caccess\u201d only to syntactic properties, or to operate\n\u201cin virtue\u201d of syntactic rather than semantic properties,\nor to be impacted by semantic properties only as\n\u201cmediated\u201d by syntactic properties. It is not always so\nclear what these formulations mean or whether they are equivalent to\none another. But the intuitive picture is that syntactic properties\nhave causal/explanatory primacy over semantic properties in driving\ncomputation forward.\nFodor\u2019s article \u201cMethodological Solipsism Considered as\na Research Strategy in Cognitive Psychology\u201d (1980) offers an\nearly statement. Fodor combines FSC with CCTM+RTM. He analogizes\nMentalese to formal languages studied by logicians: it contains simple\nand complex items individuated non-semantically, just as typical\nformal languages contain simple and complex expressions individuated\nby their shapes. Mentalese symbols have a semantic interpretation, but\nthis interpretation does not (directly) impact mental computation. A\nsymbol\u2019s formal properties, rather than its semantic properties,\ndetermine how computation manipulates the symbol. In that sense, the\nmind is a \u201csyntactic engine\u201d. Virtually all classical\ncomputationalists follow Fodor in endorsing FSC.\nConnectionists often deny that neural networks manipulate\nsyntactically structured items. For that reason, many connectionists\nwould hesitate to accept FSC. Nevertheless, most connectionists\nendorse a generalized formality thesis: computation is\ninsensitive to semantic properties. The generalized formality thesis\nraises many of the same philosophical issues raised by FSC. We focus\nhere on FSC, which has received the most philosophical discussion.\nFodor combines CCTM+RTM+FSC with intentional realism. He holds that\nCCTM+RTM+FSC vindicates folk psychology by helping us convert common\nsense intentional discourse into rigorous science. He motivates his\nposition with a famous abductive argument for CCTM+RTM+FSC (1987:\n18\u201320). Strikingly, mental activity tracks semantic properties\nin a coherent way. For example, deductive inference carries premises\nto conclusions that are true if the premises are true. How can we\nexplain this crucial aspect of mental activity? Formalization shows\nthat syntactic manipulations can track semantic properties, and\ncomputer science shows how to build physical machines that execute\ndesired syntactic manipulations. If we treat the mind as a\nsyntax-driven machine, then we can explain why mental activity tracks\nsemantic properties in a coherent way. Moreover, our explanation does\nnot posit causal mechanisms radically different from those posited\nwithin the physical sciences. We thereby answer the pivotal\nquestion: How is rationality mechanically possible?\nStephen Stich (1983) and Hartry Field (2001) combine CCTM+FSC with\neliminativism. They recommend that cognitive science model the mind in\nformal syntactic terms, eschewing intentionality altogether. They\ngrant that mental states have representational properties, but they\nask what explanatory value scientific psychology gains by invoking\nthose properties. Why supplement formal syntactic description with\nintentional description? If the mind is a syntax-driven machine, then\ndoesn\u2019t representational content drop out as explanatorily\nirrelevant?\nAt one point in his career, Putnam (1983: 139\u2013154) combined\nCCTM+FSC with a Davidson-tinged interpretivism. Cognitive\nscience should proceed along the lines suggested by Stich and Field,\ndelineating purely formal syntactic computational models. Formal\nsyntactic modeling co-exists with ordinary interpretive practice, in\nwhich we ascribe intentional contents to one another\u2019s mental\nstates and speech acts. Interpretive practice is governed by holistic\nand heuristic constraints, which stymie attempts at converting\nintentional discourse into rigorous science. For Putnam, as for Field\nand Stich, the scientific action occurs at the formal syntactic level\nrather than the intentional level.\nCTM+FSC comes under attack from various directions. One criticism\ntargets the causal relevance of representational content\n(Block 1990; Figdor 2009; Kazez 1995). Intuitively speaking, the\ncontents of mental states are causally relevant to mental activity and\nbehavior. For example, my desire to drink water rather than orange\njuice causes me to walk to the sink rather than the refrigerator. The\ncontent of my desire (that I drink water) seems to play an\nimportant causal role in shaping my behavior. According to Fodor\n(1990: 137\u2013159), CCTM+RTM+FSC accommodates such\nintuitions. Formal syntactic activity implements intentional\nmental activity, thereby ensuring that intentional mental states\ncausally interact in accord with their contents. However, it is not so\nclear that this analysis secures the causal relevance of content. FSC\nsays that computation is \u201csensitive\u201d to syntax but not\nsemantics.  Depending on how one glosses the key term\n\u201csensitive\u201d, it can look like representational content is\ncausally irrelevant, with formal syntax doing all the causal\nwork. Here is an analogy to illustrate the worry. When a car drives\nalong a road, there are stable patterns involving the car\u2019s\nshadow. Nevertheless, shadow position at one time does not influence\nshadow position at a later time. Similarly, CCTM+RTM+FSC may explain\nhow mental activity instantiates stable patterns described in\nintentional terms, but this is not enough to ensure the causal\nrelevance of content. If the mind is a syntax-driven machine, then\ncausal efficacy seems to reside at the syntactic rather the semantic\nlevel. Semantics is just \u201calong for the ride\u201d. Apparently,\nthen, CTM+FSC encourages the conclusion that representational\nproperties are causally inert. The conclusion may not trouble\neliminativists, but intentional realists usually want to avoid it.\n A second criticism dismisses the formal-syntactic picture as\nspeculation ungrounded in scientific practice. Tyler Burge (2010a,b,\n2013: 479\u2013480) contends that formal syntactic description of\nmental activity plays no significant role within large areas of\ncognitive science, including the study of theoretical reasoning,\npractical reasoning, and perception. In each case, Burge argues, the\nscience employs intentional description rather than formal\nsyntactic description. For example, perceptual psychology individuates\nperceptual states not through formal syntactic properties but through\nrepresentational relations to distal shapes, sizes, colors, and so\non. To understand this criticism, we must distinguish formal\nsyntactic description and neurophysiological\ndescription. Everyone agrees that a complete scientific\npsychology will assign prime importance to neurophysiological\ndescription. However, neurophysiological description is distinct from\nformal syntactic description, because formal syntactic description is\nsupposed to be multiply realizable in the neurophysiological. The\nissue here is whether scientific psychology should\nsupplement intentional descriptions\nand neurophysiological descriptions with multiply\nrealizable, non-intentional formal syntactic descriptions.\n5.2 Externalism about mental content\n Putnam\u2019s landmark article \u201cThe Meaning of\n\u2018Meaning\u2019\u201d (1975: 215\u2013271) introduced\nthe Twin Earth thought experiment, which postulates a world\njust like our own except that H2O is replaced by a\nqualitatively similar substance XYZ with different chemical\ncomposition. Putnam argues that XYZ is not water and that speakers on\nTwin Earth use the word \u201cwater\u201d to refer to XYZ rather\nthan to water. Burge (1982) extends this conclusion\nfrom linguistic reference to mental content. He\nargues that Twin Earthlings instantiate mental states with different\ncontents. For example, if Oscar on Earth thinks that water is\nthirst-quenching, then his duplicate on Twin Earth thinks a\nthought with a different content, which we might gloss as that\ntwater is thirst-quenching. Burge concludes that mental content\ndoes not supervene upon internal neurophysiology. Mental content is\nindividuated partly by factors outside the thinker\u2019s skin,\nincluding causal relations to the environment. This position\nis externalism about mental content.\nFormal syntactic properties of mental states are widely taken to\nsupervene upon internal neurophysiology. For example, Oscar and Twin\nOscar instantiate the same formal syntactic manipulations. Assuming\ncontent externalism, it follows that there is a huge gulf between\nordinary intentional description and formal syntactic description.\nContent externalism raises serious questions about the explanatory\nutility of representational content for scientific psychology:\nArgument from Causation (Fodor 1987, 1991): How can mental\ncontent exert any causal influence except as manifested within\ninternal neurophysiology? There is no \u201cpsychological action at a\ndistance\u201d. Differences in the physical environment impact\nbehavior only by inducing differences in local brain states. So the\nonly causally relevant factors are those that supervene upon internal\nneurophysiology. Externally individuated content is causally\nirrelevant.\nArgument from Explanation (Stich 1983): Rigorous\nscientific explanation should not take into account factors outside\nthe subject\u2019s skin. Folk psychology may taxonomize mental states\nthrough relations to the external environment, but scientific\npsychology should taxonomize mental states entirely through factors\nthat supervene upon internal neurophysiology. It should treat Oscar\nand Twin Oscar as psychological\nduplicates.[3]\nSome authors pursue the two arguments in conjunction with one\nanother. Both arguments reach the same conclusion: externally\nindividuated mental content finds no legitimate place within causal\nexplanations provided by scientific psychology. Stich (1983) argues\nalong these lines to motivate his formal-syntactic eliminativism.\nMany philosophers respond to such worries by promoting content\ninternalism. Whereas content externalists favor wide\ncontent (content that does not supervene upon internal\nneurophysiology), content internalists favor narrow content\n(content that does so supervene). Narrow content is what remains of\nmental content when one factors out all external elements. At one\npoint in his career, Fodor (1981, 1987) pursued internalism as a\nstrategy for integrating intentional psychology with\nCCTM+RTM+FSC. While conceding that wide content should not figure in\nscientific psychology, he maintained that narrow content should play a\ncentral explanatory role.\nRadical internalists insist that all content is narrow. A\ntypical analysis holds that Oscar is thinking not about water but\nabout some more general category of substance that subsumes XYZ, so\nthat Oscar and Twin Oscar entertain mental states with the same\ncontents.  Tim Crane (1991) and Gabriel Segal (2000) endorse such an\nanalysis.  They hold that folk psychology always individuates\npropositional attitudes narrowly. A less radical internalism\nrecommends that we recognize narrow content in addition to\nwide content. Folk psychology may sometimes individuate propositional\nattitudes widely, but we can also delineate a viable notion of narrow\ncontent that advances important philosophical or scientific\ngoals. Internalists have proposed various candidate notions of narrow\ncontent (Block 1986; Chalmers 2002; Cummins 1989; Fodor 1987; Lewis\n1994; Loar 1988; Mendola 2008). See the\nentry narrow mental content for an\noverview of prominent candidates.\nExternalists complain that existing theories of narrow content are\nsketchy, implausible, useless for psychological explanation, or\notherwise objectionable (Burge 2007; Sawyer 2000; Stalnaker\n1999). Externalists also question internalist arguments that\nscientific psychology requires narrow content:\nArgument from Causation: Externalists insist that wide\ncontent can be causally relevant. The details vary among externalists,\nand discussion often becomes intertwined with complex issues\nsurrounding causation, counterfactuals, and the metaphysics of mind.\nSee the entry mental causation for\nan introductory overview, and see Burge (2007), Rescorla (2014a), and\nYablo (1997, 2003) for representative externalist discussion.\nArgument from Explanation: Externalists claim that\npsychological explanation can legitimately taxonomize mental states\nthrough factors that outstrip internal neurophysiology (Peacocke\n1993; Shea, 2018). Burge observes that non-psychological sciences often\nindividuate explanatory kinds relationally, i.e., through\nrelations to external factors. For example, whether an entity counts\nas a heart depends (roughly) upon whether its biological function in\nits normal environment is to pump blood. So physiology individuates\norgan kinds relationally. Why can\u2019t psychology likewise\nindividuate mental states relationally? For a notable exchange on\nthese issues, see Burge (1986, 1989, 1995) and Fodor (1987, 1991).\nExternalists doubt that we have any good reason to replace or\nsupplement wide content with narrow content. They dismiss the search\nfor narrow content as a wild goose chase.\nBurge (2007, 2010a) defends externalism by analyzing current\ncognitive science. He argues that many branches of scientific\npsychology (especially perceptual psychology) individuate mental\ncontent through causal relations to the external environment. He\nconcludes that scientific practice embodies an externalist\nperspective.  By contrast, he maintains, narrow content is a\nphilosophical fantasy ungrounded in current science.\nSuppose we abandon the search for narrow content. What are the\nprospects for combining CTM+FSC with externalist intentional\npsychology? The most promising option emphasizes levels of\nexplanation. We can say that intentional psychology occupies one\nlevel of explanation, while formal-syntactic computational psychology\noccupies a different level. Fodor advocates this approach in his later\nwork (1994, 2008). He comes to reject narrow content as otiose. He\nsuggests that formal syntactic mechanisms implement externalist\npsychological laws. Mental computation manipulates Mentalese\nexpressions in accord with their formal syntactic properties, and\nthese formal syntactic manipulations ensure that mental activity\ninstantiates appropriate law-like patterns defined over wide\ncontents.\nIn light of the internalism/externalism distinction, let us revisit\nthe eliminativist challenge raised in \u00a75.1:\nwhat explanatory value does intentional description add to\nformal-syntactic description?  Internalists can respond that suitable\nformal syntactic manipulations determine and maybe even constitute\nnarrow contents, so that internalist intentional description is\nalready implicit in suitable formal syntactic description (cf. Field\n2001: 75). Perhaps this response vindicates intentional realism,\nperhaps not. Crucially, though, no such response is available to\ncontent externalists.  Externalist intentional description is not\nimplicit in formal syntactic description, because one can hold formal\nsyntax fixed while varying wide content. Thus, content externalists\nwho espouse CTM+FSC must say what we gain by supplementing\nformal-syntactic explanations with intentional explanations. Once we\naccept that mental computation is sensitive to syntax but not\nsemantics, it is far from clear that any useful explanatory work\nremains for wide content. Fodor addresses this challenge at various\npoints, offering his most systematic treatment in The Elm and the\nExpert (1994). See Arjo (1996), Aydede (1998), Aydede and Robbins\n(2001), Wakefield (2002); Perry (1998), and Wakefield (2002) for\ncriticism. See Rupert (2008) and Schneider (2005) for positions close\nto Fodor\u2019s. Dretske (1993) and Shea (2018, pp. 197\u2013226) pursue\nalternative strategies for vindicating the explanatory relevance of\nwide content.\n5.3 Content-involving computation\n The perceived gulf between computational description and\nintentional description animates many writings on CTM. A few\nphilosophers try to bridge the gulf using computational descriptions\nthat individuate computational states in representational terms. These\ndescriptions are content-involving, to use Christopher\nPeacocke\u2019s (1994) terminology. On the content-involving\napproach, there is no rigid demarcation between computational and\nintentional description. In particular, certain scientifically\nvaluable descriptions of mental activity are both computational and\nintentional. Call this position content-involving\ncomputationalism.\nContent-involving computationalists need not say that all\ncomputational description is intentional. To illustrate, suppose we\ndescribe a simple Turing machine that manipulates symbols individuated\nby their geometric shapes. Then the resulting computational\ndescription is not plausibly content-involving. Accordingly,\ncontent-involving computationalists do not usually advance\ncontent-involving computation as a general theory of computation. They\nclaim only that some important computational descriptions are\ncontent-involving.\nOne can develop content-involving computationalism in an\ninternalist or externalist direction. Internalist\ncontent-involving computationalists hold that some computational\ndescriptions identify mental states partly through\ntheir narrow contents.  Murat Aydede (2005) recommends a\nposition along these lines.  Externalist content-involving\ncomputationalism holds that certain computational descriptions\nidentify mental states partly through their wide\ncontents. Tyler Burge (2010a: 95\u2013101), Christopher Peacocke\n(1994, 1999), Michael Rescorla (2012), and Mark Sprevak (2010) espouse\nthis position. Oron Shagrir (2001, forthcoming) advocates a\ncontent-involving computationalism that is neutral between internalism\nand externalism.\nExternalist content-involving computationalists typically cite\ncognitive science practice as a motivating factor. For example,\nperceptual psychology describes the perceptual system as computing an\nestimate of some object\u2019s size from retinal stimulations and\nfrom an estimate of the object\u2019s depth. Perceptual\n\u201cestimates\u201d are identified representationally, as\nrepresentations of specific distal sizes and depths. Quite plausibly,\nrepresentational relations to specific distal sizes and depths do not\nsupervene on internal neurophysiology. Quite plausibly, then,\nperceptual psychology type-identifies perceptual computations through\nwide contents. So externalist content-involving computationalism seems\nto harmonize well with current cognitive science.\nA major challenge facing content-involving computationalism\nconcerns the interface with standard computationalism formalisms, such\nas the Turing machine. How exactly do content-involving descriptions\nrelate to the computational models found in logic and computer\nscience?  Philosophers usually assume that these models offer\nnon-intentional descriptions. If so, that would be a major and perhaps\ndecisive blow to content-involving computationalism.\nArguably, though, many familiar computational formalisms allow a\ncontent-involving rather than formal syntactic construal. To\nillustrate, consider the Turing machine. One can individuate\nthe \u201csymbols\u201d comprising the Turing machine alphabet\nnon-semantically, through factors akin to geometric shape. But does\nTuring\u2019s formalism require a non-semantic individuative\nscheme? Arguably, the formalism allows us\nto individuate symbols partly through their contents. Of course, the\nmachine table for a Turing machine does not explicitly cite semantic\nproperties of symbols (e.g., denotations or truth-conditions).\nNevertheless, the machine table can encode mechanical rules that\ndescribe how to manipulate symbols, where those symbols are\ntype-identified in content-involving terms. In this way, the machine\ntable dictates transitions among content-involving states without\nexplicitly mentioning semantic properties. Aydede (2005) suggests an\ninternalist version of this view, with symbols type-identified through\ntheir narrow\n contents.[4]\n Rescorla (2017a) develops the view in\nan externalist direction, with symbols type-identified through their\nwide contents. He argues that some Turing-style models describe\ncomputational operations over externalistically individuated Mentalese\nsymbols.[5]\nIn principle, one might embrace both externalist content-involving\ncomputational description and formal syntactic description.\nOne might say that these two kinds of description occupy distinct\nlevels of explanation. Peacocke suggests such a view. Other\ncontent-involving computationalists regard formal syntactic\ndescriptions of the mind more skeptically. For example, Burge\nquestions what explanatory value formal syntactic description\ncontributes to certain areas of scientific psychology (such as\nperceptual psychology). From this viewpoint, the eliminativist\nchallenge posed in \u00a75.1 has matters\nbackwards. We should not assume that formal syntactic descriptions are\nexplanatorily valuable and then ask what value intentional\ndescriptions contribute.  We should instead embrace the externalist\nintentional descriptions offered by current cognitive science and then\nask what value formal syntactic description contributes.\nProponents of formal syntactic description respond by\nciting implementation mechanisms. Externalist description of\nmental activity presupposes that suitable causal-historical relations\nbetween the mind and the external physical environment are in\nplace. But surely we want a \u201clocal\u201d description that\nignores external causal-historical relations, a description that\nreveals underlying causal mechanisms. Fodor (1987, 1994) argues in\nthis way to motivate the formal syntactic picture. For possible\nexternalist responses to the argument from implementation mechanisms,\nsee Burge (2010b), Rescorla (2017b), Shea (2013), and Sprevak\n(2010). Debate over this argument, and more generally over the\nrelation between computation and representation, seems likely to\ncontinue into the indefinite future.\n6. Alternative conceptions of computation\n The literature offers several alternative conceptions, usually\nadvanced as foundations for CTM. In many cases, these conceptions\noverlap with one another or with the conceptions considered above.\n6.1 Information-processing\nIt is common for cognitive scientists to describe computation as\n\u201cinformation-processing\u201d. It is less common for proponents\nto clarify what they mean by \u201cinformation\u201d or\n\u201cprocessing\u201d. Lacking clarification, the description is\nlittle more than an empty slogan.\nClaude Shannon introduced a scientifically important notion of\n\u201cinformation\u201d in his 1948 article \u201cA Mathematical\nTheory of Communication\u201d. The intuitive idea is that information\nmeasures reduction in uncertainty, where reduced uncertainty\nmanifests as an altered probability distribution over possible states.\nShannon codified this idea within a rigorous mathematical framework,\nlaying the foundation for information theory (Cover and\nThomas 2006). Shannon information is fundamental to modern\nengineering. It finds fruitful application within cognitive science,\nespecially cognitive neuroscience. Does it support a convincing\nanalysis of computation as \u201cinformation-processing\u201d?\nConsider an old-fashioned tape machine that records messages received\nover a wireless radio. Using Shannon\u2019s framework, one can\nmeasure how much information is carried by some recorded\nmessage. There is a sense in which the tape machine\n\u201cprocesses\u201d Shannon information whenever we replay a\nrecorded message. Still, the machine does not seem to implement a\nnon-trivial computational \nmodel.[6]\n Certainly, neither the Turing machine\nformalism nor the neural network formalism offers much insight into\nthe machine\u2019s operations. Arguably, then, a system can process\nShannon information without executing computations in any interesting\nsense.\nConfronted with such examples, one might try to isolate a more\ndemanding notion of \u201cprocessing\u201d, so that the tape machine\ndoes not \u201cprocess\u201d Shannon information. Alternatively, one\nmight insist that the tape machine executes non-trivial computations.\nPiccinini and Scarantino (2010) advance a highly general notion of\ncomputation\u2014which they dub generic\ncomputation\u2014with that consequence.\n A second prominent notion of information derives from Paul\nGrice\u2019s (1989) influential discussion of natural\nmeaning. Natural meaning involves reliable,\ncounterfactual-supporting correlations. For example, tree rings\ncorrelate with the age of the tree, and pox correlate with\nchickenpox. We colloquially describe tree rings as carrying\ninformation about tree age, pox as carrying information about\nchickenpox, and so on. Such descriptions suggest a conception that\nties information to reliable, counterfactual-supporting\ncorrelations. Fred Dretske (1981) develops this conception into a\nsystematic theory, as do various subsequent philosophers. Does\nDretske-style information subserve a plausible analysis of computation\nas \u201cinformation-processing\u201d? Consider an\nold-fashioned bimetallic strip thermostat. Two metals are\njoined together into a strip. Differential expansion of the metals\ncauses the strip to bend, thereby activating or deactivating a heating\nunit. Strip state reliably correlates with current ambient\ntemperature, and the thermostat \u201cprocesses\u201d this\ninformation-bearing state when activating or deactivating the\nheater. Yet the thermostat does not seem to implement any non-trivial\ncomputational model. One would not ordinarily regard the thermostat as\ncomputing. Arguably, then, a system can process Dretske-style\ninformation without executing computations in any interesting\nsense. Of course, one might try to handle such examples through\nmaneuvers parallel to those from the previous paragraph.\nA third prominent notion of information is semantic\ninformation, i.e., representational\ncontent.[7] Some\nphilosophers hold that a physical system computes only if the\nsystem\u2019s states have representational properties (Dietrich 1989;\nFodor 1998: 10; Ladyman 2009; Shagrir 2006; Sprevak 2010). In that\nsense, information-processing is necessary for\ncomputation. As Fodor memorably puts it, \u201cno computation without\nrepresentation\u201d (1975: 34). However, this position is\ndebatable. Chalmers (2011) and Piccinini (2008a) contend that a Turing\nmachine might execute computations even though symbols manipulated by\nthe machine have no semantic interpretation. The machine\u2019s\ncomputations are purely syntactic in nature, lacking anything like\nsemantic properties. On this view, representational content is not\nnecessary for a physical system to count as computational.\nIt remains unclear whether the slogan \u201ccomputation is\ninformation-processing\u201d provides much insight. Nevertheless, the\nslogan seems unlikely to disappear from the literature anytime soon.\nFor further discussion of possible connections between computation and\ninformation, see Gallistel and King (2009: 1\u201326), Lizier,\nFlecker, and Williams (2013), Milkowski (2013), Piccinini and\nScarantino (2010), and Sprevak (forthcoming).\n6.2 Function evaluation\n In a widely cited passage, the perceptual psychologist David Marr\n(1982) distinguishes three levels at which one can describe an\n\u201cinformation-processing device\u201d:\n\n Computational theory: \u201c[t]he device is\ncharacterized as a mapping from one kind of information to another,\nthe abstract properties of this mapping are defined precisely, and its\nappropriateness and adequacy for the task as hand are\ndemonstrated\u201d (p. 24).\n Representation and algorithm: \u201cthe choice of\nrepresentation for the input and output and the algorithm to be used\nto transform one into the other\u201d (pp. 24\u201325).\n Hardware implementation: \u201cthe details of how the\nalgorithm and representation are realized physically\u201d (p.\n25). \nMarr\u2019s three levels have attracted intense philosophical\nscrutiny. For our purposes, the key point is that Marr\u2019s\n\u201ccomputational level\u201d describes a mapping from inputs to\noutputs, without describing intermediate steps. Marr illustrates his\napproach by providing \u201ccomputational level\u201d theories of\nvarious perceptual processes, such as edge detection.\nMarr\u2019s discussion suggests a functional conception of\ncomputation, on which computation is a matter of transforming\ninputs into appropriate outputs. Frances Egan elaborates the\nfunctional conception over a series of articles (1991, 1992, 1999,\n2003, 2010, 2014, 2019). Like Marr, she treats computational\ndescription as description of input-output relations. She also claims\nthat computational models characterize a purely mathematical\nfunction: that is, a mapping from mathematical inputs to mathematical\noutputs. She illustrates by considering a visual mechanism (called\n\u201cVisua\u201d) that computes an object\u2019s depth from\nretinal disparity. She imagines a neurophysiological duplicate\n(\u201cTwin Visua\u201d) embedded so differently in the physical\nenvironment that it does not represent depth. Visua and Twin Visua\ninstantiate perceptual states with different representational\nproperties. Nevertheless, Egan says, vision science treats Visua and\nTwin Visua as computational duplicates. Visua and Twin Visua\ncompute the same mathematical function, even though the computations\nhave different representational import in the two cases. Egan\nconcludes that computational modeling of the mind yields an\n\u201cabstract mathematical description\u201d consistent with many\nalternative possible representational descriptions.  Intentional\nattribution is just a heuristic gloss upon underlying computational\ndescription.\nChalmers (2012) argues that the functional conception neglects\nimportant features of computation. As he notes, computational models\nusually describe more than just input-output relations. They describe\nintermediate steps through which inputs are transformed into outputs.\nThese intermediate steps, which Marr consigns to the\n\u201calgorithmic\u201d level, figure prominently in computational\nmodels offered by logicians and computer scientists. Restricting the\nterm \u201ccomputation\u201d to input-output description does not\ncapture standard computational practice.\nAn additional worry faces functional theories, such as\nEgan\u2019s, that exclusively emphasize mathematical inputs\nand outputs.  Critics complain that Egan mistakenly elevates\nmathematical functions, at the expense of intentional explanations\nroutinely offered by cognitive science (Burge\n2005; Rescorla\n2015; Silverberg 2006; Sprevak 2010). To illustrate, suppose\nperceptual psychology describes the perceptual system as estimating\nthat some object\u2019s depth is 5 meters. The perceptual\ndepth-estimate has a representational content: it is accurate only if\nthe object\u2019s depth is 5 meters. We cite the number 5 to identify\nthe depth-estimate.  But our choice of this number depends upon our\narbitrary choice of measurement units. Critics contend that the\ncontent of the depth-estimate, not the arbitrarily chosen number\nthrough which we theorists specify that content, is what matters for\npsychological explanation. Egan\u2019s theory places the number\nrather than the content at explanatory center stage. According to\nEgan, computational explanation should describe the visual system as\ncomputing a particular mathematical function that\ncarries particular mathematical inputs into particular\nmathematical outputs. Those particular mathematical inputs and\noutputs depend upon our arbitrary choice of measurement units, so they\narguably lack the explanatory significance that Egan assigns to\nthem.\nWe should distinguish the functional approach, as pursued by Marr\nand Egan, from the functional programming paradigm in\ncomputer science. The functional programming paradigm models\nevaluation of a complex function as successive evaluation of simpler\nfunctions. To take a simple example, one might evaluate \\(f(x,y) =\n(x^{2}+y)\\) by first evaluating the squaring function and then\nevaluating the addition function. Functional programming differs from\nthe \u201ccomputational level\u201d descriptions emphasized by Marr,\nbecause it specifies intermediate computational stages. The functional\nprogramming paradigm stretches back to Alonzo Church\u2019s\n(1936) lambda calculus, continuing with programming languages\nsuch as PCF and LISP. It plays an important role in AI and theoretical\ncomputer science. Some authors suggest that it offers special insight\ninto mental computation (Klein 2012; Piantadosi, Tenenbaum, and\nGoodman 2012). However, many computational formalisms do not conform\nto the functional paradigm: Turing machines; imperative programming\nlanguages, such as C; logic programming languages, such as Prolog; and\nso on. Even though the functional paradigm describes numerous\nimportant computations (possibly including mental computations), it\ndoes not plausibly capture computation in general.\n6.3 Structuralism\nMany philosophical discussions embody a structuralist\nconception of computation: a computational model describes an\nabstract causal structure, without taking into account particular\nphysical states that instantiate the structure. This conception traces\nback at least to Putnam\u2019s original treatment (1967).\nChalmers (1995, 1996a, 2011, 2012) develops it in detail. He\nintroduces the combinatorial-state automaton (CSA) formalism,\nwhich subsumes most familiar models of computation (including Turing\nmachines and neural networks). A CSA provides an abstract description\nof a physical system\u2019s causal topology: the pattern of\ncausal interaction among the system\u2019s parts, independent of the\nnature of those parts or the causal mechanisms through which they\ninteract.  Computational description specifies a causal topology.\nChalmers deploys structuralism to delineate a very general version\nof CTM. He assumes the functionalist view that psychological states\nare individuated by their roles in a pattern of causal organization.\nPsychological description specifies causal roles, abstracted away from\nphysical states that realize those roles. So psychological properties\nare organizationally invariant, in that they supervene upon\ncausal topology. Since computational description characterizes a\ncausal topology, satisfying a suitable computational description\nsuffices for instantiating appropriate mental properties. It also\nfollows that psychological description is a species of computational\ndescription, so that computational description should play a central\nrole within psychological explanation. Thus, structuralist computation\nprovides a solid foundation for cognitive science. Mentality is\ngrounded in causal patterns, which are precisely what computational\nmodels articulate.\nStructuralism comes packaged with an attractive account of\nthe implementation relation between abstract computational\nmodels and physical systems. Under what conditions does a physical\nsystem implement a computational model? Structuralists say that a\nphysical system implements a model just in case the model\u2019s\ncausal structure is \u201cisomorphic\u201d to the model\u2019s\nformal structure. A computational model describes a physical system by\narticulating a formal structure that mirrors some relevant causal\ntopology. Chalmers elaborates this intuitive idea, providing detailed\nnecessary and sufficient conditions for physical realization of CSAs.\nFew if any alternative conceptions of computation can provide so\nsubstantive an account of the implementation relation.\nWe may instructively compare structuralist computationalism with\nsome other theories discussed above:\nMachine functionalism. Structuralist computationalism\nembraces the core idea behind machine functionalism: mental states are\nfunctional states describable through a suitable computational\nformalism. Putnam advances CTM as an empirical hypothesis, and he\ndefends functionalism on that basis. In contrast, Chalmers follows\nDavid Lewis (1972) by grounding functionalism in the conceptual\nanalysis of mentalistic discourse. Whereas Putnam defends\nfunctionalism by defending computationalism, Chalmers defends\ncomputationalism by assuming functionalism.\nClassical computationalism, connectionism, and computational\nneuroscience. Structuralist computationalism emphasizes\norganizationally invariant descriptions, which are multiply\nrealizable.  In that respect, it diverges from computational\nneuroscience.  Structuralism is compatible with both classical and\nconnectionist computationalism, but it differs in spirit from those\nviews.  Classicists and connectionists present their rival positions\nas bold, substantive hypotheses. Chalmers advances structuralist\ncomputationalism as a relatively minimalist position unlikely to be\ndisconfirmed.\nIntentional realism and eliminativism. Structuralist\ncomputationalism is compatible with both positions. CSA description\ndoes not explicitly mention semantic properties such as reference,\ntruth-conditions, representational content, and so on. Structuralist\ncomputationalists need not assign representational content any\nimportant role within scientific psychology. On the other hand,\nstructuralist computationalism does not preclude an important role for\nrepresentational content.\nThe formal-syntactic conception of computation. Wide\ncontent depends on causal-historical relations to the external\nenvironment, relations that outstrip causal topology. Thus, CSA\ndescription leaves wide content underdetermined. Narrow content\npresumably supervenes upon causal topology, but CSA description does\nnot explicitly mention narrow contents. Overall, then, structuralist\ncomputationalism prioritizes a level of formal, non-semantic\ncomputational description. In that respect, it resembles FSC. On the\nother hand, structuralist computationalists need not say that\ncomputation is \u201cinsensitive\u201d to semantic properties, so\nthey need not endorse all aspects of FSC.\nAlthough structuralist computationalism is distinct from CTM+FSC,\nit raises some similar issues. For example, Rescorla (2012) denies\nthat causal topology plays the central explanatory role within\ncognitive science that structuralist computationalism dictates. He\nsuggests that externalist intentional description rather than\norganizationally invariant description enjoys explanatory\nprimacy. Coming from a different direction, computational\nneuroscientists will recommend that we forego organizationally\ninvariant descriptions and instead employ more neurally specific\ncomputational models. In response to such objections, Chalmers (2012)\nargues that organizationally invariant computational description\nyields explanatory benefits that neither intentional description nor\nneurophysiological description replicate: it reveals the underlying\nmechanisms of cognition (unlike intentional description); and it\nabstracts away from neural implementation details that are irrelevant\nfor many explanatory purposes.\n6.4 Mechanistic theories\nThe mechanistic nature of computation is a recurring theme in\nlogic, philosophy, and cognitive science. Gualtiero Piccinini (2007,\n2012, 2015) and Marcin Milkowski (2013) develop this theme into a\nmechanistic theory of computing systems. A functional\nmechanism is a system of interconnected components, where each\ncomponent performs some function within the overall\nsystem. Mechanistic explanation proceeds by decomposing the\nsystem into parts, describing how the parts are organized into the\nlarger system, and isolating the function performed by each part. A\ncomputing system is a functional mechanism of a particular kind. On\nPiccinini\u2019s account, a computing system is a mechanism whose\ncomponents are functionally organized to process vehicles in accord\nwith rules. Echoing Putnam\u2019s discussion of multiple\nrealizability, Piccinini demands that the rules\nbe medium-independent, in that they abstract away from the\nspecific physical implementations of the vehicles. Computational\nexplanation decomposes the system into parts and describes how each\npart helps the system process the relevant vehicles. If the system\nprocesses discretely structured vehicles, then the computation is\ndigital. If the system processes continuous vehicles, then the\ncomputation is analog. Milkowski\u2019s version of the mechanistic\napproach is similar. He differs from Piccinini by pursuing an\n\u201cinformation-processing\u201d gloss, so that computational\nmechanisms operate over information-bearing states. Milkowski and\nPiccinini deploy their respective mechanistic theories to defend\ncomputationalism.\nMechanistic computationalists typically individuate computational\nstates non-semantically. They therefore encounter worries about the\nexplanatory role of representational content, similar to worries\nencountered by FSC and structuralism. In this spirit, Shagrir (2014)\ncomplains that mechanistic computationalism does not accommodate\ncognitive science explanations that are simultaneously computational\nand representational. The perceived force of this criticism will\ndepend upon one\u2019s sympathy for content-involving\ncomputationalism.\n6.5 Pluralism\nWe have surveyed various contrasting and sometimes overlapping\nconceptions of computation: classical computation, connectionist\ncomputation, neural computation, formal-syntactic computation,\ncontent-involving computation, information-processing computation,\nfunctional computation, structuralist computation, and mechanistic\ncomputation. Each conception yields a different form of\ncomputationalism. Each conception has its own strengths and\nweaknesses.  One might adopt a pluralistic stance that\nrecognizes distinct legitimate conceptions. Rather than elevate one\nconception above the others, pluralists happily employ whichever\nconception seems useful in a given explanatory context. Edelman (2008)\ntakes a pluralistic line, as does Chalmers (2012) in his most recent\ndiscussion.\nThe pluralistic line raises some natural questions. Can we provide\na general analysis that encompasses all or most types of computation?\nDo all computations share certain characteristic marks with one\nanother?  Are they perhaps instead united by something like family\nresemblance?  Deeper understanding of computation requires us to\ngrapple with these questions.\n7. Arguments against computationalism\nCTM has attracted numerous objections. In many cases, the\nobjections apply only to specific versions of CTM (such as classical\ncomputationalism or connectionist computationalism). Here are a few\nprominent objections. See also the\nentry the Chinese room argument for a\nwidely discussed objection to classical computationalism advanced by\nJohn Searle (1980).\n7.1 Triviality arguments\n A recurring worry is that CTM is trivial, because we can\ndescribe almost any physical system as executing computations. Searle\n(1990) claims that a wall implements any computer program,\nsince we can discern some pattern of molecular movements in the wall\nthat is isomorphic to the formal structure of the program. Putnam\n(1988: 121\u2013125) defends a less extreme but still very strong\ntriviality thesis along the same lines. Triviality arguments play a\nlarge role in the philosophical literature. Anti-computationalists\ndeploy triviality arguments against computationalism, while\ncomputationalists seek to avoid triviality.\nComputationalists usually rebut triviality arguments by insisting\nthat the arguments overlook constraints upon computational\nimplementation, constraints that bar trivializing implementations. The\nconstraints may be counterfactual, causal, semantic, or otherwise,\ndepending on one\u2019s favored theory of computation. For example,\nDavid Chalmers (1995, 1996a) and B. Jack Copeland (1996) hold that\nPutnam\u2019s triviality argument ignores counterfactual conditionals\nthat a physical system must satisfy in order to implement a\ncomputational model. Other philosophers say that a physical system\nmust have representational properties to implement a computational\nmodel (Fodor 1998: 11\u201312; Ladyman 2009; Sprevak 2010) or at\nleast to implement a content-involving computational model (Rescorla\n2013, 2014b). The details here vary considerably, and\ncomputationalists debate amongst themselves exactly which types of\ncomputation can avoid which triviality arguments. But most\ncomputationalists agree that we can avoid any devastating triviality\nworries through a sufficiently robust theory of the implementation\nrelation between computational models and physical systems.\nPancomputationalism holds that every physical system\nimplements a computational model. This thesis is plausible, since any\nphysical system arguably implements a sufficiently trivial\ncomputational model (e.g., a one-state finite state automaton). As\nChalmers (2011) notes, pancomputationalism does not seem worrisome for\ncomputationalism. What would be worrisome is the much stronger\ntriviality thesis that almost every physical system implements almost\nevery computational model.\nFor further discussion of triviality arguments and computational\nimplementation, see Sprevak (2019) and the\nentry computation in physical systems.\n7.2 G\u00f6del\u2019s incompleteness theorem\n According to some authors, G\u00f6del\u2019s incompleteness\ntheorems show that human mathematical capacities outstrip the\ncapacities of any Turing machine (Nagel and Newman 1958). J.R. Lucas\n(1961) develops this position into a famous critique of CCTM. Roger Penrose\npursues the critique in The Emperor\u2019s New Mind (1989)\nand subsequent writings. Various philosophers and logicians have\nanswered the critique, arguing that existing formulations suffer from\nfallacies, question-begging assumptions, and even outright\nmathematical errors (Bowie 1982; Chalmers 1996b; Feferman 1996; Lewis 1969, 1979; Putnam\n1975: 365\u2013366, 1994; Shapiro 2003). There is a wide consensus\nthat this criticism of CCTM lacks any force. It may turn out that\ncertain human mental capacities outstrip Turing-computability, but\nG\u00f6del\u2019s incompleteness theorems provide no reason to\nanticipate that outcome.\n7.3 Limits of computational modeling\n Could a computer compose the Eroica symphony? Or discover\ngeneral relativity? Or even replicate a child\u2019s effortless\nability to perceive the environment, tie her shoelaces, and discern\nthe emotions of others? Intuitive, creative, or skillful human\nactivity may seem to resist formalization by a computer program\n(Dreyfus 1972, 1992). More generally, one might worry that crucial\naspects of human cognition elude computational modeling, especially\nclassical computational modeling.\nIronically, Fodor promulgates a forceful version of this\ncritique. Even in his earliest statements of CCTM, Fodor (1975:\n197\u2013205) expresses considerable skepticism that CCTM can handle\nall important cognitive phenomena. The pessimism becomes more\npronounced in his later writings (1983, 2000), which focus especially\non abductive reasoning as a mental phenomenon that\npotentially eludes computational modeling. His core argument may be\nsummarized as follows:\n\n(1)Turing-style\ncomputation is sensitive only to \u201clocal\u201d properties of a\nmental representation, which are exhausted by the identity and\narrangement of the representation\u2019s constituents.\n(2)Many mental\nprocesses, paradigmatically abduction, are sensitive to\n\u201cnonlocal\u201d properties such as relevance, simplicity, and\nconservatism.\n(3)Hence, we may have\nto abandon Turing-style modeling of the relevant\nprocesses.\n(4)Unfortunately, we\nhave currently have no idea what alternative theory might serve as a\nsuitable replacement.\n\nSome critics deny (1), arguing that suitable Turing-style\ncomputations can be sensitive to \u201cnonlocal\u201d properties\n(Schneider 2011; Wilson 2005). Some challenge (2), arguing that\ntypical abductive inferences are sensitive only to \u201clocal\u201d\nproperties (Carruthers 2003; Ludwig and Schneider 2008; Sperber\n2002). Some concede step (3) but dispute step (4), insisting that we\nhave promising non-Turing-style models of the relevant mental\nprocesses (Pinker 2005). Partly spurred by such criticisms, Fodor\nelaborates his argument in considerable detail. To defend (2), he\ncritiques theories that model abduction by deploying\n\u201clocal\u201d heuristic algorithms (2005: 41\u201346; 2008:\n115\u2013126) or by positing a profusion of domain-specific cognitive\nmodules (2005: 56\u2013100). To defend (4), he critiques various\ntheories that handle abduction through non-Turing-style models (2000:\n46\u201353; 2008), such as connectionist networks.\nThe scope and limits of computational modeling remain\ncontroversial. We may expect this topic to remain an active focus of\ninquiry, pursued jointly with AI.\n7.4 Temporal arguments\n Mental activity unfolds in time. Moreover, the mind accomplishes\nsophisticated tasks (e.g., perceptual estimation) very quickly. Many\ncritics worry that computationalism, especially classical\ncomputationalism, does not adequately accommodate temporal aspects of\ncognition. A Turing-style model makes no explicit mention of the time\nscale over which computation occurs. One could physically implement\nthe same abstract Turing machine with a silicon-based device, or a\nslower vacuum-tube device, or an even slower pulley-and-lever\ndevice. Critics recommend that we reject CCTM in favor of some\nalternative framework that more directly incorporates temporal\nconsiderations. van Gelder and Port (1995) use this argument to\npromote a non-computational dynamical systems framework for\nmodeling mental activity. Eliasmith (2003, 2013: 12\u201313) uses it\nto support his Neural Engineering Framework.\nComputationalists respond that we can supplement an\nabstract computational model with temporal considerations (Piccinini\n2010; Weiskopf 2004). For example, a Turing machine model presupposes\ndiscrete \u201cstages of computation\u201d, without describing how\nthe stages relate to physical time. But we can supplement our model by\ndescribing how long each stage lasts, thereby converting our\nnon-temporal Turing machine model into a theory that yields detailed\ntemporal predictions. Many advocates of CTM employ supplementation\nalong these lines to study temporal properties of cognition (Newell\n1990). Similar supplementation figures prominently in computer\nscience, whose practitioners are quite concerned to build machines\nwith appropriate temporal properties. Computationalists conclude that\na suitably supplemented version of CTM can adequately capture how\ncognition unfolds in time.\n A second temporal objection highlights the contrast\nbetween discrete and continuous temporal evolution\n(van Gelder and Port 1995). Computation by a Turing machine unfolds in\ndiscrete stages, while mental activity unfolds in a continuous time.\nThus, there is a fundamental mismatch between the temporal properties\nof Turing-style computation and those of actual mental activity. We\nneed a psychological theory that describes continuous temporal\nevolution.\nComputationalists respond that this objection assumes what is to be\nshown: that cognitive activity does not fall into explanatory\nsignificant discrete stages (Weiskopf 2004). Assuming that physical\ntime is continuous, it follows that mental activity unfolds in\ncontinuous time. It does not follow that cognitive models\nmust have continuous temporal structure. A personal computer operates\nin continuous time, and its physical state evolves continuously. A\ncomplete physical theory will reflect all those physical changes. But\nour computational model does not reflect every physical\nchange to the computer. Our computational model has discrete temporal\nstructure. Why assume that a good cognitive-level model of the mind\nmust reflect every physical change to the brain? Even if there is a\ncontinuum of evolving physical states, why assume a continuum\nof evolving cognitive states? The mere fact of continuous\ntemporal evolution does not militate against computational models with\ndiscrete temporal structure.\n7.5 Embodied cognition\nEmbodied cognition is a research program that draws inspiration\nfrom the continental philosopher Maurice Merleau-Ponty, the perceptual\npsychologist J.J. Gibson, and other assorted influences. It is a\nfairly heterogeneous movement, but the basic strategy is to emphasize\nlinks between cognition, bodily action, and the surrounding\nenvironment. See Varela, Thompson, and Rosch (1991) for an influential\nearly statement. In many cases, proponents deploy tools of dynamical\nsystems theory. Proponents typically present their approach as a\nradical alternative to computationalism (Chemero 2009; Kelso 1995;\nThelen and Smith 1994). CTM, they complain, treats mental activity as\nstatic symbol manipulation detached from the embedding environment. It\nneglects myriad complex ways that the environment causally or\nconstitutively shapes mental activity. We should replace CTM with a\nnew picture that emphasizes continuous links between mind, body, and\nenvironment. Agent-environment dynamics, not internal mental\ncomputation, holds the key to understanding cognition. Often, a\nbroadly eliminativist attitude towards intentionality propels this\ncritique.\nComputationalists respond that CTM allows due recognition of\ncognition\u2019s embodiment. Computational models can take into\naccount how mind, body, and environment continuously interact. After\nall, computational models can incorporate sensory inputs and motor\noutputs. There is no obvious reason why an emphasis upon\nagent-environment dynamics precludes a dual emphasis upon internal\nmental computation (Clark 2014: 140\u2013165; Rupert 2009).\nComputationalists maintain that CTM can incorporate any legitimate\ninsights offered by the embodied cognition movement. They also insist\nthat CTM remains our best overall framework for explaining numerous\ncore psychological phenomena.\n", "bibliography": {"categories": [], "cat_ref_text": {"ref_list": ["Aitchison, L. and Lengyel, M., 2016, \u201cThe Hamiltonian Brain:\nEfficient Probabilistic Inference with Excitatory-Inhibitory Neural\nCircuit Dynamics\u201d, <em>PloS Computational Biology</em>, 12:\ne1005186.", "Arjo, D., 1996, \u201cSticking Up for Oedipus: Fodor on\nIntentional Generalizations and Broad Content\u201d, <em>Mind and\nLanguage</em>, 11: 231\u2013245.", "Aydede, M., 1998, \u201cFodor on Concepts and Frege\nPuzzles\u201d, <em>Pacific Philosophical Quarterly</em>, 79:\n289\u2013294.", "\u2013\u2013\u2013, 2005, \u201cComputationalism and\nFunctionalism: Syntactic Theory of Mind Revisited\u201d,\nin <em>Turkish Studies in the History and Philosophy of Science</em>,\nG. Irzik and G. G\u00fczeldere (eds), Dordrecht: Springer.", "Aydede, M. and P. Robbins, 2001, \u201cAre Frege Cases Exceptions\nto Intentional Generalizations?\u201d, <em>Canadian Journal of\nPhilosophy</em>, 31: 1\u201322.", "Bechtel, W. and A. Abrahamsen, 2002, <em>Connectionism and the\nMind</em>, Malden: Blackwell.", "Berm\u00fadez, J.L., 2005, <em>Philosophy of Psychology: A\nContemporary Introduction</em>, New York: Routledge.", "\u2013\u2013\u2013, 2010, <em>Cognitive Science: An\nIntroduction to the Science of the Mind</em>, Cambridge: Cambridge\nUniversity Press.", "Block, N., 1978, \u201cTroubles With\nFunctionalism\u201d, <em>Minnesota Studies in the Philosophy of\nScience</em>, 9: 261\u2013325.", "\u2013\u2013\u2013, 1981, \u201cPsychologism and\nBehaviorism\u201d, <em>Philosophical Review</em>, 90:\n5\u201343.", "\u2013\u2013\u2013, 1983, \u201cMental Pictures and Cognitive\nScience\u201d, <em>Philosophical Review</em>, 92: 499\u2013539.", "\u2013\u2013\u2013, 1986, \u201cAdvertisement for a Semantics\nfor Psychology\u201d, <em>Midwest Studies in Philosophy</em>, 10:\n615\u2013678.", "\u2013\u2013\u2013, 1990, \u201cCan the Mind Change the\nWorld?\u201d, in <em>Meaning and Method: Essays in Honor of Hilary\nPutnam</em>, G. Boolos (ed.), Cambridge: Cambridge University\nPress.", "\u2013\u2013\u2013, 1995, <em>The Mind as the Software of the\nBrain</em>, in <em>Invitation to Cognitive Science, vol. 3:\nThinking</em>, E. Smith and B. Osherson (eds), Cambridge, MA: MIT\nPress.", "Block, N. and J. Fodor, 1972, \u201cWhat Psychological States Are\nNot\u201d, <em>The Philosophical Review</em>, 81: 159\u2013181.", "Boden, M., 1991, \u201cHorses of a Different Color?\u201d, in\nRamsey et al. 1991: 3\u201319.", "Bontly, T., 1998, \u201cIndividualism and the Nature of Syntactic\nStates\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 49: 557\u2013574.", "Bowie, G.L., 1982, \u201cLucas\u2019s Number is Finally\nUp\u201d, <em>Journal of Philosophical Logic</em>, 11:\n79\u2013285.", "Brogan, W., 1990, <em>Modern Control Theory</em>, 3rd\nedition. Englewood Cliffs: Prentice Hall.", "Buckner, C., 2019, \u201cDeep Learning: A Philosophical\nIntroduction\u201d, <em>Philosophy Compass</em>, 14: e12625.", "Buckner, C., and J. Garson, 2019, \u201cConnectionism and\nPost-Connectionist Models\u201d, in Sprevak and Colombo 2019:\n175\u2013191.", "Buesing, L., J. Bill, B. Nessler, and W. Maass, W., 2011,\n\u201cNeural Dynamics of Sampling: A Model for Stochastic Computation\nin Recurring Networks of Spiking Neurons\u201d, <em>PLOS\nComputational Biology</em>, 7: e1002211.", "Burge, T., 1982, \u201cOther Bodies\u201d, in <em>Thought and\nObject</em>, A. Woodfield (ed.), Oxford: Oxford University\nPress. Reprinted in Burge\n2007: 82\u201399.", "\u2013\u2013\u2013, 1986, \u201cIndividualism and\nPsychology\u201d, <em>The Philosophical Review</em>, 95:\n3\u201345. Reprinted in Burge\n2007: 221\u2013253.", "\u2013\u2013\u2013, 1989, \u201cIndividuation and Causation in\nPsychology\u201d, <em>Pacific Philosophical Quarterly</em>, 70:\n303\u2013322. Reprinted in Burge\n2007: 316\u2013333.", "\u2013\u2013\u2013, 1995, \u201cIntentional Properties and\nCausation\u201d, in <em>Philosophy of Psychology</em>, C. MacDonald\nand G. MacDonald (eds), Oxford: Blackwell. Reprinted in Burge\n2007: 334\u2013343.", "\u2013\u2013\u2013, 2005, \u201cDisjunctivism and Perceptual\nPsychology\u201d, <em>Philosophical Topics</em>, 33: 1\u201378.", "\u2013\u2013\u2013, 2007, <em>Foundations of Mind</em>, Oxford:\nOxford University Press.", "\u2013\u2013\u2013, 2010a, <em>Origins of Objectivity</em>,\nOxford: Oxford University Press.", "\u2013\u2013\u2013, 2010b, \u201cOrigins of\nPerception\u201d, <em>Disputatio</em>, 4: 1\u201338.", "\u2013\u2013\u2013, 2010c, \u201cSteps Towards Origins of\nPropositional Thought\u201d, <em>Disputatio</em>, 4:\n39\u201367.", "\u2013\u2013\u2013, 2013, <em>Cognition through\nUnderstanding</em>, Oxford: Oxford University Press.", "Camp, E., 2009, \u201cA Language of Baboon Thought?\u201d,\nin <em>The Philosophy of Animal Minds</em>, R. Lurz (ed.), Cambridge:\nCambridge University Press.", "Carruthers, P., 2003, \u201cOn Fodor\u2019s\nProblem\u201d, <em>Mind and Language</em>, 18: 508\u2013523.", "Chalmers, D., 1990, \u201cSyntactic Transformations on\nDistributed Representations\u201d, <em>Connection Science</em>, 2:\n53\u201362.", "\u2013\u2013\u2013, 1993, \u201cWhy Fodor and Pylyshyn Were\nWrong: The Simplest Refutation\u201d, <em>Philosophical\nPsychology</em>, 63: 305\u2013319.", "\u2013\u2013\u2013, 1995, \u201cOn Implementing a\nComputation\u201d, <em>Minds and Machines</em>, 4:\n391\u2013402.", "\u2013\u2013\u2013, 1996a, \u201cDoes a Rock Implement Every\nFinite State Automaton?\u201d, <em>Synthese</em>, 108:\n309\u2013333.", "\u2013\u2013\u2013, 1996b, \u201cMinds, Machines, and\nMathematics\u201d, <em>Psyche</em>, 2: 11\u201320.", "\u2013\u2013\u2013, 2002, \u201cThe Components of\nContent\u201d, in <em>Philosophy of Mind: Classical and Contemporary\nReadings</em>, D. Chalmers (ed.), Oxford: Oxford University\nPress.", "\u2013\u2013\u2013, 2011, \u201cA Computational Foundation for\nthe Study of Cognition\u201d, <em>The Journal of Cognitive\nScience</em>, 12: 323\u2013357.", "\u2013\u2013\u2013, 2012, \u201cThe Varieties of Computation:\nA Reply\u201d, <em>The Journal of Cognitive Science</em>, 13:\n213\u2013248.", "Chemero, A., 2009, <em>Radical Embodied Cognitive Science</em>,\nCambridge, MA: MIT Press.", "Cheney, D. and R. Seyfarth, 2007, <em>Baboon Metaphysics: The\nEvolution of a Social Mind</em>, Chicago: University of Chicago\nPress.", "Chomsky, N., 1965, <em>Aspects of the Theory of Syntax</em>,\nCambridge, MA: MIT Press.", "Church, A., 1936, \u201cAn Unsolvable Problem of Elementary\nNumber Theory\u201d, <em>American Journal of Mathematics</em>, 58:\n345\u2013363.", "Churchland, P.M., 1981, \u201cEliminative Materialism and the\nPropositional Attitudes\u201d, <em>Journal of Philosophy</em>, 78:\n67\u201390.", "\u2013\u2013\u2013, 1989, <em>A Neurocomputational Perspective:\nThe Nature of Mind and the Structure of Science</em>, Cambridge, MA: MIT\nPress.", "\u2013\u2013\u2013, 1995, <em>The Engine of Reason, the Seat of\nthe Soul</em>, Cambridge, MA: MIT Press.", "\u2013\u2013\u2013, 2007, <em>Neurophilosophy At Work</em>,\nCambridge: Cambridge University Press.", "Churchland, P.S., 1986, <em>Neurophilosophy</em>, Cambridge, MA: MIT\nPress.", "Churchland, P.S., C. Koch, and T. Sejnowski, 1990, \u201cWhat Is\nComputational Neuroscience?\u201d, in <em>Computational\nNeuroscience</em>, E. Schwartz (ed.), Cambridge, MA: MIT Press.", "Churchland, P.S. and T. Sejnowski, 1992, <em>The Computational\nBrain</em>, Cambridge, MA: MIT Press.", "Clark, A., 2014, <em>Mindware: An Introduction to the Philosophy\nof Cognitive Science</em>, Oxford: Oxford University Press.", "Clayton, N., N. Emery, and A. Dickinson, 2006, \u201cThe\nRationality of Animal Memory: Complex Caching Strategies of Western\nScrub Jays\u201d, in <em>Rational Animals?</em>, M. Nudds and\nS. Hurley (eds), Oxford: Oxford University Press.", "Copeland, J., 1996, \u201cWhat is\nComputation?\u201d, <em>Synthese</em>, 108: 335\u2013359.", "Cover, T. and J. Thomas, 2006, <em>Elements of Information\nTheory</em>, Hoboken: Wiley.", "Crane, T., 1991, \u201cAll the Difference in the\nWorld\u201d, <em>Philosophical Quarterly</em>, 41: 1\u201325.", "Crick, F. and C. Asanuma, 1986, \u201cCertain Aspects of the\nAnatomy and Physiology of the Cerebral Cortex\u201d, in McClelland et\nal. 1987: 333\u2013371.", "Cummins, R., 1989, <em>Meaning and Mental Representation</em>,\nCambridge, MA: MIT Press.", "Davidson, D., 1980, <em>Essays on Actions and Events</em>, Oxford:\nClarendon Press.", "Dayan, P., 2009, \u201cA Neurocomputational\nJeremiad\u201d, <em>Nature Neuroscience</em>, 12: 1207.", "Dennett, D., 1971, \u201cIntentional Systems\u201d, <em>Journal\nof Philosophy</em>, 68: 87\u2013106.", "\u2013\u2013\u2013, 1987, <em>The Intentional Stance</em>,\nCambridge, MA: MIT Press.", "\u2013\u2013\u2013, 1991, \u201cMother Nature versus the\nWalking Encyclopedia\u201d, in Ramsey, et\nal. 1991: 21\u201330.", "Dietrich, E., 1989, \u201cSemantics and the Computational\nParadigm in Cognitive Psychology\u201d, <em>Synthese</em>, 79:\n119\u2013141.", "Donahoe, J., 2010, \u201cMan as Machine: A Review of <em>Memory\nand Computational Brain</em>, by C.R. Gallistel and\nA.P. King\u201d, <em>Behavior and Philosophy</em>, 38:\n83\u2013101.", "Dreyfus, H., 1972, <em>What Computers Can\u2019t Do</em>,\nCambridge, MA: MIT Press.", "\u2013\u2013\u2013, 1992, <em>What Computers Still Can\u2019t\nDo</em>, Cambridge, MA: MIT Press.", "Dretske, F., 1981, <em>Knowledge and the Flow of Information</em>,\nOxford: Blackwell.", "\u2013\u2013\u2013, 1993, \u201cMental Events as Structuring\nCauses of Behavior\u201d, in <em>Mental Causation</em>, J. Heil and\nA. Mele (eds), Oxford: Clarendon Press.", "Edelman, S., 2008, <em>Computing the Mind</em>, Oxford: Oxford\nUniversity Press.", "\u2013\u2013\u2013, 2014, \u201cHow to Write a \u2018How a\nBuild a Brain\u2019 Book\u201d, <em>Trends in Cognitive\nScience</em>, 18: 118\u2013119.", "Egan, F., 1991, \u201cMust Psychology be\nIndividualistic?\u201d, <em>Philosophical Review</em>, 100:\n179\u2013203.", "\u2013\u2013\u2013, 1992, \u201cIndividualism, Computation,\nand Perceptual Content\u201d, <em>Mind</em>, 101: 443\u2013459.", "\u2013\u2013\u2013, 1999, \u201cIn Defense of Narrow\nMindedness\u201d, <em>Mind and Language</em>, 14: 177\u2013194.", "\u2013\u2013\u2013, 2003, \u201cNaturalistic Inquiry: Where\nDoes Mental Representation Fit In?\u201d, in <em>Chomsky and His\nCritics</em>, L. Antony and N. Hornstein (eds), Malden:\nBlackwell.", "\u2013\u2013\u2013, 2010, \u201cA Modest Role for\nContent\u201d, <em>Studies in History and Philosophy of Science</em>,\n41: 253\u2013259.", "\u2013\u2013\u2013, 2014, \u201cHow to Think About Mental\nContent\u201d, <em>Philosophical Studies</em>, 170:\n115\u2013135.", "\u2013\u2013\u2013, 2019, \u201cThe Nature and Function of\nContent in Computational Models\u201d, in Sprevak and Colombo 2019:\n247\u2013258.", "Eliasmith, C., 2003, \u201cMoving Beyond Metaphors: Understanding\nthe Mind for What It Is\u201d, <em>Journal of Philosophy</em>, 100:\n493\u2013520.", "\u2013\u2013\u2013, 2013, <em>How to Build a Brain</em>,\nOxford: Oxford: University Press.", "Eliasmith, C. and C.H. Anderson, 2003, <em>Neural Engineering:\nComputation, Representation and Dynamics in Neurobiological\nSystems</em>, Cambridge, MA: MIT Press.", "Elman, J., 1990, \u201cFinding Structure in\nTime\u201d, <em>Cognitive Science</em>, 14: 179\u2013211.", "Feferman, S., 1996, \u201cPenrose\u2019s G\u00f6delian\nArgument\u201d, <em>Psyche</em>, 2: 21\u201332.", "Feldman, J. and D. Ballard, 1982, \u201cConnectionist Models and\ntheir Properties\u201d, <em>Cognitive Science</em>, 6:\n205\u2013254.", "Field, H., 2001, <em>Truth and the Absence of Fact</em>, Oxford:\nClarendon Press.", "Figdor, C., 2009, \u201cSemantic Externalism and the Mechanics of\nThought\u201d, <em>Minds and Machines</em>, 19: 1\u201324.", "Fodor, J., 1975, <em>The Language of Thought</em>, New York:\nThomas Y. Crowell.", "\u2013\u2013\u2013, 1980, \u201cMethodological Solipsism\nConsidered as a Research Strategy in Cognitive\nPsychology\u201d, <em>Behavioral and Brain Science</em>, 3:\n63\u201373. Reprinted in Fodor\n1981: 225\u2013253.", "\u2013\u2013\u2013, 1981, <em>Representations</em>, Cambridge:\nMIT Press.", "\u2013\u2013\u2013, 1983, <em>The Modularity of Mind</em>,\nCambridge, MA: MIT Press.", "\u2013\u2013\u2013, 1987, <em>Psychosemantics</em>, Cambridge:\nMIT Press.", "\u2013\u2013\u2013, 1990, <em>A Theory of Content and Other\nEssays</em>, Cambridge, MA: MIT Press.", "\u2013\u2013\u2013, 1991, \u201cA Modal Argument for Narrow\nContent\u201d, <em>Journal of Philosophy</em>, 88: 5\u201326.", "\u2013\u2013\u2013, 1994, <em>The Elm and the Expert</em>,\nCambridge, MA: MIT Press.", "\u2013\u2013\u2013, 1998, <em>Concepts</em>, Oxford: Clarendon\nPress.", "\u2013\u2013\u2013, 2000, <em>The Mind Doesn\u2019t Work That\nWay</em>, Cambridge, MA: MIT Press.", "\u2013\u2013\u2013, 2005, \u201cReply to Steven Pinker\n\u2018So How Does the Mind Work?\u2019\u201d, <em>Mind and\nLanguage</em>, 20: 25\u201332.", "\u2013\u2013\u2013, 2008, <em>LOT2</em>, Oxford: Clarendon\nPress.", "Fodor, J. and Z. Pylyshyn, 1988, \u201cConnectionism and\nCognitive Architecture: A Critical\nAnalysis\u201d, <em>Cognition</em>, 28: 3\u201371.", "Frege, G., 1879/1967, <em>Begriffsschrift, eine der Arithmetischen\nNachgebildete Formelsprache des Reinen Denkens</em>. Reprinted\nas <em>Concept Script, a Formal Language of Pure Thought Modeled upon\nthat of Arithmetic</em>, in <em>From Frege to G\u00f6del: A Source\nBook in Mathematical Logic, 1879\u20131931</em>, J. van Heijenoort\n(ed.), S. Bauer-Mengelberg (trans.), Cambridge: Harvard University\nPress.", "Gallistel, C.R., 1990, <em>The Organization of Learning</em>,\nCambridge, MA: MIT Press.", "Gallistel, C.R. and King, A., 2009, <em>Memory and the\nComputational Brain</em>, Malden: Wiley-Blackwell.", "Gandy, R., 1980, \u201cChurch\u2019s Thesis and Principles for\nMechanism\u201d, in <em>The Kleene Symposium</em>, J. Barwise,\nH. Keisler, and K. Kunen (eds). Amsterdam: North Holland.", "G\u00f6del, K., 1936/65. \u201cOn Formally Undecidable\nPropositions of Principia Mathematica and Related Systems\u201d,\nReprinted with a new Postscript in <em>The Undecidable</em>, M. Davis\n(ed.), New York: Raven Press Books.", "Grice, P., 1989, <em>Studies in the Ways of Words</em>, Cambridge:\nHarvard University Press.", "Hadley, R., 2000, \u201cCognition and the Computational Power of\nConnectionist Networks\u201d, <em>Connection Science</em>, 12:\n95\u2013110.", "Harnish, R., 2002, <em>Minds, Brains, Computers</em>, Malden:\nBlackwell.", "Haykin, S., 2008, <em>Neural Networks: A Comprehensive\nFoundation</em>, New York: Prentice Hall.", "Haugeland, J., 1985, <em>Artificial Intelligence: The Very\nIdea</em>, Cambridge, MA: MIT Press.", "Horgan, T. and J. Tienson, 1996, <em>Connectionism and the\nPhilosophy of Psychology</em>, Cambridge, MA: MIT Press.", "Horowitz, A., 2007, \u201cComputation, External Factors, and\nCognitive Explanations\u201d, <em>Philosophical Psychology</em>, 20:\n65\u201380.", "Johnson, K., 2004, \u201cOn the Systematicity of Language and\nThought\u201d, <em>Journal of Philosophy</em>, 101:\n111\u2013139.", "Johnson-Laird, P., 1988, <em>The Computer and the Mind</em>,\nCambridge: Harvard University Press.", "\u2013\u2013\u2013, 2004, \u201cThe History of Mental\nModels\u201d, in <em>Psychology of Reasoning: Theoretical and\nHistorical Perspectives</em>, K. Manktelow and M.C. Chung (eds), New\nYork: Psychology Press.", "Kazez, J., 1995, \u201cComputationalism and the Causal Role of\nContent\u201d, <em>Philosophical Studies</em>, 75:\n231\u2013260.", "Kelso, J., 1995, <em>Dynamic Patterns</em>, Cambridge, MA: MIT\nPress.", "Klein, C., 2012, \u201cTwo Paradigms for Individuating\nImplementations\u201d, <em>Journal of Cognitive Science</em>, 13:\n167\u2013179.", "Kriegesgorte, K., 2015, \u201cDeep Neural Networks: A New\nFramework for Modeling Biological Vision and Brain Information\nProcessing\u201d, <em>Annual Review of Vision Science</em>, 1:\n417\u2013446.", "Kriegesgorte, K. and P. Douglas, 2018, \u201cCognitive\nComputational Neuroscience\u201d, <em>Nature Neuroscience</em>, 21:\n1148\u20131160.", "Krishevsky, A., I. Sutskever, and G. Hinton, 2012, \u201cImageNet\nClassification with Deep Convolutional Neural\nNetworks\u201d, <em>Advances in Neural Information Processing\nSystems</em>, 25: 1097\u20131105.", "Krotov, D., and J. Hopfield, 2019, \u201cUnsupervised Learning by\nCompeting Hidden Units\u201d, <em>Proceedings of the National Academy\nof Sciences</em>, 116: 7723\u20137731.", "Ladyman, J., 2009, \u201cWhat Does it Mean to Say that a Physical\nSystem Implements a Computation?\u201d, <em>Theoretical Computer\nScience</em>, 410: 376\u2013383.", "LeCun, Y., Y. Bengio, and G. Hinton, 2015, \u201cDeep\nLearning\u201d, <em>Nature</em>, 521: 436\u2013444.", "Lewis, D., 1969, \u201cLucas against\nMechanism\u201d, <em>Philosophy</em>, 44: 231\u20133.", "\u2013\u2013\u2013, 1972, \u201cPsychophysical and Theoretical\nIdentifications\u201d, <em>Australasian Journal of Philosophy</em>,\n50: 249\u201358.", "\u2013\u2013\u2013, 1979, \u201cLucas Against Mechanism\nII\u201d, <em>Canadian Journal of Philosophy</em>, 9:\n373\u2013376.", "\u2013\u2013\u2013, 1994, \u201cReduction of Mind\u201d,\nin <em>A Companion to the Philosophy of Mind</em>, S. Guttenplan\n(ed.), Oxford: Blackwell.", "Lizier, J., B. Flecker, and P. Williams, 2013, \u201cTowards a\nSynergy-based Account of Measuring Information\nModification\u201d, <em>Proceedings of the 2013 IEEE Symposium on\nArtificial Life (ALIFE)</em>, Singapore: 43\u201351.", "Ludwig, K. and S. Schneider, 2008, \u201cFodor\u2019s Critique\nof the Classical Computational Theory of Mind\u201d, <em>Mind and\nLanguage</em>, 23: 123\u2013143.", "Lucas, J.R., 1961, \u201cMinds, Machines, and\nG\u00f6del\u201d, <em>Philosophy</em>, 36: 112\u2013137.", "Ma, W. J., 2019, \u201cBayesian Decision Models: A\nPrimer\u201d, <em>Neuron</em>, 104: 164\u2013175.", "Maass, W., 1997, \u201cNetworks of Spiking Neurons: The Next\nGeneration of Neural Network Models\u201d, <em>Neural Networks</em>,\n10: 1659\u20131671.", "MacLennan, B., 2012, \u201cAnalog\nComputation\u201d, <em>Computational Complexity</em>, R. Meyers\n(ed.), New York: Springer. ", "Marblestone, A., G. Wayne, and K. Kording, 2016, \u201cToward an\nIntegration of Deep Learning and Neuroscience\u201d, <em>Frontiers in\nComputational Neuroscience</em>, 10: 1\u201341.", "Marcus, G., 2001, <em>The Algebraic Mind</em>, Cambridge, MA: MIT\nPress.", "Marr, D., 1982, <em>Vision</em>, San Francisco: W.H. Freeman.", "McClelland, J., D. Rumelhart, and G. Hinton, 1986, \u201cThe\nAppeal of Parallel Distributed Processing\u201d, in Rumelhart et\nal. 1986: 3\u201344.", "McClelland, J., D. Rumelhart, and the PDP Research Group,\n1987, <em>Parallel Distributed Processing</em>, vol. 2. Cambridge, MA: MIT\nPress.", "McCulloch, W. and W. Pitts, 1943, \u201cA Logical Calculus of the\nIdeas Immanent in Nervous Activity\u201d, <em>Bulletin of\nMathematical Biophysics</em>, 7: 115\u2013133.", "McDermott, D., 2001, <em>Mind and Mechanism</em>, Cambridge, MA: MIT\nPress.", "Mendola, J., 2008, <em>Anti-Externalism</em>, Oxford: Oxford\nUniversity Press.", "Milkowski, M., 2013, <em>Explaining the Computational Mind</em>,\nCambridge, MA: MIT Press.", "Miller, P., 2018, <em>An Introductory Course in Computational\nNeuroscience</em>, Cambridge, MA: MIT Press.", "Mole, C., 2014, \u201cDead Reckoning in the Desert Ant: A Defense\nof Connectionist Models\u201d, <em>Review of Philosophy and\nPsychology</em>, 5: 277\u2013290.", "Murphy, K., 2012, <em>Machine Learning: A Probabilistic\nPerspective</em>, Cambridge, MA: MIT Press.", "Naselaris, T., Bassett, D., Fletcher, A., K\u00f6rding, K.,\nKriegeskorte, N., Nienborg, H., Poldrack, R., Shohamy, D., and Kay,\nK., 2018, \u201cCognitive Computational Neuroscience: A New\nConference for an Emerging Discipline\u201d, <em>Trends in Cognitive\nScience</em>, 22: 365\u2013367.", "Nagel, E. and J.R. Newman, 1958, <em>G\u00f6del\u2019s\nProof</em>, New York: New York University Press.", "Newell, A., 1990, <em>Unified Theories of Cognition</em>,\nCambridge: Harvard University Press.", "Newell, A. and H. Simon, 1956, \u201cThe Logic Theory Machine: A\nComplex Information Processing System\u201d, <em>IRE Transactions on\nInformation Theory, IT-2</em>, 3: 61\u201379.", "\u2013\u2013\u2013, 1976, \u201cComputer Science as Empirical\nInquiry: Symbols and Search\u201d, <em>Communications of the\nACM</em>, 19: 113\u2013126.", "O\u2019Keefe, J. and L. Nadel, 1978, <em>The Hippocampus as a\nCognitive Map</em>, Oxford: Clarendon University Press.", "Ockham, W., 1957, <em>Summa Logicae</em>, in his <em>Philosophical\nWritings, A Selection</em>, P. Boehner (ed. and trans.), London:\nNelson.", "Orhan, A. E. and Ma, W. J., 2017, \u201cEfficient Probabilistic\nInference in Generic Neural Networks Trained with Non-probabilistic\nFeedback \u201d, <em>Nature Communications</em>, 8: 1\u201314.", "Peacocke, C., 1992, <em>A Study of Concepts</em>, Cambridge, MA: MIT\nPress.", "\u2013\u2013\u2013, 1993, \u201cExternalist\nExplanation\u201d, <em>Proceedings of the Aristotelian Society</em>,\n67: 203\u2013230.", "\u2013\u2013\u2013, 1994, \u201cContent, Computation, and\nExternalism\u201d, <em>Mind and Language</em>, 9: 303\u2013335.", "\u2013\u2013\u2013, 1999, \u201cComputation as Involving\nContent: A Response to Egan\u201d, <em>Mind and Language</em>, 14:\n195\u2013202.", "Penrose, R., 1989, <em>The Emperor\u2019s New Mind: Concerning\nComputers, Minds, and the Laws of Physics</em>, Oxford: Oxford\nUniversity Press.", "Perry, J., 1998, \u201cBroadening the Mind\u201d, <em>Philosophy\nand Phenomenological Research</em>, 58: 223\u2013231.", "Piantadosi, S., J. Tenenbaum, and N. Goodman, 2012,\n\u201cBootstrapping in a Language of\nThought\u201d, <em>Cognition</em>, 123: 199\u2013217.", "Piccinini, G., 2004, \u201cFunctionalism, Computationalism, and\nMental States\u201d, <em>Studies in History and Philosophy of\nScience</em>, 35: 811\u2013833.", "\u2013\u2013\u2013, 2007, \u201cComputing\nMechanisms\u201d, <em>Philosophy of Science</em>, 74:\n501\u2013526.", "\u2013\u2013\u2013, 2008a, \u201cComputation Without\nRepresentation\u201d, <em>Philosophical Studies</em>, 137:\n205\u2013241.", "\u2013\u2013\u2013, 2008b, \u201cSome Neural Networks Compute,\nOthers Don\u2019t\u201d, <em>Neural Networks</em>, 21:\n311\u2013321.", "\u2013\u2013\u2013, 2010, \u201cThe Resilience of\nComputationalism\u201d, <em>Philosophy of Science</em>, 77:\n852\u2013861.", "\u2013\u2013\u2013, 2012, \u201cComputationalism\u201d,\nin <em>The Oxford Handbook of Philosophy and Cognitive Science</em>,\nE. Margolis, R. Samuels, and S. Stich (eds), Oxford: Oxford University\nPress. ", "\u2013\u2013\u2013, 2015, <em>Physical Computation: A\nMechanistic Account</em>, Oxford: Oxford University Press.", "Piccinini, G. and A. Scarantino, 2010, \u201cComputation\nvs. Information processing: Why their Difference Matters to Cognitive\nScience\u201d, <em>Studies in History and Philosophy of Science</em>,\n41: 237\u2013246.", "Piccinini, G. and S. Bahar, 2013, \u201cNeural Computation and\nthe Computational Theory of Cognition\u201d, <em>Cognitive\nScience</em>, 37: 453\u2013488.", "Piccinini, G. and O. Shagrir, 2014, \u201cFoundations of\nComputational Neuroscience\u201d, <em>Current Opinion in\nNeurobiology</em>, 25: 25\u201330.", "Pinker, S., 2005, \u201cSo How Does the Mind\nWork?\u201d, <em>Mind and Language</em>, 20: 1\u201324.", "Pinker, S. and A. Prince, 1988, \u201cOn Language and\nConnectionism\u201d, <em>Cognition</em>, 28: 73\u2013193.", "Pouget, A., Beck, J., Ma., W. J., and Latham, P., 2013,\n\u201cProbabilistic Brains: Knowns and Unknowns\u201d, <em>Nature\nNeuroscience</em>, 16: 1170\u20131178.", "Putnam, H., 1967, \u201cPsychophysical Predicates\u201d,\nin <em>Art, Mind, and Religion</em>, W. Capitan and D. Merrill (eds),\nPittsburgh: University of Pittsburgh Press. Reprinted in Putnam 1975\nas \u201cThe Nature of Mental\nStates\u201d: 429\u2013440.", "\u2013\u2013\u2013, 1975, <em>Mind, Language, and Reality:\nPhilosophical Papers, vol. 2</em>, Cambridge: Cambridge University\nPress.", "\u2013\u2013\u2013, 1983, <em>Realism and Reason: Philosophical\nPapers</em>, vol. 3. Cambridge: Cambridge University Press.", "\u2013\u2013\u2013, 1988, <em>Representation and Reality</em>,\nCambridge, MA: MIT Press.", "\u2013\u2013\u2013, 1994, \u201cThe Best of All Possible\nBrains?\u201d, <em>The New York Times</em>, November 20,\n1994: 7.", " Pylyshyn, Z., 1984, <em>Computation and Cognition</em>,\nCambridge, MA: MIT Press.", "Quine, W.V.O., 1960, <em>Word and Object</em>, Cambridge, MA: MIT\nPress.", "Ramsey, W., S. Stich, and D. Rumelhart (eds), 1991, <em>Philosophy\nand Connectionist Theory</em>, Hillsdale: Lawrence Erlbaum\nAssociates.", "Rescorla, M., 2009a, \u201cChrysippus\u2019s Dog as a Case Study\nin Non-Linguistic Cognition\u201d, in <em>The Philosophy of Animal\nMinds</em>, R. Lurz (ed.), Cambridge: Cambridge University Press.", "\u2013\u2013\u2013, 2009b, \u201cCognitive Maps and the\nLanguage of Thought\u201d, <em>The British Journal for the Philosophy\nof Science</em>, 60: 377\u2013407.", "\u2013\u2013\u2013, 2012, \u201cHow to Integrate\nRepresentation into Computational Modeling, and Why We\nShould\u201d, <em>Journal of Cognitive Science</em>, 13:\n1\u201338.", "\u2013\u2013\u2013, 2013, \u201cAgainst Structuralist Theories\nof Computational Implementation\u201d, <em>British Journal for the\nPhilosophy of Science</em>, 64: 681\u2013707.", "\u2013\u2013\u2013, 2014a, \u201cThe Causal Relevance of\nContent to Computation\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 88: 173\u2013208.", "\u2013\u2013\u2013, 2014b, \u201cA Theory of Computational\nImplementation\u201d, <em>Synthese</em>, 191: 1277\u20131307.", "\u2013\u2013\u2013, 2015, \u201cBayesian Perceptual\nPsychology\u201d, in <em>The Oxford Handbook of the Philosophy of\nPerception</em>, M. Matthen (ed.), Oxford: Oxford University\nPress.", "\u2013\u2013\u2013, 2017a, \u201cFrom Ockham to\nTuring\u2014and Back Again\u201d, in <em>Turing 100: Philosophical\nExplorations of the Legacy of Alan Turing</em>, (<em>Boston Studies in\nthe Philosophy and History</em>), A. Bokulich and J. Floyd (eds),\nSpringer.", "\u2013\u2013\u2013, 2017b, \u201cLevels of Computational\nExplanation\u201d, in <em>Philosophy and Computing: Essays in\nEpistemology, Philosophy of Mind, Logic, and Ethics</em>, T. Powers\n(ed.), Cham: Springer.", "\u2013\u2013\u2013, 2020, \u201cA Realist Perspective\non Bayesian Cognitive Science\u201d, in <em>Inference and\nConsciousness</em>, A. Nes and T. Chan (eds.), New York: Routledge.", "Rogers, T. and J. McClelland, 2014, \u201cParallel Distributed\nProcessing at 25: Further Explorations of the Microstructure of\nCognition\u201d, <em>Cognitive Science</em>, 38:\n1024\u20131077.", "Rumelhart, D., 1989, \u201cThe Architecture of Mind: A\nConnectionist Approach\u201d, in <em>Foundations of Cognitive\nScience</em>, M. Posner (ed.), Cambridge, MA: MIT Press.", "Rumelhart, D., G. Hinton, and R. Williams, 1986, \u201cLearning\nRepresentations by Back-propagating Errors\u201d, <em>Nature</em>,\n323: 533\u2013536.", "Rumelhart, D. and J. McClelland, 1986, \u201cPDP Models and\nGeneral Issues in Cognitive Science\u201d, in Rumelhart et\nal. 1986: 110\u2013146.", "Rumelhart, D., J. McClelland, and the PDP Research Group,\n1986, <em>Parallel Distributed Processing</em>, vol. 1. Cambridge:\nMIT Press.", "Rupert, R., 2008, \u201cFrege\u2019s Puzzle and Frege Cases:\nDefending a Quasi-Syntactic Solution\u201d, <em>Cognitive Systems\nResearch</em>, 9: 76\u201391.", "\u2013\u2013\u2013, 2009, <em>Cognitive Systems and the\nExtended Mind</em>, Oxford: Oxford University Press.", "Russell, S. and P. Norvig, 2010, <em>Artificial Intelligence: A\nModern Approach</em>, 3<sup>rd</sup> ed., New York: Prentice\nHall.", "Sawyer, S., 2000, \u201cThere Is No Viable Notion of Narrow\nContent\u201d, in <em>Contemporary Debates in Philosophy of\nMind</em>, B. McLaughlin and J. Cohen (eds), Malden: Blackwell.", "Schneider, S., 2005, \u201cDirect Reference, Psychological\nExplanation, and Frege Cases\u201d, <em>Mind and Language</em>, 20:\n423\u2013447.", "\u2013\u2013\u2013, 2011, <em>The Language of Thought: A New\nPhilosophical Direction</em>, Cambridge, MA: MIT Press.", "Searle, J., 1980, \u201cMinds, Brains, and\nPrograms\u201d, <em>Behavioral and Brain Sciences</em>, 3:\n417\u2013457.", "\u2013\u2013\u2013, 1990, \u201cIs the Brain a Digital\nComputer?\u201d, <em>Proceedings and Addresses of the American\nPhilosophical Association</em>, 64: 21\u201337.", "Segal, G., 2000, <em>A Slim Book About Narrow Content</em>,\nCambridge, MA: MIT Press.", "Shagrir, O., 2001, \u201cContent, Computation, and\nExternalism\u201d, <em>Mind</em>, 110: 369\u2013400.", "\u2013\u2013\u2013, 2006, \u201cWhy We View the Brain as a\nComputer\u201d, <em>Synthese</em>, 153: 393\u2013416.", "\u2013\u2013\u2013, 2014, \u201cReview of <em>Explaining the\nComputational Theory of Mind</em>, by Marcin\nMilkowski\u201d, <em>Notre Dame Review of Philosophy</em>, January\n2014.", "\u2013\u2013\u2013, forthcoming, \u201cIn Defense of the\nSemantic View of Computation\u201d, <em>Synthese</em>,\nfirst online 11 October 2018; doi:10.1007/s11229-018-01921-z", "Shannon, C., 1948, \u201cA Mathematical Theory of\nCommunication\u201d, <em>Bell System Technical Journal</em> 27:\n379\u2013423, 623\u2013656.", "Shapiro, S., 2003, \u201cTruth, Mechanism, and Penrose\u2019s\nNew Argument\u201d, <em>Journal of Philosophical Logic</em>, 32:\n19\u201342.", "Shea, N., 2013, \u201cNaturalizing Representational\nContent\u201d, <em>Philosophy Compass</em>, 8: 496\u2013509.", "\u2013\u2013\u2013, 2018, <em>Representation in Cognitive\nScience</em>, Oxford: Oxford University Press.", "Sieg, W., 2009, \u201cOn Computability\u201d, in <em>Philosophy\nof Mathematics</em>, A. Irvine (ed.), Burlington: Elsevier.", "Siegelmann, H. and E. Sontag, 1991, \u201cTuring Computability\nwith Neural Nets\u201d, <em>Applied Mathematics Letters</em>, 4:\n77\u201380.", "Siegelmann, H. and E. Sontag, 1995, \u201cOn the Computational\nPower of Neural Nets\u201d, <em>Journal of Computer and Science\nSystems</em>, 50: 132\u2013150.", "Silverberg, A., 2006, \u201cChomsky and Egan on Computational\nTheories of Vision\u201d, <em>Minds and Machines</em>, 16:\n495\u2013524.", "Sloman, A., 1978, <em>The Computer Revolution in Philosophy</em>,\nHassocks: The Harvester Press.", "Smolensky, P., 1988, \u201cOn the Proper Treatment of\nConnectionism\u201d, <em>Behavioral and Brain Sciences</em>, 11:\n1\u201374.", "\u2013\u2013\u2013, 1991, \u201cConnectionism, Constituency,\nand the Language of Thought\u201d, in <em>Meaning in Mind: Fodor and\nHis Critics</em>, B. Loewer and G. Rey (eds), Cambridge:\nBlackwell.", "Sperber, D., 2002, \u201cIn Defense of Massive Modularity\u201d,\nin <em>Language, Brain, and Cognitive Development: Essays in Honor of\nJacques Mehler</em>, E. Dupoux (ed.), Cambridge, MA: MIT Press.", "Sprevak, M., 2010, \u201cComputation, Individuation, and the\nReceived View on Representation\u201d, <em>Studies in History and\nPhilosophy of Science</em>, 41: 260\u2013270.", "\u2013\u2013\u2013, 2019, \u201cTriviality Arguments About\nComputational Implementation\u201d, in Sprevak and Colombo 2019:\n175\u2013191.", "\u2013\u2013\u2013, forthcoming, \u201cTwo Kinds of\nInformation Processing in Cognition\u201d, <em>Review of Philosophy\nand Psychology</em>.", "Sprevak, M. and Colombo, M., 2019, <em>The Routledge Handbook of\nthe Computational Mind</em>, New York: Routledge.", "Stalnaker, R., 1999, <em>Context and Content</em>, Oxford: Oxford\nUniversity Press.", "Stich, S., 1983, <em>From Folk Psychology to Cognitive\nScience</em>, Cambridge, MA: MIT Press.", "Thelen, E. and L. Smith, 1994, <em>A Dynamical Systems Approach to\nthe Development of Cognition and Action</em>, Cambridge, MA: MIT\nPress.", "Thrun, S., W. Burgard, and D. Fox, 2006, <em>Probabilistic\nRobotics</em>, Cambridge, MA: MIT Press.", "Thrun, S., M. Montemerlo, and H. Dahlkamp, et al., 2006,\n\u201cStanley: The Robot That Won the DARPA Grand\nChallenge\u201d, <em>Journal of Field Robotics</em>, 23:\n661\u2013692.", "Tolman, E., 1948, \u201cCognitive Maps in Rats and\nMen\u201d, <em>Psychological Review</em>, 55: 189\u2013208.", "Trappenberg, T., 2010, <em>Fundamentals of Computational\nNeuroscience</em>, Oxford: Oxford University Press.", "Turing, A., 1936, \u201cOn Computable Numbers, with an\nApplication to the Entscheidungsproblem\u201d, <em>Proceedings of the\nLondon Mathematical Society</em>, 42: 230\u2013265.", "\u2013\u2013\u2013, 1950, \u201cComputing Machinery and\nIntelligence\u201d, <em>Mind</em>, 49: 433\u2013460.", "van Gelder, T., 1990, \u201cCompositionality: A Connectionist\nVariation on a Classical Theme\u201d,<em>Cognitive Science</em>, 14:\n355\u2013384.", "van Gelder, T. and R. Port, 1995, \u201cIt\u2019s About Time: An\nOverview of the Dynamical Approach to Cognition\u201d, in <em>Mind as\nMotion: Explorations in the Dynamics of Cognition</em>, R. Port and\nT. van Gelder (eds), Cambridge, MA: MIT Press.", "Varela, F., Thompson, E. and Rosch, E., 1991, <em>The Embodied\nMind: Cognitive Science and Human Experience</em>, Cambridge, MA: MIT\nPress.", "von Neumann, J., 1945, \u201cFirst Draft of a Report on the\nEDVAC\u201d, Moore School of Electrical Engineering, University of\nPennsylvania. Philadelphia, PA.", "Wakefield, J., 2002, \u201cBroad versus Narrow Content in the\nExplanation of Action: Fodor on Frege Cases\u201d, <em>Philosophical\nPsychology</em>, 15: 119\u2013133.", "Weiskopf, D., 2004, \u201cThe Place of Time in\nCognition\u201d, <em>British Journal for the Philosophy of\nScience</em>, 55: 87\u2013105.", "Whitehead, A.N. and B. Russell, 1925, <em>Principia\nMathematica</em>, vol. 1, 2<sup>nd</sup> ed., Cambridge: Cambridge\nUniversity Press.", "Wilson, R., 2005, \u201cWhat Computers (Still, Still) Can\u2019t\nDo\u201d, in <em>New Essays in Philosophy of Language and Mind</em>,\nR. Stainton, M. Ezcurdia, and C.D. Viger (eds). <em>Canadian Journal\nof Philosophy</em>, supplementary issue 30: 407\u2013425.", "Yablo, S., 1997, \u201cWide Causation\u201d, <em>Philosophical\nPerspectives</em>, 11: 251\u2013281.", "\u2013\u2013\u2013, 2003, \u201cCausal\nRelevance\u201d, <em>Philosophical Issues</em>, 13:\n316\u2013327.", "Zednik, C., 2019, \u201cComputational Cognitive\nNeuroscience\u201d, in Sprevak and Colombo 2019: 357\u2013369.", "Zylberberg, A., S. Dehaene, P. Roelfsema, and M. Sigman, 2011,\n\u201cThe Human Turing Machine\u201d, <em>Trends in Cognitive\nScience</em>, 15: 293\u2013300."]}, "raw_text": "<div id=\"bibliography\">\n<h2><a id=\"Bib\">Bibliography</a></h2>\n<ul class=\"hanging\">\n<li>Aitchison, L. and Lengyel, M., 2016, \u201cThe Hamiltonian Brain:\nEfficient Probabilistic Inference with Excitatory-Inhibitory Neural\nCircuit Dynamics\u201d, <em>PloS Computational Biology</em>, 12:\ne1005186.</li>\n<li>Arjo, D., 1996, \u201cSticking Up for Oedipus: Fodor on\nIntentional Generalizations and Broad Content\u201d, <em>Mind and\nLanguage</em>, 11: 231\u2013245.</li>\n<li>Aydede, M., 1998, \u201cFodor on Concepts and Frege\nPuzzles\u201d, <em>Pacific Philosophical Quarterly</em>, 79:\n289\u2013294.</li>\n<li>\u2013\u2013\u2013, 2005, \u201cComputationalism and\nFunctionalism: Syntactic Theory of Mind Revisited\u201d,\nin <em>Turkish Studies in the History and Philosophy of Science</em>,\nG. Irzik and G. G\u00fczeldere (eds), Dordrecht: Springer.</li>\n<li>Aydede, M. and P. Robbins, 2001, \u201cAre Frege Cases Exceptions\nto Intentional Generalizations?\u201d, <em>Canadian Journal of\nPhilosophy</em>, 31: 1\u201322.</li>\n<li>Bechtel, W. and A. Abrahamsen, 2002, <em>Connectionism and the\nMind</em>, Malden: Blackwell.</li>\n<li>Berm\u00fadez, J.L., 2005, <em>Philosophy of Psychology: A\nContemporary Introduction</em>, New York: Routledge.</li>\n<li>\u2013\u2013\u2013, 2010, <em>Cognitive Science: An\nIntroduction to the Science of the Mind</em>, Cambridge: Cambridge\nUniversity Press.</li>\n<li>Block, N., 1978, \u201cTroubles With\nFunctionalism\u201d, <em>Minnesota Studies in the Philosophy of\nScience</em>, 9: 261\u2013325.</li>\n<li>\u2013\u2013\u2013, 1981, \u201cPsychologism and\nBehaviorism\u201d, <em>Philosophical Review</em>, 90:\n5\u201343.</li>\n<li>\u2013\u2013\u2013, 1983, \u201cMental Pictures and Cognitive\nScience\u201d, <em>Philosophical Review</em>, 92: 499\u2013539.</li>\n<li>\u2013\u2013\u2013, 1986, \u201cAdvertisement for a Semantics\nfor Psychology\u201d, <em>Midwest Studies in Philosophy</em>, 10:\n615\u2013678.</li>\n<li>\u2013\u2013\u2013, 1990, \u201cCan the Mind Change the\nWorld?\u201d, in <em>Meaning and Method: Essays in Honor of Hilary\nPutnam</em>, G. Boolos (ed.), Cambridge: Cambridge University\nPress.</li>\n<li>\u2013\u2013\u2013, 1995, <em>The Mind as the Software of the\nBrain</em>, in <em>Invitation to Cognitive Science, vol. 3:\nThinking</em>, E. Smith and B. Osherson (eds), Cambridge, MA: MIT\nPress.</li>\n<li>Block, N. and J. Fodor, 1972, \u201cWhat Psychological States Are\nNot\u201d, <em>The Philosophical Review</em>, 81: 159\u2013181.</li>\n<li>Boden, M., 1991, \u201cHorses of a Different Color?\u201d, in\nRamsey et al. 1991: 3\u201319.</li>\n<li>Bontly, T., 1998, \u201cIndividualism and the Nature of Syntactic\nStates\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 49: 557\u2013574.</li>\n<li>Bowie, G.L., 1982, \u201cLucas\u2019s Number is Finally\nUp\u201d, <em>Journal of Philosophical Logic</em>, 11:\n79\u2013285.</li>\n<li>Brogan, W., 1990, <em>Modern Control Theory</em>, 3rd\nedition. Englewood Cliffs: Prentice Hall.</li>\n<li>Buckner, C., 2019, \u201cDeep Learning: A Philosophical\nIntroduction\u201d, <em>Philosophy Compass</em>, 14: e12625.</li>\n<li>Buckner, C., and J. Garson, 2019, \u201cConnectionism and\nPost-Connectionist Models\u201d, in Sprevak and Colombo 2019:\n175\u2013191.</li>\n<li>Buesing, L., J. Bill, B. Nessler, and W. Maass, W., 2011,\n\u201cNeural Dynamics of Sampling: A Model for Stochastic Computation\nin Recurring Networks of Spiking Neurons\u201d, <em>PLOS\nComputational Biology</em>, 7: e1002211.</li>\n<li>Burge, T., 1982, \u201cOther Bodies\u201d, in <em>Thought and\nObject</em>, A. Woodfield (ed.), Oxford: Oxford University\nPress. Reprinted in Burge\n2007: 82\u201399.</li>\n<li>\u2013\u2013\u2013, 1986, \u201cIndividualism and\nPsychology\u201d, <em>The Philosophical Review</em>, 95:\n3\u201345. Reprinted in Burge\n2007: 221\u2013253.</li>\n<li>\u2013\u2013\u2013, 1989, \u201cIndividuation and Causation in\nPsychology\u201d, <em>Pacific Philosophical Quarterly</em>, 70:\n303\u2013322. Reprinted in Burge\n2007: 316\u2013333.</li>\n<li>\u2013\u2013\u2013, 1995, \u201cIntentional Properties and\nCausation\u201d, in <em>Philosophy of Psychology</em>, C. MacDonald\nand G. MacDonald (eds), Oxford: Blackwell. Reprinted in Burge\n2007: 334\u2013343.</li>\n<li>\u2013\u2013\u2013, 2005, \u201cDisjunctivism and Perceptual\nPsychology\u201d, <em>Philosophical Topics</em>, 33: 1\u201378.</li>\n<li>\u2013\u2013\u2013, 2007, <em>Foundations of Mind</em>, Oxford:\nOxford University Press.</li>\n<li>\u2013\u2013\u2013, 2010a, <em>Origins of Objectivity</em>,\nOxford: Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 2010b, \u201cOrigins of\nPerception\u201d, <em>Disputatio</em>, 4: 1\u201338.</li>\n<li>\u2013\u2013\u2013, 2010c, \u201cSteps Towards Origins of\nPropositional Thought\u201d, <em>Disputatio</em>, 4:\n39\u201367.</li>\n<li>\u2013\u2013\u2013, 2013, <em>Cognition through\nUnderstanding</em>, Oxford: Oxford University Press.</li>\n<li>Camp, E., 2009, \u201cA Language of Baboon Thought?\u201d,\nin <em>The Philosophy of Animal Minds</em>, R. Lurz (ed.), Cambridge:\nCambridge University Press.</li>\n<li>Carruthers, P., 2003, \u201cOn Fodor\u2019s\nProblem\u201d, <em>Mind and Language</em>, 18: 508\u2013523.</li>\n<li>Chalmers, D., 1990, \u201cSyntactic Transformations on\nDistributed Representations\u201d, <em>Connection Science</em>, 2:\n53\u201362.</li>\n<li>\u2013\u2013\u2013, 1993, \u201cWhy Fodor and Pylyshyn Were\nWrong: The Simplest Refutation\u201d, <em>Philosophical\nPsychology</em>, 63: 305\u2013319.</li>\n<li>\u2013\u2013\u2013, 1995, \u201cOn Implementing a\nComputation\u201d, <em>Minds and Machines</em>, 4:\n391\u2013402.</li>\n<li>\u2013\u2013\u2013, 1996a, \u201cDoes a Rock Implement Every\nFinite State Automaton?\u201d, <em>Synthese</em>, 108:\n309\u2013333.</li>\n<li>\u2013\u2013\u2013, 1996b, \u201cMinds, Machines, and\nMathematics\u201d, <em>Psyche</em>, 2: 11\u201320.</li>\n<li>\u2013\u2013\u2013, 2002, \u201cThe Components of\nContent\u201d, in <em>Philosophy of Mind: Classical and Contemporary\nReadings</em>, D. Chalmers (ed.), Oxford: Oxford University\nPress.</li>\n<li>\u2013\u2013\u2013, 2011, \u201cA Computational Foundation for\nthe Study of Cognition\u201d, <em>The Journal of Cognitive\nScience</em>, 12: 323\u2013357.</li>\n<li>\u2013\u2013\u2013, 2012, \u201cThe Varieties of Computation:\nA Reply\u201d, <em>The Journal of Cognitive Science</em>, 13:\n213\u2013248.</li>\n<li>Chemero, A., 2009, <em>Radical Embodied Cognitive Science</em>,\nCambridge, MA: MIT Press.</li>\n<li>Cheney, D. and R. Seyfarth, 2007, <em>Baboon Metaphysics: The\nEvolution of a Social Mind</em>, Chicago: University of Chicago\nPress.</li>\n<li>Chomsky, N., 1965, <em>Aspects of the Theory of Syntax</em>,\nCambridge, MA: MIT Press.</li>\n<li>Church, A., 1936, \u201cAn Unsolvable Problem of Elementary\nNumber Theory\u201d, <em>American Journal of Mathematics</em>, 58:\n345\u2013363.</li>\n<li>Churchland, P.M., 1981, \u201cEliminative Materialism and the\nPropositional Attitudes\u201d, <em>Journal of Philosophy</em>, 78:\n67\u201390.</li>\n<li>\u2013\u2013\u2013, 1989, <em>A Neurocomputational Perspective:\nThe Nature of Mind and the Structure of Science</em>, Cambridge, MA: MIT\nPress.</li>\n<li>\u2013\u2013\u2013, 1995, <em>The Engine of Reason, the Seat of\nthe Soul</em>, Cambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 2007, <em>Neurophilosophy At Work</em>,\nCambridge: Cambridge University Press.</li>\n<li>Churchland, P.S., 1986, <em>Neurophilosophy</em>, Cambridge, MA: MIT\nPress.</li>\n<li>Churchland, P.S., C. Koch, and T. Sejnowski, 1990, \u201cWhat Is\nComputational Neuroscience?\u201d, in <em>Computational\nNeuroscience</em>, E. Schwartz (ed.), Cambridge, MA: MIT Press.</li>\n<li>Churchland, P.S. and T. Sejnowski, 1992, <em>The Computational\nBrain</em>, Cambridge, MA: MIT Press.</li>\n<li>Clark, A., 2014, <em>Mindware: An Introduction to the Philosophy\nof Cognitive Science</em>, Oxford: Oxford University Press.</li>\n<li>Clayton, N., N. Emery, and A. Dickinson, 2006, \u201cThe\nRationality of Animal Memory: Complex Caching Strategies of Western\nScrub Jays\u201d, in <em>Rational Animals?</em>, M. Nudds and\nS. Hurley (eds), Oxford: Oxford University Press.</li>\n<li>Copeland, J., 1996, \u201cWhat is\nComputation?\u201d, <em>Synthese</em>, 108: 335\u2013359.</li>\n<li>Cover, T. and J. Thomas, 2006, <em>Elements of Information\nTheory</em>, Hoboken: Wiley.</li>\n<li>Crane, T., 1991, \u201cAll the Difference in the\nWorld\u201d, <em>Philosophical Quarterly</em>, 41: 1\u201325.</li>\n<li>Crick, F. and C. Asanuma, 1986, \u201cCertain Aspects of the\nAnatomy and Physiology of the Cerebral Cortex\u201d, in McClelland et\nal. 1987: 333\u2013371.</li>\n<li>Cummins, R., 1989, <em>Meaning and Mental Representation</em>,\nCambridge, MA: MIT Press.</li>\n<li>Davidson, D., 1980, <em>Essays on Actions and Events</em>, Oxford:\nClarendon Press.</li>\n<li>Dayan, P., 2009, \u201cA Neurocomputational\nJeremiad\u201d, <em>Nature Neuroscience</em>, 12: 1207.</li>\n<li>Dennett, D., 1971, \u201cIntentional Systems\u201d, <em>Journal\nof Philosophy</em>, 68: 87\u2013106.</li>\n<li>\u2013\u2013\u2013, 1987, <em>The Intentional Stance</em>,\nCambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 1991, \u201cMother Nature versus the\nWalking Encyclopedia\u201d, in Ramsey, et\nal. 1991: 21\u201330.</li>\n<li>Dietrich, E., 1989, \u201cSemantics and the Computational\nParadigm in Cognitive Psychology\u201d, <em>Synthese</em>, 79:\n119\u2013141.</li>\n<li>Donahoe, J., 2010, \u201cMan as Machine: A Review of <em>Memory\nand Computational Brain</em>, by C.R. Gallistel and\nA.P. King\u201d, <em>Behavior and Philosophy</em>, 38:\n83\u2013101.</li>\n<li>Dreyfus, H., 1972, <em>What Computers Can\u2019t Do</em>,\nCambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 1992, <em>What Computers Still Can\u2019t\nDo</em>, Cambridge, MA: MIT Press.</li>\n<li>Dretske, F., 1981, <em>Knowledge and the Flow of Information</em>,\nOxford: Blackwell.</li>\n<li>\u2013\u2013\u2013, 1993, \u201cMental Events as Structuring\nCauses of Behavior\u201d, in <em>Mental Causation</em>, J. Heil and\nA. Mele (eds), Oxford: Clarendon Press.</li>\n<li>Edelman, S., 2008, <em>Computing the Mind</em>, Oxford: Oxford\nUniversity Press.</li>\n<li>\u2013\u2013\u2013, 2014, \u201cHow to Write a \u2018How a\nBuild a Brain\u2019 Book\u201d, <em>Trends in Cognitive\nScience</em>, 18: 118\u2013119.</li>\n<li>Egan, F., 1991, \u201cMust Psychology be\nIndividualistic?\u201d, <em>Philosophical Review</em>, 100:\n179\u2013203.</li>\n<li>\u2013\u2013\u2013, 1992, \u201cIndividualism, Computation,\nand Perceptual Content\u201d, <em>Mind</em>, 101: 443\u2013459.</li>\n<li>\u2013\u2013\u2013, 1999, \u201cIn Defense of Narrow\nMindedness\u201d, <em>Mind and Language</em>, 14: 177\u2013194.</li>\n<li>\u2013\u2013\u2013, 2003, \u201cNaturalistic Inquiry: Where\nDoes Mental Representation Fit In?\u201d, in <em>Chomsky and His\nCritics</em>, L. Antony and N. Hornstein (eds), Malden:\nBlackwell.</li>\n<li>\u2013\u2013\u2013, 2010, \u201cA Modest Role for\nContent\u201d, <em>Studies in History and Philosophy of Science</em>,\n41: 253\u2013259.</li>\n<li>\u2013\u2013\u2013, 2014, \u201cHow to Think About Mental\nContent\u201d, <em>Philosophical Studies</em>, 170:\n115\u2013135.</li>\n<li>\u2013\u2013\u2013, 2019, \u201cThe Nature and Function of\nContent in Computational Models\u201d, in Sprevak and Colombo 2019:\n247\u2013258.</li>\n<li>Eliasmith, C., 2003, \u201cMoving Beyond Metaphors: Understanding\nthe Mind for What It Is\u201d, <em>Journal of Philosophy</em>, 100:\n493\u2013520.</li>\n<li>\u2013\u2013\u2013, 2013, <em>How to Build a Brain</em>,\nOxford: Oxford: University Press.</li>\n<li>Eliasmith, C. and C.H. Anderson, 2003, <em>Neural Engineering:\nComputation, Representation and Dynamics in Neurobiological\nSystems</em>, Cambridge, MA: MIT Press.</li>\n<li>Elman, J., 1990, \u201cFinding Structure in\nTime\u201d, <em>Cognitive Science</em>, 14: 179\u2013211.</li>\n<li>Feferman, S., 1996, \u201cPenrose\u2019s G\u00f6delian\nArgument\u201d, <em>Psyche</em>, 2: 21\u201332.</li>\n<li>Feldman, J. and D. Ballard, 1982, \u201cConnectionist Models and\ntheir Properties\u201d, <em>Cognitive Science</em>, 6:\n205\u2013254.</li>\n<li>Field, H., 2001, <em>Truth and the Absence of Fact</em>, Oxford:\nClarendon Press.</li>\n<li>Figdor, C., 2009, \u201cSemantic Externalism and the Mechanics of\nThought\u201d, <em>Minds and Machines</em>, 19: 1\u201324.</li>\n<li>Fodor, J., 1975, <em>The Language of Thought</em>, New York:\nThomas Y. Crowell.</li>\n<li>\u2013\u2013\u2013, 1980, \u201cMethodological Solipsism\nConsidered as a Research Strategy in Cognitive\nPsychology\u201d, <em>Behavioral and Brain Science</em>, 3:\n63\u201373. Reprinted in Fodor\n1981: 225\u2013253.</li>\n<li>\u2013\u2013\u2013, 1981, <em>Representations</em>, Cambridge:\nMIT Press.</li>\n<li>\u2013\u2013\u2013, 1983, <em>The Modularity of Mind</em>,\nCambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 1987, <em>Psychosemantics</em>, Cambridge:\nMIT Press.</li>\n<li>\u2013\u2013\u2013, 1990, <em>A Theory of Content and Other\nEssays</em>, Cambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 1991, \u201cA Modal Argument for Narrow\nContent\u201d, <em>Journal of Philosophy</em>, 88: 5\u201326.</li>\n<li>\u2013\u2013\u2013, 1994, <em>The Elm and the Expert</em>,\nCambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 1998, <em>Concepts</em>, Oxford: Clarendon\nPress.</li>\n<li>\u2013\u2013\u2013, 2000, <em>The Mind Doesn\u2019t Work That\nWay</em>, Cambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 2005, \u201cReply to Steven Pinker\n\u2018So How Does the Mind Work?\u2019\u201d, <em>Mind and\nLanguage</em>, 20: 25\u201332.</li>\n<li>\u2013\u2013\u2013, 2008, <em>LOT2</em>, Oxford: Clarendon\nPress.</li>\n<li>Fodor, J. and Z. Pylyshyn, 1988, \u201cConnectionism and\nCognitive Architecture: A Critical\nAnalysis\u201d, <em>Cognition</em>, 28: 3\u201371.</li>\n<li>Frege, G., 1879/1967, <em>Begriffsschrift, eine der Arithmetischen\nNachgebildete Formelsprache des Reinen Denkens</em>. Reprinted\nas <em>Concept Script, a Formal Language of Pure Thought Modeled upon\nthat of Arithmetic</em>, in <em>From Frege to G\u00f6del: A Source\nBook in Mathematical Logic, 1879\u20131931</em>, J. van Heijenoort\n(ed.), S. Bauer-Mengelberg (trans.), Cambridge: Harvard University\nPress.</li>\n<li>Gallistel, C.R., 1990, <em>The Organization of Learning</em>,\nCambridge, MA: MIT Press.</li>\n<li>Gallistel, C.R. and King, A., 2009, <em>Memory and the\nComputational Brain</em>, Malden: Wiley-Blackwell.</li>\n<li>Gandy, R., 1980, \u201cChurch\u2019s Thesis and Principles for\nMechanism\u201d, in <em>The Kleene Symposium</em>, J. Barwise,\nH. Keisler, and K. Kunen (eds). Amsterdam: North Holland.</li>\n<li>G\u00f6del, K., 1936/65. \u201cOn Formally Undecidable\nPropositions of Principia Mathematica and Related Systems\u201d,\nReprinted with a new Postscript in <em>The Undecidable</em>, M. Davis\n(ed.), New York: Raven Press Books.</li>\n<li>Grice, P., 1989, <em>Studies in the Ways of Words</em>, Cambridge:\nHarvard University Press.</li>\n<li>Hadley, R., 2000, \u201cCognition and the Computational Power of\nConnectionist Networks\u201d, <em>Connection Science</em>, 12:\n95\u2013110.</li>\n<li>Harnish, R., 2002, <em>Minds, Brains, Computers</em>, Malden:\nBlackwell.</li>\n<li>Haykin, S., 2008, <em>Neural Networks: A Comprehensive\nFoundation</em>, New York: Prentice Hall.</li>\n<li>Haugeland, J., 1985, <em>Artificial Intelligence: The Very\nIdea</em>, Cambridge, MA: MIT Press.</li>\n<li>Horgan, T. and J. Tienson, 1996, <em>Connectionism and the\nPhilosophy of Psychology</em>, Cambridge, MA: MIT Press.</li>\n<li>Horowitz, A., 2007, \u201cComputation, External Factors, and\nCognitive Explanations\u201d, <em>Philosophical Psychology</em>, 20:\n65\u201380.</li>\n<li>Johnson, K., 2004, \u201cOn the Systematicity of Language and\nThought\u201d, <em>Journal of Philosophy</em>, 101:\n111\u2013139.</li>\n<li>Johnson-Laird, P., 1988, <em>The Computer and the Mind</em>,\nCambridge: Harvard University Press.</li>\n<li>\u2013\u2013\u2013, 2004, \u201cThe History of Mental\nModels\u201d, in <em>Psychology of Reasoning: Theoretical and\nHistorical Perspectives</em>, K. Manktelow and M.C. Chung (eds), New\nYork: Psychology Press.</li>\n<li>Kazez, J., 1995, \u201cComputationalism and the Causal Role of\nContent\u201d, <em>Philosophical Studies</em>, 75:\n231\u2013260.</li>\n<li>Kelso, J., 1995, <em>Dynamic Patterns</em>, Cambridge, MA: MIT\nPress.</li>\n<li>Klein, C., 2012, \u201cTwo Paradigms for Individuating\nImplementations\u201d, <em>Journal of Cognitive Science</em>, 13:\n167\u2013179.</li>\n<li>Kriegesgorte, K., 2015, \u201cDeep Neural Networks: A New\nFramework for Modeling Biological Vision and Brain Information\nProcessing\u201d, <em>Annual Review of Vision Science</em>, 1:\n417\u2013446.</li>\n<li>Kriegesgorte, K. and P. Douglas, 2018, \u201cCognitive\nComputational Neuroscience\u201d, <em>Nature Neuroscience</em>, 21:\n1148\u20131160.</li>\n<li>Krishevsky, A., I. Sutskever, and G. Hinton, 2012, \u201cImageNet\nClassification with Deep Convolutional Neural\nNetworks\u201d, <em>Advances in Neural Information Processing\nSystems</em>, 25: 1097\u20131105.</li>\n<li>Krotov, D., and J. Hopfield, 2019, \u201cUnsupervised Learning by\nCompeting Hidden Units\u201d, <em>Proceedings of the National Academy\nof Sciences</em>, 116: 7723\u20137731.</li>\n<li>Ladyman, J., 2009, \u201cWhat Does it Mean to Say that a Physical\nSystem Implements a Computation?\u201d, <em>Theoretical Computer\nScience</em>, 410: 376\u2013383.</li>\n<li>LeCun, Y., Y. Bengio, and G. Hinton, 2015, \u201cDeep\nLearning\u201d, <em>Nature</em>, 521: 436\u2013444.</li>\n<li>Lewis, D., 1969, \u201cLucas against\nMechanism\u201d, <em>Philosophy</em>, 44: 231\u20133.</li>\n<li>\u2013\u2013\u2013, 1972, \u201cPsychophysical and Theoretical\nIdentifications\u201d, <em>Australasian Journal of Philosophy</em>,\n50: 249\u201358.</li>\n<li>\u2013\u2013\u2013, 1979, \u201cLucas Against Mechanism\nII\u201d, <em>Canadian Journal of Philosophy</em>, 9:\n373\u2013376.</li>\n<li>\u2013\u2013\u2013, 1994, \u201cReduction of Mind\u201d,\nin <em>A Companion to the Philosophy of Mind</em>, S. Guttenplan\n(ed.), Oxford: Blackwell.</li>\n<li>Lizier, J., B. Flecker, and P. Williams, 2013, \u201cTowards a\nSynergy-based Account of Measuring Information\nModification\u201d, <em>Proceedings of the 2013 IEEE Symposium on\nArtificial Life (ALIFE)</em>, Singapore: 43\u201351.</li>\n<li>Ludwig, K. and S. Schneider, 2008, \u201cFodor\u2019s Critique\nof the Classical Computational Theory of Mind\u201d, <em>Mind and\nLanguage</em>, 23: 123\u2013143.</li>\n<li>Lucas, J.R., 1961, \u201cMinds, Machines, and\nG\u00f6del\u201d, <em>Philosophy</em>, 36: 112\u2013137.</li>\n<li>Ma, W. J., 2019, \u201cBayesian Decision Models: A\nPrimer\u201d, <em>Neuron</em>, 104: 164\u2013175.</li>\n<li>Maass, W., 1997, \u201cNetworks of Spiking Neurons: The Next\nGeneration of Neural Network Models\u201d, <em>Neural Networks</em>,\n10: 1659\u20131671.</li>\n<li>MacLennan, B., 2012, \u201cAnalog\nComputation\u201d, <em>Computational Complexity</em>, R. Meyers\n(ed.), New York: Springer. </li>\n<li>Marblestone, A., G. Wayne, and K. Kording, 2016, \u201cToward an\nIntegration of Deep Learning and Neuroscience\u201d, <em>Frontiers in\nComputational Neuroscience</em>, 10: 1\u201341.</li>\n<li>Marcus, G., 2001, <em>The Algebraic Mind</em>, Cambridge, MA: MIT\nPress.</li>\n<li>Marr, D., 1982, <em>Vision</em>, San Francisco: W.H. Freeman.</li>\n<li>McClelland, J., D. Rumelhart, and G. Hinton, 1986, \u201cThe\nAppeal of Parallel Distributed Processing\u201d, in Rumelhart et\nal. 1986: 3\u201344.</li>\n<li>McClelland, J., D. Rumelhart, and the PDP Research Group,\n1987, <em>Parallel Distributed Processing</em>, vol. 2. Cambridge, MA: MIT\nPress.</li>\n<li>McCulloch, W. and W. Pitts, 1943, \u201cA Logical Calculus of the\nIdeas Immanent in Nervous Activity\u201d, <em>Bulletin of\nMathematical Biophysics</em>, 7: 115\u2013133.</li>\n<li>McDermott, D., 2001, <em>Mind and Mechanism</em>, Cambridge, MA: MIT\nPress.</li>\n<li>Mendola, J., 2008, <em>Anti-Externalism</em>, Oxford: Oxford\nUniversity Press.</li>\n<li>Milkowski, M., 2013, <em>Explaining the Computational Mind</em>,\nCambridge, MA: MIT Press.</li>\n<li>Miller, P., 2018, <em>An Introductory Course in Computational\nNeuroscience</em>, Cambridge, MA: MIT Press.</li>\n<li>Mole, C., 2014, \u201cDead Reckoning in the Desert Ant: A Defense\nof Connectionist Models\u201d, <em>Review of Philosophy and\nPsychology</em>, 5: 277\u2013290.</li>\n<li>Murphy, K., 2012, <em>Machine Learning: A Probabilistic\nPerspective</em>, Cambridge, MA: MIT Press.</li>\n<li>Naselaris, T., Bassett, D., Fletcher, A., K\u00f6rding, K.,\nKriegeskorte, N., Nienborg, H., Poldrack, R., Shohamy, D., and Kay,\nK., 2018, \u201cCognitive Computational Neuroscience: A New\nConference for an Emerging Discipline\u201d, <em>Trends in Cognitive\nScience</em>, 22: 365\u2013367.</li>\n<li>Nagel, E. and J.R. Newman, 1958, <em>G\u00f6del\u2019s\nProof</em>, New York: New York University Press.</li>\n<li>Newell, A., 1990, <em>Unified Theories of Cognition</em>,\nCambridge: Harvard University Press.</li>\n<li>Newell, A. and H. Simon, 1956, \u201cThe Logic Theory Machine: A\nComplex Information Processing System\u201d, <em>IRE Transactions on\nInformation Theory, IT-2</em>, 3: 61\u201379.</li>\n<li>\u2013\u2013\u2013, 1976, \u201cComputer Science as Empirical\nInquiry: Symbols and Search\u201d, <em>Communications of the\nACM</em>, 19: 113\u2013126.</li>\n<li>O\u2019Keefe, J. and L. Nadel, 1978, <em>The Hippocampus as a\nCognitive Map</em>, Oxford: Clarendon University Press.</li>\n<li>Ockham, W., 1957, <em>Summa Logicae</em>, in his <em>Philosophical\nWritings, A Selection</em>, P. Boehner (ed. and trans.), London:\nNelson.</li>\n<li>Orhan, A. E. and Ma, W. J., 2017, \u201cEfficient Probabilistic\nInference in Generic Neural Networks Trained with Non-probabilistic\nFeedback \u201d, <em>Nature Communications</em>, 8: 1\u201314.</li>\n<li>Peacocke, C., 1992, <em>A Study of Concepts</em>, Cambridge, MA: MIT\nPress.</li>\n<li>\u2013\u2013\u2013, 1993, \u201cExternalist\nExplanation\u201d, <em>Proceedings of the Aristotelian Society</em>,\n67: 203\u2013230.</li>\n<li>\u2013\u2013\u2013, 1994, \u201cContent, Computation, and\nExternalism\u201d, <em>Mind and Language</em>, 9: 303\u2013335.</li>\n<li>\u2013\u2013\u2013, 1999, \u201cComputation as Involving\nContent: A Response to Egan\u201d, <em>Mind and Language</em>, 14:\n195\u2013202.</li>\n<li>Penrose, R., 1989, <em>The Emperor\u2019s New Mind: Concerning\nComputers, Minds, and the Laws of Physics</em>, Oxford: Oxford\nUniversity Press.</li>\n<li>Perry, J., 1998, \u201cBroadening the Mind\u201d, <em>Philosophy\nand Phenomenological Research</em>, 58: 223\u2013231.</li>\n<li>Piantadosi, S., J. Tenenbaum, and N. Goodman, 2012,\n\u201cBootstrapping in a Language of\nThought\u201d, <em>Cognition</em>, 123: 199\u2013217.</li>\n<li>Piccinini, G., 2004, \u201cFunctionalism, Computationalism, and\nMental States\u201d, <em>Studies in History and Philosophy of\nScience</em>, 35: 811\u2013833.</li>\n<li>\u2013\u2013\u2013, 2007, \u201cComputing\nMechanisms\u201d, <em>Philosophy of Science</em>, 74:\n501\u2013526.</li>\n<li>\u2013\u2013\u2013, 2008a, \u201cComputation Without\nRepresentation\u201d, <em>Philosophical Studies</em>, 137:\n205\u2013241.</li>\n<li>\u2013\u2013\u2013, 2008b, \u201cSome Neural Networks Compute,\nOthers Don\u2019t\u201d, <em>Neural Networks</em>, 21:\n311\u2013321.</li>\n<li>\u2013\u2013\u2013, 2010, \u201cThe Resilience of\nComputationalism\u201d, <em>Philosophy of Science</em>, 77:\n852\u2013861.</li>\n<li>\u2013\u2013\u2013, 2012, \u201cComputationalism\u201d,\nin <em>The Oxford Handbook of Philosophy and Cognitive Science</em>,\nE. Margolis, R. Samuels, and S. Stich (eds), Oxford: Oxford University\nPress. </li>\n<li>\u2013\u2013\u2013, 2015, <em>Physical Computation: A\nMechanistic Account</em>, Oxford: Oxford University Press.</li>\n<li>Piccinini, G. and A. Scarantino, 2010, \u201cComputation\nvs. Information processing: Why their Difference Matters to Cognitive\nScience\u201d, <em>Studies in History and Philosophy of Science</em>,\n41: 237\u2013246.</li>\n<li>Piccinini, G. and S. Bahar, 2013, \u201cNeural Computation and\nthe Computational Theory of Cognition\u201d, <em>Cognitive\nScience</em>, 37: 453\u2013488.</li>\n<li>Piccinini, G. and O. Shagrir, 2014, \u201cFoundations of\nComputational Neuroscience\u201d, <em>Current Opinion in\nNeurobiology</em>, 25: 25\u201330.</li>\n<li>Pinker, S., 2005, \u201cSo How Does the Mind\nWork?\u201d, <em>Mind and Language</em>, 20: 1\u201324.</li>\n<li>Pinker, S. and A. Prince, 1988, \u201cOn Language and\nConnectionism\u201d, <em>Cognition</em>, 28: 73\u2013193.</li>\n<li>Pouget, A., Beck, J., Ma., W. J., and Latham, P., 2013,\n\u201cProbabilistic Brains: Knowns and Unknowns\u201d, <em>Nature\nNeuroscience</em>, 16: 1170\u20131178.</li>\n<li>Putnam, H., 1967, \u201cPsychophysical Predicates\u201d,\nin <em>Art, Mind, and Religion</em>, W. Capitan and D. Merrill (eds),\nPittsburgh: University of Pittsburgh Press. Reprinted in Putnam 1975\nas \u201cThe Nature of Mental\nStates\u201d: 429\u2013440.</li>\n<li>\u2013\u2013\u2013, 1975, <em>Mind, Language, and Reality:\nPhilosophical Papers, vol. 2</em>, Cambridge: Cambridge University\nPress.</li>\n<li>\u2013\u2013\u2013, 1983, <em>Realism and Reason: Philosophical\nPapers</em>, vol. 3. Cambridge: Cambridge University Press.</li>\n<li>\u2013\u2013\u2013, 1988, <em>Representation and Reality</em>,\nCambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 1994, \u201cThe Best of All Possible\nBrains?\u201d, <em>The New York Times</em>, November 20,\n1994: 7.</li>\n<li> Pylyshyn, Z., 1984, <em>Computation and Cognition</em>,\nCambridge, MA: MIT Press.</li>\n<li>Quine, W.V.O., 1960, <em>Word and Object</em>, Cambridge, MA: MIT\nPress.</li>\n<li>Ramsey, W., S. Stich, and D. Rumelhart (eds), 1991, <em>Philosophy\nand Connectionist Theory</em>, Hillsdale: Lawrence Erlbaum\nAssociates.</li>\n<li>Rescorla, M., 2009a, \u201cChrysippus\u2019s Dog as a Case Study\nin Non-Linguistic Cognition\u201d, in <em>The Philosophy of Animal\nMinds</em>, R. Lurz (ed.), Cambridge: Cambridge University Press.</li>\n<li>\u2013\u2013\u2013, 2009b, \u201cCognitive Maps and the\nLanguage of Thought\u201d, <em>The British Journal for the Philosophy\nof Science</em>, 60: 377\u2013407.</li>\n<li>\u2013\u2013\u2013, 2012, \u201cHow to Integrate\nRepresentation into Computational Modeling, and Why We\nShould\u201d, <em>Journal of Cognitive Science</em>, 13:\n1\u201338.</li>\n<li>\u2013\u2013\u2013, 2013, \u201cAgainst Structuralist Theories\nof Computational Implementation\u201d, <em>British Journal for the\nPhilosophy of Science</em>, 64: 681\u2013707.</li>\n<li>\u2013\u2013\u2013, 2014a, \u201cThe Causal Relevance of\nContent to Computation\u201d, <em>Philosophy and Phenomenological\nResearch</em>, 88: 173\u2013208.</li>\n<li>\u2013\u2013\u2013, 2014b, \u201cA Theory of Computational\nImplementation\u201d, <em>Synthese</em>, 191: 1277\u20131307.</li>\n<li>\u2013\u2013\u2013, 2015, \u201cBayesian Perceptual\nPsychology\u201d, in <em>The Oxford Handbook of the Philosophy of\nPerception</em>, M. Matthen (ed.), Oxford: Oxford University\nPress.</li>\n<li>\u2013\u2013\u2013, 2017a, \u201cFrom Ockham to\nTuring\u2014and Back Again\u201d, in <em>Turing 100: Philosophical\nExplorations of the Legacy of Alan Turing</em>, (<em>Boston Studies in\nthe Philosophy and History</em>), A. Bokulich and J. Floyd (eds),\nSpringer.</li>\n<li>\u2013\u2013\u2013, 2017b, \u201cLevels of Computational\nExplanation\u201d, in <em>Philosophy and Computing: Essays in\nEpistemology, Philosophy of Mind, Logic, and Ethics</em>, T. Powers\n(ed.), Cham: Springer.</li>\n<li>\u2013\u2013\u2013, 2020, \u201cA Realist Perspective\non Bayesian Cognitive Science\u201d, in <em>Inference and\nConsciousness</em>, A. Nes and T. Chan (eds.), New York: Routledge.</li>\n<li>Rogers, T. and J. McClelland, 2014, \u201cParallel Distributed\nProcessing at 25: Further Explorations of the Microstructure of\nCognition\u201d, <em>Cognitive Science</em>, 38:\n1024\u20131077.</li>\n<li>Rumelhart, D., 1989, \u201cThe Architecture of Mind: A\nConnectionist Approach\u201d, in <em>Foundations of Cognitive\nScience</em>, M. Posner (ed.), Cambridge, MA: MIT Press.</li>\n<li>Rumelhart, D., G. Hinton, and R. Williams, 1986, \u201cLearning\nRepresentations by Back-propagating Errors\u201d, <em>Nature</em>,\n323: 533\u2013536.</li>\n<li>Rumelhart, D. and J. McClelland, 1986, \u201cPDP Models and\nGeneral Issues in Cognitive Science\u201d, in Rumelhart et\nal. 1986: 110\u2013146.</li>\n<li>Rumelhart, D., J. McClelland, and the PDP Research Group,\n1986, <em>Parallel Distributed Processing</em>, vol. 1. Cambridge:\nMIT Press.</li>\n<li>Rupert, R., 2008, \u201cFrege\u2019s Puzzle and Frege Cases:\nDefending a Quasi-Syntactic Solution\u201d, <em>Cognitive Systems\nResearch</em>, 9: 76\u201391.</li>\n<li>\u2013\u2013\u2013, 2009, <em>Cognitive Systems and the\nExtended Mind</em>, Oxford: Oxford University Press.</li>\n<li>Russell, S. and P. Norvig, 2010, <em>Artificial Intelligence: A\nModern Approach</em>, 3<sup>rd</sup> ed., New York: Prentice\nHall.</li>\n<li>Sawyer, S., 2000, \u201cThere Is No Viable Notion of Narrow\nContent\u201d, in <em>Contemporary Debates in Philosophy of\nMind</em>, B. McLaughlin and J. Cohen (eds), Malden: Blackwell.</li>\n<li>Schneider, S., 2005, \u201cDirect Reference, Psychological\nExplanation, and Frege Cases\u201d, <em>Mind and Language</em>, 20:\n423\u2013447.</li>\n<li>\u2013\u2013\u2013, 2011, <em>The Language of Thought: A New\nPhilosophical Direction</em>, Cambridge, MA: MIT Press.</li>\n<li>Searle, J., 1980, \u201cMinds, Brains, and\nPrograms\u201d, <em>Behavioral and Brain Sciences</em>, 3:\n417\u2013457.</li>\n<li>\u2013\u2013\u2013, 1990, \u201cIs the Brain a Digital\nComputer?\u201d, <em>Proceedings and Addresses of the American\nPhilosophical Association</em>, 64: 21\u201337.</li>\n<li>Segal, G., 2000, <em>A Slim Book About Narrow Content</em>,\nCambridge, MA: MIT Press.</li>\n<li>Shagrir, O., 2001, \u201cContent, Computation, and\nExternalism\u201d, <em>Mind</em>, 110: 369\u2013400.</li>\n<li>\u2013\u2013\u2013, 2006, \u201cWhy We View the Brain as a\nComputer\u201d, <em>Synthese</em>, 153: 393\u2013416.</li>\n<li>\u2013\u2013\u2013, 2014, \u201cReview of <em>Explaining the\nComputational Theory of Mind</em>, by Marcin\nMilkowski\u201d, <em>Notre Dame Review of Philosophy</em>, January\n2014.</li>\n<li>\u2013\u2013\u2013, forthcoming, \u201cIn Defense of the\nSemantic View of Computation\u201d, <em>Synthese</em>,\nfirst online 11 October 2018; doi:10.1007/s11229-018-01921-z</li>\n<li>Shannon, C., 1948, \u201cA Mathematical Theory of\nCommunication\u201d, <em>Bell System Technical Journal</em> 27:\n379\u2013423, 623\u2013656.</li>\n<li>Shapiro, S., 2003, \u201cTruth, Mechanism, and Penrose\u2019s\nNew Argument\u201d, <em>Journal of Philosophical Logic</em>, 32:\n19\u201342.</li>\n<li>Shea, N., 2013, \u201cNaturalizing Representational\nContent\u201d, <em>Philosophy Compass</em>, 8: 496\u2013509.</li>\n<li>\u2013\u2013\u2013, 2018, <em>Representation in Cognitive\nScience</em>, Oxford: Oxford University Press.</li>\n<li>Sieg, W., 2009, \u201cOn Computability\u201d, in <em>Philosophy\nof Mathematics</em>, A. Irvine (ed.), Burlington: Elsevier.</li>\n<li>Siegelmann, H. and E. Sontag, 1991, \u201cTuring Computability\nwith Neural Nets\u201d, <em>Applied Mathematics Letters</em>, 4:\n77\u201380.</li>\n<li>Siegelmann, H. and E. Sontag, 1995, \u201cOn the Computational\nPower of Neural Nets\u201d, <em>Journal of Computer and Science\nSystems</em>, 50: 132\u2013150.</li>\n<li>Silverberg, A., 2006, \u201cChomsky and Egan on Computational\nTheories of Vision\u201d, <em>Minds and Machines</em>, 16:\n495\u2013524.</li>\n<li>Sloman, A., 1978, <em>The Computer Revolution in Philosophy</em>,\nHassocks: The Harvester Press.</li>\n<li>Smolensky, P., 1988, \u201cOn the Proper Treatment of\nConnectionism\u201d, <em>Behavioral and Brain Sciences</em>, 11:\n1\u201374.</li>\n<li>\u2013\u2013\u2013, 1991, \u201cConnectionism, Constituency,\nand the Language of Thought\u201d, in <em>Meaning in Mind: Fodor and\nHis Critics</em>, B. Loewer and G. Rey (eds), Cambridge:\nBlackwell.</li>\n<li>Sperber, D., 2002, \u201cIn Defense of Massive Modularity\u201d,\nin <em>Language, Brain, and Cognitive Development: Essays in Honor of\nJacques Mehler</em>, E. Dupoux (ed.), Cambridge, MA: MIT Press.</li>\n<li>Sprevak, M., 2010, \u201cComputation, Individuation, and the\nReceived View on Representation\u201d, <em>Studies in History and\nPhilosophy of Science</em>, 41: 260\u2013270.</li>\n<li>\u2013\u2013\u2013, 2019, \u201cTriviality Arguments About\nComputational Implementation\u201d, in Sprevak and Colombo 2019:\n175\u2013191.</li>\n<li>\u2013\u2013\u2013, forthcoming, \u201cTwo Kinds of\nInformation Processing in Cognition\u201d, <em>Review of Philosophy\nand Psychology</em>.</li>\n<li>Sprevak, M. and Colombo, M., 2019, <em>The Routledge Handbook of\nthe Computational Mind</em>, New York: Routledge.</li>\n<li>Stalnaker, R., 1999, <em>Context and Content</em>, Oxford: Oxford\nUniversity Press.</li>\n<li>Stich, S., 1983, <em>From Folk Psychology to Cognitive\nScience</em>, Cambridge, MA: MIT Press.</li>\n<li>Thelen, E. and L. Smith, 1994, <em>A Dynamical Systems Approach to\nthe Development of Cognition and Action</em>, Cambridge, MA: MIT\nPress.</li>\n<li>Thrun, S., W. Burgard, and D. Fox, 2006, <em>Probabilistic\nRobotics</em>, Cambridge, MA: MIT Press.</li>\n<li>Thrun, S., M. Montemerlo, and H. Dahlkamp, et al., 2006,\n\u201cStanley: The Robot That Won the DARPA Grand\nChallenge\u201d, <em>Journal of Field Robotics</em>, 23:\n661\u2013692.</li>\n<li>Tolman, E., 1948, \u201cCognitive Maps in Rats and\nMen\u201d, <em>Psychological Review</em>, 55: 189\u2013208.</li>\n<li>Trappenberg, T., 2010, <em>Fundamentals of Computational\nNeuroscience</em>, Oxford: Oxford University Press.</li>\n<li>Turing, A., 1936, \u201cOn Computable Numbers, with an\nApplication to the Entscheidungsproblem\u201d, <em>Proceedings of the\nLondon Mathematical Society</em>, 42: 230\u2013265.</li>\n<li>\u2013\u2013\u2013, 1950, \u201cComputing Machinery and\nIntelligence\u201d, <em>Mind</em>, 49: 433\u2013460.</li>\n<li>van Gelder, T., 1990, \u201cCompositionality: A Connectionist\nVariation on a Classical Theme\u201d,<em>Cognitive Science</em>, 14:\n355\u2013384.</li>\n<li>van Gelder, T. and R. Port, 1995, \u201cIt\u2019s About Time: An\nOverview of the Dynamical Approach to Cognition\u201d, in <em>Mind as\nMotion: Explorations in the Dynamics of Cognition</em>, R. Port and\nT. van Gelder (eds), Cambridge, MA: MIT Press.</li>\n<li>Varela, F., Thompson, E. and Rosch, E., 1991, <em>The Embodied\nMind: Cognitive Science and Human Experience</em>, Cambridge, MA: MIT\nPress.</li>\n<li>von Neumann, J., 1945, \u201cFirst Draft of a Report on the\nEDVAC\u201d, Moore School of Electrical Engineering, University of\nPennsylvania. Philadelphia, PA.</li>\n<li>Wakefield, J., 2002, \u201cBroad versus Narrow Content in the\nExplanation of Action: Fodor on Frege Cases\u201d, <em>Philosophical\nPsychology</em>, 15: 119\u2013133.</li>\n<li>Weiskopf, D., 2004, \u201cThe Place of Time in\nCognition\u201d, <em>British Journal for the Philosophy of\nScience</em>, 55: 87\u2013105.</li>\n<li>Whitehead, A.N. and B. Russell, 1925, <em>Principia\nMathematica</em>, vol. 1, 2<sup>nd</sup> ed., Cambridge: Cambridge\nUniversity Press.</li>\n<li>Wilson, R., 2005, \u201cWhat Computers (Still, Still) Can\u2019t\nDo\u201d, in <em>New Essays in Philosophy of Language and Mind</em>,\nR. Stainton, M. Ezcurdia, and C.D. Viger (eds). <em>Canadian Journal\nof Philosophy</em>, supplementary issue 30: 407\u2013425.</li>\n<li>Yablo, S., 1997, \u201cWide Causation\u201d, <em>Philosophical\nPerspectives</em>, 11: 251\u2013281.</li>\n<li>\u2013\u2013\u2013, 2003, \u201cCausal\nRelevance\u201d, <em>Philosophical Issues</em>, 13:\n316\u2013327.</li>\n<li>Zednik, C., 2019, \u201cComputational Cognitive\nNeuroscience\u201d, in Sprevak and Colombo 2019: 357\u2013369.</li>\n<li>Zylberberg, A., S. Dehaene, P. Roelfsema, and M. Sigman, 2011,\n\u201cThe Human Turing Machine\u201d, <em>Trends in Cognitive\nScience</em>, 15: 293\u2013300.</li>\n</ul>\n</div>"}, "related_entries": {"entry_list": ["analogy and analogical reasoning", "anomalous monism", "causation: the metaphysics of", "Chinese room argument", "Church-Turing Thesis", "cognitive science", "computability and complexity", "computation: in physical systems", "computer science, philosophy of", "computing: modern history of", "connectionism", "culture: and cognitive science", "externalism about the mind", "folk psychology: as mental simulation", "frame problem", "functionalism", "G\u00f6del, Kurt", "G\u00f6del, Kurt: incompleteness theorems", "Hilbert, David: program in the foundations of mathematics", "language of thought hypothesis", "mental causation", "mental content: causal theories of", "mental content: narrow", "mental content: teleological theories of", "mental imagery", "mental representation", "mental representation: in medieval philosophy", "mind/brain identity theory", "models in science", "multiple realizability", "other minds", "reasoning: automated", "reasoning: defeasible", "reduction, scientific", "simulations in science", "Turing, Alan", "Turing machines", "Turing test", "zombies"], "entry_link": [{"../reasoning-analogy/": "analogy and analogical reasoning"}, {"../anomalous-monism/": "anomalous monism"}, {"../causation-metaphysics/": "causation: the metaphysics of"}, {"../chinese-room/": "Chinese room argument"}, {"../church-turing/": "Church-Turing Thesis"}, {"../cognitive-science/": "cognitive science"}, {"../computability/": "computability and complexity"}, {"../computation-physicalsystems/": "computation: in physical systems"}, {"../computer-science/": "computer science, philosophy of"}, {"../computing-history/": "computing: modern history of"}, {"../connectionism/": "connectionism"}, {"../culture-cogsci/": "culture: and cognitive science"}, {"../content-externalism/": "externalism about the mind"}, {"../folkpsych-simulation/": "folk psychology: as mental simulation"}, {"../frame-problem/": "frame problem"}, {"../functionalism/": "functionalism"}, {"../goedel/": "G\u00f6del, Kurt"}, {"../goedel-incompleteness/": "G\u00f6del, Kurt: incompleteness theorems"}, {"../hilbert-program/": "Hilbert, David: program in the foundations of mathematics"}, {"../language-thought/": "language of thought hypothesis"}, {"../mental-causation/": "mental causation"}, {"../content-causal/": "mental content: causal theories of"}, {"../content-narrow/": "mental content: narrow"}, {"../content-teleological/": "mental content: teleological theories of"}, {"../mental-imagery/": "mental imagery"}, {"../mental-representation/": "mental representation"}, {"../representation-medieval/": "mental representation: in medieval philosophy"}, {"../mind-identity/": "mind/brain identity theory"}, {"../models-science/": "models in science"}, {"../multiple-realizability/": "multiple realizability"}, {"../other-minds/": "other minds"}, {"../reasoning-automated/": "reasoning: automated"}, {"../reasoning-defeasible/": "reasoning: defeasible"}, {"../scientific-reduction/": "reduction, scientific"}, {"../simulations-science/": "simulations in science"}, {"../turing/": "Turing, Alan"}, {"../turing-machine/": "Turing machines"}, {"../turing-test/": "Turing test"}, {"../zombies/": "zombies"}]}, "academic_tools": {"listed_text": ["<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>", "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=computational-mind\" target=\"other\">How to cite this entry</a>.", "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>", "<a href=\"https://leibniz.stanford.edu/friends/preview/computational-mind/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.", "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>", "<a href=\"https://www.inphoproject.org/entity?sep=computational-mind&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).", "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>", "<a href=\"http://philpapers.org/sep/computational-mind/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"http://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."], "listed_links": [{"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=computational-mind": "How to cite this entry"}, {"https://leibniz.stanford.edu/friends/preview/computational-mind/": "Preview the PDF version of this entry"}, {"https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"}, {"https://www.inphoproject.org/entity?sep=computational-mind&redirect=True": "Look up topics and thinkers related to this entry"}, {"http://philpapers.org/sep/computational-mind/": "Enhanced bibliography for this entry"}, {"http://philpapers.org/": "PhilPapers"}]}, "other_internet_resources": {"listed_text": ["Graves, A., G. Wayne, and I. Danihelko, 2014, \n\u201c<a href=\"https://arxiv.org/abs/1410.5401\" target=\"other\">Neural Turing Machines</a>\u201d, manuscript at arXiv.org.", "Horst, Steven, \u201cThe Computational Theory of Mind\u201d,\n <em>Stanford Encyclopedia of Philosophy</em> (Summer 2015 Edition),\n Edward N. Zalta (ed.), URL =\n&lt;<a href=\"https://plato.stanford.edu/archives/sum2015/entries/computational-mind/\">https://plato.stanford.edu/archives/sum2015/entries/computational-mind/</a>&gt;. [This is the previous entry on the\nComputational Theory of Mind in the \n<em>Stanford Encyclopedia of Philosophy</em> \u2014 see the \n<a class=\"plain\" href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=computational-mind\" target=\"other\">version history</a>.]", "Marcin Milkowski, \n \u201c<a href=\"http://www.iep.utm.edu/compmind/\" target=\"other\">The Computational Theory of Mind</a>,\u201d\n in the <em>Internet Encyclopedia of Philosophy</em>.", "Pozzi, I., S. Boht\u00e9, and P. Roelfsema, 2019, \n\u201c<a href=\"https://arxiv.org/pdf/1811.01768.pdf\" target=\"other\">A Biologically Plausible Learning Rule for Deep Learning in the Brain</a>\u201d, \n manuscript at arXiv.org.", "<a href=\"http://philpapers.org/browse/philosophy-of-artificial-intelligence\" target=\"other\">Bibliography on philosophy of artificial intelligence</a>,\n in Philpapers.org."], "listed_links": [{"https://arxiv.org/abs/1410.5401": "Neural Turing Machines"}, {"https://plato.stanford.edu/archives/sum2015/entries/computational-mind/": "https://plato.stanford.edu/archives/sum2015/entries/computational-mind/"}, {"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=computational-mind": "version history"}, {"http://www.iep.utm.edu/compmind/": "The Computational Theory of Mind"}, {"https://arxiv.org/pdf/1811.01768.pdf": "A Biologically Plausible Learning Rule for Deep Learning in the Brain"}, {"http://philpapers.org/browse/philosophy-of-artificial-intelligence": "Bibliography on philosophy of artificial intelligence"}]}, "tokenized_text": ["1", "turing", "machine", "intuitive", "notion", "computation", "algorithm", "central", "mathematics", "roughly", "speaking", "algorithm", "explicit", "stepbystep", "procedure", "answering", "question", "solving", "problem", "algorithm", "provides", "routine", "mechanical", "instruction", "dictating", "proceed", "step", "obeying", "instruction", "requires", "special", "ingenuity", "creativity", "example", "familiar", "gradeschool", "algorithm", "describe", "compute", "addition", "multiplication", "division", "early", "twentieth", "century", "mathematician", "relied", "upon", "informal", "notion", "computation", "algorithm", "without", "attempting", "anything", "like", "formal", "analysis", "development", "foundation", "mathematics", "eventually", "impelled", "logician", "pursue", "systematic", "treatment", "alan", "turing", "landmark", "paper", "computable", "number", "application", "entscheidungsproblem", "turing", "1936", "offered", "analysis", "proved", "influential", "turing", "machine", "abstract", "model", "idealized", "computing", "device", "unlimited", "time", "storage", "space", "disposal", "device", "manipulates", "symbol", "much", "human", "computing", "agent", "manipulates", "pencil", "mark", "paper", "arithmetical", "computation", "turing", "say", "little", "nature", "symbol", "assumes", "primitive", "symbol", "drawn", "finite", "alphabet", "also", "assumes", "symbol", "inscribed", "erased", "memory", "location", "turing", "model", "work", "follows", "infinitely", "many", "memory", "location", "arrayed", "linear", "structure", "metaphorically", "memory", "location", "cell", "infinitely", "long", "paper", "tape", "literally", "memory", "location", "might", "physically", "realized", "various", "medium", "eg", "silicon", "chip", "central", "processor", "access", "one", "memory", "location", "time", "metaphorically", "central", "processor", "scanner", "move", "along", "paper", "tape", "one", "cell", "time", "central", "processor", "enter", "finitely", "many", "machine", "state", "central", "processor", "perform", "four", "elementary", "operation", "write", "symbol", "memory", "location", "erase", "symbol", "memory", "location", "access", "next", "memory", "location", "linear", "array", "move", "right", "tape", "access", "previous", "memory", "location", "linear", "array", "move", "left", "tape", "elementary", "operation", "central", "processor", "performs", "depends", "entirely", "upon", "two", "fact", "symbol", "currently", "inscribed", "present", "memory", "location", "scanner", "current", "machine", "state", "machine", "table", "dictate", "elementary", "operation", "central", "processor", "performs", "given", "current", "machine", "state", "symbol", "currently", "accessing", "machine", "table", "also", "dictate", "central", "processor", "machine", "state", "change", "given", "factor", "thus", "machine", "table", "enshrines", "finite", "set", "routine", "mechanical", "instruction", "governing", "computation", "turing", "translates", "informal", "description", "rigorous", "mathematical", "model", "detail", "see", "entry", "turing", "machine", "turing", "motivates", "approach", "reflecting", "idealized", "human", "computing", "agent", "citing", "finitary", "limit", "perceptual", "cognitive", "apparatus", "argues", "symbolic", "algorithm", "executed", "human", "replicated", "suitable", "turing", "machine", "concludes", "turing", "machine", "formalism", "despite", "extreme", "simplicity", "powerful", "enough", "capture", "humanly", "executable", "mechanical", "procedure", "symbolic", "configuration", "subsequent", "discussant", "almost", "universally", "agreed", "turing", "computation", "often", "described", "digital", "rather", "analog", "mean", "always", "clear", "basic", "idea", "usually", "computation", "operates", "discrete", "configuration", "comparison", "many", "historically", "important", "algorithm", "operate", "continuously", "variable", "configuration", "example", "euclidean", "geometry", "assigns", "large", "role", "rulerandcompass", "construction", "manipulate", "geometric", "shape", "shape", "one", "find", "another", "differs", "arbitrarily", "small", "extent", "symbolic", "configuration", "manipulated", "turing", "machine", "differ", "arbitrarily", "small", "extent", "turing", "machine", "operate", "discrete", "string", "element", "digit", "drawn", "finite", "alphabet", "one", "recurring", "controversy", "concern", "whether", "digital", "paradigm", "wellsuited", "model", "mental", "activity", "whether", "analog", "paradigm", "would", "instead", "fitting", "maclennan", "2012", "piccinini", "bahar", "2013", "besides", "introducing", "turing", "machine", "turing", "1936", "proved", "several", "seminal", "mathematical", "result", "involving", "particular", "proved", "existence", "universal", "turing", "machine", "utm", "roughly", "speaking", "utm", "turing", "machine", "mimic", "turing", "machine", "one", "provides", "utm", "symbolic", "input", "code", "machine", "table", "turing", "machine", "m", "utm", "replicates", "behavior", "executing", "instruction", "enshrined", "machine", "table", "sense", "utm", "programmable", "general", "purpose", "computer", "first", "approximation", "personal", "computer", "also", "general", "purpose", "mimic", "turing", "machine", "suitably", "programmed", "main", "caveat", "physical", "computer", "finite", "memory", "whereas", "turing", "machine", "unlimited", "memory", "accurately", "personal", "computer", "mimic", "turing", "machine", "exhaust", "limited", "memory", "supply", "turing", "discussion", "helped", "lay", "foundation", "computer", "science", "seek", "design", "build", "understand", "computing", "system", "know", "computer", "scientist", "build", "extremely", "sophisticated", "computing", "machine", "machine", "implement", "something", "resembling", "turing", "computation", "although", "detail", "differ", "turing", "simplified", "model", "2", "artificial", "intelligence", "rapid", "progress", "computer", "science", "prompted", "many", "including", "turing", "contemplate", "whether", "could", "build", "computer", "capable", "thought", "artificial", "intelligence", "ai", "aim", "construct", "thinking", "machinery", "precisely", "aim", "construct", "computing", "machine", "execute", "core", "mental", "task", "reasoning", "decisionmaking", "problem", "solving", "1950s", "1960s", "goal", "came", "seem", "increasingly", "realistic", "haugeland", "1985", "early", "ai", "research", "emphasized", "logic", "researcher", "sought", "mechanize", "deductive", "reasoning", "famous", "example", "logic", "theorist", "computer", "program", "newell", "simon", "1956", "proved", "38", "first", "52", "theorem", "principia", "mathematica", "whitehead", "russell", "1925", "one", "case", "discovered", "simpler", "proof", "principia", "early", "success", "kind", "stimulated", "enormous", "interest", "inside", "outside", "academy", "many", "researcher", "predicted", "intelligent", "machine", "year", "away", "obviously", "prediction", "fulfilled", "intelligent", "robot", "yet", "walk", "among", "u", "even", "relatively", "lowlevel", "mental", "process", "perception", "vastly", "exceed", "capacity", "current", "computer", "program", "confident", "prediction", "thinking", "machine", "proved", "optimistic", "many", "observer", "lost", "interest", "concluded", "ai", "fool", "errand", "nevertheless", "decade", "witnessed", "gradual", "progress", "one", "striking", "success", "ibm", "deep", "blue", "defeated", "chess", "champion", "gary", "kasparov", "1997", "another", "major", "success", "driverless", "car", "stanley", "thrun", "montemerlo", "dahlkamp", "et", "al", "2006", "completed", "132mile", "course", "mojave", "desert", "winning", "2005", "defense", "advanced", "research", "project", "agency", "darpa", "grand", "challenge", "le", "flashy", "success", "story", "vast", "improvement", "speech", "recognition", "algorithm", "one", "problem", "dogged", "early", "work", "ai", "uncertainty", "nearly", "reasoning", "decisionmaking", "operates", "condition", "uncertainty", "example", "may", "need", "decide", "whether", "go", "picnic", "uncertain", "whether", "rain", "bayesian", "decision", "theory", "standard", "mathematical", "model", "inference", "decisionmaking", "uncertainty", "uncertainty", "codified", "probability", "precise", "rule", "dictate", "update", "probability", "light", "new", "evidence", "select", "action", "light", "probability", "utility", "see", "entry", "bayes", "theorem", "normative", "theory", "rational", "choice", "expected", "utility", "detail", "1980s", "1990s", "technological", "conceptual", "development", "enabled", "efficient", "computer", "program", "implement", "approximate", "bayesian", "inference", "realistic", "scenario", "explosion", "bayesian", "ai", "ensued", "thrun", "burgard", "fox", "2006", "including", "aforementioned", "advance", "speech", "recognition", "driverless", "vehicle", "tractable", "algorithm", "handle", "uncertainty", "major", "achievement", "contemporary", "ai", "murphy", "2012", "possibly", "harbinger", "impressive", "future", "progress", "philosopher", "insist", "computer", "matter", "sophisticated", "become", "best", "mimic", "rather", "replicate", "thought", "computer", "simulation", "weather", "really", "rain", "computer", "simulation", "flight", "really", "fly", "even", "computing", "system", "could", "simulate", "mental", "activity", "suspect", "would", "constitute", "genuine", "article", "turing", "1950", "anticipated", "worry", "tried", "defuse", "proposed", "scenario", "called", "turing", "test", "one", "evaluates", "whether", "unseen", "interlocutor", "computer", "human", "computer", "pass", "turing", "test", "one", "determine", "computer", "turing", "proposed", "abandon", "question", "could", "computer", "think", "hopelessly", "vague", "replacing", "question", "could", "computer", "pas", "turing", "test", "turing", "discussion", "received", "considerable", "attention", "proving", "especially", "influential", "within", "ai", "ned", "block", "1981", "offer", "influential", "critique", "argues", "certain", "possible", "machine", "pas", "turing", "test", "even", "though", "machine", "come", "close", "genuine", "thought", "intelligence", "see", "entry", "turing", "test", "discussion", "block", "objection", "issue", "surrounding", "turing", "test", "ai", "see", "entry", "logic", "artificial", "intelligence", "much", "detail", "see", "russell", "norvig", "2010", "3", "classical", "computational", "theory", "mind", "warren", "mcculloch", "walter", "pitt", "1943", "first", "suggested", "something", "resembling", "turing", "machine", "might", "provide", "good", "model", "mind", "1960s", "turing", "computation", "became", "central", "emerging", "interdisciplinary", "initiative", "cognitive", "science", "study", "mind", "drawing", "upon", "psychology", "computer", "science", "especially", "ai", "linguistics", "philosophy", "economics", "especially", "game", "theory", "behavioral", "economics", "anthropology", "neuroscience", "label", "classical", "computational", "theory", "mind", "abbreviate", "cctm", "fairly", "standard", "according", "cctm", "mind", "computational", "system", "similar", "important", "respect", "turing", "machine", "core", "mental", "process", "eg", "reasoning", "decisionmaking", "problem", "solving", "computation", "similar", "important", "respect", "computation", "executed", "turing", "machine", "formulation", "imprecise", "cctm", "best", "seen", "family", "view", "rather", "single", "welldefined", "view", "1", "common", "describe", "cctm", "embodying", "computer", "metaphor", "description", "doubly", "misleading", "first", "cctm", "better", "formulated", "describing", "mind", "computing", "system", "computational", "system", "rather", "computer", "david", "chalmers", "2011", "note", "describing", "system", "computer", "strongly", "suggests", "system", "programmable", "chalmers", "also", "note", "one", "need", "claim", "mind", "programmable", "simply", "one", "regard", "turingstyle", "computational", "system", "turing", "machine", "programmable", "thus", "phrase", "computer", "metaphor", "strongly", "suggests", "theoretical", "commitment", "inessential", "cctm", "point", "terminological", "critic", "cctm", "often", "object", "mind", "programmable", "general", "purpose", "computer", "churchland", "koch", "sejnowski", "1990", "since", "classical", "computationalists", "need", "claim", "usually", "claim", "mind", "programmable", "general", "purpose", "computer", "objection", "misdirected", "second", "cctm", "intended", "metaphorically", "cctm", "simply", "hold", "mind", "like", "computing", "system", "cctm", "hold", "mind", "literally", "computing", "system", "course", "familiar", "artificial", "computing", "system", "made", "silicon", "chip", "similar", "material", "whereas", "human", "body", "made", "flesh", "blood", "cctm", "hold", "difference", "disguise", "fundamental", "similarity", "capture", "turingstyle", "computational", "model", "offering", "model", "prescind", "physical", "detail", "attain", "abstract", "computational", "description", "could", "physically", "implemented", "diverse", "way", "eg", "silicon", "chip", "neuron", "pulley", "lever", "cctm", "hold", "suitable", "abstract", "computational", "model", "offer", "literally", "true", "description", "core", "mental", "process", "common", "summarize", "cctm", "slogan", "mind", "turing", "machine", "slogan", "also", "somewhat", "misleading", "one", "regard", "turing", "precise", "formalism", "plausible", "model", "mental", "activity", "formalism", "seems", "restrictive", "several", "way", "turing", "machine", "execute", "pure", "symbolic", "computation", "input", "output", "symbol", "inscribed", "memory", "location", "contrast", "mind", "receives", "sensory", "input", "eg", "retinal", "stimulation", "produce", "motor", "output", "eg", "muscle", "activation", "complete", "theory", "must", "describe", "mental", "computation", "interface", "sensory", "input", "motor", "output", "turing", "machine", "infinite", "discrete", "memory", "capacity", "ordinary", "biological", "system", "finite", "memory", "capacity", "plausible", "psychological", "model", "must", "replace", "infinite", "memory", "store", "large", "finite", "memory", "store", "modern", "computer", "random", "access", "memory", "addressable", "memory", "location", "central", "processor", "directly", "access", "turing", "machine", "memory", "addressable", "central", "processor", "access", "location", "sequentially", "accessing", "intermediate", "location", "computation", "without", "addressable", "memory", "hopelessly", "inefficient", "reason", "cr", "gallistel", "adam", "king", "2009", "argue", "addressable", "memory", "give", "better", "model", "mind", "nonaddressable", "memory", "turing", "machine", "central", "processor", "operates", "serially", "executing", "one", "instruction", "time", "computational", "formalism", "relax", "assumption", "allowing", "multiple", "processing", "unit", "operate", "parallel", "classical", "computationalists", "allow", "parallel", "computation", "fodor", "pylyshyn", "1988", "gallistel", "king", "2009", "174", "see", "gandy", "1980", "sieg", "2009", "general", "mathematical", "treatment", "encompass", "serial", "parallel", "computation", "turing", "computation", "deterministic", "total", "computational", "state", "determines", "subsequent", "computational", "state", "one", "might", "instead", "allow", "stochastic", "computation", "stochastic", "model", "current", "state", "dictate", "unique", "next", "state", "rather", "certain", "probability", "machine", "transition", "one", "state", "another", "cctm", "claim", "mental", "activity", "turingstyle", "computation", "allowing", "departure", "turing", "formalism", "31", "machine", "functionalism", "hilary", "putnam", "1967", "introduced", "cctm", "philosophy", "contrasted", "position", "logical", "behaviorism", "typeidentity", "theory", "position", "purport", "reveal", "nature", "mental", "state", "including", "propositional", "attitude", "eg", "belief", "sensation", "eg", "pain", "emotion", "eg", "fear", "according", "logical", "behaviorism", "mental", "state", "behavioral", "disposition", "according", "typeidentity", "theory", "mental", "state", "brain", "state", "putnam", "advance", "opposing", "functionalist", "view", "mental", "state", "functional", "state", "according", "functionalism", "system", "mind", "system", "suitable", "functional", "organization", "mental", "state", "state", "play", "appropriate", "role", "system", "functional", "organization", "mental", "state", "individuated", "interaction", "sensory", "input", "motor", "output", "mental", "state", "functionalism", "offer", "notable", "advantage", "logical", "behaviorism", "typeidentity", "theory", "behaviorist", "want", "associate", "mental", "state", "characteristic", "pattern", "behaviora", "hopeless", "task", "individual", "mental", "state", "usually", "characteristic", "behavioral", "effect", "behavior", "almost", "always", "result", "distinct", "mental", "state", "operating", "together", "eg", "belief", "desire", "functionalism", "avoids", "difficulty", "individuating", "mental", "state", "characteristic", "relation", "sensory", "input", "behavior", "also", "one", "another", "typeidentity", "theorist", "want", "associate", "mental", "state", "characteristic", "physical", "neurophysiological", "state", "putnam", "cast", "project", "doubt", "arguing", "mental", "state", "multiply", "realizable", "mental", "state", "realized", "diverse", "physical", "system", "including", "terrestrial", "creature", "also", "hypothetical", "creature", "eg", "siliconbased", "martian", "functionalism", "tailormade", "accommodate", "multiple", "realizability", "according", "functionalism", "matter", "mentality", "pattern", "organization", "could", "physically", "realized", "many", "different", "way", "see", "entry", "multiple", "realizability", "discussion", "argument", "putnam", "defends", "brand", "functionalism", "called", "machine", "functionalism", "emphasizes", "probabilistic", "automaton", "similar", "turing", "machine", "except", "transition", "computational", "state", "stochastic", "proposes", "mental", "activity", "implement", "probabilistic", "automaton", "particular", "mental", "state", "machine", "state", "automaton", "central", "processor", "machine", "table", "specifies", "appropriate", "functional", "organization", "also", "specifies", "role", "individual", "mental", "state", "play", "within", "functional", "organization", "way", "putnam", "combine", "functionalism", "cctm", "machine", "functionalism", "face", "several", "problem", "one", "problem", "highlighted", "ned", "block", "jerry", "fodor", "1972", "concern", "productivity", "thought", "normal", "human", "entertain", "potential", "infinity", "proposition", "machine", "functionalism", "identifies", "mental", "state", "machine", "state", "probabilistic", "automaton", "since", "finitely", "many", "machine", "state", "enough", "machine", "state", "pair", "oneone", "possible", "mental", "state", "normal", "human", "course", "actual", "human", "ever", "entertain", "finitely", "many", "proposition", "however", "block", "fodor", "contend", "limitation", "reflects", "limit", "lifespan", "memory", "rather", "say", "psychological", "law", "restricts", "class", "humanly", "entertainable", "proposition", "probabilistic", "automaton", "endowed", "unlimited", "time", "memory", "capacity", "yet", "even", "still", "finitely", "many", "machine", "state", "apparently", "machine", "functionalism", "mislocates", "finitary", "limit", "upon", "human", "cognition", "another", "problem", "machine", "functionalism", "also", "highlighted", "block", "fodor", "1972", "concern", "systematicity", "thought", "ability", "entertain", "one", "proposition", "correlated", "ability", "think", "proposition", "example", "someone", "entertain", "thought", "john", "love", "mary", "also", "entertain", "thought", "mary", "love", "john", "thus", "seem", "systematic", "relation", "mental", "state", "good", "theory", "reflect", "systematic", "relation", "yet", "machine", "functionalism", "identifies", "mental", "state", "unstructured", "machine", "state", "lack", "requisite", "systematic", "relation", "another", "reason", "machine", "functionalism", "explain", "systematicity", "response", "objection", "machine", "functionalist", "might", "deny", "obligated", "explain", "systematicity", "nevertheless", "objection", "suggests", "machine", "functionalism", "neglect", "essential", "feature", "human", "mentality", "better", "theory", "would", "explain", "feature", "principled", "way", "productivity", "systematicity", "objection", "machine", "functionalism", "perhaps", "decisive", "provide", "strong", "impetus", "pursue", "improved", "version", "cctm", "see", "block", "1978", "additional", "problem", "facing", "machine", "functionalism", "functionalism", "generally", "32", "representational", "theory", "mind", "fodor", "1975", "1981", "1987", "1990", "1994", "2008", "advocate", "version", "cctm", "accommodates", "systematicity", "productivity", "much", "satisfactorily", "shift", "attention", "symbol", "manipulated", "turingstyle", "computation", "old", "view", "stretching", "back", "least", "william", "ockham", "summa", "logicae", "hold", "thinking", "occurs", "language", "thought", "sometimes", "called", "mentalese", "fodor", "revives", "view", "postulate", "system", "mental", "representation", "including", "primitive", "representation", "complex", "representation", "formed", "primitive", "representation", "example", "primitive", "mentalese", "word", "john", "mary", "love", "combine", "form", "mentalese", "sentence", "john", "love", "mary", "mentalese", "compositional", "meaning", "complex", "mentalese", "expression", "function", "meaning", "part", "way", "part", "combined", "propositional", "attitude", "relation", "mentalese", "symbol", "fodor", "call", "view", "representational", "theory", "mind", "rtm", "combining", "rtm", "cctm", "argues", "mental", "activity", "involves", "turingstyle", "computation", "language", "thought", "mental", "computation", "store", "mentalese", "symbol", "memory", "location", "manipulating", "symbol", "accord", "mechanical", "rule", "prime", "virtue", "rtm", "readily", "accommodates", "productivity", "systematicity", "productivity", "rtm", "postulate", "finite", "set", "primitive", "mentalese", "expression", "combinable", "potential", "infinity", "complex", "mentalese", "expression", "thinker", "access", "primitive", "mentalese", "vocabulary", "mentalese", "compounding", "device", "potential", "entertain", "infinity", "mentalese", "expression", "therefore", "potential", "instantiate", "infinitely", "many", "propositional", "attitude", "neglecting", "limit", "time", "memory", "systematicity", "according", "rtm", "systematic", "relation", "propositional", "attitude", "thinker", "entertain", "example", "suppose", "think", "john", "love", "mary", "according", "rtm", "involves", "standing", "relation", "r", "mentalese", "sentence", "john", "love", "mary", "composed", "mentalese", "word", "john", "love", "mary", "combined", "right", "way", "capacity", "also", "capacity", "stand", "relation", "r", "distinct", "mentalese", "sentence", "mary", "love", "john", "thereby", "thinking", "mary", "love", "john", "capacity", "think", "john", "love", "mary", "systematically", "related", "capacity", "think", "mary", "love", "john", "treating", "propositional", "attitude", "relation", "complex", "mental", "symbol", "rtm", "explains", "productivity", "systematicity", "cctmrtm", "differs", "machine", "functionalism", "several", "respect", "first", "machine", "functionalism", "theory", "mental", "state", "general", "rtm", "theory", "propositional", "attitude", "second", "proponent", "cctmrtm", "need", "say", "propositional", "attitude", "individuated", "functionally", "fodor", "2000", "105", "fn", "4", "note", "must", "distinguish", "computationalism", "mental", "process", "computational", "functionalism", "mental", "state", "functional", "state", "machine", "functionalism", "endorses", "doctrine", "cctmrtm", "endorses", "first", "unfortunately", "many", "philosopher", "still", "mistakenly", "assume", "computationalism", "entail", "functionalist", "approach", "propositional", "attitude", "see", "piccinini", "2004", "discussion", "philosophical", "discussion", "rtm", "tends", "focus", "mainly", "highlevel", "human", "thought", "especially", "belief", "desire", "however", "cctmrtm", "applicable", "much", "wider", "range", "mental", "state", "process", "many", "cognitive", "scientist", "apply", "nonhuman", "animal", "example", "gallistel", "king", "2009", "apply", "certain", "invertebrate", "phenomenon", "eg", "honeybee", "navigation", "even", "confining", "attention", "human", "one", "apply", "cctmrtm", "subpersonal", "processing", "fodor", "1983", "argues", "perception", "involves", "subpersonal", "module", "convert", "retinal", "input", "mentalese", "symbol", "performs", "computation", "symbol", "thus", "talk", "language", "thought", "potentially", "misleading", "since", "suggests", "nonexistent", "restriction", "higherlevel", "mental", "activity", "also", "potentially", "misleading", "description", "mentalese", "language", "suggests", "mentalese", "symbol", "resemble", "expression", "natural", "language", "many", "philosopher", "including", "fodor", "sometimes", "seem", "endorse", "position", "however", "possible", "nonpropositional", "format", "mentalese", "symbol", "proponent", "cctmrtm", "adopt", "pluralistic", "line", "allowing", "mental", "computation", "operate", "item", "akin", "image", "map", "diagram", "nonpropositional", "representation", "johnsonlaird", "2004", "187", "mcdermott", "2001", "69", "pinker", "2005", "7", "sloman", "1978", "144176", "pluralistic", "line", "seems", "especially", "plausible", "applied", "subpersonal", "process", "perception", "nonhuman", "animal", "michael", "rescorla", "2009a", "b", "survey", "research", "cognitive", "map", "tolman", "1948", "keefe", "nadel", "1978", "gallistel", "1990", "suggesting", "animal", "may", "navigate", "computing", "mental", "representation", "similar", "map", "sentence", "elisabeth", "camp", "2009", "citing", "research", "baboon", "social", "interaction", "cheney", "seyfarth", "2007", "argues", "baboon", "may", "encode", "social", "dominance", "relation", "nonsentential", "treestructured", "representation", "cctmrtm", "schematic", "fill", "schema", "one", "must", "provide", "detailed", "computational", "model", "specific", "mental", "process", "complete", "model", "describe", "mentalese", "symbol", "manipulated", "process", "isolate", "elementary", "operation", "manipulate", "symbol", "eg", "inscribing", "symbol", "memory", "location", "delineate", "mechanical", "rule", "governing", "application", "elementary", "operation", "providing", "detailed", "computational", "model", "decompose", "complex", "mental", "process", "series", "elementary", "operation", "governed", "precise", "routine", "instruction", "cctmrtm", "remains", "neutral", "traditional", "debate", "physicalism", "substance", "dualism", "turingstyle", "model", "proceeds", "abstract", "level", "saying", "whether", "mental", "computation", "implemented", "physical", "stuff", "cartesian", "soulstuff", "block", "1983", "522", "practice", "proponent", "cctmrtm", "embrace", "broadly", "physicalist", "outlook", "hold", "mental", "computation", "implemented", "soulstuff", "rather", "brain", "view", "mentalese", "symbol", "realized", "neural", "state", "computational", "operation", "mentalese", "symbol", "realized", "neural", "process", "ultimately", "physicalist", "proponent", "cctmrtm", "must", "produce", "empirically", "wellconfirmed", "theory", "explain", "exactly", "neural", "activity", "implement", "turingstyle", "computation", "gallistel", "king", "2009", "emphasize", "currently", "theoriesthough", "see", "zylberberg", "dehaene", "roelfsema", "sigman", "2011", "speculation", "fodor", "1975", "advance", "cctmrtm", "foundation", "cognitive", "science", "discus", "mental", "phenomenon", "decisionmaking", "perception", "linguistic", "processing", "case", "maintains", "best", "scientific", "theory", "postulate", "turingstyle", "computation", "mental", "representation", "fact", "argues", "viable", "theory", "form", "concludes", "cctmrtm", "game", "town", "many", "cognitive", "scientist", "argue", "along", "similar", "line", "cr", "gallistel", "adam", "king", "2009", "philip", "johnsonlaird", "1988", "allen", "newell", "herbert", "simon", "1976", "zenon", "pylyshyn", "1984", "recommend", "turingstyle", "computation", "mental", "symbol", "best", "foundation", "scientific", "theorizing", "mind", "4", "neural", "network", "1980s", "connectionism", "emerged", "prominent", "rival", "classical", "computationalism", "connectionists", "draw", "inspiration", "neurophysiology", "rather", "logic", "computer", "science", "employ", "computational", "model", "neural", "network", "differ", "significantly", "turingstyle", "model", "neural", "network", "collection", "interconnected", "node", "node", "fall", "three", "category", "input", "node", "output", "node", "hidden", "node", "mediate", "input", "output", "node", "node", "activation", "value", "given", "real", "number", "one", "node", "bear", "weighted", "connection", "another", "node", "also", "given", "real", "number", "activation", "input", "node", "determined", "exogenously", "input", "computation", "total", "input", "activation", "hidden", "output", "node", "weighted", "sum", "activation", "node", "feeding", "activation", "hidden", "output", "node", "function", "total", "input", "activation", "particular", "function", "varies", "network", "neural", "network", "computation", "wave", "activation", "propagate", "input", "node", "output", "node", "determined", "weighted", "connection", "node", "feedforward", "network", "weighted", "connection", "flow", "one", "direction", "recurrent", "network", "feedback", "loop", "connection", "emanating", "hidden", "unit", "circle", "back", "hidden", "unit", "recurrent", "network", "le", "mathematically", "tractable", "feedforward", "network", "however", "figure", "crucially", "psychological", "modeling", "various", "phenomenon", "phenomenon", "involve", "kind", "memory", "elman", "1990", "weight", "neural", "network", "typically", "mutable", "evolving", "accord", "learning", "algorithm", "literature", "offer", "various", "learning", "algorithm", "basic", "idea", "usually", "adjust", "weight", "actual", "output", "gradually", "move", "closer", "target", "output", "one", "would", "expect", "relevant", "input", "backpropagation", "algorithm", "widely", "used", "algorithm", "kind", "rumelhart", "hinton", "williams", "1986", "connectionism", "trace", "back", "mcculloch", "pitt", "1943", "studied", "network", "interconnected", "logic", "gate", "eg", "andgates", "orgates", "one", "view", "network", "logic", "gate", "neural", "network", "activation", "confined", "two", "value", "0", "1", "activation", "function", "given", "usual", "truthfunctions", "mcculloch", "pitt", "advanced", "logic", "gate", "idealized", "model", "individual", "neuron", "discussion", "exerted", "profound", "influence", "computer", "science", "von", "neumann", "1945", "modern", "digital", "computer", "simply", "network", "logic", "gate", "within", "cognitive", "science", "however", "researcher", "usually", "focus", "upon", "network", "whose", "element", "neuronlike", "logic", "gate", "particular", "modernday", "connectionists", "typically", "emphasize", "analog", "neural", "network", "whose", "node", "take", "continuous", "rather", "discrete", "activation", "value", "author", "even", "use", "phrase", "neural", "network", "exclusively", "denotes", "network", "neural", "network", "received", "relatively", "scant", "attention", "cognitive", "scientist", "1960s", "1970s", "turingstyle", "model", "dominated", "1980s", "witnessed", "huge", "resurgence", "interest", "neural", "network", "especially", "analog", "neural", "network", "twovolume", "parallel", "distributed", "processing", "rumelhart", "mcclelland", "pdp", "research", "group", "1986", "mcclelland", "rumelhart", "pdp", "research", "group", "1987", "serving", "manifesto", "researcher", "constructed", "connectionist", "model", "diverse", "phenomenon", "object", "recognition", "speech", "perception", "sentence", "comprehension", "cognitive", "development", "impressed", "connectionism", "many", "researcher", "concluded", "cctmrtm", "longer", "game", "town", "2010s", "class", "computational", "model", "known", "deep", "neural", "network", "became", "quite", "popular", "krizhevsky", "sutskever", "hinton", "2012", "lecun", "bengio", "hinton", "2015", "model", "neural", "network", "multiple", "layer", "hidden", "node", "sometimes", "hundred", "layer", "deep", "neural", "networkstrained", "large", "data", "set", "one", "another", "learning", "algorithm", "usually", "backpropagation", "have", "achieved", "great", "success", "many", "area", "ai", "including", "object", "recognition", "strategic", "gameplaying", "deep", "neural", "network", "widely", "deployed", "commercial", "application", "focus", "extensive", "ongoing", "investigation", "within", "academia", "industry", "researcher", "also", "begun", "using", "model", "mind", "eg", "marblestone", "wayne", "kording", "2016", "kriegeskorte", "2015", "detailed", "overview", "neural", "network", "see", "haykin", "2008", "userfriendly", "introduction", "emphasis", "psychological", "application", "see", "marcus", "2001", "philosophically", "oriented", "introduction", "deep", "neural", "network", "see", "buckner", "2019", "41", "relation", "neural", "network", "classical", "computation", "neural", "network", "different", "feel", "classical", "ie", "turingstyle", "model", "yet", "classical", "computation", "neural", "network", "computation", "mutually", "exclusive", "one", "implement", "neural", "network", "classical", "model", "indeed", "every", "neural", "network", "ever", "physically", "constructed", "implemented", "digital", "computer", "one", "implement", "classical", "model", "neural", "network", "modern", "digital", "computer", "implement", "turingstyle", "computation", "network", "logic", "gate", "alternatively", "one", "implement", "turingstyle", "computation", "using", "analog", "recurrent", "neural", "network", "whose", "node", "take", "continuous", "activation", "value", "graf", "wayne", "danihelka", "2014", "internet", "resource", "siegelmann", "sontag", "1991", "siegelmann", "sontag", "1995", "although", "researcher", "suggest", "fundamental", "opposition", "classical", "computation", "neural", "network", "computation", "seems", "accurate", "identify", "two", "modeling", "tradition", "overlap", "certain", "case", "others", "cf", "boden", "1991", "piccinini", "2008b", "connection", "also", "worth", "noting", "classical", "computationalism", "connectionist", "computationalism", "common", "origin", "work", "mcculloch", "pitt", "philosopher", "often", "say", "classical", "computation", "involves", "rulegoverned", "symbol", "manipulation", "neural", "network", "computation", "nonsymbolic", "intuitive", "picture", "information", "neural", "network", "globally", "distributed", "across", "weight", "activation", "rather", "concentrated", "localized", "symbol", "however", "notion", "symbol", "requires", "explication", "often", "unclear", "theorist", "mean", "describing", "computation", "symbolic", "versus", "nonsymbolic", "mentioned", "1", "turing", "formalism", "place", "condition", "symbol", "regarding", "primitive", "symbol", "turing", "assumes", "finitely", "many", "inscribed", "readwrite", "memory", "location", "neural", "network", "also", "manipulate", "symbol", "satisfying", "two", "condition", "noted", "one", "implement", "turingstyle", "model", "neural", "network", "many", "discussion", "symbolicnonsymbolic", "dichotomy", "employ", "robust", "notion", "symbol", "robust", "approach", "symbol", "sort", "thing", "represents", "subject", "matter", "thus", "something", "symbol", "semantic", "representational", "property", "employ", "robust", "notion", "symbol", "symbolicnonsymbolic", "distinction", "crosscuts", "distinction", "turingstyle", "computation", "neural", "network", "computation", "turing", "machine", "need", "employ", "symbol", "robust", "sense", "far", "turing", "formalism", "go", "symbol", "manipulated", "turing", "computation", "need", "representational", "property", "chalmers", "2011", "conversely", "neural", "network", "manipulate", "symbol", "representational", "property", "indeed", "analog", "neural", "network", "manipulate", "symbol", "combinatorial", "syntax", "semantics", "horgan", "tienson", "1996", "marcus", "2001", "following", "steven", "pinker", "alan", "prince", "1988", "may", "distinguish", "eliminative", "connectionism", "implementationist", "connectionism", "eliminative", "connectionists", "advance", "connectionism", "rival", "classical", "computationalism", "argue", "turing", "formalism", "irrelevant", "psychological", "explanation", "often", "though", "always", "seek", "revive", "associationist", "tradition", "psychology", "tradition", "cctm", "forcefully", "challenged", "often", "though", "always", "attack", "mentalist", "nativist", "linguistics", "pioneered", "noam", "chomsky", "1965", "often", "though", "always", "manifest", "overt", "hostility", "notion", "mental", "representation", "defining", "feature", "eliminative", "connectionism", "us", "neural", "network", "replacement", "turingstyle", "model", "eliminative", "connectionists", "view", "mind", "computing", "system", "radically", "different", "kind", "turing", "machine", "author", "explicitly", "espouse", "eliminative", "connectionism", "churchland", "1989", "rumelhart", "mcclelland", "1986", "horgan", "tienson", "1996", "many", "others", "incline", "towards", "implementationist", "connectionism", "ecumenical", "position", "allows", "potentially", "valuable", "role", "turingstyle", "model", "neural", "network", "operating", "harmoniously", "different", "level", "description", "marcus", "2001", "smolensky", "1988", "turingstyle", "model", "higherlevel", "whereas", "neural", "network", "model", "lowerlevel", "neural", "network", "illuminates", "brain", "implement", "turingstyle", "model", "description", "term", "logic", "gate", "illuminates", "personal", "computer", "executes", "program", "highlevel", "programming", "language", "42", "argument", "connectionism", "connectionism", "excites", "many", "researcher", "analogy", "neural", "network", "brain", "node", "resemble", "neuron", "connection", "node", "resemble", "synapsis", "connectionist", "modeling", "therefore", "seems", "biologically", "plausible", "classical", "modeling", "connectionist", "model", "psychological", "phenomenon", "apparently", "capture", "idealized", "way", "interconnected", "neuron", "might", "generate", "phenomenon", "evaluating", "argument", "biological", "plausibility", "one", "recognize", "neural", "network", "vary", "widely", "closely", "match", "actual", "brain", "activity", "many", "network", "figure", "prominently", "connectionist", "writing", "biologically", "plausible", "bechtel", "abrahamsen", "2002", "341343", "berm\u00fadez", "2010", "237239", "clark", "2014", "8789", "harnish", "2002", "359362", "example", "real", "neuron", "much", "heterogeneous", "interchangeable", "node", "figure", "typical", "connectionist", "network", "real", "neuron", "emit", "discrete", "spike", "action", "potential", "output", "node", "figure", "many", "prominent", "neural", "network", "including", "best", "known", "deep", "neural", "network", "instead", "continuous", "output", "backpropagation", "algorithm", "requires", "weight", "node", "vary", "excitatory", "inhibitory", "yet", "actual", "synapsis", "vary", "crick", "asanuma", "1986", "moreover", "algorithm", "assumes", "target", "output", "supplied", "exogenously", "modeler", "know", "desired", "answer", "sense", "learning", "supervised", "little", "learning", "actual", "biological", "system", "involves", "anything", "resembling", "supervised", "training", "hand", "neural", "network", "biologically", "realistic", "buckner", "garson", "2019", "illing", "gerstner", "brea", "2019", "instance", "neural", "network", "replace", "backpropagation", "realistic", "learning", "algorithm", "reinforcement", "learning", "algorithm", "pozzi", "boht\u00e9", "roelfsema", "2019", "internet", "resource", "unsupervised", "learning", "algorithm", "krotov", "hopfield", "2019", "also", "neural", "network", "whose", "node", "output", "discrete", "spike", "roughly", "akin", "emitted", "real", "neuron", "brain", "maass", "1996", "buesing", "bill", "nessler", "maass", "2011", "even", "neural", "network", "biologically", "plausible", "may", "still", "biologically", "plausible", "classical", "model", "neural", "network", "certainly", "seem", "closer", "turingstyle", "model", "detail", "spirit", "neurophysiological", "description", "many", "cognitive", "scientist", "worry", "cctm", "reflects", "misguided", "attempt", "imposing", "architecture", "digital", "computer", "onto", "brain", "doubt", "brain", "implement", "anything", "resembling", "digital", "computation", "ie", "computation", "discrete", "configuration", "digit", "piccinini", "bahar", "2013", "others", "doubt", "brain", "display", "clean", "turingstyle", "separation", "central", "processor", "readwrite", "memory", "dayan", "2009", "neural", "network", "fare", "better", "score", "require", "computation", "discrete", "configuration", "digit", "postulate", "clean", "separation", "central", "processor", "readwrite", "memory", "classical", "computationalists", "typically", "reply", "premature", "draw", "firm", "conclusion", "based", "upon", "biological", "plausibility", "given", "little", "understand", "relation", "neural", "computational", "cognitive", "level", "description", "gallistel", "king", "2009", "marcus", "2001", "using", "measurement", "technique", "cell", "recording", "functional", "magnetic", "resonance", "imaging", "fmri", "drawing", "upon", "discipline", "diverse", "physic", "biology", "ai", "information", "theory", "statistic", "graph", "theory", "dynamical", "system", "theory", "neuroscientist", "accumulated", "substantial", "knowledge", "brain", "varying", "level", "granularity", "zednik", "2019", "know", "quite", "lot", "individual", "neuron", "neuron", "interact", "within", "neural", "population", "localization", "mental", "activity", "cortical", "region", "eg", "visual", "cortex", "interaction", "among", "cortical", "region", "yet", "still", "tremendous", "amount", "learn", "neural", "tissue", "accomplishes", "task", "surely", "accomplishes", "perception", "reasoning", "decisionmaking", "language", "acquisition", "given", "present", "state", "relative", "ignorance", "would", "rash", "insist", "brain", "implement", "anything", "resembling", "turing", "computation", "connectionists", "offer", "numerous", "argument", "employ", "connectionist", "model", "instead", "addition", "classical", "model", "see", "entry", "connectionism", "overview", "purpose", "entry", "mention", "two", "additional", "argument", "first", "argument", "emphasizes", "learning", "bechtel", "abrahamsen", "2002", "51", "vast", "range", "cognitive", "phenomenon", "involve", "learning", "experience", "many", "connectionist", "model", "explicitly", "designed", "model", "learning", "backpropagation", "algorithm", "modifies", "weight", "node", "contrast", "connectionists", "often", "complain", "good", "classical", "model", "learning", "classical", "computationalists", "respond", "citing", "perceived", "defect", "connectionist", "learning", "algorithm", "eg", "heavy", "reliance", "backpropagation", "upon", "supervised", "training", "classical", "computationalists", "also", "cite", "bayesian", "decision", "theory", "model", "learning", "probabilistic", "updating", "specifically", "classical", "computationalists", "cite", "achievement", "bayesian", "cognitive", "science", "us", "bayesian", "decision", "theory", "construct", "mathematical", "model", "mental", "activity", "2019", "past", "decade", "bayesian", "cognitive", "science", "accrued", "many", "explanatory", "success", "impressive", "track", "record", "suggests", "mental", "process", "bayesian", "approximately", "bayesian", "rescorla", "2020", "moreover", "advance", "mentioned", "2", "show", "classical", "computing", "system", "execute", "least", "approximately", "execute", "bayesian", "updating", "various", "realistic", "scenario", "development", "provide", "hope", "classical", "computation", "model", "many", "important", "case", "learning", "second", "argument", "emphasizes", "speed", "computation", "neuron", "much", "slower", "siliconbased", "component", "digital", "computer", "reason", "neuron", "could", "execute", "serial", "computation", "quickly", "enough", "match", "rapid", "human", "performance", "perception", "linguistic", "comprehension", "decisionmaking", "etc", "connectionists", "maintain", "viable", "solution", "replace", "serial", "computation", "massively", "parallel", "computational", "architectureprecisely", "neural", "network", "provide", "feldman", "ballard", "1982", "rumelhart", "1989", "however", "argument", "effective", "classical", "computationalists", "insist", "upon", "serial", "processing", "noted", "3", "turingstyle", "model", "involve", "parallel", "processing", "many", "classical", "computationalists", "happy", "allow", "massively", "parallel", "mental", "computation", "argument", "gain", "traction", "researcher", "said", "argument", "highlight", "important", "question", "computationalistwhether", "classical", "connectionist", "otherwisemust", "address", "brain", "built", "relatively", "slow", "neuron", "execute", "sophisticated", "computation", "quickly", "neither", "classical", "connectionist", "computationalists", "answered", "question", "satisfactorily", "gallistel", "king", "2009", "174", "265", "43", "systematicity", "productivity", "fodor", "pylyshyn", "1988", "offer", "widely", "discussed", "critique", "eliminativist", "connectionism", "argue", "systematicity", "productivity", "fail", "connectionist", "model", "except", "connectionist", "model", "implement", "classical", "model", "hence", "connectionism", "furnish", "viable", "alternative", "cctm", "best", "supply", "lowlevel", "description", "help", "bridge", "gap", "turingstyle", "computation", "neuroscientific", "description", "argument", "elicited", "numerous", "reply", "counterreplies", "argue", "neural", "network", "exhibit", "systematicity", "without", "implementing", "anything", "like", "classical", "computational", "architecture", "horgan", "tienson", "1996", "chalmers", "1990", "smolensky", "1991", "van", "gelder", "1990", "argue", "fodor", "pylyshyn", "vastly", "exaggerate", "systematicity", "johnson", "2004", "productivity", "rumelhart", "mcclelland", "1986", "especially", "nonhuman", "animal", "dennett", "1991", "issue", "many", "others", "raised", "fodor", "pylyshyn", "argument", "thoroughly", "investigated", "literature", "discussion", "see", "bechtel", "abrahamsen", "2002", "156199", "berm\u00fadez", "2005", "244278", "chalmers", "1993", "clark", "2014", "8486", "encyclopedia", "entry", "language", "thought", "hypothesis", "connectionism", "gallistel", "king", "2009", "advance", "related", "distinct", "productivity", "argument", "emphasize", "productivity", "mental", "computation", "opposed", "productivity", "mental", "state", "detailed", "empirical", "case", "study", "argue", "many", "nonhuman", "animal", "extract", "store", "retrieve", "detailed", "record", "surrounding", "environment", "example", "western", "scrub", "jay", "record", "cached", "food", "kind", "food", "cached", "location", "cached", "food", "whether", "depleted", "given", "cache", "clayton", "emery", "dickinson", "2006", "jay", "access", "record", "exploit", "diverse", "computation", "computing", "whether", "food", "item", "stored", "cache", "likely", "decayed", "computing", "route", "one", "location", "another", "number", "possible", "computation", "jay", "execute", "practical", "purpose", "infinite", "cctm", "explains", "productivity", "mental", "computation", "positing", "central", "processor", "store", "retrieves", "symbol", "addressable", "readwrite", "memory", "needed", "central", "processor", "retrieve", "arbitrary", "unpredicted", "combination", "symbol", "memory", "contrast", "gallistel", "king", "argue", "connectionism", "difficulty", "accommodating", "productivity", "mental", "computation", "although", "gallistel", "king", "carefully", "distinguish", "eliminativist", "implementationist", "connectionism", "may", "summarize", "argument", "follows", "eliminativist", "connectionism", "explain", "organism", "combine", "stored", "memory", "eg", "cache", "location", "computational", "purpose", "eg", "computing", "route", "one", "cache", "another", "virtual", "infinity", "possible", "combination", "might", "useful", "predicting", "advance", "piece", "information", "must", "combined", "future", "computation", "computationally", "tractable", "solution", "symbol", "storage", "readily", "accessible", "readwrite", "memory", "locationsa", "solution", "eliminativist", "connectionists", "reject", "implementationist", "connectionists", "postulate", "symbol", "storage", "readwrite", "memory", "implemented", "neural", "network", "however", "mechanism", "connectionists", "usually", "propose", "implementing", "memory", "plausible", "existing", "proposal", "mainly", "variant", "upon", "single", "idea", "recurrent", "neural", "network", "allows", "reverberating", "activity", "travel", "around", "loop", "elman", "1990", "many", "reason", "reverberatory", "loop", "model", "hopeless", "theory", "longterm", "memory", "example", "noise", "nervous", "system", "ensures", "signal", "would", "rapidly", "degrade", "minute", "implementationist", "connectionists", "thus", "far", "offered", "plausible", "model", "readwrite", "memory", "2", "gallistel", "king", "conclude", "cctm", "much", "better", "suited", "either", "eliminativist", "implementationist", "connectionism", "explain", "vast", "range", "cognitive", "phenomenon", "critic", "attack", "new", "productivity", "argument", "various", "angle", "focusing", "mainly", "empirical", "case", "study", "adduced", "gallistel", "king", "peter", "dayan", "2009", "john", "donahoe", "2010", "christopher", "mole", "2014", "argue", "biologically", "plausible", "neural", "network", "model", "accommodate", "least", "case", "study", "dayan", "donahoe", "argue", "empirically", "adequate", "neural", "network", "model", "dispense", "anything", "resembling", "readwrite", "memory", "mole", "argues", "certain", "case", "empirically", "adequate", "neural", "network", "model", "implement", "readwrite", "memory", "mechanism", "posited", "gallistel", "king", "debate", "fundamental", "issue", "seems", "poised", "continue", "well", "future", "44", "computational", "neuroscience", "computational", "neuroscience", "describes", "nervous", "system", "computational", "model", "although", "research", "program", "grounded", "mathematical", "modeling", "individual", "neuron", "distinctive", "focus", "computational", "neuroscience", "system", "interconnected", "neuron", "computational", "neuroscience", "usually", "model", "system", "neural", "network", "sense", "variant", "offshoot", "descendant", "connectionism", "however", "computational", "neuroscientist", "selfidentify", "connectionists", "several", "difference", "connectionism", "computational", "neuroscience", "neural", "network", "employed", "computational", "neuroscientist", "much", "biologically", "realistic", "employed", "connectionists", "computational", "neuroscience", "literature", "filled", "talk", "firing", "rate", "action", "potential", "tuning", "curve", "etc", "notion", "play", "best", "limited", "role", "connectionist", "research", "research", "canvassed", "rogers", "mcclelland", "2014", "computational", "neuroscience", "driven", "large", "measure", "knowledge", "brain", "assigns", "huge", "importance", "neurophysiological", "data", "eg", "cell", "recording", "connectionists", "place", "much", "le", "emphasis", "upon", "data", "research", "primarily", "driven", "behavioral", "data", "although", "recent", "connectionist", "writing", "cite", "neurophysiological", "data", "somewhat", "greater", "frequency", "computational", "neuroscientist", "usually", "regard", "individual", "node", "neural", "network", "idealized", "description", "actual", "neuron", "connectionists", "usually", "instead", "regard", "node", "neuronlike", "processing", "unit", "rogers", "mcclelland", "2014", "remaining", "neutral", "exactly", "unit", "map", "onto", "actual", "neurophysiological", "entity", "one", "might", "say", "computational", "neuroscience", "concerned", "mainly", "neural", "computation", "computation", "system", "neuron", "whereas", "connectionism", "concerned", "mainly", "abstract", "computational", "model", "inspired", "neural", "computation", "boundary", "connectionism", "computational", "neuroscience", "admittedly", "somewhat", "porous", "overview", "computational", "neuroscience", "see", "trappenberg", "2010", "miller", "2018", "serious", "philosophical", "engagement", "neuroscience", "date", "back", "least", "patricia", "churchland", "neurophilosophy", "1986", "computational", "neuroscience", "matured", "churchland", "became", "one", "main", "philosophical", "champion", "churchland", "koch", "sejnowski", "1990", "churchland", "sejnowski", "1992", "joined", "paul", "churchland", "1995", "2007", "others", "eliasmith", "2013", "eliasmith", "anderson", "2003", "piccinini", "bahar", "2013", "piccinini", "shagrir", "2014", "author", "hold", "theorizing", "mental", "computation", "begin", "brain", "turing", "machine", "inappropriate", "tool", "drawn", "logic", "computer", "science", "also", "hold", "neural", "network", "modeling", "strive", "greater", "biological", "realism", "connectionist", "model", "typically", "attain", "chris", "eliasmith", "2013", "develops", "neurocomputational", "viewpoint", "neural", "engineering", "framework", "supplement", "computational", "neuroscience", "tool", "drawn", "control", "theory", "brogan", "1990", "aim", "reverse", "engineer", "brain", "building", "largescale", "biologically", "plausible", "neural", "network", "model", "cognitive", "phenomenon", "computational", "neuroscience", "differs", "crucial", "respect", "cctm", "connectionism", "abandon", "multiply", "realizability", "computational", "neuroscientist", "cite", "specific", "neurophysiological", "property", "process", "model", "apply", "equally", "well", "say", "sufficiently", "different", "siliconbased", "creature", "thus", "computational", "neuroscience", "sacrifice", "key", "feature", "originally", "attracted", "philosopher", "ctm", "computational", "neuroscientist", "respond", "sacrifice", "worth", "resultant", "insight", "neurophysiological", "underpinnings", "many", "computationalists", "worry", "focusing", "much", "neural", "underpinnings", "risk", "losing", "sight", "cognitive", "forest", "neuronal", "tree", "neurophysiological", "detail", "important", "also", "need", "additional", "abstract", "level", "computational", "description", "prescinds", "detail", "gallistel", "king", "2009", "argue", "myopic", "fixation", "upon", "currently", "know", "brain", "led", "computational", "neuroscience", "shortchange", "core", "cognitive", "phenomenon", "navigation", "spatial", "temporal", "learning", "similarly", "edelman", "2014", "complains", "neural", "engineering", "framework", "substitute", "blizzard", "neurophysiological", "detail", "satisfying", "psychological", "explanation", "partly", "response", "worry", "researcher", "propose", "integrated", "cognitive", "computational", "neuroscience", "connects", "psychological", "theory", "neural", "implementation", "mechanism", "naselaris", "et", "al", "2018", "kriegeskorte", "douglas", "2018", "basic", "idea", "use", "neural", "network", "model", "illuminate", "mental", "process", "instantiated", "brain", "thereby", "grounding", "multiply", "realizable", "cognitive", "description", "neurophysiological", "good", "example", "recent", "work", "neural", "implementation", "bayesian", "inference", "eg", "pouget", "et", "al", "2013", "orhan", "2017", "aitchison", "lengyel", "2016", "researcher", "articulate", "multiply", "realizable", "bayesian", "model", "various", "mental", "process", "construct", "biologically", "plausible", "neural", "network", "execute", "approximately", "execute", "posited", "bayesian", "computation", "evaluate", "well", "neural", "network", "model", "fit", "neurophysiological", "data", "despite", "difference", "connectionism", "computational", "neuroscience", "two", "movement", "raise", "many", "similar", "issue", "particular", "dialectic", "44", "regarding", "systematicity", "productivity", "arises", "similar", "form", "5", "computation", "representation", "philosopher", "cognitive", "scientist", "use", "term", "representation", "diverse", "way", "within", "philosophy", "dominant", "usage", "tie", "representation", "intentionality", "ie", "aboutness", "mental", "state", "contemporary", "philosopher", "usually", "elucidate", "intentionality", "invoking", "representational", "content", "representational", "mental", "state", "content", "represents", "world", "certain", "way", "ask", "whether", "world", "indeed", "way", "thus", "representationally", "contentful", "mental", "state", "semantically", "evaluable", "respect", "property", "truth", "accuracy", "fulfillment", "illustrate", "belief", "sort", "thing", "true", "false", "belief", "emmanuel", "macron", "french", "true", "emmanuel", "macron", "french", "false", "perceptual", "state", "sort", "thing", "accurate", "inaccurate", "perceptual", "experience", "red", "sphere", "accurate", "red", "sphere", "desire", "sort", "thing", "fulfilled", "thwarted", "desire", "eat", "chocolate", "fulfilled", "eat", "chocolate", "thwarted", "eat", "chocolate", "belief", "truthconditions", "condition", "true", "perceptual", "state", "accuracyconditions", "condition", "accurate", "desire", "fulfillmentconditions", "condition", "fulfilled", "ordinary", "life", "frequently", "predict", "explain", "behavior", "invoking", "belief", "desire", "representationally", "contentful", "mental", "state", "identify", "state", "representational", "property", "say", "frank", "belief", "emmanuel", "macron", "french", "specify", "condition", "frank", "belief", "true", "namely", "emmanuel", "macron", "french", "say", "frank", "want", "eat", "chocolate", "specify", "condition", "frank", "desire", "fulfilled", "namely", "frank", "eats", "chocolate", "folk", "psychology", "assigns", "central", "role", "intentional", "description", "ie", "description", "identify", "mental", "state", "representational", "property", "whether", "scientific", "psychology", "likewise", "employ", "intentional", "description", "contested", "issue", "within", "contemporary", "philosophy", "mind", "intentional", "realism", "realism", "regarding", "representation", "minimum", "position", "hold", "representational", "property", "genuine", "aspect", "mentality", "usually", "also", "taken", "hold", "scientific", "psychology", "freely", "employ", "intentional", "description", "appropriate", "intentional", "realism", "popular", "position", "advocated", "tyler", "burge", "2010a", "jerry", "fodor", "1987", "christopher", "peacocke", "1992", "1994", "many", "others", "one", "prominent", "argument", "intentional", "realism", "cite", "cognitive", "science", "practice", "argument", "maintains", "intentional", "description", "figure", "centrally", "many", "core", "area", "cognitive", "science", "perceptual", "psychology", "linguistics", "example", "perceptual", "psychology", "describes", "perceptual", "activity", "transforms", "sensory", "input", "eg", "retinal", "stimulation", "representation", "distal", "environment", "eg", "perceptual", "representation", "distal", "shape", "size", "color", "science", "identifies", "perceptual", "state", "citing", "representational", "property", "eg", "representational", "relation", "specific", "distal", "shape", "size", "color", "assuming", "broadly", "scientific", "realist", "perspective", "explanatory", "achievement", "perceptual", "psychology", "support", "realist", "posture", "towards", "intentionality", "eliminativism", "strong", "form", "antirealism", "intentionality", "eliminativists", "dismiss", "intentional", "description", "vague", "contextsensitive", "interestrelative", "explanatorily", "superficial", "otherwise", "problematic", "recommend", "scientific", "psychology", "jettison", "representational", "content", "early", "example", "wv", "quine", "word", "object", "1960", "seek", "replace", "intentional", "psychology", "behaviorist", "stimulusresponse", "psychology", "paul", "churchland", "1981", "another", "prominent", "eliminativist", "want", "replace", "intentional", "psychology", "neuroscience", "intentional", "realism", "eliminativism", "lie", "various", "intermediate", "position", "daniel", "dennett", "1971", "1987", "acknowledges", "intentional", "discourse", "predictively", "useful", "question", "whether", "mental", "state", "really", "representational", "property", "according", "dennett", "theorist", "employ", "intentional", "description", "literally", "asserting", "mental", "state", "representational", "property", "merely", "adopting", "intentional", "stance", "donald", "davidson", "1980", "espouses", "neighboring", "interpretivist", "position", "emphasizes", "central", "role", "intentional", "ascription", "play", "within", "ordinary", "interpretive", "practice", "ie", "practice", "interpreting", "one", "another", "mental", "state", "speech", "act", "time", "question", "whether", "intentional", "psychology", "find", "place", "within", "mature", "scientific", "theorizing", "davidson", "dennett", "profess", "realism", "intentional", "mental", "state", "nevertheless", "philosopher", "customarily", "read", "intentional", "antirealists", "particular", "dennett", "frequently", "read", "kind", "instrumentalist", "intentionality", "one", "source", "customary", "reading", "involves", "indeterminacy", "interpretation", "suppose", "behavioral", "evidence", "allows", "two", "conflicting", "interpretation", "thinker", "mental", "state", "following", "quine", "davidson", "dennett", "say", "fact", "matter", "regarding", "interpretation", "correct", "diagnosis", "indicates", "le", "fully", "realist", "attitude", "towards", "intentionality", "debate", "intentionality", "figure", "prominently", "philosophical", "discussion", "ctm", "let", "u", "survey", "highlight", "51", "computation", "formal", "classical", "computationalists", "typically", "assume", "one", "might", "call", "formalsyntactic", "conception", "computation", "fsc", "intuitive", "idea", "computation", "manipulates", "symbol", "virtue", "formal", "syntactic", "property", "rather", "semantic", "property", "fsc", "stem", "innovation", "mathematical", "logic", "late", "19th", "early", "20th", "century", "especially", "seminal", "contribution", "george", "boole", "gottlob", "frege", "begriffsschrift", "18791967", "frege", "effected", "thoroughgoing", "formalization", "deductive", "reasoning", "formalize", "specify", "formal", "language", "whose", "component", "linguistic", "expression", "individuated", "nonsemantically", "eg", "geometric", "shape", "may", "intended", "interpretation", "mind", "element", "formal", "language", "purely", "syntactic", "entity", "discus", "without", "invoking", "semantic", "property", "reference", "truthconditions", "particular", "specify", "inference", "rule", "formal", "syntactic", "term", "choose", "inference", "rule", "wisely", "cohere", "intended", "interpretation", "carry", "true", "premise", "true", "conclusion", "formalization", "frege", "invested", "logic", "unprecedented", "rigor", "thereby", "laid", "groundwork", "numerous", "subsequent", "mathematical", "philosophical", "development", "formalization", "play", "significant", "foundational", "role", "within", "computer", "science", "program", "turingstyle", "computer", "manipulates", "linguistic", "expression", "drawn", "formal", "language", "program", "computer", "wisely", "syntactic", "machination", "cohere", "intended", "semantic", "interpretation", "example", "program", "computer", "carry", "true", "premise", "true", "conclusion", "update", "probability", "dictated", "bayesian", "decision", "theory", "fsc", "hold", "computation", "manipulates", "formal", "syntactic", "item", "without", "regard", "semantic", "property", "item", "may", "precise", "formulation", "fsc", "vary", "computation", "said", "sensitive", "syntax", "semantics", "access", "syntactic", "property", "operate", "virtue", "syntactic", "rather", "semantic", "property", "impacted", "semantic", "property", "mediated", "syntactic", "property", "always", "clear", "formulation", "mean", "whether", "equivalent", "one", "another", "intuitive", "picture", "syntactic", "property", "causalexplanatory", "primacy", "semantic", "property", "driving", "computation", "forward", "fodor", "article", "methodological", "solipsism", "considered", "research", "strategy", "cognitive", "psychology", "1980", "offer", "early", "statement", "fodor", "combine", "fsc", "cctmrtm", "analogizes", "mentalese", "formal", "language", "studied", "logician", "contains", "simple", "complex", "item", "individuated", "nonsemantically", "typical", "formal", "language", "contain", "simple", "complex", "expression", "individuated", "shape", "mentalese", "symbol", "semantic", "interpretation", "interpretation", "directly", "impact", "mental", "computation", "symbol", "formal", "property", "rather", "semantic", "property", "determine", "computation", "manipulates", "symbol", "sense", "mind", "syntactic", "engine", "virtually", "classical", "computationalists", "follow", "fodor", "endorsing", "fsc", "connectionists", "often", "deny", "neural", "network", "manipulate", "syntactically", "structured", "item", "reason", "many", "connectionists", "would", "hesitate", "accept", "fsc", "nevertheless", "connectionists", "endorse", "generalized", "formality", "thesis", "computation", "insensitive", "semantic", "property", "generalized", "formality", "thesis", "raise", "many", "philosophical", "issue", "raised", "fsc", "focus", "fsc", "received", "philosophical", "discussion", "fodor", "combine", "cctmrtmfsc", "intentional", "realism", "hold", "cctmrtmfsc", "vindicates", "folk", "psychology", "helping", "u", "convert", "common", "sense", "intentional", "discourse", "rigorous", "science", "motivates", "position", "famous", "abductive", "argument", "cctmrtmfsc", "1987", "1820", "strikingly", "mental", "activity", "track", "semantic", "property", "coherent", "way", "example", "deductive", "inference", "carry", "premise", "conclusion", "true", "premise", "true", "explain", "crucial", "aspect", "mental", "activity", "formalization", "show", "syntactic", "manipulation", "track", "semantic", "property", "computer", "science", "show", "build", "physical", "machine", "execute", "desired", "syntactic", "manipulation", "treat", "mind", "syntaxdriven", "machine", "explain", "mental", "activity", "track", "semantic", "property", "coherent", "way", "moreover", "explanation", "posit", "causal", "mechanism", "radically", "different", "posited", "within", "physical", "science", "thereby", "answer", "pivotal", "question", "rationality", "mechanically", "possible", "stephen", "stich", "1983", "hartry", "field", "2001", "combine", "cctmfsc", "eliminativism", "recommend", "cognitive", "science", "model", "mind", "formal", "syntactic", "term", "eschewing", "intentionality", "altogether", "grant", "mental", "state", "representational", "property", "ask", "explanatory", "value", "scientific", "psychology", "gain", "invoking", "property", "supplement", "formal", "syntactic", "description", "intentional", "description", "mind", "syntaxdriven", "machine", "representational", "content", "drop", "explanatorily", "irrelevant", "one", "point", "career", "putnam", "1983", "139154", "combined", "cctmfsc", "davidsontinged", "interpretivism", "cognitive", "science", "proceed", "along", "line", "suggested", "stich", "field", "delineating", "purely", "formal", "syntactic", "computational", "model", "formal", "syntactic", "modeling", "coexists", "ordinary", "interpretive", "practice", "ascribe", "intentional", "content", "one", "another", "mental", "state", "speech", "act", "interpretive", "practice", "governed", "holistic", "heuristic", "constraint", "stymie", "attempt", "converting", "intentional", "discourse", "rigorous", "science", "putnam", "field", "stich", "scientific", "action", "occurs", "formal", "syntactic", "level", "rather", "intentional", "level", "ctmfsc", "come", "attack", "various", "direction", "one", "criticism", "target", "causal", "relevance", "representational", "content", "block", "1990", "figdor", "2009", "kazez", "1995", "intuitively", "speaking", "content", "mental", "state", "causally", "relevant", "mental", "activity", "behavior", "example", "desire", "drink", "water", "rather", "orange", "juice", "cause", "walk", "sink", "rather", "refrigerator", "content", "desire", "drink", "water", "seems", "play", "important", "causal", "role", "shaping", "behavior", "according", "fodor", "1990", "137159", "cctmrtmfsc", "accommodates", "intuition", "formal", "syntactic", "activity", "implement", "intentional", "mental", "activity", "thereby", "ensuring", "intentional", "mental", "state", "causally", "interact", "accord", "content", "however", "clear", "analysis", "secures", "causal", "relevance", "content", "fsc", "say", "computation", "sensitive", "syntax", "semantics", "depending", "one", "gloss", "key", "term", "sensitive", "look", "like", "representational", "content", "causally", "irrelevant", "formal", "syntax", "causal", "work", "analogy", "illustrate", "worry", "car", "drive", "along", "road", "stable", "pattern", "involving", "car", "shadow", "nevertheless", "shadow", "position", "one", "time", "influence", "shadow", "position", "later", "time", "similarly", "cctmrtmfsc", "may", "explain", "mental", "activity", "instantiates", "stable", "pattern", "described", "intentional", "term", "enough", "ensure", "causal", "relevance", "content", "mind", "syntaxdriven", "machine", "causal", "efficacy", "seems", "reside", "syntactic", "rather", "semantic", "level", "semantics", "along", "ride", "apparently", "ctmfsc", "encourages", "conclusion", "representational", "property", "causally", "inert", "conclusion", "may", "trouble", "eliminativists", "intentional", "realist", "usually", "want", "avoid", "second", "criticism", "dismisses", "formalsyntactic", "picture", "speculation", "ungrounded", "scientific", "practice", "tyler", "burge", "2010a", "b", "2013", "479480", "contends", "formal", "syntactic", "description", "mental", "activity", "play", "significant", "role", "within", "large", "area", "cognitive", "science", "including", "study", "theoretical", "reasoning", "practical", "reasoning", "perception", "case", "burge", "argues", "science", "employ", "intentional", "description", "rather", "formal", "syntactic", "description", "example", "perceptual", "psychology", "individuates", "perceptual", "state", "formal", "syntactic", "property", "representational", "relation", "distal", "shape", "size", "color", "understand", "criticism", "must", "distinguish", "formal", "syntactic", "description", "neurophysiological", "description", "everyone", "agrees", "complete", "scientific", "psychology", "assign", "prime", "importance", "neurophysiological", "description", "however", "neurophysiological", "description", "distinct", "formal", "syntactic", "description", "formal", "syntactic", "description", "supposed", "multiply", "realizable", "neurophysiological", "issue", "whether", "scientific", "psychology", "supplement", "intentional", "description", "neurophysiological", "description", "multiply", "realizable", "nonintentional", "formal", "syntactic", "description", "52", "externalism", "mental", "content", "putnam", "landmark", "article", "meaning", "meaning", "1975", "215271", "introduced", "twin", "earth", "thought", "experiment", "postulate", "world", "like", "except", "h2o", "replaced", "qualitatively", "similar", "substance", "xyz", "different", "chemical", "composition", "putnam", "argues", "xyz", "water", "speaker", "twin", "earth", "use", "word", "water", "refer", "xyz", "rather", "water", "burge", "1982", "extends", "conclusion", "linguistic", "reference", "mental", "content", "argues", "twin", "earthling", "instantiate", "mental", "state", "different", "content", "example", "oscar", "earth", "think", "water", "thirstquenching", "duplicate", "twin", "earth", "think", "thought", "different", "content", "might", "gloss", "twater", "thirstquenching", "burge", "concludes", "mental", "content", "supervene", "upon", "internal", "neurophysiology", "mental", "content", "individuated", "partly", "factor", "outside", "thinker", "skin", "including", "causal", "relation", "environment", "position", "externalism", "mental", "content", "formal", "syntactic", "property", "mental", "state", "widely", "taken", "supervene", "upon", "internal", "neurophysiology", "example", "oscar", "twin", "oscar", "instantiate", "formal", "syntactic", "manipulation", "assuming", "content", "externalism", "follows", "huge", "gulf", "ordinary", "intentional", "description", "formal", "syntactic", "description", "content", "externalism", "raise", "serious", "question", "explanatory", "utility", "representational", "content", "scientific", "psychology", "argument", "causation", "fodor", "1987", "1991", "mental", "content", "exert", "causal", "influence", "except", "manifested", "within", "internal", "neurophysiology", "psychological", "action", "distance", "difference", "physical", "environment", "impact", "behavior", "inducing", "difference", "local", "brain", "state", "causally", "relevant", "factor", "supervene", "upon", "internal", "neurophysiology", "externally", "individuated", "content", "causally", "irrelevant", "argument", "explanation", "stich", "1983", "rigorous", "scientific", "explanation", "take", "account", "factor", "outside", "subject", "skin", "folk", "psychology", "may", "taxonomize", "mental", "state", "relation", "external", "environment", "scientific", "psychology", "taxonomize", "mental", "state", "entirely", "factor", "supervene", "upon", "internal", "neurophysiology", "treat", "oscar", "twin", "oscar", "psychological", "duplicate", "3", "author", "pursue", "two", "argument", "conjunction", "one", "another", "argument", "reach", "conclusion", "externally", "individuated", "mental", "content", "find", "legitimate", "place", "within", "causal", "explanation", "provided", "scientific", "psychology", "stich", "1983", "argues", "along", "line", "motivate", "formalsyntactic", "eliminativism", "many", "philosopher", "respond", "worry", "promoting", "content", "internalism", "whereas", "content", "externalists", "favor", "wide", "content", "content", "supervene", "upon", "internal", "neurophysiology", "content", "internalists", "favor", "narrow", "content", "content", "supervene", "narrow", "content", "remains", "mental", "content", "one", "factor", "external", "element", "one", "point", "career", "fodor", "1981", "1987", "pursued", "internalism", "strategy", "integrating", "intentional", "psychology", "cctmrtmfsc", "conceding", "wide", "content", "figure", "scientific", "psychology", "maintained", "narrow", "content", "play", "central", "explanatory", "role", "radical", "internalists", "insist", "content", "narrow", "typical", "analysis", "hold", "oscar", "thinking", "water", "general", "category", "substance", "subsumes", "xyz", "oscar", "twin", "oscar", "entertain", "mental", "state", "content", "tim", "crane", "1991", "gabriel", "segal", "2000", "endorse", "analysis", "hold", "folk", "psychology", "always", "individuates", "propositional", "attitude", "narrowly", "le", "radical", "internalism", "recommends", "recognize", "narrow", "content", "addition", "wide", "content", "folk", "psychology", "may", "sometimes", "individuate", "propositional", "attitude", "widely", "also", "delineate", "viable", "notion", "narrow", "content", "advance", "important", "philosophical", "scientific", "goal", "internalists", "proposed", "various", "candidate", "notion", "narrow", "content", "block", "1986", "chalmers", "2002", "cummins", "1989", "fodor", "1987", "lewis", "1994", "loar", "1988", "mendola", "2008", "see", "entry", "narrow", "mental", "content", "overview", "prominent", "candidate", "externalists", "complain", "existing", "theory", "narrow", "content", "sketchy", "implausible", "useless", "psychological", "explanation", "otherwise", "objectionable", "burge", "2007", "sawyer", "2000", "stalnaker", "1999", "externalists", "also", "question", "internalist", "argument", "scientific", "psychology", "requires", "narrow", "content", "argument", "causation", "externalists", "insist", "wide", "content", "causally", "relevant", "detail", "vary", "among", "externalists", "discussion", "often", "becomes", "intertwined", "complex", "issue", "surrounding", "causation", "counterfactuals", "metaphysics", "mind", "see", "entry", "mental", "causation", "introductory", "overview", "see", "burge", "2007", "rescorla", "2014a", "yablo", "1997", "2003", "representative", "externalist", "discussion", "argument", "explanation", "externalists", "claim", "psychological", "explanation", "legitimately", "taxonomize", "mental", "state", "factor", "outstrip", "internal", "neurophysiology", "peacocke", "1993", "shea", "2018", "burge", "observes", "nonpsychological", "science", "often", "individuate", "explanatory", "kind", "relationally", "ie", "relation", "external", "factor", "example", "whether", "entity", "count", "heart", "depends", "roughly", "upon", "whether", "biological", "function", "normal", "environment", "pump", "blood", "physiology", "individuates", "organ", "kind", "relationally", "psychology", "likewise", "individuate", "mental", "state", "relationally", "notable", "exchange", "issue", "see", "burge", "1986", "1989", "1995", "fodor", "1987", "1991", "externalists", "doubt", "good", "reason", "replace", "supplement", "wide", "content", "narrow", "content", "dismiss", "search", "narrow", "content", "wild", "goose", "chase", "burge", "2007", "2010a", "defends", "externalism", "analyzing", "current", "cognitive", "science", "argues", "many", "branch", "scientific", "psychology", "especially", "perceptual", "psychology", "individuate", "mental", "content", "causal", "relation", "external", "environment", "concludes", "scientific", "practice", "embodies", "externalist", "perspective", "contrast", "maintains", "narrow", "content", "philosophical", "fantasy", "ungrounded", "current", "science", "suppose", "abandon", "search", "narrow", "content", "prospect", "combining", "ctmfsc", "externalist", "intentional", "psychology", "promising", "option", "emphasizes", "level", "explanation", "say", "intentional", "psychology", "occupies", "one", "level", "explanation", "formalsyntactic", "computational", "psychology", "occupies", "different", "level", "fodor", "advocate", "approach", "later", "work", "1994", "2008", "come", "reject", "narrow", "content", "otiose", "suggests", "formal", "syntactic", "mechanism", "implement", "externalist", "psychological", "law", "mental", "computation", "manipulates", "mentalese", "expression", "accord", "formal", "syntactic", "property", "formal", "syntactic", "manipulation", "ensure", "mental", "activity", "instantiates", "appropriate", "lawlike", "pattern", "defined", "wide", "content", "light", "internalismexternalism", "distinction", "let", "u", "revisit", "eliminativist", "challenge", "raised", "51", "explanatory", "value", "intentional", "description", "add", "formalsyntactic", "description", "internalists", "respond", "suitable", "formal", "syntactic", "manipulation", "determine", "maybe", "even", "constitute", "narrow", "content", "internalist", "intentional", "description", "already", "implicit", "suitable", "formal", "syntactic", "description", "cf", "field", "2001", "75", "perhaps", "response", "vindicates", "intentional", "realism", "perhaps", "crucially", "though", "response", "available", "content", "externalists", "externalist", "intentional", "description", "implicit", "formal", "syntactic", "description", "one", "hold", "formal", "syntax", "fixed", "varying", "wide", "content", "thus", "content", "externalists", "espouse", "ctmfsc", "must", "say", "gain", "supplementing", "formalsyntactic", "explanation", "intentional", "explanation", "accept", "mental", "computation", "sensitive", "syntax", "semantics", "far", "clear", "useful", "explanatory", "work", "remains", "wide", "content", "fodor", "address", "challenge", "various", "point", "offering", "systematic", "treatment", "elm", "expert", "1994", "see", "arjo", "1996", "aydede", "1998", "aydede", "robbins", "2001", "wakefield", "2002", "perry", "1998", "wakefield", "2002", "criticism", "see", "rupert", "2008", "schneider", "2005", "position", "close", "fodor", "dretske", "1993", "shea", "2018", "pp", "197226", "pursue", "alternative", "strategy", "vindicating", "explanatory", "relevance", "wide", "content", "53", "contentinvolving", "computation", "perceived", "gulf", "computational", "description", "intentional", "description", "animates", "many", "writing", "ctm", "philosopher", "try", "bridge", "gulf", "using", "computational", "description", "individuate", "computational", "state", "representational", "term", "description", "contentinvolving", "use", "christopher", "peacocke", "1994", "terminology", "contentinvolving", "approach", "rigid", "demarcation", "computational", "intentional", "description", "particular", "certain", "scientifically", "valuable", "description", "mental", "activity", "computational", "intentional", "call", "position", "contentinvolving", "computationalism", "contentinvolving", "computationalists", "need", "say", "computational", "description", "intentional", "illustrate", "suppose", "describe", "simple", "turing", "machine", "manipulates", "symbol", "individuated", "geometric", "shape", "resulting", "computational", "description", "plausibly", "contentinvolving", "accordingly", "contentinvolving", "computationalists", "usually", "advance", "contentinvolving", "computation", "general", "theory", "computation", "claim", "important", "computational", "description", "contentinvolving", "one", "develop", "contentinvolving", "computationalism", "internalist", "externalist", "direction", "internalist", "contentinvolving", "computationalists", "hold", "computational", "description", "identify", "mental", "state", "partly", "narrow", "content", "murat", "aydede", "2005", "recommends", "position", "along", "line", "externalist", "contentinvolving", "computationalism", "hold", "certain", "computational", "description", "identify", "mental", "state", "partly", "wide", "content", "tyler", "burge", "2010a", "95101", "christopher", "peacocke", "1994", "1999", "michael", "rescorla", "2012", "mark", "sprevak", "2010", "espouse", "position", "oron", "shagrir", "2001", "forthcoming", "advocate", "contentinvolving", "computationalism", "neutral", "internalism", "externalism", "externalist", "contentinvolving", "computationalists", "typically", "cite", "cognitive", "science", "practice", "motivating", "factor", "example", "perceptual", "psychology", "describes", "perceptual", "system", "computing", "estimate", "object", "size", "retinal", "stimulation", "estimate", "object", "depth", "perceptual", "estimate", "identified", "representationally", "representation", "specific", "distal", "size", "depth", "quite", "plausibly", "representational", "relation", "specific", "distal", "size", "depth", "supervene", "internal", "neurophysiology", "quite", "plausibly", "perceptual", "psychology", "typeidentifies", "perceptual", "computation", "wide", "content", "externalist", "contentinvolving", "computationalism", "seems", "harmonize", "well", "current", "cognitive", "science", "major", "challenge", "facing", "contentinvolving", "computationalism", "concern", "interface", "standard", "computationalism", "formalism", "turing", "machine", "exactly", "contentinvolving", "description", "relate", "computational", "model", "found", "logic", "computer", "science", "philosopher", "usually", "assume", "model", "offer", "nonintentional", "description", "would", "major", "perhaps", "decisive", "blow", "contentinvolving", "computationalism", "arguably", "though", "many", "familiar", "computational", "formalism", "allow", "contentinvolving", "rather", "formal", "syntactic", "construal", "illustrate", "consider", "turing", "machine", "one", "individuate", "symbol", "comprising", "turing", "machine", "alphabet", "nonsemantically", "factor", "akin", "geometric", "shape", "turing", "formalism", "require", "nonsemantic", "individuative", "scheme", "arguably", "formalism", "allows", "u", "individuate", "symbol", "partly", "content", "course", "machine", "table", "turing", "machine", "explicitly", "cite", "semantic", "property", "symbol", "eg", "denotation", "truthconditions", "nevertheless", "machine", "table", "encode", "mechanical", "rule", "describe", "manipulate", "symbol", "symbol", "typeidentified", "contentinvolving", "term", "way", "machine", "table", "dictate", "transition", "among", "contentinvolving", "state", "without", "explicitly", "mentioning", "semantic", "property", "aydede", "2005", "suggests", "internalist", "version", "view", "symbol", "typeidentified", "narrow", "content", "4", "rescorla", "2017a", "develops", "view", "externalist", "direction", "symbol", "typeidentified", "wide", "content", "argues", "turingstyle", "model", "describe", "computational", "operation", "externalistically", "individuated", "mentalese", "symbol", "5", "principle", "one", "might", "embrace", "externalist", "contentinvolving", "computational", "description", "formal", "syntactic", "description", "one", "might", "say", "two", "kind", "description", "occupy", "distinct", "level", "explanation", "peacocke", "suggests", "view", "contentinvolving", "computationalists", "regard", "formal", "syntactic", "description", "mind", "skeptically", "example", "burge", "question", "explanatory", "value", "formal", "syntactic", "description", "contributes", "certain", "area", "scientific", "psychology", "perceptual", "psychology", "viewpoint", "eliminativist", "challenge", "posed", "51", "matter", "backwards", "assume", "formal", "syntactic", "description", "explanatorily", "valuable", "ask", "value", "intentional", "description", "contribute", "instead", "embrace", "externalist", "intentional", "description", "offered", "current", "cognitive", "science", "ask", "value", "formal", "syntactic", "description", "contributes", "proponent", "formal", "syntactic", "description", "respond", "citing", "implementation", "mechanism", "externalist", "description", "mental", "activity", "presupposes", "suitable", "causalhistorical", "relation", "mind", "external", "physical", "environment", "place", "surely", "want", "local", "description", "ignores", "external", "causalhistorical", "relation", "description", "reveals", "underlying", "causal", "mechanism", "fodor", "1987", "1994", "argues", "way", "motivate", "formal", "syntactic", "picture", "possible", "externalist", "response", "argument", "implementation", "mechanism", "see", "burge", "2010b", "rescorla", "2017b", "shea", "2013", "sprevak", "2010", "debate", "argument", "generally", "relation", "computation", "representation", "seems", "likely", "continue", "indefinite", "future", "6", "alternative", "conception", "computation", "literature", "offer", "several", "alternative", "conception", "usually", "advanced", "foundation", "ctm", "many", "case", "conception", "overlap", "one", "another", "conception", "considered", "61", "informationprocessing", "common", "cognitive", "scientist", "describe", "computation", "informationprocessing", "le", "common", "proponent", "clarify", "mean", "information", "processing", "lacking", "clarification", "description", "little", "empty", "slogan", "claude", "shannon", "introduced", "scientifically", "important", "notion", "information", "1948", "article", "mathematical", "theory", "communication", "intuitive", "idea", "information", "measure", "reduction", "uncertainty", "reduced", "uncertainty", "manifest", "altered", "probability", "distribution", "possible", "state", "shannon", "codified", "idea", "within", "rigorous", "mathematical", "framework", "laying", "foundation", "information", "theory", "cover", "thomas", "2006", "shannon", "information", "fundamental", "modern", "engineering", "find", "fruitful", "application", "within", "cognitive", "science", "especially", "cognitive", "neuroscience", "support", "convincing", "analysis", "computation", "informationprocessing", "consider", "oldfashioned", "tape", "machine", "record", "message", "received", "wireless", "radio", "using", "shannon", "framework", "one", "measure", "much", "information", "carried", "recorded", "message", "sense", "tape", "machine", "process", "shannon", "information", "whenever", "replay", "recorded", "message", "still", "machine", "seem", "implement", "nontrivial", "computational", "model", "6", "certainly", "neither", "turing", "machine", "formalism", "neural", "network", "formalism", "offer", "much", "insight", "machine", "operation", "arguably", "system", "process", "shannon", "information", "without", "executing", "computation", "interesting", "sense", "confronted", "example", "one", "might", "try", "isolate", "demanding", "notion", "processing", "tape", "machine", "process", "shannon", "information", "alternatively", "one", "might", "insist", "tape", "machine", "executes", "nontrivial", "computation", "piccinini", "scarantino", "2010", "advance", "highly", "general", "notion", "computationwhich", "dub", "generic", "computationwith", "consequence", "second", "prominent", "notion", "information", "derives", "paul", "grice", "1989", "influential", "discussion", "natural", "meaning", "natural", "meaning", "involves", "reliable", "counterfactualsupporting", "correlation", "example", "tree", "ring", "correlate", "age", "tree", "pox", "correlate", "chickenpox", "colloquially", "describe", "tree", "ring", "carrying", "information", "tree", "age", "pox", "carrying", "information", "chickenpox", "description", "suggest", "conception", "tie", "information", "reliable", "counterfactualsupporting", "correlation", "fred", "dretske", "1981", "develops", "conception", "systematic", "theory", "various", "subsequent", "philosopher", "dretskestyle", "information", "subserve", "plausible", "analysis", "computation", "informationprocessing", "consider", "oldfashioned", "bimetallic", "strip", "thermostat", "two", "metal", "joined", "together", "strip", "differential", "expansion", "metal", "cause", "strip", "bend", "thereby", "activating", "deactivating", "heating", "unit", "strip", "state", "reliably", "correlate", "current", "ambient", "temperature", "thermostat", "process", "informationbearing", "state", "activating", "deactivating", "heater", "yet", "thermostat", "seem", "implement", "nontrivial", "computational", "model", "one", "would", "ordinarily", "regard", "thermostat", "computing", "arguably", "system", "process", "dretskestyle", "information", "without", "executing", "computation", "interesting", "sense", "course", "one", "might", "try", "handle", "example", "maneuver", "parallel", "previous", "paragraph", "third", "prominent", "notion", "information", "semantic", "information", "ie", "representational", "content", "7", "philosopher", "hold", "physical", "system", "computes", "system", "state", "representational", "property", "dietrich", "1989", "fodor", "1998", "10", "ladyman", "2009", "shagrir", "2006", "sprevak", "2010", "sense", "informationprocessing", "necessary", "computation", "fodor", "memorably", "put", "computation", "without", "representation", "1975", "34", "however", "position", "debatable", "chalmers", "2011", "piccinini", "2008a", "contend", "turing", "machine", "might", "execute", "computation", "even", "though", "symbol", "manipulated", "machine", "semantic", "interpretation", "machine", "computation", "purely", "syntactic", "nature", "lacking", "anything", "like", "semantic", "property", "view", "representational", "content", "necessary", "physical", "system", "count", "computational", "remains", "unclear", "whether", "slogan", "computation", "informationprocessing", "provides", "much", "insight", "nevertheless", "slogan", "seems", "unlikely", "disappear", "literature", "anytime", "soon", "discussion", "possible", "connection", "computation", "information", "see", "gallistel", "king", "2009", "126", "lizier", "flecker", "williams", "2013", "milkowski", "2013", "piccinini", "scarantino", "2010", "sprevak", "forthcoming", "62", "function", "evaluation", "widely", "cited", "passage", "perceptual", "psychologist", "david", "marr", "1982", "distinguishes", "three", "level", "one", "describe", "informationprocessing", "device", "computational", "theory", "device", "characterized", "mapping", "one", "kind", "information", "another", "abstract", "property", "mapping", "defined", "precisely", "appropriateness", "adequacy", "task", "hand", "demonstrated", "p", "24", "representation", "algorithm", "choice", "representation", "input", "output", "algorithm", "used", "transform", "one", "pp", "2425", "hardware", "implementation", "detail", "algorithm", "representation", "realized", "physically", "p", "25", "marr", "three", "level", "attracted", "intense", "philosophical", "scrutiny", "purpose", "key", "point", "marr", "computational", "level", "describes", "mapping", "input", "output", "without", "describing", "intermediate", "step", "marr", "illustrates", "approach", "providing", "computational", "level", "theory", "various", "perceptual", "process", "edge", "detection", "marr", "discussion", "suggests", "functional", "conception", "computation", "computation", "matter", "transforming", "input", "appropriate", "output", "france", "egan", "elaborates", "functional", "conception", "series", "article", "1991", "1992", "1999", "2003", "2010", "2014", "2019", "like", "marr", "treat", "computational", "description", "description", "inputoutput", "relation", "also", "claim", "computational", "model", "characterize", "purely", "mathematical", "function", "mapping", "mathematical", "input", "mathematical", "output", "illustrates", "considering", "visual", "mechanism", "called", "visua", "computes", "object", "depth", "retinal", "disparity", "imago", "neurophysiological", "duplicate", "twin", "visua", "embedded", "differently", "physical", "environment", "represent", "depth", "visua", "twin", "visua", "instantiate", "perceptual", "state", "different", "representational", "property", "nevertheless", "egan", "say", "vision", "science", "treat", "visua", "twin", "visua", "computational", "duplicate", "visua", "twin", "visua", "compute", "mathematical", "function", "even", "though", "computation", "different", "representational", "import", "two", "case", "egan", "concludes", "computational", "modeling", "mind", "yield", "abstract", "mathematical", "description", "consistent", "many", "alternative", "possible", "representational", "description", "intentional", "attribution", "heuristic", "gloss", "upon", "underlying", "computational", "description", "chalmers", "2012", "argues", "functional", "conception", "neglect", "important", "feature", "computation", "note", "computational", "model", "usually", "describe", "inputoutput", "relation", "describe", "intermediate", "step", "input", "transformed", "output", "intermediate", "step", "marr", "consigns", "algorithmic", "level", "figure", "prominently", "computational", "model", "offered", "logician", "computer", "scientist", "restricting", "term", "computation", "inputoutput", "description", "capture", "standard", "computational", "practice", "additional", "worry", "face", "functional", "theory", "egan", "exclusively", "emphasize", "mathematical", "input", "output", "critic", "complain", "egan", "mistakenly", "elevates", "mathematical", "function", "expense", "intentional", "explanation", "routinely", "offered", "cognitive", "science", "burge", "2005", "rescorla", "2015", "silverberg", "2006", "sprevak", "2010", "illustrate", "suppose", "perceptual", "psychology", "describes", "perceptual", "system", "estimating", "object", "depth", "5", "meter", "perceptual", "depthestimate", "representational", "content", "accurate", "object", "depth", "5", "meter", "cite", "number", "5", "identify", "depthestimate", "choice", "number", "depends", "upon", "arbitrary", "choice", "measurement", "unit", "critic", "contend", "content", "depthestimate", "arbitrarily", "chosen", "number", "theorist", "specify", "content", "matter", "psychological", "explanation", "egan", "theory", "place", "number", "rather", "content", "explanatory", "center", "stage", "according", "egan", "computational", "explanation", "describe", "visual", "system", "computing", "particular", "mathematical", "function", "carry", "particular", "mathematical", "input", "particular", "mathematical", "output", "particular", "mathematical", "input", "output", "depend", "upon", "arbitrary", "choice", "measurement", "unit", "arguably", "lack", "explanatory", "significance", "egan", "assigns", "distinguish", "functional", "approach", "pursued", "marr", "egan", "functional", "programming", "paradigm", "computer", "science", "functional", "programming", "paradigm", "model", "evaluation", "complex", "function", "successive", "evaluation", "simpler", "function", "take", "simple", "example", "one", "might", "evaluate", "f", "x", "x", "2", "y", "first", "evaluating", "squaring", "function", "evaluating", "addition", "function", "functional", "programming", "differs", "computational", "level", "description", "emphasized", "marr", "specifies", "intermediate", "computational", "stage", "functional", "programming", "paradigm", "stretch", "back", "alonzo", "church", "1936", "lambda", "calculus", "continuing", "programming", "language", "pcf", "lisp", "play", "important", "role", "ai", "theoretical", "computer", "science", "author", "suggest", "offer", "special", "insight", "mental", "computation", "klein", "2012", "piantadosi", "tenenbaum", "goodman", "2012", "however", "many", "computational", "formalism", "conform", "functional", "paradigm", "turing", "machine", "imperative", "programming", "language", "c", "logic", "programming", "language", "prolog", "even", "though", "functional", "paradigm", "describes", "numerous", "important", "computation", "possibly", "including", "mental", "computation", "plausibly", "capture", "computation", "general", "63", "structuralism", "many", "philosophical", "discussion", "embody", "structuralist", "conception", "computation", "computational", "model", "describes", "abstract", "causal", "structure", "without", "taking", "account", "particular", "physical", "state", "instantiate", "structure", "conception", "trace", "back", "least", "putnam", "original", "treatment", "1967", "chalmers", "1995", "1996a", "2011", "2012", "develops", "detail", "introduces", "combinatorialstate", "automaton", "csa", "formalism", "subsumes", "familiar", "model", "computation", "including", "turing", "machine", "neural", "network", "csa", "provides", "abstract", "description", "physical", "system", "causal", "topology", "pattern", "causal", "interaction", "among", "system", "part", "independent", "nature", "part", "causal", "mechanism", "interact", "computational", "description", "specifies", "causal", "topology", "chalmers", "deploys", "structuralism", "delineate", "general", "version", "ctm", "assumes", "functionalist", "view", "psychological", "state", "individuated", "role", "pattern", "causal", "organization", "psychological", "description", "specifies", "causal", "role", "abstracted", "away", "physical", "state", "realize", "role", "psychological", "property", "organizationally", "invariant", "supervene", "upon", "causal", "topology", "since", "computational", "description", "characterizes", "causal", "topology", "satisfying", "suitable", "computational", "description", "suffices", "instantiating", "appropriate", "mental", "property", "also", "follows", "psychological", "description", "specie", "computational", "description", "computational", "description", "play", "central", "role", "within", "psychological", "explanation", "thus", "structuralist", "computation", "provides", "solid", "foundation", "cognitive", "science", "mentality", "grounded", "causal", "pattern", "precisely", "computational", "model", "articulate", "structuralism", "come", "packaged", "attractive", "account", "implementation", "relation", "abstract", "computational", "model", "physical", "system", "condition", "physical", "system", "implement", "computational", "model", "structuralists", "say", "physical", "system", "implement", "model", "case", "model", "causal", "structure", "isomorphic", "model", "formal", "structure", "computational", "model", "describes", "physical", "system", "articulating", "formal", "structure", "mirror", "relevant", "causal", "topology", "chalmers", "elaborates", "intuitive", "idea", "providing", "detailed", "necessary", "sufficient", "condition", "physical", "realization", "csas", "alternative", "conception", "computation", "provide", "substantive", "account", "implementation", "relation", "may", "instructively", "compare", "structuralist", "computationalism", "theory", "discussed", "machine", "functionalism", "structuralist", "computationalism", "embrace", "core", "idea", "behind", "machine", "functionalism", "mental", "state", "functional", "state", "describable", "suitable", "computational", "formalism", "putnam", "advance", "ctm", "empirical", "hypothesis", "defends", "functionalism", "basis", "contrast", "chalmers", "follows", "david", "lewis", "1972", "grounding", "functionalism", "conceptual", "analysis", "mentalistic", "discourse", "whereas", "putnam", "defends", "functionalism", "defending", "computationalism", "chalmers", "defends", "computationalism", "assuming", "functionalism", "classical", "computationalism", "connectionism", "computational", "neuroscience", "structuralist", "computationalism", "emphasizes", "organizationally", "invariant", "description", "multiply", "realizable", "respect", "diverges", "computational", "neuroscience", "structuralism", "compatible", "classical", "connectionist", "computationalism", "differs", "spirit", "view", "classicist", "connectionists", "present", "rival", "position", "bold", "substantive", "hypothesis", "chalmers", "advance", "structuralist", "computationalism", "relatively", "minimalist", "position", "unlikely", "disconfirmed", "intentional", "realism", "eliminativism", "structuralist", "computationalism", "compatible", "position", "csa", "description", "explicitly", "mention", "semantic", "property", "reference", "truthconditions", "representational", "content", "structuralist", "computationalists", "need", "assign", "representational", "content", "important", "role", "within", "scientific", "psychology", "hand", "structuralist", "computationalism", "preclude", "important", "role", "representational", "content", "formalsyntactic", "conception", "computation", "wide", "content", "depends", "causalhistorical", "relation", "external", "environment", "relation", "outstrip", "causal", "topology", "thus", "csa", "description", "leaf", "wide", "content", "underdetermined", "narrow", "content", "presumably", "supervenes", "upon", "causal", "topology", "csa", "description", "explicitly", "mention", "narrow", "content", "overall", "structuralist", "computationalism", "prioritizes", "level", "formal", "nonsemantic", "computational", "description", "respect", "resembles", "fsc", "hand", "structuralist", "computationalists", "need", "say", "computation", "insensitive", "semantic", "property", "need", "endorse", "aspect", "fsc", "although", "structuralist", "computationalism", "distinct", "ctmfsc", "raise", "similar", "issue", "example", "rescorla", "2012", "denies", "causal", "topology", "play", "central", "explanatory", "role", "within", "cognitive", "science", "structuralist", "computationalism", "dictate", "suggests", "externalist", "intentional", "description", "rather", "organizationally", "invariant", "description", "enjoys", "explanatory", "primacy", "coming", "different", "direction", "computational", "neuroscientist", "recommend", "forego", "organizationally", "invariant", "description", "instead", "employ", "neurally", "specific", "computational", "model", "response", "objection", "chalmers", "2012", "argues", "organizationally", "invariant", "computational", "description", "yield", "explanatory", "benefit", "neither", "intentional", "description", "neurophysiological", "description", "replicate", "reveals", "underlying", "mechanism", "cognition", "unlike", "intentional", "description", "abstract", "away", "neural", "implementation", "detail", "irrelevant", "many", "explanatory", "purpose", "64", "mechanistic", "theory", "mechanistic", "nature", "computation", "recurring", "theme", "logic", "philosophy", "cognitive", "science", "gualtiero", "piccinini", "2007", "2012", "2015", "marcin", "milkowski", "2013", "develop", "theme", "mechanistic", "theory", "computing", "system", "functional", "mechanism", "system", "interconnected", "component", "component", "performs", "function", "within", "overall", "system", "mechanistic", "explanation", "proceeds", "decomposing", "system", "part", "describing", "part", "organized", "larger", "system", "isolating", "function", "performed", "part", "computing", "system", "functional", "mechanism", "particular", "kind", "piccinini", "account", "computing", "system", "mechanism", "whose", "component", "functionally", "organized", "process", "vehicle", "accord", "rule", "echoing", "putnam", "discussion", "multiple", "realizability", "piccinini", "demand", "rule", "mediumindependent", "abstract", "away", "specific", "physical", "implementation", "vehicle", "computational", "explanation", "decomposes", "system", "part", "describes", "part", "help", "system", "process", "relevant", "vehicle", "system", "process", "discretely", "structured", "vehicle", "computation", "digital", "system", "process", "continuous", "vehicle", "computation", "analog", "milkowski", "version", "mechanistic", "approach", "similar", "differs", "piccinini", "pursuing", "informationprocessing", "gloss", "computational", "mechanism", "operate", "informationbearing", "state", "milkowski", "piccinini", "deploy", "respective", "mechanistic", "theory", "defend", "computationalism", "mechanistic", "computationalists", "typically", "individuate", "computational", "state", "nonsemantically", "therefore", "encounter", "worry", "explanatory", "role", "representational", "content", "similar", "worry", "encountered", "fsc", "structuralism", "spirit", "shagrir", "2014", "complains", "mechanistic", "computationalism", "accommodate", "cognitive", "science", "explanation", "simultaneously", "computational", "representational", "perceived", "force", "criticism", "depend", "upon", "one", "sympathy", "contentinvolving", "computationalism", "65", "pluralism", "surveyed", "various", "contrasting", "sometimes", "overlapping", "conception", "computation", "classical", "computation", "connectionist", "computation", "neural", "computation", "formalsyntactic", "computation", "contentinvolving", "computation", "informationprocessing", "computation", "functional", "computation", "structuralist", "computation", "mechanistic", "computation", "conception", "yield", "different", "form", "computationalism", "conception", "strength", "weakness", "one", "might", "adopt", "pluralistic", "stance", "recognizes", "distinct", "legitimate", "conception", "rather", "elevate", "one", "conception", "others", "pluralist", "happily", "employ", "whichever", "conception", "seems", "useful", "given", "explanatory", "context", "edelman", "2008", "take", "pluralistic", "line", "chalmers", "2012", "recent", "discussion", "pluralistic", "line", "raise", "natural", "question", "provide", "general", "analysis", "encompasses", "type", "computation", "computation", "share", "certain", "characteristic", "mark", "one", "another", "perhaps", "instead", "united", "something", "like", "family", "resemblance", "deeper", "understanding", "computation", "requires", "u", "grapple", "question", "7", "argument", "computationalism", "ctm", "attracted", "numerous", "objection", "many", "case", "objection", "apply", "specific", "version", "ctm", "classical", "computationalism", "connectionist", "computationalism", "prominent", "objection", "see", "also", "entry", "chinese", "room", "argument", "widely", "discussed", "objection", "classical", "computationalism", "advanced", "john", "searle", "1980", "71", "triviality", "argument", "recurring", "worry", "ctm", "trivial", "describe", "almost", "physical", "system", "executing", "computation", "searle", "1990", "claim", "wall", "implement", "computer", "program", "since", "discern", "pattern", "molecular", "movement", "wall", "isomorphic", "formal", "structure", "program", "putnam", "1988", "121125", "defends", "le", "extreme", "still", "strong", "triviality", "thesis", "along", "line", "triviality", "argument", "play", "large", "role", "philosophical", "literature", "anticomputationalists", "deploy", "triviality", "argument", "computationalism", "computationalists", "seek", "avoid", "triviality", "computationalists", "usually", "rebut", "triviality", "argument", "insisting", "argument", "overlook", "constraint", "upon", "computational", "implementation", "constraint", "bar", "trivializing", "implementation", "constraint", "may", "counterfactual", "causal", "semantic", "otherwise", "depending", "one", "favored", "theory", "computation", "example", "david", "chalmers", "1995", "1996a", "b", "jack", "copeland", "1996", "hold", "putnam", "triviality", "argument", "ignores", "counterfactual", "conditionals", "physical", "system", "must", "satisfy", "order", "implement", "computational", "model", "philosopher", "say", "physical", "system", "must", "representational", "property", "implement", "computational", "model", "fodor", "1998", "1112", "ladyman", "2009", "sprevak", "2010", "least", "implement", "contentinvolving", "computational", "model", "rescorla", "2013", "2014b", "detail", "vary", "considerably", "computationalists", "debate", "amongst", "exactly", "type", "computation", "avoid", "triviality", "argument", "computationalists", "agree", "avoid", "devastating", "triviality", "worry", "sufficiently", "robust", "theory", "implementation", "relation", "computational", "model", "physical", "system", "pancomputationalism", "hold", "every", "physical", "system", "implement", "computational", "model", "thesis", "plausible", "since", "physical", "system", "arguably", "implement", "sufficiently", "trivial", "computational", "model", "eg", "onestate", "finite", "state", "automaton", "chalmers", "2011", "note", "pancomputationalism", "seem", "worrisome", "computationalism", "would", "worrisome", "much", "stronger", "triviality", "thesis", "almost", "every", "physical", "system", "implement", "almost", "every", "computational", "model", "discussion", "triviality", "argument", "computational", "implementation", "see", "sprevak", "2019", "entry", "computation", "physical", "system", "72", "g\u00f6del", "incompleteness", "theorem", "according", "author", "g\u00f6del", "incompleteness", "theorem", "show", "human", "mathematical", "capacity", "outstrip", "capacity", "turing", "machine", "nagel", "newman", "1958", "jr", "lucas", "1961", "develops", "position", "famous", "critique", "cctm", "roger", "penrose", "pursues", "critique", "emperor", "new", "mind", "1989", "subsequent", "writing", "various", "philosopher", "logician", "answered", "critique", "arguing", "existing", "formulation", "suffer", "fallacy", "questionbegging", "assumption", "even", "outright", "mathematical", "error", "bowie", "1982", "chalmers", "1996b", "feferman", "1996", "lewis", "1969", "1979", "putnam", "1975", "365366", "1994", "shapiro", "2003", "wide", "consensus", "criticism", "cctm", "lack", "force", "may", "turn", "certain", "human", "mental", "capacity", "outstrip", "turingcomputability", "g\u00f6del", "incompleteness", "theorem", "provide", "reason", "anticipate", "outcome", "73", "limit", "computational", "modeling", "could", "computer", "compose", "eroica", "symphony", "discover", "general", "relativity", "even", "replicate", "child", "effortless", "ability", "perceive", "environment", "tie", "shoelace", "discern", "emotion", "others", "intuitive", "creative", "skillful", "human", "activity", "may", "seem", "resist", "formalization", "computer", "program", "dreyfus", "1972", "1992", "generally", "one", "might", "worry", "crucial", "aspect", "human", "cognition", "elude", "computational", "modeling", "especially", "classical", "computational", "modeling", "ironically", "fodor", "promulgates", "forceful", "version", "critique", "even", "earliest", "statement", "cctm", "fodor", "1975", "197205", "express", "considerable", "skepticism", "cctm", "handle", "important", "cognitive", "phenomenon", "pessimism", "becomes", "pronounced", "later", "writing", "1983", "2000", "focus", "especially", "abductive", "reasoning", "mental", "phenomenon", "potentially", "eludes", "computational", "modeling", "core", "argument", "may", "summarized", "follows", "1", "turingstyle", "computation", "sensitive", "local", "property", "mental", "representation", "exhausted", "identity", "arrangement", "representation", "constituent", "2", "many", "mental", "process", "paradigmatically", "abduction", "sensitive", "nonlocal", "property", "relevance", "simplicity", "conservatism", "3", "hence", "may", "abandon", "turingstyle", "modeling", "relevant", "process", "4", "unfortunately", "currently", "idea", "alternative", "theory", "might", "serve", "suitable", "replacement", "critic", "deny", "1", "arguing", "suitable", "turingstyle", "computation", "sensitive", "nonlocal", "property", "schneider", "2011", "wilson", "2005", "challenge", "2", "arguing", "typical", "abductive", "inference", "sensitive", "local", "property", "carruthers", "2003", "ludwig", "schneider", "2008", "sperber", "2002", "concede", "step", "3", "dispute", "step", "4", "insisting", "promising", "nonturingstyle", "model", "relevant", "mental", "process", "pinker", "2005", "partly", "spurred", "criticism", "fodor", "elaborates", "argument", "considerable", "detail", "defend", "2", "critique", "theory", "model", "abduction", "deploying", "local", "heuristic", "algorithm", "2005", "4146", "2008", "115126", "positing", "profusion", "domainspecific", "cognitive", "module", "2005", "56100", "defend", "4", "critique", "various", "theory", "handle", "abduction", "nonturingstyle", "model", "2000", "4653", "2008", "connectionist", "network", "scope", "limit", "computational", "modeling", "remain", "controversial", "may", "expect", "topic", "remain", "active", "focus", "inquiry", "pursued", "jointly", "ai", "74", "temporal", "argument", "mental", "activity", "unfolds", "time", "moreover", "mind", "accomplishes", "sophisticated", "task", "eg", "perceptual", "estimation", "quickly", "many", "critic", "worry", "computationalism", "especially", "classical", "computationalism", "adequately", "accommodate", "temporal", "aspect", "cognition", "turingstyle", "model", "make", "explicit", "mention", "time", "scale", "computation", "occurs", "one", "could", "physically", "implement", "abstract", "turing", "machine", "siliconbased", "device", "slower", "vacuumtube", "device", "even", "slower", "pulleyandlever", "device", "critic", "recommend", "reject", "cctm", "favor", "alternative", "framework", "directly", "incorporates", "temporal", "consideration", "van", "gelder", "port", "1995", "use", "argument", "promote", "noncomputational", "dynamical", "system", "framework", "modeling", "mental", "activity", "eliasmith", "2003", "2013", "1213", "us", "support", "neural", "engineering", "framework", "computationalists", "respond", "supplement", "abstract", "computational", "model", "temporal", "consideration", "piccinini", "2010", "weiskopf", "2004", "example", "turing", "machine", "model", "presupposes", "discrete", "stage", "computation", "without", "describing", "stage", "relate", "physical", "time", "supplement", "model", "describing", "long", "stage", "last", "thereby", "converting", "nontemporal", "turing", "machine", "model", "theory", "yield", "detailed", "temporal", "prediction", "many", "advocate", "ctm", "employ", "supplementation", "along", "line", "study", "temporal", "property", "cognition", "newell", "1990", "similar", "supplementation", "figure", "prominently", "computer", "science", "whose", "practitioner", "quite", "concerned", "build", "machine", "appropriate", "temporal", "property", "computationalists", "conclude", "suitably", "supplemented", "version", "ctm", "adequately", "capture", "cognition", "unfolds", "time", "second", "temporal", "objection", "highlight", "contrast", "discrete", "continuous", "temporal", "evolution", "van", "gelder", "port", "1995", "computation", "turing", "machine", "unfolds", "discrete", "stage", "mental", "activity", "unfolds", "continuous", "time", "thus", "fundamental", "mismatch", "temporal", "property", "turingstyle", "computation", "actual", "mental", "activity", "need", "psychological", "theory", "describes", "continuous", "temporal", "evolution", "computationalists", "respond", "objection", "assumes", "shown", "cognitive", "activity", "fall", "explanatory", "significant", "discrete", "stage", "weiskopf", "2004", "assuming", "physical", "time", "continuous", "follows", "mental", "activity", "unfolds", "continuous", "time", "follow", "cognitive", "model", "must", "continuous", "temporal", "structure", "personal", "computer", "operates", "continuous", "time", "physical", "state", "evolves", "continuously", "complete", "physical", "theory", "reflect", "physical", "change", "computational", "model", "reflect", "every", "physical", "change", "computer", "computational", "model", "discrete", "temporal", "structure", "assume", "good", "cognitivelevel", "model", "mind", "must", "reflect", "every", "physical", "change", "brain", "even", "continuum", "evolving", "physical", "state", "assume", "continuum", "evolving", "cognitive", "state", "mere", "fact", "continuous", "temporal", "evolution", "militate", "computational", "model", "discrete", "temporal", "structure", "75", "embodied", "cognition", "embodied", "cognition", "research", "program", "draw", "inspiration", "continental", "philosopher", "maurice", "merleauponty", "perceptual", "psychologist", "jj", "gibson", "assorted", "influence", "fairly", "heterogeneous", "movement", "basic", "strategy", "emphasize", "link", "cognition", "bodily", "action", "surrounding", "environment", "see", "varela", "thompson", "rosch", "1991", "influential", "early", "statement", "many", "case", "proponent", "deploy", "tool", "dynamical", "system", "theory", "proponent", "typically", "present", "approach", "radical", "alternative", "computationalism", "chemero", "2009", "kelso", "1995", "thelen", "smith", "1994", "ctm", "complain", "treat", "mental", "activity", "static", "symbol", "manipulation", "detached", "embedding", "environment", "neglect", "myriad", "complex", "way", "environment", "causally", "constitutively", "shape", "mental", "activity", "replace", "ctm", "new", "picture", "emphasizes", "continuous", "link", "mind", "body", "environment", "agentenvironment", "dynamic", "internal", "mental", "computation", "hold", "key", "understanding", "cognition", "often", "broadly", "eliminativist", "attitude", "towards", "intentionality", "propels", "critique", "computationalists", "respond", "ctm", "allows", "due", "recognition", "cognition", "embodiment", "computational", "model", "take", "account", "mind", "body", "environment", "continuously", "interact", "computational", "model", "incorporate", "sensory", "input", "motor", "output", "obvious", "reason", "emphasis", "upon", "agentenvironment", "dynamic", "precludes", "dual", "emphasis", "upon", "internal", "mental", "computation", "clark", "2014", "140165", "rupert", "2009", "computationalists", "maintain", "ctm", "incorporate", "legitimate", "insight", "offered", "embodied", "cognition", "movement", "also", "insist", "ctm", "remains", "best", "overall", "framework", "explaining", "numerous", "core", "psychological", "phenomenon"]}