{
    "url": "logic-action",
    "title": "The Logic of Action",
    "authorship": {
        "year": "Copyright \u00a9 2013",
        "author_text": "Krister Segerberg\n\nJohn-Jules Meyer\n\nMarcus Kracht",
        "author_links": [
            {
                "http://wwwhomes.uni-bielefeld.de/mkracht/index-en.html": "Marcus Kracht"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2013</a> by\n\n<br/>\nKrister Segerberg\n<br/>\nJohn-Jules Meyer\n<br/>\n<a href=\"http://wwwhomes.uni-bielefeld.de/mkracht/index-en.html\" target=\"other\">Marcus Kracht</a>\n</p>\n</div>"
    },
    "pubinfo": [
        "First published Tue Mar 31, 2009",
        "substantive revision Tue Apr 2, 2013"
    ],
    "preamble": "\n\nIn this article we provide a brief overview of the logic of action in philosophy, linguistics, computer science, and artificial intelligence. The logic of action is the formal study of action in which formal languages are the main tool of analysis.\n\nThe concept of action is of central interest to many disciplines: the social sciences including economics, the humanities including history and literature, psychology, linguistics, law, computer science, artificial intelligence, and probably others. In philosophy it has been studied since the beginning because of its importance for epistemology and, particularly, ethics; and since a few decades it is even studied for its own sake. But it is in the logic o faction that action is studied in the most abstract way.\n\nThe logic of action began in philosophy. But it has also played a certain role in linguistics. And currently it is of great importance in computer science and artificial intelligence. For our purposes it is natural to separate the accounts of these developments.\n",
    "toc": [
        {
            "#LogAct": "1. The Logic of Action in Philosophy"
        },
        {
            "#HisOve": "1.1 Historical overview "
        },
        {
            "#StiSag": "1.2 The stit saga"
        },
        {
            "#Int": "1.3 Intentions"
        },
        {
            "#LogSpeKinAct": "1.4 Logics of special kinds of action "
        },
        {
            "#LogActLin": "2. The Logic of Action in Linguistics"
        },
        {
            "#SpeAct": "2.1 Speech acts"
        },
        {
            "#ActSen": "2.2 Action sentences"
        },
        {
            "#DynSem": "2.3 Dynamic semantics"
        },
        {
            "#LogActComSci": "3. The Logic of Action in Computer Science"
        },
        {
            "#ReaAboPro": "3.1 Reasoning about programs"
        },
        {
            "#LogActArtInt": "4. The Logic of Action in Artificial Intelligence"
        },
        {
            "#RepReaAboAct": "4.1 Representing and reasoning about actions"
        },
        {
            "#DesSpeIntAge": "4.2 Description and specification of intelligent agents"
        },
        {
            "#Con": "Conclusion"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. The Logic of Action in Philosophy\n1.1 Historical overview\n\nAlready St. Anselm studied the concept of action in a way that must be classified as logical; had he known symbolic logic, he would certainly have made use of it (Henry 1967; Walton 1976). In modern times the subject was introduced by, among others, Alan Ross Anderson, Frederick B. Fitch, Stig Kanger, and Georg Henrik von Wright; Kanger\u2019s work was further developed by his students Ingmar P\u00f6rn and Lars Lindahl. The first clearly semantic account was given by Brian F. Chellas (1969). (For a more detailed account, see Segerberg 1992 or the mini-history in Belnap 2001.)\n\nToday there are two rather different groups of theories that may be described as falling under the term logic of action. One, the result of the creation of Nuel Belnap and his many collaborators, may be called stit theory (a term that will be explained in the next paragraph). The other is dynamic logic. Both are connected with modal logic, but in different ways. Stit theory grew out of the philosophical tradition of modal logic. Dynamic logic, on the other hand, was invented by computer scientists in order to analyse computer action; only after the fact was it realized that it could be viewed as modal logic of a very general kind. One important difference between the two is that (for the most part) actions are not directly studied in stit theory: the ontology does not (usually) recognize a category of actions or events. But dynamic logic does. Among philosophers such ontological permissiveness has been unusual. Hector-Neri Casta\u00f1eda, with his distinction between propositions and practitions, provides one notable exception.\n\nThe stit tradition is treated in this section, the dynamic logic one in the next.\n1.2 The stit saga\n\nThe term \u201cstit\u201d is an acronym based on \u201csees to it that\u201d. The idea is to add, to an ordinary classical propositional language, a new propositional operator \\(\\stit\\), interpreting \\(\\stit_i\\phi\\), where \\(i\\) stands for an agent and \\(\\phi\\) for a proposition, as \\(i\\) sees to it that \\(\\phi\\). (The official notation of the Belnap school is more laborious: [\\(i \\mathop{\\mathsf{stit:}} \\phi\\)].) Note that \\(\\phi\\) is allowed to contain nestings of the new operator.\n\nIn order to develop formal meaning conditions for the stit operator \\(\\stit\\) a semantics is defined. A stit frame has four components: a set \\(T\\), the nodes of which are called moments; an irreflexive tree ordering \\(\\lt\\) of \\(T\\); a set of agents; and a choice function \\(C\\). A maximal branch through the tree is called a history.\n\nThe tree \\((T,\\lt)\\) seems to correspond to a na\u00efve picture familiar to us all: a moment \\(m\\) is a temporary present; the set \\(\\left\\{n : n \\lt m\\right\\}\\) corresponds to the past of \\(m\\), which is unique; while the set \\(\\left\\{n : m \\lt n\\right\\}\\) corresponds to the open future of \\(m\\), each particular maximal linear subset of which corresponds to a particular possible future.\n\nTo formalize the notion of action, begin with two general observations:\n\n usually an agent is not able to select one possible future to become the unique actual future, but\n by his action he can make sure that certain futures, which before his action are possible, are no longer possible after his action.\n\n\nThis is where the choice function \\(C\\) comes in: for each moment \\(m\\) and agent \\(i, C\\) yields a partitioning \\(C_i^m\\) of the set \\(H_m\\) of all histories through \\(m\\). An equivalence class in \\(C_i^m\\) is called a choice cell. (Note that two histories belonging to the same choice cell agree up to the moment in question but not necessarily later on.) If \\(h\\) is a history running through \\(m\\) we write \\(C_i^m(h)\\) for the choice cell of which \\(h\\) is a member. It is natural to associate \\(C_i^m\\) with the set of actions open to the agent \\(i\\) at \\(m\\), and to think of the choice cell \\(C_i^m(h)\\) as representing the action associated with \\(h\\).\n\nA stit model has an additional component: a valuation. A valuation in a frame, it turns out, is a function that assigns to a variable and each index either 1 (truth) or 0 (falsity), where an index is an ordered pair consisting of a history and a moment on that history. The notion of truth or falsity of a formula with respect to an index can now be defined.  If \\(V\\) is the valuation we have the following basic truth-condition for atomic \\(\\phi\\):\n\n\n\\[(h,m) \\models \\phi \\text{ iff } V(\\phi, (h,m)) = 1.\\]\n\n\nThe truth-conditions for the Boolean connectives are as expected; for example,\n\n\\[\\begin{align*}\n(h,m) &\\models \\neg\\phi \\text{ iff } (h,m) \\not\\models \\phi, \\\\\n(h,m) &\\models \\phi \\wedge \\psi \\text{ iff } (h,m) \\models \\phi \\text{ and } (h,m) \\models \\psi.\n\\end{align*}\\]\n\n\nLet us write \\(\\llbracket\\phi\\rrbracket_m\\) for the set \\(\\left\\{h \\in H_m : (h,m) \\models \\phi\\right\\}\\), that is, the set of histories agreeing with \\(h\\) at least up to \\(m\\) and such that \\(\\phi\\) is true with respect to the index consisting of that history and \\(m\\). Defining formal truth-conditions for the stit operator there are at least two possibilities to be considered:\n\n\\((h,m) \\models \\stit_i \\phi\\) iff \\(C^{m}_i(h) \\subseteq\\llbracket\\phi\\rrbracket_m\\).\n\\((h,m) \\models \\stit_i \\phi\\) iff \\(C^{m}_i(h) \\subseteq\\llbracket\\phi\\rrbracket_m\\) and \\(\\llbracket\\phi\\rrbracket_m \\ne H_m\\).\n\n\nTo distinguish the two different operators that those conditions define, the former operator is called the Chellas stit, written \\(\\cstit\\), while the latter operator is called the deliberative stit, written \\(\\dstit\\).\n\nIn words, \\(\\cstit_i \\phi\\) is true at an index \\((h,m)\\) if \\(\\phi\\) is true with respect to \\(h'\\) and \\(m\\), for all histories \\(h'\\) in the same choice cell at \\(m\\) as \\(h\\); this is called the positive condition. The truth-condition for \\(\\dstit_i \\phi\\) is more exacting; not only the positive condition has to be satisfied but also what is called the negative condition: there must be some history through \\(m\\) such that \\(\\phi\\) fails to be true with respect to that history and \\(m\\).\n\nBoth \\(\\cstit\\) and \\(\\dstit\\) are studied; it is claimed that they capture important aspects of the concept \u201csees to it that\u201d. The two operators become interdefinable if one also introduces the concept \u201cit is historically necessary that\u201d. Using \\(\\Box\\) for historical necessity, define\n\n\\[\n(h,m) \\models \\Box\\phi \\text{ iff, for all } h' \\in H_m, (h',m) \\models \\phi.\n\\]\n\n\nThen the formulas\n\n\\[\\begin{align*}\n\\dstit_i \\phi &\\leftrightarrow(\\cstit_i \\phi \\wedge \\neg \\Box\\phi) \\text{ and}\\\\\n\\cstit_i \\phi &\\leftrightarrow(\\dstit_i \\phi \\vee \\Box\\phi)\n\\end{align*}\\]\n\n are true with respect to all indices.\n\nOne advantage of stit theory is that the stit analysis of individual action can be extended in natural ways to cover group action.\n\nA number of the initial papers defining the stit tradition are collected in the volume Belnap 2001. One important later work is John F. Horty\u2019s book (2001). The logic of stit was axiomatized by Ming Xu (1998).\n1.3 Intentions\n\nMichael Bratman\u2019s philosophical analysis of the notion of intention has had a significant influence on the development of the logic of action within computer science. It will be discussed below.\n1.4 Logics of special kinds of action\n\nIn a series of papers Carlos Alchourr\u00f3n, Peter G\u00e4rdenfors and David Makinson created what they called a logic of theory change, later known as the AGM paradigm. Two particular kinds of change inspired their work: change due to deontic actions (Alchourr\u00f3n) and change due to doxastic actions (G\u00e4rdenfors and before him Isaac Levi). Examples of deontic actions are derogation and amendment (laws can be annulled or amended), while contraction and expansion are analogous doxastic actions (beliefs can be given up, new beliefs can be added). Later the modal logic of such actions has been explored under the names dynamic deontic logic, dynamic doxastic logic and dynamic epistemic logic. (For the classic paper on AGM, see AGM 1985. For an introduction to dynamic deontic logic and dynamic doxastic logic, see Lindstr\u00f6m and Segerberg 2006. We will return to this topic in Section 4, where it is viewed from the perspective of the field of artificial intelligence.\n2. The Logic of Action in Linguistics\n\nIn linguistics, there are two ways in which actions play a role: on the one hand, utterances are actions and on the other they can be used to talk about actions. The first leads to the study of speech acts, a branch of pragmatics, the second to the study of the semantics of action reports, hence is of a distinctly semantic nature. In addition to this, there is a special type of semantics, dynamic semantics, where meanings are not considered as state descriptions but as changes in the state of a hearer.\n2.1 Speech acts\n\nThe study of speech acts goes back to Austin (1957) and Searle (1969). Both emphasise that using language is to perform certain acts. Moreover, there is not just one act but a whole gamut of them (Austin himself puts the number in the magnitude of \\(10^3)\\). The classification he himself gives involves acts that are nowadays not considered as part of a separate science: the mere act of uttering a word (the phatic act) or sentence is part of phonetics (or phonology) and only of marginal concern here. By contrast, the illocutionary and perlocutionary acts have been the subject of intense study. An illocutionary act is the linguistic act performed by using that sentence; it is inherently communicative in nature. By contrast, the perlocutionary act is an act that needs surrounding social contexts to be successful. The act of naming a ship or christening a baby, for example, are perlocutionary. The sentence \u201cI hereby pronounce you husband and wife\u201d has the effect of marrying two people only under certain well-defined circumstances. By definition, perlocutionary acts take us outside the domain of language and communication.\n\nSearle and Vanderveken (1985) develop a logic of speech acts which they call illocutionary logic. This was refined in Vanderveken 1990 and Vanderveken 1991. Already, Frege used in his Begriffsschrift the notation \u201c\\(\\vdash \\phi\\)\u201d, where \\(\\phi\\) denotes a proposition and \u201c\\(\\vdash\\)\u201d the judgment sign. So, \u201c\\(\\vdash \\phi\\)\u201d says that \\(\\phi\\) is provable, but other interpretations of \\(\\vdash\\) are possible (accompanied by different notation; for example, \u201c\\(\\models \\phi\\)\u201d says that \\(\\phi\\) is true (in the model), \u201c\\(\\dashv \\phi\\)\u201d says that \\(\\phi\\) is refutable, and so on). An elementary speech act is of the form \\(F(\\phi)\\), where \\(F\\) denotes an illocutionary point and \\(\\phi\\) a proposition. In turn, an illocutionary force is identified by exactly seven elements:\n\na point,\nthe mode of achievement of the illocutionary point,\nthe degree of strength of the illocutionary point,\nthe propositional content conditions,\nthe preparatory conditions,\nthe sincerity conditions,\nthe degree of strength of the sincerity conditions.\n\n\nThere are exactly five points according to Searle and Vanderveken (1985):\n\nThe assertive point is to say how things are.\nThe commissive point is to commit speaker to doing something.\nThe directive point is to get other people to do things.\n The declarative point is to change the world by saying so.\nThe expressive point is to express feelings and attitudes.\n\n\nLater treatments of this matter tend to disregard much of the complexity of this earlier approach for the reason that it fails to have any predictive power. Especially difficult to handle are \u201cstrengths\u201d, for example. Modern models try to use update models instead (see Section 2.3 below). Van der Sandt 1991 uses a discourse model with three different slates (for each speaker, and one common slate). While each speaker is responsible for maintaining his own slate, changes to the common slate can only be made through communication with each other. Merin 1994 seeks to reduce the manipulations to a sequential combination of so-called elementary social acts: claim, concession, denial, and retraction.\n\nUttering a sentence is acting. This action can have various consequences, partly intended partly not. The fact that utterances as actions are embedded in a bigger scheme of interaction between humans has been put into focus recently (see, for example, Clark 1996). Another important aspect that has been highlighted recently is the fact that by uttering a sentence we can change the knowledge state of an entire group of agents, see Balbiani et al. 2008. After publicly announcing \\(\\phi\\), \\(\\phi\\) becomes common knowledge among the entire group. This idea sheds new light on a problem of Gricean pragmatics, where certain speech acts can only be successful if certain facts are commonly known between speaker and hearer. It is by means of an utterance that a speaker can establish this common knowledge in case it wasn\u2019t already there.\n2.2 Action sentences\n\nDavidson (1967) gave an account of action sentences in terms of what is now widely known as events. The basic idea is that an action sentence has the form \\((\\exists e)(\\cdots)\\), where \\(e\\) is a variable over acts. For example, \u201cBrutus violently stabbed Caesar\u201d is translated (ignoring tense) as \\((\\exists e) (\\mathop{\\mathrm{stab}}(e,\\mathrm{Brutus},\\mathrm{Caesar}) \\wedge \\mathop{\\mathrm{violent}}(e))\\). This allows to capture the fact that this sentence logically entails that Brutus stabbed Caesar. This idea has been widely adopted in linguistics; moreover, it is now assumed that basically all verbs denote events (Parsons 1990). Thus action sentences are those that speak about special types of events, called eventualities.\n\nVendler (1957) classified verbs into four groups:\n\nstates (\u201cknow\u201d, \u201csit\u201d),\nactivities (\u201crun\u201d, \u201ceat\u201d),\naccomplishments (\u201cwrite a letter\u201d, \u201cbuild a house\u201d), and\nachievements (\u201creach\u201d, \u201carrive\u201d).\n\n\nMoens and Steedman (1988) add a fifth category:\n\npoints (\u201cflash\u201d, \u201cburst\u201d).\n\n\nThe main dividing line is between states and the others. The types (b)\u2013(e) all refer to change. This division has been heavily influential in linguistic theory; mostly, however, research concentrated on its relation to aspect. It is to be noted, for example, that verbs of type (c) can be used with the progressive while verbs of type (d) cannot. In an attempt to explain this, Krifka 1986 and Krifka 1992 have introduced the notion of an incremental theme. The idea is that any eventuality has an underlying activity whose progress can be measured using some underlying participant of the event. If, for example, I write a letter then the progress is measured in amounts of words. The letter is therefore the incremental theme in \u201cI write a letter\u201d since it defines the progress. One implementation of the idea is the theory of aspect by Verkuyl (1993). Another way to implement the idea of change is constituted by a translation into propositional dynamic logic (see Naumann 2001). Van Lambalgen and Hamm (2005) have applied the event calculus by Shanahan (1990) to the description of events.\n2.3 Dynamic semantics\n\nThe idea that propositions can not only be viewed as state descriptions but also as updates has been advocated independently by many people. Consider the possible states of an agent to be (in the simplest case) a theory (that is, a deductively closed set of sentences). Then the update of a theory \\(T\\) by a proposition \\(\\phi\\) is the deductive closure of \\(T \\cup \\left\\{\\phi\\right\\}\\).\n\nG\u00e4rdenfors 1988 advocates this perspective with particular attention to belief revision. Veltman 1985 develops the update view for the treatment of conditionals. One advantage of the idea is that it is possible to show why the mini discourse \u201cIt rains. It may not be raining.\u201d is infelicitous in contrast to \u201cIt may not be raining. It rains.\u201d. Given that an update is felicitous only to a consistent theory, and that \u201cmay \\(\\phi\\)\u201d (with epistemic \u201cmay\u201d) simply means \u201cit is consistent\u201d (written \\(\\diamond\\phi\\)), the first is the sequence of updates with \\(\\phi\\) and \\(\\diamond \\neg\\phi\\). The second step leads to inconsistency, since \\(\\phi\\) has already been added. It is vital in this approach that the context is constantly changing.\n\nHeim 1983 contains an attempt to make this idea fruitful for the treatment of presuppositions. In Heim\u2019s proposal, a sentence has the potential to change the context, and this is why, for example, the sentence \u201cIf John is married his wife will be happy.\u201d does not presuppose that John is married. Namely, the second part of the conditional (\u201chis wife will be happy\u201d) is evaluated against the context incremented by the antecedent (\u201cJohn is married\u201d). This of course is the standard way conditions are evaluated in computer languages. This parallel is exploited in Van Eijck 1994, see also Kracht 1993.\n\nThe idea of going dynamic was further developed in Dynamic Predicate Logic (DPL, see Groenendijk and Stokhof 1991), where all expressions are interpreted dynamically. The specific insight in this grammar is that existential quantifiers have a dynamically growing scope. This has first been noted in Kamp 1981, where a semantics was given in terms of intermediate representations, so-called Discourse Representation Structures. Groenendijk and Stokhof replace these structures by introducing a dynamics into the evaluation of a formula, as proposed in Dynamic Logic (DL). An existential quantifier is translated as a random assignment \u201c\\(x \\leftarrow\\ ?\\)\u201d of DL, whose interpretation is a relation between assignments: it is the set of pairs \\(\\langle \\beta ,\\gamma \\rangle\\) such that \\(\\beta(y) = \\gamma(y)\\) for all \\(y \\ne x\\) (in symbols \\(\\beta \\sim_x \\gamma\\)). The translation of the sentence \u201cA man walks.\u201d is \n\n(1)\n\n\\(\\langle x \\leftarrow ?\\rangle\n\\mathop{\\mathrm{man}}'(x) \\wedge \\mathop{\\mathrm{walk}}'(x)\\)\n\n\nThis is a proposition, hence interpreted as a set. One can however, push the dynamicity even lower, and make all meanings relational. Then \u201cA man walks.\u201d is interpreted by the \u2018program\u2019 \n\n(2)\n\n\\(x \\leftarrow ?; \\mathop{\\mathrm{man}}'(x)?; \\mathop{\\mathrm{walk}}'(x)?\\)\n  \n\nHere, \\(\\mathop{\\mathrm{man}}'(x)?\\) uses the test constructor\n  \u201c\\(?\\)\u201d: \\(\\phi ?\\) is the set of all \\(\\langle \\beta ,\\beta \\rangle\\) such that \\(\\beta\\) satisfies \\(\\phi\\). The meaning of the entire program (2) therefore also is a relation between assignments. Namely, it is the set \\(R\\) of all pairs \\(\\langle \\beta ,\\gamma \\rangle\\) where \\(\\beta \\sim_x \\gamma\\), and \\(\\gamma(x)\\) walks and is a man. The meaning of (1) by contrast is the set of all \\(\\beta\\) such that some \\(\\langle \\beta ,\\gamma \\rangle \\in R\\). Existential quantifiers thus have \u2018side effects\u2019: the change in assignment is never undone by a quantifier over a different variable. Hence the open-endedness to the right of the existential. This explains the absence of brackets in (1). For an overview of dynamic semantics see Muskens et al. 1997.\n3. The Logic of Action in Computer Science\n\nThe logic of action plays an important role in computer science. This becomes evident once one realizes that computers perform actions in the form of executing program statements written down in some programming language, changing computer internals and, by interfaces to the outside world, also that outside world. As such a logic of action provides a means to reason about programs, or more precisely, the execution of programs and their effects. This enables one to prove the correctness of programs. In principle, this is something very desirable: if we could prove all our software correct, we would know that they would function exactly the way we designed them. This was already realized by pioneers of computer programming such as Turing (1949) and Von Neumann (Goldstein and Von Neumann 1963). Of course, this ideal is too hard to establish in daily practice for all software. Verification is a nontrivial and time-consuming occupation, and there are also theoretical limitations to it. However, as the alternative is \u201cjust\u201d massive testing of programs experimentally, with no 100% guarantee of correctness, it has remained an active area of research to this day.\n3.1 Reasoning about programs\n\nProgram verification has a long history. Already since the inception of the computer and its programming researchers started to think of ways of analyzing programs to be sure they did what they were supposed to do. In the 60s the development of a true mathematical theory of program correctness began to take serious shape (de Bakker 1980, 466). Remarkably, the work of John McCarthy who we will also encounter later on when we turn to the field of artificial intelligence played an important role here, distinguishing and studying fundamental notions such as \u2018state\u2019, McCarthy 1963a. This led on the one hand to the field of semantics of programming languages, and on the other to major advances in program correctness by Floyd (1967), Naur (1966), Hoare (1969) and Dijkstra (1976) (de Bakker 1980). Floyd and Naur used an elementary stepwise induction principle and predicates attached to program points to express invariant properties of imperative-style programs (Cousot 1990, 859), programs that are built up from basic assignment statements (of arithmetical expressions to program variables) and may be composed by sequencing, conditionals and repetitions. While the Floyd-Naur approach\u2014called the inductive assertion method\u2014giving rise to a systematic construction of verification conditions, was a method to prove the correctness of programs by means of logic, it was not a logic itself in the strict sense of the word. The way to a proper logic of programs was paved by Hoare, whose compositional proof method led to what is now known as Hoare logic. By exploiting the syntactic structure of (imperative-style) programs, Hoare was able to turn the Floyd-Naur method into a true logic with as assertions so-called Hoare triples of the form \\(\\left\\{P\\right\\}S\\left\\{Q\\right\\}\\), where \\(P\\) and \\(Q\\) are first-order formulas and \\(S\\) is a program statement in an imperative-style programming language as mentioned above. The intended reading is if \\(P\\) holds before execution of the statement \\(S\\) then \\(Q\\) holds upon termination of (execution of) \\(S\\). (The issue whether the execution of \\(S\\) terminates can be put in the reading of this Hoare triple either conditionally (partial correctness) or nonconditionally (total correctness), giving rise to different logics, see Harel et al. 2000). To give an impression of Hoare-style logics, we give here some rules for a simple programming language consisting of variable assignments to arithmetic expressions, and containing sequential (;), conditional \\((\\lif)\\) and repetitive \\((\\lwhile)\\) composition.\n\n\\[\n\\frac{\\left\\{P\\right\\}S_1\\left\\{Q\\right\\} , \\left\\{Q\\right\\}S_2\\left\\{R\\right\\}}\n     {\\left\\{P\\right\\}S_1 \\ ;\\ S_2\\left\\{R\\right\\}}\n\\]\n\n\\[\n\\frac{\\left\\{P \\wedge B\\right\\}S_1\\left\\{Q\\right\\} , \\left\\{P \\wedge \\neg B\\right\\}S_2\\left\\{Q\\right\\}}\n     {\\left\\{P\\right\\} \\lif B \\lthen S_1 \\lelse S_2 \\left\\{Q\\right\\}}\n\\]\n\n\\[\n\\frac{\\left\\{P \\wedge B\\right\\}S\\left\\{P\\right\\}}\n     {\\left\\{P\\right\\} \\lwhile B \\ldo S \\left\\{P \\wedge \\neg B\\right\\}}\n\\]\n\n\nLater Pratt and Harel generalized Hoare logic to dynamic logic (Pratt 1976, Pratt 1979a, Harel 1979, Harel 1984, Kozen and Tiuryn 1990, Harel et al. 2000), of which it was \n realized[1] \nthat it is in fact a form of modal logic, by viewing the input-output relation of a program \\(S\\) as an accessibility relation in the sense of Kripke-style \n semantics.[2] \nA Hoare triple \\(\\left\\{P\\right\\}S\\left\\{Q\\right\\}\\) becomes in dynamic logic the following formula: \\(P \\rightarrow[S] Q\\), where [\\(S\\)] is the modal box operator associated with (the accessibility relation associated with) the input-output relation of program \\(S\\). The propositional version of Dynamic Logic, PDL, was introduced by Fischer and Ladner (1977), and became an important topic of research in itself. The key axiom of PDL is the induction axiom\n\n\\[\n[S^* ] (P \\rightarrow[S] P) \\rightarrow(P \\rightarrow[S^*] P)\n\\]\n\n\nwhere \\(^*\\) stands for the iteration operator, \\(S^*\\) denoting an arbitrary (finite) number of iterations of program \\(S\\). The axiom expresses that if after any number of iterations of \\(S\\) the truth of \\(P\\) is preserved by the execution of \\(S\\), then, if \\(P\\) is true at the current state, it will also be true after any number of iterations of \\(S\\). A weaker form of PDL, called HML, with only an atomic action box and diamond and propositional connectives, was introduced by Hennessy & Milner to reason about concurrent processes, and in particular analyze process equivalence (Hennessy and Milner 1980).\n\nIt is also worth mentioning here that the work of Dijkstra (1976) on weakest precondition calculus is very much related to dynamic logic (and Hoare\u2019s logic). In fact, what Dijkstra calls the weakest liberal precondition, denoted \\(\\mathbf{wlp}(S,Q)\\), is the same as the box operator in dynamic logic: \\(\\mathbf{wlp}(S,Q) = [S]Q\\), while his weakest precondition, denoted \\(\\mathbf{wp}(S,Q)\\), is the total correctness variant of this, meaning that this expression also entails the termination of statement \\(S\\) (Cousot 1990).\n\nIt was later realized that the application of dynamic logic goes beyond program verification or reasoning about programs. In fact, it constitutes a logic of general action. In Meyer 2000 a number of other applications of dynamic logic are given including deontic logic (see also Meyer 1988), reasoning about database updates, the semantics of reasoning systems such as reflective architectures. As an aside we note here that the use of dynamic logic for deontic logic as proposed in Meyer 1988 needed an extension of the action language, in particular the addition of the \u2018action negation\u2019 operator. The rather controversial nature of this operator triggered work on action negation in itself (see e.g., Broersen 2004). Below we will also encounter the use of dynamic logic in artificial intelligence when specifying intelligent agents.\n\nThe logics thus far are adequate for reasoning about programs that are supposed to terminate and display a certain input/output behavior. However, in the late seventies one came to realize that there are also programs that are not of this kind. Reactive programs are designed to react to input streams that in theory may be infinite, and thus show ideally nonterminating behavior. Not so much input-output behavior is relevant here but rather the behavior of programs over time. Therefore Pnueli (1977) proposed a different way of reasoning about programs for this style of programming based on the idea of a logic of time, viz. (linear-time) temporal logic. (Since reactivity often involves concurrent or parallel programming, temporal logic is often associated with this style of programming. However, it should be noted that a line of research continued to extend the use of Hoare logic to concurrent programs (Lamport 1977, Cousot 1990, de Roever et al. 2001).) Linear-time temporal logic typically has temporal operators such as next-time, always (in the future), sometime (in the future), until and since.\n\nAn interesting difference between temporal logic on the one hand, and dynamic logic and Hoare logic on the other, is that the former is what in the literature is called an endogenous logic, while the latter are so-called exogenous logics. A logic is exogenous if programs are explicit in the logical language, while for endogenous logics this is not the case. In an endogenous logic such as temporal logic the program is assumed to be fixed, and is considered part of the structure over which the logic is interpreted (Harel et al. 2000, 157). Exogenous logics are compositional and have the advantage of allowing analysis by structural induction. Later Pratt (1979b) tried to blend temporal and dynamic logic into what he called process logic, which is an exogenous logic for reasoning about temporal behavior. \n\nAt the moment the field of temporal logic as applied in computer science has developed into a complete subfield on its own, including techniques and tools for (semi-)automatic reasoning and model-checking (cf. Emerson 1990). Also variants of the basic linear-time models have been proposed for verification, such as  branching-time temporal logic (and, in particular the logics CTL (computation tree logic) and its extension CTL* (Emerson 1990), in which one can reason explicitly about (quantification over) alternative paths in nondeterministic computations, and more recently also an extension of CTL, called alternating-time temporal logic (ATL), with a modality expressing that a group of agents has a joint strategy to ensure its argument, to reason about so-called open systems. These are systems, the behavior of which depends also on the behavior of their environments, see Alur et al. 1998.\n\nFinally we mention still alternative logics to reason about programs, viz. fixpoint logics, with as typical example the so-called \\(\\mu\\)-calculus, dating back to Scott and de Bakker (1969), and further developed in Hitchcock and Park 1972, Park 1976, de Bakker 1980, and Meyer 1985. The basic operator is the least fixed point operator \\(\\mu\\), capturing iteration and recursion: if \\(\\phi(X)\\) is a logical expression with a free relation variable \\(X\\), then the expression \\(\\mu X\\phi(X)\\) represents the least \\(X\\) such that \\(\\phi(X) = X\\), if such an \\(X\\) exists. A propositional version of the \\(\\mu\\)-calculus, called propositional or modal \\(\\mu\\)-calculus comprising the propositional constructs \\(\\rightarrow\\) and false, together with the atomic (action) modality [\\(a\\)] and \\(\\mu\\) operator is completely axiomatized by propositional modal logic plus the axiom \\(\\phi[X/\\mu X\\phi] \\rightarrow \\mu X\\phi\\), where \\(\\phi[X/Y\\)] stands for the expression \\(\\phi\\) in which \\(X\\) is substituted by \\(Y\\), and rule\n\n\\[\n\\frac{\\phi[X/\\psi] \\rightarrow \\psi}\n     {\\left\\{\\mu X\\phi \\rightarrow \\psi \\right\\}}\n\\]\n\n\n(Kozen 1983, Bradfield and Stirling 2007). This logic is known to subsume PDL (cf. Harel et al. 2000).\n4. The Logic of Action in Artificial Intelligence\n\nIn the field of artificial intelligence (AI), the aim is to devise intelligently behaving computer-based artifacts (with the purpose of understanding human intelligence or just making intelligent computer systems and programs). In order to achieve this, there is a tradition within AI to try and construct these systems based on symbolic representations of all relevant factors involved. This tradition is called symbolic AI or \u2018good old-fashioned\u2019 AI (GOFAI). In this tradition the sub-area of knowledge representation (KR) obviously is of major importance: it played an important role since the inception of AI, and has developed to a substantial field of its own. One of the prominent areas in KR concerns the representation of actions, performed by either the system to be devised itself or the actors in its environment. Of course, besides their pure representation also reasoning about actions is important, since representation and reasoning with these representations are deemed to be closely connected within KR (which is sometime also called KR&R, knowledge representation & reasoning). A related, more recent development within AI is that of basing the construction of intelligent systems on the concept of an (intelligent) agent, an autonomously acting entity, regarding which, by its very nature, logics of action play a crucial role in obtaining a logical description and specification.\n4.1 Representing and reasoning about actions\n\nAs said above, the representation of actions and formalisms/logics to reason with them are very central to AI and particularly the field of KR. One of the main problems that one encounters in the literature on reasoning about actions in AI, and much more so than in mainstream computer science, is the discovery of the so-called frame problem (McCarthy and Hayes 1969). Although this problem has been generalized by philosophers such as Dennett (1984) to a general problem of relevance and salience of properties pertaining to action, the heart of the problem is that in a \u2018common-sense\u2019 setting as one encounters in AI, it is virtually impossible to specify all the effects by the actions of concern, as well as, notably, all non-effects. For instance, given an action, think about what changes if the action is performed and what does not\u2014generally the latter is much more difficult to produce than the former, leading to large, complex attempts to specify the non-effects. But there is of course also the problem of relevance: what aspects are relevant for the problem at hand; which properties do we need to take into consideration? In particular, this also pertains to the preconditions of an action that would guarantee the successful performance/execution of an action. Again, in a common-sense environment, these are formidable, and one can always think of another (pre)condition that should be incorporated. For instance, for successfully starting the motor of a car, there should be a charged battery, sufficient fuel, \u2026, but also not too cold weather, or even sufficient power in your fingers to be able to turn the starting key, the presence of a motor in the car, \u2026 etc. etc. In AI one tries to find a solution for the frame problem, having to do with the smallest possible specification. Although this problem gave rise to so-called defeasible or non-monotonic solutions such as defaults (\u2018normally a car has a motor\u2019), which in itself gave rise to a whole new a realm within AI called nonmonotonic or commonsense reasoning, this is beyond the scope of this entry (we refer the interested reader to the article by Thomason (2003) in this encyclopedia). We focus here on a solution that does not appeal to nonmonotonicity (directly).\n\nReiter (2001) has proposed a (partial) solution within a framework, called the situation calculus, that has been very popular in KR especially in North America since it was proposed by John McCarthy, one of the founding fathers of AI (McCarthy 1963b, McCarthy 1986). The situation calculus is a dialect of first-order logic with some mild second-order features, especially designed to reason about actions. (One of its distinctive features is that of the so-called reification of semantic notions such as states or possible worlds (as well as truth predicates) into syntactic entities (\u2018situations\u2019) in the object language.) For the sake of conformity in this entry and reasons of space, we will try rendering Reiter\u2019s idea within (first-order) dynamic logic, or rather, a slight extension of it. (We need action variables to denote action expressions and equalities between action variables and actions (or rather action expressions) as well as (universal) quantification over action variables).\n\nWhat is known as Reiter\u2019s solution to the frame problem assumes a so-called closed system, that is to say, a system in which all (relevant) actions and changeable properties (in this setting often called \u2018fluents\u2019 to emphasize their changeability over time) are known. By this assumption it is possible to express the (non)change as a consequence of performing actions as well as the issue of the check for the preconditions to ensure successful performance in a very succinct and elegant manner, and coin it in a so-called successor state axiom of the form\n\n\\[\n(\\forall A)[\\Poss(A) \\rightarrow(([A]f(\\boldsymbol{x})) \\leftrightarrow (\\gamma_{f}^+ (\\boldsymbol{x}, A) \\vee(f(\\boldsymbol{x}) \\wedge \\neg \\gamma_{f}^- (\\boldsymbol{x}, A))))]\n\\]\n\n\nwhere \\(A\\) is an action variable, and \\(\\gamma_{f}^+ (\\boldsymbol{x}, A)\\) and \\(\\gamma_{f}^- (\\boldsymbol{x}, A)\\) are \u2018simple\u2019 expressions without action modalities expressing the conditions for \\(\\phi\\) becoming true and false, respectively. So the formula is read informally as, under certain preconditions pertaining to the action \\(A\\) at hand, the fluent (predicate) \\(f\\) becomes true of arguments \\(\\boldsymbol{x}\\), if and only if either the condition \\(\\gamma_{f}^+ (\\boldsymbol{x}, A)\\) holds or \\(f(\\boldsymbol{x})\\) holds (before the execution of \\(A)\\) and the condition \\(\\gamma_{f}^- (\\boldsymbol{x}, A)\\) (that would cause it to become false) does not hold. Furthermore, the expression \\(\\Poss(A)\\) is used schematically in such axioms, where the whole action theory should be complemented with so-called precondition axioms of the form \\(\\phi_A \\rightarrow \\Poss(A)\\) for concrete expressions \\(\\phi_A\\) stating the actual preconditions needed for a successful execution of \\(A\\).\n\nTo see how this works out in practice we consider a little example in a domain where we have a vase \\(v\\) which may be broken or not (so we have \u201cbroken\u201d as a fluent), and actions drop and repair. We also assume the (non-changeable) predicates fragile and held-in-hand of an object. Now the successor state axiom becomes \n\n\\[\\begin{align*}\n(\\forall A)[&\\Poss(A) \\rightarrow \\\\\n&([A]\\mathop{\\mathrm{broken}}(v) \\leftrightarrow \\\\\n&\\ ((A = \\mathop{\\mathrm{drop}}(v) \\wedge \\mathop{\\mathrm{fragile}}(v)) \\vee (\\mathop{\\mathrm{broken}}(v) \\wedge A \\ne \\mathop{\\mathrm{repair}}(v))))]\n\\end{align*}\\]\n\n\nand as precondition axioms we have \\(\\textrm{held-in-hand}(x) \\rightarrow \\Poss(\\mathop{\\mathrm{drop}}(x))\\) and \\(\\mathop{\\mathrm{broken}}(x) \\rightarrow \\Poss(\\mathop{\\mathrm{repair}}(x))\\). This action theory is very succinct: one needs only one successor state axiom per fluent and one precondition axiom per action.\n\nFinally in this subsection we must mention some other well-known approaches to reasoning about action and change. The event calculus (Kowalski and Sergot 1986, Shanahan 1990, Shanahan 1995) and fluent calculus (Thielscher 2005) are alternatives to the situation-based representation of actions in the situation calculus. The reader is also referred to Sandewall and Shoham 1994 for historical and methodological issues as well as the relation with non-monotonic reasoning. These ideas have led to very efficient planning systems (e.g., TALplanner, Kvarnstr\u00f6m and Doherty 2000) and practical ways to program robotic agents (e.g., the GOLOG family (Reiter 2001) of languages based on the situation calculus, and FLUX (Thielscher 2005) based on the fluent calculus).\n4.2 Description and specification of intelligent agents\n\nIn the last two decades the notion of an intelligent agent has emerged as a unifying concept to discuss the theory and practice of artificial intelligence (cf. Russell and Norvig 1995, Nilsson 1998). In short, agents are software entities that display forms of intelligence/rationality and autonomy. They are able to take initiative and make decisions to take action on their own without direct control of a human user. In this subsection we will see how logic (of action) is used to describe / specify the (desired) behavior of agents (cf. Wooldridge 2002). First we focus on single agents, after which we turn to settings with multiple agents, called multi-agent systems (MAS) or even agent societies.\n4.2.1 Single agent approaches\n\nInterestingly, the origin of the intelligent agent concept lies in philosophy. \n\nFirst of all there is a direct link with practical reasoning in the classical philosophical tradition going back to Aristotle. Here one is concerned with reasoning about action in a syllogistic manner, such as the following example taken from Audi 1999, p. 729:\n\nWould that I exercise.\n\nJogging is exercise.\n\nTherefore, I shall go jogging.\n\n\nAlthough this has the form of a deductive syllogism in the familiar Aristotelian tradition of theoretical reasoning, on closer inspection it appears that this syllogism does not express a purely logical deduction. (The conclusion does not follow logically from the premises.) It rather constitutes a representation of a decision of the agent (going to jog), where this decision is based on mental attitudes of the agent, viz. his/her beliefs (jogging is exercise) and his/her desires or goals (would that I exercise). So, practical reasoning is reasoning directed toward action, the process of figuring out what to do, as Wooldridge (2000) puts it. The process of reasoning about what to do next on the basis of mental states such as beliefs and desires is called deliberation.\n\nDennett (1971) has put forward the notion of the intentional stance: the strategy of interpreting the behaviour of an entity by treating it as if it were a rational agent that governed its choice of action by a consideration of its beliefs and desires. As such it is an anthropomorphic instance of the so called design (functionality) stance, contra the physical stance, towards systems. This stance has been proved to be extremely influential, not only in cognitive science and biology/ethology (in connection with animal behavior), but also as a starting point of thinking about artificial agents.\n\nFinally, and most importantly, there is the work of the philosopher Michael Bratman (1987), which, although in the first instance aimed at human agents, lays the foundation of the BDI approach to artificial agents. In particular, Bratman makes a case for the incorporation of the notion of intention for describing agent behavior. Intentions play the important role of selection of actions that are desired, with a distinct commitment attached to the actions thus selected. Unless there is a rationale for dropping a commitment (such as the belief that an intention has been achieved already or the belief that it is impossible to achieve) the agent should persist / persevere in its commitment, stick to it, so to speak, and try realizing it,\n\nAfter Bratman\u2019s philosophy was published, researchers tried to formalize this theory using logical means. We mention here three well-known approaches. Cohen and Levesque (1991) tried to capture Bratman\u2019s theory in a linear-time style temporal logic where they added primitive operators for belief and goal as well as some operators to cater for actions, such as operators for expressing that an action is about to be performed \n\\((\\lhappens \\alpha)\\), has just been performed \\(\\ldone \\alpha)\\) and what agent is the actor of a primitive action (\\(\\lact i\\ \\alpha\\): agent \\(i\\) is the actor of \\(\\alpha\\)). From this basic set-up they build a framework in which ultimately the notion of intention is defined in terms of the other notions. In fact they define two notions: an intention_to_do and an intention_to_be. First they define the notion of an achievement goal (A-Goal): an A-Goal is something that is a goal to hold later, but is believed not to be true now. Then they define a persistent goal (P-Goal): a P-Goal is an A-Goal that is not dropped before it is believed to be achieved or believed to be impossible. Then the intention to do an action is defined as the P-Goal of having done the action, in a way such that the agent was aware of it happening. The intention to achieve a state satisfying \\(\\phi\\) is the P-Goal of having done some action that has \\(\\phi\\) as a result where the agent was aware of something happening leading to \\(\\phi\\), such that what actually happened was not something that the agent explicitly had not as a goal.\n\nNext there is Rao & Georgeff\u2019s formalization of BDI agents using the branching-time temporal logic CTL (Rao and Georgeff 1991, Rao and Georgeff 1998, Wooldridge 2000). On top of CTL they introduce modal operators for Belief \\((\\lbel)\\), Goal \\((\\lgoal)\\) (sometimes replaced by Desire \\((\\ldes)\\)) and Intention (of the to_be kind, \\(\\lintend\\)) as well as operators to talk about the success \\((\\lsucceeded(e))\\) and \nfailure \\((\\lfailed)\\) of elementary actions \\(e\\). So they do not try to define intention in terms of other notions, but rather introduce intention as a separate operator, of which the meaning is later constrained by \u2018reasonable\u2019 axioms. The formal semantics is based on Kripke models with accessibility relations between worlds for the belief, goal and intention operators. However, possible worlds here are complete time trees (modeling the various behaviors of the agent) on which CTL formulas are interpreted in the usual way. Next they propose a number of postulates/axioms that they find reasonable interactions between the operators, and constrain the models of the logic accordingly so that these axioms become validities. For example, they propose the formulas\n\\(\\lgoal(\\alpha) \\rightarrow \\lbel(\\alpha)\\)\nand\n\\(\\lintend(\\alpha) \\rightarrow \\lgoal(\\alpha)\\),\nfor a certain class of formulas \\(\\alpha\\), of which\n\\(\\alpha = \\mathop{\\mathbf{E}}(\\psi)\\) is a typical example. Here \\(\\mathop{\\mathbf{E}}\\) stands for the existential path quantifier in CTL. Rao and Georgeff also show that one can express commitment strategies in their logic. For example, the following expresses a \u2018single-minded committed\u2019 agent, that keeps committed to its intention until it believes it has achieved it or thinks it is impossible (which is very close to what we saw in the definition of intention in the approach of Cohen and Levesque):\n\n\\[\n\\lintend(\\mathop{\\mathbf{A}} \\mathbin{\\diamond} \\phi)\n\\rightarrow\n(\\lintend(\\mathop{\\mathbf{A}} \\mathbin{\\diamond} \\phi) \\luntil (\\lbel(\\phi) \\vee \\neg\\lbel(\\mathop{\\mathrm{E}} \\mathbin{\\diamond} \\phi)))\n\\]\n\n\nwhere \\(\\mathbf{A}\\) stands for the universal path quantifier in CTL.\n\nFinally there is the KARO approach by Van Linder et al. (Van der Hoek et al. 1998, Meyer et al. 1999), which takes dynamic logic as a basis instead of a temporal logic. First a core is built, consisting of the language of propositional dynamic logic augmented with modal operators for knowledge \\((\\mathbf{K})\\), belief \\((\\mathbf{B})\\) and desire \\((\\mathbf{D})\\) as well as an operator \\((\\mathbf{A})\\) that stands for ability to perform an action. Next the language is extended mostly by abbreviations (definitions in terms of the other operators) to get a fully-fledged BDI-like logic. The most prominent operators are:\n\n opportunity to do an action (meaning that there is a way the action can be executed leading to a next state)\n practical possibility to do an action with respect to an assertion (the conjunction of ability and opportunity of doing the action, together with the statement that the execution of the action leads to the truth of the assertion)\ncan do an action with respect to an assertion (knowing to have the practical possibility to do the action with respect to the assertion at hand)\nrealizability of an assertion (the existence of a plan, i.e. a sequence of atomic actions, which the agent has the practical possibility to perform with respect to the assertion at hand)\ngoal with respect to an assertion (the conjunction of the assertion being desirable, not true yet, but realizable)\npossibly intend to do an action with respect to an assertion (expressing that the agent can do the action with respect to the assertion of which he knows it to be a goal of his)\n\n\nThe framework furthermore has special actions \\(\\lcommit\\) and \\(\\luncommit\\) to control the agent\u2019s commitments. The semantics of these actions is such that the agent obviously can only commit to an action \\(\\alpha\\) if there is good reason for it, viz. that there is a possible intention of \\(\\alpha\\) with a known goal \\(\\phi\\) as result. Furthermore the agent cannot uncommit to a certain action \\(\\alpha\\) that is part of the agent\u2019s commitments, as long there is a good reason for it to be committed to \\(\\alpha\\), i.e. as long as there is some possible intention where \\(\\alpha\\) is involved. This results in having the following validities in KARO: (Here \\(\\mathbf{I}(\\alpha, \\phi)\\) denotes the possibly intend operator and \\(\\mathbf{Com}(\\alpha)\\) is an operator that expresses that the agent is committed to the action \\(\\alpha\\), which is similar to Cohen & Levesque\u2019s intention-to-do operator \\(\\lintend_1\\) in Cohen and Levesque 1990.)\n\n\\[\\begin{align*}\n&\\vDash \\mathbf{I}(\\alpha,\\phi) \\rightarrow \\langle \\lcommit(\\alpha)\\rangle \\mathbf{Com}(\\alpha) \\\\\n&\\vDash \\mathbf{I}(\\alpha,\\phi) \\rightarrow \\neg \\mathbf{A} \\luncommit(\\alpha) \\\\\n&\\vDash \\mathbf{Com}(\\alpha) \\rightarrow \\langle\\luncommit(\\alpha)\\rangle \\neg \\mathbf{Com}(\\alpha) \\\\\n&\\vDash \\mathbf{Com}(\\alpha_1 \\ ;\\ \\alpha_2) \\rightarrow \\mathbf{KCom}(\\alpha_1) \\wedge \\mathbf{K}[\\alpha_1]\\mathbf{Com}(\\alpha_2)\n\\end{align*}\\]\n\n\nInformally these axioms say the following: if the agent possibly intends an action for fulfilling a certain goal then it has the opportunity to commit to this action, after which it is recorded on its agenda; as long as an agent possibly intends an action it is not able to uncommit to it (this reflects a form of persistence of commitments: as long as there is a good reason for a plan on the agenda it will have to stay on!); if the agent is committed to an action it has the opportunity to uncommit to it (but it may lack the ability to do this, cf. the previous axiom); if an agent is committed to a sequence of two actions then it knows that it is committed to the first and it also knows that after performing the first action it will be committed to the second.\n\nBesides this focus on motivational attitudes in the tradition of agent logics in BDI style, the KARO framework also provides an extensive account of epistemic and doxastic attitudes. This is worked out most completely in Van Linder et al. 1995. This work hooks into a different strand of research in between artificial intelligence and philosophy, viz. Dynamic Epistemic Logic, the roots of which lie in philosophy, linguistics, computer science and artificial intelligence! Dynamic Epistemic Logic (DEL) is the logic of knowledge change; it is not about one particular logical system, but about a whole family of logics that allow us to specify static and dynamic aspects of knowledge and beliefs of agents (cf. Van Ditmarsch et al. 2007). The field combines insights from philosophy (about belief revision, AGM-style (AGM 1985), as we have seen in Section 1), dynamic semantics in linguistics and the philosophy of language (as we have seen in Section 2), reasoning about programs by using dynamic logic (as we have seen in Section 3) with ideas in artificial intelligence about how knowledge and actions influence each other (Moore 1977). More generally we can see the influence of the logical analysis of information change as advocated by van Benthem and colleagues (van Benthem 1989, van Benthem 1994, Faller et al. 2000). Also Veltman\u2019s update semantics of default reasoning (Veltman 1996), an important reasoning method in artificial intelligence (Reiter 1980, Russell and Norvig 1995), can be viewed as being part of this paradigm.\n\nFor the purpose of this entry, it is interesting to note that the general approach taken is to apply a logic of action, viz. dynamic logic, to model information change. This amounts to an approach in which the epistemic (or doxastic) updates are reified into the logic as actions that change the epistemic/doxastic state of the agent. So, for example in Van Linder et al. 1995 we encounter the actions such as \\(\\lexpand(\\phi)\\), \\(\\lcontract(\\phi)\\), \\(\\lrevise(\\phi)\\), referring to expanding, contracting and revising, respectively, one\u2019s belief with the formula \\(\\phi\\). These can be reasoned about by putting them in dynamic logic boxes and diamonds, so that basically extensions of dynamic logic are employed for reasoning about these updates. It is further shown that these actions satisfy the AGM postulates so that this approach can be viewed as a modal counterpart of the AGM framework. Very similar in spirit is the work of Segerberg (1995) on Dynamic Doxastic Logic (DDL), the modal logic of belief change. In DDL modal operators of the form [\\(+\\phi\\)], [*\\(\\phi\\)] and [\\(-\\phi\\)] are introduced with informal meanings: \u201cafter the agent has expanded/revised/contracted his beliefs by \\(\\phi\\)\u201d, respectively. Combined with the \u2018standard\u2019 doxastic operator \\(B\\), where \\(B\\phi\\) is interpreted as \u201c\\(\\phi\\) is in the agent\u2019s belief set\u201d, one can now express properties like [\\(+\\phi]B\\psi\\) expressing that after having expanded its beliefs by \\(\\phi\\) the agent believes \\(\\psi\\) (also cf. Hendricks and Symons 2006).\n\nFinally in this subsection we mention recent work where the KARO formalism is used as a basis for describing also other aspects of cognitive behavior of agents, going \u2018beyond BDI\u2019, viz. attitudes regarding emotions (Meyer 2006, Steunebrink et al. 2007, Steunebrink et al. 2012). The upshot of this approach is that an expressive logic of action such as KARO can be fruitfully employed to describe how emotions such as joy, gratification, anger, and remorse, are triggered by certain informational and motivational attitudes such as certain beliefs and goals (\u2018emotion elicitation\u2019) and how, once elicited, the emotional state of an agent may influence its behavior, and in particular its decisions about the next action to take.\n4.2.2 Multi-agent approaches\n\nApart from logics to specify attitudes of single agents, also work has been done to describe the attitudes of multi-agent systems as wholes. First we mention the work by Cohen & Levesque in this direction (Levesque et al. 1990, Cohen and Levesque 1991). This work was a major influence on a multi-agent version of KARO (Aldewereld et al. 2004). An important complication in a notion of joint goal involves that of persistence of the goal: where in the single agent case the agent pursues its goal until it believes it has achieved it or believes it can never be achieved, in the context of multiple agents, the agent that realizes this, has to inform the others of the team about it so that the group/team as a whole will believe that this is the case and may drop the goal. This is captured in the approaches mentioned above. Related work, but not a logic of action in the strict sense, concerns the logical treatment of collective intentions (Keplicz and Verbrugge 2002).\n\nIt must also be mentioned here that inspired by several sources among which the work on knowledge and belief updates for individual agents as described by DEL and DDL, combined with work on knowledge in groups of agents such as common knowledge (see, e.g., Meyer and Van der Hoek 1995), a whole new subfield has arisen, which can be seen as the multi-agent (counter)part of Dynamic Epistemic Logic. This deals with matters such as the logic of public announcement, and more generally actions that have effect on the knowledge of groups of agents. This has generated quite some work by different authors such as Plaza (1989), Baltag (1999), Gerbrandy (1998), Van Ditmarsch (2000), and Kooi (2003). For example, public announcement logic (Plaza 1989) contains an operator of the form [\\(\\phi]\\psi\\), where both \\(\\phi\\) and \\(\\psi\\) are formulas of the logic, expressing \u201cafter announcement of \\(\\phi\\), it holds that \\(\\psi\\)\u201d. This logic can be seen as a form of dynamic logic again, where the semantic clause for [\\(\\phi]\\psi\\) reads (in informal terms): [\\(\\phi]\\psi\\) is true in a model-state pair iff the truth of \\(\\phi\\) in that model-state pair implies the truth of \\(\\psi\\) in a model-state pair, where the state is the same, but the model is transformed to capture the information contained in \\(\\phi\\). Also in the other approaches the transformation of models induced by communicated information plays an important role, notably in the approach by Baltag et al. on action models (Baltag 1999, Baltag and Moss 2004). A typical element in this approach is that in action model logic one has both epistemic and action models and that the update of an epistemic model by an epistemic action (an action that affects the epistemic state of a group of agents) is represented by a (restricted) modal product of that epistemic model and an action model associated with that action. (See Van Ditmarsch et al. 2007, p. 151; this book is a recent comprehensive reference to the field.)\n\nFinally we mention logics that incorporate notions from game theory to reason about multi-agent systems, such as game logic, coalition logic (Pauly 2001) and alternating temporal logic (ATL, which we also encountered at the end of the section on mainstream computer science!), and its epistemic variant ATEL (Van der Hoek and Wooldridge 2003, Van der Hoek et al. 2007). For instance, game logic is an extension of PDL to reason about so-called determined 2-player games. Interestingly there is a connection between these logics and the stit approach we have encountered in philosophy. For instance, Broersen, partially jointly with Herzig and Troquard, has shown several connections such as embeddings of Coalition Logic and ATL in forms of stit logic (Broersen et al. 2006a,b) and extensions of stit (and ATL) to cater for reasoning about interesting properties of multi-agent systems (Broersen 2009, 2010). This area currently is growing fast, also aimed at the application of verifying multi-agent systems (cf. Van der Hoek et al. 2007), viz. Dastani et al. 2010. The latter constitutes still somewhat of a holy grail in agent technology. On the one hand there are many logics to reason about both single and multiple agents, while on the other hand multi-agent systems are being built that need to be verified. To this day there is still a gap between theory and practice. Much work is being done to render logical means combining the agent logics discussed and the logical techniques from mainstream computer science for the verification of distributed systems (from section 3), but we are not there yet\u2026!\nConclusion\n\nIn this entry we have briefly reviewed the history of the logic of action, in philosophy, in linguistics, in computer science and in artificial intelligence. Although the ideas and techniques we have considered were developed in these separate communities in a quite independent way, we feel that they are nevertheless very much related, and by putting them together in this entry we hope we have contributed in a modest way to some cross-fertilization between these communities regarding this interesting and important subject.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Alchourr\u00f3n, C., G\u00e4rdenfors, P., and Makinson, D., 1985, \u201cOn the Logic of Theory Change: Partial Meet Contraction and Revision Functions\u201d, <em>Journal of Symbolic Logic</em>, 50: 510\u2013530.",
                "Aldewereld, H. M., Van der Hoek, W., and Meyer, J.-J. Ch., 2004, \u201cRational Teams: Logical Aspects of Multi-Agent Systems\u201d, <em>Fundamenta Informaticae</em>, 63(2\u20133): 159\u2013183.",
                "Alur, R., Henzinger, T., and Kupferman, O., 1998, \u201cAlternating-time Temporal Logic\u201d, in W.-P. de Roever, H. Langmaack and A. Pnueli (eds.), <em>Compositionality: The Significant Difference, Proceedings COMPOS-97</em> (Lecture Notes in Computer Science 1536), Berlin: Springer, pp. 23\u201360.",
                "Anderson, A. R., 1962, \u201cLogic, norms, and roles\u201d, <em>Ratio</em>, 4: 36\u201349.",
                "Audi, R. (ed.), 1999, <em>The Cambridge Dictionary of Philosophy</em>, Cambridge: Cambridge University Press.",
                "Austin, J. L., 1957, <em>How to Do Things with Words</em>, Oxford: Oxford University Press.",
                "Bakker, J. W. de, 1980, <em>Mathematical Theory of Program Correctness</em>, Englewood Cliffs, NJ: Prentice-Hall International.",
                "Balbiani, P., Baltag, A., van Ditmarsch, H., Herzig, A., Hosi, T. and de Lima, S., 2008, \u201c\u2018Knowable\u2019 as \u2018Known After an Announcement\u2019\u201d, <em>The Review of Symbolic Logic</em>, 1: 305\u2013334",
                "Baltag, A., 1999, \u201cA Logic of Epistemic Actions\u201d, in W. van der Hoek, J.-J. Meyer, and C. Witteveen (eds.), <em>Foundations and Applications of Collective Agent-Based Systems</em> (Proceedings of the Workshop at the 11th European Summer School in Logic, Language, and Computation, Utrecht, 1999). ",
                "Baltag, A. and Moss, L. S., 2004, \u201cLogics for Epistemic Programs\u201d, <em>Synthese</em>, 139: 165\u2013224.",
                "Belnap, N., Perloff, M., and Xu, M., 2001, <em>Facing the future</em>, Oxford: Oxford University Press.",
                "Bradfield, J. and Stirling, C., 2007, \u201cModal \\(\\mu\\)-calculi\u201d, in P. Blackburn, J. F. A. K. van Benthem, and F. Wolter (eds.), <em>Handbook of Modal Logic</em>, Amsterdam: Elsevier, pp. 721\u2013756.",
                "Bratman, M. E., 1987, <em>Intentions, Plans, and Practical Reason</em>, Cambridge, Massachusetts: Harvard University Press.",
                "Broersen, J.M., 2004, \u201cAction Negation and Alternative Reductions for Dynamic Deontic Logics\u201d, <em>Journal of Applied Logic</em>, 2(1): 153\u2013168.",
                "\u2013\u2013\u2013, 2009, \u201cA Complete STIT Logic for Knowledge and Action, and Some of Its Applications\u201d, in M. Baldoni, T. Cao Son, M.B. van Riemsdijk and M. Winikoff (eds.), <em>Declarative Agent Languages and Technologies VI</em>, 6th International Workshop, DALT 2008, Estoril, Portugal, May 12, 2008, Revised Selected and Invited Papers: Springer, Berlin, pp. 47\u201359.",
                "\u2013\u2013\u2013, 2010, \u201cCTL.STIT: enhancing ATL to express important multi-agent system verification properties\u201d, in <em>Proceedings 9th International Conference on Autonomous Agents and Multiagent Systems</em>. New York: ACM Press, pp. 683\u2013690.",
                "Broersen, J.M., Herzig, A. and Troquard, N., 2006a, \u201cFrom Coalition Logic to STIT\u201d, <em>Electronic Notes in Theoretical Computer Science</em>, 157(4): 23\u201335.",
                "\u2013\u2013\u2013, 2006b, \u201cEmbedding Alternating-time Temporal Logic in strategic STIT logic of agency\u201d, <em>Journal of logic and computation</em>, 16: 559\u2013578.",
                "Chellas, B. F., 1969, <em>The Logical Form of Imperatives</em>, Stanford, CA: Perry Lane Press.",
                "\u2013\u2013\u2013, 1980, <em>Modal Logic: An Introduction</em>, Cambridge and London: Cambridge University Press.",
                "Clark, Herbert H., 1996, <em>Using Language</em>, Cambridge University Press.",
                "Cohen, P. R. and Levesque, H. J., 1990, \u201cIntention is Choice with Commitment\u201d, <em>Artificial Intelligence</em>, 42(3): 213\u2013261.",
                "Cohen, P. and Levesque, H., 1991, \u201cTeamwork\u201d, <em>No\u00fbs</em>, 24(4): 487\u2013512.",
                "Cousot, P., 1990, \u201cMethods and Logic for Proving Programs\u201d, in J. van Leeuwen (ed.), <em>Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics</em>, Amsterdam: Elsevier, pp. 841\u2013993. ",
                "Dastani, M.M., Hindriks, K.V. and Meyer, J.-J. Ch. (eds.), 2010, <em>Specification and Verification of Multi-Agent Systems</em>, New York/Dordrecht/Heidelberg/London: Springer.",
                "Davidson, D., 1967, \u201cThe Logical Form of Action Sentences\u201d, in N. Rescher (ed.), <em>The Logic of Decision and Action</em>, Pittsburgh: University of Pittsburgh Press, pp. 81\u2013120.",
                "Dennett, D. C., 1971, \u201cIntentional Systems\u201d, <em>Journal of Philosophy</em>, 68(4): 87\u2013106.",
                "\u2013\u2013\u2013, 1984, \u201cCognitive Wheels: The Frame Problem of AI\u201d, in C. Hookway (ed.), <em>Minds, Machines, and Evolution: Philosophical Studies</em>, Cambridge: Cambridge University Press.",
                "Dijkstra, E. W., 1976, <em>A Discipline of Programming</em>, Englewood Cliffs, NJ: Prentice-Hall.",
                "Dunin-Ke\u0327plicz, B. and Verbrugge, R., 2002, \u201cCollective Intentions\u201d, <em>Fundamenta Informaticae</em>, 51(3): 271\u2013295.",
                "Emerson, E. A., 1990, \u201cTemporal and Modal Logic\u201d, in J. van Leeuwen (ed.), <em>Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics</em>, Amsterdam: Elsevier, pp. 995\u20131072.",
                "Faller, M., Kaufmann, S., and Pauly, M. (eds.), 2000, <em>Formalizing the Dynamics of Information</em>, Stanford, CA: CSLI Publications.",
                "Fischer, M. J. and Ladner, R. E., 1977, \u201cPropositional Modal Logic of Programs\u201d, in <em>Proceedings of the 9th ACM Annual Symposium on Theory of Computing</em>, New York: Association for Computing Machinery, pp. 286\u2013294.",
                "Fitch, F. B., 1963, \u201cA logical analysis of some value concepts\u201d, <em>Journal of Symbolic Logic</em>, 28: 135\u2013142.",
                "Floyd, R. W., 1967, \u201cAssigning Meanings to Programs\u201d, in J. T. Swartz (ed.), <em>Proceedings Symposium in Applied Mathematics</em>, American Mathematical Society, pp. 19\u201332.",
                "Goldstein, H. H. and Neumann J. Von, 1963, \u201cPlanning and Coding Problems for an Electronic Computer Instrument\u201d, in A. M. Taub (ed.), <em>John von Neumann Collected Works</em> (Vol. 5), Oxford: Pergamon Press, pp. 80\u2013235.",
                "Groenendijk, J. and Stokhof, M., 1991, \u201cDynamic Predicate Logic\u201d, <em>Linguistics and Philosophy</em>, 14: 39\u2013100.",
                "G\u00e4rdenfors, P., 1988, <em>Knowledge in Flux</em>, Cambridge, Massachusetts: MIT Press.",
                "Gerbrandy, J. D., 1998, <em>Bisimulations on Planet Kripke</em>, Ph.D. Thesis, Amsterdam: University of Amsterdam.",
                "Harel, D., 1979, <em>First-Order Dynamic Logic</em>, Berlin: Springer-Verlag.",
                "\u2013\u2013\u2013, 1984, \u201cDynamic Logic\u201d, in D. Gabbay and F. Guenthner (eds.), <em>Handbook of Philosophical Logic</em> (Vol. II), Dordrecht and Boston: Reidel, pp. 497\u2013604.",
                "Harel, D., Kozen, D., and Tiuryn, J., 2000, <em>Dynamic Logic</em>, Cambridge, Massachusetts: MIT Press.",
                "Heim, I., 1983, \u201cOn the projection problem for presuppositions\u201d, in M. Barlow, D. Flickinger and D. Westcoat (eds.), <em>Proceedings of the 2nd West Coast Conference on Formal Linguistics</em>, Stanford, CA: Stanford University, pp. 114\u2013126.",
                "Hendricks, V. and J. Symons, J., 2006, \u201cEpistemic Logic\u201d, in <em>The Stanford Encyclopedia of Philosophy</em> (Spring 2009 Edition), Edward N. Zalta (ed.), URL = &lt;<a href=\"https://plato.stanford.edu/archives/spr2009/entries/logic-epistemic/\">https://plato.stanford.edu/archives/spr2009/entries/logic-epistemic/</a>&gt;.",
                "Hennessy, M. and Milner, R., 1980, \u201cOn Observing Nondeterminism and Concurrency\u201d, in <em>Proceedings ICALP \u201880</em> (Lecture Notes in Computer Science: 85), Berlin: Springer, pp. 295\u2013309.",
                "Henry, D. P., 1967, <em>The Logic of St. Anselm</em>, Oxford: Oxford University Press.",
                "Hitchcock, P. and Park, D., 1972, \u201cInduction Rules and Termination Proofs\u201d, in M. Nivat (ed.), <em>Proceedings First International Colloquium on Automata, Languages and Programming</em>, Amsterdam: North-Holland, pp. 225\u2013251.",
                "Hoare, C. A. R., 1969, \u201cAn Axiomatic Basis for Computer Programming\u201d, <em>Communications of the ACM</em>, 12: 576\u2013580.",
                "Horty, J. F., 2001, <em>Agency and Deontic Logic</em>, Oxford: Oxford University Press.",
                "Kamp, H., 1981, \u201cA theory of truth and semantic representation\u201d, in J. Groenendijk (ed.), <em>Formal Methods in the Study of Language</em>, Amsterdam: Mathematisch Centrum.",
                "Kanger, S., 1957, \u201cNew foundations for ethical theory\u201d, Technical Report, Stockholm University; reprinted in R. Hilpinen (ed.), <em>Deontic Logic: Introductory and Systematic Readings</em>, D. Reidel: Dordrecht, 1971, pp. 36-58.",
                "\u2013\u2013\u2013, 1972, \u201cLaw and logic\u201d, <em>Theoria</em>, 38: 105\u2013132",
                "Kooi, B., 2003, <em>Knowledge, Chance, and Change</em>, Ph.D. Thesis, Groningen: University of Groningen.",
                "Kowalski, R. and Sergot, M., 1986, \u201cA Logic-Based Calculus of Events\u201d, <em>New Generation Computing</em>, 4: 67\u201395.",
                "Kozen, D., 1983, \u201cResults on the Propositional \\(\\mu\\)-calculus\u201d, <em>Theoretical Computer Science</em>, 27: 333\u2013354.",
                "Kozen, D. and Tiuryn, J., 1990, \u201cLogics of Programs\u201d, in J. van Leeuwen (ed.), <em>Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics</em>, Amsterdam: Elsevier, pp. 789\u2013840.",
                "Kracht, M., 1993, \u201cLogic and Control: How They Determine the Behaviour of Presuppositions\u201d, in J. van Eijck and A. Visser, (eds.), <em>Logic and Information Flow</em>, Cambridge, Massachusetts: MIT Press, pp. 89\u2013111.",
                "Krifka, M., 1986, <em>Nominalreferenz und Zeitkonstitution. Zur Semantik von Massentermen</em>, Ph.D. Thesis, M\u00fcnchen, Universit\u00e4t M\u00fcnchen.",
                "\u2013\u2013\u2013, 1992, \u201cThematic Relations as Links between Nominal Reference and Temporal Constitution\u201d, in I. Sag and A. Szaboclcsi (eds.), <em>Lexical Matters</em>, Stanford: Stanford University Press, pp. 29\u201353.",
                "Kvarnstr\u00f6m, J. and Doherty, P., 2000, \u201cTALplanner: A Temporal Logic-Based Forward-Chaining Planner\u201d, <em>Annals of Mathematics and Artificial Intelligence</em>, 30: 119\u2013169.",
                "Lamport, L., 1977, \u201cProving the Correctness of Multiprocess Programs\u201d, <em>IEEE Transactions on Software Engineering</em>, SE-3(2): 125\u2013143.",
                "Levesque, H. J., Cohen, P. R., and Nunes, J. H. T., 1990, \u201cOn Acting Together\u201d, in <em>Proceedings AAAI \u201890</em>, pp. 94\u201399.",
                "Lindahl. L., 1977, <em>Position and Change: A Study in Law and Logic</em>, Dordrecht and Boston: Reidel.",
                "Lindstr\u00f6m, S. and Segerberg, K., 2006, \u201cModal Logic and Philosophy\u201d, in P. Blackburn, J. van Benthem, and F. Wolter (eds.), <em>Handbook of Modal Logic</em> (Studies in Logic and Practical Reasoning: 3), Amsterdam: Elsevier, pp. 1153\u20131218.",
                "McCarthy, J., 1963a, \u201cTowards a Mathematical Science of Computation\u201d, in C. M. Popplewell (ed.), <em>Proceedings of IFIP Congress \u201862</em>, Amsterdam: North-Holland, pp. 21\u201328.",
                "\u2013\u2013\u2013, 1963b, \u201cSituations, Actions, and Causal Laws\u201d, Technical Report Memo 2, Stanford University Artificial Intelligence Project, Stanford University; reprinted in M. Minsky (ed.), <em>Semantic Information Processing</em>, Cambridge, MA: MIT Press, 1968, pp. 410-417.",
                "\u2013\u2013\u2013, 1986, \u201cPrograms with Common Sense\u201d, in M. L. Minsky (ed.), <em>Semantic Information Processing</em>, Cambridge, Massachusetts: MIT Press, pp. 403\u2013418.",
                "McCarthy J. and Hayes, P. J., 1969, \u201cSome Philosophical Problems from the Standpoint of Artificial Intelligence\u201d, in B. Meltzer, D. Michie and M. Swann (eds.), <em>Machine Intelligence 4</em>, Edinburgh: Edinburgh University Press, pp. 463\u2013502.",
                "Merin, A., 1994, \u201cAlgebra of elementary social acts\u201d, in S. L. Tsohatzidis (ed.), <em>Foundations of Speech Act Theory: Philosophical and Linguistic Perspectives</em>, London: Routledge, pp. 234\u2013264. ",
                "Meyer, J.-J. Ch., 1985, <em>Programming Calculi Based on Fixed Point Transformations: Semantics and Applications</em>, Ph.D. Thesis, Amsterdam: Vrije Universiteit Amsterdam.",
                "\u2013\u2013\u2013, 1988, \u201cA Different Approach to Deontic Logic: Deontic Logic Viewed as a Variant of Dynamic Logic\u201d, <em>Notre Dame Journal of Formal Logic</em>, 29(1): 109\u2013136.",
                "\u2013\u2013\u2013, 2000, \u201cDynamic Logic for Reasoning about Actions and Agents\u201d, in J. Minker, (ed.), <em>Logic-Based Artificial Intelligence</em>, Boston and Dordrecht: Kluwer, pp. 281\u2013311. ",
                "\u2013\u2013\u2013, 2006, \u201cReasoning about Emotional Agents\u201d, <em>International Journal of Intelligent Systems</em>, 21(6): 601\u2013619.",
                "Meyer, J.-J. Ch. and Van der Hoek, W., 1995, <em>Epistemic Logic for AI and Computer Science</em>, Cambridge: Cambridge University Press.",
                "Meyer, J.-J. Ch., Van der Hoek, W., and Van Linder, B., 1999, \u201cA Logical Approach to the Dynamics of Commitments\u201d, <em>Artificial Intelligence</em>, 113: 1\u201340.",
                "Meyer, J.-J. Ch. and Veltman, F., 2007, \u201cIntelligent Agents and Common Sense Reasoning\u201d, in P. Blackburn, J. van Benthem and F. Wolter (eds.), <em>Handbook of Modal Logic</em>, Amsterdam: Elsevier, pp. 991\u20131029.",
                "Moens, M. and Steedman, M., 1988, \u201cTemporal ontology and temporal reference\u201d, <em>Computational Linguistics</em>, 14: 15\u201328.",
                "Moore, R. C., 1977, \u201cReasoning about Knowledge and Action\u201d, in <em>Proceedings of the 5th International Joint Conference on Artificial Intelligence (IJCAI-77)</em>, Cambridge, Massachusetts: William Kaufmann, pp. 223\u2013227.",
                "Muskens, R., van Benthem, J., and Visser, A., 1997, \u201cDynamics\u201d, in J. van Benthem and A. ter Meulen (eds.), <em>Handbook of Logic and Language</em>, Amsterdam: Elsevier, pp. 587\u2013648.",
                "Naumann, R., 2001, \u201cAspects of changes: a dynamic event semantics\u201d, <em>Journal of Semantics</em>, 18: 27\u201381.",
                "Naur, P., 1966, \u201cProof of Algorithms by General Snapshots\u201d, <em>BIT Numerical Mathematics</em>, 6: 310\u2013316.",
                "Nilsson, N. J., 1998, <em>Artificial Intelligence: A New Synthesis</em>, San Francisco: Morgan Kaufmann.",
                "Park, D., 1976, \u201cFiniteness is \\(\\mu\\)-ineffable\u201d, <em>Theoretical Computer Science</em>, 3: 173\u2013181.",
                "Parsons, T., 1990, <em>Events in the Semantics of English: A Study in Subatomic Semantics</em> (Current Studies in Linguistics: 19), Cambridge, Massachusetts: MIT Press.",
                "Pauly, M., 2001, <em>Logic for Social Software</em>, ILLC Dissertations Series, Amsterdam.",
                "Plaza, J. A., 1989, \u201cLogics of Public Communication\u201d, in M. L. Emlich, <em>et al</em>. (eds.), <em>Proceedings of the 4th International Symposium on Methodologies for Intelligent Systems</em>, Amsterdam: North-Holland Publishing, pp. 201\u2013216.",
                "Pnueli, A., 1977, \u201cThe Temporal Logic of Programs\u201d, in <em>Proceedings of the 18th Annual IEEE Symposium on Foundations of Computer Science</em>, Piscataway, New Jersey: IEEE, pp. 46\u201357.",
                "P\u00f6rn, I., 1977, <em>Action Theory and Social Science</em>, Dordrecht: Reidel.",
                "Pratt, V. R., 1976, \u201cSemantical Considerations on Floyd-Hoare Logic\u201d, in <em>Proceedings of the 17th Annual IEEE Symposium on Foundations of Computer Science</em>, New York: ACM, pp. 109\u2013121.",
                "\u2013\u2013\u2013, 1979a, \u201cDynamic Logic\u201d, in J. W. de Bakker and J. van Leeuwen (eds.), <em>Proceedings Foundations of Computer Science III</em> Mathematical Centre Tracts 108, Amsterdam: Mathematisch Centrum, pp. 53\u201382.",
                "\u2013\u2013\u2013, 1979b, \u201cProcess Logic: Preliminary Report\u201d, in <em>Proceedings of the 6th Symposium on Principles of Programming Languages</em>, New York: ACM, pp. 93\u2013100.",
                "Rao, A. S. and Georgeff, M. P., 1991, \u201cModeling rational agents within a BDI-architecture\u201d, in J. Allen, R. Fikes and E. Sandewall (eds.), <em>Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning (KR \u201891)</em>, San Francisco: Morgan Kaufmann, pp. 473\u2013484.",
                "\u2013\u2013\u2013, 1998, \u201cDecision Procedures for BDI Logics\u201d, <em>Journal of Logic and Computation</em>, 8(3): 293\u2013344.",
                "Reiter, R., 1980, \u201cA Logic for Default Reasoning\u201d, <em>Artificial Intelligence</em>, 13(1\u20132): 81\u2013132.",
                "\u2013\u2013\u2013, 2001, <em>Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems</em>, Cambridge, Massachusetts: MIT Press. ",
                "Roever, W.-P. de, Boer, F. S. de, <em>et al.</em>, 2001, <em>Concurrency Verification: Introduction to Compositional and Noncompositional Methods</em>, Cambridge: Cambridge University Press.",
                "Russell, S. and Norvig, P., 1995, <em>Artificial Intelligence: A Modern Approach</em>, Englewood Cliffs, NJ: Prentice-Hall.",
                "Salwicki, A., 1970, \u201cFormalized Algorithmic Languages\u201d, <em>Bulletin de l\u2019Acad\u00e9mie Polonaise des Sciences</em> (S\u00e9rie des sciences math\u00e9matiques, astronomiques et physiques), 18(5): 227\u2013232.",
                "Sandewall, E. and Shoham, Y., 1994, \u201cNonmonotonic Temporal Reasoning\u201d, in D. M. Gabbay, C. J. Hogger and J. A. Robinson (eds.), <em>Handbook of Logic in Artificial Intelligence and Logic Programming, Volume 4: Epistemic and Temporal Reasoning</em>, Oxford: Oxford University Press.",
                "Scott, D. S. and Bakker, J. W. de, 1969, <em>A Theory of Programs</em>, Vienna: IBM.",
                "Searle, J. R., 1969, <em>Speech Acts: An Essay in the Philosophy of Language</em>, Cambridge: Cambridge University Press.",
                "Searle, J. R. and Vanderveken D., 1985, <em>Foundations of Illocutionary Logic</em>, Cambridge: Cambridge University Press.",
                "Segerberg, K., 1992, \u201cGetting started: beginnings in the logic of action\u201d, <em>Studia Logica</em>, 51: 347\u2013378.",
                "\u2013\u2013\u2013, 1995, \u201cBelief Revision from the Point of View of Doxastic Logic\u201d, <em>Bulletin of the IGPL</em>, 3: 535\u2013553.",
                "Shanahan, M., 1990, \u201cRepresenting continuous change in the event calculus\u201d, in <em>Proceedings of ECAI \u201990</em>, pp. 598\u2013603.",
                "\u2013\u2013\u2013, 1995, \u201cA circumscriptive calculus of events\u201d, <em>Artificial Intelligence</em>, 77: 249\u2013284.",
                "Shoham, Y., 1993, \u201cAgent-Oriented Programming\u201d, <em>Artificial Intelligence</em>, 60(1): 51\u201392.",
                "Steunebrink, B., Dastani, M. and Meyer, J.-J. Ch., 2007, \u201cA Logic of Emotions for Intelligent Agents\u201d, in Holte, R. C. and Howe, A. E. (eds.), <em>Proceedings AAAI \u201807</em>, Vancouver: AAAI Press, pp. 142\u2013147.",
                "Steunebrink, B.R., Dastani, M.M. and Meyer, J.-J. Ch., 2012, \u201cA Formal Model of Emotion Triggers for BDI Agents with Achievement Goals\u201d, Synthese/KRA 185 (1): 83\u2013129 (KRA: 413\u2013459).",
                "Thielscher, M., 2005, <em>Reasoning Robots, The Art and Science of Programming Robotic Agents</em>, Dordrecht: Springer.",
                "Thomason, R., 2003, \u201cLogic and Artificial Intelligence\u201d, in <em>The Stanford Encyclopedia of Philosophy</em> (Spring 2009 Edition), Edward N. Zalta (ed.), URL = &lt;<a href=\"https://plato.stanford.edu/archives/spr2009/entries/logic-ai/\">https://plato.stanford.edu/archives/spr2009/entries/logic-ai/</a>&gt;.",
                "Turing, A. M., 1949, \u201cOn Checking a Large Routine\u201d, Report of a Conference on High-Speed Automatic Calculating Machines, Cambridge: University Mathematical Laboratory, pp. 67\u201369.",
                "van Benthem, J., 1989, \u201cSemantic Parallels in Natural Language and Computation\u201d, in H. D. Ebbinghaus, <em>et al</em>. (eds.), <em>Logic Colloquium \u201887</em>, Amsterdam: North-Holland, pp. 331\u2013375.",
                "\u2013\u2013\u2013, 1994, \u201cLogic and the Flow of Information\u201d, in D. Prawitz, <em>et al</em>. (eds.), <em>Proceedings of the 9th International Congress of Logic, Methodology and Philosophy of Science</em>, Amsterdam: Elsevier.",
                "van der Hoek, W., van Linder, B., and Meyer, J.-J. Ch., 1998, \u201cAn Integrated Modal Approach to Rational Agents\u201d, in M. Wooldridge and A. Rao (eds.), <em>Foundations of Rational Agency</em> (Applied Logic Series: 14), Dordrecht: Kluwer, pp. 133\u2013168.",
                "van der Hoek, W. and Pauly, M., 2007, \u201cModal Logic for Games and Information\u201d, in P. Blackburn, J. van Benthem, and F. Wolter (eds.), <em>Handbook of Modal Logic</em>, Amsterdam: Elsevier, pp. 1077\u20131148.",
                "van der Hoek, W., and Wooldridge, M. J., 2003, \u201cCooperation, Knowledge, and Time: Alternating-Time Temporal Epistemic Logic and Its Applications\u201d, <em>Studia Logica</em>, 75(1): 125\u2013157.",
                "van der Sandt, R. A., 1991, \u201cDenial\u201d, in <em>Papers from the 27th Regional Meetings of the Chicago Linguistic Society Meetings</em> (Volume 2: Parasession on Negation), Chicago Linguistics Society, pp. 331\u2013344.",
                "van Ditmarsch, H. P., 2000, <em>Knowledge Games</em>, Ph.D. Thesis, Groningen: University of Groningen.",
                "van Ditmarsch, H., Van der Hoek, W., and Kooi, B., 2007, <em>Dynamic Epistemic Logic</em>, Dordrecht: Springer.",
                "van Eijck, J., 1994, \u201cPresupposition failure: a comedy of errors\u201d, <em>Formal Aspects of Computing</em>, 3: 766\u2013787.",
                "van Lambalgen, M. and Hamm, F., 2005, <em>The Proper Treatment of Events</em>, Oxford: Blackwell.",
                "van Linder, B., Van der Hoek, W., and Meyer, J.-J. Ch., 1995, \u201cActions That Make You Change Your Mind\u201d, in A. Laux and H. Wansing (eds.), <em>Knowledge and Belief in Philosophy and Artificial Intelligence</em>, Berlin: Akademie Verlag, pp. 103\u2013146.",
                "Vanderveken, D., 1990, <em>Meaning and Speech Acts, Volume 1: Principles of Language Use</em>, Cambridge: Cambridge University Press.",
                "\u2013\u2013\u2013, 1991, <em>Meaning and Speech Acts, Volume 2: Formal Semantics of Success and Satisfaction</em>, Cambridge: Cambridge University Press.",
                "Veltman, F., 1985, <em>Logics for Conditionals</em>, Ph.D. Thesis, Amsterdam: University of Amsterdam.",
                "\u2013\u2013\u2013, 1996, \u201cDefaults in Update Semantics\u201d, <em>Journal of Philosophical Logic</em>, 25: 221\u2013261.",
                "Vendler, Z., 1957, \u201cVerbs and times\u201d, <em>Philosophical Review</em>, 66: 143\u2013160.",
                "Verkuyl, H., 1993, <em>A Theory of Aspectuality: The Interaction Between Temporal and Atemporal Structure</em>, Cambridge: Cambridge University Press.",
                "Walton, D., 1976, \u201cSt. Anselm and the logical syntax of agency\u201d, <em>Franciscan Studies</em>, 36: 298\u2013312.",
                "Wooldridge, M. J., 2000, <em>Reasoning about Rational Agents, Cambridge</em>, Massachusetts: MIT Press.",
                "\u2013\u2013\u2013, 2002, <em>An Introduction to MultiAgent Systems</em>, Chichester: Wiley.",
                "Wright, G. H. von, 1963, <em>Norm and Action: A Logical Inquiry</em>, London: Routledge &amp; Kegan Paul.",
                "Xu, M., 1998, \u201cAxioms for deliberative stit\u201d, <em>Journal of Philosophical Logic</em>, 27: 505\u2013552."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2><a name=\"Bib\">Bibliography</a></h2>\n<ul class=\"hanging\">\n<li>Alchourr\u00f3n, C., G\u00e4rdenfors, P., and Makinson, D., 1985, \u201cOn the Logic of Theory Change: Partial Meet Contraction and Revision Functions\u201d, <em>Journal of Symbolic Logic</em>, 50: 510\u2013530.</li>\n<li>Aldewereld, H. M., Van der Hoek, W., and Meyer, J.-J. Ch., 2004, \u201cRational Teams: Logical Aspects of Multi-Agent Systems\u201d, <em>Fundamenta Informaticae</em>, 63(2\u20133): 159\u2013183.</li>\n<li>Alur, R., Henzinger, T., and Kupferman, O., 1998, \u201cAlternating-time Temporal Logic\u201d, in W.-P. de Roever, H. Langmaack and A. Pnueli (eds.), <em>Compositionality: The Significant Difference, Proceedings COMPOS-97</em> (Lecture Notes in Computer Science 1536), Berlin: Springer, pp. 23\u201360.</li>\n<li>Anderson, A. R., 1962, \u201cLogic, norms, and roles\u201d, <em>Ratio</em>, 4: 36\u201349.</li>\n<li>Audi, R. (ed.), 1999, <em>The Cambridge Dictionary of Philosophy</em>, Cambridge: Cambridge University Press.</li>\n<li>Austin, J. L., 1957, <em>How to Do Things with Words</em>, Oxford: Oxford University Press.</li>\n<li>Bakker, J. W. de, 1980, <em>Mathematical Theory of Program Correctness</em>, Englewood Cliffs, NJ: Prentice-Hall International.</li>\n<li>Balbiani, P., Baltag, A., van Ditmarsch, H., Herzig, A., Hosi, T. and de Lima, S., 2008, \u201c\u2018Knowable\u2019 as \u2018Known After an Announcement\u2019\u201d, <em>The Review of Symbolic Logic</em>, 1: 305\u2013334</li>\n<li>Baltag, A., 1999, \u201cA Logic of Epistemic Actions\u201d, in W. van der Hoek, J.-J. Meyer, and C. Witteveen (eds.), <em>Foundations and Applications of Collective Agent-Based Systems</em> (Proceedings of the Workshop at the 11th European Summer School in Logic, Language, and Computation, Utrecht, 1999). </li>\n<li>Baltag, A. and Moss, L. S., 2004, \u201cLogics for Epistemic Programs\u201d, <em>Synthese</em>, 139: 165\u2013224.</li>\n<li>Belnap, N., Perloff, M., and Xu, M., 2001, <em>Facing the future</em>, Oxford: Oxford University Press.</li>\n<li>Bradfield, J. and Stirling, C., 2007, \u201cModal \\(\\mu\\)-calculi\u201d, in P. Blackburn, J. F. A. K. van Benthem, and F. Wolter (eds.), <em>Handbook of Modal Logic</em>, Amsterdam: Elsevier, pp. 721\u2013756.</li>\n<li>Bratman, M. E., 1987, <em>Intentions, Plans, and Practical Reason</em>, Cambridge, Massachusetts: Harvard University Press.</li>\n<li>Broersen, J.M., 2004, \u201cAction Negation and Alternative Reductions for Dynamic Deontic Logics\u201d, <em>Journal of Applied Logic</em>, 2(1): 153\u2013168.</li>\n<li>\u2013\u2013\u2013, 2009, \u201cA Complete STIT Logic for Knowledge and Action, and Some of Its Applications\u201d, in M. Baldoni, T. Cao Son, M.B. van Riemsdijk and M. Winikoff (eds.), <em>Declarative Agent Languages and Technologies VI</em>, 6th International Workshop, DALT 2008, Estoril, Portugal, May 12, 2008, Revised Selected and Invited Papers: Springer, Berlin, pp. 47\u201359.</li>\n<li>\u2013\u2013\u2013, 2010, \u201cCTL.STIT: enhancing ATL to express important multi-agent system verification properties\u201d, in <em>Proceedings 9th International Conference on Autonomous Agents and Multiagent Systems</em>. New York: ACM Press, pp. 683\u2013690.</li>\n<li>Broersen, J.M., Herzig, A. and Troquard, N., 2006a, \u201cFrom Coalition Logic to STIT\u201d, <em>Electronic Notes in Theoretical Computer Science</em>, 157(4): 23\u201335.</li>\n<li>\u2013\u2013\u2013, 2006b, \u201cEmbedding Alternating-time Temporal Logic in strategic STIT logic of agency\u201d, <em>Journal of logic and computation</em>, 16: 559\u2013578.</li>\n<li>Chellas, B. F., 1969, <em>The Logical Form of Imperatives</em>, Stanford, CA: Perry Lane Press.</li>\n<li>\u2013\u2013\u2013, 1980, <em>Modal Logic: An Introduction</em>, Cambridge and London: Cambridge University Press.</li>\n<li>Clark, Herbert H., 1996, <em>Using Language</em>, Cambridge University Press.</li>\n<li>Cohen, P. R. and Levesque, H. J., 1990, \u201cIntention is Choice with Commitment\u201d, <em>Artificial Intelligence</em>, 42(3): 213\u2013261.</li>\n<li>Cohen, P. and Levesque, H., 1991, \u201cTeamwork\u201d, <em>No\u00fbs</em>, 24(4): 487\u2013512.</li>\n<li>Cousot, P., 1990, \u201cMethods and Logic for Proving Programs\u201d, in J. van Leeuwen (ed.), <em>Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics</em>, Amsterdam: Elsevier, pp. 841\u2013993. </li>\n<li>Dastani, M.M., Hindriks, K.V. and Meyer, J.-J. Ch. (eds.), 2010, <em>Specification and Verification of Multi-Agent Systems</em>, New York/Dordrecht/Heidelberg/London: Springer.</li>\n<li>Davidson, D., 1967, \u201cThe Logical Form of Action Sentences\u201d, in N. Rescher (ed.), <em>The Logic of Decision and Action</em>, Pittsburgh: University of Pittsburgh Press, pp. 81\u2013120.</li>\n<li>Dennett, D. C., 1971, \u201cIntentional Systems\u201d, <em>Journal of Philosophy</em>, 68(4): 87\u2013106.</li>\n<li>\u2013\u2013\u2013, 1984, \u201cCognitive Wheels: The Frame Problem of AI\u201d, in C. Hookway (ed.), <em>Minds, Machines, and Evolution: Philosophical Studies</em>, Cambridge: Cambridge University Press.</li>\n<li>Dijkstra, E. W., 1976, <em>A Discipline of Programming</em>, Englewood Cliffs, NJ: Prentice-Hall.</li>\n<li>Dunin-Ke\u0327plicz, B. and Verbrugge, R., 2002, \u201cCollective Intentions\u201d, <em>Fundamenta Informaticae</em>, 51(3): 271\u2013295.</li>\n<li>Emerson, E. A., 1990, \u201cTemporal and Modal Logic\u201d, in J. van Leeuwen (ed.), <em>Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics</em>, Amsterdam: Elsevier, pp. 995\u20131072.</li>\n<li>Faller, M., Kaufmann, S., and Pauly, M. (eds.), 2000, <em>Formalizing the Dynamics of Information</em>, Stanford, CA: CSLI Publications.</li>\n<li>Fischer, M. J. and Ladner, R. E., 1977, \u201cPropositional Modal Logic of Programs\u201d, in <em>Proceedings of the 9th ACM Annual Symposium on Theory of Computing</em>, New York: Association for Computing Machinery, pp. 286\u2013294.</li>\n<li>Fitch, F. B., 1963, \u201cA logical analysis of some value concepts\u201d, <em>Journal of Symbolic Logic</em>, 28: 135\u2013142.</li>\n<li>Floyd, R. W., 1967, \u201cAssigning Meanings to Programs\u201d, in J. T. Swartz (ed.), <em>Proceedings Symposium in Applied Mathematics</em>, American Mathematical Society, pp. 19\u201332.</li>\n<li>Goldstein, H. H. and Neumann J. Von, 1963, \u201cPlanning and Coding Problems for an Electronic Computer Instrument\u201d, in A. M. Taub (ed.), <em>John von Neumann Collected Works</em> (Vol. 5), Oxford: Pergamon Press, pp. 80\u2013235.</li>\n<li>Groenendijk, J. and Stokhof, M., 1991, \u201cDynamic Predicate Logic\u201d, <em>Linguistics and Philosophy</em>, 14: 39\u2013100.</li>\n<li>G\u00e4rdenfors, P., 1988, <em>Knowledge in Flux</em>, Cambridge, Massachusetts: MIT Press.</li>\n<li>Gerbrandy, J. D., 1998, <em>Bisimulations on Planet Kripke</em>, Ph.D. Thesis, Amsterdam: University of Amsterdam.</li>\n<li>Harel, D., 1979, <em>First-Order Dynamic Logic</em>, Berlin: Springer-Verlag.</li>\n<li>\u2013\u2013\u2013, 1984, \u201cDynamic Logic\u201d, in D. Gabbay and F. Guenthner (eds.), <em>Handbook of Philosophical Logic</em> (Vol. II), Dordrecht and Boston: Reidel, pp. 497\u2013604.</li>\n<li>Harel, D., Kozen, D., and Tiuryn, J., 2000, <em>Dynamic Logic</em>, Cambridge, Massachusetts: MIT Press.</li>\n<li>Heim, I., 1983, \u201cOn the projection problem for presuppositions\u201d, in M. Barlow, D. Flickinger and D. Westcoat (eds.), <em>Proceedings of the 2nd West Coast Conference on Formal Linguistics</em>, Stanford, CA: Stanford University, pp. 114\u2013126.</li>\n<li>Hendricks, V. and J. Symons, J., 2006, \u201cEpistemic Logic\u201d, in <em>The Stanford Encyclopedia of Philosophy</em> (Spring 2009 Edition), Edward N. Zalta (ed.), URL = &lt;<a href=\"https://plato.stanford.edu/archives/spr2009/entries/logic-epistemic/\">https://plato.stanford.edu/archives/spr2009/entries/logic-epistemic/</a>&gt;.</li>\n<li>Hennessy, M. and Milner, R., 1980, \u201cOn Observing Nondeterminism and Concurrency\u201d, in <em>Proceedings ICALP \u201880</em> (Lecture Notes in Computer Science: 85), Berlin: Springer, pp. 295\u2013309.</li>\n<li>Henry, D. P., 1967, <em>The Logic of St. Anselm</em>, Oxford: Oxford University Press.</li>\n<li>Hitchcock, P. and Park, D., 1972, \u201cInduction Rules and Termination Proofs\u201d, in M. Nivat (ed.), <em>Proceedings First International Colloquium on Automata, Languages and Programming</em>, Amsterdam: North-Holland, pp. 225\u2013251.</li>\n<li>Hoare, C. A. R., 1969, \u201cAn Axiomatic Basis for Computer Programming\u201d, <em>Communications of the ACM</em>, 12: 576\u2013580.</li>\n<li>Horty, J. F., 2001, <em>Agency and Deontic Logic</em>, Oxford: Oxford University Press.</li>\n<li>Kamp, H., 1981, \u201cA theory of truth and semantic representation\u201d, in J. Groenendijk (ed.), <em>Formal Methods in the Study of Language</em>, Amsterdam: Mathematisch Centrum.</li>\n<li>Kanger, S., 1957, \u201cNew foundations for ethical theory\u201d, Technical Report, Stockholm University; reprinted in R. Hilpinen (ed.), <em>Deontic Logic: Introductory and Systematic Readings</em>, D. Reidel: Dordrecht, 1971, pp. 36-58.</li>\n<li>\u2013\u2013\u2013, 1972, \u201cLaw and logic\u201d, <em>Theoria</em>, 38: 105\u2013132</li>\n<li>Kooi, B., 2003, <em>Knowledge, Chance, and Change</em>, Ph.D. Thesis, Groningen: University of Groningen.</li>\n<li>Kowalski, R. and Sergot, M., 1986, \u201cA Logic-Based Calculus of Events\u201d, <em>New Generation Computing</em>, 4: 67\u201395.</li>\n<li>Kozen, D., 1983, \u201cResults on the Propositional \\(\\mu\\)-calculus\u201d, <em>Theoretical Computer Science</em>, 27: 333\u2013354.</li>\n<li>Kozen, D. and Tiuryn, J., 1990, \u201cLogics of Programs\u201d, in J. van Leeuwen (ed.), <em>Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics</em>, Amsterdam: Elsevier, pp. 789\u2013840.</li>\n<li>Kracht, M., 1993, \u201cLogic and Control: How They Determine the Behaviour of Presuppositions\u201d, in J. van Eijck and A. Visser, (eds.), <em>Logic and Information Flow</em>, Cambridge, Massachusetts: MIT Press, pp. 89\u2013111.</li>\n<li>Krifka, M., 1986, <em>Nominalreferenz und Zeitkonstitution. Zur Semantik von Massentermen</em>, Ph.D. Thesis, M\u00fcnchen, Universit\u00e4t M\u00fcnchen.</li>\n<li>\u2013\u2013\u2013, 1992, \u201cThematic Relations as Links between Nominal Reference and Temporal Constitution\u201d, in I. Sag and A. Szaboclcsi (eds.), <em>Lexical Matters</em>, Stanford: Stanford University Press, pp. 29\u201353.</li>\n<li>Kvarnstr\u00f6m, J. and Doherty, P., 2000, \u201cTALplanner: A Temporal Logic-Based Forward-Chaining Planner\u201d, <em>Annals of Mathematics and Artificial Intelligence</em>, 30: 119\u2013169.</li>\n<li>Lamport, L., 1977, \u201cProving the Correctness of Multiprocess Programs\u201d, <em>IEEE Transactions on Software Engineering</em>, SE-3(2): 125\u2013143.</li>\n<li>Levesque, H. J., Cohen, P. R., and Nunes, J. H. T., 1990, \u201cOn Acting Together\u201d, in <em>Proceedings AAAI \u201890</em>, pp. 94\u201399.</li>\n<li>Lindahl. L., 1977, <em>Position and Change: A Study in Law and Logic</em>, Dordrecht and Boston: Reidel.</li>\n<li>Lindstr\u00f6m, S. and Segerberg, K., 2006, \u201cModal Logic and Philosophy\u201d, in P. Blackburn, J. van Benthem, and F. Wolter (eds.), <em>Handbook of Modal Logic</em> (Studies in Logic and Practical Reasoning: 3), Amsterdam: Elsevier, pp. 1153\u20131218.</li>\n<li>McCarthy, J., 1963a, \u201cTowards a Mathematical Science of Computation\u201d, in C. M. Popplewell (ed.), <em>Proceedings of IFIP Congress \u201862</em>, Amsterdam: North-Holland, pp. 21\u201328.</li>\n<li>\u2013\u2013\u2013, 1963b, \u201cSituations, Actions, and Causal Laws\u201d, Technical Report Memo 2, Stanford University Artificial Intelligence Project, Stanford University; reprinted in M. Minsky (ed.), <em>Semantic Information Processing</em>, Cambridge, MA: MIT Press, 1968, pp. 410-417.</li>\n<li>\u2013\u2013\u2013, 1986, \u201cPrograms with Common Sense\u201d, in M. L. Minsky (ed.), <em>Semantic Information Processing</em>, Cambridge, Massachusetts: MIT Press, pp. 403\u2013418.</li>\n<li>McCarthy J. and Hayes, P. J., 1969, \u201cSome Philosophical Problems from the Standpoint of Artificial Intelligence\u201d, in B. Meltzer, D. Michie and M. Swann (eds.), <em>Machine Intelligence 4</em>, Edinburgh: Edinburgh University Press, pp. 463\u2013502.</li>\n<li>Merin, A., 1994, \u201cAlgebra of elementary social acts\u201d, in S. L. Tsohatzidis (ed.), <em>Foundations of Speech Act Theory: Philosophical and Linguistic Perspectives</em>, London: Routledge, pp. 234\u2013264. </li>\n<li>Meyer, J.-J. Ch., 1985, <em>Programming Calculi Based on Fixed Point Transformations: Semantics and Applications</em>, Ph.D. Thesis, Amsterdam: Vrije Universiteit Amsterdam.</li>\n<li>\u2013\u2013\u2013, 1988, \u201cA Different Approach to Deontic Logic: Deontic Logic Viewed as a Variant of Dynamic Logic\u201d, <em>Notre Dame Journal of Formal Logic</em>, 29(1): 109\u2013136.</li>\n<li>\u2013\u2013\u2013, 2000, \u201cDynamic Logic for Reasoning about Actions and Agents\u201d, in J. Minker, (ed.), <em>Logic-Based Artificial Intelligence</em>, Boston and Dordrecht: Kluwer, pp. 281\u2013311. </li>\n<li>\u2013\u2013\u2013, 2006, \u201cReasoning about Emotional Agents\u201d, <em>International Journal of Intelligent Systems</em>, 21(6): 601\u2013619.</li>\n<li>Meyer, J.-J. Ch. and Van der Hoek, W., 1995, <em>Epistemic Logic for AI and Computer Science</em>, Cambridge: Cambridge University Press.</li>\n<li>Meyer, J.-J. Ch., Van der Hoek, W., and Van Linder, B., 1999, \u201cA Logical Approach to the Dynamics of Commitments\u201d, <em>Artificial Intelligence</em>, 113: 1\u201340.</li>\n<li>Meyer, J.-J. Ch. and Veltman, F., 2007, \u201cIntelligent Agents and Common Sense Reasoning\u201d, in P. Blackburn, J. van Benthem and F. Wolter (eds.), <em>Handbook of Modal Logic</em>, Amsterdam: Elsevier, pp. 991\u20131029.</li>\n<li>Moens, M. and Steedman, M., 1988, \u201cTemporal ontology and temporal reference\u201d, <em>Computational Linguistics</em>, 14: 15\u201328.</li>\n<li>Moore, R. C., 1977, \u201cReasoning about Knowledge and Action\u201d, in <em>Proceedings of the 5th International Joint Conference on Artificial Intelligence (IJCAI-77)</em>, Cambridge, Massachusetts: William Kaufmann, pp. 223\u2013227.</li>\n<li>Muskens, R., van Benthem, J., and Visser, A., 1997, \u201cDynamics\u201d, in J. van Benthem and A. ter Meulen (eds.), <em>Handbook of Logic and Language</em>, Amsterdam: Elsevier, pp. 587\u2013648.</li>\n<li>Naumann, R., 2001, \u201cAspects of changes: a dynamic event semantics\u201d, <em>Journal of Semantics</em>, 18: 27\u201381.</li>\n<li>Naur, P., 1966, \u201cProof of Algorithms by General Snapshots\u201d, <em>BIT Numerical Mathematics</em>, 6: 310\u2013316.</li>\n<li>Nilsson, N. J., 1998, <em>Artificial Intelligence: A New Synthesis</em>, San Francisco: Morgan Kaufmann.</li>\n<li>Park, D., 1976, \u201cFiniteness is \\(\\mu\\)-ineffable\u201d, <em>Theoretical Computer Science</em>, 3: 173\u2013181.</li>\n<li>Parsons, T., 1990, <em>Events in the Semantics of English: A Study in Subatomic Semantics</em> (Current Studies in Linguistics: 19), Cambridge, Massachusetts: MIT Press.</li>\n<li>Pauly, M., 2001, <em>Logic for Social Software</em>, ILLC Dissertations Series, Amsterdam.</li>\n<li>Plaza, J. A., 1989, \u201cLogics of Public Communication\u201d, in M. L. Emlich, <em>et al</em>. (eds.), <em>Proceedings of the 4th International Symposium on Methodologies for Intelligent Systems</em>, Amsterdam: North-Holland Publishing, pp. 201\u2013216.</li>\n<li>Pnueli, A., 1977, \u201cThe Temporal Logic of Programs\u201d, in <em>Proceedings of the 18th Annual IEEE Symposium on Foundations of Computer Science</em>, Piscataway, New Jersey: IEEE, pp. 46\u201357.</li>\n<li>P\u00f6rn, I., 1977, <em>Action Theory and Social Science</em>, Dordrecht: Reidel.</li>\n<li>Pratt, V. R., 1976, \u201cSemantical Considerations on Floyd-Hoare Logic\u201d, in <em>Proceedings of the 17th Annual IEEE Symposium on Foundations of Computer Science</em>, New York: ACM, pp. 109\u2013121.</li>\n<li>\u2013\u2013\u2013, 1979a, \u201cDynamic Logic\u201d, in J. W. de Bakker and J. van Leeuwen (eds.), <em>Proceedings Foundations of Computer Science III</em> Mathematical Centre Tracts 108, Amsterdam: Mathematisch Centrum, pp. 53\u201382.</li>\n<li>\u2013\u2013\u2013, 1979b, \u201cProcess Logic: Preliminary Report\u201d, in <em>Proceedings of the 6th Symposium on Principles of Programming Languages</em>, New York: ACM, pp. 93\u2013100.</li>\n<li>Rao, A. S. and Georgeff, M. P., 1991, \u201cModeling rational agents within a BDI-architecture\u201d, in J. Allen, R. Fikes and E. Sandewall (eds.), <em>Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning (KR \u201891)</em>, San Francisco: Morgan Kaufmann, pp. 473\u2013484.</li>\n<li>\u2013\u2013\u2013, 1998, \u201cDecision Procedures for BDI Logics\u201d, <em>Journal of Logic and Computation</em>, 8(3): 293\u2013344.</li>\n<li>Reiter, R., 1980, \u201cA Logic for Default Reasoning\u201d, <em>Artificial Intelligence</em>, 13(1\u20132): 81\u2013132.</li>\n<li>\u2013\u2013\u2013, 2001, <em>Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems</em>, Cambridge, Massachusetts: MIT Press. </li>\n<li>Roever, W.-P. de, Boer, F. S. de, <em>et al.</em>, 2001, <em>Concurrency Verification: Introduction to Compositional and Noncompositional Methods</em>, Cambridge: Cambridge University Press.</li>\n<li>Russell, S. and Norvig, P., 1995, <em>Artificial Intelligence: A Modern Approach</em>, Englewood Cliffs, NJ: Prentice-Hall.</li>\n<li>Salwicki, A., 1970, \u201cFormalized Algorithmic Languages\u201d, <em>Bulletin de l\u2019Acad\u00e9mie Polonaise des Sciences</em> (S\u00e9rie des sciences math\u00e9matiques, astronomiques et physiques), 18(5): 227\u2013232.</li>\n<li>Sandewall, E. and Shoham, Y., 1994, \u201cNonmonotonic Temporal Reasoning\u201d, in D. M. Gabbay, C. J. Hogger and J. A. Robinson (eds.), <em>Handbook of Logic in Artificial Intelligence and Logic Programming, Volume 4: Epistemic and Temporal Reasoning</em>, Oxford: Oxford University Press.</li>\n<li>Scott, D. S. and Bakker, J. W. de, 1969, <em>A Theory of Programs</em>, Vienna: IBM.</li>\n<li>Searle, J. R., 1969, <em>Speech Acts: An Essay in the Philosophy of Language</em>, Cambridge: Cambridge University Press.</li>\n<li>Searle, J. R. and Vanderveken D., 1985, <em>Foundations of Illocutionary Logic</em>, Cambridge: Cambridge University Press.</li>\n<li>Segerberg, K., 1992, \u201cGetting started: beginnings in the logic of action\u201d, <em>Studia Logica</em>, 51: 347\u2013378.</li>\n<li>\u2013\u2013\u2013, 1995, \u201cBelief Revision from the Point of View of Doxastic Logic\u201d, <em>Bulletin of the IGPL</em>, 3: 535\u2013553.</li>\n<li>Shanahan, M., 1990, \u201cRepresenting continuous change in the event calculus\u201d, in <em>Proceedings of ECAI \u201990</em>, pp. 598\u2013603.</li>\n<li>\u2013\u2013\u2013, 1995, \u201cA circumscriptive calculus of events\u201d, <em>Artificial Intelligence</em>, 77: 249\u2013284.</li>\n<li>Shoham, Y., 1993, \u201cAgent-Oriented Programming\u201d, <em>Artificial Intelligence</em>, 60(1): 51\u201392.</li>\n<li>Steunebrink, B., Dastani, M. and Meyer, J.-J. Ch., 2007, \u201cA Logic of Emotions for Intelligent Agents\u201d, in Holte, R. C. and Howe, A. E. (eds.), <em>Proceedings AAAI \u201807</em>, Vancouver: AAAI Press, pp. 142\u2013147.</li>\n<li>Steunebrink, B.R., Dastani, M.M. and Meyer, J.-J. Ch., 2012, \u201cA Formal Model of Emotion Triggers for BDI Agents with Achievement Goals\u201d, Synthese/KRA 185 (1): 83\u2013129 (KRA: 413\u2013459).</li>\n<li>Thielscher, M., 2005, <em>Reasoning Robots, The Art and Science of Programming Robotic Agents</em>, Dordrecht: Springer.</li>\n<li>Thomason, R., 2003, \u201cLogic and Artificial Intelligence\u201d, in <em>The Stanford Encyclopedia of Philosophy</em> (Spring 2009 Edition), Edward N. Zalta (ed.), URL = &lt;<a href=\"https://plato.stanford.edu/archives/spr2009/entries/logic-ai/\">https://plato.stanford.edu/archives/spr2009/entries/logic-ai/</a>&gt;.</li>\n<li>Turing, A. M., 1949, \u201cOn Checking a Large Routine\u201d, Report of a Conference on High-Speed Automatic Calculating Machines, Cambridge: University Mathematical Laboratory, pp. 67\u201369.</li>\n<li>van Benthem, J., 1989, \u201cSemantic Parallels in Natural Language and Computation\u201d, in H. D. Ebbinghaus, <em>et al</em>. (eds.), <em>Logic Colloquium \u201887</em>, Amsterdam: North-Holland, pp. 331\u2013375.</li>\n<li>\u2013\u2013\u2013, 1994, \u201cLogic and the Flow of Information\u201d, in D. Prawitz, <em>et al</em>. (eds.), <em>Proceedings of the 9th International Congress of Logic, Methodology and Philosophy of Science</em>, Amsterdam: Elsevier.</li>\n<li>van der Hoek, W., van Linder, B., and Meyer, J.-J. Ch., 1998, \u201cAn Integrated Modal Approach to Rational Agents\u201d, in M. Wooldridge and A. Rao (eds.), <em>Foundations of Rational Agency</em> (Applied Logic Series: 14), Dordrecht: Kluwer, pp. 133\u2013168.</li>\n<li>van der Hoek, W. and Pauly, M., 2007, \u201cModal Logic for Games and Information\u201d, in P. Blackburn, J. van Benthem, and F. Wolter (eds.), <em>Handbook of Modal Logic</em>, Amsterdam: Elsevier, pp. 1077\u20131148.</li>\n<li>van der Hoek, W., and Wooldridge, M. J., 2003, \u201cCooperation, Knowledge, and Time: Alternating-Time Temporal Epistemic Logic and Its Applications\u201d, <em>Studia Logica</em>, 75(1): 125\u2013157.</li>\n<li>van der Sandt, R. A., 1991, \u201cDenial\u201d, in <em>Papers from the 27th Regional Meetings of the Chicago Linguistic Society Meetings</em> (Volume 2: Parasession on Negation), Chicago Linguistics Society, pp. 331\u2013344.</li>\n<li>van Ditmarsch, H. P., 2000, <em>Knowledge Games</em>, Ph.D. Thesis, Groningen: University of Groningen.</li>\n<li>van Ditmarsch, H., Van der Hoek, W., and Kooi, B., 2007, <em>Dynamic Epistemic Logic</em>, Dordrecht: Springer.</li>\n<li>van Eijck, J., 1994, \u201cPresupposition failure: a comedy of errors\u201d, <em>Formal Aspects of Computing</em>, 3: 766\u2013787.</li>\n<li>van Lambalgen, M. and Hamm, F., 2005, <em>The Proper Treatment of Events</em>, Oxford: Blackwell.</li>\n<li>van Linder, B., Van der Hoek, W., and Meyer, J.-J. Ch., 1995, \u201cActions That Make You Change Your Mind\u201d, in A. Laux and H. Wansing (eds.), <em>Knowledge and Belief in Philosophy and Artificial Intelligence</em>, Berlin: Akademie Verlag, pp. 103\u2013146.</li>\n<li>Vanderveken, D., 1990, <em>Meaning and Speech Acts, Volume 1: Principles of Language Use</em>, Cambridge: Cambridge University Press.</li>\n<li>\u2013\u2013\u2013, 1991, <em>Meaning and Speech Acts, Volume 2: Formal Semantics of Success and Satisfaction</em>, Cambridge: Cambridge University Press.</li>\n<li>Veltman, F., 1985, <em>Logics for Conditionals</em>, Ph.D. Thesis, Amsterdam: University of Amsterdam.</li>\n<li>\u2013\u2013\u2013, 1996, \u201cDefaults in Update Semantics\u201d, <em>Journal of Philosophical Logic</em>, 25: 221\u2013261.</li>\n<li>Vendler, Z., 1957, \u201cVerbs and times\u201d, <em>Philosophical Review</em>, 66: 143\u2013160.</li>\n<li>Verkuyl, H., 1993, <em>A Theory of Aspectuality: The Interaction Between Temporal and Atemporal Structure</em>, Cambridge: Cambridge University Press.</li>\n<li>Walton, D., 1976, \u201cSt. Anselm and the logical syntax of agency\u201d, <em>Franciscan Studies</em>, 36: 298\u2013312.</li>\n<li>Wooldridge, M. J., 2000, <em>Reasoning about Rational Agents, Cambridge</em>, Massachusetts: MIT Press.</li>\n<li>\u2013\u2013\u2013, 2002, <em>An Introduction to MultiAgent Systems</em>, Chichester: Wiley.</li>\n<li>Wright, G. H. von, 1963, <em>Norm and Action: A Logical Inquiry</em>, London: Routledge &amp; Kegan Paul.</li>\n<li>Xu, M., 1998, \u201cAxioms for deliberative stit\u201d, <em>Journal of Philosophical Logic</em>, 27: 505\u2013552.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "events",
            "frame problem",
            "logic: dynamic epistemic",
            "logic: non-monotonic",
            "logic: propositional dynamic",
            "logic: temporal",
            "semantics: dynamic",
            "situations: in natural language semantics",
            "speech acts"
        ],
        "entry_link": [
            {
                "../events/": "events"
            },
            {
                "../frame-problem/": "frame problem"
            },
            {
                "../dynamic-epistemic/": "logic: dynamic epistemic"
            },
            {
                "../logic-nonmonotonic/": "logic: non-monotonic"
            },
            {
                "../logic-dynamic/": "logic: propositional dynamic"
            },
            {
                "../logic-temporal/": "logic: temporal"
            },
            {
                "../dynamic-semantics/": "semantics: dynamic"
            },
            {
                "../situations-semantics/": "situations: in natural language semantics"
            },
            {
                "../speech-acts/": "speech acts"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<td valign=\"top\"><img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=logic-action\" target=\"other\">How to cite this entry</a>.",
            "<td valign=\"top\"><img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/logic-action/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<td valign=\"top\"><img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=logic-action&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<td valign=\"top\"><img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"http://philpapers.org/sep/logic-action/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"http://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=logic-action": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/logic-action/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=logic-action&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "http://philpapers.org/sep/logic-action/": "Enhanced bibliography for this entry"
            },
            {
                "http://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [],
        "listed_links": []
    }
}