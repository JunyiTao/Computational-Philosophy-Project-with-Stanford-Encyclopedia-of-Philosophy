{
    "main_text": "Can computers be moral agents? || Computers as morally responsible agents\n2.1 Computers as morally responsible agents\n\nThe increasing complexity of computer technology and the advances in\nArtificial Intelligence (AI), challenge the idea that human beings are\nthe only entities to which moral responsibility can or should be\nascribed (Bechtel 1985; Kroes and Verbeek 2014). Dennett, for example,\nsuggested that holding a computer morally responsible is possible if\nit concerned a higher-order intentional computer system (1997). An\nintentional system, according to him, is one that can be predicted and\nexplained by attributing beliefs and desires to it, as well as\nrationality. In other words, its behavior can be described by assuming\nthe systems has mental states and that it acts according what it\nthinks it ought to do, given its beliefs and desires. At the time,\nDennett noted that many computers were already intentional systems,\nbut they lacked the higher-order ability to reflect on and reason\nabout their mental states. They did not have beliefs about their\nbeliefs or thoughts about desires. Dennett suggested that the\nfictional HAL 9000 that featured in the movie 2001: A Space\nOdyssey would qualify as a higher-order intentional system that\ncan be held morally responsible. Although advances in AI might not\nlead to HAL, he did see the development of computers systems with\nhigher-order intentionality as a real possibility.\n\nSullins argues in line with Dennett that moral agency is not\nrestricted to human beings (2006). He proposes that computers systems\nor, more specifically, robots are moral agents when they have a\nsignificant level of autonomy and they can be regarded at an\nappropriate level of abstraction as exhibiting intentional behavior. A\nrobot, according to Sullins, would be significantly autonomous if it\nwas not under the direct control of other agents in performing its\ntasks. Note that Sullins interprets autonomy in a narrow sense in\ncomparison to the conception of autonomy in moral philosophy as\nproperty of human beings. He adds as a third condition that a robot\nalso has to be in a position of responsibility to be a moral agent.\nThat is, the robot performs some social role that carries with it some\nresponsibilities and in performing this role the robot appears to have\n\u2018beliefs\u2019 about and an understanding of its duties towards\nother moral agents (p. 28). To illustrate what kind of capabilities\nare required for \u201cfull moral agency\u201d, he draws an analogy\nwith a human nurse. He argues that if a robot was autonomous enough to\ncarry out the same duties as a human nurse and had an understanding of\nits role and responsibilities in the health care systems, then it\nwould be a \u201cfull moral agent\u201d. Sullins maintains that it\nwill be some time before machines with these kinds of capabilities\nwill be available, but \u201ceven the modest robots of today can be\nseen to be moral agents of a sort under certain, but not all, levels\nof abstraction and are deserving of moral consideration\u201d (p.\n29).\n\nEchoing objections to the early project of (strong) AI (Sack\n 1997),[3]\n critics of analyses such as presented by Dennett and Sullins, have\nobjected to the idea that computer technologies can have capacities\nthat make human beings moral agents, such as mental states,\nintentionality, common sense, emotion or empathy (Johnson 2006; Kuflik\n1999; Nyholm 2018). They, for instance, point out that it makes no\nsense to treat computer system as moral agents that can be held\nresponsible, for they cannot suffer and thus cannot be punished\n(Sparrow 2007; Asaro 2011). Veliz argues that computers may act like\nmoral agents, but they lack sentience and are therefore \u2018moral\nzombies\u2019 (2021). Hakli and Makela argue that computers\ncannot have the kind of autonomy required for moral agency, because\ntheir capacities are a result of engineering and programming which\nundermines the autonomy of robots and disqualifies them as moral\nagents (2019). Or they argue, as Stahl does, that computers are not\ncapable of moral reasoning, because they do not have the capacity to\nunderstand the meaning of the information that they process (2006). In\norder to comprehend the meaning of moral statements an agent has to be\npart of the form of life in which the statement is meaningful; it has\nto be able to take part in moral discourses. Similar to the debates\nabout AI, critics continue to draw a distinction between humans and\ncomputers by noting various capacities that computers do not, and\ncannot, have that would justify the attribution of moral agency.\n\nSome other critics do not contest that human beings might be able to\nbuild computer systems with the required capacities for moral agency,\nbut question whether it is ethically appropriate to do so. Bryson, for\ninstance, argues that even if it was possible to create artifacts with\nsuch capacities \u2013 and she assumes this might very well be\npossible \u2013 human beings have a choice in the matter\n(2018). She defines a moral agent as \u201csomething deemed\nresponsible by a society for its actions\u201d (p. 16). Society can\nthus at one point deem it appropriate to view certain computer systems\nas moral agents, for instance as it would provide a short cut to\nfiguring out how responsibility should be distributed. However, she\nargues that there is no necessary or predetermined position for these\ntechnologies in our society. This is because, she notes, computer\ntechnologies ethical frameworks are \u201cartefacts of our societies,\nand therefore subject to human control\u201d (p. 15). We can choose\nwhat capacities we equip these artefacts with, and she sees no\ncoherent reason for creating artificial agents that human beings have\nto compete with in terms of moral agency or patiency.\n",
    "section_title": "2.1 Computers as morally responsible agents",
    "entry_title": "Computing and Moral Responsibility",
    "hierarchy_title": "Computing and Moral Responsibility || Can computers be moral agents? || Computers as morally responsible agents",
    "tokenized_text": [
        "computer",
        "moral",
        "agent",
        "computer",
        "morally",
        "responsible",
        "agent",
        "computer",
        "morally",
        "responsible",
        "agent",
        "increasing",
        "complexity",
        "computer",
        "technology",
        "advance",
        "artificial",
        "intelligence",
        "ai",
        "challenge",
        "idea",
        "human",
        "being",
        "entity",
        "moral",
        "responsibility",
        "ascribed",
        "bechtel",
        "kroes",
        "verbeek",
        "dennett",
        "example",
        "suggested",
        "holding",
        "computer",
        "morally",
        "responsible",
        "possible",
        "concerned",
        "higherorder",
        "intentional",
        "computer",
        "system",
        "intentional",
        "system",
        "according",
        "one",
        "predicted",
        "explained",
        "attributing",
        "belief",
        "desire",
        "well",
        "rationality",
        "word",
        "behavior",
        "described",
        "assuming",
        "system",
        "mental",
        "state",
        "act",
        "according",
        "think",
        "ought",
        "given",
        "belief",
        "desire",
        "time",
        "dennett",
        "noted",
        "many",
        "computer",
        "already",
        "intentional",
        "system",
        "lacked",
        "higherorder",
        "ability",
        "reflect",
        "reason",
        "mental",
        "state",
        "belief",
        "belief",
        "thought",
        "desire",
        "dennett",
        "suggested",
        "fictional",
        "hal",
        "featured",
        "movie",
        "space",
        "odyssey",
        "would",
        "qualify",
        "higherorder",
        "intentional",
        "system",
        "held",
        "morally",
        "responsible",
        "although",
        "advance",
        "ai",
        "might",
        "lead",
        "hal",
        "see",
        "development",
        "computer",
        "system",
        "higherorder",
        "intentionality",
        "real",
        "possibility",
        "sullins",
        "argues",
        "line",
        "dennett",
        "moral",
        "agency",
        "restricted",
        "human",
        "being",
        "proposes",
        "computer",
        "system",
        "specifically",
        "robot",
        "moral",
        "agent",
        "significant",
        "level",
        "autonomy",
        "regarded",
        "appropriate",
        "level",
        "abstraction",
        "exhibiting",
        "intentional",
        "behavior",
        "robot",
        "according",
        "sullins",
        "would",
        "significantly",
        "autonomous",
        "direct",
        "control",
        "agent",
        "performing",
        "task",
        "note",
        "sullins",
        "interprets",
        "autonomy",
        "narrow",
        "sense",
        "comparison",
        "conception",
        "autonomy",
        "moral",
        "philosophy",
        "property",
        "human",
        "being",
        "add",
        "third",
        "condition",
        "robot",
        "also",
        "position",
        "responsibility",
        "moral",
        "agent",
        "robot",
        "performs",
        "social",
        "role",
        "carry",
        "responsibility",
        "performing",
        "role",
        "robot",
        "appears",
        "belief",
        "understanding",
        "duty",
        "towards",
        "moral",
        "agent",
        "p",
        "illustrate",
        "kind",
        "capability",
        "required",
        "full",
        "moral",
        "agency",
        "draw",
        "analogy",
        "human",
        "nurse",
        "argues",
        "robot",
        "autonomous",
        "enough",
        "carry",
        "duty",
        "human",
        "nurse",
        "understanding",
        "role",
        "responsibility",
        "health",
        "care",
        "system",
        "would",
        "full",
        "moral",
        "agent",
        "sullins",
        "maintains",
        "time",
        "machine",
        "kind",
        "capability",
        "available",
        "even",
        "modest",
        "robot",
        "today",
        "seen",
        "moral",
        "agent",
        "sort",
        "certain",
        "level",
        "abstraction",
        "deserving",
        "moral",
        "consideration",
        "p",
        "echoing",
        "objection",
        "early",
        "project",
        "strong",
        "ai",
        "sack",
        "critic",
        "analysis",
        "presented",
        "dennett",
        "sullins",
        "objected",
        "idea",
        "computer",
        "technology",
        "capacity",
        "make",
        "human",
        "being",
        "moral",
        "agent",
        "mental",
        "state",
        "intentionality",
        "common",
        "sense",
        "emotion",
        "empathy",
        "johnson",
        "kuflik",
        "nyholm",
        "instance",
        "point",
        "make",
        "sense",
        "treat",
        "computer",
        "system",
        "moral",
        "agent",
        "held",
        "responsible",
        "suffer",
        "thus",
        "punished",
        "sparrow",
        "asaro",
        "veliz",
        "argues",
        "computer",
        "may",
        "act",
        "like",
        "moral",
        "agent",
        "lack",
        "sentience",
        "therefore",
        "moral",
        "zombie",
        "hakli",
        "makela",
        "argue",
        "computer",
        "kind",
        "autonomy",
        "required",
        "moral",
        "agency",
        "capacity",
        "result",
        "engineering",
        "programming",
        "undermines",
        "autonomy",
        "robot",
        "disqualifies",
        "moral",
        "agent",
        "argue",
        "stahl",
        "computer",
        "capable",
        "moral",
        "reasoning",
        "capacity",
        "understand",
        "meaning",
        "information",
        "process",
        "order",
        "comprehend",
        "meaning",
        "moral",
        "statement",
        "agent",
        "part",
        "form",
        "life",
        "statement",
        "meaningful",
        "able",
        "take",
        "part",
        "moral",
        "discourse",
        "similar",
        "debate",
        "ai",
        "critic",
        "continue",
        "draw",
        "distinction",
        "human",
        "computer",
        "noting",
        "various",
        "capacity",
        "computer",
        "would",
        "justify",
        "attribution",
        "moral",
        "agency",
        "critic",
        "contest",
        "human",
        "being",
        "might",
        "able",
        "build",
        "computer",
        "system",
        "required",
        "capacity",
        "moral",
        "agency",
        "question",
        "whether",
        "ethically",
        "appropriate",
        "bryson",
        "instance",
        "argues",
        "even",
        "possible",
        "create",
        "artifact",
        "capacity",
        "assumes",
        "might",
        "well",
        "possible",
        "human",
        "being",
        "choice",
        "matter",
        "defines",
        "moral",
        "agent",
        "something",
        "deemed",
        "responsible",
        "society",
        "action",
        "p",
        "society",
        "thus",
        "one",
        "point",
        "deem",
        "appropriate",
        "view",
        "certain",
        "computer",
        "system",
        "moral",
        "agent",
        "instance",
        "would",
        "provide",
        "short",
        "cut",
        "figuring",
        "responsibility",
        "distributed",
        "however",
        "argues",
        "necessary",
        "predetermined",
        "position",
        "technology",
        "society",
        "note",
        "computer",
        "technology",
        "ethical",
        "framework",
        "artefact",
        "society",
        "therefore",
        "subject",
        "human",
        "control",
        "p",
        "choose",
        "capacity",
        "equip",
        "artefact",
        "see",
        "coherent",
        "reason",
        "creating",
        "artificial",
        "agent",
        "human",
        "being",
        "compete",
        "term",
        "moral",
        "agency",
        "patiency"
    ]
}