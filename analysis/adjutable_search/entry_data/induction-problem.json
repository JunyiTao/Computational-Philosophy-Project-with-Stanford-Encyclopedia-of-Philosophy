{
    "url": "induction-problem",
    "title": "The Problem of Induction",
    "authorship": {
        "year": "Copyright \u00a9 2022",
        "author_text": "Leah Henderson\n<l.henderson@rug.nl>",
        "author_links": [
            {
                "http://lhenderson.org/": "Leah Henderson"
            },
            {
                "mailto:l%2ehenderson%40rug%2enl": "l.henderson@rug.nl"
            }
        ],
        "raw_html": "<div id=\"article-copyright\">\n<p>\n<a href=\"../../info.html#c\">Copyright \u00a9 2022</a> by\n\n<br/>\n<a href=\"http://lhenderson.org/\" target=\"other\">Leah Henderson</a>\n&lt;<a href=\"mailto:l%2ehenderson%40rug%2enl\"><em>l<abbr title=\" dot \">.</abbr>henderson<abbr title=\" at \">@</abbr>rug<abbr title=\" dot \">.</abbr>nl</em></a>&gt;\n    </p>\n</div>"
    },
    "pubinfo": [
        "First published Wed Mar 21, 2018",
        "substantive revision Tue Nov 22, 2022"
    ],
    "preamble": "\n\nWe generally think that the observations we make are able to justify\nsome expectations or predictions about observations we have not yet\nmade, as well as general claims that go beyond the observed. For\nexample, the observation that bread of a certain appearance has thus\nfar been nourishing seems to justify the expectation that the next\nsimilar piece of bread I eat will also be nourishing, as well as the\nclaim that bread of this sort is generally nourishing. Such inferences\nfrom the observed to the unobserved, or to general laws, are known as\n\u201cinductive inferences\u201d.\n\nThe original source of what has become known as the \u201cproblem of\ninduction\u201d is in Book 1, part iii, section 6 of A Treatise\nof Human Nature by David Hume, published in 1739 (Hume 1739). In\n1748, Hume gave a shorter version of the argument in Section iv of\nAn enquiry concerning human understanding (Hume 1748).\nThroughout this article we will give references to the\nTreatise as \u201cT\u201d, and the Enquiry as\n\u201cE\u201d.\n\nHume asks on what grounds we come to our beliefs about the unobserved\non the basis of inductive inferences. He presents an argument in the\nform of a dilemma which appears to rule out the possibility of any\nreasoning from the premises to the conclusion of an inductive\ninference. There are, he says, two possible types of arguments,\n\u201cdemonstrative\u201d and \u201cprobable\u201d, but neither\nwill serve. A demonstrative argument produces the wrong kind of\nconclusion, and a probable argument would be circular. Therefore, for\nHume, the problem remains of how to explain why we form any\nconclusions that go beyond the past instances of which we have had\nexperience (T. 1.3.6.10). Hume stresses that he is not disputing that\nwe do draw such inferences. The challenge, as he sees it, is to\nunderstand the \u201cfoundation\u201d of the inference\u2014the\n\u201clogic\u201d or \u201cprocess of argument\u201d that it is\nbased upon (E. 4.2.21). The problem of meeting this challenge, while\nevading Hume\u2019s argument against the possibility of doing so, has\nbecome known as \u201cthe problem of induction\u201d.\n\nHume\u2019s argument is one of the most famous in philosophy. A\nnumber of philosophers have attempted solutions to the problem, but a\nsignificant number have embraced his conclusion that it is insoluble.\nThere is also a wide spectrum of opinion on the significance of the\nproblem. Some have argued that Hume\u2019s argument does not\nestablish any far-reaching skeptical conclusion, either because it was\nnever intended to, or because the argument is in some way\nmisformulated. Yet many have regarded it as one of the most profound\nphilosophical challenges imaginable since it seems to call into\nquestion the justification of one of the most fundamental ways in\nwhich we form knowledge. Bertrand Russell, for example, expressed the\nview that if Hume\u2019s problem cannot be solved, \u201cthere is no\nintellectual difference between sanity and insanity\u201d (Russell\n1946: 699).\n\nIn this article, we will first examine Hume\u2019s own argument,\nprovide a reconstruction of it, and then survey different responses to\nthe problem which it poses.\n",
    "toc": [
        {
            "#HumeProb": "1. Hume\u2019s Problem"
        },
        {
            "#Reco": "2. Reconstruction"
        },
        {
            "#TackFirsHornHumeDile": "3. Tackling the First Horn of Hume\u2019s Dilemma"
        },
        {
            "#SyntPrio": "3.1 Synthetic a priori"
        },
        {
            "#NomoExplSolu": "3.2 The Nomological-Explanatory solution"
        },
        {
            "#BayeSolu": "3.3 Bayesian solution"
        },
        {
            "#PartSolu": "3.4 Partial solutions"
        },
        {
            "#CombAppr": "3.5 The combinatorial approach"
        },
        {
            "#TackSecoHornHumeDile": "4. Tackling the Second Horn of Hume\u2019s Dilemma"
        },
        {
            "#InduJustIndu": "4.1 Inductive Justifications of Induction"
        },
        {
            "#NoRule": "4.2 No Rules"
        },
        {
            "#AlteConcJust": "5. Alternative Conceptions of Justification"
        },
        {
            "#PostHing": "5.1 Postulates and Hinges"
        },
        {
            "#OrdiLangDiss": "5.2 Ordinary Language Dissolution"
        },
        {
            "#PragVindIndu": "5.3 Pragmatic vindication of induction"
        },
        {
            "#FormLearTheo": "5.4 Formal Learning Theory"
        },
        {
            "#MetaIndu": "5.5 Meta-induction"
        },
        {
            "#LiviInduSkep": "6. Living with Inductive Skepticism"
        },
        {
            "#Bib": "Bibliography"
        },
        {
            "#Aca": "Academic Tools"
        },
        {
            "#Oth": "Other Internet Resources"
        },
        {
            "#Rel": "Related Entries"
        }
    ],
    "main_text": "\n1. Hume\u2019s Problem\n\nHume introduces the problem of induction as part of an analysis of the\nnotions of cause and effect. Hume worked with a picture, widespread in\nthe early modern period, in which the mind was populated with mental\nentities called \u201cideas\u201d. Hume thought that ultimately all\nour ideas could be traced back to the \u201cimpressions\u201d of\nsense experience. In the simplest case, an idea enters the mind by\nbeing \u201ccopied\u201d from the corresponding impression (T.\n1.1.1.7/4). More complex ideas are then created by the combination of\nsimple ideas (E. 2.5/19). Hume took there to be a number of relations\nbetween ideas, including the relation of causation (E. 3.2). (For more\non Hume\u2019s philosophy in general, see Morris & Brown\n2014).\n\nFor Hume, the relation of causation is the only relation by means of\nwhich \u201cwe can go beyond the evidence of our memory and\nsenses\u201d (E. 4.1.4, T. 1.3.2.3/74). Suppose we have an object\npresent to our senses: say gunpowder. We may then infer to an effect\nof that object: say, the explosion. The causal relation links our past\nand present experience to our expectations about the future (E.\n4.1.4/26).\n\nHume argues that we cannot make a causal inference by purely a\npriori means (E. 4.1.7). Rather, he claims, it is based on\nexperience, and specifically experience of constant conjunction. We\ninfer that the gunpowder will explode on the basis of past experience\nof an association between gunpowder and explosions.\n\nHume wants to know more about the basis for this kind of inference. If\nsuch an inference is made by a \u201cchain of reasoning\u201d (E.\n4.2.16), he says, he would like to know what that reasoning is. In\ngeneral, he claims that the inferences depend on a transition of the\nform:\n\n\nI have found that such an object has always been attended with\nsuch an effect, and I foresee, that other objects, which are, in\nappearance, similar, will be attended with similar effects. (E.\n4.2.16)\n\n\nIn the Treatise, Hume says that\n\n\nif Reason determin\u2019d us, it would proceed upon that principle\nthat instances, of which we have had no experience, must resemble\nthose, of which we have had experience, and that the course of nature\ncontinues always uniformly the same. (T. 1.3.6.4)\n\n\nFor convenience, we will refer to this claim of similarity or\nresemblance between observed and unobserved regularities as the\n\u201cUniformity Principle (UP)\u201d. Sometimes it is also called\nthe \u201cResemblance Principle\u201d, or the \u201cPrinciple of\nUniformity of Nature\u201d.\n\nHume then presents his famous argument to the conclusion that there\ncan be no reasoning behind this principle. The argument takes the form\nof a dilemma. Hume makes a distinction between relations of ideas and\nmatters of fact. Relations of ideas include geometric, algebraic and\narithmetic propositions, \u201cand, in short, every affirmation,\nwhich is either intuitively or demonstratively certain\u201d.\n\u201cMatters of fact\u201d, on the other hand are empirical\npropositions which can readily be conceived to be other than they are.\nHume says that\n\n\nAll reasonings may be divided into two kinds, namely, demonstrative\nreasoning, or that concerning relations of ideas, and moral reasoning,\nor that concerning matter of fact and existence. (E. 4.2.18)\n\n\nHume considers the possibility of each of these types of reasoning in\nturn, and in each case argues that it is impossible for it to supply\nan argument for the Uniformity Principle.\n\nFirst, Hume argues that the reasoning cannot be demonstrative, because\ndemonstrative reasoning only establishes conclusions which cannot be\nconceived to be false. And, he says,\n\n\nit implies no contradiction that the course of nature may change, and\nthat an object seemingly like those which we have experienced, may be\nattended with different or contrary effects. (E. 4.2.18)\n\n\nIt is possible, he says, to clearly and distinctly conceive of a\nsituation where the unobserved case does not follow the regularity so\nfar observed (E. 4.2.18, T. 1.3.6.5/89).\n\nSecond, Hume argues that the reasoning also cannot be \u201csuch as\nregard matter of fact and real existence\u201d. He also calls this\n\u201cprobable\u201d reasoning. All such reasoning, he claims,\n\u201cproceed upon the supposition, that the future will be\nconformable to the past\u201d, in other words on the Uniformity\nPrinciple (E. 4.2.19).\n\nTherefore, if the chain of reasoning is based on an argument of this\nkind it will again be relying on this supposition, \u201cand taking\nthat for granted, which is the very point in question\u201d. (E.\n4.2.19, see also T. 1.3.6.7/90). The second type of reasoning then\nfails to provide a chain of reasoning which is not circular.\n\nIn the Treatise version, Hume concludes\n\n\nThus, not only our reason fails us in the discovery of the\nultimate connexion of causes and effects, but even after\nexperience has inform\u2019d us of their constant\nconjunction, \u2019tis impossible for us to satisfy ourselves by\nour reason, why we shou\u2019d extend that experience beyond those\nparticular instances, which have fallen under our observation. (T.\n1.3.6.11/91\u20132)\n\n\nThe conclusion then is that our tendency to project past regularities\ninto the future is not underpinned by reason. The problem of induction\nis to find a way to avoid this conclusion, despite Hume\u2019s\nargument.\n\nAfter presenting the problem, Hume does present his own\n\u201csolution\u201d to the doubts he has raised (E. 5, T.\n1.3.7\u201316). This consists of an explanation of what the inductive\ninferences are driven by, if not reason. In the Treatise Hume\nraises the problem of induction in an explicitly contrastive way. He\nasks whether the transition involved in the inference is produced\n\n\nby means of the understanding or imagination; whether we are\ndetermin\u2019d by reason to make the transition, or by a certain\nassociation and relation of perceptions? (T. 1.3.6.4)\n\n\nAnd he goes on to summarize the conclusion by saying\n\n\nWhen the mind, therefore, passes from the idea or impression of one\nobject to the idea or belief of another, it is not determin\u2019d by\nreason, but by certain principles, which associate together the ideas\nof these objects, and unite them in the imagination. (T. 1.3.6.12)\n\n\nThus, it is the imagination which is taken to be responsible for\nunderpinning the inductive inference, rather than reason.\n\nIn the Enquiry, Hume suggests that the step taken by the\nmind,\n\n\nwhich is not supported by any argument, or process of the\nunderstanding \u2026 must be induced by some other principle of\nequal weight and authority. (E. 5.1.2)\n\n\nThat principle is \u201ccustom\u201d or \u201chabit\u201d. The\nidea is that if one has seen similar objects or events constantly\nconjoined, then the mind is inclined to expect a similar regularity to\nhold in the future. The tendency or \u201cpropensity\u201d to draw\nsuch inferences, is the effect of custom:\n\n\n\u2026 having found, in many instances, that any two kinds of\nobjects, flame and heat, snow and cold, have always been conjoined\ntogether; if flame or snow be presented anew to the senses, the mind\nis carried by custom to expect heat or cold, and to believe,\nthat such a quality does exist and will discover itself upon a nearer\napproach. This belief is the necessary result of of placing the mind\nin such circumstances. It is an operation of the soul, when we are so\nsituated, as unavoidable as to feel the passion of love, when we\nreceive benefits; or hatred, when we meet with injuries. All these\noperations are a species of natural instincts, which no reasoning or\nprocess of the thought and understanding is able, either to produce,\nor to prevent. (E. 5.1.8)\n\n\nHume argues that the fact that these inferences do follow the course\nof nature is a kind of \u201cpre-established harmony\u201d (E.\n5.2.21). It is a kind of natural instinct, which may in fact be more\neffective in making us successful in the world, than if we relied on\nreason to make these inferences.\n2. Reconstruction\n\nHume\u2019s argument has been presented and formulated in many\ndifferent versions. There is also an ongoing lively discussion over\nthe historical interpretation of what Hume himself intended by the\nargument. It is therefore difficult to provide an unequivocal and\nuncontroversial reconstruction of Hume\u2019s argument. Nonetheless,\nfor the purposes of organizing the different responses to Hume\u2019s\nproblem that will be discussed in this article, the following\nreconstruction will serve as a useful starting point.\n\nHume\u2019s argument concerns specific inductive inferences such\nas:\n\n\nAll observed instances of A have been B.\n\nThe next instance of A will be B.\n\n\nLet us call this \u201cinference I\u201d. Inferences which\nfall under this type of schema are now often referred to as cases of\n\u201csimple enumerative induction\u201d.\n\nHume\u2019s own example is:\n\n\nAll observed instances of bread (of a particular appearance) have been\nnourishing.\n\nThe next instance of bread (of that appearance) will be\nnourishing.\n\n\nHume\u2019s argument then proceeds as follows (premises are labeled\nas P, and subconclusions and conclusions as C):\n\n\nP1.\nThere are only two kinds of arguments: demonstrative and probable\n(Hume\u2019s fork).\nP2.\nInference I presupposes the Uniformity Principle\n(UP).\n\n1st horn:\n\nP3. A\ndemonstrative argument establishes a conclusion whose negation is a\ncontradiction.\nP4. The\nnegation of the UP is not a contradiction.\nC1.There is no\ndemonstrative argument for the UP (by P3 and P4).\n\n\n2nd horn:\n\nP5. Any\nprobable argument for UP presupposes UP.\nP6. An argument\nfor a principle may not presuppose the same principle\n(Non-circularity).\nC2. There is\nno probable argument for the UP (by P5 and P6).\n\n\nConsequences:\n\nC3. There is no argument\nfor the UP (by P1, C1 and C2).\nP7. If there is no\nargument for the UP, there is no chain of reasoning from the premises\nto the conclusion of any inference that presupposes the UP.\nC4. There is\nno chain of reasoning from the premises to the conclusion of inference\nI (by P2, C3 and P7).\nP8. If there\nis no chain of reasoning from the premises to the conclusion of\ninference I, the inference is not justified.\nC5. Inference\nI is not justified (by C4 and P8).\n\n\n\nThere have been different interpretations of what Hume means by\n\u201cdemonstrative\u201d and \u201cprobable\u201d arguments.\nSometimes \u201cdemonstrative\u201d is equated with\n\u201cdeductive\u201d, and probable with \u201cinductive\u201d\n(e.g., Salmon 1966). Then the first horn of Hume\u2019s dilemma would\neliminate the possibility of a deductive argument, and the second\nwould eliminate the possibility of an inductive argument. However,\nunder this interpretation,\n premise P3\n would not hold, because it is possible for the conclusion of a\ndeductive argument to be a non-necessary proposition. Premise\n P3\n could be modified to say that a demonstrative (deductive) argument\nestablishes a conclusion that cannot be false if the premises are\ntrue. But then it becomes possible that the supposition that the\nfuture resembles the past, which is not a necessary proposition, could\nbe established by a deductive argument from some premises, though not\nfrom a priori premises (in contradiction to conclusion\n C1).\n\nAnother common reading is to equate \u201cdemonstrative\u201d with\n\u201cdeductively valid with a priori premises\u201d, and\n\u201cprobable\u201d with \u201chaving an empirical premise\u201d\n(e.g., Okasha 2001). This may be closer to the mark, if one thinks, as\nHume seems to have done, that premises which can be known a\npriori cannot be false, and hence are necessary. If the inference\nis deductively valid, then the conclusion of the inference from a\npriori premises must also be necessary. What the first horn of\nthe dilemma then rules out is the possibility of a deductively valid\nargument with a priori premises, and the second horn rules\nout any argument (deductive or non-deductive), which relies on an\nempirical premise.\n\nHowever, recent commentators have argued that in the historical\ncontext that Hume was situated in, the distinction he draws between\ndemonstrative and probable arguments has little to do with whether or\nnot the argument has a deductive form (Owen 1999; Garrett 2002). In\naddition, the class of inferences that establish conclusions whose\nnegation is a contradiction may include not just deductively valid\ninferences from a priori premises, but any inferences that\ncan be drawn using a priori reasoning (that is, reasoning\nwhere the transition from premises to the conclusion makes no appeal\nto what we learn from observations). It looks as though Hume does\nintend the argument of the first horn to rule out any a\npriori reasoning, since he says that a change in the course of\nnature cannot be ruled out \u201cby any demonstrative argument or\nabstract reasoning a priori\u201d (E. 5.2.18). On this\nunderstanding, a priori arguments would be ruled out by the\nfirst horn of Hume\u2019s dilemma, and empirical arguments by the\nsecond horn. This is the interpretation that I will adopt for the\npurposes of this article.\n\nIn Hume\u2019s argument, the UP plays a central role. As we will see\nin\n section 4.2,\n various authors have been doubtful about this principle. Versions of\nHume\u2019s argument have also been formulated which do not make\nreference to the UP. Rather they directly address the question of what\narguments can be given in support of the transition from the premises\nto the conclusion of the specific inductive inference I. What\narguments could lead us, for example, to infer that the next piece of\nbread will nourish from the observations of nourishing bread made so\nfar? For the first horn of the argument, Hume\u2019s argument can be\ndirectly applied. A demonstrative argument establishes a conclusion\nwhose negation is a contradiction. The negation of the conclusion of\nthe inductive inference is not a contradiction. It is not a\ncontradiction that the next piece of bread is not nourishing.\nTherefore, there is no demonstrative argument for the conclusion of\nthe inductive inference. In the second horn of the argument, the\nproblem Hume raises is a circularity. Even if Hume is wrong that all\ninductive inferences depend on the UP, there may still be a\ncircularity problem, but as we shall see in\n section 4.1,\n the exact nature of the circularity needs to be carefully considered.\nBut the main point at present is that the Humean argument is often\nformulated without invoking the UP.\n\nSince Hume\u2019s argument is a dilemma, there are two main ways to\nresist it. The first is to tackle the first horn and to argue that\nthere is after all a demonstrative argument \u2013here taken to mean\nan argument based on a priori reasoning\u2014that can\njustify the inductive inference. The second is to tackle the second\nhorn and to argue that there is after all a probable (or empirical)\nargument that can justify the inductive inference. We discuss the\ndifferent variants of these two approaches in sections\n 3\n and\n 4.\n\nThere are also those who dispute the consequences of the dilemma. For\nexample, some scholars have denied that Hume should be read as\ninvoking a premise such\n premise P8\n at all. The reason, they claim, is that he was not aiming for an\nexplicitly normative conclusion about justification such as\n C5.\n Hume certainly is seeking a \u201cchain of reasoning\u201d from the\npremises of the inductive inference to the conclusion, and he thinks\nthat an argument for the UP is necessary to complete the chain.\nHowever, one could think that there is no further premise regarding\njustification, and so the conclusion of his argument is simply\n C4:\n there is no chain of reasoning from the premises to the conclusion of\nan inductive inference. Hume could then be, as Don Garrett and David\nOwen have argued, advancing a \u201cthesis in cognitive\npsychology\u201d, rather than making a normative claim about\njustification (Owen 1999; Garrett 2002). The thesis is about the\nnature of the cognitive process underlying the inference. According to\nGarrett, the main upshot of Hume\u2019s argument is that there can be\nno reasoning process that establishes the UP. For Owen, the message is\nthat the inference is not drawn through a chain of ideas connected by\nmediating links, as would be characteristic of the faculty of\nreason.\n\nThere are also interpreters who have argued that Hume is merely trying\nto exclude a specific kind of justification of induction, based on a\nconception of reason predominant among rationalists of his time,\nrather than a justification in general (Beauchamp & Rosenberg\n1981; Baier 2009). In particular, it has been claimed that it is\n\u201can attempt to refute the rationalist belief that at least some\ninductive arguments are demonstrative\u201d (Beauchamp &\nRosenberg 1981: xviii). Under this interpretation,\n premise P8\n should be modified to read something like:\n\nIf there is no chain of reasoning based on demonstrative arguments\nfrom the premises to the conclusion of inference I, then\ninference I is not justified.\n\n\nSuch interpretations do however struggle with the fact that\nHume\u2019s argument is explicitly a two-pronged attack, which\nconcerns not just demonstrative arguments, but also probable\narguments.\n\nThe question of how expansive a normative conclusion to attribute to\nHume is a complex one. It depends in part on the interpretation of\nHume\u2019s own solution to his problem. As we saw in\n section 1,\n Hume attributes the basis of inductive inference to principles of the\nimagination in the Treatise, and in the Enquiry to\n\u201ccustom\u201d, \u201chabit\u201d, conceived as a kind of\nnatural instinct. The question is then whether this alternative\nprovides any kind of justification for the inference, even if not one\nbased on reason. On the face of it, it looks as though Hume is\nsuggesting that inductive inferences proceed on an entirely arational\nbasis. He clearly does not think that they do not succeed in producing\ngood outcomes. In fact, Hume even suggests that this operation of the\nmind may even be less \u201cliable to error and mistake\u201d than\nif it were entrusted to \u201cthe fallacious deductions of our\nreason, which is slow in its operations\u201d (E. 5.2.22). It is also\nnot clear that he sees the workings of the imagination as completely\ndevoid of rationality. For one thing, Hume talks about the imagination\nas governed by principles. Later in the Treatise, he\neven gives \u201crules\u201d and \u201clogic\u201d for\ncharacterizing what should count as a good causal inference (T.\n1.3.15). He also clearly sees it as possible to distinguish between\nbetter forms of such \u201creasoning\u201d, as he continues to call\nit. Thus, there may be grounds to argue that Hume was not trying to\nargue that inductive inferences have no rational foundation\nwhatsoever, but merely that they do not have the specific type of\nrational foundation which is rooted in the faculty of Reason.\n\nAll this indicates that there is room for debate over the intended\nscope of Hume\u2019s own conclusion. And thus there is also room for\ndebate over exactly what form a premise (such as\n premise P8)\n that connects the rest of his argument to a normative conclusion\nshould take. No matter who is right about this however, the fact\nremains that Hume has throughout history been predominantly read as\npresenting an argument for inductive skepticism.\n\nThere are a number of approaches which effectively, if not explicitly,\ntake issue with\n premise P8\n and argue that providing a chain of reasoning from the premises to\nthe conclusion is not a necessary condition for justification of an\ninductive inference. According to this type of approach, one may admit\nthat Hume has shown that inductive inferences are not justified in the\nsense that we have reasons to think their conclusions true, but still\nthink that weaker kinds of justification of induction are possible\n (section 5).\n Finally, there are some philosophers who do accept the skeptical\nconclusion\n C5\n and attempt to accommodate it. For example, there have been attempts\nto argue that inductive inference is not as central to scientific\ninquiry as is often thought\n (section 6).\n3. Tackling the First Horn of Hume\u2019s Dilemma\n\nThe first horn of Hume\u2019s argument, as formulated above, is aimed\nat establishing that there is no demonstrative argument for the UP.\nThere are several ways people have attempted to show that the first\nhorn does not definitively preclude a demonstrative or a\npriori argument for inductive inferences. One possible escape\nroute from the first horn is to deny\n premise P3,\n which amounts to admitting the possibility of synthetic a\npriori propositions\n (section 3.1).\n Another possibility is to attempt to provide an a priori\nargument that the conclusion of the inference is probable, though not\ncertain. The first horn of Hume\u2019s dilemma implies that there\ncannot be a demonstrative argument to the conclusion of an inductive\ninference because it is possible to conceive of the negation of the\nconclusion. For instance, it is quite possible to imagine that the\nnext piece of bread I eat will poison me rather than nourish me.\nHowever, this does not rule out the possibility of a demonstrative\nargument that establishes only that the bread is highly likely to\nnourish, not that it definitely will. One might then also challenge\n premise P8,\n by saying that it is not necessary for justification of an inductive\ninference to have a chain of reasoning from its premises to its\nconclusion. Rather it would suffice if we had an argument from the\npremises to the claim that the conclusion is probable or likely. Then\nan a priori justification of the inductive inference would\nhave been provided. There have been attempts to provide a\npriori justifications for inductive inference based on Inference\nto the Best Explanation\n (section 3.2).\n There are also attempts to find an a priori solution based\non probabilistic formulations of inductive inference, though many now\nthink that a purely a priori argument cannot be found because\nthere are empirical assumptions involved (sections\n 3.3\n -3.5).\n3.1 Synthetic a priori\n\nAs we have seen in\n section 1,\n Hume takes demonstrative arguments to have conclusions which are\n\u201crelations of ideas\u201d, whereas \u201cprobable\u201d or\n\u201cmoral\u201d arguments have conclusions which are\n\u201cmatters of fact\u201d. Hume\u2019s distinction between\n\u201crelations of ideas\u201d and \u201cmatters of fact\u201d\nanticipates the distinction drawn by Kant between\n\u201canalytic\u201d and \u201csynthetic\u201d propositions (Kant\n1781). A classic example of an analytic proposition is\n\u201cBachelors are unmarried men\u201d, and a synthetic proposition\nis \u201cMy bike tyre is flat\u201d. For Hume, demonstrative\narguments, which are based on a priori reasoning, can\nestablish only relations of ideas, or analytic propositions. The\nassociation between a prioricity and analyticity underpins\n premise P3,\n which states that a demonstrative argument establishes a conclusion\nwhose negation is a contradiction.\n\nOne possible response to Hume\u2019s problem is to deny\n premise P3,\n by allowing the possibility that a priori reasoning could\ngive rise to synthetic propositions. Kant famously argued in response\nto Hume that such synthetic a priori knowledge is possible\n(Kant 1781, 1783). He does this by a kind of reversal of the\nempiricist programme espoused by Hume. Whereas Hume tried to\nunderstand how the concept of a causal or necessary connection could\nbe based on experience, Kant argued instead that experience only comes\nabout through the concepts or \u201ccategories\u201d of the\nunderstanding. On his view, one can gain a priori knowledge\nof these concepts, including the concept of causation, by a\ntranscendental argument concerning the necessary preconditions of\nexperience. A more detailed account of Kant\u2019s response to Hume\ncan be found in de Pierris and Friedman 2013.\n3.2 The Nomological-Explanatory solution\n\nThe \u201cNomological-explanatory\u201d solution, which has been put\nforward by Armstrong, BonJour and Foster (Armstrong 1983; BonJour\n1998; Foster 2004) appeals to the principle of Inference to the Best\nExplanation (IBE). According to IBE, we should infer that the\nhypothesis which provides the best explanation of the evidence is\nprobably true. Proponents of the Nomological-Explanatory approach take\nInference to the Best Explanation to be a mode of inference which is\ndistinct from the type of \u201cextrapolative\u201d inductive\ninference that Hume was trying to justify. They also regard it as a\ntype of inference which although non-deductive, is justified a\npriori. For example, Armstrong says \u201cTo infer to the best\nexplanation is part of what it is to be rational. If that is not\nrational, what is?\u201d (Armstrong 1983: 59).\n\nThe a priori justification is taken to proceed in two steps.\nFirst, it is argued that we should recognize that certain observed\nregularities require an explanation in terms of some underlying law.\nFor example, if a coin persistently lands heads on repeated tosses,\nthen it becomes increasingly implausible that this occurred just\nbecause of \u201cchance\u201d. Rather, we should infer to the better\nexplanation that the coin has a certain bias. Saying that the coin\nlands heads not only for the observed cases, but also for the\nunobserved cases, does not provide an explanation of the observed\nregularity. Thus, mere Humean constant conjunction is not sufficient.\nWhat is needed for an explanation is a \u201cnon-Humean,\nmetaphysically robust conception of objective regularity\u201d\n(BonJour 1998), which is thought of as involving actual natural\nnecessity (Armstrong 1983; Foster 2004).\n\nOnce it has been established that there must be some metaphysically\nrobust explanation of the observed regularity, the second step is to\nargue that out of all possible metaphysically robust explanations, the\n\u201cstraight\u201d inductive explanation is the best one, where\nthe straight explanation extrapolates the observed frequency to the\nwider population. For example, given that a coin has some objective\nchance of landing heads, the best explanation of the fact that \\(m/n\\)\nheads have been so far observed, is that the objective chance of the\ncoin landing heads is \\(m/n\\). And this objective chance determines\nwhat happens not only in observed cases but also in unobserved\ncases.\n\nThe Nomological-Explanatory solution relies on taking IBE as a\nrational, a priori form of inference which is distinct from\ninductive inferences like inference I. However, one might\nalternatively view inductive inferences as a special case of IBE\n(Harman 1968), or take IBE to be merely an alternative way of\ncharacterizing inductive inference (Henderson 2014). If either of\nthese views is right, IBE does not have the necessary independence\nfrom inductive inference to provide a non-circular justification of\nit.\n\nOne may also object to the Nomological-Explanatory approach on the\ngrounds that regularities do not necessarily require an explanation in\nterms of necessary connections or robust metaphysical laws. The\nviability of the approach also depends on the tenability of a\nnon-Humean conception of laws. There have been several serious\nattempts to develop such an account (Armstrong 1983; Tooley 1977;\nDretske 1977), but also much criticism (see J. Carroll 2016).\n\nAnother critical objection is that the Nomological-Explanatory\nsolution simply begs the question, even if it is taken to be\nlegitimate to make use of IBE in the justification of induction. In\nthe first step of the argument we infer to a law or regularity which\nextends beyond the spatio-temporal region in which observations have\nbeen thus far made, in order to predict what will happen in the\nfuture. But why could a law that only applies to the observed\nspatio-temporal region not be an equally good explanation? The main\nreply seems to be that we can see a priori that laws with\ntemporal or spatial restrictions would be less good explanations.\nFoster argues that the reason is that this would introduce more\nmysteries:\n\n\nFor it seems to me that a law whose scope is restricted to some\nparticular period is more mysterious, inherently more puzzling, than\none which is temporally universal. (Foster 2004)\n\n3.3 Bayesian solution\n\nAnother way in which one can try to construct an a priori\nargument that the premises of an inductive inference make its\nconclusion probable, is to make use of the formalism of probability\ntheory itself. At the time Hume wrote, probabilities were used to\nanalyze games of chance. And in general, they were used to address the\nproblem of what we would expect to see, given that a certain cause was\nknown to be operative. This is the so-called problem of \u201cdirect\ninference\u201d. However, the problem of induction concerns the\n\u201cinverse\u201d problem of determining the cause or general\nhypothesis, given particular observations.\n\nOne of the first and most important methods for tackling the\n\u201cinverse\u201d problem using probabilities was developed by\nThomas Bayes. Bayes\u2019s essay containing the main results was\npublished after his death in 1764 (Bayes 1764). However, it is\npossible that the work was done significantly earlier and was in fact\nwritten in direct response to the publication of Hume\u2019s Enquiry\nin 1748 (see Zabell 1989: 290\u201393, for discussion of what is\nknown about the history).\n\nWe will illustrate the Bayesian method using the problem of drawing\nballs from an urn. Suppose that we have an urn which contains white\nand black balls in an unknown proportion. We draw a sample of balls\nfrom the urn by removing a ball, noting its color, and then putting it\nback before drawing again.\n\nConsider first the problem of direct inference. Given the proportion\nof white balls in the urn, what is the probability of various outcomes\nfor a sample of observations of a given size? Suppose the proportion\nof white balls in the urn is \\(\\theta = 0.6\\). The probability of\ndrawing one white ball in a sample of one is then \\(p(W; \\theta = 0.6)\n= 0.6\\). We can also compute the probability for other outcomes, such\nas drawing two white balls in a sample of two, using the rules of the\nprobability calculus (see section 1 of H\u00e1jek 2011). Generally,\nthe probability that \\(n_w\\) white balls are drawn in a sample of size\nN, is given by the binomial distribution: \n\\[ p(n_w;\\theta=x) = \\left(\\begin{matrix}N\\\\\nn_w\n\\end{matrix}\\right) x^{n_w} (1-x)^{(N-n_w)} \\]\n\n\nThis is a specific example of a \u201csampling distribution\u201d,\n\\(p(E\\mid H)\\), which gives the probability of certain evidence\nE in a sample, on the assumption that a certain hypothesis\nH is true. Calculation of the sampling distribution can in\ngeneral be done a priori, given the rules of the probability\ncalculus.\n\nHowever, the problem of induction is the inverse problem. We want to\ninfer not what the sample will be like, with a known hypothesis,\nrather we want to infer a hypothesis about the general situation or\npopulation, based on the observation of a limited sample. The\nprobabilities of the candidate hypotheses can then be used to inform\npredictions about further observations. In the case of the urn, for\nexample, we want to know what the observation of a particular sample\nfrequency of white balls, \\(\\frac{n_w}{N}\\), tells us about\n\\(\\theta\\), the proportion of white balls in the urn.\n\nThe idea of the Bayesian approach is to assign probabilities not only\nto the events which constitute evidence, but also to hypotheses. One\nstarts with a \u201cprior probability\u201d distribution over the\nrelevant hypotheses \\(p(H)\\). On learning some evidence E,\nthe Bayesian updates the prior \\(p(H)\\) to the conditional probability\n\\(p(H\\mid E)\\). This update rule is called the \u201crule of\nconditionalisation\u201d. The conditional probability \\(p(H\\mid E)\\)\nis known as the \u201cposterior probability\u201d, and is calculated\nusing Bayes\u2019 rule: \n\\[ p(H\\mid E) = \\frac{p(E\\mid H) p(H)}{p(E)} \\]\n\n\nHere the sampling distribution can be taken to be a conditional\nprobability \\(p(E\\mid H)\\), which is known as the\n\u201clikelihood\u201d of the hypothesis H on evidence\nE.\n\nOne can then go on to compute the predictive distribution for as yet\nunobserved data \\(E'\\), given observations E. The predictive\ndistribution in a Bayesian approach is given by \n\\[ p(E'\\mid E) = \\sum_{H} p(E'\\mid H) p(H\\mid E) \\]\n\n\nwhere the sum becomes an integral in cases where H is a\ncontinuous variable.\n\nFor the urn example, we can compute the posterior probability\n\\(p(\\theta\\mid n_w)\\) using Bayes\u2019 rule, and the likelihood\ngiven by the binomial distribution above. In order to do so, we also\nneed to assign a prior probability distribution to the parameter\n\\(\\theta\\). One natural choice, which was made early on by Bayes\nhimself and by Laplace, is to put a uniform prior over the parameter\n\\(\\theta\\). Bayes\u2019 own rationale for this choice was that then\nif you work out the probability of each value for the number of whites\nin the sample based only on the prior, before any data is observed,\nall those probabilities are equal. Laplace had a different\njustification, based on the Principle of Indifference. This principle\nstates that if you don\u2019t have any reason to favor one hypothesis\nover another, you should assign them all equal probabilities.\n\nWith the choice of uniform prior, the posterior probability and\npredictive distribution can be calculated. It turns out that the\nprobability that the next ball will be white, given that \\(n_w\\) of\nN draws were white, is given by \n\\[ p(w\\mid n_w) = \\frac{n_w + 1}{N+2} \\]\n\n\nThis is Laplace\u2019s famous \u201crule of succession\u201d\n(1814). Suppose on the basis of observing 90 white balls out of 100,\nwe calculate by the rule of succession that the probability of the\nnext ball being white is \\(91/102=0.89\\). It is quite conceivable that\nthe next ball might be black. Even in the case, where all 100 balls\nhave been white, so that the probability of the next ball being white\nis 0.99, there is still a small probability that the next ball is not\nwhite. What the probabilistic reasoning supplies then is not an\nargument to the conclusion that the next ball will be a certain color,\nbut an argument to the conclusion that certain future observations are\nvery likely given what has been observed in the past.\n\nOverall, the Bayes-Laplace argument in the urn case provides an\nexample of how probabilistic reasoning can take us from evidence about\nobservations in the past to a prediction for how likely certain future\nobservations are. The question is what kind of solution, if any, this\ntype of calculation provides to the problem of induction. At first\nsight, since it is just a mathematical calculation, it looks as though\nit does indeed provide an a priori argument from the premises\nof an inductive inference to the proposition that a certain conclusion\nis probable.\n\nHowever, in order to establish this definitively, one would need to\nargue that all the components and assumptions of the argument are\na priori and this requires further examination of at least\nthree important issues.\n\nFirst, the Bayes-Laplace argument relies on the rules of the\nprobability calculus. What is the status of these rules? Does\nfollowing them amount to a priori reasoning? The answer to\nthis depends in part on how probability itself is interpreted. Broadly\nspeaking, there are prominent interpretations of probability according\nto which the rules plausibly have a priori status and could\nform the basis of a demonstrative argument. These include the\nclassical interpretation originally developed by Laplace (1814), the\nlogical interpretation (Keynes (1921), Johnson (1921), Jeffreys\n(1939), Carnap (1950), Cox (1946, 1961), and the subjectivist\ninterpretation of Ramsey (1926), Savage (1954), and de Finetti (1964).\nAttempts to argue for a probabilistic a priori solution to\nthe problem of induction have been primarily associated with these\ninterpretations.\n\nSecondly, in the case of the urn, the Bayes-Laplace argument is based\non a particular probabilistic model\u2014the binomial model. This\ninvolves the assumption that there is a parameter describing an\nunknown proportion \\(\\theta\\) of balls in the urn, and that the data\namounts to independent draws from a distribution over that parameter.\nWhat is the basis of these assumptions? Do they generalize to other\ncases beyond the actual urn case\u2014i.e., can we see observations\nin general as analogous to draws from an \u201cUrn of Nature\u201d?\nThere has been a persistent worry that these types of assumptions,\nwhile reasonable when applied to the case of drawing balls from an\nurn, will not hold for other cases of inductive inference. Thus, the\nprobabilistic solution to the problem of induction might be of\nrelatively limited scope. At the least, there are some assumptions\ngoing into the choice of model here that need to be made explicit.\nArguably the choice of model introduces empirical assumptions, which\nwould mean that the probabilistic solution is not an a priori\none.\n\nThirdly, the Bayes-Laplace argument relies on a particular choice of\nprior probability distribution. What is the status of this assignment,\nand can it be based on a priori principles? Historically, the\nBayes-Laplace choice of a uniform prior, as well as the whole concept\nof classical probability, relied on the Principle of Indifference.\nThis principle has been regarded by many as an a priori\nprinciple. However, it has also been subjected to much criticism on\nthe grounds that it can give rise to inconsistent probability\nassignments (Bertrand 1888; Borel 1909; Keynes 1921). Such\ninconsistencies are produced by there being more than one way to carve\nup the space of alternatives, and different choices give rise to\nconflicting probability assignments. One attempt to rescue the\nPrinciple of Indifference has been to appeal to explanationism, and\nargue that the principle should be applied only to the carving of the\nspace at \u201cthe most explanatorily basic level\u201d, where this\nlevel is identified according to an a priori notion of\nexplanatory priority (Huemer 2009).\n\nThe quest for an a priori argument for the assignment of the\nprior has been largely abandoned. For many, the subjectivist\nfoundations developed by Ramsey, de Finetti and Savage provide a more\nsatisfactory basis for understanding probability. From this point of\nview, it is a mistake to try to introduce any further a\npriori constraints on the probabilities beyond those dictated by\nthe probability rules themselves. Rather the assignment of priors may\nreflect personal opinions or background knowledge, and no prior is\na priori an unreasonable choice.\n\nSo far, we have considered probabilistic arguments which place\nprobabilities over hypotheses in a hypothesis space as well as\nobservations. There is also a tradition of attempts to determine what\nprobability distributions we should have, given certain observations,\nfrom the starting point of a joint probability distribution over all\nthe observable variables. One may then postulate axioms directly on\nthis distribution over observables, and examine the consequences for\nthe predictive distribution. Much of the development of inductive\nlogic, including the influential programme by Carnap, proceeded in\nthis manner (Carnap 1950, 1952).\n\nThis approach helps to clarify the role of the assumptions behind\nprobabilistic models. One assumption that one can make about the\nobservations is that they are \u201cexchangeable\u201d. This means\nthat the joint distribution of the random variables is invariant under\npermutations. Informally, this means that the order of the\nobservations does not affect the probability. For instance, in the urn\ncase, this would mean that drawing first a white ball and then a black\nball is just as probable as first drawing a black and then a white. De\nFinetti proved a general representation theorem that if the joint\nprobability distribution of an infinite sequence of random variables\nis assumed to be exchangeable, then it can be written as a mixture of\ndistribution functions from each of which the data behave as if they\nare independent random draws (de Finetti 1964). In the case of the urn\nexample, the theorem shows that it is as if the data are\nindependent random draws from a binomial distribution over a parameter\n\\(\\theta\\), which itself has a prior probability distribution.\n\nThe assumption of exchangeability may be seen as a natural\nformalization of Hume\u2019s assumption that the past resembles the\nfuture. This is intuitive because assuming exchangeability means\nthinking that the order of observations, both past and future, does\nnot matter to the probability assignments.\n\nHowever, the development of the programme of inductive logic revealed\nthat many generalizations are possible. For example, Johnson proposed\nto assume an axiom he called the \u201csufficientness\npostulate\u201d. This states that outcomes can be of a number of\ndifferent types, and that the conditional probability that the next\noutcome is of type i depends only on the number of previous\ntrials and the number of previous outcomes of type i (Johnson\n1932). Assuming the sufficientness postulate for three or more types\ngives rise to a general predictive distribution corresponding to\nCarnap\u2019s \u201ccontinuum of inductive methods\u201d (Carnap\n1952). This predictive distribution takes the form: \n\\[ p(i\\mid N_1,N_2,\\ldots N_t)= \\frac{N_i + k}{N_1 +N_2 + \\cdots + N_t + kt} \\]\n\n\nfor some positive number k. This reduces to Laplace\u2019s\nrule of succession when \\(t=2\\) and \\(k=1\\).\n\nGeneralizations of the notion of exchangeability, such as\n\u201cpartial exchangeability\u201d and \u201cMarkov\nexchangeability\u201d, have been explored, and these may be thought\nof as forms of symmetry assumption (Zabell 1988; Skyrms 2012). As less\nrestrictive axioms on the probabilities for observables are assumed,\nthe result is that there is no longer a unique result for the\nprobability of a prediction, but rather a whole class of possible\nprobabilities, mapped out by a generalized rule of succession such as\nthe above. Therefore, in this tradition, as in the Bayes-Laplace\napproach, we have moved away from producing an argument which produces\na unique a priori probabilistic answer to Hume\u2019s problem.\n\nOne might think then that the assignment of the prior, or the relevant\ncorresponding postulates on the observable probability distribution,\nis precisely where empirical assumptions enter into inductive\ninferences. The probabilistic calculations are empirical arguments,\nrather than a priori ones. If this is correct, then the\nprobabilistic framework has not in the end provided an a\npriori solution to the problem of induction, but it has rather\nallowed us to clarify what could be meant by Hume\u2019s claim that\ninductive inferences rely on the Uniformity Principle.\n3.4 Partial solutions\n\nSome think that although the problem of induction is not solved, there\nis in some sense a partial solution, which has been called a\n\u201clogical solution\u201d. Howson, for example, argues that\n\u201cInductive reasoning is justified to the extent that it is\nsound, given appropriate premises\u201d (Howson 2000: 239, his\nemphasis). According to this view, there is no getting away from an\nempirical premise for inductive inferences, but we might still think\nof Bayesian conditioning as functioning like a kind of logic or\n\u201cconsistency constraint\u201d which \u201cgenerates\npredictions from the assumptions and observations together\u201d\n(Romeijn 2004: 360). Once we have an empirical assumption,\ninstantiated in the prior probability, and the observations, Bayesian\nconditioning tells us what the resulting predictive probability\ndistribution should be.\n\nThe idea of a partial solution also arises in the context of the\nlearning theory that grounds contemporary machine learning. Machine\nlearning is a field in computer science concerned with algorithms that\nlearn from experience. Examples are algorithms which can be trained to\nrecognise or classify patterns in data. Learning theory concerns\nitself with finding mathematical theorems which guarantee the\nperformance of algorithms which are in practical use. In this domain,\nthere is a well-known finding that learning algorithms are only\neffective if they have \u2018inductive bias\u2019 \u2014 that is, if\nthey make some a priori assumptions about the domain they are employed\nupon (Mitchell 1997).\n\nThe idea is also given formal expression in the so-called\n\u2018No-Free-Lunch theorems\u2019 (Wolpert 1992, 1996, 1997). These\ncan be interpreted as versions of the argument in Hume\u2019s first\nfork since they establish that there can be no contradiction in the\nalgorithm not performing well, since there are a priori\npossible situations in which it does not (Sterkenburg and\nGr\u00fcnwald 2021:9992). Given Hume\u2019s premise\n P3,\n this rules out a demonstrative argument for its good performance.\n\nPremise\n P3\n can perhaps be challenged on the grounds that a priori\njustifications can also be given for contingent propositions. Even\nthough an inductive inference can fail in some possible situations, it\ncould still be reasonable to form an expectation of reliability if we\nspread our credence equally over all the possibilities and have reason\nto think (or at least no reason to doubt) that the cases where\ninductive inference is unreliable require a \u2018very specific\narrangement of things\u2019 and thus form a small fraction of the\ntotal space of possibilities (White 2015). The No-Free-Lunch theorems\nmake difficulties for this approach since they show that if we put a\nuniform distribution over all logically possible sequences of future\nevents, any learning algorithm is expected to have a generalisation\nerror of 1/2, and hence to do no better than guessing at random\n(Schurz 2021b).\n\nThe No-Free-Lunch theorems may be seen as fundamental limitations on\njustifying learning algorithms when these algorithms are seen as\n\u2018purely data-driven\u2019 \u2014 that is as mappings from possible\ndata to conclusions. However, learning algorithms may also be\nconceived as functions not only of input data, but also of a\nparticular model (Sterkenburg and Gr\u00fcnwald 2021). For example,\nthe Bayesian \u2018algorithm\u2019 gives a universal recipe for\ntaking a particular model and prior and updating on the data. A number\nof theorems in learning theory provide general guarantees for the\nperformance of such recipes. For instance, there are theorems which\nguarantee convergence of the Bayesian algorithm (Ghosal, Ghosh and van\nder Vaart 2000, Ghosal, Lember and van der Vaart 2008). In each\ninstantiation, this convergence is relative to a particular specific\nprior. Thus, although the considerations first raised by Hume, and\nlater instantiated in the No-Free-Lunch theorems, preclude any\nuniversal model-independent justification for learning algorithms, it\ndoes not rule out partial justifications in the form of such general a\npriori \u2018model-relative\u2019 learning guarantees (Sterkenburg\nand Gr\u00fcnwald 2021).\n3.5 The combinatorial approach\n\nAn alternative attempt to use probabilistic reasoning to produce an\na priori justification for inductive inferences is the\nso-called \u201ccombinatorial\u201d solution. This was first put\nforward by Donald C. Williams (1947) and later developed by David\nStove (1986).\n\nLike the Bayes-Laplace argument, the solution relies heavily on the\nidea that straightforward a priori calculations can be done\nin a \u201cdirect inference\u201d from population to sample. As we\nhave seen, given a certain population frequency, the probability of\ngetting different frequencies in a sample can be calculated\nstraightforwardly based on the rules of the probability calculus. The\nBayes-Laplace argument relied on inverting the probability\ndistribution using Bayes\u2019 rule to get from the sampling\ndistribution to the posterior distribution. Williams instead proposes\nthat the inverse inference may be based on a certain logical\nsyllogism: the proportional (or statistical) syllogism.\n\nThe proportional, or statistical syllogism, is the following:\n\nOf all the things that are M, \\(m/n\\) are\nP.\na is an M\n\n\nTherefore, a is P, with probability \\(m/n\\).\n\nFor example, if 90% of rabbits in a population are white and we\nobserve a rabbit a, then the proportional syllogism says that\nwe infer that a is white with a probability of 90%. Williams\nargues that the proportional syllogism is a non-deductive logical\nsyllogism, which effectively interpolates between the syllogism for\nentailment\n\nAll Ms are P\na is an M\n\n\nTherefore, a is P.\n\nAnd the syllogism for contradiction\n\nNo M is P\na is M\n\n\nTherefore, a is not P.\n\nThis syllogism can be combined with an observation about the behavior\nof increasingly large samples. From calculations of the sampling\ndistribution, it can be shown that as the sample size increases, the\nprobability that the sample frequency is in a range which closely\napproximates the population frequency also increases. In fact,\nBernoulli\u2019s law of large numbers states that the probability\nthat the sample frequency approximates the population frequency tends\nto one as the sample size goes to infinity. Williams argues that such\nresults support a \u201cgeneral over-all premise, common to all\ninductions, that samples \u2018match\u2019 their populations\u201d\n(Williams 1947: 78).\n\nWe can then apply the proportional syllogism to samples from a\npopulation, to get the following argument:\n\nMost samples match their population\nS is a sample.\n\n\nTherefore, S matches its population, with high\nprobability.\n\nThis is an instance of the proportional syllogism, and it uses the\ngeneral result about samples matching populations as the first major\npremise.\n\nThe next step is to argue that if we observe that the sample contains\na proportion of \\(m/n\\) Fs, then we can conclude that since\nthis sample with high probability matches its population, the\npopulation, with high probability, has a population frequency that\napproximates the sample frequency \\(m/n\\). Both Williams and Stove\nclaim that this amounts to a logical a priori solution to the\nproblem of induction.\n\nA number of authors have expressed the view that the Williams-Stove\nargument is only valid if the sample S is drawn randomly from\nthe population of possible samples\u2014i.e., that any sample is as\nlikely to be drawn as any other (Brown 1987; Will 1948; Giaquinto\n1987). Sometimes this is presented as an objection to the application\nof the proportional syllogism. The claim is that the proportional\nsyllogism is only valid if a is drawn randomly from the\npopulation of Ms. However, the response has been that there\nis no need to know that the sample is randomly drawn in order to apply\nthe syllogism (Maher 1996; Campbell 2001; Campbell & Franklin\n2004). Certainly if you have reason to think that your sampling\nprocedure is more likely to draw certain individuals than\nothers\u2014for example, if you know that you are in a certain\nlocation where there are more of a certain type\u2014then you should\nnot apply the proportional syllogism. But if you have no such reasons,\nthe defenders claim, it is quite rational to apply it. Certainly it is\nalways possible that you draw an unrepresentative sample\u2014meaning\none of the few samples in which the sample frequency does not match\nthe population frequency\u2014but this is why the conclusion is only\nprobable and not certain.\n\nThe more problematic step in the argument is the final step, which\ntakes us from the claim that samples match their populations with high\nprobability to the claim that having seen a particular sample\nfrequency, the population from which the sample is drawn has frequency\nclose to the sample frequency with high probability. The problem here\nis a subtle shift in what is meant by \u201chigh probability\u201d,\nwhich has formed the basis of a common misreading of\nBernouilli\u2019s theorem. Hacking (1975: 156\u201359) puts the\npoint in the following terms. Bernouilli\u2019s theorem licenses the\nclaim that much more often than not, a small interval around the\nsample frequency will include the true population frequency. In other\nwords, it is highly probable in the sense of \u201cusually\nright\u201d to say that the sample matches its population. But this\ndoes not imply that the proposition that a small interval around the\nsample will contain the true population frequency is highly probable\nin the sense of \u201ccredible on each occasion of use\u201d. This\nwould mean that for any given sample, it is highly credible that the\nsample matches its population. It is quite compatible with the claim\nthat it is \u201cusually right\u201d that the sample matches its\npopulation to say that there are some samples which do not match their\npopulations at all. Thus one cannot conclude from Bernouilli\u2019s\ntheorem that for any given sample frequency, we should assign high\nprobability to the proposition that a small interval around the sample\nfrequency will contain the true population frequency. But this is\nexactly the slide that Williams makes in the final step of his\nargument. Maher (1996) argues in a similar fashion that the last step\nof the Williams-Stove argument is fallacious. In fact, if one wants to\ndraw conclusions about the probability of the population frequency\ngiven the sample frequency, the proper way to do so is by using the\nBayesian method described in the previous section. But, as we there\nsaw, this requires the assignment of prior probabilities, and this\nexplains why many people have thought that the combinatorial solution\nsomehow illicitly presupposed an assumption like the principle of\nindifference. The Williams-Stove argument does not in fact give us an\nalternative way of inverting the probabilities which somehow bypasses\nall the issues that Bayesians have faced.\n4. Tackling the Second Horn of Hume\u2019s Dilemma\n\nSo far we have considered ways in which the first horn of Hume\u2019s\ndilemma might be tackled. But it is of course also possible to take on\nthe second horn instead.\n\nOne may argue that a probable argument would not, despite what Hume\nsays, be circular in a problematic way (we consider responses of this\nkind in\n section 4.1).\n Or, one might attempt to argue that probable arguments are not\ncircular at all\n (section 4.2).\n4.1 Inductive Justifications of Induction\n\nOne way to tackle the second horn of Hume\u2019s dilemma is to reject\n premise P6,\n which rules out circular arguments. Some have argued that certain\nkinds of circular arguments would provide an acceptable justification\nfor the inductive inference. Since the justification would then itself\nbe an inductive one, this approach is often referred to as an\n\u201cinductive justification of induction\u201d.\n\nFirst we should examine how exactly the Humean circularity supposedly\narises. Take the simple case of enumerative inductive inference that\nfollows the following pattern (X):\n\n\nMost observed Fs have been Gs\n\nTherefore: Most Fs are Gs.\n\n\nHume claims that such arguments presuppose the Uniformity Principle\n(UP). According to premises\n P7\n and\n P8,\n this supposition also needs to be supported by an argument in order\nthat the inductive inference be justified. A natural idea is that we\ncan argue for the Uniformity Principle on the grounds that \u201cit\nworks\u201d. We know that it works, because past instances of\narguments which relied upon it were found to be successful. This alone\nhowever is not sufficient unless we have reason to think that such\narguments will also be successful in the future. That claim must\nitself be supported by an inductive argument (S):\n\n\nMost arguments of form X that rely on UP have succeeded in\nthe past.\n\nTherefore, most arguments of form X that rely on UP\nsucceed.\n\n\nBut this argument itself depends on the UP, which is the very\nsupposition which we were trying to justify.\n\nAs we have seen in\n section 2,\n some reject Hume\u2019s claim that all inductive inferences\npresuppose the UP. However, the argument that basing the justification\nof the inductive inference on a probable argument would result in\ncircularity need not rely on this claim. The circularity concern can\nbe framed more generally. If argument S relies on\nsomething which is already presupposed in inference\nX, then argument S cannot be used to justify\ninference X. The question though is what precisely the\nsomething is.\n\nSome authors have argued that in fact S does not rely on any\npremise or even presupposition that would require us to already know\nthe conclusion of X. S is then not a \u201cpremise\ncircular\u201d argument. Rather, they claim, it is\n\u201crule-circular\u201d\u2014it relies on a rule of inference in\norder to reach the conclusion that that very rule is reliable. Suppose\nwe adopt the rule R which says that when it is observed that\nmost Fs are Gs, we should infer that most\nFs are Gs. Then inference X relies on rule\nR. We want to show that rule R is reliable. We could\nappeal to the fact that R worked in the past, and so, by an\ninductive argument, it will also work in the future. Call this\nargument S*:\n\n\nMost inferences following rule R have been successful\n\nTherefore, most inferences following R are successful.\n\n\nSince this argument itself uses rule R, using it to establish\nthat R is reliable is rule-circular.\n\nSome authors have then argued that although premise-circularity is\nvicious, rule-circularity is not (Cleve 1984; Papineau 1992). One\nreason for thinking rule-circularity is not vicious would be if it is\nnot necessary to know or even justifiably believe that rule R\nis reliable in order to move to a justified conclusion using the rule.\nThis is a claim made by externalists about justification (Cleve 1984).\nThey say that as long as R is in fact reliable, one\ncan form a justified belief in the conclusion of an argument relying\non R, as long as one has justified belief in the\npremises.\n\nIf one is not persuaded by the externalist claim, one might attempt to\nargue that rule circularity is benign in a different fashion. For\nexample, the requirement that a rule be shown to be reliable without\nany rule-circularity might appear unreasonable when the rule is of a\nvery fundamental nature. As Lange puts it:\n\n\nIt might be suggested that although a circular argument is ordinarily\nunable to justify its conclusion, a circular argument is acceptable in\nthe case of justifying a fundamental form of reasoning. After all,\nthere is nowhere more basic to turn, so all that we can reasonably\ndemand of a fundamental form of reasoning is that it endorse itself.\n(Lange 2011: 56)\n\n\nProponents of this point of view point out that even deductive\ninference cannot be justified deductively. Consider Lewis\nCarroll\u2019s dialogue between Achilles and the Tortoise (Carroll\n1895). Achilles is arguing with a Tortoise who refuses to perform\nmodus ponens. The Tortoise accepts the premise that\np, and the premise that p implies q but he\nwill not accept q. How can Achilles convince him? He manages\nto persuade him to accept another premise, namely \u201cif p\nand p implies q, then q\u201d. But the\nTortoise is still not prepared to infer to q. Achilles goes\non adding more premises of the same kind, but to no avail. It appears\nthen that modus ponens cannot be justified to someone who is\nnot already prepared to use that rule.\n\nIt might seem odd if premise circularity were vicious, and rule\ncircularity were not, given that there appears to be an easy\ninterchange between rules and premises. After all, a rule can always,\nas in the Lewis Carroll story, be added as a premise to the argument.\nBut what the Carroll story also appears to indicate is that there is\nindeed a fundamental difference between being prepared to accept a\npremise stating a rule (the Tortoise is happy to do this), and being\nprepared to use that rule (this is what the Tortoise refuses to\ndo).\n\nSuppose that we grant that an inductive argument such as S\n(or S*) can support an inductive inference X without\nvicious circularity. Still, a possible objection is that the argument\nsimply does not provide a full justification of X. After all,\nless sane inference rules such as counterinduction can support\nthemselves in a similar fashion. The counterinductive rule is CI:\n\n\nMost observed As are Bs.\n\nTherefore, it is not the case that most As are\nBs.\n\n\nConsider then the following argument CI*:\n\n\nMost CI arguments have been unsuccessful\n\nTherefore, it is not the case that most CI arguments are unsuccessful,\ni.e., many CI arguments are successful.\n\n\nThis argument therefore establishes the reliability of CI in a\nrule-circular fashion (see Salmon 1963).\n\nArgument S can be used to support inference X, but\nonly for someone who is already prepared to infer inductively by using\nS. It cannot convince a skeptic who is not prepared to rely\nupon that rule in the first place. One might think then that the\nargument is simply not achieving very much.\n\nThe response to these concerns is that, as Papineau puts it, the\nargument is \u201cnot supposed to do very much\u201d\n(Papineau 1992: 18). The fact that a counterinductivist counterpart of\nthe argument exists is true, but irrelevant. It is conceded that the\nargument cannot persuade either a counterinductivist, or a skeptic.\nNonetheless, proponents of the inductive justification maintain that\nthere is still some added value in showing that inductive inferences\nare reliable, even when we already accept that there is nothing\nproblematic about them. The inductive justification of induction\nprovides a kind of important consistency check on our existing\nbeliefs.\n4.2 No Rules\n\nIt is possible to go even further in an attempt to dismantle the\nHumean circularity. Maybe inductive inferences do not even have a rule\nin common. What if every inductive inference is essentially unique?\nThis can be seen as rejecting Hume\u2019s premise\n P5.\n Okasha, for example, argues that Hume\u2019s circularity problem can\nbe evaded if there are \u201cno rules\u201d behind induction (Okasha\n2005a,b). Norton puts forward the similar idea that all inductive\ninferences are material, and have nothing formal in common (Norton\n2003, 2010, 2021).\n\nProponents of such views have attacked Hume\u2019s claim that there\nis a UP on which all inductive inferences are based. There have long\nbeen complaints about the vagueness of the Uniformity Principle\n(Salmon 1953). The future only resembles the past in some respects,\nbut not others. Suppose that on all my birthdays so far, I have been\nunder 40 years old. This does not give me a reason to expect that I\nwill be under 40 years old on my next birthday. There seems then to be\na major lacuna in Hume\u2019s account. He might have explained or\ndescribed how we draw an inductive inference, on the assumption that\nit is one we can draw. But he leaves untouched the question\nof how we distinguish between cases where we extrapolate a regularity\nlegitimately, regarding it as a law, and cases where we do not.\n\nNelson Goodman is often seen as having made this point in a\nparticularly vivid form with his \u201cnew riddle of induction\u201d\n(Goodman 1955: 59\u201383). Suppose we define a predicate\n\u201cgrue\u201d in the following way. An object is\n\u201cgrue\u201d when it is green if observed before time t\nand blue otherwise. Goodman considers a thought experiment in which we\nobserve a bunch of green emeralds before time t. We could\ndescribe our results by saying all the observed emeralds are green.\nUsing a simple enumerative inductive schema, we could infer from the\nresult that all observed emeralds are green, that all emeralds are\ngreen. But equally, we could describe the same results by saying that\nall observed emeralds are grue. Then using the same schema, we could\ninfer from the result that all observed emeralds are grue, that all\nemeralds are grue. In the first case, we expect an emerald observed\nafter time t to be green, whereas in the second, we expect it\nto be blue. Thus the two predictions are incompatible. Goodman claims\nthat what Hume omitted to do was to give any explanation for why we\nproject predicates like \u201cgreen\u201d, but not predicates like\n\u201cgrue\u201d. This is the \u201cnew riddle\u201d, which is\noften taken to be a further problem of induction that Hume did not\naddress.\n\nOne moral that could be taken from Goodman is that there is not one\ngeneral Uniformity Principle that all probable arguments rely upon\n(Sober 1988; Norton 2003; Okasha 2001, 2005a,b, Jackson 2019). Rather\neach inductive inference presupposes some more specific empirical\npresupposition. A particular inductive inference depends on some\nspecific way in which the future resembles the past. It can then be\njustified by another inductive inference which depends on some quite\ndifferent empirical claim. This will in turn need to be\njustified\u2014by yet another inductive inference. The nature of\nHume\u2019s problem in the second horn is thus transformed. There is\nno circularity. Rather there is a regress of inductive justifications,\neach relying on their own empirical presuppositions (Sober 1988;\nNorton 2003; Okasha 2001, 2005a,b).\n\nOne way to put this point is to say that Hume\u2019s argument rests\non a quantifier shift fallacy (Sober 1988; Okasha 2005a). Hume says\nthat there exists a general presupposition for all inductive\ninferences, whereas he should have said that for each inductive\ninference, there is some presupposition. Different inductive\ninferences then rest on different empirical presuppositions, and the\nproblem of circularity is evaded.\n\nWhat will then be the consequence of supposing that Hume\u2019s\nproblem should indeed have been a regress, rather than a circularity?\nHere different opinions are possible. On the one hand, one might think\nthat a regress still leads to a skeptical conclusion (Schurz and Thorn\n2020). So although the exact form in which Hume stated his problem was\nnot correct, the conclusion is not substantially different (Sober\n1988). Another possibility is that the transformation mitigates or\neven removes the skeptical problem. For example, Norton argues that\nthe upshot is a dissolution of the problem of induction, since the\nregress of justifications benignly terminates (Norton 2003). And\nOkasha more mildly suggests that even if the regress is infinite,\n\u201cPerhaps infinite regresses are less bad than vicious circles\nafter all\u201d (Okasha 2005b: 253).\n\nAny dissolution of Hume\u2019s circularity does not depend only on\narguing that the UP should be replaced by empirical presuppositions\nwhich are specific to each inductive inference. It is also necessary\nto establish that inductive inferences share no common\nrules\u2014otherwise there will still be at least some\nrule-circularity. Okasha suggests that the Bayesian model of\nbelief-updating is an illustration how induction can be characterized\nin a rule-free way, but this is problematic, since in this model all\ninductive inferences still share the common rule of Bayesian\nconditionalisation. Norton\u2019s material theory of induction\npostulates a rule-free characterization of induction, but it is not\nclear whether it really can avoid any role for general rules\n(Achinstein 2010, Kelly 2010, Worrall 2010).\n5. Alternative Conceptions of Justification\n\nHume is usually read as delivering a negative verdict on the\npossibility of justifying inference I, via a premise such as\n P8,\n though as we have seen in section\n section 2,\n some have questioned whether Hume is best interpreted as drawing a\nconclusion about justification of inference I at all. In this\nsection we examine approaches which question in different ways whether\n premise P8\n really does give a valid necessary condition for justification of\ninference I and propose various alternative conceptions of\njustification.\n5.1 Postulates and Hinges\n\nOne approach has been to turn to general reflection on what is even\nneeded for justification of an inference in the first place. For\nexample, Wittgenstein raised doubts over whether it is even meaningful\nto ask for the grounds for inductive inferences.\n\n\nIf anyone said that information about the past could not convince him\nthat something would happen in the future, I should not understand\nhim. One might ask him: what do you expect to be told, then? What sort\nof information do you call a ground for such a belief? \u2026 If\nthese are not grounds, then what are grounds?\u2014If you say these\nare not grounds, then you must surely be able to state what must be\nthe case for us to have the right to say that there are grounds for\nour assumption\u2026. (Wittgenstein 1953: 481)\n\n\nOne might not, for instance, think that there even needs to be a chain\nof reasoning in which each step or presupposition is supported by an\nargument. Wittgenstein took it that there are some principles so\nfundamental that they do not require support from any further\nargument. They are the \u201chinges\u201d on which enquiry\nturns.\n\nOut of Wittgenstein\u2019s ideas has developed a general notion of\n\u201centitlement\u201d, which is a kind of rational warrant to hold\ncertain propositions which does not come with the same requirements as\n\u201cjustification\u201d. Entitlement provides epistemic rights to\nhold a proposition, without responsibilities to base the belief in it\non an argument. Crispin Wright (2004) has argued that there are\ncertain principles, including the Uniformity Principle, that we are\nentitled in this sense to hold.\n\nSome philosophers have set themselves the task of determining a set or\nsets of postulates which form a plausible basis for inductive\ninferences. Bertrand Russell, for example, argued that five postulates\nlay at the root of inductive reasoning (Russell 1948). Arthur Burks,\non the other hand, proposed that the set of postulates is not unique,\nbut there may be multiple sets of postulates corresponding to\ndifferent inductive methods (Burks 1953, 1955).\n\nThe main objection to all these views is that they do not really solve\nthe problem of induction in a way that adequately secures the pillars\non which inductive inference stands. As Salmon puts it,\n\u201cadmission of unjustified and unjustifiable postulates to deal\nwith the problem is tantamount to making scientific method a matter of\nfaith\u201d (Salmon 1966: 48).\n5.2 Ordinary Language Dissolution\n\nRather than allowing undefended empirical postulates to give normative\nsupport to an inductive inference, one could instead argue for a\ncompletely different conception of what is involved in justification.\nLike Wittgenstein, later ordinary language philosophers, notably P.F.\nStrawson, also questioned what exactly it means to ask for a\njustification of inductive inferences (Strawson 1952). This has become\nknown as the \u201cOrdinary language dissolution\u201d of the\nproblem of induction.\n\nStrawson points out that it could be meaningful to ask for a deductive\njustification of inductive inferences. But it is not clear that this\nis helpful since this is effectively \u201ca demand that induction\nshall be shown to be really a kind of deduction\u201d (Strawson 1952:\n230). Rather, Strawson says, when we ask about whether a particular\ninductive inference is justified, we are typically judging whether it\nconforms to our usual inductive standards. Suppose, he says, someone\nhas formed the belief by inductive inference that All\nf\u2019s are g. Strawson says that if that person\nis asked for their grounds or reasons for holding that belief,\n\n\nI think it would be felt to be a satisfactory answer if he replied:\n\u201cWell, in all my wide and varied experience I\u2019ve come\nacross innumerable cases of f and never a case of f\nwhich wasn\u2019t a case of g\u201d. In saying this, he is\nclearly claiming to have inductive support,\ninductive evidence, of a certain kind, for his belief.\n(Strawson 1952)\n\n\nThat is just because inductive support, as it is usually understood,\nsimply consists of having observed many positive instances in a wide\nvariety of conditions.\n\nIn effect, this approach denies that producing a chain of reasoning is\na necessary condition for justification. Rather, an inductive\ninference is justified if it conforms to the usual standards of\ninductive justification. But, is there more to it? Might we not ask\nwhat reason we have to rely on those inductive standards?\n\nIt surely makes sense to ask whether a particular inductive inference\nis justified. But the answer to that is fairly straightforward.\nSometimes people have enough evidence for their conclusions and\nsometimes they do not. Does it also make sense to ask about whether\ninductive procedures generally are justified? Strawson draws the\nanalogy between asking whether a particular act is legal. We may\nanswer such a question, he says, by referring to the law of the\nland.\n\n\nBut it makes no sense to inquire in general whether the law of the\nland, the legal system as a whole, is or is not legal. For to what\nlegal standards are we appealing? (Strawson 1952: 257)\n\n\nAccording to Strawson,\n\n\nIt is an analytic proposition that it is reasonable to have a degree\nof belief in a statement which is proportional to the strength of the\nevidence in its favour; and it is an analytic proposition, though not\na proposition of mathematics, that, other things being equal, the\nevidence for a generalisation is strong in proportion as the number of\nfavourable instances, and the variety of circumstances in which they\nhave been found, is great. So to ask whether it is reasonable to place\nreliance on inductive procedures is like asking whether it is\nreasonable to proportion the degree of one\u2019s convictions to the\nstrength of the evidence. Doing this is what \u201cbeing\nreasonable\u201d means in such a context. (Strawson 1952:\n256\u201357)\n\n\nThus, according to this point of view, there is no further question to\nask about whether it is reasonable to rely on inductive\ninferences.\n\nThe ordinary language philosophers do not explicitly argue against\nHume\u2019s\n premise P8.\n But effectively what they are doing is offering a whole different\nstory about what it would mean to be justified in believing the\nconclusion of inductive inferences. What is needed is just conformity\nto inductive standards, and there is no real meaning to asking for any\nfurther justification for those.\n\nThe main objection to this view is that conformity to the usual\nstandards is insufficient to provide the needed justification. What we\nneed to know is whether belief in the conclusion of an inductive\ninference is \u201cepistemically reasonable or justified in the sense\nthat \u2026there is reason to think that it is likely to be\ntrue\u201d (BonJour 1998: 198). The problem Hume has raised is\nwhether, despite the fact that inductive inferences have tended to\nproduce true conclusions in the past, we have reason to think the\nconclusion of an inductive inference we now make is likely to be true.\nArguably, establishing that an inductive inference is rational in the\nsense that it follows inductive standards is not sufficient to\nestablish that its conclusion is likely to be true. In fact Strawson\nallows that there is a question about whether \u201cinduction will\ncontinue to be successful\u201d, which is distinct from the question\nof whether induction is rational. This question he does take to hinge\non a \u201ccontingent, factual matter\u201d (Strawson 1952: 262).\nBut if it is this question that concerned Hume, it is no answer to\nestablish that induction is rational, unless that claim is understood\nto involve or imply that an inductive inference carried out according\nto rational standards is likely to have a true conclusion.\n5.3 Pragmatic vindication of induction\n\nAnother solution based on an alternative criterion for justification\nis the \u201cpragmatic\u201d approach initiated by Reichenbach (1938\n[2006]). Reichenbach did think Hume\u2019s argument unassailable, but\nnonetheless he attempted to provide a weaker kind of justification for\ninduction. In order to emphasize the difference from the kind of\njustification Hume sought, some have given it a different term and\nrefer to Reichenbach\u2019s solution as a \u201cvindication\u201d,\nrather than a justification of induction (Feigl 1950; Salmon\n1963).\n\nReichenbach argued that it was not necessary for the justification of\ninductive inference to show that its conclusion is true. Rather\n\u201cthe proof of the truth of the conclusion is only a sufficient\ncondition for the justification of induction, not a necessary\ncondition\u201d (Reichenbach 2006: 348). If it could be shown, he\nsays, that inductive inference is a necessary condition of success,\nthen even if we do not know that it will succeed, we still have some\nreason to follow it. Reichenbach makes a comparison to the situation\nwhere a man is suffering from a disease, and the physician says\n\u201cI do not know whether an operation will save the man, but if\nthere is any remedy, it is an operation\u201d (Reichenbach 1938\n[2006: 349]). This provides some kind of justification for operating\non the man, even if one does not know that the operation will\nsucceed.\n\nIn order to get a full account, of course, we need to say more about\nwhat is meant for a method to have \u201csuccess\u201d, or to\n\u201cwork\u201d. Reichenbach thought that this should be defined in\nrelation to the aim of induction. This aim, he thought, is\n\u201cto find series of events whose frequency of occurrence\nconverges towards a limit\u201d (1938 [2006: 350]).\n\nReichenbach applied his strategy to a general form of\n\u201cstatistical induction\u201d in which we observe the relative\nfrequency \\(f_n\\) of a particular event in n observations and\nthen form expectations about the frequency that will arise when more\nobservations are made. The \u201cinductive principle\u201d then\nstates that if after a certain number of instances, an observed\nfrequency of \\(m/n\\) is observed, for any prolongation of the series\nof observations, the frequency will continue to fall within a small\ninterval of \\(m/n\\). Hume\u2019s examples are special cases of this\nprinciple, where the observed frequency is 1. For example, in\nHume\u2019s bread case, suppose bread was observed to nourish\nn times out of n (i.e. an observed frequency of\n100%), then according to the principle of induction, we expect that as\nwe observe more instances, the frequency of nourishing ones will\ncontinue to be within a very small interval of 100%. Following this\ninductive principle is also sometimes referred to as following the\n\u201cstraight rule\u201d. The problem then is to justify the use of\nthis rule.\n\nReichenbach argued that even if Hume is right to think that we cannot\nbe justified in thinking for any particular application of the rule\nthat the conclusion is likely to be true, for the purposes of\npractical action we do not need to establish this. We can instead\nregard the inductive rule as resulting in a \u201cposit\u201d, or\nstatement that we deal with as if it is true. We posit a certain\nfrequency f on the basis of our evidence, and this is like\nmaking a wager or bet that the frequency is in fact f. One\nstrategy for positing frequencies is to follow the rule of\ninduction.\n\nReichenbach proposes that we can show that the rule of induction meets\nhis weaker justification condition. This does not require showing that\nfollowing the inductive principle will always work. It is possible\nthat the world is so disorderly that we cannot construct series with\nany limits. In that case, neither the inductive principle, nor any\nother method will succeed. But, he argues, if there is a limit, by\nfollowing the inductive principle we will eventually find it. There is\nsome element of a series of observations, beyond which the principle\nof induction will lead to the true value of the limit. Although the\ninductive rule may give quite wrong results early in the sequence, as\nit follows chance fluctuations in the sample frequency, it is\nguaranteed to eventually approximate the limiting frequency, if such a\nlimit exists. Therefore, the rule of induction is justified as an\ninstrument of positing because it is a method of which we know that if\nit is possible to achieve the aim of inductive inference we shall do\nso by means of this method (Reichenbach 1949: 475).\n\nOne might question whether Reichenbach has achieved his goal of\nshowing that following the inductive rule is a necessary condition of\nsuccess. In order to show that, one would also need to establish that\nno other methods can also achieve the aim. But, as Reichenbach himself\nrecognises, many other rules of inference as well as the straight rule\nmay also converge on the limit (Salmon 1966: 53). In fact, any method\nwhich converges asymptotically to the straight rule also does so. An\neasily specified class of such rules are those which add to the\ninductive rule a function \\(c_n\\) in which the \\(c_n\\) converge to\nzero with increasing n.\n\nReichenbach makes two suggestions aimed at avoiding this problem. On\nthe one hand, he claims, since we have no real way to pick between\nmethods, we might as well just use the inductive rule since it is\n\u201ceasier to handle, owing to its descriptive simplicity\u201d.\nHe also claims that the method which embodies the \u201csmallest\nrisk\u201d is following the inductive rule (Reichenbach 1938 [2006:\n355\u2013356]).\n\nThere is also the concern that there could be a completely different\nkind of rule which converges on the limit. We can consider, for\nexample, the possibility of a soothsayer or psychic who is able to\npredict future events reliably. Here Reichenbach argues that induction\nis still necessary in such a case, because it has to be used to check\nwhether the other method works. It is only by using induction,\nReichenbach says, that we could recognise the reliability of the\nalternative method, by examining its track record.\n\nIn assessing this argument, it is helpful to distinguish between\nlevels at which the principle of induction can be applied. Following\nSkyrms (2000), we may distinguish between level 1, where candidate\nmethods are applied to ordinary events or individuals, and level 2,\nwhere they are applied not to individuals or events, but to the\narguments on level 1. Let us refer to \u201cobject-induction\u201d\nwhen the inductive principle is applied at level 1, and\n\u201cmeta-induction\u201d when it is applied at level 2.\nReichenbach\u2019s response does not rule out the possibility that\nanother method might do better than object-induction at level 1. It\nonly shows that the success of that other method may be recognised by\na meta-induction at level 2 (Skyrms 2000). Nonetheless,\nReichenbach\u2019s thought was later picked up and developed into the\nsuggestion that a meta-inductivist who applies induction not only at\nthe object level to observations, but also to the success of\nothers\u2019 methods, might by those means be able to do as well\npredictively as the alternative method (Schurz 2008; see\n section 5.5\n for more discussion of meta-induction).\n\nReichenbach\u2019s justification is generally taken to be a pragmatic\none, since though it does not supply knowledge of a future event, it\nsupplies a sufficient reason for action (Reichenbach 1949: 481). One\nmight question whether a pragmatic argument can really deliver an\nall-purpose, general justification for following the inductive rule.\nSurely a pragmatic solution should be sensitive to differences in\npay-offs that depend on the circumstances. For example, Reichenbach\noffers the following analogue to his pragmatic justification:\n\n\nWe may compare our situation to that of a man who wants to fish in an\nunexplored part of the sea. There is no one to tell him whether or not\nthere are fish in this place. Shall he cast his net? Well, if he wants\nto fish in that place, I should advise him to cast the net, to take\nthe chance at least. It is preferable to try even in uncertainty than\nnot to try and be certain of getting nothing. (Reichenbach 1938 [2006:\n362\u2013363])\n\n\nAs Lange points out, the argument here \u201cpresumes that there is\nno cost to trying\u201d. In such a situation, \u201cthe fisherman\nhas everything to gain and nothing to lose by casting his net\u201d\n(Lange 2011: 77). But if there is some significant cost to making the\nattempt, it may not be so clear that the most rational course of\naction is to cast the net. Similarly, whether or not it would make\nsense to adopt the policy of making no predictions, rather than the\npolicy of following the inductive rule, may depend on what the\npractical penalties are for being wrong. A pragmatic solution may not\nbe capable of offering rationale for following the inductive rule\nwhich is applicable in all circumstances.\n\nAnother question is whether Reichenbach has specified the aim of\ninduction too narrowly. Finding series of events whose frequency of\noccurrence converges to a limit ties the vindication to the long-run,\nwhile allowing essentially no constraint on what can be posited in the\nshort-run. Yet it is in the short run that inductive practice actually\noccurs and where it really needs justification (BonJour 1998: 194;\nSalmon 1966: 53).\n5.4 Formal Learning Theory\n\nFormal learning theory can be regarded as a kind of extension of the\nReichenbachian programme. It does not offer justifications for\ninductive inferences in the sense of giving reasons why they should be\ntaken as likely to provide a true conclusion. Rather it offers a\n\u201cmeans-ends\u201d epistemology -- it provides reasons for\nfollowing particular methods based on their optimality in achieving\ncertain desirable epistemic ends, even if there is no guarantee that\nat any given stage of inquiry the results they produce are at all\nclose to the truth (Schulte 1999).\n\nFormal learning theory is particularly concerned with showing that\nmethods are \u201clogically reliable\u201d in the sense that they\narrive at the truth given any sequence of data consistent with our\nbackground knowledge (Kelly 1996). However, it goes further than this.\nAs we have just seen, one of the problems for Reichenbach was that\nthere are too many rules which converge in the limit to the true\nfrequency. Which one should we then choose in the short-run? Formal\nlearning theory broadens Reichenbach\u2019s general strategy by\nconsidering what happens if we have other epistemic goals besides\nlong-run convergence to the truth. In particular, formal learning\ntheorists have considered the goal of getting to the truth as\nefficiently, or quickly, as possible, as well as the goal of\nminimising the number of mind-changes, or retractions along the way.\nIt has then been argued that the usual inductive method, which is\ncharacterised by a preference for simpler hypotheses (Occam\u2019s\nrazor), can be justified since it is the unique method which meets the\nstandards for getting to the truth in the long run as efficiently as\npossible, with a minimum number of retractions (Kelly 2007).\n\nSteel (2010) has proposed that the Principle of Induction (understood\nas a rule which makes inductive generalisations along the lines of the\nStraight Rule) can be given a means-ends justification by showing that\nfollowing it is both necessary and sufficient for logical reliability.\nThe proof is an a priori mathematical one, thus it allegedly avoids\nthe circularity of Hume\u2019s second horn. However, Steel also does\nnot see the approach as an attempt to grasp Hume\u2019s first horn,\nsince the proof is only relative to a certain choice of epistemic\nends.\n\nAs with other results in formal learning theory, this solution is also\nonly valid relative to a given hypothesis space and conception of\npossible sequences of data. For this reason, some have seen it as not\naddressing Hume\u2019s problem of giving grounds for a particular\ninductive inference (Howson 2011). An alternative attitude is that it\ndoes solve a significant part of Hume\u2019s problem (Steel 2010).\nThere is a similar dispute over formal learning theory\u2019s\ntreatment of Goodman\u2019s riddle (Chart 2000, Schulte 2017).\n5.5 Meta-induction\n\nAnother approach to pursuing a broadly Reichenbachian programme is\nGerhard Schurz\u2019s strategy based on meta-induction (Schurz 2008,\n2017, 2019). Schurz draws a distinction between applying inductive\nmethods at the level of events\u2014so-called\n\u201cobject-level\u201d induction (OI), and applying inductive\nmethods at the level of competing prediction methods\u2014so-called\n\u201cmeta-induction\u201d (MI). Whereas object-level inductive\nmethods make predictions based on the events which have been observed\nto occur, meta-inductive methods make predictions based on aggregating\nthe predictions of different available prediction methods according to\ntheir success rates. Here, the success rate of a method is defined\naccording to some precise way of scoring success in making\npredictions.\n\nThe starting point of the meta-inductive approach is that the aim of\ninductive inference is not just, as Reichenbach had it, finding\nlong-run limiting frequencies, but also predicting successfully in\nboth the long and short run. Even if Hume has precluded showing that\nthe inductive method is reliable in achieving successful prediction,\nperhaps it can still be shown that it is \u201cpredictively\noptimal\u201d. A method is \u201cpredictively optimal\u201d if it\nsucceeds best in making successful predictions out of all competing\nmethods, no matter what data is received. Schurz brings to bear\nresults from the regret-based learning framework in machine learning\nthat show that there is a meta-inductive strategy that is predictively\noptimal among all predictive methods that are accessible to an\nepistemic agent (Cesa-Bianchi and Lugosi 2006, Schurz 2008, 2017,\n2019). This meta-inductive strategy, which Schurz calls\n\u201cwMI\u201d, predicts a weighted average of the predictions of\nthe accessible methods, where the weights are\n\u201cattractivities\u201d, which measure the difference between the\nmethod\u2019s own success rate and the success rate of wMI.\n\nThe main result is that the wMI strategy is long-run optimal in the\nsense that it converges to the maximum success rate of the accessible\nprediction methods. Worst-case bounds for short-run performance can\nalso be derived. The optimality result forms the basis for an a\npriori means-ends justification for the use of wMI. Namely, the\nthought is, it is reasonable to use wMI, since it achieves the best\nsuccess rates possible in the long run out of the given methods.\n\nSchurz also claims that this a priori justification of wMI,\ntogether with the contingent fact that inductive methods have so far\nbeen much more successful than non-inductive methods, gives rise to an\na posteriori non-circular justification of induction. Since\nwMI will achieve in the long run the maximal success rate of the\navailable prediction methods, it is reasonable to use it. But as a\nmatter of fact, object-inductive prediction methods have been more\nsuccessful than non-inductive methods so far. Therefore Schurz says\n\u201cit is meta-inductively justified to favor object-inductivistic\nstrategies in the future\u201d (Schurz 2019: 85). This justification,\nhe claims, is not circular because meta-induction has an a\npriori independent justification. The idea is that since it is\na priori justified to use wMI, it is also a priori\njustified to use the maximally successful method at the object level.\nSince it turns out that that the maximally successful method is\nobject-induction, then we have a non-circular a posteriori\nargument that it is reasonable to use object-induction.\n\nSchurz\u2019s original theorems on the optimality of wMI apply to the\ncase where there are finitely many predictive methods. One point of\ndiscussion is whether this amounts to an important limitation on its\nclaims to provide a full solution of the problem of induction. The\nquestion then is whether it is necessary that the optimality results\nbe extended to an infinite, or perhaps an expanding pool of strategies\n(Eckhardt 2010, Sterkenburg 2019, Schurz 2021a).\n\nAnother important issue concerns what it means for object-induction to\nbe \u201cmeta-inductively justified\u201d. The meta-inductive\nstrategy wMI and object-induction are clearly different strategies.\nThey could result in different predictions tomorrow, if OI would stop\nworking and another method would start to do better. In that case, wMI\nwould begin to favour the other method, and wMI would start to come\napart from OI. The optimality results provide a reason to follow wMI.\nHow exactly does object-induction inherit that justification? At most,\nit seems that we get a justification for following OI on the next\ntime-step, on the grounds that OI\u2019s prediction approximately\ncoincides with that of wMI (Sterkenburg 2020, Sterkenburg\n(forthcoming)). However, this requires a stronger empirical postulate\nthan simply the observation that OI has been more successful than\nnon-inductive methods. It also requires something like that \u201cas\na matter of empirical fact, the strategy OI has been so much more\nsuccessful than its competitors, that the meta-inductivist attributes\nit such a large share of the total weight that its prediction\n(approximately) coincides with OI\u2019s prediction\u201d\n(Sterkenburg 2020: 538). Furthermore, even if we allow that the\nempirical evidence does back up such a strong claim, the issue remains\nthat the meta-inductive justification is in support of following the\nstrategy of meta-induction, not in support of the strategy of\nfollowing OI (Sterkenburg (2020), sec. 3.3.2).\n6. Living with Inductive Skepticism\n\nSo far we have considered the various ways in which we might attempt\nto solve the problem of induction by resisting one or other premise of\nHume\u2019s argument. Some philosophers have however seen his\nargument as unassailable, and have thus accepted that it does lead to\ninductive skepticism, the conclusion that inductive inferences cannot\nbe justified. The challenge then is to find a way of living with such\na radical-seeming conclusion. We appear to rely on inductive inference\nubiquitously in daily life, and it is also generally thought that it\nis at the very foundation of the scientific method. Can we go on with\nall this, whilst still seriously thinking none of it is justified by\nany rational argument?\n\nOne option here is to argue, as does Nicholas Maxwell, that the\nproblem of induction is posed in an overly restrictive context.\nMaxwell argues that the problem does not arise if we adopt a different\nconception of science than the \u2018standard empiricist\u2019 one,\nwhich he denotes \u2018aim-oriented empiricism\u2019 (Maxwell\n2017).\n\nAnother option here is to think that the significance of the problem\nof induction is somehow restricted to a skeptical context. Hume\nhimself seems to have thought along these lines. For instance he\nsays:\n\n\nNature will always maintain her rights, and prevail in the end over\nany abstract reasoning whatsoever. Though we should conclude, for\ninstance, as in the foregoing section, that, in all reasonings from\nexperience, there is a step taken by the mind, which is not supported\nby any argument or process of the understanding; there is no danger,\nthat these reasonings, on which almost all knowledge depends, will\never be affected by such a discovery. (E. 5.1.2)\n\n\nHume\u2019s purpose is clearly not to argue that we should not make\ninductive inferences in everyday life, and indeed his whole method and\nsystem of describing the mind in naturalistic terms depends on\ninductive inferences through and through. The problem of induction\nthen must be seen as a problem that arises only at the level of\nphilosophical reflection.\n\nAnother way to mitigate the force of inductive skepticism is to\nrestrict its scope. Karl Popper, for instance, regarded the problem of\ninduction as insurmountable, but he argued that science is not in fact\nbased on inductive inferences at all (Popper 1935 [1959]). Rather he\npresented a deductivist view of science, according to which it\nproceeds by making bold conjectures, and then attempting to falsify\nthose conjectures. In the simplest version of this account, when a\nhypothesis makes a prediction which is found to be false in an\nexperiment, the hypothesis is rejected as falsified. The logic of this\nprocedure is fully deductive. The hypothesis entails the prediction,\nand the falsity of the prediction refutes the hypothesis by modus\ntollens. Thus, Popper claimed that science was not based on the\nextrapolative inferences considered by Hume. The consequence then is\nthat it is not so important, at least for science, if those inferences\nwould lack a rational foundation.\n\nPopper\u2019s account appears to be incomplete in an important way.\nThere are always many hypotheses which have not yet been refuted by\nthe evidence, and these may contradict one another. According to the\nstrictly deductive framework, since none are yet falsified, they are\nall on an equal footing. Yet, scientists will typically want to say\nthat one is better supported by the evidence than the others. We seem\nto need more than just deductive reasoning to support practical\ndecision-making (Salmon 1981). Popper did indeed appeal to a notion of\none hypothesis being better or worse \u201ccorroborated\u201d by the\nevidence. But arguably, this took him away from a strictly deductive\nview of science. It appears doubtful then that pure deductivism can\ngive an adequate account of scientific method.\n",
    "bibliography": {
        "categories": [],
        "cat_ref_text": {
            "ref_list": [
                "Achinstein, Peter, 2010, \u201cThe War on Induction: Whewell\nTakes on Newton and Mill (Norton Takes on Everyone)\u201d,\n<em>Philosophy of Science</em>, 77(5): 728\u2013739.",
                "Armstrong, David M., 1983, <em>What is a Law of Nature?</em>,\nCambridge: Cambridge University Press.",
                "Baier, Annette C., 2009, <em>A Progress of Sentiments</em>,\nHarvard: Harvard University Press.",
                "Bayes, Thomas, 1764, \u201cAn Essay Towards Solving a Problem in\nthe Doctrine of Chances\u201d, <em>Philosophical Transactions of the\nRoyal Society of London</em>, 53: 370\u2013418.",
                "Beauchamp, Tom L, and Alexander Rosenberg, 1981, <em>Hume and the\nProblem of Causation</em>, Oxford: Oxford University Press.",
                "Bertrand, Joseph Louis Francois, 1888, <em>Calcul des\nprobabilites</em>, Paris: Gauthier-Villars.",
                "BonJour, Laurence, 1998, <em>In Defense of Pure Reason: A\nRationalist Account of A Priori Justification</em>, Cambridge:\nCambridge University Press.",
                "Borel, Emile, 1909, <em>Elements de la theorie des\nprobabilites</em>, Paris: Herman et Fils.",
                "Brown, M.B., 1987, \u201cReview of <em>The Rationality of\nInduction</em>, D.C. Stove [1986]\u201d, <em>History and Philosophy\nof Logic</em>, 8(1): 116\u2013120.",
                "Burks, Arthur W., 1953, \u201cThe Presupposition Theory of\nInduction\u201d, <em>Philosophy of Science</em>, 20(3):\n177\u2013197.",
                "\u2013\u2013\u2013, 1955, \u201cOn the Presuppositions of\nInduction\u201d, <em>Review of Metaphysics</em>, 8(4):\n574\u2013611.",
                "Campbell, Scott, 2001, \u201cFixing a Hole in the Ground of\nInduction\u201d, <em>Australasian Journal of Philosophy</em>, 79(4):\n553\u2013563.",
                "Campbell, Scott, and James Franklin, 2004, \u201cRandomness and\nthe Justification of Induction\u201d, <em>Synthese</em>, 138(1):\n79\u201399.",
                "Carnap, Rudolph, 1950, <em>Logical Foundations of\nProbability</em>, Chicago: University of Chicago Press.",
                "\u2013\u2013\u2013, 1952, <em>The Continuum of Inductive\nMethods</em>, Chicago: University of Chicago Press.",
                "Carroll, John W., 2016, \u201cLaws of Nature\u201d, <em>Stanford\nEncyclopedia of Philosophy</em> (Fall 2016 Edition), Edward N. Zalta\n(ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/fall2016/entries/laws-of-nature/\" target=\"other\">https://plato.stanford.edu/archives/fall2016/entries/laws-of-nature/</a>&gt;.",
                "Carroll, Lewis, 1895, \u201cWhat the Tortoise said to\nAchilles\u201d, <em>Mind</em>, 4(14): 278\u2013280.",
                "Cesa-Bianchi, Nicolo, and Gabor Lugosi, 2006, <em>Prediction,\nLearning, and Games</em>, Cambridge: Cambridge University Press.",
                "Chart, David, 2000, \u201cSchulte and Goodman\u2019s\nRiddle\u201d, <em>British Journal for the Philosophy of Science,</em>\n51(1): 147\u2013149.",
                "Cleve, James van, 1984, \u201cReliability, Justification, and the\nProblem of Induction\u201d, <em>Midwest Studies In Philosophy</em>:\n555\u2013567.",
                "Cox, R. T., 1946, \u201cProbability, frequency and reasonable\nexpectation\u201d, <em>American Journal of Physics</em>, 14:\n1\u201310.",
                "\u2013\u2013\u2013, 1961, <em>The Algebra of Probable Inference</em>,\nBaltimore, MD: Johns Hopkins University Press.",
                "de Finetti, Bruno, 1964, \u201cForesight: its logical laws, its\nsubjective sources\u201d, in H.E. Kyburg (ed.), <em>Studies in\nsubjective probability</em>, New York: Wiley, pp. 93\u2013158.",
                "de Pierris, Graciela and Michael Friedman, 2013, \u201cKant and\nHume on Causality\u201d, <em>The Stanford Encyclopedia of\nPhilosophy</em> (Winter 2013 Edition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/win2013/entries/kant-hume-causality/\" target=\"other\">https://plato.stanford.edu/archives/win2013/entries/kant-hume-causality/</a>&gt;.",
                "Dretske, Fred I., 1977, \u201cLaws of Nature\u201d,\n<em>Philosophy of Science</em>, 44(2): 248\u201368.",
                "Eckhardt, Arnold, 2010, \u201cCan the\nBest-Alternative-Justification Solve Hume\u2019s Problem? (On the\nlimits of a promising approach)\u201d, <em>Philosophy of\nScience</em>, 77(4): 584\u2013593.",
                "Feigl, Herbert, 1950, \u201cDe Principiis non disputandum\u201d,\nin Max Black (ed.), <em>Philosophical Analysis</em>, Ithaca, NY:\nCornell University Press, pp. 119\u201356.",
                "Foster, John, 2004, <em>The Divine Lawmaker: Lectures on\nInduction, Laws of Nature and the Existence of God</em>, Oxford:\nClarendon Press. ",
                "Garrett, Don, 2002, <em>Cognition and Commitment in Hume\u2019s\nPhilosophy</em>, Oxford: Oxford University Press.",
                "Ghosal, S., J. K. Ghosh, and A.W. van der Vaart, 2000,\n\u201cConvergence rates of posterior distributions\u201d, <em>The\nAnnals of Statistics</em>, 28: 500\u2013531.",
                "Ghosal, S., J. Lember, and A. W. van der Vaart, 2008,\n\u201cNon-parametric Bayesian model selection and averaging\u201d,\n<em>Electronic Journal of Statistics,</em> 2: 63\u201389.",
                "Giaquinto, Marcus, 1987, \u201cReview of <em>The Rationality of\nInduction</em>, D.C. Stove [1986]\u201d, <em>Philosophy of\nScience</em>, 54(4): 612\u2013615.",
                "Goodman, Nelson, 1955, <em>Fact, Fiction and Forecast</em>,\nCambridge, MA: Harvard University Press.",
                "Hacking, Ian, 1975, <em>The Emergence of Probability: a\nPhilosophical Study of Early Ideas About Probability, Induction and\nStatistical Inference</em>, Cambridge: Cambridge University\nPress.",
                "H\u00e1jek, Alan, 2011, \u201cInterpretations of\nProbability\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2012 Edition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/win2012/entries/probability-interpret/\" target=\"other\">https://plato.stanford.edu/archives/win2012/entries/probability-interpret/</a>&gt;.",
                "Harman, Gilbert, 1968, \u201cEnumerative Induction as Inference\nto the Best Explanation\u201d, <em>Journal of Philosophy</em>,\n65(18): 529\u2013533.",
                "Henderson, Leah, 2014, \u201cBayesianism and Inference to the\nBest Explanation\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 65(4): 687\u2013715.",
                "Howson, Colin, 2000, <em>Hume\u2019s Problem: Induction and the\nJustification of Belief</em>, Oxford: Oxford University Press.",
                "\u2013\u2013\u2013, 2011, \u201cNo Answer to Hume\u201d,\n<em>International Studies in the Philosophy of Science</em>, 25(3):\n279\u2013284.",
                "Huemer, Michael, 2009, \u201cExplanationist Aid for the Theory of\nInductive Logic\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 60(2): 345\u2013375.",
                "[T] Hume, David, 1739, <em>A Treatise of Human Nature</em>,\nOxford: Oxford University Press. (Cited by\nbook.part.section.paragraph.)",
                "[E] \u2013\u2013\u2013, 1748, <em>An Enquiry Concerning Human\nUnderstanding</em>, Oxford: Oxford University Press. (Cited by\nsection.part.paragraph.)",
                "Jackson, Alexander, 2019, \u201cHow to solve Hume\u2019s problem\nof induction\u201d, <em>Episteme</em> 16: 157\u2013174.",
                "Jeffreys, Harold, 1939, <em>Theory of Probability</em>, Oxford:\nOxford University Press.",
                "Johnson, William Ernest, 1921, <em>Logic</em>, Cambridge:\nCambridge University Press.",
                "\u2013\u2013\u2013, 1932, \u201cProbability: the Deductive and\nInductive Problems\u201d, <em>Mind</em>, 49(164): 409\u2013423.",
                "Kant, Immanuel, 1781, <em>Kritik der reinen Vernunft</em>.\nTranslated as <em>Critique of Pure Reason</em>, Paul Guyer and Allen\nW. Wood, A., (eds.), Cambridge: Cambridge University Press, 1998.",
                "\u2013\u2013\u2013, 1783, <em>Prolegomena zu einer jeden\nk\u00fcnftigen Metaphysik, die als Wissenschaft wird auftreten\nk\u00f6nnen</em>. Translated as <em>Prologomena to Any Future\nMetaphysics</em>, James W. Ellington (trans.), Indianapolis: Hackett\npublishing, 2002.",
                "Kelly, Kevin T., 1996, <em>The Logic of Reliable Inquiry</em>,\nOxford: Oxford University Press.",
                "\u2013\u2013\u2013, 2007, \u201cA new solution to the puzzle\nof simplicity\u201d, <em>Philosophy of Science</em>, 74:\n561\u2013573.",
                "Kelly, Thomas, 2010, \u201cHume, Norton and induction without\nrules\u201d, <em>Philosophy of Science,</em> 77: 754\u2013764.",
                "Keynes, John Maynard, 1921, <em>A Treatise on Probability</em>,\nLondon: Macmillan.",
                "Lange, Marc, 2011, \u201cHume and the Problem of\ninduction\u201d, in Dov Gabbay, Stephan Hartmann and John Woods\n(eds.), <em>Inductive Logic</em>, (<em>Handbook of the History of\nLogic</em>, Volume 10), Amsterdam: Elsevier, pp. 43\u201392.",
                "Laplace, Pierre-Simon, 1814, <em>Essai philosophique sur les\nprobabilit\u00e9s</em>, Paris. Translated in 1902 from the sixth\nFrench edition as <em>A Philosophical Essay on Probabilities</em>, by\nFrederick Wilson Truscott and Frederick Lincoln Emory, New York: John\nWiley and Sons. Retranslated in 1995 from the fifth French edition\n(1825) as <em>Philosophical Essay on Probabilities</em>, by Andrew I.\nDale, 1995, New York: Springer-Verlag.",
                "Maher, Patrick, 1996, \u201cThe Hole in the Ground of\nInduction\u201d, <em>Australasian Journal of Philosophy</em>, 74(3):\n423\u2013432.",
                "Maxwell, Nicholas, 2017, <em>Understanding Scientific Progress:\nAim-Oriented Empiricism</em>, St. Paul: Paragon House.",
                "Mitchell, Tom, 1997, <em>Machine Learning</em>: McGraw-Hill.",
                "Morris, William E., and Charlotte R. Brown, 2014 [2017],\n\u201cDavid Hume\u201d, <em>The Stanford Encyclopedia of\nPhilosophy</em> (Spring 2017 Edition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/spr2017/entries/hume/\" target=\"other\">https://plato.stanford.edu/archives/spr2017/entries/hume/</a>&gt;.",
                "Norton, John D., 2003, \u201cA Material Theory of\nInduction\u201d, <em>Philosophy of Science</em>, 70(4):\n647\u2013670.",
                "\u2013\u2013\u2013, 2010, \u201cThere are no universal rules\nfor induction\u201d, <em>Philosophy of Science</em>, 77:\n765\u2013777.",
                "\u2013\u2013\u2013, 2021, <em>The Material Theory of\nInduction</em>: BSPS Open/University of Calgary Press.",
                "Okasha, Samir, 2001, \u201cWhat did Hume Really Show about\nInduction?\u201d, <em>The Philosophical Quarterly</em>, 51(204):\n307\u2013327.",
                "\u2013\u2013\u2013, 2005a, \u201cBayesianism and the\nTraditional Problem of Induction\u201d, <em>Croatian Journal of\nPhilosophy</em>, 5(14): 181\u2013194.",
                "\u2013\u2013\u2013, 2005b, \u201cDoes Hume\u2019s Argument\nagainst Induction Rest on a Quantifier-Shift Fallacy?\u201d,\n<em>Proceedings of the Aristotelian Society</em>, 105:\n237\u2013255.",
                "Owen, David, 1999, <em>Hume\u2019s Reason</em>, Oxford: Oxford\nUniversity Press.",
                "Papineau, David, 1992, \u201cReliabilism, Induction and\nScepticism\u201d, <em>The Philosophical Quarterly</em>, 42(166):\n1\u201320.",
                "Popper, Karl, 1935 [1959], <em>Logik der Forschung</em>, Wien: J.\nSpringer. Translated by Popper as <em>The Logic of Scientific\nDiscovery</em>, London: Hutchinson, 1959.",
                "Ramsey, Frank P., 1926, \u201cTruth and Probability\u201d, in\nR.B. Braithwaite (ed.), <em>The Foundations of Mathematics and Other\nLogical Essays</em>, London: Routledge and Kegan-Paul Ltd., pp.\n156\u201398.",
                "Reichenbach, Hans, 1949, <em>The Theory of Probability</em>,\nBerkeley: University of California Press.",
                "\u2013\u2013\u2013, 1938 [2006], <em>Experience and Prediction:\nAn Analysis of the Foundations and the Structure of Knowledge</em>,\nChicago: University of Chicago Press. Page numbers from the 2006\nedition, Indiana: University of Notre Dame Press.",
                "Romeijn, Jan-Willem, 2004, \u201cHypotheses and Inductive\nPredictions\u201d, <em>Synthese</em>, 141(3): 333\u2013364.",
                "Russell, Bertrand, 1946, <em>A History of Western Philosophy</em>,\nLondon: George Allen and Unwin Ltd.",
                "\u2013\u2013\u2013, 1948, <em>Human Knowledge: Its Scope and\nLimits</em>, New York: Simon and Schuster.",
                "Salmon, Wesley C., 1963, \u201cOn Vindicating Induction\u201d,\n<em>Philosophy of Science</em>, 30(3): 252\u2013261.",
                "\u2013\u2013\u2013, 1966, <em>The Foundations of Scientific\nInference</em>, Pittsburgh: University of Pittsburgh Press.",
                "\u2013\u2013\u2013, 1981, \u201cRational Prediction\u201d,\n<em>British Journal for the Philosophy of Science</em>, 32(2):\n115\u2013125.",
                "Salmon, Wesley C., 1953, \u201cThe Uniformity of Nature\u201d,\n<em>Philosophy and Phenomenological Research</em>, 14(1):\n39\u201348.",
                "Savage, Leonard J, 1954, <em>The Foundations of Statistics</em>,\nNew York: Dover Publications.",
                "Schulte, Oliver, 1999, \u201cMeans-Ends Epistemology\u201d,\n<em>British Journal for the Philosophy of Science</em>, 50(1):\n1\u201331.",
                "\u2013\u2013\u2013, 2000, \u201cWhat to believe and what to\ntake seriously: a reply to David Chart concerning the riddle of\ninduction\u201d, <em>British Journal for the Philosophy of\nScience,</em> 51: 151\u2013153.",
                "\u2013\u2013\u2013, 2017 [2018], \u201cFormal Learning\nTheory\u201d, <em>The Stanford Encyclopedia of Philosophy</em> (Spring 2018\nEdition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/spr2018/entries/learning-formal/\" target=\"other\">https://plato.stanford.edu/archives/spr2018/entries/learning-formal/</a>&gt;.",
                "Schurz, Gerhard, 2008, \u201cThe Meta-inductivist\u2019s Winning\nStrategy in the Prediction Game: A New Approach to Hume\u2019s\nProblem\u201d, <em>Philosophy of Science</em>, 75(3):\n278\u2013305.",
                "\u2013\u2013\u2013, 2017, \u201cOptimality Justifications: New\nFoundations for Foundation-Oriented Epistemology\u201d,\n<em>Synthese</em>, 73:1\u201323.",
                "\u2013\u2013\u2013, 2019, <em>Hume\u2019s Problem Solved: the\nOptimality of Meta-induction</em>, Cambridge, MA: MIT Press.",
                "\u2013\u2013\u2013, 2021a, \u201cMeta-induction over\nunboundedly many prediction methods: a reply to Arnold and\nSterkenburg\u201d, <em>Philosophy of Science</em>, 88: 320\u2013340.",
                "\u2013\u2013\u2013, 2021b, \u201cThe No Free Lunch Theorem:\nbad news for (White\u2019s account of) the problem of\ninduction\u201d, <em>Episteme</em>, 18: 31\u201345.",
                "Schurz, Gerhard, and Paul Thorn, 2020, \u201cThe material theory\nof object-induction and the universal optimality of meta-induction:\ntwo complementary accounts\u201d, <em>Studies in History and\nPhilosophy of Science A</em>, 82: 99\u201393.",
                "Skyrms, Brian 2000, <em>Choice and Chance: an introduction to\ninductive logic</em>, Wadsworth.",
                "\u2013\u2013\u2013, 2012, <em>From Zeno to Arbitrage: Essays on\nQuantity, Coherence and Induction</em>, Oxford: Oxford University\nPress.",
                "Sober, Elliott, 1988, <em>Reconstructing the Past: Parsimony,\nEvolution and Inference</em>, Cambridge MA: MIT Press.",
                "Steel, Daniel, 2010, \u201cWhat If the Principle of Induction Is\nNormative? Formal Learning Theory and Hume\u2019s Problem\u201d,\n<em>International Studies in the Philosophy of Science</em>, 24(2):\n171\u2013185.",
                "Sterkenburg, Tom, 2019, \u201cThe meta-inductive justification of\ninduction: the pool of strategies\u201d, <em>Philosophy of\nScience</em>, 86: 981\u2013992.",
                "\u2013\u2013\u2013, 2020, \u201cThe meta-inductive\njustification of induction\u201d, <em>Episteme</em>, 17:\n519\u2013541.",
                "\u2013\u2013\u2013, forthcoming, \u201cExplaining the success\nof induction\u201d, <em>British Journal for the Philosophy of\nScience</em>, https://doi.org/10.1086/717068.",
                "Sterkenburg, Tom and Peter Gr\u00fcnwald, 2021, \u201cThe\nno-free-lunch theorems of supervised learning\u201d,\n<em>Synthese</em>, 199: 9979\u201310015.",
                "Stove, David C., 1986, <em>The Rationality of Induction</em>,\nOxford: Clarendon Press.",
                "Strawson, Peter Frederick, 1952, <em>Introduction to Logical\nTheory</em>, London: Methuen.",
                "Tooley, Michael, 1977, \u201cThe Nature of Laws\u201d,\n<em>Canadian Journal of Philosophy</em>, 7(4): 667\u2013698.",
                "White, Roger, 2015, \u201cThe problem of the problem of\ninduction\u201d, <em>Episteme</em>, 12: 275\u2013290.",
                "Will, Frederick L., 1948, \u201cDonald Williams\u2019 Theory of\nInduction\u201d, <em>Philosophical Review</em>, 57(3):\n231\u2013247.",
                "Williams, Donald C., 1947, <em>The Ground of Induction</em>,\nHarvard: Harvard University Press.",
                "Wittgenstein, Ludwig, 1953, <em>Philosophical Investigations</em>,\nNew Jersey: Prentice Hall.",
                "Wolpert, D. H., 1997, \u201cNo free lunch theorems for\noptimization\u201d, <em>IEEE Transactions on Evolutionary\nComputation</em>, 1: 67\u201382.",
                "\u2013\u2013\u2013, 1992, \u201cOn the connecton between\nin-sample testing and generalization error\u201d, <em>Complex\nSystems</em>, 6: 47\u201394.",
                "\u2013\u2013\u2013, 1996, \u201cThe lack of a priori\ndistinctions between learning algorithms\u201d, <em>Neural\nComputation</em> 8: 1341\u20131390.",
                "Worrall, John, 2010, \u201cFor Universal Rules, Against\nInduction\u201d, <em>Philosophy of Science</em>, 77(5):\n740\u201353.",
                "Wright, Crispin, 2004, \u201cWittgensteinian Certainties\u201d,\nin Denis McManus (ed.), <em>Wittgenstein and Scepticism</em>, London:\nRoutledge, pp. 22\u201355.",
                "Zabell, Sandy L., 1988, \u201cSymmetry and Its\nDiscontents\u201d, in Brian Skyrms (ed.), <em>Causation, Chance and\nCredence</em>, Dordrecht: Springer Netherlands, pp.\n155\u2013190.",
                "\u2013\u2013\u2013, 1989, \u201cThe Rule of Succession\u201d,\n<em>Erkenntnis</em>, 31(2\u20133): 283\u2013321."
            ]
        },
        "raw_text": "<div id=\"bibliography\">\n<h2 id=\"Bib\">Bibliography</h2>\n<ul class=\"hanging\">\n<li>Achinstein, Peter, 2010, \u201cThe War on Induction: Whewell\nTakes on Newton and Mill (Norton Takes on Everyone)\u201d,\n<em>Philosophy of Science</em>, 77(5): 728\u2013739.</li>\n<li>Armstrong, David M., 1983, <em>What is a Law of Nature?</em>,\nCambridge: Cambridge University Press.</li>\n<li>Baier, Annette C., 2009, <em>A Progress of Sentiments</em>,\nHarvard: Harvard University Press.</li>\n<li>Bayes, Thomas, 1764, \u201cAn Essay Towards Solving a Problem in\nthe Doctrine of Chances\u201d, <em>Philosophical Transactions of the\nRoyal Society of London</em>, 53: 370\u2013418.</li>\n<li>Beauchamp, Tom L, and Alexander Rosenberg, 1981, <em>Hume and the\nProblem of Causation</em>, Oxford: Oxford University Press.</li>\n<li>Bertrand, Joseph Louis Francois, 1888, <em>Calcul des\nprobabilites</em>, Paris: Gauthier-Villars.</li>\n<li>BonJour, Laurence, 1998, <em>In Defense of Pure Reason: A\nRationalist Account of A Priori Justification</em>, Cambridge:\nCambridge University Press.</li>\n<li>Borel, Emile, 1909, <em>Elements de la theorie des\nprobabilites</em>, Paris: Herman et Fils.</li>\n<li>Brown, M.B., 1987, \u201cReview of <em>The Rationality of\nInduction</em>, D.C. Stove [1986]\u201d, <em>History and Philosophy\nof Logic</em>, 8(1): 116\u2013120.</li>\n<li>Burks, Arthur W., 1953, \u201cThe Presupposition Theory of\nInduction\u201d, <em>Philosophy of Science</em>, 20(3):\n177\u2013197.</li>\n<li>\u2013\u2013\u2013, 1955, \u201cOn the Presuppositions of\nInduction\u201d, <em>Review of Metaphysics</em>, 8(4):\n574\u2013611.</li>\n<li>Campbell, Scott, 2001, \u201cFixing a Hole in the Ground of\nInduction\u201d, <em>Australasian Journal of Philosophy</em>, 79(4):\n553\u2013563.</li>\n<li>Campbell, Scott, and James Franklin, 2004, \u201cRandomness and\nthe Justification of Induction\u201d, <em>Synthese</em>, 138(1):\n79\u201399.</li>\n<li>Carnap, Rudolph, 1950, <em>Logical Foundations of\nProbability</em>, Chicago: University of Chicago Press.</li>\n<li>\u2013\u2013\u2013, 1952, <em>The Continuum of Inductive\nMethods</em>, Chicago: University of Chicago Press.</li>\n<li>Carroll, John W., 2016, \u201cLaws of Nature\u201d, <em>Stanford\nEncyclopedia of Philosophy</em> (Fall 2016 Edition), Edward N. Zalta\n(ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/fall2016/entries/laws-of-nature/\" target=\"other\">https://plato.stanford.edu/archives/fall2016/entries/laws-of-nature/</a>&gt;.</li>\n<li>Carroll, Lewis, 1895, \u201cWhat the Tortoise said to\nAchilles\u201d, <em>Mind</em>, 4(14): 278\u2013280.</li>\n<li>Cesa-Bianchi, Nicolo, and Gabor Lugosi, 2006, <em>Prediction,\nLearning, and Games</em>, Cambridge: Cambridge University Press.</li>\n<li>Chart, David, 2000, \u201cSchulte and Goodman\u2019s\nRiddle\u201d, <em>British Journal for the Philosophy of Science,</em>\n51(1): 147\u2013149.</li>\n<li>Cleve, James van, 1984, \u201cReliability, Justification, and the\nProblem of Induction\u201d, <em>Midwest Studies In Philosophy</em>:\n555\u2013567.</li>\n<li>Cox, R. T., 1946, \u201cProbability, frequency and reasonable\nexpectation\u201d, <em>American Journal of Physics</em>, 14:\n1\u201310.</li>\n<li>\u2013\u2013\u2013, 1961, <em>The Algebra of Probable Inference</em>,\nBaltimore, MD: Johns Hopkins University Press.</li>\n<li>de Finetti, Bruno, 1964, \u201cForesight: its logical laws, its\nsubjective sources\u201d, in H.E. Kyburg (ed.), <em>Studies in\nsubjective probability</em>, New York: Wiley, pp. 93\u2013158.</li>\n<li>de Pierris, Graciela and Michael Friedman, 2013, \u201cKant and\nHume on Causality\u201d, <em>The Stanford Encyclopedia of\nPhilosophy</em> (Winter 2013 Edition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/win2013/entries/kant-hume-causality/\" target=\"other\">https://plato.stanford.edu/archives/win2013/entries/kant-hume-causality/</a>&gt;.</li>\n<li>Dretske, Fred I., 1977, \u201cLaws of Nature\u201d,\n<em>Philosophy of Science</em>, 44(2): 248\u201368.</li>\n<li>Eckhardt, Arnold, 2010, \u201cCan the\nBest-Alternative-Justification Solve Hume\u2019s Problem? (On the\nlimits of a promising approach)\u201d, <em>Philosophy of\nScience</em>, 77(4): 584\u2013593.</li>\n<li>Feigl, Herbert, 1950, \u201cDe Principiis non disputandum\u201d,\nin Max Black (ed.), <em>Philosophical Analysis</em>, Ithaca, NY:\nCornell University Press, pp. 119\u201356.</li>\n<li>Foster, John, 2004, <em>The Divine Lawmaker: Lectures on\nInduction, Laws of Nature and the Existence of God</em>, Oxford:\nClarendon Press. </li>\n<li>Garrett, Don, 2002, <em>Cognition and Commitment in Hume\u2019s\nPhilosophy</em>, Oxford: Oxford University Press.</li>\n<li>Ghosal, S., J. K. Ghosh, and A.W. van der Vaart, 2000,\n\u201cConvergence rates of posterior distributions\u201d, <em>The\nAnnals of Statistics</em>, 28: 500\u2013531.</li>\n<li>Ghosal, S., J. Lember, and A. W. van der Vaart, 2008,\n\u201cNon-parametric Bayesian model selection and averaging\u201d,\n<em>Electronic Journal of Statistics,</em> 2: 63\u201389.</li>\n<li>Giaquinto, Marcus, 1987, \u201cReview of <em>The Rationality of\nInduction</em>, D.C. Stove [1986]\u201d, <em>Philosophy of\nScience</em>, 54(4): 612\u2013615.</li>\n<li>Goodman, Nelson, 1955, <em>Fact, Fiction and Forecast</em>,\nCambridge, MA: Harvard University Press.</li>\n<li>Hacking, Ian, 1975, <em>The Emergence of Probability: a\nPhilosophical Study of Early Ideas About Probability, Induction and\nStatistical Inference</em>, Cambridge: Cambridge University\nPress.</li>\n<li>H\u00e1jek, Alan, 2011, \u201cInterpretations of\nProbability\u201d, <em>The Stanford Encyclopedia of Philosophy</em>\n(Winter 2012 Edition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/win2012/entries/probability-interpret/\" target=\"other\">https://plato.stanford.edu/archives/win2012/entries/probability-interpret/</a>&gt;.</li>\n<li>Harman, Gilbert, 1968, \u201cEnumerative Induction as Inference\nto the Best Explanation\u201d, <em>Journal of Philosophy</em>,\n65(18): 529\u2013533.</li>\n<li>Henderson, Leah, 2014, \u201cBayesianism and Inference to the\nBest Explanation\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 65(4): 687\u2013715.</li>\n<li>Howson, Colin, 2000, <em>Hume\u2019s Problem: Induction and the\nJustification of Belief</em>, Oxford: Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 2011, \u201cNo Answer to Hume\u201d,\n<em>International Studies in the Philosophy of Science</em>, 25(3):\n279\u2013284.</li>\n<li>Huemer, Michael, 2009, \u201cExplanationist Aid for the Theory of\nInductive Logic\u201d, <em>The British Journal for the Philosophy of\nScience</em>, 60(2): 345\u2013375.</li>\n<li>[T] Hume, David, 1739, <em>A Treatise of Human Nature</em>,\nOxford: Oxford University Press. (Cited by\nbook.part.section.paragraph.)</li>\n<li>[E] \u2013\u2013\u2013, 1748, <em>An Enquiry Concerning Human\nUnderstanding</em>, Oxford: Oxford University Press. (Cited by\nsection.part.paragraph.)</li>\n<li>Jackson, Alexander, 2019, \u201cHow to solve Hume\u2019s problem\nof induction\u201d, <em>Episteme</em> 16: 157\u2013174.</li>\n<li>Jeffreys, Harold, 1939, <em>Theory of Probability</em>, Oxford:\nOxford University Press.</li>\n<li>Johnson, William Ernest, 1921, <em>Logic</em>, Cambridge:\nCambridge University Press.</li>\n<li>\u2013\u2013\u2013, 1932, \u201cProbability: the Deductive and\nInductive Problems\u201d, <em>Mind</em>, 49(164): 409\u2013423.</li>\n<li>Kant, Immanuel, 1781, <em>Kritik der reinen Vernunft</em>.\nTranslated as <em>Critique of Pure Reason</em>, Paul Guyer and Allen\nW. Wood, A., (eds.), Cambridge: Cambridge University Press, 1998.</li>\n<li>\u2013\u2013\u2013, 1783, <em>Prolegomena zu einer jeden\nk\u00fcnftigen Metaphysik, die als Wissenschaft wird auftreten\nk\u00f6nnen</em>. Translated as <em>Prologomena to Any Future\nMetaphysics</em>, James W. Ellington (trans.), Indianapolis: Hackett\npublishing, 2002.</li>\n<li>Kelly, Kevin T., 1996, <em>The Logic of Reliable Inquiry</em>,\nOxford: Oxford University Press.</li>\n<li>\u2013\u2013\u2013, 2007, \u201cA new solution to the puzzle\nof simplicity\u201d, <em>Philosophy of Science</em>, 74:\n561\u2013573.</li>\n<li>Kelly, Thomas, 2010, \u201cHume, Norton and induction without\nrules\u201d, <em>Philosophy of Science,</em> 77: 754\u2013764.</li>\n<li>Keynes, John Maynard, 1921, <em>A Treatise on Probability</em>,\nLondon: Macmillan.</li>\n<li>Lange, Marc, 2011, \u201cHume and the Problem of\ninduction\u201d, in Dov Gabbay, Stephan Hartmann and John Woods\n(eds.), <em>Inductive Logic</em>, (<em>Handbook of the History of\nLogic</em>, Volume 10), Amsterdam: Elsevier, pp. 43\u201392.</li>\n<li>Laplace, Pierre-Simon, 1814, <em>Essai philosophique sur les\nprobabilit\u00e9s</em>, Paris. Translated in 1902 from the sixth\nFrench edition as <em>A Philosophical Essay on Probabilities</em>, by\nFrederick Wilson Truscott and Frederick Lincoln Emory, New York: John\nWiley and Sons. Retranslated in 1995 from the fifth French edition\n(1825) as <em>Philosophical Essay on Probabilities</em>, by Andrew I.\nDale, 1995, New York: Springer-Verlag.</li>\n<li>Maher, Patrick, 1996, \u201cThe Hole in the Ground of\nInduction\u201d, <em>Australasian Journal of Philosophy</em>, 74(3):\n423\u2013432.</li>\n<li>Maxwell, Nicholas, 2017, <em>Understanding Scientific Progress:\nAim-Oriented Empiricism</em>, St. Paul: Paragon House.</li>\n<li>Mitchell, Tom, 1997, <em>Machine Learning</em>: McGraw-Hill.</li>\n<li>Morris, William E., and Charlotte R. Brown, 2014 [2017],\n\u201cDavid Hume\u201d, <em>The Stanford Encyclopedia of\nPhilosophy</em> (Spring 2017 Edition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/spr2017/entries/hume/\" target=\"other\">https://plato.stanford.edu/archives/spr2017/entries/hume/</a>&gt;.</li>\n<li>Norton, John D., 2003, \u201cA Material Theory of\nInduction\u201d, <em>Philosophy of Science</em>, 70(4):\n647\u2013670.</li>\n<li>\u2013\u2013\u2013, 2010, \u201cThere are no universal rules\nfor induction\u201d, <em>Philosophy of Science</em>, 77:\n765\u2013777.</li>\n<li>\u2013\u2013\u2013, 2021, <em>The Material Theory of\nInduction</em>: BSPS Open/University of Calgary Press.</li>\n<li>Okasha, Samir, 2001, \u201cWhat did Hume Really Show about\nInduction?\u201d, <em>The Philosophical Quarterly</em>, 51(204):\n307\u2013327.</li>\n<li>\u2013\u2013\u2013, 2005a, \u201cBayesianism and the\nTraditional Problem of Induction\u201d, <em>Croatian Journal of\nPhilosophy</em>, 5(14): 181\u2013194.</li>\n<li>\u2013\u2013\u2013, 2005b, \u201cDoes Hume\u2019s Argument\nagainst Induction Rest on a Quantifier-Shift Fallacy?\u201d,\n<em>Proceedings of the Aristotelian Society</em>, 105:\n237\u2013255.</li>\n<li>Owen, David, 1999, <em>Hume\u2019s Reason</em>, Oxford: Oxford\nUniversity Press.</li>\n<li>Papineau, David, 1992, \u201cReliabilism, Induction and\nScepticism\u201d, <em>The Philosophical Quarterly</em>, 42(166):\n1\u201320.</li>\n<li>Popper, Karl, 1935 [1959], <em>Logik der Forschung</em>, Wien: J.\nSpringer. Translated by Popper as <em>The Logic of Scientific\nDiscovery</em>, London: Hutchinson, 1959.</li>\n<li>Ramsey, Frank P., 1926, \u201cTruth and Probability\u201d, in\nR.B. Braithwaite (ed.), <em>The Foundations of Mathematics and Other\nLogical Essays</em>, London: Routledge and Kegan-Paul Ltd., pp.\n156\u201398.</li>\n<li>Reichenbach, Hans, 1949, <em>The Theory of Probability</em>,\nBerkeley: University of California Press.</li>\n<li>\u2013\u2013\u2013, 1938 [2006], <em>Experience and Prediction:\nAn Analysis of the Foundations and the Structure of Knowledge</em>,\nChicago: University of Chicago Press. Page numbers from the 2006\nedition, Indiana: University of Notre Dame Press.</li>\n<li>Romeijn, Jan-Willem, 2004, \u201cHypotheses and Inductive\nPredictions\u201d, <em>Synthese</em>, 141(3): 333\u2013364.</li>\n<li>Russell, Bertrand, 1946, <em>A History of Western Philosophy</em>,\nLondon: George Allen and Unwin Ltd.</li>\n<li>\u2013\u2013\u2013, 1948, <em>Human Knowledge: Its Scope and\nLimits</em>, New York: Simon and Schuster.</li>\n<li>Salmon, Wesley C., 1963, \u201cOn Vindicating Induction\u201d,\n<em>Philosophy of Science</em>, 30(3): 252\u2013261.</li>\n<li>\u2013\u2013\u2013, 1966, <em>The Foundations of Scientific\nInference</em>, Pittsburgh: University of Pittsburgh Press.</li>\n<li>\u2013\u2013\u2013, 1981, \u201cRational Prediction\u201d,\n<em>British Journal for the Philosophy of Science</em>, 32(2):\n115\u2013125.</li>\n<li>Salmon, Wesley C., 1953, \u201cThe Uniformity of Nature\u201d,\n<em>Philosophy and Phenomenological Research</em>, 14(1):\n39\u201348.</li>\n<li>Savage, Leonard J, 1954, <em>The Foundations of Statistics</em>,\nNew York: Dover Publications.</li>\n<li>Schulte, Oliver, 1999, \u201cMeans-Ends Epistemology\u201d,\n<em>British Journal for the Philosophy of Science</em>, 50(1):\n1\u201331.</li>\n<li>\u2013\u2013\u2013, 2000, \u201cWhat to believe and what to\ntake seriously: a reply to David Chart concerning the riddle of\ninduction\u201d, <em>British Journal for the Philosophy of\nScience,</em> 51: 151\u2013153.</li>\n<li>\u2013\u2013\u2013, 2017 [2018], \u201cFormal Learning\nTheory\u201d, <em>The Stanford Encyclopedia of Philosophy</em> (Spring 2018\nEdition), Edward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/spr2018/entries/learning-formal/\" target=\"other\">https://plato.stanford.edu/archives/spr2018/entries/learning-formal/</a>&gt;.</li>\n<li>Schurz, Gerhard, 2008, \u201cThe Meta-inductivist\u2019s Winning\nStrategy in the Prediction Game: A New Approach to Hume\u2019s\nProblem\u201d, <em>Philosophy of Science</em>, 75(3):\n278\u2013305.</li>\n<li>\u2013\u2013\u2013, 2017, \u201cOptimality Justifications: New\nFoundations for Foundation-Oriented Epistemology\u201d,\n<em>Synthese</em>, 73:1\u201323.</li>\n<li>\u2013\u2013\u2013, 2019, <em>Hume\u2019s Problem Solved: the\nOptimality of Meta-induction</em>, Cambridge, MA: MIT Press.</li>\n<li>\u2013\u2013\u2013, 2021a, \u201cMeta-induction over\nunboundedly many prediction methods: a reply to Arnold and\nSterkenburg\u201d, <em>Philosophy of Science</em>, 88: 320\u2013340.</li>\n<li>\u2013\u2013\u2013, 2021b, \u201cThe No Free Lunch Theorem:\nbad news for (White\u2019s account of) the problem of\ninduction\u201d, <em>Episteme</em>, 18: 31\u201345.</li>\n<li>Schurz, Gerhard, and Paul Thorn, 2020, \u201cThe material theory\nof object-induction and the universal optimality of meta-induction:\ntwo complementary accounts\u201d, <em>Studies in History and\nPhilosophy of Science A</em>, 82: 99\u201393.</li>\n<li>Skyrms, Brian 2000, <em>Choice and Chance: an introduction to\ninductive logic</em>, Wadsworth.</li>\n<li>\u2013\u2013\u2013, 2012, <em>From Zeno to Arbitrage: Essays on\nQuantity, Coherence and Induction</em>, Oxford: Oxford University\nPress.</li>\n<li>Sober, Elliott, 1988, <em>Reconstructing the Past: Parsimony,\nEvolution and Inference</em>, Cambridge MA: MIT Press.</li>\n<li>Steel, Daniel, 2010, \u201cWhat If the Principle of Induction Is\nNormative? Formal Learning Theory and Hume\u2019s Problem\u201d,\n<em>International Studies in the Philosophy of Science</em>, 24(2):\n171\u2013185.</li>\n<li>Sterkenburg, Tom, 2019, \u201cThe meta-inductive justification of\ninduction: the pool of strategies\u201d, <em>Philosophy of\nScience</em>, 86: 981\u2013992.</li>\n<li>\u2013\u2013\u2013, 2020, \u201cThe meta-inductive\njustification of induction\u201d, <em>Episteme</em>, 17:\n519\u2013541.</li>\n<li>\u2013\u2013\u2013, forthcoming, \u201cExplaining the success\nof induction\u201d, <em>British Journal for the Philosophy of\nScience</em>, https://doi.org/10.1086/717068.</li>\n<li>Sterkenburg, Tom and Peter Gr\u00fcnwald, 2021, \u201cThe\nno-free-lunch theorems of supervised learning\u201d,\n<em>Synthese</em>, 199: 9979\u201310015.</li>\n<li>Stove, David C., 1986, <em>The Rationality of Induction</em>,\nOxford: Clarendon Press.</li>\n<li>Strawson, Peter Frederick, 1952, <em>Introduction to Logical\nTheory</em>, London: Methuen.</li>\n<li>Tooley, Michael, 1977, \u201cThe Nature of Laws\u201d,\n<em>Canadian Journal of Philosophy</em>, 7(4): 667\u2013698.</li>\n<li>White, Roger, 2015, \u201cThe problem of the problem of\ninduction\u201d, <em>Episteme</em>, 12: 275\u2013290.</li>\n<li>Will, Frederick L., 1948, \u201cDonald Williams\u2019 Theory of\nInduction\u201d, <em>Philosophical Review</em>, 57(3):\n231\u2013247.</li>\n<li>Williams, Donald C., 1947, <em>The Ground of Induction</em>,\nHarvard: Harvard University Press.</li>\n<li>Wittgenstein, Ludwig, 1953, <em>Philosophical Investigations</em>,\nNew Jersey: Prentice Hall.</li>\n<li>Wolpert, D. H., 1997, \u201cNo free lunch theorems for\noptimization\u201d, <em>IEEE Transactions on Evolutionary\nComputation</em>, 1: 67\u201382.</li>\n<li>\u2013\u2013\u2013, 1992, \u201cOn the connecton between\nin-sample testing and generalization error\u201d, <em>Complex\nSystems</em>, 6: 47\u201394.</li>\n<li>\u2013\u2013\u2013, 1996, \u201cThe lack of a priori\ndistinctions between learning algorithms\u201d, <em>Neural\nComputation</em> 8: 1341\u20131390.</li>\n<li>Worrall, John, 2010, \u201cFor Universal Rules, Against\nInduction\u201d, <em>Philosophy of Science</em>, 77(5):\n740\u201353.</li>\n<li>Wright, Crispin, 2004, \u201cWittgensteinian Certainties\u201d,\nin Denis McManus (ed.), <em>Wittgenstein and Scepticism</em>, London:\nRoutledge, pp. 22\u201355.</li>\n<li>Zabell, Sandy L., 1988, \u201cSymmetry and Its\nDiscontents\u201d, in Brian Skyrms (ed.), <em>Causation, Chance and\nCredence</em>, Dordrecht: Springer Netherlands, pp.\n155\u2013190.</li>\n<li>\u2013\u2013\u2013, 1989, \u201cThe Rule of Succession\u201d,\n<em>Erkenntnis</em>, 31(2\u20133): 283\u2013321.</li>\n</ul>\n</div>"
    },
    "related_entries": {
        "entry_list": [
            "Bayes\u2019 Theorem",
            "belief, formal representations of",
            "confirmation",
            "epistemology, formal",
            "Feigl, Herbert",
            "Goodman, Nelson",
            "Hume, David",
            "Kant, Immanuel: and Hume on causality",
            "laws of nature",
            "learning theory, formal",
            "logic: inductive",
            "Popper, Karl",
            "probability, interpretations of",
            "Reichenbach, Hans",
            "simplicity",
            "skepticism",
            "statistics, philosophy of",
            "Strawson, Peter Frederick"
        ],
        "entry_link": [
            {
                "../bayes-theorem/": "Bayes\u2019 Theorem"
            },
            {
                "../formal-belief/": "belief, formal representations of"
            },
            {
                "../confirmation/": "confirmation"
            },
            {
                "../formal-epistemology/": "epistemology, formal"
            },
            {
                "../feigl/": "Feigl, Herbert"
            },
            {
                "../goodman/": "Goodman, Nelson"
            },
            {
                "../hume/": "Hume, David"
            },
            {
                "../kant-hume-causality/": "Kant, Immanuel: and Hume on causality"
            },
            {
                "../laws-of-nature/": "laws of nature"
            },
            {
                "../learning-formal/": "learning theory, formal"
            },
            {
                "../logic-inductive/": "logic: inductive"
            },
            {
                "../popper/": "Popper, Karl"
            },
            {
                "../probability-interpret/": "probability, interpretations of"
            },
            {
                "../reichenbach/": "Reichenbach, Hans"
            },
            {
                "../simplicity/": "simplicity"
            },
            {
                "../skepticism/": "skepticism"
            },
            {
                "../statistics/": "statistics, philosophy of"
            },
            {
                "../strawson/": "Strawson, Peter Frederick"
            }
        ]
    },
    "academic_tools": {
        "listed_text": [
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=induction-problem\" target=\"other\">How to cite this entry</a>.",
            "<img alt=\"sep man icon\" src=\"../../symbols/sepman-icon.jpg\"/>",
            "<a href=\"https://leibniz.stanford.edu/friends/preview/induction-problem/\" target=\"other\">Preview the PDF version of this entry</a> at the\n <a href=\"https://leibniz.stanford.edu/friends/\" target=\"other\">Friends of the SEP Society</a>.",
            "<img alt=\"inpho icon\" src=\"../../symbols/inpho.png\"/>",
            "<a href=\"https://www.inphoproject.org/entity?sep=induction-problem&amp;redirect=True\" target=\"other\">Look up topics and thinkers related to this entry</a>\n at the Internet Philosophy Ontology Project (InPhO).",
            "<img alt=\"phil papers icon\" src=\"../../symbols/pp.gif\"/>",
            "<a href=\"https://philpapers.org/sep/induction-problem/\" target=\"other\">Enhanced bibliography for this entry</a>\nat <a href=\"https://philpapers.org/\" target=\"other\">PhilPapers</a>, with links to its database."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=induction-problem": "How to cite this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/preview/induction-problem/": "Preview the PDF version of this entry"
            },
            {
                "https://leibniz.stanford.edu/friends/": "Friends of the SEP Society"
            },
            {
                "https://www.inphoproject.org/entity?sep=induction-problem&redirect=True": "Look up topics and thinkers related to this entry"
            },
            {
                "https://philpapers.org/sep/induction-problem/": "Enhanced bibliography for this entry"
            },
            {
                "https://philpapers.org/": "PhilPapers"
            }
        ]
    },
    "other_internet_resources": {
        "listed_text": [
            "Vickers, John, \u201cThe Problem of Induction,\u201d\n<em>Stanford Encyclopedia of Philosophy</em> (Spring 2018 Edition),\nEdward N. Zalta (ed.), URL =\n &lt;<a href=\"https://plato.stanford.edu/archives/spr2018/entries/induction-problem/\" target=\"other\">https://plato.stanford.edu/archives/spr2018/entries/induction-problem/</a>&gt;.\n [This was the previous entry on the problem of induction in the\n<em>Stanford Encyclopedia of Philosophy</em> \u2014 see the\n <a class=\"plain\" href=\"https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=induction-problem\" target=\"other\">version history</a>.]",
            "<a href=\"http://www.ditext.com/clay/armendt2.html\" target=\"other\">Teaching Theory of Knowledge: Probability and Induction</a>,\n organization of topics and bibliography by Brad Armendt (Arizona\nState University) and Martin Curd (Purdue).",
            "<a href=\"http://www.forecastingprinciples.com/\" target=\"other\">Forecasting Principles</a>,\n A brief survey of prediction markets."
        ],
        "listed_links": [
            {
                "https://plato.stanford.edu/archives/spr2018/entries/induction-problem/": "https://plato.stanford.edu/archives/spr2018/entries/induction-problem/"
            },
            {
                "https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=induction-problem": "version history"
            },
            {
                "http://www.ditext.com/clay/armendt2.html": "Teaching Theory of Knowledge: Probability and Induction"
            },
            {
                "http://www.forecastingprinciples.com/": "Forecasting Principles"
            }
        ]
    }
}