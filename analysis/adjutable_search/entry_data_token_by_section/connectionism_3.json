{
    "main_text": "Strengths and Weaknesses of Neural Network Models\n4. Strengths and Weaknesses of Neural Network Models\n\nPhilosophers are interested in neural networks because they may\nprovide a new framework for understanding the nature of the mind and\nits relation to the brain (Rumelhart & McClelland 1986: Chapter\n1). Connectionist models seem particularly well matched to what we\nknow about neurology. The brain is indeed a neural net, formed from\nmassively many units (neurons) and their connections (synapses).\nFurthermore, several properties of neural network models suggest that\nconnectionism may offer an especially faithful picture of the nature\nof cognitive processing. Neural networks exhibit robust flexibility in\nthe face of the challenges posed by the real world. Noisy input or\ndestruction of units causes graceful degradation of function. The\nnet\u2019s response is still appropriate, though somewhat less\naccurate. In contrast, noise and loss of circuitry in classical\ncomputers typically result in catastrophic failure. Neural networks\nare also particularly well adapted for problems that require the\nresolution of many conflicting constraints in parallel. There is ample\nevidence from research in artificial intelligence that cognitive tasks\nsuch as object recognition, planning, and even coordinated motion\npresent problems of this kind. Although classical systems are capable\nof multiple constraint satisfaction, connectionists argue that neural\nnetwork models provide much more natural mechanisms for dealing with\nsuch problems.\n\nOver the centuries, philosophers have struggled to understand how our\nconcepts are defined. It is now widely acknowledged that trying to\ncharacterize ordinary notions with necessary and sufficient conditions\nis doomed to failure. Exceptions to almost any proposed definition are\nalways waiting in the wings. For example, one might propose that a\ntiger is a large black and orange feline. But then what about albino\ntigers? Philosophers and cognitive psychologists have argued that\ncategories are delimited in more flexible ways, for example via a\nnotion of family resemblance or similarity to a prototype.\nConnectionist models seem especially well suited to accommodating\ngraded notions of category membership of this kind. Nets can learn to\nappreciate subtle statistical patterns that would be very hard to\nexpress as hard and fast rules. Connectionism promises to explain\nflexibility and insight found in human intelligence using methods that\ncannot be easily expressed in the form of exception free principles\n(Horgan & Tienson 1989, 1990), thus avoiding the brittleness that\narises from standard forms of symbolic representation.\n\nDespite these intriguing features, there are some weaknesses in\nconnectionist models that bear mentioning. First, most neural network\nresearch abstracts away from many interesting and possibly important\nfeatures of the brain. For example, connectionists usually do not\nattempt to explicitly model the variety of different kinds of brain\nneurons, nor the effects of neurotransmitters and hormones.\nFurthermore, it is far from clear that the brain contains the kind of\nreverse connections that would be needed if the brain were to learn by\na process like backpropagation, and the immense number of repetitions\nneeded for such training methods seems far from realistic. Attention\nto these matters will probably be necessary if convincing\nconnectionist models of human cognitive processing are to be\nconstructed. A more serious objection must also be met. It is widely\nfelt, especially among classicists, that neural networks are not\nparticularly good at the kind of rule based processing that is thought\nto undergird language, reasoning, and higher forms of thought. (For a\nwell known critique of this kind see Pinker and Prince 1988.) We will\ndiscuss the matter further when we turn to\n the systematicity debate.\n\nThere has been a cottage industry in developing more\nbiologically-plausible algorithms for error-driven training that can\nbe shown to approximate the results of backpropagation without its\nimplausible features. Prominent examples include\nO\u2019Reilly\u2019s Generalized Error Recirculation algorithm\n(O\u2019Reilly 1996), using randomized error signals rather than\nerror signals individually computed for each neuron (Lillicrap,\nCownden, Tweed, & Akerman 2016), and modifying weights using\nspike-timing dependent plasticity--the latter of which has been a\nfavorite of prominent figures in deep learning research (Bengio et al.\n2017). (For more on deep learning see\n section 11\n below.) \n",
    "section_title": "4. Strengths and Weaknesses of Neural Network Models",
    "entry_title": "Connectionism",
    "hierarchy_title": "Connectionism || Strengths and Weaknesses of Neural Network Models",
    "tokenized_text": [
        "strength",
        "weakness",
        "neural",
        "network",
        "model",
        "strength",
        "weakness",
        "neural",
        "network",
        "model",
        "philosopher",
        "interested",
        "neural",
        "network",
        "may",
        "provide",
        "new",
        "framework",
        "understanding",
        "nature",
        "mind",
        "relation",
        "brain",
        "rumelhart",
        "mcclelland",
        "chapter",
        "connectionist",
        "model",
        "seem",
        "particularly",
        "well",
        "matched",
        "know",
        "neurology",
        "brain",
        "indeed",
        "neural",
        "net",
        "formed",
        "massively",
        "many",
        "unit",
        "neuron",
        "connection",
        "synapsis",
        "furthermore",
        "several",
        "property",
        "neural",
        "network",
        "model",
        "suggest",
        "connectionism",
        "may",
        "offer",
        "especially",
        "faithful",
        "picture",
        "nature",
        "cognitive",
        "processing",
        "neural",
        "network",
        "exhibit",
        "robust",
        "flexibility",
        "face",
        "challenge",
        "posed",
        "real",
        "world",
        "noisy",
        "input",
        "destruction",
        "unit",
        "cause",
        "graceful",
        "degradation",
        "function",
        "net",
        "response",
        "still",
        "appropriate",
        "though",
        "somewhat",
        "le",
        "accurate",
        "contrast",
        "noise",
        "loss",
        "circuitry",
        "classical",
        "computer",
        "typically",
        "result",
        "catastrophic",
        "failure",
        "neural",
        "network",
        "also",
        "particularly",
        "well",
        "adapted",
        "problem",
        "require",
        "resolution",
        "many",
        "conflicting",
        "constraint",
        "parallel",
        "ample",
        "evidence",
        "research",
        "artificial",
        "intelligence",
        "cognitive",
        "task",
        "object",
        "recognition",
        "planning",
        "even",
        "coordinated",
        "motion",
        "present",
        "problem",
        "kind",
        "although",
        "classical",
        "system",
        "capable",
        "multiple",
        "constraint",
        "satisfaction",
        "connectionists",
        "argue",
        "neural",
        "network",
        "model",
        "provide",
        "much",
        "natural",
        "mechanism",
        "dealing",
        "problem",
        "century",
        "philosopher",
        "struggled",
        "understand",
        "concept",
        "defined",
        "widely",
        "acknowledged",
        "trying",
        "characterize",
        "ordinary",
        "notion",
        "necessary",
        "sufficient",
        "condition",
        "doomed",
        "failure",
        "exception",
        "almost",
        "proposed",
        "definition",
        "always",
        "waiting",
        "wing",
        "example",
        "one",
        "might",
        "propose",
        "tiger",
        "large",
        "black",
        "orange",
        "feline",
        "albino",
        "tiger",
        "philosopher",
        "cognitive",
        "psychologist",
        "argued",
        "category",
        "delimited",
        "flexible",
        "way",
        "example",
        "via",
        "notion",
        "family",
        "resemblance",
        "similarity",
        "prototype",
        "connectionist",
        "model",
        "seem",
        "especially",
        "well",
        "suited",
        "accommodating",
        "graded",
        "notion",
        "category",
        "membership",
        "kind",
        "net",
        "learn",
        "appreciate",
        "subtle",
        "statistical",
        "pattern",
        "would",
        "hard",
        "express",
        "hard",
        "fast",
        "rule",
        "connectionism",
        "promise",
        "explain",
        "flexibility",
        "insight",
        "found",
        "human",
        "intelligence",
        "using",
        "method",
        "easily",
        "expressed",
        "form",
        "exception",
        "free",
        "principle",
        "horgan",
        "tienson",
        "thus",
        "avoiding",
        "brittleness",
        "arises",
        "standard",
        "form",
        "symbolic",
        "representation",
        "despite",
        "intriguing",
        "feature",
        "weakness",
        "connectionist",
        "model",
        "bear",
        "mentioning",
        "first",
        "neural",
        "network",
        "research",
        "abstract",
        "away",
        "many",
        "interesting",
        "possibly",
        "important",
        "feature",
        "brain",
        "example",
        "connectionists",
        "usually",
        "attempt",
        "explicitly",
        "model",
        "variety",
        "different",
        "kind",
        "brain",
        "neuron",
        "effect",
        "neurotransmitter",
        "hormone",
        "furthermore",
        "far",
        "clear",
        "brain",
        "contains",
        "kind",
        "reverse",
        "connection",
        "would",
        "needed",
        "brain",
        "learn",
        "process",
        "like",
        "backpropagation",
        "immense",
        "number",
        "repetition",
        "needed",
        "training",
        "method",
        "seems",
        "far",
        "realistic",
        "attention",
        "matter",
        "probably",
        "necessary",
        "convincing",
        "connectionist",
        "model",
        "human",
        "cognitive",
        "processing",
        "constructed",
        "serious",
        "objection",
        "must",
        "also",
        "met",
        "widely",
        "felt",
        "especially",
        "among",
        "classicist",
        "neural",
        "network",
        "particularly",
        "good",
        "kind",
        "rule",
        "based",
        "processing",
        "thought",
        "undergird",
        "language",
        "reasoning",
        "higher",
        "form",
        "thought",
        "well",
        "known",
        "critique",
        "kind",
        "see",
        "pinker",
        "prince",
        "discus",
        "matter",
        "turn",
        "systematicity",
        "debate",
        "cottage",
        "industry",
        "developing",
        "biologicallyplausible",
        "algorithm",
        "errordriven",
        "training",
        "shown",
        "approximate",
        "result",
        "backpropagation",
        "without",
        "implausible",
        "feature",
        "prominent",
        "example",
        "include",
        "reilly",
        "generalized",
        "error",
        "recirculation",
        "algorithm",
        "reilly",
        "using",
        "randomized",
        "error",
        "signal",
        "rather",
        "error",
        "signal",
        "individually",
        "computed",
        "neuron",
        "lillicrap",
        "cownden",
        "tweed",
        "akerman",
        "modifying",
        "weight",
        "using",
        "spiketiming",
        "dependent",
        "plasticity",
        "latter",
        "favorite",
        "prominent",
        "figure",
        "deep",
        "learning",
        "research",
        "bengio",
        "et",
        "al",
        "deep",
        "learning",
        "see",
        "section"
    ]
}