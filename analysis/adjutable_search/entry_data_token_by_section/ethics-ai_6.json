{
    "main_text": "Main Debates || Opacity of AI Systems\n2.3 Opacity of AI Systems\n\nOpacity and bias are central issues in what is now sometimes called\n\u201cdata ethics\u201d or \u201cbig data ethics\u201d (Floridi\nand Taddeo 2016; Mittelstadt and Floridi 2016). AI systems for\nautomated decision support and \u201cpredictive analytics\u201d\nraise \u201csignificant concerns about lack of due process,\naccountability, community engagement, and auditing\u201d (Whittaker\net al. 2018: 18ff). They are part of a power structure in which\n\u201cwe are creating decision-making processes that constrain and\nlimit opportunities for human participation\u201d (Danaher 2016b:\n245). At the same time, it will often be impossible for the affected\nperson to know how the system came to this output, i.e., the system is\n\u201copaque\u201d to that person. If the system involves machine\nlearning, it will typically be opaque even to the expert, who will not\nknow how a particular pattern was identified, or even what the pattern\nis. Bias in decision systems and data sets is exacerbated by this\nopacity. So, at least in cases where there is a desire to remove bias,\nthe analysis of opacity and bias go hand in hand, and political\nresponse has to tackle both issues together.\n\nMany AI systems rely on machine learning techniques in (simulated)\nneural networks that will extract patterns from a given dataset, with\nor without \u201ccorrect\u201d solutions provided; i.e., supervised,\nsemi-supervised or unsupervised. With these techniques, the\n\u201clearning\u201d captures patterns in the data and these are\nlabelled in a way that appears useful to the decision the system\nmakes, while the programmer does not really know which\npatterns in the data the system has used. In fact, the programs are\nevolving, so when new data comes in, or new feedback is given\n(\u201cthis was correct\u201d, \u201cthis was incorrect\u201d),\nthe patterns used by the learning system change. What this means is\nthat the outcome is not transparent to the user or programmers: it is\nopaque. Furthermore, the quality of the program depends heavily on the\nquality of the data provided, following the old slogan \u201cgarbage\nin, garbage out\u201d. So, if the data already involved a bias (e.g.,\npolice data about the skin colour of suspects), then the program will\nreproduce that bias. There are proposals for a standard description of\ndatasets in a \u201cdatasheet\u201d that would make the\nidentification of such bias more feasible (Gebru et al. 2018 [OIR]).\nThere is also significant recent literature about the limitations of\nmachine learning systems that are essentially sophisticated data\nfilters (Marcus 2018 [OIR]). Some have argued that the ethical\nproblems of today are the result of technical \u201cshortcuts\u201d\nAI has taken (Cristianini forthcoming).\n\nThere are several technical activities that aim at \u201cexplainable\nAI\u201d, starting with (Van Lent, Fisher, and Mancuso 1999; Lomas et\nal. 2012) and, more recently, a DARPA programme (Gunning 2017 [OIR]).\n\nMore broadly, the demand for\n\n\na mechanism for elucidating and articulating the power structures,\nbiases, and influences that computational artefacts exercise in\nsociety (Diakopoulos 2015: 398)\n\n\nis sometimes called \u201calgorithmic accountability\nreporting\u201d. This does not mean that we expect an AI to\n\u201cexplain its reasoning\u201d\u2014doing so would require far\nmore serious moral autonomy than we currently attribute to AI systems\n(see below\n \u00a72.10).\n\nThe politician Henry Kissinger pointed out that there is a fundamental\nproblem for democratic decision-making if we rely on a system that is\nsupposedly superior to humans, but cannot explain its decisions. He\nsays we may have \u201cgenerated a potentially dominating technology\nin search of a guiding philosophy\u201d (Kissinger 2018). Danaher\n(2016b) calls this problem \u201cthe threat of algocracy\u201d\n(adopting the previous use of \u2018algocracy\u2019 from Aneesh 2002\n[OIR], 2006). In a similar vein, Cave (2019) stresses that we need a\nbroader societal move towards more \u201cdemocratic\u201d\ndecision-making to avoid AI being a force that leads to a Kafka-style\nimpenetrable suppression system in public administration and\nelsewhere. The political angle of this discussion has been stressed by\nO\u2019Neil in her influential book Weapons of Math\nDestruction (2016), and by Yeung and Lodge (2019).\n\nIn the EU, some of these issues have been taken into account with the\n(Regulation (EU) 2016/679), which foresees that consumers, when faced\nwith a decision based on data processing, will have a legal\n\u201cright to explanation\u201d\u2014how far this goes and to what\nextent it can be enforced is disputed (Goodman and Flaxman 2017;\nWachter, Mittelstadt, and Floridi 2016; Wachter, Mittelstadt, and\nRussell 2017). Zerilli et al. (2019) argue that there may be a double\nstandard here, where we demand a high level of explanation for\nmachine-based decisions despite humans sometimes not reaching that\nstandard themselves.\n",
    "section_title": "2.3 Opacity of AI Systems",
    "entry_title": "Ethics of Artificial Intelligence and Robotics",
    "hierarchy_title": "Ethics of Artificial Intelligence and Robotics || Main Debates || Opacity of AI Systems",
    "tokenized_text": [
        "main",
        "debate",
        "opacity",
        "ai",
        "system",
        "opacity",
        "ai",
        "system",
        "opacity",
        "bias",
        "central",
        "issue",
        "sometimes",
        "called",
        "data",
        "ethic",
        "big",
        "data",
        "ethic",
        "floridi",
        "taddeo",
        "mittelstadt",
        "floridi",
        "ai",
        "system",
        "automated",
        "decision",
        "support",
        "predictive",
        "analytics",
        "raise",
        "significant",
        "concern",
        "lack",
        "due",
        "process",
        "accountability",
        "community",
        "engagement",
        "auditing",
        "whittaker",
        "et",
        "al",
        "ff",
        "part",
        "power",
        "structure",
        "creating",
        "decisionmaking",
        "process",
        "constrain",
        "limit",
        "opportunity",
        "human",
        "participation",
        "danaher",
        "b",
        "time",
        "often",
        "impossible",
        "affected",
        "person",
        "know",
        "system",
        "came",
        "output",
        "ie",
        "system",
        "opaque",
        "person",
        "system",
        "involves",
        "machine",
        "learning",
        "typically",
        "opaque",
        "even",
        "expert",
        "know",
        "particular",
        "pattern",
        "identified",
        "even",
        "pattern",
        "bias",
        "decision",
        "system",
        "data",
        "set",
        "exacerbated",
        "opacity",
        "least",
        "case",
        "desire",
        "remove",
        "bias",
        "analysis",
        "opacity",
        "bias",
        "go",
        "hand",
        "hand",
        "political",
        "response",
        "tackle",
        "issue",
        "together",
        "many",
        "ai",
        "system",
        "rely",
        "machine",
        "learning",
        "technique",
        "simulated",
        "neural",
        "network",
        "extract",
        "pattern",
        "given",
        "dataset",
        "without",
        "correct",
        "solution",
        "provided",
        "ie",
        "supervised",
        "semisupervised",
        "unsupervised",
        "technique",
        "learning",
        "capture",
        "pattern",
        "data",
        "labelled",
        "way",
        "appears",
        "useful",
        "decision",
        "system",
        "make",
        "programmer",
        "really",
        "know",
        "pattern",
        "data",
        "system",
        "used",
        "fact",
        "program",
        "evolving",
        "new",
        "data",
        "come",
        "new",
        "feedback",
        "given",
        "correct",
        "incorrect",
        "pattern",
        "used",
        "learning",
        "system",
        "change",
        "mean",
        "outcome",
        "transparent",
        "user",
        "programmer",
        "opaque",
        "furthermore",
        "quality",
        "program",
        "depends",
        "heavily",
        "quality",
        "data",
        "provided",
        "following",
        "old",
        "slogan",
        "garbage",
        "garbage",
        "data",
        "already",
        "involved",
        "bias",
        "eg",
        "police",
        "data",
        "skin",
        "colour",
        "suspect",
        "program",
        "reproduce",
        "bias",
        "proposal",
        "standard",
        "description",
        "datasets",
        "datasheet",
        "would",
        "make",
        "identification",
        "bias",
        "feasible",
        "gebru",
        "et",
        "al",
        "oir",
        "also",
        "significant",
        "recent",
        "literature",
        "limitation",
        "machine",
        "learning",
        "system",
        "essentially",
        "sophisticated",
        "data",
        "filter",
        "marcus",
        "oir",
        "argued",
        "ethical",
        "problem",
        "today",
        "result",
        "technical",
        "shortcut",
        "ai",
        "taken",
        "cristianini",
        "forthcoming",
        "several",
        "technical",
        "activity",
        "aim",
        "explainable",
        "ai",
        "starting",
        "van",
        "lent",
        "fisher",
        "mancuso",
        "lomas",
        "et",
        "al",
        "recently",
        "darpa",
        "programme",
        "gunning",
        "oir",
        "broadly",
        "demand",
        "mechanism",
        "elucidating",
        "articulating",
        "power",
        "structure",
        "bias",
        "influence",
        "computational",
        "artefact",
        "exercise",
        "society",
        "diakopoulos",
        "sometimes",
        "called",
        "algorithmic",
        "accountability",
        "reporting",
        "mean",
        "expect",
        "ai",
        "explain",
        "reasoning",
        "doing",
        "would",
        "require",
        "far",
        "serious",
        "moral",
        "autonomy",
        "currently",
        "attribute",
        "ai",
        "system",
        "see",
        "politician",
        "henry",
        "kissinger",
        "pointed",
        "fundamental",
        "problem",
        "democratic",
        "decisionmaking",
        "rely",
        "system",
        "supposedly",
        "superior",
        "human",
        "explain",
        "decision",
        "say",
        "may",
        "generated",
        "potentially",
        "dominating",
        "technology",
        "search",
        "guiding",
        "philosophy",
        "kissinger",
        "danaher",
        "b",
        "call",
        "problem",
        "threat",
        "algocracy",
        "adopting",
        "previous",
        "use",
        "algocracy",
        "aneesh",
        "oir",
        "similar",
        "vein",
        "cave",
        "stress",
        "need",
        "broader",
        "societal",
        "move",
        "towards",
        "democratic",
        "decisionmaking",
        "avoid",
        "ai",
        "force",
        "lead",
        "kafkastyle",
        "impenetrable",
        "suppression",
        "system",
        "public",
        "administration",
        "elsewhere",
        "political",
        "angle",
        "discussion",
        "stressed",
        "neil",
        "influential",
        "book",
        "weapon",
        "math",
        "destruction",
        "yeung",
        "lodge",
        "eu",
        "issue",
        "taken",
        "account",
        "regulation",
        "eu",
        "foresees",
        "consumer",
        "faced",
        "decision",
        "based",
        "data",
        "processing",
        "legal",
        "right",
        "explanation",
        "how",
        "far",
        "go",
        "extent",
        "enforced",
        "disputed",
        "goodman",
        "flaxman",
        "wachter",
        "mittelstadt",
        "floridi",
        "wachter",
        "mittelstadt",
        "russell",
        "zerilli",
        "et",
        "al",
        "argue",
        "may",
        "double",
        "standard",
        "demand",
        "high",
        "level",
        "explanation",
        "machinebased",
        "decision",
        "despite",
        "human",
        "sometimes",
        "reaching",
        "standard"
    ]
}