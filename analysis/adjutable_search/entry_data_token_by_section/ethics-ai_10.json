{
    "main_text": "Main Debates || Autonomous Systems\n2.7 Autonomous Systems\n\nThere are several notions of autonomy in the discussion of autonomous\nsystems. A stronger notion is involved in philosophical debates where\nautonomy is the basis for responsibility and personhood (Christman\n2003 [2018]). In this context, responsibility implies autonomy, but\nnot inversely, so there can be systems that have degrees of technical\nautonomy without raising issues of responsibility. The weaker, more\ntechnical, notion of autonomy in robotics is relative and gradual: A\nsystem is said to be autonomous with respect to human control to a\ncertain degree (M\u00fcller 2012). There is a parallel here to the\nissues of bias and opacity in AI since autonomy also concerns a\npower-relation: who is in control, and who is responsible?\n\nGenerally speaking, one question is the degree to which autonomous\nrobots raise issues our present conceptual schemes must adapt to, or\nwhether they just require technical adjustments. In most\njurisdictions, there is a sophisticated system of civil and criminal\nliability to resolve such issues. Technical standards, e.g., for the\nsafe use of machinery in medical environments, will likely need to be\nadjusted. There is already a field of \u201cverifiable AI\u201d for\nsuch safety-critical systems and for \u201csecurity\napplications\u201d. Bodies like the IEEE (The Institute of Electrical\nand Electronics Engineers) and the BSI (British Standards Institution)\nhave produced \u201cstandards\u201d, particularly on more technical\nsub-problems, such as data security and transparency. Among the many\nautonomous systems on land, on water, under water, in air or space, we\ndiscuss two samples: autonomous vehicles and autonomous weapons.\n2.7.1 Example (a) Autonomous Vehicles\n\nAutonomous vehicles hold the promise to reduce the very significant\ndamage that human driving currently causes\u2014approximately 1\nmillion humans being killed per year, many more injured, the\nenvironment polluted, earth sealed with concrete and tarmac, cities\nfull of parked cars, etc. However, there seem to be questions on how\nautonomous vehicles should behave, and how responsibility and risk\nshould be distributed in the complicated system the vehicles operates\nin. (There is also significant disagreement over how long the\ndevelopment of fully autonomous, or \u201clevel 5\u201d cars (SAE\nInternational 2018) will actually take.)\n\nThere is some discussion of \u201ctrolley problems\u201d in this\ncontext. In the classic \u201ctrolley problems\u201d (Thomson 1976;\nWoollard and Howard-Snyder 2016: section 2) various dilemmas are\npresented. The simplest version is that of a trolley train on a track\nthat is heading towards five people and will kill them, unless the\ntrain is diverted onto a side track, but on that track there is one\nperson, who will be killed if the train takes that side track. The\nexample goes back to a remark in (Foot 1967: 6), who discusses a\nnumber of dilemma cases where tolerated and intended consequences of\nan action differ. \u201cTrolley problems\u201d are not supposed to\ndescribe actual ethical problems or to be solved with a\n\u201cright\u201d choice. Rather, they are thought-experiments where\nchoice is artificially constrained to a small finite number of\ndistinct one-off options and where the agent has perfect knowledge.\nThese problems are used as a theoretical tool to investigate ethical\nintuitions and theories\u2014especially the difference between\nactively doing vs. allowing something to happen, intended vs.\ntolerated consequences, and consequentialist vs. other normative\napproaches (Kamm 2016). This type of problem has reminded many of the\nproblems encountered in actual driving and in autonomous driving (Lin\n2016). It is doubtful, however, that an actual driver or autonomous\ncar will ever have to solve trolley problems (but see Keeling 2020).\nWhile autonomous car trolley problems have received a lot of media\nattention (Awad et al. 2018), they do not seem to offer anything new\nto either ethical theory or to the programming of autonomous\nvehicles.\n\nThe more common ethical problems in driving, such as speeding, risky\novertaking, not keeping a safe distance, etc. are classic problems of\npursuing personal interest vs. the common good. The vast majority of\nthese are covered by legal regulations on driving. Programming the car\nto drive \u201cby the rules\u201d rather than \u201cby the interest\nof the passengers\u201d or \u201cto achieve maximum utility\u201d\nis thus deflated to a standard problem of programming ethical machines\n(see\n section 2.9).\n There are probably additional discretionary rules of politeness and\ninteresting questions on when to break the rules (Lin 2016), but again\nthis seems to be more a case of applying standard considerations\n(rules vs. utility) to the case of autonomous vehicles.\n\nNotable policy efforts in this field include the report (German\nFederal Ministry of Transport and Digital Infrastructure 2017), which\nstresses that safety is the primary objective. Rule 10\nstates\n\n\nIn the case of automated and connected driving systems, the\naccountability that was previously the sole preserve of the individual\nshifts from the motorist to the manufacturers and operators of the\ntechnological systems and to the bodies responsible for taking\ninfrastructure, policy and legal decisions.\n\n\n(See\n section 2.10.1\n below). The resulting German and EU laws on licensing automated\ndriving are much more restrictive than their US counterparts where\n\u201ctesting on consumers\u201d is a strategy used by some\ncompanies\u2014without informed consent of the consumers or their\npossible victims.\n2.7.2 Example (b) Autonomous Weapons\n\nThe notion of automated weapons is fairly old:\n\n\nFor example, instead of fielding simple guided missiles or remotely\npiloted vehicles, we might launch completely autonomous land, sea, and\nair vehicles capable of complex, far-ranging reconnaissance and attack\nmissions. (DARPA 1983: 1)\n\n\nThis proposal was ridiculed as \u201cfantasy\u201d at the time\n(Dreyfus, Dreyfus, and Athanasiou 1986: ix), but it is now a reality,\nat least for more easily identifiable targets (missiles, planes,\nships, tanks, etc.), but not for human combatants. The main arguments\nagainst (lethal) autonomous weapon systems (AWS or LAWS), are that\nthey support extrajudicial killings, take responsibility away from\nhumans, and make wars or killings more likely\u2014for a detailed\nlist of issues see Lin, Bekey, and Abney (2008: 73\u201386).\n\nIt appears that lowering the hurdle to use such systems (autonomous\nvehicles, \u201cfire-and-forget\u201d missiles, or drones loaded\nwith explosives) and reducing the probability of being held\naccountable would increase the probability of their use. The crucial\nasymmetry where one side can kill with impunity, and thus has few\nreasons not to do so, already exists in conventional drone wars with\nremote controlled weapons (e.g., US in Pakistan). It is easy to\nimagine a small drone that searches, identifies, and kills an\nindividual human\u2014or perhaps a type of human. These are the kinds\nof cases brought forward by the Campaign to Stop Killer\nRobots and other activist groups. Some seem to be equivalent to\nsaying that autonomous weapons are indeed weapons \u2026, and\nweapons kill, but we still make them in gigantic numbers. On the\nmatter of accountability, autonomous weapons might make identification\nand prosecution of the responsible agents more difficult\u2014but\nthis is not clear, given the digital records that one can keep, at\nleast in a conventional war. The difficulty of allocating punishment\nis sometimes called the \u201cretribution gap\u201d (Danaher\n2016a).\n\nAnother question is whether using autonomous weapons in war would make\nwars worse, or make wars less bad. If robots reduce war crimes and\ncrimes in war, the answer may well be positive and has been used as an\nargument in favour of these weapons (Arkin 2009; M\u00fcller 2016a)\nbut also as an argument against them (Amoroso and Tamburrini 2018).\nArguably the main threat is not the use of such weapons in\nconventional warfare, but in asymmetric conflicts or by non-state\nagents, including criminals.\n\nIt has also been said that autonomous weapons cannot conform to\nInternational Humanitarian Law, which requires observance of the\nprinciples of distinction (between combatants and civilians),\nproportionality (of force), and military necessity (of force) in\nmilitary conflict (A. Sharkey 2019). It is true that the distinction\nbetween combatants and non-combatants is hard, but the distinction\nbetween civilian and military ships is easy\u2014so all this says is\nthat we should not construct and use such weapons if they do violate\nHumanitarian Law. Additional concerns have been raised that being\nkilled by an autonomous weapon threatens human dignity, but even the\ndefenders of a ban on these weapons seem to say that these are not\ngood arguments:\n\n\nThere are other weapons, and other technologies, that also compromise\nhuman dignity. Given this, and the ambiguities inherent in the\nconcept, it is wiser to draw on several types of objections in\narguments against AWS, and not to rely exclusively on human dignity.\n(A. Sharkey 2019)\n\n\nA lot has been made of keeping humans \u201cin the loop\u201d or\n\u201con the loop\u201d in the military guidance on\nweapons\u2014these ways of spelling out \u201cmeaningful\ncontrol\u201d are discussed in (Santoni de Sio and van den Hoven\n2018). There have been discussions about the difficulties of\nallocating responsibility for the killings of an autonomous weapon,\nand a \u201cresponsibility gap\u201d has been suggested (esp. Rob\nSparrow 2007), meaning that neither the human nor the machine may be\nresponsible. On the other hand, we do not assume that for every event\nthere is someone responsible for that event, and the real issue may\nwell be the distribution of risk (Simpson and M\u00fcller 2016). Risk\nanalysis (Hansson 2013) indicates it is crucial to identify who is\nexposed to risk, who is a potential beneficiary, and\nwho makes the decisions (Hansson 2018: 1822\u20131824).\n",
    "section_title": "2.7 Autonomous Systems",
    "entry_title": "Ethics of Artificial Intelligence and Robotics",
    "hierarchy_title": "Ethics of Artificial Intelligence and Robotics || Main Debates || Autonomous Systems",
    "tokenized_text": [
        "main",
        "debate",
        "autonomous",
        "system",
        "autonomous",
        "system",
        "several",
        "notion",
        "autonomy",
        "discussion",
        "autonomous",
        "system",
        "stronger",
        "notion",
        "involved",
        "philosophical",
        "debate",
        "autonomy",
        "basis",
        "responsibility",
        "personhood",
        "christman",
        "context",
        "responsibility",
        "implies",
        "autonomy",
        "inversely",
        "system",
        "degree",
        "technical",
        "autonomy",
        "without",
        "raising",
        "issue",
        "responsibility",
        "weaker",
        "technical",
        "notion",
        "autonomy",
        "robotics",
        "relative",
        "gradual",
        "system",
        "said",
        "autonomous",
        "respect",
        "human",
        "control",
        "certain",
        "degree",
        "m\u00fcller",
        "parallel",
        "issue",
        "bias",
        "opacity",
        "ai",
        "since",
        "autonomy",
        "also",
        "concern",
        "powerrelation",
        "control",
        "responsible",
        "generally",
        "speaking",
        "one",
        "question",
        "degree",
        "autonomous",
        "robot",
        "raise",
        "issue",
        "present",
        "conceptual",
        "scheme",
        "must",
        "adapt",
        "whether",
        "require",
        "technical",
        "adjustment",
        "jurisdiction",
        "sophisticated",
        "system",
        "civil",
        "criminal",
        "liability",
        "resolve",
        "issue",
        "technical",
        "standard",
        "eg",
        "safe",
        "use",
        "machinery",
        "medical",
        "environment",
        "likely",
        "need",
        "adjusted",
        "already",
        "field",
        "verifiable",
        "ai",
        "safetycritical",
        "system",
        "security",
        "application",
        "body",
        "like",
        "ieee",
        "institute",
        "electrical",
        "electronics",
        "engineer",
        "bsi",
        "british",
        "standard",
        "institution",
        "produced",
        "standard",
        "particularly",
        "technical",
        "subproblems",
        "data",
        "security",
        "transparency",
        "among",
        "many",
        "autonomous",
        "system",
        "land",
        "water",
        "water",
        "air",
        "space",
        "discus",
        "two",
        "sample",
        "autonomous",
        "vehicle",
        "autonomous",
        "weapon",
        "example",
        "autonomous",
        "vehicle",
        "autonomous",
        "vehicle",
        "hold",
        "promise",
        "reduce",
        "significant",
        "damage",
        "human",
        "driving",
        "currently",
        "causesapproximately",
        "million",
        "human",
        "killed",
        "per",
        "year",
        "many",
        "injured",
        "environment",
        "polluted",
        "earth",
        "sealed",
        "concrete",
        "tarmac",
        "city",
        "full",
        "parked",
        "car",
        "etc",
        "however",
        "seem",
        "question",
        "autonomous",
        "vehicle",
        "behave",
        "responsibility",
        "risk",
        "distributed",
        "complicated",
        "system",
        "vehicle",
        "operates",
        "also",
        "significant",
        "disagreement",
        "long",
        "development",
        "fully",
        "autonomous",
        "level",
        "car",
        "sae",
        "international",
        "actually",
        "take",
        "discussion",
        "trolley",
        "problem",
        "context",
        "classic",
        "trolley",
        "problem",
        "thomson",
        "woollard",
        "howardsnyder",
        "section",
        "various",
        "dilemma",
        "presented",
        "simplest",
        "version",
        "trolley",
        "train",
        "track",
        "heading",
        "towards",
        "five",
        "people",
        "kill",
        "unless",
        "train",
        "diverted",
        "onto",
        "side",
        "track",
        "track",
        "one",
        "person",
        "killed",
        "train",
        "take",
        "side",
        "track",
        "example",
        "go",
        "back",
        "remark",
        "foot",
        "discus",
        "number",
        "dilemma",
        "case",
        "tolerated",
        "intended",
        "consequence",
        "action",
        "differ",
        "trolley",
        "problem",
        "supposed",
        "describe",
        "actual",
        "ethical",
        "problem",
        "solved",
        "right",
        "choice",
        "rather",
        "thoughtexperiments",
        "choice",
        "artificially",
        "constrained",
        "small",
        "finite",
        "number",
        "distinct",
        "oneoff",
        "option",
        "agent",
        "perfect",
        "knowledge",
        "problem",
        "used",
        "theoretical",
        "tool",
        "investigate",
        "ethical",
        "intuition",
        "theoriesespecially",
        "difference",
        "actively",
        "vs",
        "allowing",
        "something",
        "happen",
        "intended",
        "vs",
        "tolerated",
        "consequence",
        "consequentialist",
        "vs",
        "normative",
        "approach",
        "kamm",
        "type",
        "problem",
        "reminded",
        "many",
        "problem",
        "encountered",
        "actual",
        "driving",
        "autonomous",
        "driving",
        "lin",
        "doubtful",
        "however",
        "actual",
        "driver",
        "autonomous",
        "car",
        "ever",
        "solve",
        "trolley",
        "problem",
        "see",
        "keeling",
        "autonomous",
        "car",
        "trolley",
        "problem",
        "received",
        "lot",
        "medium",
        "attention",
        "awad",
        "et",
        "al",
        "seem",
        "offer",
        "anything",
        "new",
        "either",
        "ethical",
        "theory",
        "programming",
        "autonomous",
        "vehicle",
        "common",
        "ethical",
        "problem",
        "driving",
        "speeding",
        "risky",
        "overtaking",
        "keeping",
        "safe",
        "distance",
        "etc",
        "classic",
        "problem",
        "pursuing",
        "personal",
        "interest",
        "vs",
        "common",
        "good",
        "vast",
        "majority",
        "covered",
        "legal",
        "regulation",
        "driving",
        "programming",
        "car",
        "drive",
        "rule",
        "rather",
        "interest",
        "passenger",
        "achieve",
        "maximum",
        "utility",
        "thus",
        "deflated",
        "standard",
        "problem",
        "programming",
        "ethical",
        "machine",
        "see",
        "section",
        "probably",
        "additional",
        "discretionary",
        "rule",
        "politeness",
        "interesting",
        "question",
        "break",
        "rule",
        "lin",
        "seems",
        "case",
        "applying",
        "standard",
        "consideration",
        "rule",
        "vs",
        "utility",
        "case",
        "autonomous",
        "vehicle",
        "notable",
        "policy",
        "effort",
        "field",
        "include",
        "report",
        "german",
        "federal",
        "ministry",
        "transport",
        "digital",
        "infrastructure",
        "stress",
        "safety",
        "primary",
        "objective",
        "rule",
        "state",
        "case",
        "automated",
        "connected",
        "driving",
        "system",
        "accountability",
        "previously",
        "sole",
        "preserve",
        "individual",
        "shift",
        "motorist",
        "manufacturer",
        "operator",
        "technological",
        "system",
        "body",
        "responsible",
        "taking",
        "infrastructure",
        "policy",
        "legal",
        "decision",
        "see",
        "section",
        "resulting",
        "german",
        "eu",
        "law",
        "licensing",
        "automated",
        "driving",
        "much",
        "restrictive",
        "u",
        "counterpart",
        "testing",
        "consumer",
        "strategy",
        "used",
        "companieswithout",
        "informed",
        "consent",
        "consumer",
        "possible",
        "victim",
        "example",
        "b",
        "autonomous",
        "weapon",
        "notion",
        "automated",
        "weapon",
        "fairly",
        "old",
        "example",
        "instead",
        "fielding",
        "simple",
        "guided",
        "missile",
        "remotely",
        "piloted",
        "vehicle",
        "might",
        "launch",
        "completely",
        "autonomous",
        "land",
        "sea",
        "air",
        "vehicle",
        "capable",
        "complex",
        "farranging",
        "reconnaissance",
        "attack",
        "mission",
        "darpa",
        "proposal",
        "ridiculed",
        "fantasy",
        "time",
        "dreyfus",
        "dreyfus",
        "athanasiou",
        "ix",
        "reality",
        "least",
        "easily",
        "identifiable",
        "target",
        "missile",
        "plane",
        "ship",
        "tank",
        "etc",
        "human",
        "combatant",
        "main",
        "argument",
        "lethal",
        "autonomous",
        "weapon",
        "system",
        "aws",
        "law",
        "support",
        "extrajudicial",
        "killing",
        "take",
        "responsibility",
        "away",
        "human",
        "make",
        "war",
        "killing",
        "likelyfor",
        "detailed",
        "list",
        "issue",
        "see",
        "lin",
        "bekey",
        "abney",
        "appears",
        "lowering",
        "hurdle",
        "use",
        "system",
        "autonomous",
        "vehicle",
        "fireandforget",
        "missile",
        "drone",
        "loaded",
        "explosive",
        "reducing",
        "probability",
        "held",
        "accountable",
        "would",
        "increase",
        "probability",
        "use",
        "crucial",
        "asymmetry",
        "one",
        "side",
        "kill",
        "impunity",
        "thus",
        "reason",
        "already",
        "exists",
        "conventional",
        "drone",
        "war",
        "remote",
        "controlled",
        "weapon",
        "eg",
        "u",
        "pakistan",
        "easy",
        "imagine",
        "small",
        "drone",
        "search",
        "identifies",
        "kill",
        "individual",
        "humanor",
        "perhaps",
        "type",
        "human",
        "kind",
        "case",
        "brought",
        "forward",
        "campaign",
        "stop",
        "killer",
        "robot",
        "activist",
        "group",
        "seem",
        "equivalent",
        "saying",
        "autonomous",
        "weapon",
        "indeed",
        "weapon",
        "weapon",
        "kill",
        "still",
        "make",
        "gigantic",
        "number",
        "matter",
        "accountability",
        "autonomous",
        "weapon",
        "might",
        "make",
        "identification",
        "prosecution",
        "responsible",
        "agent",
        "difficultbut",
        "clear",
        "given",
        "digital",
        "record",
        "one",
        "keep",
        "least",
        "conventional",
        "war",
        "difficulty",
        "allocating",
        "punishment",
        "sometimes",
        "called",
        "retribution",
        "gap",
        "danaher",
        "a",
        "another",
        "question",
        "whether",
        "using",
        "autonomous",
        "weapon",
        "war",
        "would",
        "make",
        "war",
        "worse",
        "make",
        "war",
        "le",
        "bad",
        "robot",
        "reduce",
        "war",
        "crime",
        "crime",
        "war",
        "answer",
        "may",
        "well",
        "positive",
        "used",
        "argument",
        "favour",
        "weapon",
        "arkin",
        "m\u00fcller",
        "a",
        "also",
        "argument",
        "amoroso",
        "tamburrini",
        "arguably",
        "main",
        "threat",
        "use",
        "weapon",
        "conventional",
        "warfare",
        "asymmetric",
        "conflict",
        "nonstate",
        "agent",
        "including",
        "criminal",
        "also",
        "said",
        "autonomous",
        "weapon",
        "conform",
        "international",
        "humanitarian",
        "law",
        "requires",
        "observance",
        "principle",
        "distinction",
        "combatant",
        "civilian",
        "proportionality",
        "force",
        "military",
        "necessity",
        "force",
        "military",
        "conflict",
        "a",
        "sharkey",
        "true",
        "distinction",
        "combatant",
        "noncombatants",
        "hard",
        "distinction",
        "civilian",
        "military",
        "ship",
        "easyso",
        "say",
        "construct",
        "use",
        "weapon",
        "violate",
        "humanitarian",
        "law",
        "additional",
        "concern",
        "raised",
        "killed",
        "autonomous",
        "weapon",
        "threatens",
        "human",
        "dignity",
        "even",
        "defender",
        "ban",
        "weapon",
        "seem",
        "say",
        "good",
        "argument",
        "weapon",
        "technology",
        "also",
        "compromise",
        "human",
        "dignity",
        "given",
        "ambiguity",
        "inherent",
        "concept",
        "wiser",
        "draw",
        "several",
        "type",
        "objection",
        "argument",
        "aws",
        "rely",
        "exclusively",
        "human",
        "dignity",
        "a",
        "sharkey",
        "lot",
        "made",
        "keeping",
        "human",
        "loop",
        "loop",
        "military",
        "guidance",
        "weaponsthese",
        "way",
        "spelling",
        "meaningful",
        "control",
        "discussed",
        "santoni",
        "de",
        "sio",
        "van",
        "den",
        "hoven",
        "discussion",
        "difficulty",
        "allocating",
        "responsibility",
        "killing",
        "autonomous",
        "weapon",
        "responsibility",
        "gap",
        "suggested",
        "esp",
        "rob",
        "sparrow",
        "meaning",
        "neither",
        "human",
        "machine",
        "may",
        "responsible",
        "hand",
        "assume",
        "every",
        "event",
        "someone",
        "responsible",
        "event",
        "real",
        "issue",
        "may",
        "well",
        "distribution",
        "risk",
        "simpson",
        "m\u00fcller",
        "risk",
        "analysis",
        "hansson",
        "indicates",
        "crucial",
        "identify",
        "exposed",
        "risk",
        "potential",
        "beneficiary",
        "make",
        "decision",
        "hansson"
    ]
}