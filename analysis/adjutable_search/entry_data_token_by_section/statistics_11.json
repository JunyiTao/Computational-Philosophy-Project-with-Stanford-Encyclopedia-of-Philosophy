{
    "main_text": "Bayesian statistics || Responses to criticism\n4.3 Responses to criticism\nThe philosophy of Bayesian statistics offers a wide range of\nresponses to the problems outlined above. Some Bayesians bite the\nbullet and defend the essentially subjective character of Bayesian\nmethods. Others attempt to remedy or compensate for the subjectivity,\nby providing objectively motivated means of determining the prior\nprobability or by emphasizing the objective character of the Bayesian\nformalism itself.\n4.3.1 Strict but empirically informed subjectivism \nOne very influential view on Bayesian statistics buys into the\nsubjectivity of the analysis (e.g., Goldstein 2006, Kadane 2011).\nSo-called personalists or strict subjectivists argue\nthat it is just right that the statistical methods do not provide any\nobjective guidelines, pointing to radically subjective sources of any\nform of knowledge. The problems on the interpretation and choice of\nthe prior distribution are thus dissolved, at least in part: the\nBayesian statistician may choose her prior at will, and they are an\nexpression of her beliefs. However, it deserves emphasis that a\nsubjectivist view on Bayesian statistics does not mean that all\nconstraints deriving from empirical fact can be disregarded. Nobody\ndenies that if you have further knowledge that imposes constraints on\nthe model or the prior, then those constraints must be\naccommodated. For example, today's posterior probability may be used\nas tomorrow's prior, in the next statistical inference. The point is\nthat such constraints concern the rationality of belief and not the\nconsistency of the statistical inference per se.\nSubjectivist views are most prominent among those who interpret\nprobability assignments in a pragmatic fashion, and motivate the\nrepresentation of belief with probability assignments by the\nafore-mentioned Dutch book arguments. Central to this approach is the\nwork of Savage and De Finetti. Savage (1962) proposed to axiomatize\nstatistics in tandem with decision theory, a mathematical\ntheory about practical rationality. He argued that by themselves the\nprobability assignments do not mean anything at all, and that they can\nonly be interpreted in the context where an agent faces a choice\nbetween actions, i.e., a choice among a set of bets. In similar vein,\nDe Finetti (e.g., 1974) advocated a view on statistics in which only\nthe empirical consequences of the probabilistic beliefs, expressed in\na willingness to bet, mattered but he did not make statistical\ninference fully dependent on decision theory. Remarkably, it thus\nappears that the subjectivist view on Bayesian statistics is based on\nthe same behaviorism and empiricism that motivated Neyman and Pearson\nto develop classical statistics.\nNotice that all this makes one aspect of the interpretation problem\nof \n Section 4.2.1\nreappear: how will the prior distribution over hypotheses make itself\napparent in behavior, so that it can rightfully be interpreted in\nterms of belief, here understood as a willingness to act? One response\nto this question is to turn to different motivations for representing\ndegrees of beliefs by means of probability assignments.  Following\nwork by De Finetti, several authors have proposed vindications of\nprobabilistic expressions of belief that are not based on behavioral\ngoals, but rather on the epistemic goal of holding beliefs that\naccurately represent the world, e.g., Rosenkrantz (1981), Joyce\n(2001), Leitgeb and Pettigrew (2010), Easwaran (2013). A strong\ngeneralization of this idea is achieved in Schervish, Seidenfeld and\nKadane (2009), which builds on a longer tradition of using scoring\nrules for achieving statistical aims. An alternative approach is that\nany formal representation of belief must respect certain logical\nconstraints, e.g., Cox provides an argument for the expression of\nbelief in terms of probability assignments on the basis of the nature\nof partial belief per se. \nHowever, the original subjectivist response to the issue that a\nprior over hypotheses is hard to interpret came from De Finetti's\nso-called representation theorem, which shows that every\nprior distribution can be associated with its own set of predictions,\nand hence with its own behavioral consequences.  In other words, De\nFinetti showed how priors are indeed associated with beliefs that can\ncarry a betting interpretation.\n\n4.3.2 Excursion: the representation theorem\nDe Finetti's representation theorem relates rules for\nprediction, as functions of the given sample data, to Bayesian\nstatistical analyses of those data, against the background of a\nstatistical model. See Festa (1996) and Suppes (2001) for useful\nintroductions. De Finetti considers a process that generates a series\nof time-indexed observations, and he then studies prediction rules\nthat take these finite segments as input and return a probability over\nfuture events, using a statistical model that can analyze such samples\nand provide the predictions. The key result of De Finetti is that a\nparticular statistical model, namely the set of all distributions in\nwhich the observations are independently and identically\ndistributed, can be equated with the class of exchangeable\nprediction rules, namely the rules whose predictions do not\ndepend on the order in which the observations come in.\nLet us consider the representation theorem in some more formal\ndetail. For simplicity, say that the process generates time-indexed\nbinary observations, i.e., 0's and 1's. The prediction rules take such\nbit strings of length \\(t\\), denoted \\(S_{t}\\), as input, and return a\nprobability for the event that the next bit in the string is a 1,\ndenoted \\(Q^{1}_{t+1}\\). So we write the prediction rules as partial\nprobability assignments \\(P(Q^{1}_{t+1} \\mid S_{t})\\). Exchangeable\nprediction rules are rules that deliver the same prediction\nindependently of the order of the bits in the string \\(S_{t}\\). If we\nwrite the event that the string \\(S_{t}\\) has a total of \\(n\\)\nobservations of 1's as \\(S_{n/t}\\), then exchangeable prediction rules\nare written as \\(P(Q^{1}_{t+1} \\mid S_{n/t})\\). The crucial property\nis that the value of the prediction is not affected by the order in\nwhich the 0's and 1's show up in the string \\(S_{t}\\).\nDe Finetti relates this particular set of exchangeable prediction\nrules to a Bayesian inference over a specific type of statistical\nmodel. The model that De Finetti considers comprises the so-called\nBernoulli hypotheses \\(h_{\\theta}\\), i.e., hypotheses for\nwhich\n\n\\[ P(Q^{1}_{t+1} \\mid h_{\\theta} \\cap S_{t}) = \\theta . \\]\n\nThis likelihood does not depend on the string \\(S_{t}\\) that has gone\nbefore. The hypotheses are best thought of as determining a fixed bias\n\\(\\theta\\) for the binary process, where \\(\\theta \\in \\Theta = [0,\n1]\\).  The representation theoremstates that there is a\none-to-one mapping of priors over Bernoulli hypotheses and\nexchangeable prediction rules. That is, every prior distribution\n\\(P(h_{\\theta})\\) can be associated with exactly one exchangeable\nprediction rule \\(P(Q^{1}_{t+1} \\mid S_{n/t})\\), and conversely. Next\nto the original representation theorem derived by De Finetti, several\nother and more general representation theorems were proved, e.g., for\npartially exchangeable sequences and hypotheses on Markov processes\n(Diaconis and Freedman 1980, Skyrms 1991), for clustering predictions\nand partitioning processes (Kingman 1975 and 1978), and even for\nsequences of graphs and their generating process (Aldous 1981).\nRepresentation theorems equate a prior distribution over\nstatistical hypotheses to a prediction rule, and thus to a probability\nassignment that can be given a subjective and behavioral\ninterpretation. This removes the worry expressed above, that the prior\ndistribution over hypotheses cannot be interpreted subjectively\nbecause it cannot be related to belief as a willingness to act: priors\nrelate uniquely to particular predictions. However, for De Finetti the\nrepresentation theorem provided a reason for doing away with\nstatistical hypotheses altogether, and hence for the removal of a\nnotion of probability as anything other than subjective opinion (cf.\nHintikka 1970): hypotheses whose probabilistic claims could be taken\nto refer to intangible chancy processes are superfluous metaphysical\nbaggage.\nNot all subjectivists are equally dismissive of the use of\nstatistical hypotheses. Jeffrey (1992) has proposed so-called\nmixed Bayesianism in which subjectively interpreted\ndistributions over the hypotheses are combined with a physical\ninterpretation of the distributions that hypotheses define over sample\nspace. Romeijn (2003, 2005, 2006) argues that priors over hypotheses\nare an efficient and more intuitive way of determining inductive\npredictions than specifying properties of predictive systems directly. This advantage of using hypotheses seems in agreement with the practice of science,\nin which hypotheses are routinely used, and often motivated by mechanistic knowledge on the data generating process. The fact that statistical hypotheses can\nstrictly speaking be eliminated does not take away from their utility in making predictions.\n4.3.3 Bayesian statistics as logic\nDespite its\u2014seemingly inevitable\u2014subjective character,\nthere is a sense in which Bayesian statistics might lay claim to\nobjectivity. It can be shown that the Bayesian formalism meets certain\nobjective criteria of rationality, coherence, and\ncalibration. Bayesian statistics thus answers to the requirement of\nobjectivity at a meta-level: while the opinions that it deals with\nretain a subjective aspect, the way in which it deals with these\nopinions, in particular the way in which data impacts on them, is\nobjectively correct, or so it is argued. Arguments supporting the\nBayesian way of accommodating data, namely by\nconditionalization, have been provided in a pragmatic context\nby dynamic Dutch book arguments, whereby probability is\ninterpreted as a willingness to bet (cf. Maher 1993, van Fraassen\n1989). Similar arguments have been advanced on the grounds that our\nbeliefs must accurately represent the world along the lines of De\nFinetti (1974), e.g., Greaves and Wallace (2006) and Leitgeb and\nPettigrew (2010).\nAn important distinction must be made in arguments that support the\nBayesian way of accommodating evidence: the distinction between Bayes'\ntheorem, as a mathematical given, and Bayes' rule, as a\nprinciple of coherence over time. The theorem is simply a mathematical\nrelation among probability assignments,\n\n\\[ P(h \\mid s) \\; = \\; P(h) \\frac{P(s \\mid h)}{P(s)} , \\]\n\nand as such not subject to debate. Arguments that support the\nrepresentation of the epistemic state of an agent by means of\nprobability assignments also provide support for Bayes' theorem as a\nconstraint on degrees of belief. The conditional probability \\(P(h\n\\mid s)\\) can be interpreted as the degree of belief attached to the\nhypothesis \\(h\\) on the condition that the sample \\(s\\) is obtained,\nas integral part of the epistemic state captured by the probability\nassignment. Bayes' rule, by contrast, presents a constraint on\nprobability assignments that represent epistemic states of an agent at\ndifferent points in time. It is written as\n\n\\[ P_{s}(h) \\; = P(h \\mid s) , \\]\n\nand it determines that the new probability assignment, expressing the\nepistemic state of the agent after the sample has been obtained, is\nsystematically related to the old assignment, representing the\nepistemic state before the sample came in. In the philosophy of\nstatistics many Bayesians adopt Bayes' rule implicitly, but in what\nfollows I will only assume that Bayesian statistical inferences rely\non Bayes' theorem.\nWhether the focus lies on Bayes' rule or on Bayes' theorem, the\ncommon theme in the above-mentioned arguments is that they approach\nBayesian statistical inference from a logical angle, and focus on its\ninternal coherence or consistency (cf. Howson 2003). While its use in\nstatistics is undeniably inductive, Bayesian inference thereby obtains\na deductive, or at least non-ampliative character: everything that is\nconcluded in the inference is somehow already present in the\npremises. In Bayesian statistical inference, those premises are given\nby the prior over the hypotheses, \\(P(h_{\\theta})\\) for \\(\\theta \\in\n\\Theta\\), and the likelihood functions, \\(P(s \\mid h_{\\theta})\\), as\ndetermined for each hypothesis \\(h_{\\theta}\\) separately.  These\npremises fix a single probability assignment over the space \\(M \\times\nS\\) at the outset of the inference. The conclusions, in turn, are\nstraightforward consequences of this probability assignment. They can\nbe derived by applying theorems of probability theory, most notably\nBayes' theorem. Bayesian statistical inference thus becomes an\ninstance of probabilistic logic (cf. Hailperin 1986, Halpern\n2003, Haenni et al 2011).\nSumming up, there are several arguments showing that statistical\ninference by Bayes' theorem, or by Bayes' rule, is objectively\ncorrect. These arguments invite us to consider Bayesian statistics as\nan instance of probabilistic logic.  Such appeals to the logicality of\nBayesian statistical inference may provide a partial remedy for its\nsubjective character. Moreover, a logical approach to the statistical\ninferences avoids the problem that the formalism places\nunrealistic demands on the agents, and that it presumes the agent to\nhave certain knowledge. Much like in deductive logic, we need not\nassume that the inferences are psychologically realistic, nor that the\nagents actually believe the premises of the arguments. Rather the\narguments present the agents with a normative ideal and take the\nconditional form of consistency constraints: if you accept the\npremises, then these are the conclusions.\n4.3.4 Excursion: inductive logic and statistics\nAn important instance of probabilistic logic is presented in\ninductive logic, as devised by Carnap, Hintikka and others\n(Carnap 1950 and 1952, Hintikka and Suppes 1966, Carnap and Jeffrey\n1970, Hintikka and Niiniluoto 1980, Kuipers 1978, and Paris 1994, Nix\nand Paris 2006, Paris and Waterhouse 2009). Historically, Carnapian\ninductive logic developed prior to the probabilistic logics referenced\nabove, and more or less separately from the debates in the philosophy\nof statistics. But the logical systems of Carnap can quite easily be\nplaced in the context of a logical approach to Bayesian inference, and\ndoing this is in fact quite insightful.\nFor simplicity, we choose a setting that is similar to the one used\nin the exposition of the representation theorem, namely a binary data\ngenerating process, i.e., strings of 0's and 1's. A prediction rule\ndetermines a probability for the event, denoted \\(Q^{1}_{t+1}\\), that\nthe next bit in the string is a 1, on the basis of a given string of\nbits with length \\(t\\), denoted by \\(S_{t}\\). Carnap and followers\ndesigned specific exchangeable prediction rules, mostly variants of\nthe straight rule (Reichenbach 1938),\n\n\\[ P(Q^{1}_{t+1} \\mid S_{n/t}) = \\frac{n + 1}{t + 2} , \\]\n\nwhere \\(S_{n/t}\\) denotes a string of length \\(t\\) of which \\(n\\)\nentries are 1's. Carnap derived such rules from constraints on the\nprobability assignments over the samples. Some of these constraints\nboil down to the axioms of probability. Other constraints,\nexchangeability among them, are independently motivated, by an appeal\nto so-called logical interpretation of probability.  Under\nthis logical interpretation, the probability assignment must respect\ncertain invariances under transformations of the sample space, in\nanalogy to logical principles that constrain truth valuations over a\nlanguage in a particular way.\nCarnapian inductive logic is an instance of probabilistic logic,\nbecause its sequential predictions are all based on a single\nprobability assignment at the outset, and because it relies on Bayes'\ntheorem to adapt the predictions to sample data (cf. Romeijn 2011).\nOne important difference with Bayesian statistical inference is that,\nfor Carnap, the probability assignment specified at the outset only\nranges over samples and not over hypotheses. However, by De Finetti's\nrepresentation theorem Carnap's exchangeable rules can be equated to\nparticular Bayesian statistical inferences. A further difference is\nthat Carnapian inductive logic gives preferred status to particular\nexchangeable rules. In view of De Finetti's representation theorem,\nthis comes down to the choice for a particular set of preferred\npriors. As further developed below, Carnapian inductive logic is thus\nrelated to objective Bayesian statistics. It is a moot point whether\nfurther constraints on the probability assignments can be considered\nas logical, as Carnap and followers have it, or whether the title of\nlogic is best reserved for the probability formalism in isolation, as\nDe Finetti and followers argue. \n4.3.5 Objective priors\nA further set of responses to the subjectivity of Bayesian\nstatistical inference targets the prior distribution directly: we\nmight provide further rationality principles, with which the choice of\npriors can be chosen objectively. The literature proposes several\nobjective criteria for filling in the prior over the model. Each of\nthese lays claim to being the correct expression of complete ignorance\nconcerning the value of the model parameters, or of minimal\ninformation regarding the parameters. Three such criteria are\ndiscussed here.\nIn the context of Bertrand's paradox we already discussed\nthe principle of indifference, according to which probability\nshould be distributed evenly over the available possibilities. A\nfurther development of this idea is presented by the requirement that\na distribution should have maximum entropy. Notably, the use of\nentropy maximization for determining degrees of beliefs finds much\nbroader application than only in statistics: similar ideas are taken\nup in diverse fields like epistemology (e.g., Shore and Johnson 1980,\nWilliams 1980, Uffink 1996, and also Williamson 2010), inductive logic\n(Paris and Vencovska 1989), statistical mechanics (Jaynes 2003)\nand decision theory (Seidenfeld 1986, Grunwald and Halpern 2004). In\nobjective Bayesian statistics, the idea is applied to the\nprior distribution over the model (cf. Berger 2006).  For a finite\nnumber of hypotheses the entropy of the distribution \\(P(h_{\\theta})\\)\nis defined as\n\n\\[ E[P] \\; = \\; \\sum_{\\theta \\in \\Theta} P(h_{\\theta}) \\log\nP(h_{\\theta}) . \\]\n\nThis requirement unequivocally leads to equiprobable\nhypotheses. However, for continuous models the maximum entropy\ndistribution depends crucially on the metric over the parameters in\nthe model. The burden of subjectivity is thereby moved to the\nparameterization, but of course it may well be that we have strong\nreasons for preferring a particular parameterization over others (cf.\nJaynes 1973).\nThere are other approaches to the objective determination of\npriors. In view of the above problems, a particularly attractive\nmethod for choosing a prior over a continuous model is proposed by\nJeffreys (1961). The general idea of so-called Jeffreys\npriors is that the prior probability assigned to a small patch in\nthe parameter space is proportional to, what may be called, the\ndensity of the distributions within that patch. Intuitively, if a lot\nof distributions, i.e., distributions that differ quite a lot among\nthemselves, are packed together on a small patch in the parameter\nspace, this patch should be given a larger prior probability than a\nsimilar patch within which there is little variation among the\ndistributions (cf. Balasubramanian 2005). More technically, such a\ndensity is expressed by a prior distribution that is proportional to\nthe Fisher information.  A key advantage of these priors is\nthat they are invariant under reparameterizations of the parameter\nspace: a new parameterization naturally leads to an adjusted density\nof distributions.\nA final method of defining priors goes under the name of\nreference priors (Berger et al 2009). The proposal\nstarts from the observation that we should minimize the subjectivity\nof the results of our statistical analysis, and hence that we should\nminimize the impact of the prior probability on the posterior. The\nidea of reference priors is exactly that it will allow the sample data\na maximal say in the posterior distribution. But since at the outset\nwe do not know what sample we will obtain, the prior is chosen so as\nto maximize the expected impact of the data. The expectation must\nitself be taken with respect to some distribution over sample space,\nbut again, it may well be that we have strong reasons for this latter\ndistribution.\n4.3.6 Circumventing priors\nA different response to the subjectivity of priors is to\nextend the Bayesian formalism, in order to leave the choice of prior\nto some extent open. The subjective choice of a prior is in that case\ncircumvented. Two such responses will be considered in some\ndetail.\nRecall that a prior probability distribution over statistical\nhypotheses expresses our uncertain opinion on which of the hypotheses\nis right. The central idea behind hierarchical Bayesian\nmodels (Gelman et al 2013) is that the same pattern of putting a\nprior over statistical hypotheses can be repeated on the level of\npriors itself. More precisely, we may be uncertain over which prior\nprobability distribution over the hypotheses is right. If we\ncharacterize possible priors by means of a set of parameters, we can\nexpress this uncertainty about prior choice in a probability\ndistribution over the parameters that characterize the shape of the\nprior. In other words, we move our uncertainty one level up in a\nhierarchy: we consider multiple priors over the statistical\nhypotheses, and compare the performance of these priors on the sample\ndata as if the priors were themselves hypotheses.\nThe idea of hierarchical Bayesian modeling (Gelman et al 2013)\nrelates naturally to the Bayesian comparison of Carnapian prediction\nrules (e.g., Skyrms 1993 and 1996, Festa 1996), and also to the\nestimation of optimum inductive methods (Kuipers 1986, Festa 1993).\nHierarchical Bayesian modeling can also be related to another\ntool for choosing a particular prior distribution over hypotheses,\nnamely the method of empirical Bayes, which estimates the\nprior that leads to the maximal marginal likelihood of the model. In\nthe philosophy of science, hierarchical Bayesian modeling has made a\nfirst appearance due to Henderson et al (2010).\nThere is also a response that avoids the choice of a prior\naltogether. This response starts with the same idea as hierarchical\nmodels: rather than considering a single prior over the hypotheses in\nthe model, we consider a parameterized set of them. But instead of\ndefining a distribution over this set, proponents of\ninterval-valued or imprecise probability claim that\nour epistemic state regarding the priors is better expressed by this\nset of distributions, and that sharp probability assignments must\ntherefore be replaced by lower and upper bounds to the\nassignments. Now the idea that uncertain opinion is best captured by a\nset of probability assignments, or a credal set for short,\nhas a long history and is backed by an extensive literature (e.g., De\nFinetti 1974, Levi 1980, Dempster 1967 and 1968, Shafer 1976, Walley\n1991). In light of the main debate in the philosophy of statistics,\nthe use of interval-valued priors indeed forms an attractive extension\nof Bayesian statistics: it allows us to refrain from choosing a\nspecific prior, and thereby presents a rapprochement to the classical\nview on statistics.\nThese theoretical developments may look attractive, but the fact is\nthat they mostly enjoy a cult status among philosophers of statistics\nand that they have not moved the statistician in the street. On the\nother hand, standard Bayesian statistics has seen a steep rise in\npopularity over the past decade or so, owing to the availability of\ngood software and numerical approximation methods. And most of the\npractical use of Bayesian statistics is more or less insensitive to\nthe potentially subjective aspects of the statistical results,\nemploying uniform priors as a neutral starting point for the analysis\nand relying on the afore-mentioned convergence results to wash out the\nremaining subjectivity (cf. Gelman and Shalizi 2013). However, this\npractical attitude of scientists towards modelling should not be\nmistaken for a principled answer to the questions raised in the\nphilosophy of statistics (see Morey et al 2013).\n5. Statistical models\nIn the foregoing we have seen how classical and Bayesian statistics\ndiffer. But the two major approaches to statistics also have a lot in\ncommon. Most importantly, all statistical procedures rely on the\nassumption of a statistical model, here referring to any\nrestricted set of statistical hypotheses.  Moreover, they are both\naimed at delivering a verdict over these hypotheses.  For example, a\nclassical likelihood ratio test considers two hypotheses, \\(h\\) and\n\\(h'\\), and then offers a verdict of rejection and acceptance, while a\nBayesian comparison delivers a posterior probability over these two\nhypotheses. Whereas in Bayesian statistics the model presents a very\nstrong assumption, classical statistics does not endow the model with\na special epistemic status: they are simply the hypotheses currently\nentertained by the scientist. But across the board, the adoption of a\nmodel is absolutely central to any statistical procedure.\nA natural question is whether anything can be said about the\nquality of the statistical model, and whether any verdict on this\nstarting point for statistical procedures can be given. Surely some\nmodels will lead to better predictions, or be a better guide to the\ntruth, than others. The evaluation of models touches on deep issues in\nthe philosophy of science, because the statistical model often\ndetermines how the data-generating system under investigation is\nconceptualized and approached (Kieseppa 2001). Model choice thus\nresembles the choice of a theory, a conceptual scheme, or even of a\nwhole paradigm, and thereby might seem to transcend the formal\nframeworks for studying theoretical rationality (cf. Carnap 1950,\nJeffrey 1980). Despite the fact that some considerations on model\nchoice will seem extra-statistical, in the sense that they fall\noutside the scope of statistical treatment, statistics offers several\nmethods for approaching the choice of statistical models.\n5.1 Model comparisons\nThere are in fact very many methods for evaluating statistical\nmodels (Claeskens and Hjort 2008, Wagenmakers and Waldorp 2006). In\nfirst instance, the methods occasion the comparison of statistical\nmodels, but very often they are used for selecting one model over the\nothers. In what follows we only review prominent techniques that have\nled to philosophical debate: Akaike's information criterion, the\nBayesian information criterion, and furthermore the computation of\nmarginal likelihoods and posterior model probabilities, both\nassociated with Bayesian model selection. We leave aside methods that\nuse cross-validation as they have, unduly, not received as much\nattention in the philosophical literature.\n5.1.1 Akaike's information criterion\nAkaike's information criterion, modestly termed An\nInformation Criterion or AIC for short, is based on the classical\nstatistical procedure of estimation (see Burnham and Anderson 2002,\nKieseppa 1997). It starts from the idea that a model \\(M\\) can be\njudged by the estimate \\(\\hat{\\theta}\\) that it delivers, and more\nspecifically by the proximity of this estimate to the distribution\nwith which the data are actually generated, i.e., the true\ndistribution. This proximity is often equated with the expected\npredictive accuracy of the estimate, because if the estimate and the\ntrue distribution are closer to each other, their predictions will be\nbetter aligned to one another as well. In the derivation of the AIC,\nthe so-called relative entropy or Kullback-Leibler divergence\nof the two distributions is used as a measure of their proximity, and\nhence as a measure of the expected predictive accuracy of the\nestimate.\nNaturally, the true distribution is not known to the statistician\nwho is evaluating the model. If it were, then the whole statistical\nanalysis would be useless. However, it turns out that we can give an\nunbiased estimation of the divergence between the true distribution\nand the distribution estimated from a particular model,\n\n \\[ \\text{AIC}[M] = - 2 \\log P( s \\mid h_{\\hat{\\theta}(s)} ) + 2 d , \\]\n\nin which \\(s\\) is the sample data, \\(\\hat{\\theta}(s)\\) is the maximum\nlikelihood estimate (MLE) of the model \\(M\\), and \\(d = dim(\\Theta)\\)\nis the number of dimensions of the parameter space of the model. The\nMLE of the model thereby features in an expression of the model\nquality, i.e., in a role that is conceptually distinct from the\nestimator function.\nAs can be seen from the expression above, a model with a smaller\nAIC is preferable: we want the fit to be optimal at little cost in\ncomplexity. Notice that the number of dimensions, or independent\nparameters, in the model increases the AIC and thereby lowers the\neligibility of the model: if two models achieve the same maximum\nlikelihood for the sample, then the model with fewer parameters will\nbe preferred. For this reason, statistical model selection by the AIC\ncan be seen as an independent motivation for preferring simple models\nover more complex ones (Sober and Forster 1994). But this result also\ninvites some critical remarks. For one, we might impose other criteria\nthan merely the unbiasedness on the estimation of the proximity to the\ntruth, and this will lead to different expressions for the\napproximation. Moreover, it is not always clearcut what the\ndimensions of the model under scrutiny really are. For curve fitting\nthis may seem simple, but for more complicated models or different\nconceptualizations of the space of models, things do not look so easy\n(cf. Myung et al 2001, Kieseppa 2001). \nA prime example of model selection is presented in curve\nfitting.  Given a sample \\(s\\) consisting of a set of points in\nthe plane \\((x, y)\\), we are asked to choose the curve that fits these\ndata best. We assume that the models under consideration are of the\nform \\(y = f(x) + \\epsilon\\), where \\(\\epsilon\\) is a normal\ndistribution with mean 0 and a fixed standard deviation, and where\n\\(f\\) is a polynomial function. Different models are characterized by\npolynomials of different degrees that have different numbers of\nparameters. Estimations fix the parameters of these polynomials. For\nexample, for the 0-degree polynomial \\(f(x) = c_{0}\\) we estimate the\nconstant \\(\\hat{c_{0}}\\) for which the probability of the data is\nmaximal, and for the 1-degree polynomial \\(f(x) = c_{0} + c_{1}\\, x\\)\nwe estimate the slope \\(\\hat{c_{1}}\\) and the offset\n\\(\\hat{c_{0}}\\). Now notice that for a total of \\(n\\) points, we can\nalways find a polynomial of degree \\(n\\) that intersects with all\npoints exactly, resulting in a comparatively high maximum likelihood\n\\(P(s \\mid \\{\\hat{c_{0}}, \\ldots \\hat{c_{n}} \\})\\). Applying the AIC,\nhowever, we will typically find that some model with a polynomial of\ndegree \\(k < n\\) is preferable. Although \\(P(s \\mid \\{\\hat{c_{0}},\n\\ldots \\hat{c_{k}} \\})\\) will be somewhat lower, this is compensated\nfor in the AIC by the smaller number of parameters.\n5.1.2 Bayesian evaluation of models\nVarious other prominent model selection tools are based on methods\nfrom Bayesian statistics. They all start from the idea that the\nquality of a model is expressed in the performance of the model on the\nsample data: the model that, on the whole, makes the sampled data most\nprobable is to be preferred.  Because of this, there is a close\nconnection with the hierarchical Bayesian modelling referred to\nearlier (Gelman 2013). The central notion in the Bayesian model\nselection tools is thus the marginal likelihood of the model, i.e.,\nthe weighted average of the likelihoods over the model, using the\nprior distribution as a weighing function:\n\n\\[ P(s \\mid M_{i}) \\; = \\; \\int_{\\theta \\in \\Theta_{i}} P(h_{\\theta}) P(s\n\\mid h_{\\theta}) d\\theta . \\]\n\nHere \\(\\Theta_{i}\\) is the parameter space belonging to model\n\\(M_{i}\\).  The marginal likelihoods can be combined with a prior\nprobability over models, \\(P(M_{i})\\), to derive the\nso-called posterior model probability, using Bayes'\ntheorem. One way of evaluating models, known as Bayesian model\nselection, is by comparing the models on their marginal\nlikelihood, or else on their posteriors (cf. Kass and Raftery\n1995).\nUsually the marginal likelihood cannot be computed analytically.\nNumerical approximations can often be obtained, but for practical\npurposes it has proved very useful, and quite sufficient, to employ an\napproximation of the marginal likelihood. This approximation has\nbecome known as the Bayesian information criterion, or BIC\nfor short (Schwarz 1978, Raftery 1995). It turns out that this\napproximation shows remarkable similarities to the AIC:\n\n\\[ \\text{BIC}[M] \\; = \\; - 2 \\log P(s \\mid h_{\\hat{\\theta}(s)}) + d \\log\nn . \\]\n\nHere \\(\\hat{\\theta}(s)\\) is again the maximum likelihood estimate of\nthe model, \\(d = dim(M)\\) the number of independent parameters, and\n\\(n\\) is the number of data points in the sample. The latter\ndependence is the only difference with the AIC, but a major difference\nin how the model evaluation may turn out.\nThe concurrence of the AIC and the BIC seems to give a further\nmotivation for our intuitive preference for simple models over more\ncomplex ones. Indeed, other model selection tools, like the\ndeviance information criterion (Spiegelhalter et al 2002) and\nthe approach based on minimum description length (Grunwald\n2007), also result in expressions that feature a term that penalizes\ncomplex models. However, this is not to say that the dimension term\nthat we know from the information criteria exhausts the notion of\nmodel complexity. There is ongoing debate in the philosophy of science\nconcerning the merits of model selection in explications of the notion\nof simplicity, informativeness, and the like (see, for example, Sober\n2004, Romeijn and van de Schoot 2008, Romeijn et al 2012, Sprenger\n2013).\n5.2 Statistics without models\nThere are also statistical methods that refrain from the use of a\nparticular model, by focusing exclusively on the data or by\ngeneralizing over all possible models.  Some of these techniques are\nproperly localized in descriptive statistics: they do not concern an\ninference from data but merely serve to describe the data in a\nparticular way. Statistical methods that do not rely on an explicit\nmodel choice have unfortunately not attracted much attention in the\nphilosophy of statistics, but for completeness sake they will be\nbriefly discussed here.\n5.2.1 Data reduction techniques\nOne set of methods, and a quite important one for many practicing\nstatisticians, is aimed at data reduction. Often the sample\ndata are very rich, e.g., consisting of a set of points in a space of\nvery many dimensions. The first step in a statistical analysis may\nthen be to pick out the salient variability in the data, in order to\nscale down the computational burden of the analysis itself.\nThe technique of principal component analysis (PCA) is\ndesigned for this purpose (Jolliffe 2002). Given a set of points in a\nspace, it seeks out the set of vectors along which the variation in\nthe points is large. As an example, consider two points in a plane\nparameterized as \\((x, y)\\): the points \\((0, 0)\\) and \\((1, 1)\\). In\nthe \\(x\\)-direction and in the \\(y\\)-direction the variation is \\(1\\),\nbut over the diagonal the variation is maximal, namely\n\\(\\sqrt{2}\\). The vector on the diagonal is called the principal\ncomponent of the data. In richer data structures, and using a more\ngeneral measure of variation among points, we can find the first\ncomponent in a similar way. Moreover, we can repeat the procedure\nafter subtracting the variation along the last found component, by\nprojecting the data onto the plane perpendicular to that\ncomponent. This allows us to build up a set of principal components of\ndiminishing importance.\nPCA is only one item from a large collection of techniques that are\naimed at keeping the data manageable and finding patterns in it, a\ncollection that also includes kernel methods and support\nvector machines (e.g., Vapnik and Kotz 2006). For present\npurposes, it is important to stress that such tools should not be\nconfused with statistical analysis: they do not involve the testing or\nevaluation of distributions over sample space, even though they build\nup and evaluate models of the data. This sets them apart from, e.g.,\nconfirmatory and exploratory factor analysis (Bartholomew 2008), which\nis sometimes taken to be a close relative of PCA because both\nsets of techniques allows us to identify salient dimensions within\nsample space, along which the data show large variation. \nPracticing statisticians often employ data reduction tools to\narrive at conclusions on the distributions from which the data were\nsampled. There is already a wide use for machine learning and data\nmining techniques in the sciences, and we may expect even mode usage\nof these techniques in the future, because so much data is now coming\navailable for scientific analysis. However, in the philosophy of\nstatistics there is as yet little debate over the epistemic status of\nconclusions reached by means of these techniques. Philosophers of\nstatistics would do well to direct some attention here.\n5.2.2 Formal learning theory\nAn entirely different approach to statistics is presented by\n formal learning theory.\nThis is again a vast area of research, primarily located in\ncomputer science and artificial intelligence. The discipline is here\nmentioned briefly, as another example of an approach to statistics\nthat avoids the choice of a statistical model altogether and merely\nidentifies patterns in the data. We leave aside the theory of\nneural networks, which also concerns predictive systems that\ndo not rely on a statistical model, and focus on the theory of\nlearning algorithms because of all these approaches they have seen\nmost philosophical attention.\nPioneering work on formal learning was done by Solomonoff\n(1964). As before, the setting is one in which the data consist of\nstrings of 0's and 1's, and in which an agent is attempting to\nidentify the pattern in these data. So, for example, the data may be a\nstring of the form \\(0101010101\\ldots\\), and the challenge is to\nidentify this strings as an alternating sequence. The central idea of\nSolomonoff is that all possible computable patterns must be considered\nby the agent, and therefore that no restrictive choice on statistical\nhypotheses is warranted. Solomonoff then defined a formal system in\nwhich indeed all patterns can be taken into consideration, effectively\nusing a Bayesian analysis with a cleverly constructed prior over all\ncomputable hypotheses.\nThis general idea can also be identified in a rather new field on\nthe intersection of Bayesian statistics and machine learning,\nBayesian nonparametrics (e.g., Orbanz and Teh\n2010, Hjort et al 2010). Rather than specifying, at the outset, a\nconfined set of distributions from which a statistical analysis is\nsupposed to choose on the basis of the data, the idea is that the data\nare confronted with a potentially infinite-dimensional space of\npossible distributions. The set of distributions taken into\nconsideration is then made relative to the data obtained: the\ncomplexity of the model grows with the sample. The result is a\npredictive system that performs an online model selection alongside a\nBayesian accommodation of the posterior over the model.\nCurrent formal learning theory is a lively field, to which\nphilosophers of statistics also contribute (e.g., Kelly 1996, Kelly et\nal 1997). Particularly salient for the present concerns is that the\nsystems of formal learning are set up to achieve some notion of\nadequate universal prediction, without confining themselves\nto a specific set of hypotheses, and hence by imposing minimal\nconstraints on the set of possible patterns in the data. It is a\nmatter of debate whether this is at all possible, and to what extent\nthe predictions of formal learning theory thereby rely on, e.g.,\nimplicit assumptions on structure of the sample space. Philosophical\nreflection on this is only in its infancy.\n6. Related topics\n\nThere are numerous topics in the philosophy of science that bear\ndirect relevance to the themes covered in this lemma. A few central\ntopics are mentioned here to direct the reader to related lemmas in\nthe encyclopedia. \nOne very important topic that is immediately adjacent to the\nphilosophy of statistics is \n confirmation theory, \nthe philosophical theory that describes and justifies\nrelations between scientific theory and empirical\nevidence. Arguably, the theory of statistics is a proper part of\nconfirmation theory, as it describes and justifies the relation that\nobtains between statistical theory and evidence in the form of\nsamples. It can be insightful to place statistical procedures in this\nwider framework of relations between evidence and theory. Zooming out\neven further, the philosophy of statistics is part of the\nphilosophical topic of methodology, i.e., the general theory on\nwhether and how science acquires knowledge. Thus conceived, statistics\nis one component in a large collection of scientific methods\ncomprising concept formation, experimental design, manipulation and\nobservation, confirmation, revision, and theorizing.\nThere are also a fair number of specific topics from the philosophy\nof science that are spelled out in terms of statistics or that are\nlocated in close proximity to it. One of these topics is the process\nof measurement, in particular the measurement of latent variables on\nthe basis of statistical facts about manifest variables.  The\nso-called representational theory of measurement (Kranz et al\n1971) relies on statistics, in particular on factor analysis, to\nprovide a conceptual clarification of how mathematical structures\nrepresent empirical phenomena. Another important topic form the\nphilosophy of science is causation (see the entries on\n probabilistic causation\nand\n Reichenbach's common cause principle). \nPhilosophers have employed probability theory to capture causal\nrelations ever since Reichenbach (1956), but more recent work in\ncausality and statistics (e.g., Spirtes et al 2001) has given the\ntheory of probabilistic causality an enormous impulse. Here\nagain, statistics provides a basis for the conceptual analysis of\ncausal relations.\nAnd there is so much more.  Several specific statistical\ntechniques, like factor analysis and the theory of Bayesian networks,\ninvite conceptual discussion of their own accord. Numerous topics\nwithin the philosophy of science lend themselves to statistical\nelucidation, e.g., the coherence, informativeness, and surprise of\nevidence. And in turn there is a wide range of discussions in the\nphilosophy of science that inform a proper understanding of\nstatistics. Among them are debates over experimentation and\nintervention, concepts of chance, the nature of scientific models, and\ntheoretical terms. The reader is invited to consult the entries on\nthese topics to find further indications of how they relate to the\nphilosophy of statistics.",
    "section_title": "4.3 Responses to criticism",
    "entry_title": "Philosophy of Statistics",
    "hierarchy_title": "Philosophy of Statistics || Bayesian statistics || Responses to criticism",
    "tokenized_text": [
        "bayesian",
        "statistic",
        "response",
        "criticism",
        "response",
        "criticism",
        "philosophy",
        "bayesian",
        "statistic",
        "offer",
        "wide",
        "range",
        "response",
        "problem",
        "outlined",
        "bayesians",
        "bite",
        "bullet",
        "defend",
        "essentially",
        "subjective",
        "character",
        "bayesian",
        "method",
        "others",
        "attempt",
        "remedy",
        "compensate",
        "subjectivity",
        "providing",
        "objectively",
        "motivated",
        "mean",
        "determining",
        "prior",
        "probability",
        "emphasizing",
        "objective",
        "character",
        "bayesian",
        "formalism",
        "strict",
        "empirically",
        "informed",
        "subjectivism",
        "one",
        "influential",
        "view",
        "bayesian",
        "statistic",
        "buy",
        "subjectivity",
        "analysis",
        "eg",
        "goldstein",
        "kadane",
        "socalled",
        "personalists",
        "strict",
        "subjectivist",
        "argue",
        "right",
        "statistical",
        "method",
        "provide",
        "objective",
        "guideline",
        "pointing",
        "radically",
        "subjective",
        "source",
        "form",
        "knowledge",
        "problem",
        "interpretation",
        "choice",
        "prior",
        "distribution",
        "thus",
        "dissolved",
        "least",
        "part",
        "bayesian",
        "statistician",
        "may",
        "choose",
        "prior",
        "expression",
        "belief",
        "however",
        "deserves",
        "emphasis",
        "subjectivist",
        "view",
        "bayesian",
        "statistic",
        "mean",
        "constraint",
        "deriving",
        "empirical",
        "fact",
        "disregarded",
        "nobody",
        "denies",
        "knowledge",
        "imposes",
        "constraint",
        "model",
        "prior",
        "constraint",
        "must",
        "accommodated",
        "example",
        "today",
        "s",
        "posterior",
        "probability",
        "may",
        "used",
        "tomorrow",
        "s",
        "prior",
        "next",
        "statistical",
        "inference",
        "point",
        "constraint",
        "concern",
        "rationality",
        "belief",
        "consistency",
        "statistical",
        "inference",
        "per",
        "se",
        "subjectivist",
        "view",
        "prominent",
        "among",
        "interpret",
        "probability",
        "assignment",
        "pragmatic",
        "fashion",
        "motivate",
        "representation",
        "belief",
        "probability",
        "assignment",
        "aforementioned",
        "dutch",
        "book",
        "argument",
        "central",
        "approach",
        "work",
        "savage",
        "de",
        "finetti",
        "savage",
        "proposed",
        "axiomatize",
        "statistic",
        "tandem",
        "decision",
        "theory",
        "mathematical",
        "theory",
        "practical",
        "rationality",
        "argued",
        "probability",
        "assignment",
        "mean",
        "anything",
        "interpreted",
        "context",
        "agent",
        "face",
        "choice",
        "action",
        "ie",
        "choice",
        "among",
        "set",
        "bet",
        "similar",
        "vein",
        "de",
        "finetti",
        "eg",
        "advocated",
        "view",
        "statistic",
        "empirical",
        "consequence",
        "probabilistic",
        "belief",
        "expressed",
        "willingness",
        "bet",
        "mattered",
        "make",
        "statistical",
        "inference",
        "fully",
        "dependent",
        "decision",
        "theory",
        "remarkably",
        "thus",
        "appears",
        "subjectivist",
        "view",
        "bayesian",
        "statistic",
        "based",
        "behaviorism",
        "empiricism",
        "motivated",
        "neyman",
        "pearson",
        "develop",
        "classical",
        "statistic",
        "notice",
        "make",
        "one",
        "aspect",
        "interpretation",
        "problem",
        "section",
        "reappear",
        "prior",
        "distribution",
        "hypothesis",
        "make",
        "apparent",
        "behavior",
        "rightfully",
        "interpreted",
        "term",
        "belief",
        "understood",
        "willingness",
        "act",
        "one",
        "response",
        "question",
        "turn",
        "different",
        "motivation",
        "representing",
        "degree",
        "belief",
        "mean",
        "probability",
        "assignment",
        "following",
        "work",
        "de",
        "finetti",
        "several",
        "author",
        "proposed",
        "vindication",
        "probabilistic",
        "expression",
        "belief",
        "based",
        "behavioral",
        "goal",
        "rather",
        "epistemic",
        "goal",
        "holding",
        "belief",
        "accurately",
        "represent",
        "world",
        "eg",
        "rosenkrantz",
        "joyce",
        "leitgeb",
        "pettigrew",
        "easwaran",
        "strong",
        "generalization",
        "idea",
        "achieved",
        "schervish",
        "seidenfeld",
        "kadane",
        "build",
        "longer",
        "tradition",
        "using",
        "scoring",
        "rule",
        "achieving",
        "statistical",
        "aim",
        "alternative",
        "approach",
        "formal",
        "representation",
        "belief",
        "must",
        "respect",
        "certain",
        "logical",
        "constraint",
        "eg",
        "cox",
        "provides",
        "argument",
        "expression",
        "belief",
        "term",
        "probability",
        "assignment",
        "basis",
        "nature",
        "partial",
        "belief",
        "per",
        "se",
        "however",
        "original",
        "subjectivist",
        "response",
        "issue",
        "prior",
        "hypothesis",
        "hard",
        "interpret",
        "came",
        "de",
        "finetti",
        "s",
        "socalled",
        "representation",
        "theorem",
        "show",
        "every",
        "prior",
        "distribution",
        "associated",
        "set",
        "prediction",
        "hence",
        "behavioral",
        "consequence",
        "word",
        "de",
        "finetti",
        "showed",
        "prior",
        "indeed",
        "associated",
        "belief",
        "carry",
        "betting",
        "interpretation",
        "excursion",
        "representation",
        "theorem",
        "de",
        "finetti",
        "s",
        "representation",
        "theorem",
        "relates",
        "rule",
        "prediction",
        "function",
        "given",
        "sample",
        "data",
        "bayesian",
        "statistical",
        "analysis",
        "data",
        "background",
        "statistical",
        "model",
        "see",
        "festa",
        "suppes",
        "useful",
        "introduction",
        "de",
        "finetti",
        "considers",
        "process",
        "generates",
        "series",
        "timeindexed",
        "observation",
        "study",
        "prediction",
        "rule",
        "take",
        "finite",
        "segment",
        "input",
        "return",
        "probability",
        "future",
        "event",
        "using",
        "statistical",
        "model",
        "analyze",
        "sample",
        "provide",
        "prediction",
        "key",
        "result",
        "de",
        "finetti",
        "particular",
        "statistical",
        "model",
        "namely",
        "set",
        "distribution",
        "observation",
        "independently",
        "identically",
        "distributed",
        "equated",
        "class",
        "exchangeable",
        "prediction",
        "rule",
        "namely",
        "rule",
        "whose",
        "prediction",
        "depend",
        "order",
        "observation",
        "come",
        "let",
        "u",
        "consider",
        "representation",
        "theorem",
        "formal",
        "detail",
        "simplicity",
        "say",
        "process",
        "generates",
        "timeindexed",
        "binary",
        "observation",
        "ie",
        "s",
        "s",
        "prediction",
        "rule",
        "take",
        "bit",
        "string",
        "length",
        "t",
        "denoted",
        "s_",
        "input",
        "return",
        "probability",
        "event",
        "next",
        "bit",
        "string",
        "denoted",
        "q",
        "_",
        "t",
        "write",
        "prediction",
        "rule",
        "partial",
        "probability",
        "assignment",
        "p",
        "q",
        "_",
        "t",
        "mid",
        "s_",
        "exchangeable",
        "prediction",
        "rule",
        "rule",
        "deliver",
        "prediction",
        "independently",
        "order",
        "bit",
        "string",
        "s_",
        "write",
        "event",
        "string",
        "s_",
        "total",
        "n",
        "observation",
        "s",
        "s_",
        "nt",
        "exchangeable",
        "prediction",
        "rule",
        "written",
        "p",
        "q",
        "_",
        "t",
        "mid",
        "s_",
        "nt",
        "crucial",
        "property",
        "value",
        "prediction",
        "affected",
        "order",
        "s",
        "s",
        "show",
        "string",
        "s_",
        "de",
        "finetti",
        "relates",
        "particular",
        "set",
        "exchangeable",
        "prediction",
        "rule",
        "bayesian",
        "inference",
        "specific",
        "type",
        "statistical",
        "model",
        "model",
        "de",
        "finetti",
        "considers",
        "comprises",
        "socalled",
        "bernoulli",
        "hypothesis",
        "h_",
        "theta",
        "ie",
        "hypothesis",
        "p",
        "q",
        "_",
        "t",
        "mid",
        "h_",
        "theta",
        "cap",
        "s_",
        "theta",
        "likelihood",
        "depend",
        "string",
        "s_",
        "gone",
        "hypothesis",
        "best",
        "thought",
        "determining",
        "fixed",
        "bias",
        "theta",
        "binary",
        "process",
        "theta",
        "in",
        "theta",
        "representation",
        "theoremstates",
        "onetoone",
        "mapping",
        "prior",
        "bernoulli",
        "hypothesis",
        "exchangeable",
        "prediction",
        "rule",
        "every",
        "prior",
        "distribution",
        "p",
        "h_",
        "theta",
        "associated",
        "exactly",
        "one",
        "exchangeable",
        "prediction",
        "rule",
        "p",
        "q",
        "_",
        "t",
        "mid",
        "s_",
        "nt",
        "conversely",
        "next",
        "original",
        "representation",
        "theorem",
        "derived",
        "de",
        "finetti",
        "several",
        "general",
        "representation",
        "theorem",
        "proved",
        "eg",
        "partially",
        "exchangeable",
        "sequence",
        "hypothesis",
        "markov",
        "process",
        "diaconis",
        "freedman",
        "skyrms",
        "clustering",
        "prediction",
        "partitioning",
        "process",
        "kingman",
        "even",
        "sequence",
        "graph",
        "generating",
        "process",
        "aldous",
        "representation",
        "theorem",
        "equate",
        "prior",
        "distribution",
        "statistical",
        "hypothesis",
        "prediction",
        "rule",
        "thus",
        "probability",
        "assignment",
        "given",
        "subjective",
        "behavioral",
        "interpretation",
        "remove",
        "worry",
        "expressed",
        "prior",
        "distribution",
        "hypothesis",
        "interpreted",
        "subjectively",
        "related",
        "belief",
        "willingness",
        "act",
        "prior",
        "relate",
        "uniquely",
        "particular",
        "prediction",
        "however",
        "de",
        "finetti",
        "representation",
        "theorem",
        "provided",
        "reason",
        "away",
        "statistical",
        "hypothesis",
        "altogether",
        "hence",
        "removal",
        "notion",
        "probability",
        "anything",
        "subjective",
        "opinion",
        "cf",
        "hintikka",
        "hypothesis",
        "whose",
        "probabilistic",
        "claim",
        "could",
        "taken",
        "refer",
        "intangible",
        "chancy",
        "process",
        "superfluous",
        "metaphysical",
        "baggage",
        "subjectivist",
        "equally",
        "dismissive",
        "use",
        "statistical",
        "hypothesis",
        "jeffrey",
        "proposed",
        "socalled",
        "mixed",
        "bayesianism",
        "subjectively",
        "interpreted",
        "distribution",
        "hypothesis",
        "combined",
        "physical",
        "interpretation",
        "distribution",
        "hypothesis",
        "define",
        "sample",
        "space",
        "romeijn",
        "argues",
        "prior",
        "hypothesis",
        "efficient",
        "intuitive",
        "way",
        "determining",
        "inductive",
        "prediction",
        "specifying",
        "property",
        "predictive",
        "system",
        "directly",
        "advantage",
        "using",
        "hypothesis",
        "seems",
        "agreement",
        "practice",
        "science",
        "hypothesis",
        "routinely",
        "used",
        "often",
        "motivated",
        "mechanistic",
        "knowledge",
        "data",
        "generating",
        "process",
        "fact",
        "statistical",
        "hypothesis",
        "strictly",
        "speaking",
        "eliminated",
        "take",
        "away",
        "utility",
        "making",
        "prediction",
        "bayesian",
        "statistic",
        "logic",
        "despite",
        "itsseemingly",
        "inevitablesubjective",
        "character",
        "sense",
        "bayesian",
        "statistic",
        "might",
        "lay",
        "claim",
        "objectivity",
        "shown",
        "bayesian",
        "formalism",
        "meet",
        "certain",
        "objective",
        "criterion",
        "rationality",
        "coherence",
        "calibration",
        "bayesian",
        "statistic",
        "thus",
        "answer",
        "requirement",
        "objectivity",
        "metalevel",
        "opinion",
        "deal",
        "retain",
        "subjective",
        "aspect",
        "way",
        "deal",
        "opinion",
        "particular",
        "way",
        "data",
        "impact",
        "objectively",
        "correct",
        "argued",
        "argument",
        "supporting",
        "bayesian",
        "way",
        "accommodating",
        "data",
        "namely",
        "conditionalization",
        "provided",
        "pragmatic",
        "context",
        "dynamic",
        "dutch",
        "book",
        "argument",
        "whereby",
        "probability",
        "interpreted",
        "willingness",
        "bet",
        "cf",
        "maher",
        "van",
        "fraassen",
        "similar",
        "argument",
        "advanced",
        "ground",
        "belief",
        "must",
        "accurately",
        "represent",
        "world",
        "along",
        "line",
        "de",
        "finetti",
        "eg",
        "greave",
        "wallace",
        "leitgeb",
        "pettigrew",
        "important",
        "distinction",
        "must",
        "made",
        "argument",
        "support",
        "bayesian",
        "way",
        "accommodating",
        "evidence",
        "distinction",
        "bayes",
        "theorem",
        "mathematical",
        "given",
        "bayes",
        "rule",
        "principle",
        "coherence",
        "time",
        "theorem",
        "simply",
        "mathematical",
        "relation",
        "among",
        "probability",
        "assignment",
        "p",
        "h",
        "mid",
        "p",
        "h",
        "frac",
        "p",
        "mid",
        "h",
        "p",
        "subject",
        "debate",
        "argument",
        "support",
        "representation",
        "epistemic",
        "state",
        "agent",
        "mean",
        "probability",
        "assignment",
        "also",
        "provide",
        "support",
        "bayes",
        "theorem",
        "constraint",
        "degree",
        "belief",
        "conditional",
        "probability",
        "p",
        "h",
        "mid",
        "interpreted",
        "degree",
        "belief",
        "attached",
        "hypothesis",
        "h",
        "condition",
        "sample",
        "s",
        "obtained",
        "integral",
        "part",
        "epistemic",
        "state",
        "captured",
        "probability",
        "assignment",
        "bayes",
        "rule",
        "contrast",
        "present",
        "constraint",
        "probability",
        "assignment",
        "represent",
        "epistemic",
        "state",
        "agent",
        "different",
        "point",
        "time",
        "written",
        "p_",
        "h",
        "p",
        "h",
        "mid",
        "determines",
        "new",
        "probability",
        "assignment",
        "expressing",
        "epistemic",
        "state",
        "agent",
        "sample",
        "obtained",
        "systematically",
        "related",
        "old",
        "assignment",
        "representing",
        "epistemic",
        "state",
        "sample",
        "came",
        "philosophy",
        "statistic",
        "many",
        "bayesians",
        "adopt",
        "bayes",
        "rule",
        "implicitly",
        "follows",
        "assume",
        "bayesian",
        "statistical",
        "inference",
        "rely",
        "bayes",
        "theorem",
        "whether",
        "focus",
        "lie",
        "bayes",
        "rule",
        "bayes",
        "theorem",
        "common",
        "theme",
        "abovementioned",
        "argument",
        "approach",
        "bayesian",
        "statistical",
        "inference",
        "logical",
        "angle",
        "focus",
        "internal",
        "coherence",
        "consistency",
        "cf",
        "howson",
        "use",
        "statistic",
        "undeniably",
        "inductive",
        "bayesian",
        "inference",
        "thereby",
        "obtains",
        "deductive",
        "least",
        "nonampliative",
        "character",
        "everything",
        "concluded",
        "inference",
        "somehow",
        "already",
        "present",
        "premise",
        "bayesian",
        "statistical",
        "inference",
        "premise",
        "given",
        "prior",
        "hypothesis",
        "p",
        "h_",
        "theta",
        "theta",
        "in",
        "theta",
        "likelihood",
        "function",
        "p",
        "mid",
        "h_",
        "theta",
        "determined",
        "hypothesis",
        "h_",
        "theta",
        "separately",
        "premise",
        "fix",
        "single",
        "probability",
        "assignment",
        "space",
        "times",
        "s",
        "outset",
        "inference",
        "conclusion",
        "turn",
        "straightforward",
        "consequence",
        "probability",
        "assignment",
        "derived",
        "applying",
        "theorem",
        "probability",
        "theory",
        "notably",
        "bayes",
        "theorem",
        "bayesian",
        "statistical",
        "inference",
        "thus",
        "becomes",
        "instance",
        "probabilistic",
        "logic",
        "cf",
        "hailperin",
        "halpern",
        "haenni",
        "et",
        "al",
        "summing",
        "several",
        "argument",
        "showing",
        "statistical",
        "inference",
        "bayes",
        "theorem",
        "bayes",
        "rule",
        "objectively",
        "correct",
        "argument",
        "invite",
        "u",
        "consider",
        "bayesian",
        "statistic",
        "instance",
        "probabilistic",
        "logic",
        "appeal",
        "logicality",
        "bayesian",
        "statistical",
        "inference",
        "may",
        "provide",
        "partial",
        "remedy",
        "subjective",
        "character",
        "moreover",
        "logical",
        "approach",
        "statistical",
        "inference",
        "avoids",
        "problem",
        "formalism",
        "place",
        "unrealistic",
        "demand",
        "agent",
        "presumes",
        "agent",
        "certain",
        "knowledge",
        "much",
        "like",
        "deductive",
        "logic",
        "need",
        "assume",
        "inference",
        "psychologically",
        "realistic",
        "agent",
        "actually",
        "believe",
        "premise",
        "argument",
        "rather",
        "argument",
        "present",
        "agent",
        "normative",
        "ideal",
        "take",
        "conditional",
        "form",
        "consistency",
        "constraint",
        "accept",
        "premise",
        "conclusion",
        "excursion",
        "inductive",
        "logic",
        "statistic",
        "important",
        "instance",
        "probabilistic",
        "logic",
        "presented",
        "inductive",
        "logic",
        "devised",
        "carnap",
        "hintikka",
        "others",
        "carnap",
        "hintikka",
        "suppes",
        "carnap",
        "jeffrey",
        "hintikka",
        "niiniluoto",
        "kuiper",
        "paris",
        "nix",
        "paris",
        "paris",
        "waterhouse",
        "historically",
        "carnapian",
        "inductive",
        "logic",
        "developed",
        "prior",
        "probabilistic",
        "logic",
        "referenced",
        "le",
        "separately",
        "debate",
        "philosophy",
        "statistic",
        "logical",
        "system",
        "carnap",
        "quite",
        "easily",
        "placed",
        "context",
        "logical",
        "approach",
        "bayesian",
        "inference",
        "fact",
        "quite",
        "insightful",
        "simplicity",
        "choose",
        "setting",
        "similar",
        "one",
        "used",
        "exposition",
        "representation",
        "theorem",
        "namely",
        "binary",
        "data",
        "generating",
        "process",
        "ie",
        "string",
        "s",
        "s",
        "prediction",
        "rule",
        "determines",
        "probability",
        "event",
        "denoted",
        "q",
        "_",
        "t",
        "next",
        "bit",
        "string",
        "basis",
        "given",
        "string",
        "bit",
        "length",
        "t",
        "denoted",
        "s_",
        "carnap",
        "follower",
        "designed",
        "specific",
        "exchangeable",
        "prediction",
        "rule",
        "mostly",
        "variant",
        "straight",
        "rule",
        "reichenbach",
        "p",
        "q",
        "_",
        "t",
        "mid",
        "s_",
        "nt",
        "frac",
        "n",
        "s_",
        "nt",
        "denotes",
        "string",
        "length",
        "t",
        "n",
        "entry",
        "s",
        "carnap",
        "derived",
        "rule",
        "constraint",
        "probability",
        "assignment",
        "sample",
        "constraint",
        "boil",
        "axiom",
        "probability",
        "constraint",
        "exchangeability",
        "among",
        "independently",
        "motivated",
        "appeal",
        "socalled",
        "logical",
        "interpretation",
        "probability",
        "logical",
        "interpretation",
        "probability",
        "assignment",
        "must",
        "respect",
        "certain",
        "invariance",
        "transformation",
        "sample",
        "space",
        "analogy",
        "logical",
        "principle",
        "constrain",
        "truth",
        "valuation",
        "language",
        "particular",
        "way",
        "carnapian",
        "inductive",
        "logic",
        "instance",
        "probabilistic",
        "logic",
        "sequential",
        "prediction",
        "based",
        "single",
        "probability",
        "assignment",
        "outset",
        "relies",
        "bayes",
        "theorem",
        "adapt",
        "prediction",
        "sample",
        "data",
        "cf",
        "romeijn",
        "one",
        "important",
        "difference",
        "bayesian",
        "statistical",
        "inference",
        "carnap",
        "probability",
        "assignment",
        "specified",
        "outset",
        "range",
        "sample",
        "hypothesis",
        "however",
        "de",
        "finetti",
        "s",
        "representation",
        "theorem",
        "carnap",
        "s",
        "exchangeable",
        "rule",
        "equated",
        "particular",
        "bayesian",
        "statistical",
        "inference",
        "difference",
        "carnapian",
        "inductive",
        "logic",
        "give",
        "preferred",
        "status",
        "particular",
        "exchangeable",
        "rule",
        "view",
        "de",
        "finetti",
        "s",
        "representation",
        "theorem",
        "come",
        "choice",
        "particular",
        "set",
        "preferred",
        "prior",
        "developed",
        "carnapian",
        "inductive",
        "logic",
        "thus",
        "related",
        "objective",
        "bayesian",
        "statistic",
        "moot",
        "point",
        "whether",
        "constraint",
        "probability",
        "assignment",
        "considered",
        "logical",
        "carnap",
        "follower",
        "whether",
        "title",
        "logic",
        "best",
        "reserved",
        "probability",
        "formalism",
        "isolation",
        "de",
        "finetti",
        "follower",
        "argue",
        "objective",
        "prior",
        "set",
        "response",
        "subjectivity",
        "bayesian",
        "statistical",
        "inference",
        "target",
        "prior",
        "distribution",
        "directly",
        "might",
        "provide",
        "rationality",
        "principle",
        "choice",
        "prior",
        "chosen",
        "objectively",
        "literature",
        "proposes",
        "several",
        "objective",
        "criterion",
        "filling",
        "prior",
        "model",
        "lay",
        "claim",
        "correct",
        "expression",
        "complete",
        "ignorance",
        "concerning",
        "value",
        "model",
        "parameter",
        "minimal",
        "information",
        "regarding",
        "parameter",
        "three",
        "criterion",
        "discussed",
        "context",
        "bertrand",
        "s",
        "paradox",
        "already",
        "discussed",
        "principle",
        "indifference",
        "according",
        "probability",
        "distributed",
        "evenly",
        "available",
        "possibility",
        "development",
        "idea",
        "presented",
        "requirement",
        "distribution",
        "maximum",
        "entropy",
        "notably",
        "use",
        "entropy",
        "maximization",
        "determining",
        "degree",
        "belief",
        "find",
        "much",
        "broader",
        "application",
        "statistic",
        "similar",
        "idea",
        "taken",
        "diverse",
        "field",
        "like",
        "epistemology",
        "eg",
        "shore",
        "johnson",
        "williams",
        "uffink",
        "also",
        "williamson",
        "inductive",
        "logic",
        "paris",
        "vencovska",
        "statistical",
        "mechanic",
        "jaynes",
        "decision",
        "theory",
        "seidenfeld",
        "grunwald",
        "halpern",
        "objective",
        "bayesian",
        "statistic",
        "idea",
        "applied",
        "prior",
        "distribution",
        "model",
        "cf",
        "berger",
        "finite",
        "number",
        "hypothesis",
        "entropy",
        "distribution",
        "p",
        "h_",
        "theta",
        "defined",
        "e",
        "p",
        "sum_",
        "theta",
        "in",
        "theta",
        "p",
        "h_",
        "theta",
        "log",
        "p",
        "h_",
        "theta",
        "requirement",
        "unequivocally",
        "lead",
        "equiprobable",
        "hypothesis",
        "however",
        "continuous",
        "model",
        "maximum",
        "entropy",
        "distribution",
        "depends",
        "crucially",
        "metric",
        "parameter",
        "model",
        "burden",
        "subjectivity",
        "thereby",
        "moved",
        "parameterization",
        "course",
        "may",
        "well",
        "strong",
        "reason",
        "preferring",
        "particular",
        "parameterization",
        "others",
        "cf",
        "jaynes",
        "approach",
        "objective",
        "determination",
        "prior",
        "view",
        "problem",
        "particularly",
        "attractive",
        "method",
        "choosing",
        "prior",
        "continuous",
        "model",
        "proposed",
        "jeffreys",
        "general",
        "idea",
        "socalled",
        "jeffreys",
        "prior",
        "prior",
        "probability",
        "assigned",
        "small",
        "patch",
        "parameter",
        "space",
        "proportional",
        "may",
        "called",
        "density",
        "distribution",
        "within",
        "patch",
        "intuitively",
        "lot",
        "distribution",
        "ie",
        "distribution",
        "differ",
        "quite",
        "lot",
        "among",
        "packed",
        "together",
        "small",
        "patch",
        "parameter",
        "space",
        "patch",
        "given",
        "larger",
        "prior",
        "probability",
        "similar",
        "patch",
        "within",
        "little",
        "variation",
        "among",
        "distribution",
        "cf",
        "balasubramanian",
        "technically",
        "density",
        "expressed",
        "prior",
        "distribution",
        "proportional",
        "fisher",
        "information",
        "key",
        "advantage",
        "prior",
        "invariant",
        "reparameterizations",
        "parameter",
        "space",
        "new",
        "parameterization",
        "naturally",
        "lead",
        "adjusted",
        "density",
        "distribution",
        "final",
        "method",
        "defining",
        "prior",
        "go",
        "name",
        "reference",
        "prior",
        "berger",
        "et",
        "al",
        "proposal",
        "start",
        "observation",
        "minimize",
        "subjectivity",
        "result",
        "statistical",
        "analysis",
        "hence",
        "minimize",
        "impact",
        "prior",
        "probability",
        "posterior",
        "idea",
        "reference",
        "prior",
        "exactly",
        "allow",
        "sample",
        "data",
        "maximal",
        "say",
        "posterior",
        "distribution",
        "since",
        "outset",
        "know",
        "sample",
        "obtain",
        "prior",
        "chosen",
        "maximize",
        "expected",
        "impact",
        "data",
        "expectation",
        "must",
        "taken",
        "respect",
        "distribution",
        "sample",
        "space",
        "may",
        "well",
        "strong",
        "reason",
        "latter",
        "distribution",
        "circumventing",
        "prior",
        "different",
        "response",
        "subjectivity",
        "prior",
        "extend",
        "bayesian",
        "formalism",
        "order",
        "leave",
        "choice",
        "prior",
        "extent",
        "open",
        "subjective",
        "choice",
        "prior",
        "case",
        "circumvented",
        "two",
        "response",
        "considered",
        "detail",
        "recall",
        "prior",
        "probability",
        "distribution",
        "statistical",
        "hypothesis",
        "express",
        "uncertain",
        "opinion",
        "hypothesis",
        "right",
        "central",
        "idea",
        "behind",
        "hierarchical",
        "bayesian",
        "model",
        "gelman",
        "et",
        "al",
        "pattern",
        "putting",
        "prior",
        "statistical",
        "hypothesis",
        "repeated",
        "level",
        "prior",
        "precisely",
        "may",
        "uncertain",
        "prior",
        "probability",
        "distribution",
        "hypothesis",
        "right",
        "characterize",
        "possible",
        "prior",
        "mean",
        "set",
        "parameter",
        "express",
        "uncertainty",
        "prior",
        "choice",
        "probability",
        "distribution",
        "parameter",
        "characterize",
        "shape",
        "prior",
        "word",
        "move",
        "uncertainty",
        "one",
        "level",
        "hierarchy",
        "consider",
        "multiple",
        "prior",
        "statistical",
        "hypothesis",
        "compare",
        "performance",
        "prior",
        "sample",
        "data",
        "prior",
        "hypothesis",
        "idea",
        "hierarchical",
        "bayesian",
        "modeling",
        "gelman",
        "et",
        "al",
        "relates",
        "naturally",
        "bayesian",
        "comparison",
        "carnapian",
        "prediction",
        "rule",
        "eg",
        "skyrms",
        "festa",
        "also",
        "estimation",
        "optimum",
        "inductive",
        "method",
        "kuiper",
        "festa",
        "hierarchical",
        "bayesian",
        "modeling",
        "also",
        "related",
        "another",
        "tool",
        "choosing",
        "particular",
        "prior",
        "distribution",
        "hypothesis",
        "namely",
        "method",
        "empirical",
        "bayes",
        "estimate",
        "prior",
        "lead",
        "maximal",
        "marginal",
        "likelihood",
        "model",
        "philosophy",
        "science",
        "hierarchical",
        "bayesian",
        "modeling",
        "made",
        "first",
        "appearance",
        "due",
        "henderson",
        "et",
        "al",
        "also",
        "response",
        "avoids",
        "choice",
        "prior",
        "altogether",
        "response",
        "start",
        "idea",
        "hierarchical",
        "model",
        "rather",
        "considering",
        "single",
        "prior",
        "hypothesis",
        "model",
        "consider",
        "parameterized",
        "set",
        "instead",
        "defining",
        "distribution",
        "set",
        "proponent",
        "intervalvalued",
        "imprecise",
        "probability",
        "claim",
        "epistemic",
        "state",
        "regarding",
        "prior",
        "better",
        "expressed",
        "set",
        "distribution",
        "sharp",
        "probability",
        "assignment",
        "must",
        "therefore",
        "replaced",
        "lower",
        "upper",
        "bound",
        "assignment",
        "idea",
        "uncertain",
        "opinion",
        "best",
        "captured",
        "set",
        "probability",
        "assignment",
        "credal",
        "set",
        "short",
        "long",
        "history",
        "backed",
        "extensive",
        "literature",
        "eg",
        "de",
        "finetti",
        "levi",
        "dempster",
        "shafer",
        "walley",
        "light",
        "main",
        "debate",
        "philosophy",
        "statistic",
        "use",
        "intervalvalued",
        "prior",
        "indeed",
        "form",
        "attractive",
        "extension",
        "bayesian",
        "statistic",
        "allows",
        "u",
        "refrain",
        "choosing",
        "specific",
        "prior",
        "thereby",
        "present",
        "rapprochement",
        "classical",
        "view",
        "statistic",
        "theoretical",
        "development",
        "may",
        "look",
        "attractive",
        "fact",
        "mostly",
        "enjoy",
        "cult",
        "status",
        "among",
        "philosopher",
        "statistic",
        "moved",
        "statistician",
        "street",
        "hand",
        "standard",
        "bayesian",
        "statistic",
        "seen",
        "steep",
        "rise",
        "popularity",
        "past",
        "decade",
        "owing",
        "availability",
        "good",
        "software",
        "numerical",
        "approximation",
        "method",
        "practical",
        "use",
        "bayesian",
        "statistic",
        "le",
        "insensitive",
        "potentially",
        "subjective",
        "aspect",
        "statistical",
        "result",
        "employing",
        "uniform",
        "prior",
        "neutral",
        "starting",
        "point",
        "analysis",
        "relying",
        "aforementioned",
        "convergence",
        "result",
        "wash",
        "remaining",
        "subjectivity",
        "cf",
        "gelman",
        "shalizi",
        "however",
        "practical",
        "attitude",
        "scientist",
        "towards",
        "modelling",
        "mistaken",
        "principled",
        "answer",
        "question",
        "raised",
        "philosophy",
        "statistic",
        "see",
        "morey",
        "et",
        "al",
        "statistical",
        "model",
        "foregoing",
        "seen",
        "classical",
        "bayesian",
        "statistic",
        "differ",
        "two",
        "major",
        "approach",
        "statistic",
        "also",
        "lot",
        "common",
        "importantly",
        "statistical",
        "procedure",
        "rely",
        "assumption",
        "statistical",
        "model",
        "referring",
        "restricted",
        "set",
        "statistical",
        "hypothesis",
        "moreover",
        "aimed",
        "delivering",
        "verdict",
        "hypothesis",
        "example",
        "classical",
        "likelihood",
        "ratio",
        "test",
        "considers",
        "two",
        "hypothesis",
        "h",
        "h",
        "offer",
        "verdict",
        "rejection",
        "acceptance",
        "bayesian",
        "comparison",
        "delivers",
        "posterior",
        "probability",
        "two",
        "hypothesis",
        "whereas",
        "bayesian",
        "statistic",
        "model",
        "present",
        "strong",
        "assumption",
        "classical",
        "statistic",
        "endow",
        "model",
        "special",
        "epistemic",
        "status",
        "simply",
        "hypothesis",
        "currently",
        "entertained",
        "scientist",
        "across",
        "board",
        "adoption",
        "model",
        "absolutely",
        "central",
        "statistical",
        "procedure",
        "natural",
        "question",
        "whether",
        "anything",
        "said",
        "quality",
        "statistical",
        "model",
        "whether",
        "verdict",
        "starting",
        "point",
        "statistical",
        "procedure",
        "given",
        "surely",
        "model",
        "lead",
        "better",
        "prediction",
        "better",
        "guide",
        "truth",
        "others",
        "evaluation",
        "model",
        "touch",
        "deep",
        "issue",
        "philosophy",
        "science",
        "statistical",
        "model",
        "often",
        "determines",
        "datagenerating",
        "system",
        "investigation",
        "conceptualized",
        "approached",
        "kieseppa",
        "model",
        "choice",
        "thus",
        "resembles",
        "choice",
        "theory",
        "conceptual",
        "scheme",
        "even",
        "whole",
        "paradigm",
        "thereby",
        "might",
        "seem",
        "transcend",
        "formal",
        "framework",
        "studying",
        "theoretical",
        "rationality",
        "cf",
        "carnap",
        "jeffrey",
        "despite",
        "fact",
        "consideration",
        "model",
        "choice",
        "seem",
        "extrastatistical",
        "sense",
        "fall",
        "outside",
        "scope",
        "statistical",
        "treatment",
        "statistic",
        "offer",
        "several",
        "method",
        "approaching",
        "choice",
        "statistical",
        "model",
        "model",
        "comparison",
        "fact",
        "many",
        "method",
        "evaluating",
        "statistical",
        "model",
        "claeskens",
        "hjort",
        "wagenmakers",
        "waldorp",
        "first",
        "instance",
        "method",
        "occasion",
        "comparison",
        "statistical",
        "model",
        "often",
        "used",
        "selecting",
        "one",
        "model",
        "others",
        "follows",
        "review",
        "prominent",
        "technique",
        "led",
        "philosophical",
        "debate",
        "akaike",
        "s",
        "information",
        "criterion",
        "bayesian",
        "information",
        "criterion",
        "furthermore",
        "computation",
        "marginal",
        "likelihood",
        "posterior",
        "model",
        "probability",
        "associated",
        "bayesian",
        "model",
        "selection",
        "leave",
        "aside",
        "method",
        "use",
        "crossvalidation",
        "unduly",
        "received",
        "much",
        "attention",
        "philosophical",
        "literature",
        "akaike",
        "s",
        "information",
        "criterion",
        "akaike",
        "s",
        "information",
        "criterion",
        "modestly",
        "termed",
        "information",
        "criterion",
        "aic",
        "short",
        "based",
        "classical",
        "statistical",
        "procedure",
        "estimation",
        "see",
        "burnham",
        "anderson",
        "kieseppa",
        "start",
        "idea",
        "model",
        "m",
        "judged",
        "estimate",
        "hat",
        "theta",
        "delivers",
        "specifically",
        "proximity",
        "estimate",
        "distribution",
        "data",
        "actually",
        "generated",
        "ie",
        "true",
        "distribution",
        "proximity",
        "often",
        "equated",
        "expected",
        "predictive",
        "accuracy",
        "estimate",
        "estimate",
        "true",
        "distribution",
        "closer",
        "prediction",
        "better",
        "aligned",
        "one",
        "another",
        "well",
        "derivation",
        "aic",
        "socalled",
        "relative",
        "entropy",
        "kullbackleibler",
        "divergence",
        "two",
        "distribution",
        "used",
        "measure",
        "proximity",
        "hence",
        "measure",
        "expected",
        "predictive",
        "accuracy",
        "estimate",
        "naturally",
        "true",
        "distribution",
        "known",
        "statistician",
        "evaluating",
        "model",
        "whole",
        "statistical",
        "analysis",
        "would",
        "useless",
        "however",
        "turn",
        "give",
        "unbiased",
        "estimation",
        "divergence",
        "true",
        "distribution",
        "distribution",
        "estimated",
        "particular",
        "model",
        "text",
        "aic",
        "log",
        "p",
        "mid",
        "h_",
        "hat",
        "theta",
        "s",
        "sample",
        "data",
        "hat",
        "theta",
        "maximum",
        "likelihood",
        "estimate",
        "mle",
        "model",
        "m",
        "dim",
        "theta",
        "number",
        "dimension",
        "parameter",
        "space",
        "model",
        "mle",
        "model",
        "thereby",
        "feature",
        "expression",
        "model",
        "quality",
        "ie",
        "role",
        "conceptually",
        "distinct",
        "estimator",
        "function",
        "seen",
        "expression",
        "model",
        "smaller",
        "aic",
        "preferable",
        "want",
        "fit",
        "optimal",
        "little",
        "cost",
        "complexity",
        "notice",
        "number",
        "dimension",
        "independent",
        "parameter",
        "model",
        "increase",
        "aic",
        "thereby",
        "lower",
        "eligibility",
        "model",
        "two",
        "model",
        "achieve",
        "maximum",
        "likelihood",
        "sample",
        "model",
        "fewer",
        "parameter",
        "preferred",
        "reason",
        "statistical",
        "model",
        "selection",
        "aic",
        "seen",
        "independent",
        "motivation",
        "preferring",
        "simple",
        "model",
        "complex",
        "one",
        "sober",
        "forster",
        "result",
        "also",
        "invite",
        "critical",
        "remark",
        "one",
        "might",
        "impose",
        "criterion",
        "merely",
        "unbiasedness",
        "estimation",
        "proximity",
        "truth",
        "lead",
        "different",
        "expression",
        "approximation",
        "moreover",
        "always",
        "clearcut",
        "dimension",
        "model",
        "scrutiny",
        "really",
        "curve",
        "fitting",
        "may",
        "seem",
        "simple",
        "complicated",
        "model",
        "different",
        "conceptualization",
        "space",
        "model",
        "thing",
        "look",
        "easy",
        "cf",
        "myung",
        "et",
        "al",
        "kieseppa",
        "prime",
        "example",
        "model",
        "selection",
        "presented",
        "curve",
        "fitting",
        "given",
        "sample",
        "s",
        "consisting",
        "set",
        "point",
        "plane",
        "x",
        "asked",
        "choose",
        "curve",
        "fit",
        "data",
        "best",
        "assume",
        "model",
        "consideration",
        "form",
        "f",
        "x",
        "epsilon",
        "epsilon",
        "normal",
        "distribution",
        "mean",
        "fixed",
        "standard",
        "deviation",
        "f",
        "polynomial",
        "function",
        "different",
        "model",
        "characterized",
        "polynomial",
        "different",
        "degree",
        "different",
        "number",
        "parameter",
        "estimation",
        "fix",
        "parameter",
        "polynomial",
        "example",
        "degree",
        "polynomial",
        "f",
        "x",
        "c_",
        "estimate",
        "constant",
        "hat",
        "c_",
        "probability",
        "data",
        "maximal",
        "degree",
        "polynomial",
        "f",
        "x",
        "c_",
        "c_",
        "x",
        "estimate",
        "slope",
        "hat",
        "c_",
        "offset",
        "hat",
        "c_",
        "notice",
        "total",
        "n",
        "point",
        "always",
        "find",
        "polynomial",
        "degree",
        "n",
        "intersects",
        "point",
        "exactly",
        "resulting",
        "comparatively",
        "high",
        "maximum",
        "likelihood",
        "p",
        "mid",
        "hat",
        "c_",
        "ldots",
        "hat",
        "c_",
        "n",
        "applying",
        "aic",
        "however",
        "typically",
        "find",
        "model",
        "polynomial",
        "degree",
        "k",
        "n",
        "preferable",
        "although",
        "p",
        "mid",
        "hat",
        "c_",
        "ldots",
        "hat",
        "c_",
        "k",
        "somewhat",
        "lower",
        "compensated",
        "aic",
        "smaller",
        "number",
        "parameter",
        "bayesian",
        "evaluation",
        "model",
        "various",
        "prominent",
        "model",
        "selection",
        "tool",
        "based",
        "method",
        "bayesian",
        "statistic",
        "start",
        "idea",
        "quality",
        "model",
        "expressed",
        "performance",
        "model",
        "sample",
        "data",
        "model",
        "whole",
        "make",
        "sampled",
        "data",
        "probable",
        "preferred",
        "close",
        "connection",
        "hierarchical",
        "bayesian",
        "modelling",
        "referred",
        "earlier",
        "gelman",
        "central",
        "notion",
        "bayesian",
        "model",
        "selection",
        "tool",
        "thus",
        "marginal",
        "likelihood",
        "model",
        "ie",
        "weighted",
        "average",
        "likelihood",
        "model",
        "using",
        "prior",
        "distribution",
        "weighing",
        "function",
        "p",
        "mid",
        "m_",
        "int_",
        "theta",
        "in",
        "theta_",
        "p",
        "h_",
        "theta",
        "p",
        "mid",
        "h_",
        "theta",
        "dtheta",
        "theta_",
        "parameter",
        "space",
        "belonging",
        "model",
        "m_",
        "marginal",
        "likelihood",
        "combined",
        "prior",
        "probability",
        "model",
        "p",
        "m_",
        "derive",
        "socalled",
        "posterior",
        "model",
        "probability",
        "using",
        "bayes",
        "theorem",
        "one",
        "way",
        "evaluating",
        "model",
        "known",
        "bayesian",
        "model",
        "selection",
        "comparing",
        "model",
        "marginal",
        "likelihood",
        "else",
        "posterior",
        "cf",
        "ka",
        "raftery",
        "usually",
        "marginal",
        "likelihood",
        "computed",
        "analytically",
        "numerical",
        "approximation",
        "often",
        "obtained",
        "practical",
        "purpose",
        "proved",
        "useful",
        "quite",
        "sufficient",
        "employ",
        "approximation",
        "marginal",
        "likelihood",
        "approximation",
        "become",
        "known",
        "bayesian",
        "information",
        "criterion",
        "bic",
        "short",
        "schwarz",
        "raftery",
        "turn",
        "approximation",
        "show",
        "remarkable",
        "similarity",
        "aic",
        "text",
        "bic",
        "log",
        "p",
        "mid",
        "h_",
        "hat",
        "theta",
        "log",
        "n",
        "hat",
        "theta",
        "maximum",
        "likelihood",
        "estimate",
        "model",
        "dim",
        "number",
        "independent",
        "parameter",
        "n",
        "number",
        "data",
        "point",
        "sample",
        "latter",
        "dependence",
        "difference",
        "aic",
        "major",
        "difference",
        "model",
        "evaluation",
        "may",
        "turn",
        "concurrence",
        "aic",
        "bic",
        "seems",
        "give",
        "motivation",
        "intuitive",
        "preference",
        "simple",
        "model",
        "complex",
        "one",
        "indeed",
        "model",
        "selection",
        "tool",
        "like",
        "deviance",
        "information",
        "criterion",
        "spiegelhalter",
        "et",
        "al",
        "approach",
        "based",
        "minimum",
        "description",
        "length",
        "grunwald",
        "also",
        "result",
        "expression",
        "feature",
        "term",
        "penalizes",
        "complex",
        "model",
        "however",
        "say",
        "dimension",
        "term",
        "know",
        "information",
        "criterion",
        "exhaust",
        "notion",
        "model",
        "complexity",
        "ongoing",
        "debate",
        "philosophy",
        "science",
        "concerning",
        "merit",
        "model",
        "selection",
        "explication",
        "notion",
        "simplicity",
        "informativeness",
        "like",
        "see",
        "example",
        "sober",
        "romeijn",
        "van",
        "de",
        "schoot",
        "romeijn",
        "et",
        "al",
        "sprenger",
        "statistic",
        "without",
        "model",
        "also",
        "statistical",
        "method",
        "refrain",
        "use",
        "particular",
        "model",
        "focusing",
        "exclusively",
        "data",
        "generalizing",
        "possible",
        "model",
        "technique",
        "properly",
        "localized",
        "descriptive",
        "statistic",
        "concern",
        "inference",
        "data",
        "merely",
        "serve",
        "describe",
        "data",
        "particular",
        "way",
        "statistical",
        "method",
        "rely",
        "explicit",
        "model",
        "choice",
        "unfortunately",
        "attracted",
        "much",
        "attention",
        "philosophy",
        "statistic",
        "completeness",
        "sake",
        "briefly",
        "discussed",
        "data",
        "reduction",
        "technique",
        "one",
        "set",
        "method",
        "quite",
        "important",
        "one",
        "many",
        "practicing",
        "statistician",
        "aimed",
        "data",
        "reduction",
        "often",
        "sample",
        "data",
        "rich",
        "eg",
        "consisting",
        "set",
        "point",
        "space",
        "many",
        "dimension",
        "first",
        "step",
        "statistical",
        "analysis",
        "may",
        "pick",
        "salient",
        "variability",
        "data",
        "order",
        "scale",
        "computational",
        "burden",
        "analysis",
        "technique",
        "principal",
        "component",
        "analysis",
        "pca",
        "designed",
        "purpose",
        "jolliffe",
        "given",
        "set",
        "point",
        "space",
        "seek",
        "set",
        "vector",
        "along",
        "variation",
        "point",
        "large",
        "example",
        "consider",
        "two",
        "point",
        "plane",
        "parameterized",
        "x",
        "point",
        "x",
        "direction",
        "y",
        "direction",
        "variation",
        "diagonal",
        "variation",
        "maximal",
        "namely",
        "sqrt",
        "vector",
        "diagonal",
        "called",
        "principal",
        "component",
        "data",
        "richer",
        "data",
        "structure",
        "using",
        "general",
        "measure",
        "variation",
        "among",
        "point",
        "find",
        "first",
        "component",
        "similar",
        "way",
        "moreover",
        "repeat",
        "procedure",
        "subtracting",
        "variation",
        "along",
        "last",
        "found",
        "component",
        "projecting",
        "data",
        "onto",
        "plane",
        "perpendicular",
        "component",
        "allows",
        "u",
        "build",
        "set",
        "principal",
        "component",
        "diminishing",
        "importance",
        "pca",
        "one",
        "item",
        "large",
        "collection",
        "technique",
        "aimed",
        "keeping",
        "data",
        "manageable",
        "finding",
        "pattern",
        "collection",
        "also",
        "includes",
        "kernel",
        "method",
        "support",
        "vector",
        "machine",
        "eg",
        "vapnik",
        "kotz",
        "present",
        "purpose",
        "important",
        "stress",
        "tool",
        "confused",
        "statistical",
        "analysis",
        "involve",
        "testing",
        "evaluation",
        "distribution",
        "sample",
        "space",
        "even",
        "though",
        "build",
        "evaluate",
        "model",
        "data",
        "set",
        "apart",
        "eg",
        "confirmatory",
        "exploratory",
        "factor",
        "analysis",
        "bartholomew",
        "sometimes",
        "taken",
        "close",
        "relative",
        "pca",
        "set",
        "technique",
        "allows",
        "u",
        "identify",
        "salient",
        "dimension",
        "within",
        "sample",
        "space",
        "along",
        "data",
        "show",
        "large",
        "variation",
        "practicing",
        "statistician",
        "often",
        "employ",
        "data",
        "reduction",
        "tool",
        "arrive",
        "conclusion",
        "distribution",
        "data",
        "sampled",
        "already",
        "wide",
        "use",
        "machine",
        "learning",
        "data",
        "mining",
        "technique",
        "science",
        "may",
        "expect",
        "even",
        "mode",
        "usage",
        "technique",
        "future",
        "much",
        "data",
        "coming",
        "available",
        "scientific",
        "analysis",
        "however",
        "philosophy",
        "statistic",
        "yet",
        "little",
        "debate",
        "epistemic",
        "status",
        "conclusion",
        "reached",
        "mean",
        "technique",
        "philosopher",
        "statistic",
        "would",
        "well",
        "direct",
        "attention",
        "formal",
        "learning",
        "theory",
        "entirely",
        "different",
        "approach",
        "statistic",
        "presented",
        "formal",
        "learning",
        "theory",
        "vast",
        "area",
        "research",
        "primarily",
        "located",
        "computer",
        "science",
        "artificial",
        "intelligence",
        "discipline",
        "mentioned",
        "briefly",
        "another",
        "example",
        "approach",
        "statistic",
        "avoids",
        "choice",
        "statistical",
        "model",
        "altogether",
        "merely",
        "identifies",
        "pattern",
        "data",
        "leave",
        "aside",
        "theory",
        "neural",
        "network",
        "also",
        "concern",
        "predictive",
        "system",
        "rely",
        "statistical",
        "model",
        "focus",
        "theory",
        "learning",
        "algorithm",
        "approach",
        "seen",
        "philosophical",
        "attention",
        "pioneering",
        "work",
        "formal",
        "learning",
        "done",
        "solomonoff",
        "setting",
        "one",
        "data",
        "consist",
        "string",
        "s",
        "s",
        "agent",
        "attempting",
        "identify",
        "pattern",
        "data",
        "example",
        "data",
        "may",
        "string",
        "form",
        "ldots",
        "challenge",
        "identify",
        "string",
        "alternating",
        "sequence",
        "central",
        "idea",
        "solomonoff",
        "possible",
        "computable",
        "pattern",
        "must",
        "considered",
        "agent",
        "therefore",
        "restrictive",
        "choice",
        "statistical",
        "hypothesis",
        "warranted",
        "solomonoff",
        "defined",
        "formal",
        "system",
        "indeed",
        "pattern",
        "taken",
        "consideration",
        "effectively",
        "using",
        "bayesian",
        "analysis",
        "cleverly",
        "constructed",
        "prior",
        "computable",
        "hypothesis",
        "general",
        "idea",
        "also",
        "identified",
        "rather",
        "new",
        "field",
        "intersection",
        "bayesian",
        "statistic",
        "machine",
        "learning",
        "bayesian",
        "nonparametrics",
        "eg",
        "orbanz",
        "teh",
        "hjort",
        "et",
        "al",
        "rather",
        "specifying",
        "outset",
        "confined",
        "set",
        "distribution",
        "statistical",
        "analysis",
        "supposed",
        "choose",
        "basis",
        "data",
        "idea",
        "data",
        "confronted",
        "potentially",
        "infinitedimensional",
        "space",
        "possible",
        "distribution",
        "set",
        "distribution",
        "taken",
        "consideration",
        "made",
        "relative",
        "data",
        "obtained",
        "complexity",
        "model",
        "grows",
        "sample",
        "result",
        "predictive",
        "system",
        "performs",
        "online",
        "model",
        "selection",
        "alongside",
        "bayesian",
        "accommodation",
        "posterior",
        "model",
        "current",
        "formal",
        "learning",
        "theory",
        "lively",
        "field",
        "philosopher",
        "statistic",
        "also",
        "contribute",
        "eg",
        "kelly",
        "kelly",
        "et",
        "al",
        "particularly",
        "salient",
        "present",
        "concern",
        "system",
        "formal",
        "learning",
        "set",
        "achieve",
        "notion",
        "adequate",
        "universal",
        "prediction",
        "without",
        "confining",
        "specific",
        "set",
        "hypothesis",
        "hence",
        "imposing",
        "minimal",
        "constraint",
        "set",
        "possible",
        "pattern",
        "data",
        "matter",
        "debate",
        "whether",
        "possible",
        "extent",
        "prediction",
        "formal",
        "learning",
        "theory",
        "thereby",
        "rely",
        "eg",
        "implicit",
        "assumption",
        "structure",
        "sample",
        "space",
        "philosophical",
        "reflection",
        "infancy",
        "related",
        "topic",
        "numerous",
        "topic",
        "philosophy",
        "science",
        "bear",
        "direct",
        "relevance",
        "theme",
        "covered",
        "lemma",
        "central",
        "topic",
        "mentioned",
        "direct",
        "reader",
        "related",
        "lemma",
        "encyclopedia",
        "one",
        "important",
        "topic",
        "immediately",
        "adjacent",
        "philosophy",
        "statistic",
        "confirmation",
        "theory",
        "philosophical",
        "theory",
        "describes",
        "justifies",
        "relation",
        "scientific",
        "theory",
        "empirical",
        "evidence",
        "arguably",
        "theory",
        "statistic",
        "proper",
        "part",
        "confirmation",
        "theory",
        "describes",
        "justifies",
        "relation",
        "obtains",
        "statistical",
        "theory",
        "evidence",
        "form",
        "sample",
        "insightful",
        "place",
        "statistical",
        "procedure",
        "wider",
        "framework",
        "relation",
        "evidence",
        "theory",
        "zooming",
        "even",
        "philosophy",
        "statistic",
        "part",
        "philosophical",
        "topic",
        "methodology",
        "ie",
        "general",
        "theory",
        "whether",
        "science",
        "acquires",
        "knowledge",
        "thus",
        "conceived",
        "statistic",
        "one",
        "component",
        "large",
        "collection",
        "scientific",
        "method",
        "comprising",
        "concept",
        "formation",
        "experimental",
        "design",
        "manipulation",
        "observation",
        "confirmation",
        "revision",
        "theorizing",
        "also",
        "fair",
        "number",
        "specific",
        "topic",
        "philosophy",
        "science",
        "spelled",
        "term",
        "statistic",
        "located",
        "close",
        "proximity",
        "one",
        "topic",
        "process",
        "measurement",
        "particular",
        "measurement",
        "latent",
        "variable",
        "basis",
        "statistical",
        "fact",
        "manifest",
        "variable",
        "socalled",
        "representational",
        "theory",
        "measurement",
        "kranz",
        "et",
        "al",
        "relies",
        "statistic",
        "particular",
        "factor",
        "analysis",
        "provide",
        "conceptual",
        "clarification",
        "mathematical",
        "structure",
        "represent",
        "empirical",
        "phenomenon",
        "another",
        "important",
        "topic",
        "form",
        "philosophy",
        "science",
        "causation",
        "see",
        "entry",
        "probabilistic",
        "causation",
        "reichenbach",
        "s",
        "common",
        "cause",
        "principle",
        "philosopher",
        "employed",
        "probability",
        "theory",
        "capture",
        "causal",
        "relation",
        "ever",
        "since",
        "reichenbach",
        "recent",
        "work",
        "causality",
        "statistic",
        "eg",
        "spirtes",
        "et",
        "al",
        "given",
        "theory",
        "probabilistic",
        "causality",
        "enormous",
        "impulse",
        "statistic",
        "provides",
        "basis",
        "conceptual",
        "analysis",
        "causal",
        "relation",
        "much",
        "several",
        "specific",
        "statistical",
        "technique",
        "like",
        "factor",
        "analysis",
        "theory",
        "bayesian",
        "network",
        "invite",
        "conceptual",
        "discussion",
        "accord",
        "numerous",
        "topic",
        "within",
        "philosophy",
        "science",
        "lend",
        "statistical",
        "elucidation",
        "eg",
        "coherence",
        "informativeness",
        "surprise",
        "evidence",
        "turn",
        "wide",
        "range",
        "discussion",
        "philosophy",
        "science",
        "inform",
        "proper",
        "understanding",
        "statistic",
        "among",
        "debate",
        "experimentation",
        "intervention",
        "concept",
        "chance",
        "nature",
        "scientific",
        "model",
        "theoretical",
        "term",
        "reader",
        "invited",
        "consult",
        "entry",
        "topic",
        "find",
        "indication",
        "relate",
        "philosophy",
        "statistic"
    ]
}